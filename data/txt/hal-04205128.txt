Driver Model for Take-Over-Request in Autonomous
Vehicles
Ankica Barisic, Pierre Sigrist, Sylvain Oliver, Aurélien Sciarra, Marco

Winckler

To cite this version:

Ankica Barisic, Pierre Sigrist, Sylvain Oliver, Aurélien Sciarra, Marco Winckler. Driver Model for
Take-Over-Request in Autonomous Vehicles. UMAP 2023 - 31st ACM Conference on User Modeling,
Adaptation and Personalization, Jun 2023, Limassol, Cyprus. pp.317-324, ￿10.1145/3563359.3596994￿.
￿hal-04205128￿

HAL Id: hal-04205128

https://hal.science/hal-04205128

Submitted on 12 Sep 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Driver Model for Take-Over-Request in Autonomous Vehicles
Pierre Sigrist
Epicenpoc
Sophia Antipolis, France
pierre.sigrist@epicnpoc.com

Sylvain Oliver
Avisto
Vallauris, France
sylvain.oliver@avisto.com

Ankica Barišić
Université Côte d’Azur, CNRS, INRIA,
I3S
Sophia Antipolis, France
Ankica.Barisic@univ-cotedazur.fr

Aurélien Sciarra
Avisto
Vallauris, France
aurelien.sciarra@avisto.com

Marco Winckler
Université Côte d’Azur, CNRS, INRIA,
I3S
Sophia Antipolis, France
Marco.Winckler@univ-cotedazur.fr

ABSTRACT
This work presents a driver model for Take-Over-Request (TOR) in
autonomous vehicles (AVs) that considers the driver’s mental state
and response time during the transition from automatic to manual
driving modes. The Fallback Ready User (FRU) is introduced as a key
component that defines the minimum attention required from the
driver to respond to TORs and system failures. Highly adaptive FRU
models are essential for ensuring the safety of AVs. By using non-
intrusive methods, such as facial expression tracking, to capture
the driver’s mental state and improve AV safety we study shared
control between the vehicle and driver during TOR. The paper
presents two application scenarios for TOR analysis in ADAVEC
system: detecting when the driver is ready for TOR and reacting
to unpredictable situations, such as driver sickness or drowsiness.
The proposed driver model considers user personalization based
on high-level features, long-term changes, and real-time evidence.

CCS CONCEPTS
• Human-centered computing → User models; User centered
design; • Software and its engineering → Empirical software
validation; • Computing methodologies → Modeling method-
ologies; • Applied computing → Transportation.

KEYWORDS
User Profiling, Human Factors, Overlay User Model, Autonomous
Vehicles, Control transfer, Takeover Request, Reaction Time

ACM Reference Format:
Ankica Barišić, Pierre Sigrist, Sylvain Oliver, Aurélien Sciarra, and Marco
Winckler. 2023. Driver Model for Take-Over-Request in Autonomous Vehi-
cles. In Adjunct Proceedings of the 31st ACM Conference on User Modeling,
Adaptation and Personalization (UMAP ’23 Adjunct), June 26–29, 2023, Li-
massol, Cyprus. ACM, New York, NY, USA, 8 pages. https://doi.org/10.1145/
3563359.3596994

Publication rights licensed to ACM. ACM acknowledges that this contribution was
authored or co-authored by an employee, contractor or affiliate of a national govern-
ment. As such, the Government retains a nonexclusive, royalty-free right to publish or
reproduce this article, or to allow others to do so, for Government purposes only.
UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus
© 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-9891-6/23/06. . . $15.00
https://doi.org/10.1145/3563359.3596994

1 INTRODUCTION
The field of autonomous vehicles (AVs) has grown rapidly with
the aim of reducing human error and decreasing fatalities on the
road. With the ultimate goal of achieving a Level 5 fully self-driving
vehicle that can perform the Dynamic Driving Task (DDT) without
any human intervention, addressing human factors remains a chal-
lenge. In Level 3 AVs, which are expected to perform the complete
Dynamic Driving Task (DDT) within its Operational Design Do-
main (ODD), a safe transition process from the Automated Driving
System (ADS) mode to manual driving is crucial [1]. This transition
requires AVs to issue an appropriate Take Over Request (TOR), and
the driver’s state plays a crucial role in this process, as a low level
of attention can increase the driver’s reaction time to take over
control of the vehicle [10].

As automation increases, the driver’s workload decreases, re-
sulting in a lower level of attention paid to the system while it is
operating[4]. This can lead to boredom and states such as drowsi-
ness or sleepiness [15]. Furthermore, more effective communication
methods for conveying TOR messages to the driver could reduce the
overall time required to safely take over control of the vehicle[6].
To address these challenges, we profiled the driver’s characteristics
relevant to TOR and studied how to measure the reaction times
of drivers continuously during autonomous operation, taking into
account different mental states and communication methods. We
illustrate our findings, based on state-of-the-art emphasis to have
highly adaptive models that gather information about individual
drivers, in the case of ADAVEC system. The ADAVEC system is
in charge to operate the authority change following a protocol
and a series of rules that take into account the driver’s state and
mastering of the situation when such a change is being operated.
The paper is structured as follows: Section 2 highlights the need
to capture the individual driver’s state for TOR, Section 3 gives an
overview of existing studies to capture driver’s mental state and
response time in AV, Section 4 emphasizes multimodal interaction
design for the warning system, Section 5 introduces the ADAVEC
system environment, proposes the driver’s model, and presents an
illustrative scenario for monitoring driver reaction time. Finally,
Section 6 gives pointers for future work and concludes.

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

A. Barišić, P. Sigrist, S. Oliver, A. Sciarra and M. Winckler

2 HIGHLY ADAPTIVE DRIVER MODEL
From SAE Level 3 (Conditional Automation), the vehicle expects
that the Fallback Ready User (FRU) is responsive to Autonomous
Driving System (ADS) requests to intervene, called Take Over Re-
quest (TOR), as well as being able to properly detect and respond
to DDT-related system failures [1]. The TOR is a concept being
studied in the context of the ADAVEC project, falling between SAE
Level 3 and Level 4 (High automation), by executing automatically
the driving function while keeping the driver informed and ready
to take control at any time. Idea is to ensure a safe transition from
automatic to manual driving mode while considering the AV and
driver’s state.

When a TOR is issued, drivers must process information from
the environment and react in a reasonable time by activating the
vehicle actuators to perform the dynamic driving task based on
their understanding of the present situation. Before triggering a
TOR, internal and external information about the driver’s state and
driving situation should be gathered for a safe outcome, especially
in emergency situations [12].

A Fallback Ready State (FRS) can be defined as the minimum
engagement/attention/awareness necessary from the driver in order
to safely detect and react to TORs and system failures [1]. It can be
described in terms of Workload, which is defined as task demand for
the human operator to accomplish mission requirements [7]. Dunn
et al. classified workload in AV systems in terms of Environment,
Task, Equipment, and Operator [6].

The required FRS for a given situation may not be the same for
two different individuals. Moreover, the reaction before a given
stimulus (e.g. sound alert) may also be different. For example, in the
case of workload, even if a task with the same objective workload is
presented with two different users, each one may require a different
level of awareness to act correctly, as the task may be more difficult
for one person than another [2]. Variance can also happen within
the same person. If the same task is presented to a user at different
points in time, the response may change depending on previous
and current user states (e.g. level of distraction, emotions, increased
knowledge, etc.).

Therefore, it is necessary to have highly adaptive FRU models
which try to represent one particular driver and therefore allow a
very high adaptivity of the AV. In contrast to stereotype-based user
models, the idea is not to rely on demographic statistics but to find
a specific solution for each user. Although drivers can take great
benefit from this high adaptivity, this kind of model needs to gather
a lot of information first [16]. In general, there are two principal
ways for an adaptive system to obtain user modelling information:
to ask the user directly, and to derive it based on the user’s activity
with the system. We need to use a combination of these approaches,
as the natural flow of the ‘user-system’ communication, to have an
enabling infrastructure to study user experience for TOR.

The benefit of having this type of FRU model called the overlay
model, is it’s precision and flexibility. Fine-grained concept-based
modelling allows systems to adjust their actions on a very detailed
level. An overlay model is capable of dynamically and precisely
reflecting the evolution of driver characteristics [16], which is espe-
cially important for AV. Among the drawbacks of this approach is
the necessity of developing an accurate and formal domain model,

which is a hard task for some domains, however being a common
approach when working with AVs.

3 HUMAN FACTORS FOR TOR
The focus of this study is to examine the response time of drivers
to TOR while accounting for the variability in different mental
states that can impact a driver’s situational awareness. Situational
awareness refers to the driver’s knowledge about navigation, en-
vironment and interaction, spatial orientation, and vehicle status.
The objective is to assist the decision-making process of the system
during authority transfer, and to enable the validation of the dri-
ver’s reaction to multi-sensorial warnings. Training the FRU model
for each individual is necessary when measuring physiological data,
which can be challenging as it may pose a safety risk if the model
is not accurately trained. Therefore, it is essential to identify mea-
surements that are as objective and user-independent as possible
[14].

3.1 Driver mental state
A driver’s mental load, stress, drowsiness, sleepiness, and fatigue
level, among others, can reduce driver situational awareness, lead-
ing to longer response times or even a complete inability to re-
spond to TOR. It is essential to track the driver’s mental state non-
intrusively and communicate effectively to retain their attention
when needed.

Using biosignals, such as facial expressions, to determine the dri-
ver’s state is a promising approach that eliminates the need for mul-
tiple sensors in the vehicle, which can be distracting [9]. In-vehicle
multi-modal data stream predictors through facial expressions, like
Face2Multi-modal, provide a more user-friendly approach to cap-
turing a driver’s mental state. The collected data could serve as the
building block for personalized Human-Machine Interaction (HMI)
designs.

Recent studies have shown that subject-dependent classification
and imbalance distributions play a crucial role in driver sleepi-
ness detection in realistic conditions [14]. A field-driving study
resulted in a database that showed a significant decrease in subject-
independent classification, highlighting the importance of captur-
ing the driver’s mental state accurately in subject-dependant men-
ner. Therefore, using cameras to capture the driver’s mental state
is a promising solution for improving AV safety.

3.2 Driver response time
Driver response time is a critical factor in TOR. When a transition
of control from automated to manual driving is required, there
is an interval for the driver to take control of the vehicle safely.
During this interval, the driver needs to adapt from a state of low
situational awareness to a higher one [5]. Shared control between
the vehicle and the driver should be guaranteed during this interval.
One of the biggest challenges is to create a system that conveys the
message in a clear, explicit way, while at the same time allowing
for the possibility of continued automated control of the vehicle in
the event that the driver cannot take over [11].

In [10], the authors introduce three different measures for dri-
ver response time: Take Over Time (TOT), Take Over Reaction Time
(TOrt), and Lead time from a TOR to a critical event (TORlt). TOT is

Driver Model for Take-Over-Request in Autonomous Vehicles

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

the time interval from when the transition of control is initiated
until the driver has successfully taken control of the vehicle and
resumed the driving task. TOrt is the time needed to return control
of the vehicle to the human driver. TORlt determines the time it
takes drivers to resume control from conditional automation in
noncritical scenarios. The impact of different TORlt on drivers was
studied, and the authors concluded that drivers require approx-
imately 7 seconds to regain control of the vehicle. While some
studies suggested that TOrt should be between 2 and 3.5 seconds,
other studies showed that participants needed less than 1 second
to take the vehicle.

It is essential to give drivers enough time to adapt to the situation,
but not too long as it could confuse them due to the lack of an
imminent emergency. On the other hand, some drivers might check
the mirrors or adjust their seating position before taking control of
the vehicle. An overview of the different reaction times measured in
various scenarios can be found in [10]. Response time from various
alerts needs to be assessed from the time the alert began to the first
indication of a response from the driver [15].

To model and predict the return time of the driver, one of the
known approaches is to use a Bayesian point process, such as the
log Gaussian Cox process [17]. This approach enables encoding
the prior domain knowledge and non-parametric estimation of
latent intensity functions that capture user reaction. It allows for
capturing the similarities among users in their return time by using
a multi-task learning approach. Another model to predict driver
performance, but related more to studying driver behavior, can be
found in [3].

4 MULTIMODAL INTERACTION DESIGN FOR

TOR WARNING SYSTEM

The way the AV behaves and communicates with the driver also
requires personalization. The communication methods and amount
of information necessary to keep the "human in the loop" may also
depend on the preferences of each user. An individual may prefer
a higher amount of information and communication in a mostly
visual manner, while others may prefer a more simplified interface
and voice communication [13].

The design of warning systems to capture drivers’ attention in
safety-critical situations has been a topic of interest for researchers.
Research studies have shown that using a multisensory approach,
also known as multimodal interaction design, increases the effec-
tiveness of Human-Machine Interaction (HMI) [6, 8, 10]. The most
common methods used in this approach are visual, sound, and haptic
modalities. Redundancy, or the use of multiple modalities for pre-
senting the same information, can significantly increase alertness
and response to warning notifications.

Researchers have also investigated the effectiveness of differ-
ent HMI modalities in conveying TOR-related information. In [8]
authors experiment with 7 multimodal signals (i.e., visual, audi-
tory, tactile, visual-auditory, visual-tactile, auditory-tactile, and
visual-auditory-tactile) while driving under SAE Level 3 automa-
tion. Findings indicate that trimodal combinations result in the
shortest response time. Also, response times were longer and the
perceived workload was higher when participants were engaged in
a secondary task. In [6] researchers found that it is important for

AV drivers to be able to differentiate between a TOR and continuous
feedback about the system’s state. The second point is the impor-
tance of using any modality other than visual communication. They
justified this by saying that in real life, as well as in the experiment,
drivers are visually "over-whelmed" by other tasks. Concerning the
displayed colors, drivers report that it is hard for them to notice the
difference between the various shades. For them, it was either red
or yellow or green. The perceived workload of the driver is least in
multi-modal communication, and their performance is improved
by a multi-modal approach.

Visual images can transmit a great amount of information in a
single display, but TOR information can be missed by distracted
drivers. Ambient alerts are easily detected by distracted drivers
and found to be joyful, but it is hard to understand if they convey
a particular message. Auditory and tactile alerts do not require
drivers to take their eyes off the road, but acoustic alerts risk the
message being unclear or not intuitive, while informative signals
require a longer time to transmit urgent information. Vibrotactile
alerts can enhance driver auditory or visual perception, but they
transmit only a limited amount of information and can be obtrusive
[10] .

5 ADAVEC SYSTEM
ADAVEC 1 is a software product designed for car manufacturers
to create and validate the onboard user experience and to provide
a simulation environment for autonomous vehicles while having
a human in cockpit. It is meant to be a design and experiment
studio for creating and testing user experiences in customizable
conditions for authority transfer phases between the driver and
the car. ADAVEC focuses on creating and testing drivable systems
that provide personalized behaviour depending on the driver’s
characteristics.

The key ADAVEC components include Persona Manager, Driving
Conditions Simulation, Cabin Monitoring System, Driving Moni-
toring System, Cabin Experience Manager, and Data Logging Sys-
tem. The Persona Manager allows customers to define and man-
age the various properties to create their own personas, based on
defined characters, ADAVEC will adapt its behaviour regarding
driver and cabin monitoring functions and trigger personalized
answers/actions accordingly. The Driving Conditions Simulation
is based on the CARLA 2 driving simulator server and the Auto-
ware Foundation 3 autonomous driving module. It provides a large
range of driving condition scenarios that can be extended, modified,
and re-used at will. The Cabin Monitoring System developed by
CanControls 4 is based on RGB and IR cameras. It provides a full
range of information indicating the driver and passengers’ activity
such as gaze direction, distraction, smartphone usage, drowsiness,
or sudden sickness. The Driving Monitoring System analyzes the
driving scheme of the user and detects if the current way of driving
is hazardous or not and triggers appropriate actions or advice. The
Cabin Experience Manager, based on Epicnpoc’s BOWL® Automo-
tive starter kit, provides a large panel of possible interactions with
the driver inside the cabin such as lighting, voice, graphical user

1www.adavec.fr
2www.carla.org
3www.autoware.org
4www.cancontrols.com

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

A. Barišić, P. Sigrist, S. Oliver, A. Sciarra and M. Winckler

interfaces, seat morphing, and haptics. Lastly, the Data Logging
System provides an integrated, automated, and timestamped data
logging system for each of its features, ensuring the origin, quality,
and anonymization of the data system or human has created during
a drive test. It has a connector to export the various data to the
Elastic Suite, supporting algorithms to analyze, learn and enhance
the user experience of the designed system.

6 FRU MODEL
To adapt the AV behavior based on the driver performance from
the previous session, we need to explicitly model the driver. Per-
sonalization needs to be studied on different levels, focusing on
high-level features (like preferences and background), long-term
changes (change in experience level) and real-time evidence (be-
havior, response time).

6.1 High-level features
High-level features that represent individual differences can be
assumed to be constant over time. Birthdate is used to collect in-
formation regarding the driver’s age, which together with Gender
serves to fit the driver in the stereotype persona group. Addition-
ally, driving category is used to indicate the driver’s driving skills,
which is usually important when the system needs to make a deci-
sion on whether the driver is capable of performing the expected
manoeuvre. However, there are no studies that explicitly correlate
these human factors to the TOR or to driving capabilities in general.
During the initialization session, it can only be assumed that older
drivers might have more trouble accepting and trusting the ADS,
and drivers with higher categorization or longer driving experience
might be more reliable in performing the TOR request. These are
general assumptions, and concrete indicators can be established
during the training/learning sessions.

Table 1: Static properties

N
1
1
1
1-*
1-*
1
1
1
1

variable
birthdate
age
gander
driving license
language
vision
color
hearing
ADS level

value
date
int
m-male/f-female/u-unknown
string + date
string
o - no problem, f - far, n - near, nf - far and near
boolean
o - no problem, d - deaf, p - hearing problem
n - novice, i - intermediate, e - expert

Moreover, Spoken language is important for setting up the lan-
guage preferences for communication, while Vision and Auditory
problems help the system configure appropriate settings for trans-
mitting visual and auditory alerts. For instance, if a driver has vision
problems like color blindness or difficulty seeing near or far objects,
the system can adjust the visual alerts accordingly. If the driver has
auditory problems, such as being deaf or having hearing difficulties,
the system can adjust the auditory signals and frequency of alerts
to ensure they are effective.

6.2 Long-term FRU properties
Long-term changes in a driver’s experience level are considered
a crucial factor in characterizing the user profile in the Adavec
system. To operationalize this concept, the authors introduce three
experience levels: novice, intermediate, and expert.

During the novice phase, the driver is in the process of learning
how to use the ADS system and is introduced to the communication
methods provided by the vehicle. The driver is encouraged to test
these methods during a simulation ride, and feedback is collected
after each session. The user profile is initialized during this phase.
Trust in the system may be lacking during this phase as the driver
has little to no experience with the automation features.

In the intermediate phase, the driver has a basic knowledge of
how the ADS system works, and behavioral adaptation of the user
profile begins to occur. The system tries to gather driver feedback
to assess their level of trust in the system, and an intermediate
explanation of the system’s operations is provided. Overreliance
and over-trust in the automation features may develop in this phase
resulting increase in safety-critical events associated with risky
behaviors, such as distracted driving.

In the expert phase, the driver has hands-on experience in the
transition of control authority, and sufficient data is collected to
personalize the driver’s response time. The driver is provided with
a basic explanation of the system’s actions by default. Overreliance
and work underload may manifest during this phase in the form of
drowsiness or inattention.

Table 2: Dynamic properties

variable
distraction

value
boolean

occupation

boolean

sleep

sickness

boolean

boolean

drowsiness

boolean

feet_on_pedalle

boolean

hands_on _wheel

hand_to_screen

hand_none
hand_left
hand_right
hand_both
boolean

tracking_zone

string

faces_detection

.front: int
.rear: int
.occupation: int

description
indicate if the driver is occu-
pied with non-driving task
indicate if the driver is occu-
pied with other driving task
indicates if driver is in sleep
state
indicates if driver is experienc-
ing sudden sickness or faint-
ness
indicates if driver is tired or
sleepy
Indicates if driver’s feet are on
the pedals

Indicates which hand(s) the dri-
ver has on the wheel

indicates if driver’s hand is at
the touch screen
Indicates where the driver is
looking
N of detected humans in front
N of detected humans in rear
N of seat occupied

By considering these experience levels, the Adavec system can
better personalize the communication methods and alerts for each
driver. Long-term changes are related to the driver’s history, such as

Driver Model for Take-Over-Request in Autonomous Vehicles

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

Figure 1: TOR scenario

a change in experience level. The high-level and long-term proper-
ties, summarized in Table 1, are seen to be static during the driving
sessions. The driver can access these properties and change them
manually. The change in experience level should be justified with
sufficient data collected from the user through the feedback and
the driving sessions.

6.3 Real-time FRU evidence
We focused on gathering real-time evidence to assess the situational
awareness of the driver during the driving session. To achieve this,
we captured various dynamic properties related to the driver’s
mental state, behaviour, and position inside of cockpit using third-
party tools. Properties that are relevant to decision-making for
authority transfer, along with their variable values and descriptions,
are presented in Table 2.

Properties are recorded as triple, with a timestamp at intervals
of 1 second, and each value is assigned a confidence level of low,
medium, or high. The properties include distraction indicating
whether the driver is occupied with a non-driving-related task
(NRDT), and occupation, indicating whether the driver is occupied
with other driving tasks. Other properties include sleep, sickness,
and drowsiness, indicating that the driver has entered a sleep state,
is experiencing sudden sickness or faintness, or is feeling tired or
sleepy. The Adavec system also tracks whether the driver has their
feet on the pedals, their hands on the wheel, or their hands on the
screen. Additionally, the system records where the driver is looking
through the tracking_zone, and it detects faces with three different

properties: front, rear, and total_occupation, which indicate the
number of detected humans in front of the vehicle, behind the
vehicle, and in total.

7 ILLUSTRATIVE SCENARIO: MONITORING

DRIVER REACTION TIME FOR TOR

To individualize the driving experience, the ADAVEC system saves
a variety of data in its long-term memory. This encompasses bio-
metric information such as facial and vocal recognition, as well as
semantic data such as age and experience level. Additionally, the
system records response times from previous driving sessions to
inform future decision-making. By analyzing this data, the AV can
propose customized communication methods based on the driver’s
previous experiences. For instance, if a particular driver’s FRS re-
sults in a quicker response time for a specific type of alert, the AV
may recommend using that same alert in similar situations in the
future.

7.1 Warrning system configurations
The current system has five different types of alerts:

• Images (Visual) -> Visual images are displayed on the right-
hand touch screen to signal TOR, and there are various com-
binations of icons that can be used to draw the driver’s
attention, with a warning signal commonly coloured in red.
• Ambient lights (Visual) -> Ambient lights are situated in the
cockpit, and the most common sequence includes a "green"

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

A. Barišić, P. Sigrist, S. Oliver, A. Sciarra and M. Winckler

Table 3: Persona example

Name Maria

Birthdate
Age
Gender

01/01/1990
33
Female

Driving License Class B (2010)

Spanish, English
Reduced near vision

Language
Vision
Color O (no problem)
Hearing O (no problem)

Intermediate

ADS Level
Distraction Occasional (when receiving messages)
Occupation
Sleepeness Occasional, especially during long drives

Focused

Sickness

Rarely gets sick

Drowsiness Occasional, especially after lunch

Alerts Warning Configuration
v1-b1-al2-h1
tv2-b3-al3-h2
v3-b1-al2-h1
v3-b3-al1-h3

Nominal
Sickness
Drowsiness
Sleep

TOR Reaction time (s)

Feet
on
Pedal

Hands
on
Wheel

Eyes
On
Road

Ready
Mental

TOT

Nominal
Sickness
Drowsiness
Sleep
Nominal
Sickness
Drowsiness
Sleep
Nominal
Sickness
Drowsiness
Sleep
Nominal
Sickness
Drowsiness
Sleep
Nominal
Sickness
Drowsiness
Sleep

average min max
1.5
2.3
n/a
n/a
1.7
3.2
2.4
3.8
1.2
1.9
n/a
n/a
1.6
3.1
2.1
3.2
0.7
2.1
n/a
n/a
1.8
3.3
2.2
3.4
1.7
2.3
n/a
n/a
2
3.4
2.2
3.5
5.7
6.6
n/a
n/a
6.3
8.6
7.3
9.2

8
n/a
12
14.2
7.7
n/a
11.2
12.1
15.7
n/a
12.7
13.7
14.9
n/a
13.4
17
21.6
n/a
27.5
37.4

ambient colour when everything is fine, "orange" when it is
anticipated that TOR will be launched soon, and "red" when
authority transfer from the driver is expected. The lighting
can be continuous or blinking.

• Informative (Acoustic) -> For informative messages, we use
text-to-speech, and like images, there are numerous combi-
nations to transmit an alert. However, the message should be
as clear and concise as possible, in a language that matches
the driver’s persona profile.

• Beeps (Acoustic) -> Beep sequences should be unique for
TOR alerts, and it is preferable to use a single beep to transmit
the warning quickly, followed by timely repetitions as the
ODD exit point approaches. The beep should not overlap
with informative acoustic warnings.

• Seat Vibration (Heptic) -> Seat vibrations are used in a similar
manner to beeps, starting with light shaking that increases
in frequency and strength as the ODD exit point approaches.

There are many combinations of alerts that we can utilize, using
them sequentially or in parallel. The Bowl environment allows
us to define different configurations, and designers can use it for
experimentation. Moreover, each configuration has a different time
duration. We define Talert as the time required to send the TOR
warning to the driver. It takes some time for the driver to receive
the message, particularly when we use visual images. We call this
time Tinterpert.

7.2 Driver persona example
We give an illustrative example of FRU driver persona in Table
3, randomly generated based on the driver model presented in
Section 6. This persona is of a 33-year-old female named Maria,
with an intermediate experience level with ADS. She has a Class
B driving license since 2010 and speaks both Spanish and English.
Maria occasionally gets distracted while driving, particularly when

receiving messages, but is generally focused. She experiences oc-
casional sleepiness, especially during long drives, and drowsiness
after lunch. Maria rarely gets sick. Her vision is reduced near vision,
but she has no hearing or colour perception problems. Her total
takeover reaction time is on average 6.6 seconds in normal situa-
tions, ranging to 8.6 when showing drowsiness and 9.2 when being
sleepy. There is not enough information to estimate the reaction
time for cases of sickens. She reacts fastest when multi-modal alert
is transmitted.

7.3 TOR scenario
In Figure 1, we illustrate the common TOR scenario for a non-
critical event. The scenario begins with the vehicle in autonomous
driving mode, and the driving condition simulator monitors the
time to the ODD exit point. Based on preconfigured values of Tto-
TOR (Time to TOR), the TOR request is sent. The cabin experience
system launches the TOR alert, and the total time to transmit the
message is estimated as the sum of Talert and Tinterpert. The cabin
monitoring system then checks, in a given time T, if the following
constraints are true at that moment: FeetOnPeddle, HandsOnWheel,
EyesOnRoad, and ReadyMental. For each of these constraints, the
system calculates the individual reaction time after the alert is sub-
mitted. Therefore, Treact is the reaction time of the driver and is cal-
culated as maxT(T_FeetOnPeddle, T_HandsOnWheel, T_EyesOnRoad,
T_ReadyMental). If these conditions are met, the authority is trans-
ferred to the driver, which also takes some time to have the vehicle
in manual mode. We save this time as Ttransfer. We can see that
in this scenario, TOT = Talert + Tinterpert + Treact + Ttransfer. We
need to note that TtoTOR is always greater than TOT.

In cases where the conditions are not met at a given timestamp
(ts) = T, it is necessary to determine whether there is enough time
to try again and get the driver’s attention to the TOR, based on
the remaining time. If the system predicts that there is not enough
time, it will perform an emergency manoeuvre and park the vehicle.

Driver Model for Take-Over-Request in Autonomous Vehicles

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

However, if there is still time, it will repeat the previously described
sequence of events. Note that in each attempt to get the driver’s
attention, the system may have a new configuration of alerts to
use. Each individual reacts differently to the situation and the mul-
timodal combination of the communication signals. Therefore, it is
important to capture the exact response time of the driver (or that
there was no response), and associate it with the communication
signals used to find the most optimal combination.

The above scenario is simplistic and does not take into con-
sideration the properties that indicate lower situation awareness,
represented as the ReadyMental condition. The system continu-
ously monitors these properties for the driver during the ride and is
able to detect if any of them are true at any moment, providing the
possibility to design different scenarios to react to any reduction in
the driver’s mental state. For instance, if the system detects that the
driver has signs of sickness, it will perform an emergency manoeu-
vre and call for help if the driver does not recover when the vehicle
is stopped. However, if the driver signals drowsiness or a sleeping
state, the vehicle is aware that it might take longer for the driver
to get into FRS when TOR takes place. In the case of a predicted
ODD exit point, it is necessary to indicate to the driver TOR sooner.
On the other hand, when unpredictable situations happen, such as
sudden weather changes or traffic conditions, the vehicle needs to
decide whether there is time to try to get the driver to FRS or to
proceed immediately with an emergency manoeuvre.

Furthermore, in the case of the above-detected states (sickness,
drowsiness or sleeping), the vehicle needs to confirm with the
driver that they are really in the captured state, especially when the
confidence level (c) is not ’high,’ by direct interaction over available
communication channels. If the driver shows that they are not in a
given state, the situation should be registered and post-analysis of
the sensing data should be performed.

8 CONCLUSIONS AND FEATURE WORK
This research delves into the analysis of human factors that are
pertinent to driver reaction time when authority transfer occurs.
The study focuses on the software product ADAVEC, which is
specifically designed for car manufacturers to create and validate
the onboard user experience of AVs while having a human in the
cockpit. Personalization of AV behaviour based on the driver’s per-
formance from the previous session requires the explicit modelling
of the driver. Hence, the study investigates personalization on var-
ious levels, such as high-level features, long-term changes, and
real-time evidence. The system follows different phases, namely,
novice, intermediate, and expert, and initializes the driver profile
during the novice phase. We emphasize the importance of accu-
rately capturing the driver’s response time and associating it with
the communication signals used to determine the most optimal
combination of warning alerts. This approach is expected to im-
prove the prediction of when to use different types of warnings,
leading to a more efficient and effective warning system.

As a future research direction, we aim to develop a simulation
module for unrealistic personas based on existing driving data to
validate the infrastructure and study the conditions and communica-
tion for different ADS levels. Furthermore, controlled experiments
with real drivers are required to validate the system. Finally, the

framework is planned to be extended to investigate the impact
of different driving behaviour patterns for critical situations, en-
abling the system to make decisions in the case of timely critical
manoeuvres.

ACKNOWLEDGMENTS
We want to thank for financial support to French national project
’Adaptation automatique du Degré d’Autonomie du Véhicule à son
Environnement et au Conducteur’ (ADAVEC) (www.adavec.fr) with
reference DOS0110362/00 and to IDEX Academy of Université Côte
d’Azur for funding CC: C460ZE08-EOTP:BARISIC-DF:D103.

REFERENCES
[1] [n. d.]. J3016_202104: Taxonomy and Definitions for Terms Related to Driving
Automation Systems for On-Road Motor Vehicles - SAE International. https:
//www.sae.org/standards/content/j3016_202104/

[2] Christer Ahlström, A. Anund, and Erik Kjellman. 2018. Stress , fatigue and
inattention amongst city bus drivers – an explorative study on real roads within
the ADAS & ME project. (2018).

[3] Andrei Aksjonov, Pavel Nedoma, Valery Vodovozov, Eduard Petlenkov, and
Martin Herrmann. 2018. A Novel Driver Performance Model Based on Machine
Learning. IFAC-PapersOnLine 51, 9 (1 2018), 267–272. https://doi.org/10.1016/J.
IFACOL.2018.07.044

[4] Lisanne Bainbridge. 1983. Ironies of automation. Automatica 19, 6 (11 1983),

775–779. https://doi.org/10.1016/0005-1098(83)90046-8

[5] Giulia Belgiovine, Jonas Gonzalez-Billandon, Giulio Sandini, Francesco Rea, and
Alessandra Sciutti. [n. d.]. Towards an HRI Tutoring Framework for Long-term
Personalization and Real-time Adaptation;. Adjunct Proceedings of the 30th ACM
Conference on User Modeling, Adaptation and Personalization ([n. d.]). https:
//doi.org/10.1145/3511047

[6] Sarah Faltaous, Martin Baumann, Stefan Schneegass, and Lewis L. Chuang.
2018. Design guidelines for reliability communication in autonomous vehi-
cles. Proceedings - 10th International ACM Conference on Automotive User Inter-
faces and Interactive Vehicular Applications, AutomotiveUI 2018 (9 2018), 258–267.
https://doi.org/10.1145/3239060.3239072

[7] Sandra G. Hart and Lowell E. Staveland. 1988. Development of NASA-TLX
(Task Load Index): Results of Empirical and Theoretical Research. Advances in
Psychology 52, C (1 1988), 139–183. https://doi.org/10.1016/S0166-4115(08)62386-
9

[8] Gaojian Huang, Clayton Steele, Xinrui Zhang, and Brandon J. Pitts. 2019. Multi-
modal Cue Combinations: A Possible Approach to Designing In-Vehicle Takeover
Requests for Semi-autonomous Driving. https://doi.org/10.1177/1071181319631053
63, 1 (11 2019), 1739–1743. https://doi.org/10.1177/1071181319631053

[9] Zhentao Huang, Rongze Li, Wangkai Jin, Zilin Song, Yu Zhang, Xiangjun Peng,
and Xu Sun. 2020. Face2multi-modal: In-vehicle multi-modal predictors via
facial expressions. Adjunct Proceedings - 12th International ACM Conference on
Automotive User Interfaces and Interactive Vehicular Applications, AutomotiveUI
2020 (9 2020), 30–33. https://doi.org/10.1145/3409251.3411716

[10] Walter Morales-Alvarez, Oscar Sipele, Régis Léberon, Hadj Hamma Tadjine, and
Cristina Olaverri-Monreal. 2020. Automated Driving: A Literature Review of the
Take over Request in Conditional Automation. Electronics 2020, Vol. 9, Page 2087
9, 12 (12 2020), 2087. https://doi.org/10.3390/ELECTRONICS9122087

[11] Oluwafemi Olaleke, Ivan Oseledets, and Evgeny Frolov. 2021. Dynamic modeling
of user preferences for stable recommendations. UMAP 2021 - Proceedings of the
29th ACM Conference on User Modeling, Adaptation and Personalization (6 2021),
262–266. https://doi.org/10.1145/3450613.3456830

[12] David Puertas-Ramirez, Ana Serrano-Mamolar, David Martin Gomez, and Jesus G.
Boticario. 2021. Should Conditional Self-Driving Cars Consider the State of the
Human Inside the Vehicle? UMAP 2021 - Adjunct Publication of the 29th ACM
Conference on User Modeling, Adaptation and Personalization (6 2021), 137–141.
https://doi.org/10.1145/3450614.3462243

[13] Shitian Shen, Markel Sanz Ausin, Behrooz Mostafavi, and Min Chi. 2018. Im-
proving learning and reducing time: A constrained action-based reinforcement
learning approach. UMAP 2018 - Proceedings of the 26th Conference on User Mod-
eling, Adaptation and Personalization (7 2018), 43–51. https://doi.org/10.1145/
3209219.3209232

[14] Cláudia Sofia Silveira, Jaime S. Cardoso, André L. Lourenço, and Christer
Ahlström. 2019. Importance of subject-dependent classification and imbalanced
distributions in driver sleepiness detection in realistic conditions.
IET Intel-
ligent Transport Systems 13, 2 (2 2019), 347–355. https://doi.org/10.1049/IET-
ITS.2018.5284

[15] Susan Soccolich, Naomi Dunn, and Thomas A. Dingus. 2019. Understanding the
Impact of Technology: Do Advanced Driver Assistance and Semi-Automated

UMAP ’23 Adjunct, June 26–29, 2023, Limassol, Cyprus

A. Barišić, P. Sigrist, S. Oliver, A. Sciarra and M. Winckler

Vehicle Systems Lead to Improper Driving Behavior? AAA Foundation for
Traffic Safety. (12 2019). https://aaafoundation.org/understanding-the-impact-
of-technology-do-advanced-driver-assistance-and-semi-automated-vehicle-
systems-lead-to-improper-driving-behavior/

[16] Sergey Sosnovsky and Darina Dicheva. 2010. Ontological technologies for user
modelling. International Journal of Metadata, Semantics and Ontologies 5, 1 (2010),

32–71. https://doi.org/10.1504/IJMSO.2010.032649

[17] Sherin Thomas, P. K. Srijith, and Michal Lukasik. 2018. A Bayesian point process
model for user return time prediction in recommendation systems. UMAP 2018 -
Proceedings of the 26th Conference on User Modeling, Adaptation and Personaliza-
tion (7 2018), 363–364. https://doi.org/10.1145/3209219.3209261

