The effects of VR in training simulators: Exploring
perception and knowledge gain
Aline Menin, Rafael Torchelsen, Luciana Nedel

To cite this version:

Aline Menin, Rafael Torchelsen, Luciana Nedel.
The effects of VR in training simulators:
Exploring perception and knowledge gain. Computers and Graphics, 2021, 102, pp.402-412.
￿10.1016/j.cag.2021.09.015￿. ￿hal-03369680￿

HAL Id: hal-03369680

https://hal.science/hal-03369680

Submitted on 12 Oct 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Computers & Graphics (2021)

Contents lists available at ScienceDirect

Computers & Graphics

journal homepage: www.elsevier.com/locate/cag

The Eﬀects of VR in Training Simulators: Exploring Perception and Knowledge Gain

Aline Menina,∗, Rafael Torchelsenb, Luciana Nedelc

aUniv. Cˆote d’Azur, CNRS, Inria, Sophia Antipolis, France
bCDTec, Federal University of Pelotas, Pelotas, Brazil
cInstitute of Informatics, Federal University of Rio Grande do Sul, Porto Alegre, Brazil

A R T I C L E I N F O

A B S T R A C T

Article history:
Received October 12, 2021

Keywords: Virtual Reality, Immersion,
Training Simulators, User Perception,
Knowledge Gain

Although immersive virtual environments have been used for years for training and
learning purposes (e.g., ﬂight and surgery simulators), the eﬀects of using VR devices
on simulation sessions are yet to be understood. In this work, we explore the eﬀects of
diﬀerent VR devices on virtual environments developed for training, focusing on per-
ception and knowledge gain aspects. We performed two user studies to investigate the
inﬂuence of these devices on users’ workload, motion sickness, and performance in the
domain of work safety training. The ﬁrst experiment includes 61 participants and seeks
to understand whether and how VR displays providing diﬀerent ﬁelds of view aﬀects the
users’ ability to search for risks in an oﬃce-like virtual environment (i.e. focus on user
perception). Subsequently, we conducted a second experiment involving 46 subjects,
where we assess whether and how interaction techniques providing diﬀerent degrees-
of-freedom inﬂuence users’ ability to learn procedural tasks (i.e. focus on knowledge
gain). From our results, we learned that users’ knowledge on the simulation’s topic
(i.e. work safety) and gaming experience play an important role in VR simulations, and
that cybersickness symptoms such as disorientation are likely caused by unawareness
of one’s surroundings instead of VR content.

© 2021 Elsevier B.V. All rights reserved.

1

2

3

4

5

6

7

8

9

10

11

12

1. Introduction

The low-cost and danger-free aspects of virtual reality (VR)
technology enable the design of immersive simulations with
game aspects (i.e. gameplay, challenge, interaction, and objec-
tive) for training people in diverse application domains. There
are numerous successful examples on the literature on how im-
mersive VR can improve user performance and game eﬀective-
ness. Chitarro et al. [1] proposed an immersive simulator for
educating passengers on aviation safety through experiencing
a serious aircraft emergency situation using a Head-Mounted
Display (HMD). In ﬁre service, Backlund et al. [2] present a
simulator to train ﬁreﬁghter’s skills using a Cave Automatic

∗Corresponding author:
e-mail: aline.menin@inria.fr (Aline Menin)

Virtual Environment (CAVE) based system and allowing free
interaction through motion tracking. In health-care, Pedraza-
Hueso et al. [3] propose a simulator that allows the user to carry
out physical and cognitive rehabilitation therapies using a nat-
ural user interface based on motion tracking. Cecil et al. [4]
proposed a VR simulator to facilitate and supplement the train-
ing opportunities provided to orthopedic residents. Mobach [5]
showed that VR simulations can incite users to actively engage
in architectural and organizational participatory design, while
improving staﬀ satisfaction and reducing costs. Jiang et al. [6]
proposed an immersive serious game delivered via an HMD for
teaching users the sequence of operations necessary to launch
a lifeboat and on handling the potential risks of such a task.
Furthermore, the analysis of the usage of VR technology in
immersive simulations presented by Menin et al. [7] showed
that VR enables users to save money and perform safe training,

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

2

Preprint Submitted for review / Computers & Graphics (2021)

while supporting knowledge gain as eﬃciently as conventional
methods. Further, VR training simulations improve knowledge
retention and increase users’ engagement, which, consequently,
enable situational awareness and improve the understanding of
training procedures [7].

It is well-known that eﬀective learning occurs when the body
senses are stimulated, particularly the visual one [8]. Nonethe-
less, motion sickness is a common side-eﬀect of using VR due
to standing still while the surrounding environment is moving,
disturbing the brain’s equilibrium and causing nausea. Thus,
in this paper, we investigate the eﬀects of diﬀerent VR display
devices and interaction techniques on perceptual learning and
knowledge retention. We performed two user-based evalua-
tions with two realistic immersive simulations designed to teach
and train people on work safety. We considered aspects of user
experience (i.e. workload and cybersickness) and user perfor-
mance (i.e. error rate, simulation time) to understand how VR
technology stimulates the body’s senses and how it reacts. The
contributions of this work are summarized as follows:

• A user study involving 107 unpaid persons divided into
two groups to assess the eﬀects of: three diﬀerent display
devices (from conventional desktop displays to VR head-
sets) on perceptual learning, and four diﬀerent interaction
techniques (from traditional game like interaction to VR
techniques, such as walking-in-place) on perception and
knowledge retention. The studies also assessed user expe-
rience in two immersive simulations designed for training
purposes; and

• A set of lessons learned, which can lead to research ques-
tions and help developers on choosing the VR setup for
new training simulations.

The remainder of this paper is organized as follows. Sec-
tion 2 presents the related work. Section 3 explains our de-
sign rationale, and presents the description of the serious games
developed. Section 4 presents the protocol used for both user
studies, while Sections 5 and 6 present the two experiments, the
methodology employed, the results achieved and the hypothe-
ses assessment. Section 7 discusses our ﬁndings, presents the
lessons learned from this study, and the limitations of our stud-
ies. Finally, we conclude in Section 8.

2. Related Work

Studies preceding ours have already investigated the impacts
of VR technology on user experience (UX), which we present
hereafter. Mania et al. [9] have studied the eﬀects of diﬀer-
ent levels of immersion (real-world, desktop, audio-only, and
head-mounted display – HMD) on sense of presence and mem-
orization in a seminar-like presentation. Predictably, users re-
ported the highest sense of presence and performance when
they were in a real-world seminar room. In terms of ﬁdelity
aspects (i.e. the objective degree of exactness with which real-
world sensory stimuli is reproduced [10]), Mania et al. [9] re-
sults suggest that low interaction/display ﬁdelity may improve
memorization due to the higher attention demand imposed to

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

the cognitive system. These ﬁndings were later contradicted by
Bowman et al. [11], who showed that a higher level of visual ﬁ-
delity provides better performance in procedure memorization
tasks. They also showed that high display ﬁdelity improves spa-
tial knowledge and allows users to use spatial strategies on pro-
cedure memorization, leading to better target detection. More
recently, Kwon [12] showed that high ﬁdelity VR setups help
users to recognize a virtual experience as the actual experience,
while improving their ability to analyze, evaluate, and create
questions based on the subject learned during the simulation.

Ragan et al. [13] showed that the use of auxiliary spatial in-
formation aﬀects mental strategies and improves user perfor-
mance in terms of cognitive processing and learning-based ac-
tivities. Moreover, stereoscopic vision has been shown to im-
prove memory recall when objects are consistent with the en-
vironmental context [14]. In another study, Roman et al. [15]
showed that a three-monitor CAVE is more engaging with a 3D
ﬁrst-person shooter game than a single monitor.

Napieralski et al. [16] showed that users can locate them-
selves easier inside a VR environment when the realism of
graphics is higher. Furthermore, Ragan et al. [17] showed that
high visual realism improves strategy transfer, but worsen user
performance in scanning tasks probably due to the extra infor-
mation that exists on VR environments simulating real-world
scenarios (e.g., trees, people, buildings), which can distract the
user from their main task. They also demonstrated that train-
ing with higher FOVs lead to better object detection in a seri-
ous game using scanning tasks to train military personnel. Al-
though, they did not ﬁnd any correlation between the user per-
formance on the VR environment and the real-world, their ﬁnd-
ings suggest that a higher FOV do not improve the real-world
task performance more than training with a lower FOV.

Bowman and McMahan [18] also showed that using wide
FOV and high resolution provides a less cluttered and more
comprehensible VE. McMahan et al. [10] showed that high
display and interaction ﬁdelity aﬀect strategy and user perfor-
mance in a ﬁrst-person shooter game in a way that, with high
interaction ﬁdelity users took less damage and were less ac-
curate then with low interaction ﬁdelity. The authors showed
that users’ familiarity with the technology improves user per-
formance, which could explain the high accuracy when inter-
acting with conventional mouse and keyboard devices. In terms
of user experience (UX), the authors observed that high dis-
play/interaction ﬁdelity increases the users’ sense of presence,
engagement and the simulator’s assessed usability.

Krokos et al. [19] showed that using virtual memory palaces
(i.e. placing pieces of information within palace and medieval
town environments, and associating them to salient features of
the environment) as a spatial mnemonic to support informa-
tion recall are more eﬀective when delivered via HMDs than
desktop displays. Nabioyuni and Bowman [20] investigated the
eﬀects of hyper-natural transfer and biomechanical techniques
for navigating inside a VR environment. Their ﬁndings suggest
that well-designed hyper-natural navigation techniques can be
understood and adapted by users, resulting in more speed per-
formance. However, these techniques may still be more diﬃ-
cult to control than real walking when performing complicated,

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

104

105

106

107

108

109

110

Preprint Submitted for review / Computers & Graphics (2021)

3

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

more precise movements. Further, hyper-natural biomechanical
techniques do not improve locomotion performance in VR, but
instead reduce accuracy and users’ comfort [20].

Kakoschke et al. [21] investigated the eﬀects of Approach-
Avoidance Training (AAT) delivered via three interfaces (com-
puter, smartphone, and VR) on user experience (ﬂow, immer-
sion, engagement) and performance (accuracy, approach bias).
Their results showed that VR was a more eﬀective way to de-
liver the training by providing higher engagement, ﬂow, and im-
mersion than the AAT delivered via a computer or smartphone
application, while reducing errors.

Albus et al. [22] used signals in the form of textual annota-
tions to support learning in VR simulations. They also inves-
tigated its eﬀects on diﬀerent learning outcomes and cognitive
load. Results showed that annotations in VR can help users to
process and recall the information, but have no eﬀects in terms
of reducing distractions. Gupta et al. [23] used a VR simulator
for condylar plating surgery to show that VR based environ-
ments can serve both as skills training and learning tools.

Di Mascio et al. [24] evaluated the acceptability, usability,
and engagement of two HMDs (i.e. Oculus Rift and Hololens)
as tools to provide VR and AR-based treatment for people with
Autism Spectrum Disorder (ASD). For both devices, results
suggest that initial training is necessary, as well as long-term
usage to provide users with freedom to virtually and physi-
cally move around the environment. The study showed yet that
familiarity with objects in an IVE’s (Immersive Virtual Envi-
ronments) had a higher impact on emotional participation than
photo-realism.

Hasanzadeh et al. [25] investigated the feasibility and useful-
ness of providing passive haptics in a mixed-reality (MR) envi-
ronment to capture the risk-taking behavior of workers. Results
showed that MR helps to raise users’ sense of presence and to
capture their realistic response to safety features for both re-
search and training purposes. Additionally, the study showed
that extroverts workers could place themselves more readily
within this mental representation and experience higher levels
of involvement, higher degrees of presence, and stronger sense
of being there.

Recently, due to the constraints imposed by the COVID-19
pandemics, the use of VR for training and learning has receiv-
ing more attention and the inﬂuence of aspects such as users’
visual attention and behavior are being explored. Simeone et
al. [26] found that the presence of a virtual instructor increases
the engagement and accelerate the progress of the user during
a learning experience. Bozkir et al. [27] focused in three diﬀer-
ent objects-of-interest for measuring attention: peer-learners,
instructor, and lecture material. More speciﬁcally, they var-
ied sitting positions of students, visualization styles of virtual
avatars (realistic or cartoon-like), and hand-raising percentages
of peer-learners. Results showed that such manipulations play
an important role in students’ attention.

These user studies illustrate the interest and beneﬁts of using
VR technologies to provide the user with high ﬁdelity setups to
support training procedures through low-cost and danger-free
alternatives. A high ﬁdelity VR setup would be built with tech-
nologies that provide the closest experience as one would have

in the real-world, which means peripheral vision and natural in-
teraction techniques, such as through mid-air gestures and real
walking. Nonetheless, we could see that, depending on the tar-
get tasks, low interaction ﬁdelity provides better user perfor-
mance than high ﬁdelity due to the users’ familiarity with de-
vices such as game controllers and mouse devices. The study
reported by McMahan et al. [10] is the closest to the one we
present in this paper in terms of comparing diﬀerent combina-
tions of low and high interaction/display ﬁdelity devices, which
considers for instance the joint use of CAVEs and mouse de-
vices or display-walls and pointing devices. However, the dis-
parity in terms of ﬁdelity between one display and interaction
devices are quite large.

In this paper, we extend the understanding of the eﬀects of
low/intermediate/high ﬁdelity in user perception and knowl-
edge retention. We considered diﬀerent VR devices, interaction
and navigation techniques on the outcomes of training simula-
tions. Few previous studies have considered the eﬀects of mo-
tion sickness, even though it is known to be a side-eﬀect of
VR, or the quantity of work necessary to achieve the task using
high ﬁdelity interaction tools, which are quite new to the users.
Therefore, we measure motion sickness and workload and eval-
uate their impact on user engagement, sense of presence and
immersion.

3. Design Rationale

Perception and learning are intrinsically connected: in train-
ing tasks, one cannot learn a new procedure without the ability
of perceiving one’s surroundings. Thus, this study focuses on
investigating the eﬀects of diﬀerent VR technologies on percep-
tion and learning aspects of VR simulations. To reduce cogni-
tive load possibly engendered by the combination of all these
technologies, we separated the study in two user experiments:
(i) user perception (Section 5) comparing three display devices,
and (ii) knowledge gain (Section 6) comparing four combina-
tions of semi- and non-natural interaction and locomotion tech-
niques.

First and foremost, the purpose of a training simulation is to
prepare the user for the real-world situation, which has naturally
high visual complexity. Thus, the simulators where build on the
basis of realistic scenarios, supporting the transfer of what has
been learned during the simulation to the real-world situation.
We used a simulator for risk perception assessment (Fig. 1a),
which purpose is to train workers on detecting potential risk
elements in a normal workplace environment [28], and a sim-
ulator for lightning rod replacement (Fig. 1b), which intend
to train apprentices on basic safety procedures for electrical in-
stallations on public utility poles.

The risk perception assessment simulator reinforces users’
perception through their ability to see, hear, or become aware
of something through the senses to apprehend their surround-
ings, detecting and avoiding risk hazards. Thus, the simulator
train users through perceptual learning, which comprises the
ability to detect pieces of information (i.e. events, distinctive
features, and aﬀordances) oﬀered by the environment [29]. Ra-
gan et al. [17] had previously evaluated the eﬀects of diﬀerent

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

104

105

106

107

108

109

110

111

112

4

Preprint Submitted for review / Computers & Graphics (2021)

(a)

(b)

Fig. 1: Virtual environments used in the Experiment I - risk perception assessment (a) and Experiment II - lighting rod replacement(b).

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

levels of FOV (in an HMD device) on a scanning task using
realistic scenarios, which shown no signiﬁcant eﬀect on target
detection or assessment strategy usage. In order to extend the
understanding of VR impact on perceptual learning, we investi-
gate how diﬀerent display devices providing diﬀerent FOVs and
diﬀerent usage settings (more or less comfortable to the user),
could impact user experience and performance.

Further to acquire information, the user should be able to re-
tain the information obtained through training simulations in
order to transfer it into the real-world situation. Recalling infor-
mation is also known as knowledge and can be classiﬁed into
diﬀerent categories such as factual, conceptual, procedural and
meta-cognitive [30]. Both simulators require the user to recog-
nize speciﬁc details or elements (i.e. factual knowledge). In
this paper, we explore knowledge retention through the light-
ing rod replacement simulator, where we investigate the eﬀects
of diﬀerent navigation and interaction techniques for grabbing
and manipulation, which are fundamental in numerous training
simulators (e.g., ﬁreﬁghting, military training, etc). In terms of
interaction, we use motion tracking to map knowledge retention
to the real-world by providing high ﬁdelity experiences to the
user.

In terms of navigation, we considered the use of motion
tracking, but the solutions found to track the large physical
spaces required for both simulations (Fig. 1) were too expen-
sive [31]. Hyper-natural navigation techniques such as Seven
League Boots [32] could improve speed performance, but they
might be diﬃcult to control when precision is needed [20].
Thus, we focus in less natural navigation techniques such as
walking-in-place (WIP) and joystick navigation. Particularly,
the Wii balance board has been largely used by researchers to
provide low-cost WIP techniques, showing positive eﬀects on
user performance in human-scale spaces and spatial orientation,
while providing high sense of presence [33].

we combine physical objects and body movement by using the
Razer Hydra controllers, and compare it to conventional game
controllers, since users are familiar with these devices.

The ﬁrst experiment focuses on perception, using a VE that
requires walking around while observing and perceiving haz-
ardous features in diﬀerent rooms. In this task, the display de-
vice impacts the performance more than the interaction tech-
nique, so we compared three diﬀerent display devices. The sec-
ond experiment focused on investigating the eﬀects of interac-
tion and locomotion techniques on learning. Although it uses a
diﬀerent simulator, the perception skills are as important, since
the user should be aware of their surroundings to judge the best
way of securing the workplace. Therefore, we chose the display
device that has shown the best eﬀects on the ﬁrst trial, ensuring
that the display was not a bias, while showing positive eﬀects
in terms of perception.

Particularly, as shown by previous works (see Section 2), VR
devices providing highly immersive and natural experiences
can improve user performance. Therefore, we selected a set of
VR devices that provide proper levels of immersion (i.e. HMD
and display-wall) and naturalness (i.e. Razer Hydra and Wii
Balance Boards) while comparing them with traditional and
familiar devices (i.e. PC monitor and game controllers), en-
abling us to investigate their eﬀects the outcomes of the train-
ing simulations. Furthermore, the selected devices are cheap
and therefore accessible to the companies interested on using
these types of simulators, thus easing their dissemination since
these are intended for use in large-scale training sessions within
companies [28]. Hereafter, we ﬁrst describe the shared exper-
iment protocol, measures, and statistical analysis process, then
we present both user experiments and their results.

4. Shared Protocol Between Experiments and Measures

In terms of grabbing and manipulating objects, motion track-
ing can also enable natural interaction through mid-air ges-
tures [34], which has shown to oﬀer less precise control and
require more physical work on the part of the user [35]. Fur-
thermore, Mine et al. [36] showed that having a physical refer-
ence helps the user to be more precise on memory recall. Thus,

Since we focus on learning, we assumed that using a within-
subjects design could inﬂuence the results by allowing users
to recycle the information they learned while using a partic-
ular display/interaction technique. Thus, we used a between-
subjects design in both experiments, where participants were
randomly assigned to each experimental condition.

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

Preprint Submitted for review / Computers & Graphics (2021)

5

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

In both experiments, the experimental sessions were individ-
ual, accompanied by an experimenter who guided the partic-
ipant through ﬁve steps of a standard protocol consisting of:
(1) a Term and Conditions Agreement, where the user is in-
formed about the risks and beneﬁts of participating in the ex-
periment, and through which they consent their participation al-
lowing us to anonymously use their data for research purposes;
(2) a socio-demographic questionnaire, where we gather stan-
dard proﬁling information (e.g., age, sex, profession), data re-
garding their experience with the technologies used (e.g., expe-
rience with VR, 3D games) and the subject being addressed in
each simulation (e.g., work safety); (3) a learning phase, where
users were given time to get familiar with the VR setup; (4)
a trial phase, where the user carry out the required tasks; and
(5) a post-test phase, where we apply a questionnaire gathering
users’ self-reported engagement, cybersickness, and workload,
as well as information speciﬁc to each experiment.

Particularly, to measure the impact of the VR devices on cy-
bersickness (i.e. visually induced motion sickness) we admin-
istered the Simulator Sickness Questionnaire (SSQ) [37]. The
questionnaire allows the user to assess the severity with which
they experienced sixteen sickness symptoms in a 4-point scale
(i.e. from low to high), which allows to determine the user’s
level of sickness regarding four scales: nausea (N), oculomo-
tor (O), disorientation (D), and total severity (TS). The highest
scores possible are 124 for nausea, 90.9 for oculomotor, 97.4 for
disorientation, and 108.6 for total severity. As common prac-
tice [38], we administrated the SSQ before and after the trial in
both experiments to obtain baseline and completion measure-
ments. This way, we can ensure that the results are not biased
by the condition of the participant before the trial, who could
be stressed, anxious, or nauseous for unrelated reasons.

Regarding statistical analysis, we set the signiﬁcance level
to p = 0.05 to analyze the empirical data. We submitted the
data to a mixed design, where the between-subjects variables
are the experimental conditions and the user proﬁle, while the
within-subjects variables are the simulator sickness scores (ob-
tained before and after the trial) and other measures speciﬁc
to each experiment, such as the sense of presence scores (ob-
tained per room in the VE), and the self-reported workload
scores (obtained before and after the trial). We performed a
Shapiro-Wilk Normality test of the null hypothesis that the data
come from a normal distribution, and a Fligner-Killeen test of
the null hypothesis that the variances in each group are the
If the data passes both tests (p <0.5) we performed
same.
a One-Way ANOVA test. Otherwise, the data was submit-
ted to non-parametric tests, namely Friedman for paired and
In tests involving more
Kruskal-Wallis for unpaired groups.
than two groups, with statistical signiﬁcance, we ran post-hoc
tests: Tukey’s range test [39] for One-Way ANOVA, and Ne-
menyi test [40] for the remaining. We report statistical signiﬁ-
cance in the diﬀerence of means for two or more groups through
codes on the charts, if any, as follows: ‘***’ 0.001, ‘**’ 0.01,
‘*’ 0.05, and ‘.’ 0.1.

5. Experiment I: User Perception

This experiment aims to understand whether diﬀerent VR
display devices inﬂuence the user perception in a simulation de-
signed to train workers of an electricity distribution company on
detecting risks elements in their work environment. This exper-
iment requires users to leverage their perception skills to detect
potential hazards in the virtual environment. Based on previous
studies’ ﬁndings (see Section 2), we believe that the higher the
feeling of being “there” in the VE, the better the user can per-
form the tasks and recall the information acquired during the
simulation. Particularly, a high immersive setup would enable
them to completely focus on the elements of the virtual world
without being distracted by the real-world objects surrounding
them. Thus, we hypothesized that (H1) display devices pro-
ducing higher self-reported sense of presence improve the user
performance. Moreover, the existing immersive training simu-
lators have shown overall positive outcomes [7], which lead us
to hypothesize that (H2) simulator sickness will not worsen the
user performance.

5.1. Virtual Environment

This simulation was designed for assessing the ability of
workers to detect potential risk elements in a normal work-
place environment. The VE contains a building with a recep-
tion room, a parking lot, an oﬃce, and a kitchen. Further to
the normal objects of an oﬃce environment, the scenario has
53 objects deﬁned as potential hazards which can be simple or
composite. The former refers to imminent risk items (e.g., wet
ﬂoor, blocked ﬁre extinguisher), while the latter refers to ob-
jects which hazard is triggered by an external situation (e.g.,
ﬂashing lamp, alarm oﬀ). These require higher cognitive eﬀort
from the user to be detected.

5.2. Experimental Conditions

We compared three VR display devices: (A) a 23-inch LCD
screen with a 120Hz refresh rate and 1920 × 1080 pixels resolu-
tion desktop display, which we used as our baseline condition,
since games and current non-immersive simulations are usually
ran on PC desktops; (B) a 3200 × 1800 pixels resolution dis-
play wall built up from a set of twelve 22-inch LCD screens,
with a total dimension of 244 × 108 centimeters (Fig. 2b). This
display intends to immerse the user on the simulation while
allowing them to be aware of their surroundings; and (C) an
HMD device, since it is widely used in VR and provides high
self-reported sense of presence, allowing the user to focus on
the simulation while avoiding distractions issued from their sur-
roundings. We used the Oculus Rift DK2 device, which has a
960 × 1080 pixels resolution per eye and a refresh rate of 75Hz.

5.3. Participants

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

Sixty-one volunteers (15 female) took part in this experi-
ment. They were students, mostly from Computer Science,
and University personnel, aged between 19 and 63 years old
(M=28.67, SD=10.12). They were all beginners in terms of
work safety and VR, and 42% reported to be experienced on 3D 106
video games. All the participants reported normal or corrected-
to-normal vision.

105

102

103

104

107

108

6

Preprint Submitted for review / Computers & Graphics (2021)

Fig. 2: Experimental conditions for the ﬁrst experiment (user perception).

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

5.4. Task

The users were assigned with two tasks: (1) to follow the in-
structions (e.g. “Inside of this building has a kitchen. Go there
and get a coﬀee.”) given by a storyteller, while (2) scanning
the environment for potential risks objects. The guidance en-
abled users to go through every room in the building. In each
room, they were instructed to reach a target object (ﬂashing in
red) by moving back and forward using the game controller’s
joystick. Users would turn their heads to set the movement di-
rection when using the HMD and the display wall, and use the
joystick when using the desktop display. After reaching the tar-
get, the system triggers the next instruction, except in the case
of two special instructions, when the user should stand in a lo-
cation and scan the room for potential risks for as long as they
would like. These tasks were included as a strategy to reduce
the diﬀerence among the experimental conditions, demanding
users to perform the same movements by either turning their
heads with the HMD or using the game controller. Further, it
serves also to verify whether users would simply follow what
the narrator was telling them to do or they were also attentive
to the scanning task. Such as in the real world, the detection of
risky situations should be a background task.

5.5. Measures

We measured the users’ subjective sense of presence us-
ing the SUS (Slater-Usoh-Steed) presence questionnaire [41],
which consists of six statements rated in a 7-point Likert scale
used to assess the sense of presence in each room of the VE.
Further, we asked users to respond the question “how much im-
mersed did you feel?” in a 10-point scale, in order to assess
their sense of immersion. Regarding user experience, we asked
users to rate in a 5-point Likert scale the following statements:
“I believe the simulation achieve the purpose of assessing the
user’s aptitude on detecting risk hazards in the work environ-
ment”, “I could perform the simulation easily”; “I enjoyed us-
ing the simulator”. Finally, we measured user performance by
combining three factors: task completion time (the lower the
better), traveled distance in the VE (the less the better), and the
number of detected risks (the more the better).

5.6. Results

The virtual path which users were supposed to follow was
determined by the audio instructions, which send them to the

car at the parking lot, the coﬀee maker at the kitchen, the desk
at the oﬃce, and, ﬁnally, to meet their co-workers outside the
oﬃce. Although, we did not observe major diﬀerences among
the experimental conditions, users wearing the HMD followed
a path slightly more straight than the ones in Display-Wall and
Desktop conditions.

42

43

44

45

46

47

Fig. 3: Mean selection rates per type of risk in each experimental condition of
experiment I.

Overall, users took between 5 and 15 minutes to complete
the simulation regardless the display device. We observed sig-
niﬁcant diﬀerence in the mean completion times for the dis-
play wall and the remaining devices, suggesting that partici-
pants using the display wall took longer to ﬁnish the simu-
lation (M=12.4, p<0.001).
In terms of risk selection, users
were able to identify about 21% of potential risk objects in
the VE (Fig. 3). The mean scores show that users found
more risk objects using the desktop display than with the re-
maining, but no statistical diﬀerence was observed. Nonethe-
less, when analyzing the type of risk objects users found,
we observed that they detected more simple than composite
risks using the display wall (p<0.001) and the desktop display
(p<0.05), while there was no signiﬁcant diﬀerence under the
HMD condition. We observed that completion time and risk se-
lection is positively correlated when using the desktop (p<0.02,
R=0.5) and HMD (p<0.03, R=0.48) display devices.

In order to determine whether the devices inﬂicted cyber-
sickness on users, we compared the SSQ scores measured be-
fore and after the trial. We observed statistical diﬀerence be-

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

Preprint Submitted for review / Computers & Graphics (2021)

7

1

2

3

4

5

6

tween mean scores for symptoms of nausea (p<0.01), disorien-
tation (p<0.001), and total severity (p<0.01) of users using the
HMD. The desktop display reduced users’ perceived severity of
symptoms, where we observed statistical diﬀerence in the mean
scores of oculomotor and total severity (p<0.02). No statistical
diﬀerence was observed for the display wall device.

Fig. 4: Mean scores per SSQ scale before and after the trial in each experimental
condition of Experiment I. A, B and C are the experimental conditions, see
section 5.2

We did not observe statistical diﬀerences in the mean SSQ
scores for users using the desktop display and the display wall.
However, the users of the HMD appear to perceive the sever-
ity of symptoms of nausea, disorientation, and the total sever-
ity signiﬁcantly higher than the users of other devices (p<0.01)
(Fig. 4). We have also observed statistical diﬀerences in the
mean scores of the oculomotor scale between the HMD and
the desktop display devices (p<0.05), while no statistical diﬀer-
ences were observed in regard to the display wall. The highest
SSQ score was 45.4 points (SD=53.7) regarding disorientation
symptoms while using the HMD device, which is a high score
compared to the maximum score of 97.4 points.

In terms of immersion, mean scores suggest that participants
using the HMD device (M=7.96, SD=1.68) perceived them-
selves more immersed in the simulation than the users of the
display wall (M=5.8, SD=2.63, p<0.001) and the desktop dis-
play (M=5.45, SD=1.77, p<0.01). Regarding the users’ sense
of presence, we observed statistical signiﬁcance in the SUS
scores for the HMD and the desktop display (p<0.05), indicat-
ing that users could feel more present when using the HMD
device. No statistical diﬀerence was observed in the scores for
the display wall and the remaining devices.

Overall, users reported to be satisﬁed with the experience
and, particularly the users who experienced it through the HMD
and display wall, reported to have felt “really” there. A few
participants mentioned that having to only walk towards what
they are seeing did not felt natural. However, we believe that,
diﬀerently from the real world, looking towards one direction
and walking towards another can increase disorientation. Users
have also appreciated the short duration of the experiment and
agreed that the simulation meets its goals.

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

5.6.1. Hypotheses Assessment.

Although the assessed sense of presence of users using the
HMD was higher than the other devices, the participants’ risk
selection rate and completion time were similar among devices,
which means that we cannot accept H1. Nonetheless, we ob-
served that the mean number of risk selection was quite low,
which is most likely a consequence of the users’ overall lack
of expertise on work safety. The users with the HMD device
reported more severe sickness symptoms than the users of dis-
play wall and desktop display devices, which latter appear to
have reduced the severity of symptoms. Nonetheless, comple-
tion time and risk selection rate did not present any diﬀerence
among users of diﬀerent display devices. Moreover, we did not
observe correlation between SSQ scores and completion time
or risk selection rate, which allows us to accept H2. Although
the participants did not present high performance, their varied
perception of sickness symptoms severity did not impacted the
user performance among the diﬀerent display devices.

6. Experiment II: Knowledge Gain

This experiment intends to explore the eﬀects of two diﬀerent
interaction and two locomotion techniques on user experience
and knowledge gain in a simulator designed for teaching ap-
prentices the work safety procedures of a lightning rod replace-
ment task. Overall, we believe the devices enabling movements
closer to natural ones would improve user experience and, con-
sequently, increase the knowledge gain from the simulation.
Therefore, we hypothesized that (H1) the closest the movement
is to the natural one, the better will be the user performance;
(H2) the devices enabling arms and legs movements will not
inﬂict severe motion sickness; and (H3) high workload induc-
ing techniques will worsen user performance.

6.1. Virtual Environment

This simulation was designed for training apprentices on ba-
sic safety procedures for electrical installations on public utility
poles. The VE consists of a town street where a lightning rod is
being replaced (Fig. 1b). A storyteller guides the user through
audio instructions (e.g. “The workers need to be equipped with
scrap gloves, safety belt, and helmet, while carrying the service
order. Please, select the objects representing this equipment.
They are ﬂashing in red. When you have ﬁnished, activate the
next instruction.”), while teaching them the steps needed to se-
cure the job site for workers and pedestrians. The simulation
has three phases: a learning phase, where the user learn the
proper placement of safety items, which is indicated via glow-
ing objects and arrows; and two application phases, where the
user is asked to perform the safety task using the information
they just learned. In the learning phase, users can only grab ob-
jects that have been mentioned by the storyteller, which should
reinforce their focus on the task. In the application phases, users
can grab whichever items they like and follow their own strat-
egy to place them in the scene. We change the initial placement
of objects between one phase and another to reduce the bias of
already knowing where to start.

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

8

Preprint Submitted for review / Computers & Graphics (2021)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

The users were asked to perform a set of ﬁve tasks: (1) to
ensure that the truck is parked correctly and stuck with shims at
the wheels; (2) to equip workers with scrap gloves, safety belt,
helmet, and the service order; (3) to place the materials on the
protection canvas; (4) to signal the workplace using signposts;
and (5) to isolate the workplace, including the vehicle, using
cones and ropes. The tasks should be performed according to
the users’ interpretation. In the assignment to arrange the cones
around the workplace, the users had eight available cones to be
arranged along a square illustrated by four arrows, so they could
either place one cone by each arrow or distribute a number of
cones they found necessary in the provided space. Later, they
were requested to tie the ropes between the cones previously
placed. In this case, there were seven ropes available and they
could choose a number of ropes they found necessary to isolate
the place. A barrier prevented users from crossing through the
rope after it has been tied between two cones, which served to
remind them of leaving an opening in the isolated area to allow
workers to transit.

6.2. Experimental Conditions and Apparatus

In this experiment we compared two interaction and two lo-
comotion techniques. For grabbing and manipulating objects,
we use (1) a ray-casting technique based on the Razer Hydra
controllers used as pointing devices controlled by the user arms’
movements. When the object is within view, the user holds the
controller’s button to grab and drag it, and drop it by releasing
the button; and (2) a head orientation technique, which uses
the user’s head orientation to point out to objects and one of the
Hydra’s controllers to manipulate them using a button. In terms
of locomotion techniques, we use (1) the joystick of a Hydra’s
controller for moving forward, backward, left, and right in the
environment; and (2) a WIP technique supported by a set of
four Wii balance boards, which gives the user a 0.80 × 1.2 me-
ters platform to “walk”. The experimental conditions for this
experiment are then resulting from the combination of these
techniques: (A) ray-casting and WIP, (B) ray-casting and joy-
stick, (C) head orientation and WIP, and (D) head orientation
and joystick.

The equipment worn by the participants consisted of an Ocu-
lus Rift DK2 device, a headphone, and a Sixense Razer Hydra.
To ensure a certain homogeneity among the conditions, users
went through the simulation on top of the Wii Balance Boards
platform and used the Razer Hydra controllers, regardless of the
enabled interaction/locomotion techniques (Fig. 5). The Razer
Hydra device contains a base station with a low-power mag-
netic ﬁeld that gets the controller’s position and orientation. Al-
though it does not require a line of sight to the controllers, the
range area is quite small, introducing noise to the tracking when
the user turns its back to the base station. Therefore, we used
a band to hold the base station on the user’s body (Fig. 5b). In
between, we placed a smartphone to capture the orientation of
the user’s torso, allowing this way to properly place the virtual
hands according to the user’s rotational movements. Finally, to
provide users with conﬁdence and control when using the WIP
technique, we added an EVA mat over the platform with EVA
borders around 7.5 centimeters high so the user could sense it,
being aware of the platform limits.

Fig. 5: Technical apparatus of experiment II: (a) WIP platform; (b) band to
hold the Razer Hydra base station on the user’s body; (c) a smartphone to get
the user’s orientation; (d) Oculus Rift device; (e) headphones.

6.3. Participants

Sixty volunteers took part in this experiment. They were all
students recruited in the context of a Human-Computer Interac-
tion course. Thirteen participants abandoned the simulation due
to sever cybersickness symptoms, and we have lost the log ﬁles
of one participant. Thus, we conducted the experiment with a
sample of 46 participants (4 female), aged between 18 and 33
years old (M=23.21, SD=3.42). They reported to have great
experience with 3D video games, but little with VR. They all
had normal or corrected-to-normal vision (self-reported).

6.4. Measures

Prior to the trial, we established the baseline for cybersick-
ness and users’ knowledge regarding safety procedures. We
also assessed users’ subjective memory complaints through a
10-item memory questionnaire [42], which information could
support knowledge outcomes. To assess knowledge (before and
after the trial), we prepared a 7-question test on the safety pro-
cedures addressed in the simulation. These were essay ques-
tions, presented one by one to the user and deﬁned as follows:
What do you do to secure a job site for workers and pedestri-
ans?; What do you do after arriving at the site and parking the
vehicle?; What safety equipment do you wear to perform the
task?; What extra item(s) do you need?; Where and how do you
place the working tools?; What do you do ﬁrst to secure the site
for pedestrians?; How do you isolate the job site?.

We applied the NASA Task Load Index (TLX) [43] question-
naire to assess workload for using the diﬀerent navigation and
interaction techniques. The questionnaire provides an overall
workload score based on a weighted average of ratings on six
workload factors (scales): Mental Demand (MD), Physical De-
mand (PD), Temporal Demand (TD), Own Performance (OP),
Eﬀort (EF), and Frustration (FR). Additionally, we assess user
engagement’s factors such as immersion, presence, ﬂow, and

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

Preprint Submitted for review / Computers & Graphics (2021)

9

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

physiological absorption through the Game Engagement Ques-
tionnaire (GEQ) [10]. The GEQ consists of 15 statements de-
scribing diﬀerent feelings, which the user must rate in a 5-point
Likert scale to indicate the intensity with which they experi-
enced that feeling during the simulation. Finally, we measure
user performance by combining three information: task com-
pletion time, accuracy of objects’ placement according to the
instructions given in the learning phase, and knowledge gain.

6.5. Results

Fig. 6 presents the mean scores per SSQ scale and experi-
mental condition. Although we have found statistical diﬀerence
in the mean scores of certain scales before and after the trial in
every experimental condition, suggesting that they inﬂict cy-
bersickness to users, we did not observe statistical diﬀerence
in the mean scores among the experimental conditions, nei-
ther before nor after the trial. Particularly, every experimental
condition has engendered disorientation, which highest scores
(M=56.84) were reported by users of condition C (head orien-
tation and WIP). Surprisingly, we found a 82% correlation be-
tween disorientation and knowledge gain in condition A (ray-
casting and WIP) with p<0.01. Although no statistical diﬀer-
ence was observed, the users in this group reported the lowest
disorientation scores and the highest experience scores in 3D
games (M=4.25 in a 5-point scale, SD=1.03), suggesting that
disorientation probably did not aﬀect their performance.

Fig. 6: Mean scores per SSQ scale before and after the trial in each experimental
condition of Experiment II. A, B, C and D are the experimental conditions, see
section 6.2

The overall workload scores were above average (scores
range from 0 to 100), varying from 49.2 in condition A to 62.4
in condition B, which diﬀerence of means showed statistical
signiﬁcance with p<0.05. In terms of the diﬀerent scales mea-
sured by the NASA TLX questionnaire (Fig. 7), we observed
statistical diﬀerence in the mean scores of: frustration between
conditions A (M=37.27) and D (M=206.36); mental demand
between conditions A (M=177.27) and D (M=50); own per-
formance between conditions B (M=315) and D (M=143.63);
and physical demand between conditions C (M=131.66) and
D (M=205.45). Furthermore, we observed a 71% correla-
tion between mental demand and knowledge gain in condition
A (p<0.05), suggesting that users had higher knowledge gain

Fig. 7: Reported workload scores for each scale: mental demand (MD), phys-
ical demand (PD), temporal demand (TD), own performance (OP), eﬀort (EF)
and frustration (FR) for the experimental conditions on Experiment II.

when the task required higher mental eﬀort. For users in condi-
tion B, we found a -69% correlation between overall workload
scores and knowledge gain (p=0.019), suggesting that when
users needed higher loads of work their ability to retain knowl-
edge is reduced.

Figure 8 shows the response accuracy for the knowledge test
taken by users before, after, and three weeks after the trial. We
observed a statistical diﬀerence in the mean accuracy scores for
those three measurement times. We did not found statistical dif-
ference between scores of tests taken after the trial, which simi-
larity between means suggest that users were capable of recall-
ing the information learned during the simulation. The mean
simulation times across conditions varied from 20 minutes in
conditions A and B to 32.7 minutes in condition D, which
diﬀerence of means showed statistical signiﬁcance (p<0.001).
Overall, the completion time reduced between the simulation’s
phases, which was expected due to users familiarizing with the
navigation/interaction techniques, the VE, and the tasks. Users
took around 3.6 minutes less time to ﬁnish the ﬁrst application
phase than the learning, and the completion time of the second
application phase was yet reduced in around 1.1 minutes (no
statistical diﬀerence was observed among conditions).

Overall, users could complete the simulation’s tasks with
95% of accuracy. Particularly, we noticed that 88% of users
could correctly recall the instructions given in the learning
phase regarding the objects’ placement. In terms of isolating
the job site, i.e. by forming a fence with cones and a rope
around the area containing the canvas with the tools and the
truck, while leaving an opening on it to allow workers to tran-
sit, we observed that the 78% of users placed the cones cor-
rectly, but only 36% of them left an opening in the fence. We
observed statistical diﬀerence among conditions in users’ accu-
racy to complete certain tasks. In terms of tools placement on
the canvas, participants in condition B performed better than
users in condition D (p<0.038). Participants in condition C
and D were more accurate in terms of arranging the signposts
than users in condition A (p<0.05) and B (p<0.05), respectively.
Users in condition C were also more accurate in terms of iso-
lating the job site than participants in condition D (p<0.05).

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

10

Preprint Submitted for review / Computers & Graphics (2021)

7. Discussion

In this work, we performed two empirical studies to investi-
gate the impacts of three diﬀerent VR displays and four interac-
tion techniques on several VR aspects, such as motion sickness,
workload, engagement, sense of presence, user performance,
and learning outcomes on training simulations.

7.1. Main Findings

Our results showed that participants could perform certain
tasks with higher accuracy, such as isolating the job site us-
ing the conditions where navigation was supported via the WIP
technique, and placing tools over a canvas in conditions where
they would grab and manipulate objects using the ray-casting
technique. The latter provided a physical reference through a
Razer Hydra’s controller, which higher accuracy on perform-
ing the task suggests that users could better recall the informa-
tion given during the learning phase, in conformity with previ-
ous ﬁndings [36]. Although we did not observe statistical dif-
ference in knowledge gain among experimental conditions and
replication of these experiments may be necessary to evaluate
our hypotheses, our results suggest that semi-natural naviga-
tion/interaction techniques could improve user performance.

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

62

65

64

61

Previous studies suggest that semi-natural interfaces, i.e. in-
terfaces that use real walking and body interaction, could be in-
eﬃcient since they require the user to operate it diﬀerently from 63
what they are used to, which adds workload to the process [44].
However, we observed that users reported higher frustration
scores when using the head orientation technique and the joy-
stick to navigate, while they were more engaged with the simu-
lation when moving their arms and legs through the ray-casting
and WIP techniques, which were considered high mentally de-
manding by users. Users also perceived a higher quality on their
own performance when using the WIP technique compared to
the joystick. Furthermore, we observed a positive correlation
between mental demand and knowledge gain in the condition
using WIP and ray-casting, which also had the lowest simula-
tor sickness eﬀects. Our results suggest that providing close
to natural interaction interfaces can be enjoyable and aid users
to transfer the potential mental burden generated from adapting
their real-walking expertise to better performance.

78

77

75

74

72

69

73

70

71

66

67

68

76

7.2. Lessons Learned

Disorientation is probably a consequence of the user un-
awareness of their surroundings. As we have hypothesized,
techniques providing semi-natural interaction did not increase
the severity of sickness symptoms, because users could “move”
together with the VE. Nonetheless, we observed that disorienta-
tion would be a constant across the experimental conditions in
experiment II, which coincides with the disorientation reported
by users of the HMD in experiment I, suggesting that disori-
entation is only the fact that the user is not aware of their sur-
roundings, which seems not to be aﬀected by the diﬀerent inter-
action/locomotion techniques. Thus, our ﬁndings suggest that
better VEs would allow the user to be aware of their surround-
ings, such as through the use of physical interaction devices
and more importantly through haptic interaction, allowing the

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

Fig. 8: Response accuracy for the knowledge test taken by users before, after,
and three weeks after the trial phase of experiment II.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

The GEQ mean score was 2.8 across experimental condi-
tions, which diﬀerences were not statistical signiﬁcant. We
have found a 45% correlation between mental demand and en-
gagement (p<0.01), suggesting that navigation/interaction tech-
niques demanding higher mental eﬀort also tend to be more en-
gaging. Overall, users reported to have enjoyed the experience
and found it easy to learn and apply the safety procedures. As in
the previous experiment, we allow users to walk towards their
looking direction to reduce the severity of sickness symptoms.
In this matter, two persons have said that they would like to
walk backwards. Selecting objects in the scene was reported
to be diﬃcult by some users, particularly regarding the cones.
Participants suggested the addition of a checklist to allow the
user to check tasks as done as they progress in the simulation.

6.6. Hypotheses Assessment

Due to the lack of statistical signiﬁcance regarding knowl-
edge gain, simulation time, and task accuracy across condi-
tions, we cannot accept not refuse H1. Every experimental
condition increased the severity of sickness symptoms in every
SSQ scale, except oculomotor. Condition A requires the user
to move their arms around to select objects and employs the
WIP technique for navigating in the VE. Although the mean
SSQ scores in condition A are the lowest in every scale, we
could not ﬁnd statistical signiﬁcance to support the diﬀerence
In terms of knowledge gain, a
of means among conditions.
negative correlation between overall workload and knowledge
gain suggests that high demanding navigation/interaction tech-
niques could distract users from the task, requiring them to
place higher attention on how to use the techniques, decreasing
knowledge gain. In condition A, we observed a positive corre-
lation between mental demand and knowledge gain, suggesting
that mentally demanding techniques do not aﬀect knowledge
gain. In this condition, we also observed that users appear to
be more engaging when mental demand increase. Thus, we be-
lieve that the freedom provided by more natural movements in
condition A allowed users to keep focus on the task, increas-
ing mental demand and learning. These experiments should be
repeated and the sample enlarged to evaluate H2 and H3. How-
ever, we believe these results favor their acceptance.

Preprint Submitted for review / Computers & Graphics (2021)

11

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

user to physically feel what they’re virtually experiencing. Such
physical approaches have been previously explored to increase
awareness in VEs and improve user experience (see [45, 46]).

The use of interaction techniques as natural as possible
continue to be the best choice. Simulations designed for VR
technology aim to provide a real-world-like experience, where
high sense of presence, immersion and realism are essential in-
gredients. Thus, it is important to allow the use of our well-
known movements to navigate and interact with the VE. While
much research is still needed to improve this technology, there
are several studies [10, 20, 32], including this one, showing the
advantages of natural or semi-natural interaction techniques on
user performance and experience. Thus, users could leverage of
training simulators employing well-drafted (semi-)natural inter-
action techniques, which provide the sense of naturally navigat-
ing and grabbing objects in the VE, while providing accuracy
for eﬀectively dealing with small objects or performing precise
tasks, such as painting.

Perception is more likely to be aﬀected by the user ex-
pertise on the simulator subject than by the technology em-
ployed. We have observed in experiment I (Section 5) that nei-
ther the VR display nor the sickness caused by it aﬀected user
perception. However, we noticed that users had a rather poor
performance on what refers to the risk scanning task. Users
were able to select 20% of risks elements (consistently through-
out the devices), which is a low selection rate, likely explained
by users’ self-reported very low knowledge on work safety pro-
cedures. Previous works showed that the familiarity of users
with the objects in the environment improves the user expe-
rience [24, 10]. Similarly, considering that our simulator have
been developed to assess the ability of users to detect hazardous
objects in the workplace, we suppose that the knowledge on the
subject could have strongly impacted user performance, since
one should know what is an hazardous element in the real work-
place to be able to identify it in the simulation. Therefore, fur-
ther studies using the “risk perception assessment” or similar
simulations to investigate user perception should recruit target
users of the simulation or to provide a training on work safety
to the participants before undertaking the simulation.

Gaming experience plays an important role on VR simu-
lation. We have found a positive correlation between disorien-
tation and knowledge gain in condition A of experiment II (Sec-
tion 6), which oddly suggests that users improved their scores
despite the severity of disorientation’s symptoms. However, we
noticed that the users in this group reported to have high experi-
ence with 3D video games. Thus, we could suppose that users’
familiarity with games and the constantly experienced mild cy-
bersickness due 3D graphics allowed them to keep focused on
the simulation despite the disorientation experienced in the VE.
Further, while studying the impact of narrative in immersive
VR games, Weech et al. [47] also observed diﬀerences cyber-
sickness symptoms reported by gamers and non-gamers. While
non-gamers reported higher cybersickness when receiving min-
imal narrative, regular gamers would present similar levels of
cybersickness regardless of the narrative context.

Although our case study focuses on work safety training, our
results and lessons learned can assist the choice of VR devices

to provide a comfortable and eﬃcient virtual training environ-
ment in other application domains and, particularly, for simula-
tions requiring the users to leverage their perception skills. For
instance, our observations regarding the eﬀects of users’ proﬁle
on perception and cybersickness could help designers to con-
ceive suitable guidance for simulators based on users’ proﬁle
(e.g., whether they need more pre-training on the simulator’s
subject or the usage of devices, etc). Likewise, the usage of
high ﬁdelity devices to provide a real-world-like experience is
independent of the application domain and can be generalized
to any type of training simulator.

7.3. Limitations

Each user experiment tested multiple independent variables
by 107 volunteers in total. Nevertheless, we applied between-
subjects designs in both experiments due to the learning nature
of our dependent variables, reducing the groups to 20 and 12
persons, respectively. Thus, these experiments should be repli-
cated using larger groups, and preferably the simulator’s target
users, to strengthen our ﬁndings. The lack of expertise on work
safety may have introduced bias to the results. As suggested by
Nazir et al. [48], immersive simulators are not eﬀective per se
and need guidance of a professional in the ﬁeld when the task
is unfamiliar. We have used VR technology that was available
to us at the time of this study. Hence, a new set of experi-
ments should be performed using novel technology to under-
stand whether these results are technology independent.

8. Conclusion

We conducted two empirical studies to investigate the eﬀects
of VR interface on perceptual learning and knowledge reten-
tion in simulations designed for worker safety training. We
measured simulator sickness, self-reported workload, engage-
ment, presence and performance. Our objective was to better
understand the impacts of diﬀerent display devices and interac-
tion techniques on user performance and simulation outcomes.
Our results strongly suggest that a setup employing interaction
and navigation techniques closest to natural movements can im-
prove user performance. In our experiments, we observed this
improvement through accurately placing objects in the VE, giv-
ing users the feeling of performing better, and having low ef-
fects on simulator sickness. However, users still had a phys-
ical reference for moving the hands in the VE and select ob-
jects, which is supported by previous studies as a mechanism to
improve memory recall. Diﬀerent VR display devices did not
inﬂuence the user performance in our risk scanning task, but
rather their experience on work safety.

9. Acknowledgments

58

59

60

61

62

63

64

65

66

67

68

69

70

71

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

This study was ﬁnanced in part by the Coordination for the
Improvement of Higher Education Personnel, Brazil (CAPES,
Finance Code 001). We also acknowledge the support from Na-
tional Council for Scientiﬁc and Technological, Brazil (CNPq),
the participants of our experiments for allowing us to borrow 108
their time and knowledge for this study, and the comments of
the reviewers that helped us to improve the quality of this paper.

105

106

107

104

109

110

12

References

Preprint Submitted for review / Computers & Graphics (2021)

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

56

57

58

59

60

61

62

63

64

65

66

67

68

69

70

71

[1] Chittaro, L, Buttussi, F. Assessing knowledge retention of an immersive
serious game vs. a traditional education method in aviation safety. IEEE
Transactions on Visualization & Computer Graphics 2015;21(4):529–
538. doi:10.1109/TVCG.2015.2391853.

[2] Backlund, P, Engstr¨om, H, Hammar, C, Johannesson, M, Lebram,
M. Sidh-a game based ﬁreﬁghter training simulation.
In: Information
Visualization, 2007. IV’07. 11th International Conference. IEEE; 2007,
p. 899–907.

[3] Pedraza-Hueso, M, Mart´ın-Calz´on, S, D´ıaz-Pernas, FJ, Mart´ınez-
Zarzuela, M. Rehabilitation using kinect-based games and virtual reality.
Procedia Computer Science 2015;75:161 – 168. doi:https://doi.org/
10.1016/j.procs.2015.12.233; 2015 International Conference Vir-
tual and Augmented Reality in Education.

[4] Cecil, J, Gupta, A, Pirela-Cruz, M. An advanced simulator for orthope-
dic surgical training. International journal of computer assisted radiology
and surgery 2018;13(2):305–319.

[5] Mobach, MP. Do virtual worlds create better real worlds?

Vir-
tual Reality 2008;12(3):163–179. URL: https://doi.org/10.1007/
s10055-008-0081-2. doi:10.1007/s10055-008-0081-2.

[6] Jiang, M, Lan, W, Chang, J, Dodwell, M, Jekins, J, Yang, HJ, et al. A
game prototype for understanding the safety issues of a lifeboat launch.
Virtual Real 2018;22(2):137–148. URL: https://doi.org/10.1007/
s10055-018-0334-7. doi:10.1007/s10055-018-0334-7.

[7] Menin, A, Torchelsen, R, Nedel, L. An analysis of vr technology used in
immersive simulations with a serious game perspective. IEEE Computer
Graphics and Applications 2018;38(2):57–73. doi:10.1109/MCG.2018.
021951633.

[8] Laird, D. Approaches to training and development addison-wesley. Read-

ing, Mass 1985;.

[9] Mania, K, Chalmers, A. The eﬀects of levels of immersion on
memory and presence in virtual environments: a reality centered ap-
proach. Cyberpsychology & behavior : the impact of the Internet, multi-
media and virtual reality on behavior and society 2001;4(2):247—264.
URL: https://doi.org/10.1089/109493101300117938. doi:10.
1089/109493101300117938.

[10] McMahan, RP, Bowman, DA, Zielinski, DJ, Brady, RB. Evaluating
IEEE
display ﬁdelity and interaction ﬁdelity in a virtual reality game.
Transactions on Visualization and Computer Graphics 2012;18(4):626–
633. doi:10.1109/TVCG.2012.43.

[11] Bowman, DA, Sowndararajan, A, Ragan, ED, Kopper, R. Higher
levels of immersion improve procedure memorization performance. In:
Proceedings of the 15th Joint Virtual Reality Eurographics Conference
on Virtual Environments. JVRC’09; Aire-la-Ville, Switzerland, Switzer-
land: Eurographics Association. ISBN 978-3-905674-20-0; 2009, p. 121–
128. URL: http://dx.doi.org/10.2312/EGVE/JVRC09/121-128.
doi:10.2312/EGVE/JVRC09/121-128.

[12] Kwon, C. Veriﬁcation of the possibility and eﬀectiveness of experien-
tial learning using hmd-based immersive vr technologies. Virtual Re-
ality 2018;URL: https://doi.org/10.1007/s10055-018-0364-1.
doi:10.1007/s10055-018-0364-1.

[13] Ragan, ED. Supporting learning through spatial information presenta-
tions in virtual environments. Ph.D. thesis; Blacksburg, VA, USA; 2013.
AAI3585819.

[14] Bennett, A, Coxon, M, Mania, K. The eﬀect of stereo and context
on memory and awareness states in immersive virtual environments. In:
Proceedings of the 7th Symposium on Applied Perception in Graphics
and Visualization. ACM; 2010, p. 135–140.

[15] Roman, F, Maciel, A, Nedel, L. Improving gameplay in ﬁrst person 3-d
games using multiple displays. Comput Entertain 2015;12(2):1:1–1:22.
URL: http://doi.acm.org/10.1145/2701657.2701653. doi:10.
1145/2701657.2701653.

[16] Napieralski, PE, Altenhoﬀ, BM, Bertrand, JW, Long, LO, Babu, SV,
Pagano, CC, et al. Eﬀects of immersion on spatial updating in virtual
panoramas. In: Proceedings of the ACM Symposium on Applied Percep-
tion. SAP ’12; New York, NY, USA: ACM. ISBN 978-1-4503-1431-2;
2012, p. 129–129. URL: http://doi.acm.org/10.1145/2338676.
2338711. doi:10.1145/2338676.2338711.

[17] Ragan, ED, Bowman, DA, Kopper, R, Stinson, C, Scerbo, S, McMa-
han, RP. Eﬀects of ﬁeld of view and visual complexity on virtual
reality training eﬀectiveness for a visual scanning task.
IEEE Trans-

actions on Visualization and Computer Graphics 2015;21(7):794–807.
doi:10.1109/TVCG.2015.2403312.

[18] McMahan, RP, Bowman, DA. Virtual reality: How much im-
mersion is enough?
URL: doi.
ieeecomputersociety.org/10.1109/MC.2007.257. doi:10.1109/
MC.2007.257.

Computer 2007;40:36–43.

[19] Krokos, E, Plaisant, C, Varshney, A. Virtual memory palaces:

im-
mersion aids recall. Virtual Reality 2018;URL: https://doi.org/10.
1007/s10055-018-0346-3. doi:10.1007/s10055-018-0346-3.
[20] Nabioyuni, M, Bowman, DA. An evaluation of the eﬀects of hyper-
natural components of interaction ﬁdelity on locomotion performance in
virtual reality. In: Proceedings of the 25th International Conference on
Artiﬁcial Reality and Telexistence and 20th Eurographics Symposium
on Virtual Environments. ICAT - EGVE ’15; Aire-la-Ville, Switzerland,
Switzerland: Eurographics Association. ISBN 978-3-905674-84-2; 2015,
p. 167–174. URL: http://dx.doi.org/10.2312/egve.20151325.
doi:10.2312/egve.20151325.

[21] Kakoschke, N, Page, R, de Courten, B, Verdejo-Garcia, A, McCormack,
J. Brain training with the body in mind: Towards gamiﬁed approach-
avoidance training using virtual reality. International Journal of Human-
Computer Studies 2021;151:102626.

[22] Albus, P, Vogt, A, Seufert, T. Signaling in virtual reality inﬂu-
ences learning outcome and cognitive load. Computers & Education
2021;166:104154.

[23] Gupta, A, Cecil, J, Pirela-Cruz, M. A cyber-human based integrated
assessment approach for orthopedic surgical training. In: 2020 IEEE 8th
International Conference on Serious Games and Applications for Health
(SeGAH). IEEE; 2020, p. 1–8.

[24] Di Mascio, T, Tarantino, L, De Gasperis, G, Pino, C. Immersive virtual
environments: a comparison of mixed reality and virtual reality headsets
for asd treatment.
In: International Conference in Methodologies and
intelligent Systems for Techhnology Enhanced Learning. Springer; 2019,
p. 153–163.

[25] Hasanzadeh, S, Polys, NF, de la Garza, JM. Presence, mixed reality, and
risk-taking behavior: A study in safety interventions. IEEE Transactions
on Visualization and Computer Graphics 2020;26(5):2115–2125. doi:10.
1109/TVCG.2020.2973055.

[26] Simeone, AL, Speicher, M, Molnar, A, Wilde, A, Daiber,

F.
LIVE: the human role in learning in immersive virtual environments.
In: Borst, CW, Kulshreshth, AK, Bruder, G, Seraﬁn, S, Sandor,
C, Johnsen, K, et al., editors. Symposium on Spatial User Interaction,
SUI 2019, New Orleans, LA, USA, October 19-20, 2019. ACM; 2019,
p. 5:1–5:11. URL: https://doi.org/10.1145/3357251.3357590.
doi:10.1145/3357251.3357590.

[27] Bozkir, E, Stark, P, Gao, H, Hasenbein, L, Hahn,

J, Kasneci, E,
et al. Exploiting object-of-interest information to understand attention
in VR classrooms.
In: IEEE Virtual Reality and 3D User Interfaces,
VR 2021, Lisbon, Portugal, March 27 - April 1, 2021. IEEE; 2021, p.
597–605. URL: https://doi.org/10.1109/VR50410.2021.00085.
doi:10.1109/VR50410.2021.00085.

[28] Nedel, L, de Souza, VC, Menin, A, Sebben, L, Oliveira, J, Faria, F,
et al. Using immersive virtual reality to reduce work accidents in develop-
ing countries. IEEE computer graphics and applications 2016;36(2):36–
46.

[29] Adolph, KE, Kretch, KS. Gibson’s theory of perceptual learning.

i:
Keller H(Developmental Section red) International Encyclopedia of the
Social and Behavioral Sciences, 2015;10:127–134.

[30] Krathwohl, DR. A revision of bloom’s taxonomy: An overview. Theory
Into Practice 2002;41(4):212–218. doi:10.1207/s15430421tip4104\
_2.

[31] Hodgson, E, Bachmann, E, Waller, D. Redirected walking to ex-
plore virtual environments: Assessing the potential for spatial interfer-
ence. ACM Trans Appl Percept 2008;8(4):22:1–22:22. URL: http://
doi.acm.org/10.1145/2043603.2043604. doi:10.1145/2043603.
2043604.

[32] Interrante, V, Ries, B, Anderson, L. Seven league boots: A new
metaphor for augmented locomotion through moderately large scale im-
mersive virtual environments.
In: 2007 IEEE Symposium on 3D User
interfaces. IEEE; 2007,.

[33] Usoh, M, Arthur, K, Whitton, MC, Bastos, R, Steed, A, Slater,
M, et al. Walking > walking-in-place > ﬂying, in virtual environments.
In: Proceedings of the 26th Annual Conference on Computer Graph-

72

73

74

75

76

77

78

79

80

81

82

83

84

85

86

87

88

89

90

91

92

93

94

95

96

97

98

99

100

101

102

103

104

105

106

107

108

109

110

111

112

113

114

115

116

117

118

119

120

121

122

123

124

125

126

127

128

129

130

131

132

133

134

135

136

137

138

139

140

141

142

143

Preprint Submitted for review / Computers & Graphics (2021)

13

ics and Interactive Techniques. SIGGRAPH ’99; New York, NY, USA:
ACM Press/Addison-Wesley Publishing Co. ISBN 0-201-48560-5; 1999,
p. 359–364. URL: http://dx.doi.org/10.1145/311535.311589.
doi:10.1145/311535.311589.

[34] Greunke, L, Sadagic, A. Taking immersive vr leap in training of landing
signal oﬃcers. IEEE transactions on visualization and computer graphics
2016;22(4):1482–1491.

[35] Bowman, DA, Hodges, LF. An Evaluation of Techniques for Grabbing
and Manipulating Remote Objects in Immersive Virtual Environments.
In: Proceedings of the Symposium on Interactive 3D Graphics. Provi-
dence, RI, USA; 1997, p. 35–38.

[36] Mine, MR, Brooks Jr, FP, Sequin, CH. Moving objects in space: ex-
ploiting proprioception in virtual-environment interaction. In: Proceed-
ings of the 24th annual conference on Computer graphics and interactive
techniques. 1997, p. 19–26.

[37] Kennedy, RS, Lane, NE, Berbaum, KS, Lilienthal, MG. Simulator sick-
ness questionnaire: An enhanced method for quantifying simulator sick-
ness. The international journal of aviation psychology 1993;3(3):203–
220.

[38] Balk, SA, Bertola, MA, Inman, VW. Simulator sickness question-
naire: Twenty years later. In: Seventh International Driving Symposium
on Human Factors in Driver Assessment, Training and Vehicle Design.
University of Iowa; 2013,.

[39] Abdi, H, Williams, LJ. Tukey’s honestly signiﬁcant diﬀerence (hsd) test.

Encyclopedia of research design 2010;3(1):1–5.

[40] Nemenyi, PB. Distribution-free multiple comparisons. Princeton Uni-

versity; 1963.
[41] Usoh, M, Catena,

S, Slater, M. Using presence
questionnaires in reality. Presence 2000;9(5):497–503. doi:10.1162/
105474600566989.

E, Arman,

[42] Zelinski, EM, Gilewski, M. A 10-item rasch modeled memory self-

eﬃcacy scale. Aging & mental health 2004;8(4):293–306.

[43] Hart, SG, Staveland, LE. Development of nasa-tlx (task load index):
Results of empirical and theoretical research. In: Hancock, PA, Meshkati,
N, editors. Human Mental Workload; vol. 52 of Advances in Psychology.
North-Holland; 1988, p. 139 – 183. doi:https://doi.org/10.1016/
S0166-4115(08)62386-9.

[44] Nabiyouni, M, Saktheeswaran, A, Bowman, DA, Karanth, A. Compar-
ing the performance of natural, semi-natural, and non-natural locomotion
techniques in virtual reality. In: 2015 IEEE Symposium on 3D User In-
terfaces (3DUI). 2015, p. 3–10. doi:10.1109/3DUI.2015.7131717.

[45] de Jesus Oliveira, VA, Brayda, L, Nedel, L, Maciel, A. Designing a vi-
brotactile head-mounted display for spatial awareness in 3d spaces. IEEE
transactions on visualization and computer graphics 2017;23(4):1409–
1417.

[46] Valkov, D, Linsen, L. Vibro-tactile feedback for real-world awareness
in immersive virtual environments. In: 2019 IEEE Conference on Virtual
Reality and 3D User Interfaces (VR). IEEE; 2019, p. 340–349.

[47] Weech,

S, Kenny,

S, Lenizky, M, Barnett-Cowan, M. Narra-
tive and gaming experience interact to aﬀect presence and cybersick-
ness in virtual reality. International Journal of Human-Computer Studies
2020;138:102398.

[48] Nazir, S, Kluge, A, Manca, D. Can immersive virtual environments
make the diﬀerence in training industrial operators. Proceedings of the
Human Factors and Ergonomics Society Europe 2014;:251–265.

1

2

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

26

27

28

29

30

31

32

33

34

35

36

37

38

39

40

41

42

43

44

45

46

47

48

49

50

51

52

53

54

55

