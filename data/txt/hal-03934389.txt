The Regular Languages of First-Order Logic with One
Alternation
Corentin Barloy, Michael Cadilhac, Charles Paperman, Thomas Zeume

To cite this version:

Corentin Barloy, Michael Cadilhac, Charles Paperman, Thomas Zeume. The Regular Languages of
First-Order Logic with One Alternation. LICS 2022 - 37th Annual ACM/IEEE Symposium on Logic
in Computer Science, Aug 2022, Haïfa, Israel. pp.1-11, ￿10.1145/3531130.3533371￿. ￿hal-03934389￿

HAL Id: hal-03934389

https://hal.science/hal-03934389

Submitted on 11 Jan 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

The Regular Languages of First-Order Logic
with One Alternation

2
2
0
2

r
a

M
1
1

]

O
L
.
s
c
[

1
v
5
7
0
6
0
.
3
0
2
2
:
v
i
X
r
a

Corentin Barloy
corentin.barloy@inria.fr
Univ. Lille, CNRS, INRIA, Centrale Lille, UMR 9189
CRIStAL
France

Charles Paperman
charles.paperman@univ-lille.fr
Univ. Lille, CNRS, INRIA, Centrale Lille, UMR 9189
CRIStAL
France

Abstract
The regular languages with a neutral letter expressible
in first-order logic with one alternation are characterized.
Specifically, it is shown that if an arbitrary Σ2 formula
defines a regular language with a neutral letter, then there is
an equivalent Σ2 formula that only uses the order predicate.
This shows that the so-called Central Conjecture of Straub-
ing holds for Σ2 over languages with a neutral letter, the first
progress on the Conjecture in more than 20 years. To show
the characterization, lower bounds against polynomial-size
depth-3 Boolean circuits with constant top fan-in are
developed. The heart of the combinatorial argument resides
in studying how positions within a language are determined
from one another, a technique of independent interest.

Keywords: automata theory, first-order logic, descriptive
complexity, circuit complexity.

1 Introduction

Circuits and regular languages. Since the works of
Barrington and Thérien [2, 5] in the early 1990s, regular
languages have emerged as the backbone of small-depth cir-
cuit complexity. Despite being the most elementary class of
languages, regular languages seem to embody the intrinsic
power of circuit classes. Under a suitable notion of reduction,
a lot of relevant circuit classes even admit complete regular
languages (this is at the heart of Barrington’s Theorem [2]).
In addition, it seems that each natural restriction of small-
depth circuits defines its own class of regular languages.

More precisely, consider the following families:
• AC0

𝑖 is the class of Boolean circuits families of depth 𝑖

and polynomial size,

𝑖 is the same as AC0

𝑖 but with additional modulo

• ACC0
gates,

• TC0

𝑖 is the same as AC0

𝑖 but with additional threshold

gates (more than half of the inputs are 1).

The hierarchy in depth of AC0 is known to be strict [26], but
this is open for the other classes (for TC0 this is known up

Michaël Cadilhac
michael@cadilhac.name
DePaul University
USA

Thomas Zeume
thomas.zeume@rub.de
Ruhr-Universität Bochum
Germany

to depth 3 [13]). It is however conjectured that each of these
hierarchies is strict and that strictness can always be wit-
nessed by regular languages; in other words, as mentioned,
each of these classes is conjectured to have its own subset of
regular languages.

Over the past 30 years, abundant literature has provided
a sophisticated toolset to show separation (and sometimes
decidability) of classes of regular languages. This toolset
relies on algebraic objects that characterize the complexity
of regular languages; this object satisfies some properties
iff the language belongs to some class. It is thus tempting
to, first, characterize the regular languages that belong to
a circuit class, and, second, separate the classes that arise.
This paper is focused on that first step, for a specific class of
circuits (loosely speaking, AC0
3).
Logic. Wishing to provide a guiding light, Straubing [30]
presented in a succinct but beautiful way the links between
circuit complexity and automata theory, and formulated a
conjecture on. . . logics. Indeed, circuits themselves are ill-
formed for statements of the form “a circuit family AC0
𝑖 rec-
ognizes a regular language iff it has this specific shape.” Logic
came to the rescue by giving a descriptional tool for circuits.
This started with the work of Barrington et al. [3] and Straub-
ing [29] who showed that AC0 (= (cid:208)𝑖 AC0
𝑖 ) is equivalent to
first-order logic. This means that for any AC0 circuit family,
there is a first-order formula, with quantifiers over positions,
that recognizes the same language. For instance, over the
alphabet 𝐴 = {𝑎, 𝑏, 𝑐} the language 𝐴∗𝑎𝑏∗𝑎𝐴∗, which is in
AC0

2, can be written as:

(∃𝑥, 𝑦) [𝑥 < 𝑦 ∧ 𝑎(𝑥) ∧ 𝑎(𝑦) ∧

(find the 2 𝑎s)

(∀𝑧) [𝑥 < 𝑧 < 𝑦 → 𝑏 (𝑧)]]

(everything in between is a 𝑏)
In this formula, we used the numerical predicate <; numer-
ical predicates speak about the numerical value of positions
but not their contents. The class of (languages recognized
by) formulas FO[arb] is that of first-order formulas where
we allow any numerical predicate (even undecidable ones!).

 
 
 
 
 
 
The aforementioned characterization reads: AC0 = FO[arb].
Extensions of this tight relationship between circuits and
logics exist for ACC0, TC0, and other classes (see [30]).

Equipped with this, the characterization of the regular

languages of AC0 is given by this striking statement [29]:

FO[arb] ∩ Reg = FO[reg],

where reg is the set of numerical predicates <, +1, and divisi-
bility by constants. Straubing notes “this phenomenon appears
to be quite general” and postulates that for well-behaved log-
ics L, it holds that

L [arb] ∩ Reg = L [reg].

This is known as the Straubing Property for L (simply Cen-
tral Conjecture in [30]) and it is explicitly stated for the logics
Σ𝑖 . Straubing [30, p. 169] explains: “This has the look of a
very natural principle. It says, in effect, that the only numer-
ical predicates we need in a sentence that defines a regular
language are themselves recognized by finite automata.”

The Program for Separation in circuit complexity then

becomes:

1. Identify a logic that corresponds to the circuit class,
2. Prove the Straubing Property for the class,
3. Show separation over regular languages.

In this work, we apply this approach to the lower reaches
of the AC0
𝑖 hierarchy. Step 1 in the Program is covered by a
result of [20]; we will be focusing on the subset Σ𝑖 of FO of
formulas with 𝑖 quantifier alternations, starting with an ex-
istential one. For instance, the above formula is in Σ2 [<, +1].
The Straubing Properties for these logics are very much
open: it is known to hold for Σ1 [30] and its Boolean clo-
sure [20, 31], but no progress has been made on Straubing
Properties since the end of the 1990s.

We will be mostly focusing on languages with a neutral
letter, this means that the languages will admit a letter 𝑐 that
can be added or removed from words without impacting their
membership in the language. This is usually not a restric-
tion to the Program for Separation, since it is conjectured
that circuit classes are separated by regular languages with
neutral letters. See, in particular, the fascinating survey by
Koucký [17]. Write Neut for the set of languages that have a
neutral letter. The Neutral Straubing Property is that for a
logic L, it holds that:

L [arb] ∩ Reg ∩ Neut = L [<] ∩ Neut.

Contributions. We show that Σ2 has the Neutral Straub-
ing Property and that Δ2 = (Σ2 ∩ Π2) has the Straubing Prop-
erty, where Π2 is defined as Σ2 but with ∃ and ∀ swapped.
Consequently, we exhibit some natural regular languages
that separate AC0

2 and AC0
3.

Related work. In [12], the authors study the model of so-
called programs over DA. This defines another subclass of

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

AC0, but it is not known to have any equivalent characteri-
zation in terms of circuits. It is in particular not known to be
equivalent to Σ2 [arb] ∩ Π2 [arb] or to the two-variable frag-
ment of FO[arb], classes that we will explore in Section 6.
They give a precise description of the regular languages
computable with programs over DA, but their proof uses
the algebraic structure of DA, which is not available in our
setting.

The class Σ2 [<] corresponds to the second level of the
Straubing-Thérien hierarchy, an extensively studied hierar-
chy that is closely tied to the famous dot-depth hierarchy.
A major open problem is to decide whether a given regular
language belongs to a given level of this hierarchy. See the
survey of Pin [21] for a modern account on this topic and
the recent major progress of Place and Zeitoun [25].

Organization of the paper. We introduce circuits, logic,
and a bit of algebra in Section 2. In Section 3, we introduce so-
called limits, a classical tool in devising lower bounds against
depth-3 circuits. In Section 4, we present a simple lower
bound against a language in Σ2; this serves as both a warm-
up for the main proof and to identify the difficulties ahead.
In Section 5, we prove our main result, that is, the Neutral
Straubing Property for Σ2. In Section 6, we derive some
consequences of our main result, in particular the Straubing
Property for Δ2. We conclude in Section 7.

2 Preliminaries
We assume familiarity with regular languages, logic, and
circuits, although we strive to keep this presentation self-
contained. We write Reg for the class of regular languages.

Word, languages, neutral letters. Following Lothaire [19],

a word 𝑣 = 𝑎1𝑎2 . . . 𝑎𝑛, with each 𝑎𝑖 in an alphabet 𝐴, is a sub-
word of a word 𝑣 if 𝑣 can be written as 𝑣 = 𝑣0𝑎1𝑣1𝑎2 · · · 𝑎𝑛𝑣𝑛,
with each 𝑣𝑖 in 𝐴∗. We say that a language 𝐿 separates 𝑋
from 𝑌 if 𝑋 ⊆ 𝐿 and 𝐿 ∩ 𝑌 = ∅. A language 𝐿 has a neutral
letter if there is a letter 𝑐 such that 𝑢 · 𝑐 · 𝑣 ∈ 𝐿 ⇔ 𝑢 · 𝑣 ∈ 𝐿
for all words 𝑢, 𝑣. We write Neut for the class of languages
with a neutral letter.

Monoids, ordered monoids, morphisms. A monoid is a
set equipped with a binary associative operation, denoted
multiplicatively, with a identity element. An idempotent of 𝑀
is an element 𝑒 ∈ 𝑀 that satisfies 𝑒2 = 𝑒. For an alphabet 𝐴,
the set 𝐴∗ is the free monoid generated by 𝐴, its identity ele-
ment being the empty word. An ordered monoid is a monoid
equipped with a partial order ≤ compatible with the product,
i.e., 𝑥 ≤ 𝑦 implies 𝑥𝑧 ≤ 𝑦𝑧 and 𝑧𝑥 ≤ 𝑧𝑦 for any 𝑥, 𝑦, 𝑧 ∈ 𝑀.
Any monoid can be seen as an ordered monoid, using equal-
ity as order. An upper set of an ordered monoid 𝑀 is a set 𝑆
such that for any 𝑥, 𝑦 ∈ 𝑀, if 𝑥 ∈ 𝑆 and 𝑥 ≤ 𝑦 then 𝑦 ∈ 𝑆. A
morphism is a map ℎ : 𝑀 → 𝑁 satisfying ℎ(𝑎𝑏) = ℎ(𝑎)ℎ(𝑏)
and ℎ(1) = 1, with 𝑎, 𝑏 ∈ 𝑀 and 1 denoting the identity
element of 𝑀 and 𝑁 .

The Regular Languages of First-Order Logic with One Alternation

Monoids as recognizers. An ordered monoid 𝑀 recog-
nizes a language 𝐿 ⊆ 𝐴∗ if there is a morphism ℎ : 𝐴∗ → 𝑀
and an upper set 𝑃 of 𝑀 such that 𝐿 = ℎ−1(𝑃). The ordered
syntactic monoid of 𝐿 is the smallest ordered monoid that
recognizes 𝐿; it is finite iff 𝐿 is regular, in which case it is
unique.1

Logic. We work with first-order logics recognizing lan-

guages. For instance, the formula over the alphabet {𝑎, 𝑏}

(∀𝑥)(∃𝑦) [mod2(𝑥) ∨ (𝑦 = 𝑥 + 1) ∧ (𝑎(𝑥) ↔ 𝑏 (𝑦))]

asserts that, in a given word 𝑤, for every position 𝑥 there is
another position 𝑦 such that either 𝑥 is divisible by 2 (mod2)
or 𝑦 is just after 𝑥 and 𝑤 has different letters at 𝑥 and 𝑦. The
predicates mod2 and +1 are examples of numerical predicates,
i.e., they only speak about the numerical positions, not the
contents of the input word. The predicates 𝑎(·) and 𝑏 (·) are
the letter predicates.

In this paper, first-order logics are specified by restricting

two aspects:

• The number of quantifier alternations. We write Σ2 for
the subset of first-order formulas that can be written
as (∃𝑥1, 𝑥2, . . .)(∀𝑦1, 𝑦2, . . .) [𝜙] with 𝜙 a quantifier-free
formula, that is, Σ2 is the set of formulas starting with
an existential quantifier and alternating once. In Sec-
tion 6.1, we will briefly mention Π2 (defined as Σ2 but
with ∃ and ∀ swapped) and Δ2, the set of formulas
that are equivalent to both a Σ2 and a Π2 formula (this
describes, a priori, fewer languages than Σ2 or Π2).
• The numerical predicates allowed. Except for a quick
detour in Section 6.1, we will only be using two sets:
<, that is, the sole order relation (e.g., Σ2 [<]) and arb
the set of all predicates (e.g., Σ2 [arb]). In the latter
set, there would be predicates asserting that two posi-
tions are coprime or that a position encodes an halting
Turing machine, there is no restriction whatsoever.

The language of a formula is the set of words that satisfy
it. We commonly identify a class of formulas with the class
of languages they recognize.

Languages of a syntactic ordered monoid. Let 𝑀 be
an ordered monoid. For any element 𝑥 ∈ 𝑀, the up-word
problem for 𝑀 and 𝑥 is the following language over 𝑀 seen
as an alphabet:

Lemma 2.1 (From [23, Lemma 5.6]). A regular language
with a neutral letter is in Σ2 [arb] iff all the up-word problems
for its ordered syntactic monoid are in Σ2 [arb].

Circuits. We will study languages computed by fami-
lies of constant-depth, polynomial-size circuits consisting of
unbounded fan-in ∧- and ∨-gates. A circuit with 𝑛 inputs
𝑥1, 𝑥2, . . . , 𝑥𝑛 in some alphabet 𝐴 can query whether any in-
put contains any given letter in 𝐴. The depth of the circuit is
the maximal number of gates appearing on a path from an
input to the output. A circuit family is an infinite set (𝐶𝑛)𝑛 ≥0
where the circuit 𝐶𝑛 has 𝑛 inputs and one output gate; a word
𝑤 is deemed accepted if the circuit 𝐶 |𝑤 | outputs 1 when 𝑤 is
placed as input. We identify classes of circuits with the class
of languages they recognize.

For a circuit 𝐶 we visualize the inputs on top and the
one output gate at the bottom.2 The top fan-in of 𝐶 is the
maximum fan-in of the gates that receive an input letter
directly. We say that 𝐶 is a ∃∀∃ circuit if it is layered with
a bottom OR gate with AND gates as inputs, each of these
having OR gates as inputs.

We let Σ2 be the class of families of ∃∀∃ circuits of
polynomial-size and constant top fan-in. In the literature,
this circuit family is also called ΣΠΣ(𝑘) in [10] and Σpoly,𝑘
2
in [9], where 𝑘 is the top fan-in. It is a subclass of AC0
3, the
class of polynomial-size, depth-3 circuits, a class we will
discuss in Section 6.2. The name “Σ2 circuit family” is all the
more justified that:

Lemma 2.2 (From [20, Proposition 11]). A language is rec-
ognized by a Σ2 [arb] formula iff it is recognized by a Σ2 circuit
family.

We will often exploit this equivalence without pointing at

this lemma.

A decidable characterization of Σ2 [<]. Let 𝑥, 𝑦 ∈ 𝑀;
we say that 𝑦 is a subword of 𝑥 if there are two words
𝑤𝑥, 𝑤𝑦 ∈ 𝑀 ∗ that evaluate, using 𝑀’s product, to 𝑥 and
𝑦, respectively, and 𝑤𝑦 is a subword of 𝑤𝑥 . The following is a
characterization of the languages in Σ2 [<] that is due to Pin
and Weil [22], and we use a version proposed by Bojańczyk:
Theorem 2.3 (From [6]). A regular language is in Σ2 [<] iff
its ordered syntactic monoid 𝑀 is such that for any 𝑥, 𝑦 ∈ 𝑀
such that 𝑥 is an idempotent3 and 𝑦 a subword of 𝑥, it holds
that

{𝑤 ∈ 𝑀 ∗ | 𝑤 evaluates in 𝑀 to an element ≥ 𝑥 }.

𝑥 ≤ 𝑥𝑦𝑥 .

In some precise sense, a regular language has the same com-
plexity as the hardest of the up-word problems for its ordered
syntactic monoid; in the case on Σ2 [arb], we can state:

1The ordered syntactic monoid is usually defined as the quotient of 𝐴∗ by
the so-called syntactic order induced by 𝐿; the definition proposed here is
equivalent [23, Corollary 4.4] and allows to introduce one fewer concept.

Equivalently, this could be worded over languages directly:
a regular language 𝐿 is in Σ2 [<] iff for any three words

2The literature has been flip-flopping between putting the inputs at the
bottom or at the top, with a semblance of stability for “top” achieved in the
late 90s. This explains that some references mention “bottom fan-in.”
3This is usually written by letting 𝑥 be any element, and considering 𝑥𝜔 ,
which is the unique idempotent that is a power of 𝑥; we simplify the pre-
sentation slightly by simply requiring 𝑥 to be an idempotent.

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

𝑤1, 𝑤2, 𝑤3 that map to the same idempotent in 𝑀 and 𝑣 a
subword of 𝑤2, if a word 𝑤0 · 𝑤1𝑤2𝑤3 · 𝑤4 is in 𝐿, for some
words 𝑤0, 𝑤4, then so is 𝑤0 · 𝑤1𝑣𝑤3 · 𝑤4. We will allude to
this wording in some proofs in the Consequences section
(Section 6.2).

Corollary 3.3. Let 𝐿 be a language and write 𝐿𝑛 for the subset
of words of length 𝑛 in 𝐿. Assume that for any 𝑘, 𝑑 ∈ N, there
is an 𝑛 ∈ N and a subset 𝐿′ ⊆ 𝐿𝑛 such that every subset 𝐹 ⊆ 𝐿′
of size at least |𝐿′|/𝑛𝑑 admits a 𝑘-limit outside of 𝐿. Then 𝐿 is
not in Σ2 [arb].

3 Limits and lower bounds against Σ2 [arb]
We present a tool that has been used several times to show
lower bounds against depth-3 circuits, in particular in [14].
The following definition is attributed to Sipser therein:
Definition 3.1 (From [27]). Let 𝐹 be a set of words, all of
same length 𝑛, and 𝑘 > 0. A 𝑘-limit for 𝐹 is a word 𝑢 of
length 𝑛 such that for any set of 𝑘 positions, a word in 𝐹
matches 𝑢 on all these positions. In symbols, 𝑢 satisfies:

(∀𝑃 ⊆ [𝑛].|𝑃 | = 𝑘)(∃𝑣 ∈ 𝐹 )(∀𝑝 ∈ 𝑃) (cid:2)𝑢𝑝 = 𝑣𝑝 (cid:3) .
Naturally, we will be interested in 𝑘-limits that fall out-
side of 𝐹 , otherwise finding 𝑘-limits is trivial. In fact, we
will consider sets 𝐹 that are included in a subset of a target
language, and find 𝑘-limits outside of the target language
itself. We include a short proof of the following statement
for completeness and because it makes the statement itself
more readily understandable.
Lemma 3.2 (From [14, Lemma 2.2]). Let 𝐿 be a set of words
all of same length 𝑛 and 𝐶 be a ∃∀∃ circuit that accepts at
least all the words of 𝐿. Let 𝑘 be the top fan-in of 𝐶 and 𝑠 its
size.

Assume there is a subset 𝐿′ ⊆ 𝐿 such that for any 𝐹 ⊆ 𝐿′ of
size at least |𝐿′|/𝑠 there is a 𝑘-limit for 𝐹 that does not belong
to 𝐿. Then 𝐶 accepts a word outside of 𝐿. The hypothesis can
be represented graphically as:

𝐿

∃𝐿′

∀𝐹
|𝐹 | ≥ |𝐿′|/𝑠

∃𝑢
𝑘-lim. for 𝐹

Proof. At the bottom of 𝐶, we have an OR gate of fan-in
at most 𝑠 that receives the result of some AND gates. By
counting, one of these AND gates should accept a subset 𝐹
of 𝐿′ of size at least |𝐿′|/𝑠; we will now focus on that gate. Let
𝑢 ∉ 𝐿 be the 𝑘-limit for 𝐹 that exists by hypothesis. Consider
an OR gate that feeds into the AND gate under consideration.
This OR gate checks the contents of a subset 𝑃 ⊆ [𝑛] of 𝑘
positions of the input. By hypothesis, there is a word 𝑣 in 𝐹
that matches 𝑢 on all the positions in 𝑃, hence the OR gate
cannot distinguish between 𝑢 and 𝑣 and must output 1 (true)
as 𝑣 must be accepted. This holds for all the OR gates feeding
into the AND gate under consideration, hence the AND gate
□
must accept 𝑢, and so does 𝐶.

Proof. For a contradiction, assume there is a Σ2 circuit family
for 𝐿, with top fan-in 𝑘 and size 𝑛𝑑 . Let 𝑛 be the value pro-
vided by the hypothesis, then the circuit 𝐶 for 𝐿𝑛 satisfies the
hypotheses of Lemma 3.2, hence 𝐶 accepts a word outside
□
of 𝐿, a contradiction.

4 Warm-up: 𝐾 = (𝑎𝑐∗𝑏 + 𝑐)∗ ∉ Σ2 [arb]
In this section, we follow the approach of Håstad, Jukna, and
Pudlák [14] to show the claim of the section title. We present
it in a specific way that will help us stress the commonality
and the differences of this approach with our main proof.

To show the claim of the section title, we consider a
slightly different language. For any 𝑛 that is a perfect square,
we let Good𝑛 be the set of words of length 𝑛 over {𝑎, 𝑏} of
the following shape:

𝑛

𝑏 · · · 𝑏𝑎𝑏 · · · 𝑏

. . .

𝑏 · · · 𝑏𝑎𝑏 · · · 𝑏

√
𝑛

√
𝑛

In words, a word is in Good𝑛 if it can be decomposed into
√
𝑛, such that each of them has exactly

𝑛 blocks of length

√

one 𝑎. We let Good = (cid:208)𝑛 Good𝑛.

Lemma 4.1. If 𝐾 is in Σ2 [arb], then so is Good.

√

Proof. This is easier to see on circuits, so assume there is a
Σ2 circuit family for 𝐾. For 𝑛 a perfect square, we design a
circuit for Good𝑛. On any input, we convert the 𝑏’s to 𝑐’s and
insert a 𝑏 every
𝑛 positions; we call this the expansion of the
input word. For instance, with 𝑛 = 9, the input 𝑎𝑏𝑏 𝑏𝑎𝑏 𝑏𝑏𝑎
is expanded to 𝑎𝑐𝑐𝑏 𝑐𝑎𝑐𝑏 𝑐𝑐𝑎𝑏. Clearly, if the input word is
in Good𝑛, then its expansion is in 𝐾. Conversely, if a block
of the input had two 𝑎’s, the expansion will not add a 𝑏 in
between, so the expansion is not in 𝐾; similarly, if a block of
the input contains only 𝑏’s, it will be expanded to only 𝑐’s
sandwiched between two 𝑏’s, and the expansion will not be
in 𝐾 (in the case where the block containing only 𝑏’s is the
first one, the expansion starts with 𝑐 · · · 𝑐𝑏, again putting the
expansion outside of 𝐾).

Thus a circuit for Good𝑛 can be constructed by computing
the expansion (this only requires wires and no gates), then
feeding that expansion to a circuit for 𝐾. If the circuit family
for 𝐾 were in Σ2, so would the circuit family for Good. □

We use Corollary 3.3 to show that Good ∉ Σ2 [arb]. Let
then 𝑘, 𝑑 ∈ N. The value of 𝐿′ in Corollary 3.3 will simply be
Good𝑛, and we show:

The Regular Languages of First-Order Logic with One Alternation

Lemma 4.2. If 𝑛 is large enough, any subset 𝐹 ⊆ Good𝑛
√
𝑛 has a 𝑘-limit outside of Good𝑛. This holds in
with |𝐹 | > 𝑘
particular if |𝐹 | ≥ |Good𝑛 |/𝑛𝑑 .

Proof. We rely on the Flower Lemma, a combinatorial lemma
that is a relaxation of the traditional Sunflower Lemma. We
first need to introduce some vocabulary.

We consider families F containing sets of size 𝑠 for some 𝑠.
The core of the family is the set 𝑌 = (cid:209)𝑆 ∈ F 𝑆. The coreless
version of F is the family F𝑌 = {𝑆 \ 𝑌 | 𝑆 ∈ F }. A set 𝑆
intersects a family F if all the sets of F have a nonempty
intersection with 𝑆. Finally, a flower with 𝑝 petals is a family
F of size 𝑝 with core 𝑌 such that any set which intersects
F𝑌 is of size at least 𝑝.
Lemma 4.3 (Flower Lemma [16, Lemma 6.4]). Let F be
a family containing sets of cardinality 𝑠 and 𝑝 ≥ 1 be an
integer. If |F | > (𝑝 − 1)𝑠 , then there is a subfamily F ′ ⊆ F
that is a flower with 𝑝 petals.
To apply this lemma, consider the mapping 𝜏 from words
in Good𝑛 to 2[𝑛] that lists all the positions where a word
has an 𝑎. For instance, with 𝑛 = 9, 𝜏 (𝑏𝑏𝑎 𝑎𝑏𝑏 𝑏𝑎𝑏) = {3, 4, 8}.
𝑛. We let F =
For any word 𝑤 in Good𝑛, 𝜏 (𝑤) is of size
{𝜏 (𝑤) | 𝑤 ∈ 𝐹 }.
√

We now apply the lemma with 𝑠 =

𝑛 and 𝑝 = 𝑘 + 1.
Since |F | = |𝐹 |, we can apply the lemma on F and obtain a
subfamily F ′ that is a flower with 𝑘 + 1 petals. Let 𝑌 be its
core. Consider the word 𝑢 of length 𝑛 over {𝑎, 𝑏} which has
𝑎’s exactly at the positions in 𝑌 . Then:

√

√
√

• 𝑢 is outside of Good𝑛. Indeed, |𝑌 | <
𝑛, since it is the
𝑛. Hence one of
intersection of distinct sets of size
the blocks of 𝑢 will contain only 𝑏’s, putting it outside
of Good𝑛.

• 𝑢 is a 𝑘-limit. Let 𝑃 be a set of 𝑘 positions, we will
find a word that is mapped to F ′ that matches 𝑢 on
𝑃. If a position in 𝑃 points to an 𝑎 in 𝑢, then every
word in F ′ has an 𝑎 at that position (by construction,
since this position would belong to the core 𝑌 ). So we
assume that 𝑃 contains only positions on which 𝑢 is
𝑏. Since |𝑃 | is 𝑘, it cannot intersect F ′, hence there is
a set 𝑆 ∈ F ′ such that 𝑆 ∩ 𝑃 = ∅. The set 𝑆 is thus
𝜏 (𝑤) for a word 𝑤 ∈ 𝐹 that has a 𝑏 on all positions in
𝑃. This word 𝑤 thus matches 𝑢 on 𝑃, concluding the
proof of the main statement.

The “in particular” part is implied by the fact that, for 𝑛

large enough:

|Good𝑛 |
𝑛𝑑

=

√

𝑛

√
𝑛
𝑛𝑑 ≥ 𝑘

√
𝑛.

□

Theorem 4.4. The language 𝐾 = (𝑎𝑐∗𝑏+𝑐)∗ is not in Σ2 [arb].
Proof. Corollary 3.3 applied on Good, using Lemma 4.2, im-
plies that Good ∉ Σ2 [arb]. Lemma 4.1 then asserts that 𝐾
□
cannot be in Σ2 [arb] either.

5 The regular languages with a neutral
letter not in Σ2 [<] are not in Σ2 [arb]
The proof of the statement of the section title is along two
main steps:

Section 5.1. We will start with a language with a neutral
letter 𝐿 ∉ Σ2 [<]. Since it is not in Σ2 [<], there are 𝑥, 𝑦 ∈ 𝑀
that falsify the equations of Theorem 2.3. We use these wit-
nesses to build a up-word problem 𝑇 of the ordered syntactic
monoid of 𝐿 and show that it lies outside of Σ2 [arb], implying
that 𝐿 ∉ Σ2 [arb] by Lemma 2.1.

To show 𝑇 out of Σ2 [arb], we identify (Section 5.1.1) a
subset of well-behaved words of 𝑇 , and make some simple
syntactical changes (in Section 5.1.2) on them so that they
look like words in Good, in a similar fashion as the “expan-
sions” of Lemma 4.1. The argument used in Lemma 4.1 then
needs to be refined, as we do not have that any word outside
of Good comes from a word outside of 𝑇 . We will define a
set Bad of words that look like words in Good except for
one block that contains only 𝑏’s; Lemma 4.1 is then worded
as: if 𝐾 is in Σ2 [arb], then there is a Σ2 [arb] language that
separates Good from Bad (Lemma 5.1).

√

𝑛]

Section 5.2. We show that no language of Σ2 [arb] can
separate Good from Bad. We thus need to provide a state-
ment in the spirit of Lemma 4.2. We first write good and bad
√
𝑛, the
words in a succinct (“packed”) way, as words in [
𝑖-th letter being some value 𝑣 if the original word had the 𝑎 of
its 𝑖-th block in position 𝑣 (Section 5.2.1). We then translate
the notion of 𝑘-limit to packed words (Lemma 5.3). Finally,
we provide a measure of how diverse a set of (packed) good
words is (Definition 5.4), and show that such a set is either
not diverse and small (Lemma 5.5), or diverse and admits
a 𝑘-limit (Lemma 5.6). Our term for “not diverse” will be
tangled, referring to the fact that there is a strong correlation
between the contents of positions within words.

5.1 If a language not in Σ2 [<] is in Σ2 [arb], we can
separate Good from Bad with a language in
Σ2 [arb]

5.1.1 Target up-word problem and some of its words.
For the rest of this section, let 𝐿 ⊆ 𝐴∗ be a regular language
with a neutral letter that lies outside of Σ2 [<] and let 𝑀 be its
ordered syntactic monoid. Since 𝐿 is not in Σ2 [<], there are
elements 𝑥, 𝑦 ∈ 𝑀 such that 𝑥 ≰ 𝑥𝑦𝑥 with 𝑥 an idempotent
and 𝑦 a subword of 𝑥. Let 𝑇 be the up-word problem of 𝑀
for 𝑥. Clearly, any word of 𝑀 ∗ that evaluates to 𝑥𝑦𝑥 does not
belong to 𝑇 .

Naturally, 𝑦 is thus also a subword of 𝑥; this provides us

with words that evaluate to 𝑥 and 𝑦 of the shape:

𝑥1𝑦1 . . . 𝑥𝑡𝑦𝑡 evaluates to 𝑥,

𝑦1 . . . 𝑦𝑡 evaluates to 𝑦,

with each 𝑥𝑖 and 𝑦𝑖 in 𝑀. (Note that we can use the identity
element of 𝑀 as needed to ensure we have as many 𝑥𝑖 ’s as
𝑦𝑖 ’s.)

Let 𝑛 ∈ N be a large enough perfect square (“large enough”
only depends on 𝑡, the length of the word for 𝑦). We define
√

√

𝑛 + 1 words of length

𝑛 + 𝑡 over 𝑀:

√

𝑛],

• For 𝑖 ∈ [
(cid:16)

𝑥 (𝑖) =

𝑖−1𝑥11
1

√
𝑛−𝑖 · 𝑦1

(cid:17)

(cid:16)

𝑖−1𝑥𝑡 1
1

√
𝑛−𝑖 · 𝑦𝑡

(cid:17)

.

· · ·

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

would turn into:
√
(cid:16)
𝑛−8 · 𝑦1

17𝑥11

(cid:17)

(cid:16)

· · ·

17𝑥𝑡 1

√
𝑛−8 · 𝑦𝑡

(cid:17)

= 𝑥 (8) .

In particular, if the block were all 𝑏’s, we would obtain the
word 𝑦, which has no letter 𝑥 𝑗 .

We can do this to each block of

𝑛 letters, concatenate
the resulting words, then add the word 𝑥 (1) at the beginning
and the end. Note that these operations can be done with
only wires, with no gates involved.

√

Here 1 ∈ 𝑀 is the neutral element of 𝑀. Note that
these words evaluate to 𝑥.

• Additionally, we consider the word 1

√
√
𝑛𝑦𝑡 ,
𝑛𝑦1 . . . 1
which evaluates to 𝑦, and we simply write 𝑦 for it.
Note that 𝑦 can be obtained by removing all the letters
𝑥 𝑗 from any word 𝑥 (𝑖) .
Call 𝑇 -good a concatenation of

𝑛 words of the form 𝑥 (𝑖)
sandwiched between two words 𝑥 (1) (the 1 is arbitrary), and
𝑇 -bad a word obtained by changing, in a 𝑇 -good word, ex-
actly one of the words 𝑥 (𝑖) to 𝑦 (but for the 𝑥 (1) at the begin-
ning and end). By construction, any 𝑇 -good word evaluates
to 𝑥 in 𝑀, so belongs to 𝑇 , while any 𝑇 -bad word evaluates
to 𝑥𝑦𝑥, hence does not belong to 𝑇 . Note that if we had
switched two blocks of a 𝑇 -good word to 𝑦, we would not be
able to say whether it belonged to 𝑇 or not.

√

√

5.1.2 𝑇 -good, 𝑇 -bad to Good and Bad. The 𝑇 -good and
𝑇 -bad words contain a lot of redundant information, for
instance 𝑥 (𝑖) is of length
𝑛 + 𝑡, while all the information it
√
really contains is 𝑖 ∈ [
𝑛]. Recall the set Good𝑛 of Section 4
which contains all words of length 𝑛 over {𝑎, 𝑏} that can
𝑛, each containing a
be divided into
single 𝑎. Again, we let Good be all such words, of any perfect
square length. Define similarly Bad𝑛 as the set of words that
are like Good𝑛 except for one block which has only 𝑏’s, and
let Bad = (cid:208)𝑛 Bad𝑛.

𝑛 blocks of length

√

√

In the next lemma, we show that we can modify, using
only wires in a circuit, words over {𝑎, 𝑏} so that if they are
in Good they become 𝑇 -good, and if they are in Bad they
become 𝑇 -bad. This modification is simple enough that we
can take a Σ2 [arb] circuit family for𝑇 , apply the modification
at the top of each circuit, and still have a circuit family in
Σ2 [arb]; the resulting circuit family separates Good from
Bad:

Lemma 5.1. If 𝑇 ∈ Σ2 [arb], then there is a Σ2 [arb] language
that separates Good from Bad.

Proof. As in Lemma 4.1, this is easier seen on circuits: we de-
sign a circuit for inputs of length 𝑛 over {𝑎, 𝑏} that separates
Good from Bad.

Consider the first block of

𝑛 letters of the input. We
replicate it 𝑡 times, with the 𝑖-th replication changing 𝑏’s to 1
and 𝑎’s to 𝑥𝑖 . We then concatenate these and add 𝑦𝑖 between
𝑛−8
the 𝑖-th and (𝑖 + 1)-th replication. For instance, 𝑏7𝑎𝑏

√

√

If the input word is in Good, then the word produced is
𝑇 -good, hence in 𝑇 . If it was in Bad, then the resulting word
would be 𝑇 -bad, hence would lie outside of 𝑇 . This shows
that the desired circuit can be constructed using the above
wiring followed by the circuit for 𝑇 for inputs of length
(𝑡
𝑛). Since 𝑡 is a constant and depends solely
on 𝐿, the resulting circuit is of polynomial size and of the
□
correct shape.

𝑛 + 𝑡)(2 +

√

√

5.2 No language in Σ2 [arb] separates Good from Bad
Note that this section is independent from the previous one.
We will now rely on Corollary 3.3 to show that any Σ2 [arb]
language 𝐿 that accepts all of Good must accept a word in
Bad. To apply Corollary 3.3, from this point onward we let
𝑘, 𝑑 ∈ N, and set 𝑛 to be a large enough value that depends
only on 𝑘 and 𝑑. The role of 𝐿′ in the statement of Corol-
lary 3.3 will be played by Good𝑛 and we will build 𝑘-limits
belonging to Bad𝑛, which we call bad 𝑘-limits. The reader
may check that the statements of the forthcoming Lemma 5.5
and Lemma 5.6 conclude the proof.

√

𝑛. We make this explicit, by seeing [

5.2.1 Packed words. Words in Good𝑛 and Bad𝑛 can be
described by the position of the letter 𝑎 in each block of size
√
√
𝑛] ∪{⊥} as
√
𝑛. We call
an alphabet, and working with words in [
these words packed and will use Greek letters 𝜆, 𝜇, 𝜈 for them;
we also call the letter at some position in packed words its
contents at this position, only to stress that we are working
with packed words. We define the natural functions to pack
and unpack words:
√

𝑛, ⊥] = [
√
𝑛, ⊥]

• unpack : [
⊥ to 𝑏

𝑛, ⊥] → {𝑎, 𝑏}

√
𝑛 maps 𝑖 to 𝑏𝑖−1𝑎𝑏

√
𝑛. This extends naturally to words over [

√
𝑛−𝑖 and
√
𝑛, ⊥].
𝑛, ⊥]∗ is the inverse of unpack. We
will use that function on sets of words too, with the
natural meaning.

• pack : {𝑎, 𝑏}∗ → [

√

Example 5.2. With 𝑛 = 9, pack(𝑎𝑏𝑏 𝑏𝑏𝑏 𝑏𝑎𝑏) = 1⊥2, and
unpack(31⊥) = 𝑏𝑏𝑎 𝑎𝑏𝑏 𝑏𝑏𝑏.

We can now rephrase the notion of 𝑘-limit using packed

words:

Lemma 5.3. Let 𝐹 ⊆ Good𝑛 and define Φ = pack(𝐹 ). If 𝜇 is a
packed word that has the following properties, then unpack(𝜇)
is a bad 𝑘-limit for 𝐹 :

The Regular Languages of First-Order Logic with One Alternation

1. There is a word 𝜈 ∈ Φ that differs on a single position 𝑖

with 𝜇, at which 𝜇 has contents ⊥:

𝜇𝑖 = ⊥ ∧ (∀𝑗 ≠ 𝑖) [𝜈 𝑗 = 𝜇 𝑗 ].

√
𝑛] of contents that contains 𝜈𝑖
2. For every set 𝐶 ⊆ [
√
and every set 𝑃 ⊆ [
𝑛] \ {𝑖} of positions such that
|𝐶 | + |𝑃 | = 𝑘, there is a word 𝜆 ∈ Φ whose contents at
position 𝑖 is not in 𝐶 and that matches 𝜈 on 𝑃:

𝜆𝑖 ∉ 𝐶 ∧ (∀𝑝 ∈ 𝑃) [𝜆𝑝 = 𝜈𝑝 ].

of 𝐷; additionally, the position 𝑖 should not appear in 𝑆:

((cid:154)𝑐) [(𝑖, 𝑐) ∈ 𝑆]∧
(∀𝜇 ∈ Φ) [(∀( 𝑗, 𝑑) ∈ 𝑆) [𝜇 𝑗 = 𝑑] →

(∃(𝑖, 𝑐) ∈ 𝐷) [𝜇𝑖 = 𝑐]].

√

The set 𝐹 is said to be 𝑘-tangled if for any word 𝜇 ∈ Φ and
any position 𝑖 ∈ [
𝑛], there is an 𝑖-set of pairs of size ≤ 𝑘
that contains (𝑖, 𝜇𝑖 ) and that is entailed by a set of size 𝑘 that
agrees with 𝜇. In other words, every position of 𝜇 is entailed
by a subset of its positions. We drop the 𝑘 in 𝑘-tangled if it
is clear from context.

Proof. Write 𝑢 for unpack(𝜇). That 𝑢 ∈ Bad is immediate
from Property 1: 𝑢 is but a word 𝑣 of Good in which one
block was set to all 𝑏’s.

We now show that 𝑢 is a 𝑘-limit. Let 𝑇 be a set of 𝑘 posi-

tions, we split 𝑇 into two sets:

• 𝑇 ′ is the set of positions that do not belong to the 𝑖-th
𝑛⌉ = 𝑖. We
𝑛, that

block of 𝑢, that is, they do not satisfy ⌈𝑝/
let 𝑃 be each of the elements of 𝑇 ′ divided by
is, for any 𝑝 ∈ 𝑇 ′ we add ⌈𝑝/

𝑛⌉ to 𝑃.

√

√

√

• 𝑇 ′′ is the set of positions that do fall in the 𝑖-th block.
Note that 𝑢 only has 𝑏’s at the positions of 𝑇 ′′. We let
𝑛, that is, for any 𝑝 ∈ 𝑇 ′′, we
𝐶 be that set, modulo
√
𝑛 if this value is 0.
𝑛 to 𝐶 or
add 𝑝 mod

√
√

First, if 𝜇𝑖 ∉ 𝐶, then 𝑇 indicates positions of 𝑢 that have
the same letter as in unpack(𝜈) ∈ 𝐹 , so a word of 𝐹 matches
𝑢 over 𝑇 , as required. We thus assume next that 𝜇𝑖 ∈ 𝐶.

Let 𝜆 ∈ Φ be the word given by Property 2 for 𝐶 and 𝑃,
we claim that 𝑤 = unpack(𝜆) matches 𝑢 on the positions of
𝑇 , concluding the proof.

First note that the 𝑖-th block of 𝑤 has its 𝑎 in a position
that is not in 𝑇 ′′, hence 𝑤 matches 𝑢 on 𝑇 ′′. Consider next
any position 𝑝 ∈ 𝑇 ′ and write 𝑗 for the block in which 𝑝 falls
𝑛⌉). Since 𝜇 𝑗 = 𝜆 𝑗 by hypothesis, the 𝑗-th block
(i.e., 𝑗 = ⌈𝑝/
□
of 𝑢 and 𝑤 are the same, hence 𝑢𝑝 = 𝑤𝑝 .

√

5.2.2 Tangled sets of good words are small, nontan-
gled ones have a bad 𝑘-limit. Consider a 𝐹 ⊆ Good𝑛. To
find a bad 𝑘-limit for 𝐹 , we need a lot of diversity in 𝐹 ; see in
particular Prop. 2 of Lemma 5.3. Hence having some given
contents at a given position in a word of Φ should not force
too many other positions to have a specific value. We make
this notion formal:

Definition 5.4. Let 𝐹 ⊆ Good𝑛 and Φ = pack(𝐹 ). The en-
tailment relation of Φ is relating sets of pairs (𝑖, 𝑐) of posi-
tion/contents in words of Φ. Let us say that a word and a
pair position/contents (𝑖, 𝑐) agree if the contents at position
𝑖 of the word is 𝑐, and that a word and a set of such pairs
agree if they agree on all the pairs. We say that a set of pairs
is an 𝑖-set if all its pairs have 𝑖 as position.

A set 𝑆 of pairs position/contents entails an 𝑖-set 𝐷 if all
words in Φ that agree with 𝑆 also agree with at least one pair

√

𝑛2𝑘

𝑛/(2𝑘+1)

Lemma 5.5. Let 𝐹 ⊆ Good𝑛. If 𝐹 is 𝑘-tangled, then |𝐹 | <
√
. In particular, |𝐹 | < |Good𝑛 |/𝑛𝑑 .
Proof. Assume 𝐹 is 𝑘-tangled and let Φ = pack(𝐹 ). We show
that every word in Φ can be fully described in Φ by fully
specifying a portion 𝑘/(𝑘 + 1) of its positions and encoding
the contents of each of the other 1/(𝑘 + 1) positions with
elements from [𝑘]. That is, if two words in Φ have the same
such description, they are the same, hence Φ cannot be larger
than the number of such descriptions. We first show this
property, then derive the numerical implication on |𝐹 |.

Let 𝜇 ∈ Φ, we construct iteratively a set 𝐾 of positions
that we will fully specify and a set 𝐾 + of positions that are
restricted when setting the positions in 𝐾.

First consider the pair (1, 𝜇1). Since 𝐹 is tangled, there is
an 1-set containing (1, 𝜇1), entailed by a set 𝑆 that agrees
with 𝜇. We add to 𝐾 the positions of 𝑆 and to 𝐾 + the positions
of 𝑆 and position 1.

We now iterate this process: Take a pair (𝑖, 𝜇𝑖 ) such that
𝑖 ∉ 𝐾 +. There is an 𝑖-set containing (𝑖, 𝜇𝑖 ) that is entailed by
a set 𝑆 that agrees with 𝜇. Let 𝑆 ′ be the set of positions of 𝑆
that are not in 𝐾 +. We add 𝑆 ′ to 𝐾, and 𝑆 ′ ∪ {𝑖} to 𝐾 +. Note
that the size increase for 𝐾 + is one more than that for 𝐾. We
continue iterating until all positions appear in 𝐾 +.

We now bound the size of 𝐾 at the end of the computa-
tion. For each iteration, in the worst case, we need to add
𝑘 positions to 𝐾 to obtain 𝑘 + 1 new positions in 𝐾 + (this is
the worst case in the sense that this is the worst ratio of the
number of positions we need to pick in 𝐾 to the number of
positions that are put in 𝐾 +). In that case, after 𝑠 steps, we
have |𝐾 | = 𝑠𝑘 and |𝐾 +| = 𝑠𝑘 + 𝑠. Thus when |𝐾 +| =
𝑛, that
is, when no more iterations are possible, we have:

√

√

𝑛 ⇒ 𝑠 =

√
𝑛
𝑘 + 1

.

𝑠𝑘 + 𝑠 =
√

This shows that |𝐾 | ≤ 𝑘

𝑛/(𝑘 + 1).
We now turn to describing the word 𝜇 using 𝐾. We first
provide all the contents of 𝜇 at positions in 𝐾; call 𝑍 the set
of pairs position/contents of 𝜇 that correspond to positions
in 𝐾. We mark the positions of 𝐾 as specified, and carry on
to specify the other positions in a deterministic fashion.

We first fix an arbitrary order on sets of pairs of posi-
tion/contents. We iterate through all the subsets of 𝑍 of size

𝑘, in order. For each such subset 𝑆, we consider, in order again,
the subsets 𝐷 that are entailed by 𝑆. Assume 𝐷 is an 𝑖-set; if
position 𝑖 is already specified, we do nothing, otherwise, we
describe which element of 𝐷 is (𝑖, 𝜇𝑖 ) using an integer in [𝑘],
and mark 𝑖 as specified. We proceed until all the subsets of
𝑍 have been seen, at which point, by construction of 𝐾, all
the positions will have been specified. As claimed, given 𝑍
and the description of which elements in sets 𝐷 correspond
to the correct contents, we can reconstruct 𝜇.

√

√

√

√

𝑛𝑘

Summing up, to fully describe 𝜇, we had to specify the
𝑛
(cid:1) possible choices), their
𝑛/(𝑘+1)

positions of 𝐾 (one of (cid:0)
𝑘
𝑛/(𝑘+1)

contents (one of
possible choices), and for each
position not specified by 𝐾, we needed to provide an integer
√
𝑛/(𝑘+1) possible choices). This shows that:
in [𝑘] (one of 𝑘
√
𝑛
𝑛/(𝑘 + 1)
√

√
𝑛𝑘

|𝐹 | ≤

𝑛/(𝑘+1)

𝑛/(𝑘+1)

· 𝑘

√

√

√

√

(cid:19)

(cid:18)

·

𝑛/(𝑘+1)) log(𝑘)

𝑘
√
𝑛 · 2(
√
𝑛/(𝑘+1)) ( (𝑘+1)+𝑘 log

𝑛/(𝑘+1)) (𝑘 log

√
𝑛) · 2(
𝑛+log 𝑘)

√

𝑛/(𝑘+1)) ( (𝑘+ 1

𝑘 ) log

√

𝑛)

(n large enough)

√

𝑛/(𝑘+1)

√
𝑛2𝑘

√
𝑛/(2𝑘+1) .

≤

≤ 2
= 2(
≤ 2(
√
𝑛 (𝑘+ 1
𝑘 )

√

≤

The “in particular” part is a consequence of the fact that,

for 𝑛 large enough:

|Good𝑛 |
𝑛𝑑

=

√

𝑛

√
𝑛
𝑛𝑑 ≥

√
𝑛2𝑘

√
𝑛/(2𝑘+1) .

□

Lemma 5.6. Let 𝐹 ⊆ Good𝑛. If 𝐹 is not 𝑘-tangled, then 𝐹 has
a bad 𝑘-limit.

Proof. Write Φ = pack(𝐹 ). That 𝐹 is not tangled means that
there is a word 𝜈 ∈ Φ and a position 𝑖 such that for any set
of pairs position/contents 𝑆 and any 𝑖-set 𝐷 that contains
(𝑖, 𝜈𝑖 ), 𝑆 does not entail 𝐷. We define 𝜇 to be the word 𝜈 but
with 𝜇𝑖 set to ⊥. We show that unpack(𝜇) is a bad 𝑘-limit
using Lemma 5.3. Property 1 therein is true by construction,
so we need only show Property 2.

Let 𝐶 ⊆ [

𝑛] \ {𝑖} with
𝑛] with 𝜇𝑖 ∈ 𝐶 and 𝑃 ⊆ [
|𝐶 | + |𝑃 | = 𝑘. We add some more arbitrary positions in 𝑃 so
that |𝑃 | = 𝑘, avoiding 𝑖. Define:

√

√

𝑆 = {(𝑝, 𝜇𝑝 ) | 𝑝 ∈ 𝑃 }, 𝐷 = {(𝑖, 𝑐) | 𝑐 ∈ 𝐶}.
By hypothesis, since (𝑖, 𝜇𝑖 ) ∈ 𝐷, 𝑆 does not entail 𝐷. This
means that there is a word 𝜆 ∈ Φ such that 𝑆 and 𝜆 agree, but
𝜆𝑖 ∉ 𝐶. This is the word needed for Property 2 of Lemma 5.3,
□
concluding the proof.

Corollary 5.7. No Σ2 [arb] language can separate Good from
Bad.

Proof. We apply Corollary 3.3 on any language 𝐿 that sepa-
rates Good from Bad. We let 𝑘, 𝑑 ∈ N, and 𝑛 large enough;

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

𝐿′ in the statement of Corollary 3.3 is set to Good𝑛. We are
then given a set 𝐹 of size at least |Good𝑛 |/𝑛𝑑 and Lemma 5.5
shows that 𝐹 is not tangled. Lemma 5.6 then implies that 𝐹
has a bad 𝑘-limit. Corollary 3.3 concludes that 𝐺 is not in
□
Σ2 [arb], showing the statement.
Theorem 5.8 (Neutral Straubing Property for Σ2).

Σ2 [arb] ∩ Reg ∩ Neut ⊆ Σ2 [<].
Proof. Let 𝐿 ∉ Σ2 [<] with a neutral letter and 𝑇 be the lan-
guage defined in Section 5.1.1. Corollary 5.7 and Lemma 5.1
imply that 𝑇 cannot be in Σ2 [arb], and in turn, Lemma 2.1
□
shows that 𝐿 cannot be in Σ2 [arb].

6 Consequences
6.1 Life without neutral letters

The regular numerical predicates, denoted reg, are the numer-
ical predicates +1, <, and for any 𝑝 > 0, mod𝑝 which is true
of a position if it is divisible by 𝑝. The term “regular” stems
from the fact that these are the properties on numerical po-
sitions that automata can express. Recall that the Straubing
Property for a logic L expresses that L [arb] ∩Reg = L [reg].
The Straubing Property does not immediately imply the
Neutral Straubing Property; for this, one would need in ad-
dition that L [reg] ∩ Neut ⊆ L [<]. This latter property is
called the Crane Beach Property of L [reg], and also stems
from the natural idea that if a language has a neutral letter,
then numerical predicates do not provide any useful infor-
mation. Albeit natural, this property is false for FO[arb] [4],
but Theorem 5.8 shows that Σ2 [reg] does have the Crane
Beach Property.

Relying on Theorem 4.4 and some results from [8], we can

show:
Theorem 6.1 (Straubing Property of Δ2).
Δ2 [arb] ∩ Reg = Δ2 [reg].

Proof. The proof structure is as follows: We first show that
Δ2 [arb] ∩ Reg has some closure properties, so that it is a
so-called lm-variety. We then show that Δ2 [reg] recognizes
precisely all the regular languages definable with a first-order
formula with two variables that uses reg as numerical predi-
cates; that class of languages is denoted FO2 [reg]. We then
rely on the following lemma, where 𝐾 = (𝑎𝑐∗𝑏 + 𝑐)∗:

Lemma 6.2 (From [8, Lemma 8]). If an lm-variety of regu-
lar languages V satisfies:

FO2 [reg] ⊆ V ⊆ FO[arb] and 𝐾 ∉ V

then V = FO2 [reg].
Since Δ2 [arb] ∩ Reg satisfies the hypotheses, it is equal to
FO2 [reg] = Δ2 [reg], concluding the proof.

𝚫2[arb] ∩ Reg is an lm-variety. We ought to first define
lm-variety. If for a morphism ℎ : 𝐴∗ → 𝐵∗ there is a 𝑘 such
that ℎ(𝐴) ⊆ 𝐵𝑘 , we call ℎ an lm-morphism, where lm stands

The Regular Languages of First-Order Logic with One Alternation

for length-multiplying. Given a language 𝐿 and a letter 𝑎, the
left quotient of 𝐿 by 𝑎 is the set 𝑎−1𝐿 = {𝑣 | 𝑎𝑣 ∈ 𝐿}. The
right quotient 𝐿𝑎−1 is defined symmetrically. An lm-variety
of languages is a set of languages closed under the Boolean
operations, quotient, and inverse lm-morphisms.

Since Reg is an lm-variety of languages, it is sufficient to

show that Δ2 [arb] is too; this is not hard:

• Boolean operations: Both Σ2 [arb] and Π2 [arb] formu-
las are closed under Boolean OR and AND, hence the
classes of languages they recognize are closed under
union and intersection, and so is Δ2 [arb]. Also, since
the negation of a Σ2 [arb] formula is a Π2 [arb] formula,
and vice versa, Δ2 [arb] is closed under complement.
• Quotient: We show that Σ2 [arb] is closed under quo-
tient; the proof is the same for Π2 [arb], and this im-
plies that Δ2 [arb] is also closed under quotient. Let
𝐿 ∈ Σ2 [arb] and 𝑎 be a letter. Consider the circuit for
the words of length 𝑛 in 𝐿. We can hardwire the first
letter to 𝑎; the resulting circuit has 𝑛 −1 inputs, and rec-
ognizes a word 𝑤 iff 𝑎𝑤 ∈ 𝐿. The family thus obtained
recognizes 𝑎−1𝐿. The argument for right quotient is
similar.

• Lm-morphisms: Again, we show this holds for Σ2 [arb],
the proof for Π2 [arb] being similar, and these two
facts imply closure under lm-morphisms of Δ2 [arb].
Let 𝐿 ∈ Σ2 [arb] over the alphabet 𝐵 and ℎ be an lm-
morphism such that ℎ(𝐴) ⊆ 𝐵𝑘 for some 𝑘. Consider
the circuit for the words of 𝐿 of length 𝑘𝑛 for some 𝑛.
Given a word in 𝐴𝑛, we can use wires to map each input
letter 𝑎 ∈ 𝐴 to ℎ(𝑎), and we can feed the resulting word
to the circuit for 𝐿. A word 𝑤 ∈ 𝐴𝑛 is thus accepted
iff ℎ(𝑤) ∈ 𝐿, hence the circuit family thus defined
recognizes ℎ−1(𝐿).

𝚫2[reg] and FO2[reg] recognize the same languages.
We show the inclusion from left to right, the converse being
similar. We rely on the fact that FO2 [<, +1] = Δ2 [<, +1], a
result due to Thérien and Wilke [33, Theorem 7]. The rest
of our proof is fairly simple: we put the information given
by the mod𝑝 predicates within the alphabet, show that this
information is easily checked with one universal quantifier
if we have reg predicates, and that if the modular predicates
are put within the alphabet, the only required predicates
to express our Δ2 [reg] formula are < and +1. We then rely
on the equivalence of FO2 and Δ2 over these predicates to
conclude.

Formally, let 𝜙 ∈ Δ2 [reg] be a formula over the alphabet
𝐴. Let 𝑃 be the set of moduli used in 𝜙, that is, the predicate
mod𝑝 appears in 𝜙 iff 𝑝 ∈ 𝑃. The 𝑃-annotation of a word
𝑤 ∈ 𝐴∗ is the word in (𝐴 ∪ 2𝑃 )∗ that indicates, for each
position 𝑖, the set of moduli in 𝑃 that divide 𝑖. In other words,
the 𝑃-annotation of 𝑤 = 𝑤1𝑤2 · · · 𝑤𝑛, with each 𝑤𝑖 ∈ 𝐴, is

the word of length 𝑛 whose 𝑖-th letter is:

(cid:18)

𝑤𝑖
{𝑝 ∈ 𝑃 | 𝑝 divides 𝑖}

(cid:19)

∈ (𝐴 ∪ 2

𝑃 ).

Let W be the set of words in (𝐴∪2𝑃 )∗ that are 𝑃-annotations.
Then:

• W ∈ FO2 [reg] ∩ Δ2 [reg]. Indeed, a formula for W
need only assert that for all positions 𝑖, the 2𝑃 part
of the letter at position 𝑖 is exactly the set {𝑝 ∈ 𝑃 |
𝑝 divides 𝑖}. This can be written as a single universal
quantifier followed by a quantifier-free formula.
• There is a 𝜙 ′ ∈ Δ2 [<, +1] such that the words of W
that satisfy 𝜙 ′ are precisely the 𝑃-annotations of words
that satisfy 𝜙. The formula 𝜙 ′ is simply the formula 𝜙
in which each predicate mod𝑝 (𝑥) is replaced with the
property “𝑝 belongs to the 2𝑃 part of the letter at posi-
tion 𝑥,” which can be written as a simple disjunction.
If the input word is a 𝑃-annotation, mod𝑝 (𝑥) is indeed
equivalent to that property.

Since FO2 [<, +1] = Δ2 [<, +1], there is a formula 𝜓 of
FO2 [<, +1] that accepts the same language as 𝜙 ′. With 𝜓W
the FO2 [reg] formula for W, we conclude that 𝜓 ∧ 𝜓W is a
□
FO2 [reg] formula that is equivalent to 𝜙.

The proof of the previous statement hinged on the char-
acterization given by Lemma 6.2. To show the (nonneutral)
Straubing Property of Σ2 [arb], a similar statement will need
to be proved. To make the similarity more salient, we reword
Lemma 6.2 as the equivalent statement:

Lemma 6.3. If an lm-variety of regular languages V satisfies:
Δ2 [reg] ⊆ V ⊆ FO[arb] and V ∩ Neut ⊆ Δ2 [<].

then V = Δ2 [reg].

Proof. The second part of the proof of Theorem 6.1 shows
that FO2 [reg] = Δ2 [reg], while the same was already known
if < is the only available numerical predicate, so we can
freely swap FO2 for Δ2 in the statement of Lemma 6.2. We
need to show that the hypothesis V ∩ Neut ⊆ Δ2 [<] is
equivalent to 𝐾 ∉ V. For the left-to-right implication, it is
known [18] that 𝐾 ∉ FO2 [<] = Δ2 [<]. For the right-to-left
implication, we use the hypothesis that V ⊆ FO[arb]: [8,
Theorem 9] shows that V ⊆ FO[arb] and 𝐾 ∉ V implies that
V ⊆ FO2 [reg] and [8, Theorem 15] asserts that FO2 [reg] ∩
Neut ⊆ FO2 [<]. Hence V ∩ Neut ⊆ FO2 [<] and replacing
□
FO2 with Δ2 concludes the proof.

A positive lm-variety is defined just as lm-variety, but
without requiring closure under complement. The statement
we need for Σ2 thus reads:

Conjecture 6.4. If a positive lm-variety of regular languages
V satisfies:

Σ2 [reg] ⊆ V ⊆ FO[arb] and V ∩ Neut ⊆ Σ2 [<]

then V = FO2 [reg].

If the conjecture held, then using V = Σ2 [arb] ∩ Reg

would show the Straubing Property for Σ2 [arb].

6.2 On the fine structure of AC0
For this section, we use notations similar to [20] on circuit
complexity (these correspond to the classes BC0

𝑖 therein):

• AC0

𝑖 is the class of polynomial-size, depth-𝑘 Boolean
circuit families, where all the circuits in a family have
the same kind of output gate (AND or OR);

• (cid:100)AC0

𝑖 is defined similarly, the only difference being that
the input gates of the circuits are allowed to compute
any function of at most a constant number of positions
of the input string. This class is equivalent to Σ𝑖 [arb] ∪
Π𝑖 [arb] (the 𝑖 here is the number of quantifiers blocks,
so that there are 𝑖 − 1 alternations between ∃ and ∀).

The implied hierarchies interleave in a strict way:

AC0
1

⊊ (cid:100)AC0
1

⊊ AC0
2

⊊ · · ·

The strictness of the hierarchy was independently obtained
by [20] and [9], both relying on previous bounds by Hås-
tad [15], but with very different approaches. However, the
question of finding explicit languages that separate this hier-
archy is still open, to the best of our knowledge. We make
some modest progress towards this:

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

without changing membership to 𝐾 ′. Also, the word 𝑏𝑎 ap-
pears as a subword of (𝑎𝑏)2. However (𝑎𝑏)6 · 𝑏𝑏 ∈ 𝐾, but
(𝑎𝑏)2(𝑏𝑎)(𝑎𝑏)2 · 𝑏𝑏 ∉ 𝐾 ′, showing that 𝐾 ′ ∉ Σ2 [<].

If we assume that 𝐾 ′ ∈ Π2 [arb], we have to show that the
complement of 𝐾 ′ is not in Σ2 [<]. This time, we pick (𝑎𝑏)3
as the idempotent, and 𝑏𝑏𝑎 as the subword. Then (𝑎𝑏)9 ∉ 𝐾 ′
but (𝑎𝑏)3(𝑏𝑏𝑎)(𝑎𝑏)3 ∈ 𝐾 ′, hence the complement of 𝐾 ′ is
□
not in Σ2 [<].

The language 𝐾 itself appears very often in the literature
pertaining to the fine separation of small circuit classes [7,
18]. This is no surprise: The language is the first of the fam-
ily of bounded-depth Dyck languages. These are the well-
parenthesized expressions that nest no more than a fixed
value:

𝐷 (1)
1 = 𝐾 = (𝑎𝑐∗𝑏 + 𝑐)∗,
1 = (𝑎𝐷 (𝑖−1)
𝐷 (𝑖)
𝑏 + 𝑐)∗.

1

(Here, 𝑎 can be interpreted as “opening parenthesis” and 𝑏
as “closing.”)

Saliently, these languages separate the class Σ𝑖 [<] from
Σ𝑖+1 [<], with 𝐷 (𝑖)
1 belonging to the latter but not the for-
mer [7]. It is open whether these languages also separate the
Σ𝑖 [arb] hierarchy, and thus the AC0
𝑖 one. We can show that:

Theorem 6.5. The language 𝐾 ′ = 𝐾 ·𝑏𝑐∗𝑏 ·𝐴∗ is in AC0

3\ (cid:100)AC0
2.
It is easily seen that a word is in the

Proof. Upper bound.
language 𝐾 iff:

• Between every two 𝑎’s there is a 𝑏, and vice versa;
• The first (resp. last) nonneutral letter of the word is 𝑎

(resp. 𝑏).

Each of these statements can be written as an AND of ORs;
for the first one, it is easier seen on the complement: we have
an OR gate that selects two positions 𝑝1, 𝑝2 and checks that
there is an 𝑎 at both positions and only 𝑐’s in between. Thus
𝐾 can be written as an AND of these, and so 𝐾 has a circuit
of depth exactly 2.

To build a circuit for 𝐾 ′, we start with an OR gate that
selects two positions 𝑝1, 𝑝2, and checks with an AND gate
that they both contain a 𝑏 and that only 𝑐’s appear in between.
We add as input to that AND gate the inputs of the AND
gate for 𝐾 where the positions considered are restricted to
be smaller than 𝑝1. This thus correctly checks that the prefix
up to 𝑝1 is in 𝐾, and that it is followed by a word starting
with 𝑏𝑐∗𝑏.

Lower bound. If 𝐾 ′ ∈ (cid:100)AC0

2, then 𝐾 ′ is either in Σ2 [arb]

or Π2 [arb].

Assume 𝐾 ′ ∈ Σ2 [arb], then 𝐾 ′ ∈ Σ2 [<] by Theorem 5.8.
We show that 𝐾 ′ ∉ Σ2 [<] using the equations provided by
Theorem 2.3 with the wording appearing after the Theorem.
First, the word (𝑎𝑏)2 is mapped to an idempotent: if (𝑎𝑏)2
appears in a word, we can repeat it any number of times

Theorem 6.6. 𝐷 (2)

1 ∈ AC0

Proof. Upper bound.

.
3 \ (cid:154)AC0
2
It can be shown [7, Lemma 4+] that:

𝐷 (2)
1 = 𝐾𝑏𝐴∗ ∪ 𝐴∗𝑏𝑐∗𝑏𝐾𝑏𝐴∗ ∪ 𝐴∗𝑎𝐾 ∪ 𝐴∗𝑎𝐾𝑎𝑐∗𝑎𝐴∗.
We can use an OR gate to select the positions of the letters
𝑎, 𝑏 mentioned in that expression, and then either use an
AND gate to verify that only 𝑐’s appear between them, or
use the AND of ORs circuit for 𝐾 from the previous proof to
check that a word of 𝐾 appears between two positions.

Lower bound. We again use the wording appearing af-
ter Theorem 2.3. As in the previous proof, we need to show
that neither 𝐷 (2)
1 nor its complement are in Σ2 [<]. For the
language itself, we pick (𝑎𝑏)3 as the word mapping to an
idempotent and 𝑏𝑏𝑎 as the subword. We indeed have that
(𝑎𝑏)9 ∈ 𝐷 (2)
. For the comple-
1
ment, we pick (𝑎𝑏)2 as the word mapping to an idempotent
and 𝑎𝑎𝑏 as the subword; they satisfy (𝑎𝑏)6 · 𝑏 ∉ 𝐷 (2)
but
1
(𝑎𝑏)2(𝑎𝑎𝑏)(𝑎𝑏)2 · 𝑏 ∈ 𝐷 (2)
□
.
1

, but (𝑎𝑏)3(𝑏𝑏𝑎)(𝑎𝑏)3 ∉ 𝐷 (2)
1

7 Conclusion
We have shown the Neutral Straubing Property for Σ2:

Σ2 [arb] ∩ Reg ∩ Neut = Σ2 [<] ∩ Neut.
To do so, we developed a new lower bound technique against
circuits of depth 3 that relies on the entailment relation of
a language. This relation indicates how dependent the posi-
tions within a language are on one another. We believe that

The Regular Languages of First-Order Logic with One Alternation

this relation may be exploited to show Straubing Properties
at higher levels of the Σ𝑖 hierarchy.

Dropping the neutral-letter restriction from our main re-
sult is an interesting task. Although it would not imply a
much stronger statement in terms of circuits, it is still a stain
on the clean statement that is the Straubing Property. We
note that Conjecture 6.4 is implied by the so-called locality
property of the algebraic counterpart of Σ2 [<]; showing lo-
cality is a notoriously hard problem in algebraic language
theory (see, e.g., [1, 28, 32, 34]).

Showing Straubing Properties remains a challenging and
wide open problem. If we are to follow our approach for Σ𝑖 ,
𝑖 ≥ 3, it requires in particular a decidable characterization
of the form of Theorem 2.3. This is usually provided by an
equational characterization of the class, and although the
general shape of the equations for each Σ𝑖 [<] is known [25,
Theorem 6.2], they do not readily imply decidability; in fact,
the decidability of Σ𝑖 [<] for 𝑖 ≥ 5 is open [24].

An outstanding example of the connection between the
Straubing Property of a circuit class and its computational
power is given in [8, 18]: FO2 [arb] has the Straubing Prop-
erty if and only if addition cannot be computed with a lin-
ear number of gates. This latter question, pertaining to the
precise complexity of addition, was asked, in particular, by
Furst, Saxe, and Sipser [11, Section 5]. Note that even though
Δ2 [reg] = FO2 [reg], this is not known to hold for the set of
arbitrary numerical predicates.

Acknowledgments
We wish to thank Nikhil Balaji and Sébastien Tavenas. The
last author acknowledges financial support by the DFG grant
ZE 1235/2-1.

References
[1] Jorge Almeida. 1996. A Syntactical Proof of Locality of da.

Int.
https://doi.org/10.1142/

J. Algebra Comput. 6, 2 (1996), 165–178.
S021819679600009X

[2] David A. Mix Barrington. 1989. Bounded-Width Polynomial-Size
Branching Programs Recognize Exactly Those Languages in NC1. J.
Comput. Syst. Sci. 38, 1 (1989), 150–164. https://doi.org/10.1016/0022-
0000(89)90037-8

[3] David A. Mix Barrington, Kevin J. Compton, Howard Straubing, and
Denis Thérien. 1992. Regular Languages in NC1. J. Comput. Syst. Sci.
44, 3 (1992), 478–499. https://doi.org/10.1016/0022-0000(92)90014-A
[4] David A. Mix Barrington, Neil Immerman, Clemens Lautemann, Nicole
Schweikardt, and Denis Thérien. 2005. First-order expressibility of
languages with neutral letters or: The Crane Beach conjecture. J.
Comput. Syst. Sci. 70, 2 (2005), 101–127. https://doi.org/10.1016/j.jcss.
2004.07.004

[5] David A. Mix Barrington and Denis Thérien. 1988. Finite monoids
and the fine structure of NC1. J. ACM 35, 4 (1988), 941–952. https:
//doi.org/10.1145/48014.63138

[6] Mikolaj Bojanczyk. 2009. Factorization Forests. In Developments in
Language Theory, 13th International Conference, DLT 2009, Stuttgart,
Germany, June 30 - July 3, 2009. Proceedings (Lecture Notes in Computer
Science, Vol. 5583), Volker Diekert and Dirk Nowotka (Eds.). Springer,
1–17. https://doi.org/10.1007/978-3-642-02737-6_1

[7] Janusz A. Brzozowski and Robert Knast. 1978. The Dot-Depth Hierar-
chy of Star-Free Languages is Infinite. J. Comput. Syst. Sci. 16, 1 (1978),
37–55. https://doi.org/10.1016/0022-0000(78)90049-1

[8] Michaël Cadilhac and Charles Paperman. 2021. The Regular Languages
of Wire Linear AC0. (Dec. 2021). https://hal.archives-ouvertes.fr/hal-
03466451 Submitted to Acta Informatica, special issue for the 70th
birthday of Klaus-Jörn Lange.

[9] Liming Cai, Jianer Chen, and Johan Håstad. 1998. Circuit Bottom Fan-
In and Computational Power. SIAM J. Comput. 27, 2 (1998), 341–355.
https://doi.org/10.1137/S0097539795282432

[10] Ning Ding, Yanli Ren, and Dawu Gu. 2017. PAC Learning Depth-
3 AC0 Circuits of Bounded Top Fanin. In International Conference
on Algorithmic Learning Theory, ALT 2017, 15-17 October 2017, Kyoto
University, Kyoto, Japan (Proceedings of Machine Learning Research,
Vol. 76), Steve Hanneke and Lev Reyzin (Eds.). PMLR, 667–680. http:
//proceedings.mlr.press/v76/ding17a.html

[11] Merrick L. Furst, James B. Saxe, and Michael Sipser. 1984. Parity,
Circuits, and the Polynomial-Time Hierarchy. Math. Syst. Theory 17, 1
(1984), 13–27. https://doi.org/10.1007/BF01744431

[12] Nathan Grosshans, Pierre McKenzie, and Luc Segoufin. 2017. The
Power of Programs over Monoids in DA. In 42nd International Sym-
posium on Mathematical Foundations of Computer Science, MFCS 2017,
August 21-25, 2017 - Aalborg, Denmark (LIPIcs, Vol. 83), Kim G. Larsen,
Hans L. Bodlaender, and Jean-François Raskin (Eds.). Schloss Dagstuhl
- Leibniz-Zentrum für Informatik, 2:1–2:20. https://doi.org/10.4230/
LIPIcs.MFCS.2017.2

[13] András Hajnal, Wolfgang Maass, Pavel Pudlák, Mario Szegedy, and
György Turán. 1993. Threshold Circuits of Bounded Depth. J. Comput.
Syst. Sci. 46, 2 (1993), 129–154. https://doi.org/10.1016/0022-0000(93)
90001-D

[14] Johan Håstad, Stasys Jukna, and Pavel Pudlák. 1995. Top-Down Lower
Bounds for Depth-Three Circuits. Comput. Complex. 5, 2 (1995), 99–112.
https://doi.org/10.1007/BF01268140

[15] John Håstad. 1989. Almost Optimal Lower Bounds for Small Depth

Circuits. Adv. Comput. Res. 5 (1989), 143–170.

[16] Stasys Jukna. 2011. Extremal Combinatorics - With Applications in
Computer Science (second ed.). Springer. https://doi.org/10.1007/978-
3-642-17364-6

[17] Michal Koucký. 2009. Circuit Complexity of Regular Languages. The-
ory Comput. Syst. 45, 4 (2009), 865–879. https://doi.org/10.1007/s00224-
009-9180-z

[18] Michal Koucký, Pavel Pudlák, and Denis Thérien. 2005. Bounded-depth
circuits: separating wires from gates. In Proceedings of the 37th Annual
ACM Symposium on Theory of Computing, Baltimore, MD, USA, May
22-24, 2005, Harold N. Gabow and Ronald Fagin (Eds.). ACM, 257–265.
https://doi.org/10.1145/1060590.1060629

[19] M. Lothaire. 1997. Combinatorics on words (second ed.). Cambridge

University Press.

[20] Alexis Maciel, Pierre Péladeau, and Denis Thérien. 2000. Programs
over semigroups of dot-depth one. Theor. Comput. Sci. 245, 1 (2000),
135–148. https://doi.org/10.1016/S0304-3975(99)00278-9

[21] Jean-Éric Pin. 2017. The Dot-Depth Hierarchy, 45 Years Later. In
The Role of Theory in Computer Science - Essays Dedicated to Janusz
Brzozowski, Stavros Konstantinidis, Nelma Moreira, Rogério Reis, and
Jeffrey O. Shallit (Eds.). World Scientific, 177–202. https://doi.org/10.
1142/9789813148208_0008

[22] Jean-Éric Pin and Pascal Weil. 1997. Polynomial Closure and Un-
ambiguous Product. Theory Comput. Syst. 30, 4 (1997), 383–422.
https://doi.org/10.1007/BF02679467

[23] Jean-Éric Pin. 1995. A variety theorem without complementation.

Russian Mathematics (Izvestija vuzov. Matematika) 39 (1995), 80–90.

[24] Thomas Place. 2018. Separating regular languages with two quantifier
alternations. Log. Methods Comput. Sci. 14, 4 (2018). https://doi.org/
10.23638/LMCS-14(4:16)2018

[25] Thomas Place and Marc Zeitoun. 2019. Going Higher in First-Order
Quantifier Alternation Hierarchies on Words. J. ACM 66, 2 (2019),
12:1–12:65. https://doi.org/10.1145/3303991

[26] Michael Sipser. 1983. Borel Sets and Circuit Complexity. In Proceedings
of the 15th Annual ACM Symposium on Theory of Computing, 25-27
April, 1983, Boston, Massachusetts, USA, David S. Johnson, Ronald Fagin,
Michael L. Fredman, David Harel, Richard M. Karp, Nancy A. Lynch,
Christos H. Papadimitriou, Ronald L. Rivest, Walter L. Ruzzo, and Joel I.
Seiferas (Eds.). ACM, 61–69. https://doi.org/10.1145/800061.808733

[27] Michael Sipser. 1984. A Topological View of Some Problems in Com-
plexity Theory. In Mathematical Foundations of Computer Science 1984,
Praha, Czechoslovakia, September 3-7, 1984, Proceedings (Lecture Notes
in Computer Science, Vol. 176), Michal Chytil and Václav Koubek (Eds.).
Springer, 567–572. https://doi.org/10.1007/BFb0030341

[28] Howard Straubing. 1985. Finite semigroup varieties of the form 𝑉 ★ 𝐷.
Journal of Pure and Applied Algebra 36 (1985), 53–94. https://doi.org/
10.1016/0022-4049(85)90062-3

[29] Howard Straubing. 1991. Constant-Depth periodic Circuits.

Int.
https://doi.org/10.1142/

J. Algebra Comput. 1, 1 (1991), 49–88.

Corentin Barloy, Michaël Cadilhac, Charles Paperman, and Thomas Zeume

S0218196791000043

[30] Howard Straubing. 1994. Finite Automata, Formal Logic, and Circuit
Complexity. Birkhäuser, Boston. https://doi.org/10.1007/978-1-4612-
0289-9

[31] Howard Straubing. 2001. Languages Defined with Modular Counting
Quantifiers. Inf. Comput. 166, 2 (2001), 112–132. https://doi.org/10.
1006/inco.2000.2923

[32] Howard Straubing. 2015. A new proof of the locality of R.

Int. J.
https://doi.org/10.1142/

Algebra Comput. 25, 1-2 (2015), 293–300.
S0218196715400111

[33] Denis Thérien and Thomas Wilke. 1998. Over Words, Two Variables
Are as Powerful as One Quantifier Alternation. In Proceedings of the
Thirtieth Annual ACM Symposium on the Theory of Computing, Dallas,
Texas, USA, May 23-26, 1998, Jeffrey Scott Vitter (Ed.). ACM, 234–240.
https://doi.org/10.1145/276698.276749

[34] Bret Tilson. 1987. Categories as algebra: An essential ingredient in the
theory of monoids. Journal of Pure and Applied Algebra 48, 1 (1987),
83–198. https://doi.org/10.1016/0022-4049(87)90108-3

