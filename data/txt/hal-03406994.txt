Federated Multi-Task Learning under a Mixture of
Distributions
Othmane Marfoq, Giovanni Neglia, Aurélien Bellet, Laetitia Kameni, Richard

Vidal

To cite this version:

Othmane Marfoq, Giovanni Neglia, Aurélien Bellet, Laetitia Kameni, Richard Vidal. Federated Multi-
Task Learning under a Mixture of Distributions. NeurIPS 2021 - 35th Conference on Neural Informa-
tion Processing Systems, Dec 2021, Sydney / Virtual, Australia. ￿hal-03406994￿

HAL Id: hal-03406994

https://hal.science/hal-03406994

Submitted on 17 Jun 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

2
2
0
2

b
e
F
8
1

]

G
L
.
s
c
[

3
v
2
5
2
0
1
.
8
0
1
2
:
v
i
X
r
a

Federated Multi-Task Learning
under a Mixture of Distributions

Othmane Marfoq1,3, Giovanni Neglia1, Aurélien Bellet2, Laetitia Kameni3, and Richard Vidal3

1Inria, Université Côte d’Azur, France, {othmane.marfoq, giovanni.neglia}@inria.fr
2Inria, Université de Lille, France, aurelien.bellet@inria.fr
3Accenture Labs, France, {richard.vidal, laetitia.kameni}@accenture.com

Abstract

The increasing size of data generated by smartphones and IoT devices motivated the
development of Federated Learning (FL), a framework for on-device collaborative
training of machine learning models. First efforts in FL focused on learning a
single global model with good average performance across clients, but the global
model may be arbitrarily bad for a given client, due to the inherent heterogeneity of
local data distributions. Federated multi-task learning (MTL) approaches can learn
personalized models by formulating an opportune penalized optimization problem.
The penalization term can capture complex relations among personalized models,
but eschews clear statistical assumptions about local data distributions.
In this work, we propose to study federated MTL under the ﬂexible assumption
that each local data distribution is a mixture of unknown underlying distributions.
This assumption encompasses most of the existing personalized FL approaches and
leads to federated EM-like algorithms for both client-server and fully decentralized
settings. Moreover, it provides a principled way to serve personalized models to
clients not seen at training time. The algorithms’ convergence is analyzed through a
novel federated surrogate optimization framework, which can be of general interest.
Experimental results on FL benchmarks show that our approach provides models
with higher accuracy and fairness than state-of-the-art methods.

1

Introduction

Federated Learning (FL) [28] allows a set of clients to collaboratively train models without sharing
their local data. Standard FL approaches train a unique model for all clients [47, 32, 38, 29, 48].
However, as discussed in [56], the existence of such a global model suited for all clients is at odds
with the statistical heterogeneity observed across different clients [37, 28]. Indeed, clients can have
non-iid data and varying preferences. Consider for example a language modeling task: given the
sequence of tokens “I love eating,” the next word can be arbitrarily different from one client to
another. Thus, having personalized models for each client is a necessity in many FL applications.

Previous work on personalized FL. A naive approach for FL personalization consists in learning
ﬁrst a global model and then ﬁne-tuning its parameters at each client via a few iterations of stochastic
gradient descent [58]. In this case, the global model plays the role of a meta-model to be used as
initialization for few-shot adaptation at each client. In particular, the connection between FL and
Model Agnostic Meta Learning (MAML) [27] has been studied in [19, 30, 1] in order to build a more
suitable meta-model for local personalization. Unfortunately, these methods can fail to build a model
with low generalization error (as exempliﬁed by LEAF synthetic dataset [7, App. 1]). An alternative

35th Conference on Neural Information Processing Systems (NeurIPS 2021).

 
 
 
 
 
 
approach is to jointly train a global model and one local model per client and then let each client
build a personalized model by interpolating them [14, 9, 44]. However, if local distributions are far
from the average distribution, a relevant global model does not exist and this approach boils down to
every client learning only on its own local data. This issue is formally captured by the generalization
bound in [14, Theorem 1].

Clustered FL [56, 20, 44] addresses the potential lack of a global model by assuming that clients can
be partitioned into several clusters. Clients belonging to the same cluster share the same optimal
model, but those models can be arbitrarily different across clusters (see [56, Assumption 2] for a
rigorous formulation). During training, clients learn the cluster to which they belong as well as
the cluster model. The Clustered FL assumption is also quite limiting, as no knowledge transfer is
possible across clusters. In the extreme case where each client has its own optimal local model (recall
the example on language modeling), the number of clusters coincides with the number of clients and
no federated learning is possible.

Multi-Task Learning (MTL) has recently emerged as an alternative approach to learn personalized
models in the federated setting and allows for more nuanced relations among clients’ models [59, 63,
67, 24, 16]. The authors of [59, 63] were the ﬁrst to frame FL personalization as a MTL problem. In
particular, they deﬁned federated MTL as a penalized optimization problem, where the penalization
term models relationships among tasks (clients). The work [59] proposed the MOCHA algorithm for
the client-server scenario, while [63, 67] presented decentralized algorithms for the same problem.
Unfortunately, these algorithms can only learn simple models (linear models or linear combination of
pre-trained models), because of the complex penalization term. Other MTL-based approaches [24, 23,
16, 26, 36] are able to train more general models at the cost of considering simpler penalization terms
(e.g., the distance to the average model), thereby losing the capability to capture complex relations
among tasks. Moreover, a general limitation of this line of work is that the penalization term is
justiﬁed qualitatively and not on the basis of clear statistical assumptions on local data distributions.

More recently, [57] proposed pFedHN. pFedHN feeds local clients’ representations to a global (across
clients) hypernetwork, which can output personalized heterogeneous models. Unfortunately, the
hypernetwork has a large memory footprint already for small clients’ models (e.g., the hypernetwork
in the experiments in [57] has 100 more parameters than the output model). Hence, it is not clear if
pFedHN can scale to more complex models. Moreover, pFedHN requires each client to communicate
multiple times for the server to learn meaningful representations. Therefore, its performance is
likely to deteriorate when clients participate only once (or few times) to training, as it is the case
for large-scale cross-device FL training. Furthermore, even once the hypernetwork parameters
have been learned, training personalized models for new clients still requires multiple client-server
communication rounds. More similar to our approach, FedFOMO [68] lets each client interpolate other
clients’ local models with opportune weights learned during training. However, this method lacks
both theoretical justiﬁcations for such linear combinations and convergence guarantees. Moreover,
FedFOMO requires the presence of a powerful server able to 1) store all individual local models and
2) learn for each client—through repeated interactions—which other clients’ local models may be
useful. Therefore, FedFOMO is not suited for cross-device FL where the number of clients may be
very large (e.g., 105–107 participating clients [28, Table 2]) and a given client may only participate in
a single training round.

Overall, although current personalization approaches can lead to superior empirical performance
in comparison to a shared global model or individually trained local models, it is still not well
understood whether and under which conditions clients are guaranteed to beneﬁt from collaboration.

Our contributions.
In this work, we ﬁrst show that federated learning is impossible without
assumptions on local data distributions. Motivated by this negative result, we formulate a general and
ﬂexible assumption: the data distribution of each client is a mixture of M underlying distributions.
The proposed formulation has the advantage that each client can beneﬁt from knowledge distilled
from all other clients’ datasets (even if any two clients can be arbitrarily different from each other).
We also show that this assumption encompasses most of the personalized FL approaches previously
proposed in the literature.

In our framework, a personalized model is a linear combination of M shared component models. All
clients jointly learn the M components, while each client learns its personalized mixture weights.
We show that federated EM-like algorithms can be used for training. In particular, we propose
FedEM and D-FedEM for the client-server and the fully decentralized settings, respectively, and we

2

prove convergence guarantees. Our approach also provides a principled and efﬁcient way to infer
personalized models for clients unseen at training time. Our algorithms can easily be adapted to
solve more general problems in a novel framework, which can be seen as a federated extension of the
centralized surrogate optimization approach in [43]. To the best of our knowledge, our paper is the
ﬁrst work to propose federated surrogate optimization algorithms with convergence guarantees.

Through extensive experiments on FL benchmark datasets, we show that our approach generally
yields models that 1) are on average more accurate, 2) are fairer across clients, and 3) generalize
better to unseen clients than state-of-the-art personalized and non-personalized FL approaches.

Paper outline. The rest of the paper is organized as follows. In Section 2 we provide our impossibility
result, introduce our main assumptions, and show that several popular personalization approaches
can be obtained as special cases of our framework. Section 3 describes our algorithms, states their
convergence results, and presents our general federated surrogate optimization framework. Finally,
we provide experimental results in Section 4 before concluding in Section 5.

2 Problem Formulation

We consider a (countable) set T of classiﬁcation (or regression) tasks which represent the set of
possible clients. We will use the terms task and client interchangeably. Data at client t ∈ T is
generated according to a local distribution Dt over X × Y. Local data distributions {Dt}t∈T are
in general different, thus it is natural to ﬁt a separate model (hypothesis) ht ∈ H to each data
distribution Dt. The goal is then to solve (in parallel) the following optimization problems

∀t ∈ T , minimize

ht∈H

LDt(ht),

(1)

where ht : X (cid:55)→ ∆|Y| (∆D denoting the unitary simplex of dimension D), l : ∆|Y| × Y (cid:55)→ R+ is
a loss function,1 and LDt(ht) = E(x,y)∼Dt [l(ht(x), y)] is the true risk of a model ht under data
distribution Dt. For (x, y) ∈ X × Y, we will denote the joint distribution density associated to Dt by
pt(x, y), and the marginal densities by pt(x) and pt(y).
A set of T clients [T ] (cid:44) {1, 2, . . . T } ⊆ T participate to the initial training phase; other clients may
join the system in a later stage. We denote by St = {s(i)
i=1 the dataset at client
t ∈ [T ] drawn i.i.d. from Dt, and by n = (cid:80)T
The idea of federated learning is to enable each client to beneﬁt from data samples available at other
clients in order to get a better estimation of LDt, and therefore get a model with a better generalization
ability to unseen examples.

, y(i)
t=1 nt the total dataset size.

t = (x(i)

t )}nt

t

2.1 An Impossibility Result

We start by showing that some assumptions on the local distributions pt(x, y), t ∈ T are needed for
federated learning to be possible, i.e., for each client to be able to take advantage of the data at other
clients. This holds even if all clients participate to the initial training phase (i.e., T = [T ]).

We consider the classic PAC learning framework where we ﬁx a class of models H and seek a
learning algorithm which is guaranteed, for all possible data distributions over X × Y, to return with
high probability a model with expected error (cid:15)-close to the best possible error in the class H. The
worst-case sample complexity then refers to the minimum amount of labeled data required by any
algorithm to reach a given (cid:15)-approximation.

Our impossibility result for FL is based on a reduction to an impossibility result for Semi-Supervised
Learning (SSL), which is the problem of learning from a training set with only a small amount of
labeled data. The authors of [4] conjectured that, when the quantity of unlabeled data goes to inﬁnity,
the worst-case sample complexity of SSL improves over supervised learning at most by a constant
factor that only depends on the hypothesis class [4, Conjecture 4]. This conjecture was later proved
for the realizable case and hypothesis classes of ﬁnite VC dimension [13, Theorem 1], even when the
marginal distribution over the domain set X is known [21, Theorem 2]. 2

1In the case of (multi-output) regression, we have ht : X (cid:55)→ Rd for some d ≥ 1 and l : Rd × Rd (cid:55)→ R+.
2We note that whether the conjecture in [4] holds in the agnostic case is still an open problem.

3

In the context of FL, if the marginal distributions pt (x) are identical, but the conditional distributions
pt (y|x) can be arbitrarily different, then each client t can learn using: 1) its own local labeled dataset,
and 2) the other clients’ datasets, but only as unlabeled ones (because their labels have no relevance
for t). The FL problem, with T clients, then reduces to T parallel SSL problems, or more precisely,
it is at least as difﬁcult as T parallel SSL problems (because client t has no direct access to the
other local datasets but can only learn through the communication exchanges allowed by the FL
algorithm). The SSL impossibility result implies that, without any additional assumption on the local
distributions pt (x, y) , t ∈ [T ], any FL algorithm can reduce the sample complexity of client-t’s
problem in (1) only by a constant in comparison to local learning, independently of how many other
clients participate to training and how large their datasets’ sizes are.

2.2 Learning under a Mixture Model

Motivated by the above impossibility result, in this work we propose to consider that each local data
distribution Dt is a mixture of M underlying distributions ˜Dm, 1 ≤ m ≤ M , as formalized below.
Assumption 1. There exist M underlying (independent) distributions ˜Dm, 1 ≤ m ≤ M , such that
for t ∈ T , Dt is mixture of the distributions { ˜Dm}M
tM ] ∈ ∆M , i.e.

m=1 with weights π∗

t1, . . . , π∗

t = [π∗

∀t ∈ T ,
where M(π) is a multinomial (categorical) distribution with parameters π.

((xt, yt) |zt = m) ∼ ˜Dm,

zt ∼ M(π∗

t ),

(2)

Similarly to what was done above, we use pm(x, y), pm(x), and pm(y) to denote the probability
distribution densities associated to ˜Dm. We further assume that marginals over X are identical.
Assumption 2. For all m ∈ [M ], we have pm(x) = p(x).

Assumption 2 is not strictly required for our analysis to hold, but, in the most general case, solving
Problem (1) requires to learn generative models. Instead, under Assumption 2 we can restrict our
attention to discriminative models (e.g., neural networks). 3 More speciﬁcally, we consider a
parameterized set of models ˜H with the following properties.
Assumption 3. ˜H = {hθ}θ∈Rd is a set of hypotheses parameterized by θ ∈ Rd, whose convex hull
is in H. For each distribution ˜Dm with m ∈ [M ], there exists a hypothesis hθ∗

, such that

m

(3)
where c ∈ R is a normalization constant. The function l(·, ·) is then the log-loss associated
to pm(y|x).

(x) , y(cid:1) = − log pm(y|x) + c,

l (cid:0)hθ∗

m

We refer to the hypotheses in ˜H as component models or simply components. We denote by
Θ∗ ∈ RM ×d the matrix whose m-th row is θ∗
m, and by Π∗ ∈ ∆T ×M the matrix whose t-th row is
t ∈ ∆M . Similarly, we will use Θ and Π to denote arbitrary parameters.
π∗
Remark 1. Assumptions 2–3 are mainly technical and are not required for our approach to work in
practice. Experiments in Section 4 show that our algorithms perform well on standard FL benchmark
datasets, for which these assumptions do not hold in general.

Note that, under the above assumptions, pt(x, y) depends on Θ∗ and π∗
t . Moreover, we can prove
t ∈ H for client t is a weighted average of models in ˜H.
(see App. A) that the optimal local model h∗
Proposition 2.1. Let l(·, ·) be the mean squared error loss, the logistic loss or the cross-entropy loss,
and ˘Θ and ˘Π be a solution of the following optimization problem:

E
(x,y)∼Dt
where DT is any distribution with support T . Under Assumptions 1, 2, and 3, the predictors

[− log pt(x, y|Θ, πt)] ,

minimize
Θ,Π

E
t∼DT

h∗
t =

M
(cid:88)

m=1

˘πtmh˘θm

(x) ,

∀t ∈ T

(4)

(5)

minimize E(x,y)∼Dt [l(ht(x), y)] and thus solve Problem (1).

3A possible way to ensure that Assumption 2 holds is to use the batch normalization technique from [40] to

account for feature shift.

4

Proposition 2.1 suggests the following approach to solve Problem (1). First, we estimate the parame-
ters ˘Θ and ˘πt, 1 ≤ t ≤ T , by minimizing the empirical version of Problem (4) on the training data,
i.e., minimizing:

f (Θ, Π) (cid:44) −

log p(S1:T |Θ, Π)
n

(cid:44) −

1
n

T
(cid:88)

nt(cid:88)

t=1

i=1

log p(s(i)
t

|Θ, πt),

(6)

which is the (negative) likelihood of the probabilistic model (2). 4 Second, we use (5) to get the client
predictor for the T clients present at training time. Finally, to deal with a client tnew /∈ [T ] not seen
during training, we keep the mixture component models ﬁxed and simply choose the weights πtnew
that maximize the likelihood of the client data and get the client predictor via (5).

2.3 Generalizing Existing Frameworks

Before presenting our federated learning algorithms in Section 3, we show that the generative model
in Assumption 1 extends some popular multi-task/personalized FL formulations in the literature.

Clustered Federated Learning [56, 20] assumes that each client belongs to one among C clusters
and proposes that all clients in the same cluster learn the same model. Our framework recovers this
scenario considering M = C and π∗

tc = 1 if task (client) t is in cluster c and π∗

tc = 0 otherwise.

Personalization via model interpolation [44, 14] relies on learning a global model hglob and T
local models hloc,t, and then using at each client the linear interpolation ht = αthloc,t + (1 − αt)hglob.
Each client model can thus be seen as a linear combination of M = T + 1 models hm = hloc,m for
tt(cid:48) = 0 for t(cid:48) ∈ [T ] \ {t}.
m ∈ [T ] and h0 = hglob with speciﬁc weights π∗
Federated MTL via task relationships. The authors of [59] proposed to learn personalized models
by solving the following optimization problem inspired from classic MTL formulations:

t0 = 1 − αt, and π∗

tt = αt, π∗

min
W,Ω

T
(cid:88)

nt(cid:88)

t=1

i=1

l(hwt(x(i)

t ), y(i)

t ) + λ tr (W ΩW (cid:124)) ,

(7)

where hwt are linear predictors parameterized by the rows of matrix W and the matrix Ω captures
task relationships (similarity). This formulation is motivated by the alternating structure optimization
method (ASO) [2, 70]. In App. B, we show that, when predictors hθ∗
m are linear and have bounded
norm, our framework leads to the same ASO formulation that motivated Problem (7). Problem (7)
can also be justiﬁed by probabilistic priors [69] or graphical models [35] (see [59, App. B.1]). Similar
considerations hold for our framework (see again App. B). Reference [67] extends the approach
in [59] by letting each client learn a personalized model as a weighted combination of M known
hypotheses. Our approach is more general and ﬂexible as clients learn both the weights and the
hypotheses. Finally, other personalized FL algorithms, like pFedMe [16], FedU [17], and those studied
in [24] and in [23], can be framed as special cases of formulation (7). Their assumptions can thus
also be seen as a particular case of our framework.

3 Federated Expectation-Maximization

3.1 Centralized Expectation-Maximization

Our goal is to estimate the optimal components’ parameters Θ∗ = (θ∗
m)1≤m≤M and mixture
weights Π∗ = (π∗
t )1≤t≤T by minimizing the negative log-likelihood f (Θ, Π) in (6). A natural
approach to solve such non-convex problems is the Expectation-Maximization algorithm (EM),
which alternates between two steps. Expectation steps update the distribution (denoted by qt)
over the latent variables z(i)
t ) given the current estimates
t
of the parameters {Θ, Π}. Maximization steps update the parameters {Θ, Π} by maximizing the
expected log-likelihood, where the expectation is computed according to the current latent variables’
distributions.

for every data point s(i)

t = (x(i)

, y(i)

t

The following proposition provides the EM updates for our problem (proof in App. C).

4As the distribution DT over tasks in Proposition 2.1 is arbitrary, any positively weighted sum of clients’

empirical losses could be considered.

5

Proposition 3.1. Under Assumptions 1 and 2, at the k-th iteration the EM algorithm updates
parameter estimates through the following steps:
t = m) ∝ πk

t ∈ [T ], m ∈ [M ], i ∈ [nt]

t ), y(i)
t )

tm · exp

−l(hθk

E-step:

qk+1
t

(x(i)

(z(i)

(8)

(cid:16)

(cid:17)

,

m

M-step:

πk+1
tm =

,

t ∈ [T ], m ∈ [M ]

(9)

θk+1
m ∈ arg min

qk+1
t

(z(i)

t = m)l(cid:0)hθ(x(i)

t ), y(i)

t

(cid:1),

m ∈ [M ] (10)

t = m)

(cid:80)nt

t

(z(i)
i=1 qk+1
nt
T
(cid:88)

nt(cid:88)

θ∈Rd

t=1

i=1

tm and on how well the corresponding component θk

In the E-step, given current
The EM updates in Proposition 3.1 have a natural interpretation.
component models Θk and mixture weights Πk, (8) updates the a-posteriori probability qk+1
t =
m) that point s(i)
t of client t was drawn from the m-th distribution based on the current mixture
weight πk
. The M-step consists of
two updates under ﬁxed probabilities qk+1
to reﬂect the
prominence of each distribution ˜Dm in St as given by qk+1
. Finally, (10) updates the components’
parameters Θk+1 by solving M independent, weighted empirical risk minimization problems with
weights given by qk+1
. These weights aim to construct an unbiased estimate of the true risk over
each underlying distribution ˜Dm using only points sampled from the client mixtures, similarly to
importance sampling strategies used to learn from data with sample selection bias [61, 11, 10, 64].

. First, (9) updates the mixture weights πk+1

m classiﬁes s(i)

(z(i)

t

t

t

t

t

t

3.2 Client-Server Algorithm

Federated learning aims to train machine learning models directly on the clients, without exchanging
raw data, and thus we should run EM while assuming that only client t has access to dataset St. The
E-step (8) and the Π update (9) in the M-step operate separately on each local dataset St and can thus
be performed locally at each client t. On the contrary, the Θ update (10) requires interaction with
other clients, since the computation spans all data samples S1:T .

In this section, we consider a client-server setting, in which each client t can communicate only with
a centralized server (the orchestrator) and wants to learn components’ parameters Θ∗ = (θ∗
m)1≤m≤M
and its own mixture weights π∗
t .

We propose the algorithm FedEM for Federated Expectation-Maximization (Alg. 1). FedEM pro-
ceeds through communication rounds similarly to most FL algorithms including FedAvg [47],
FedProx [38], SCAFFOLD [29], and pFedMe [16]. At each round, 1) the central server broadcasts
the (shared) component models to the clients, 2) each client locally updates components and its
personalized mixture weights, and 3) sends the updated components back to the server, 4) the server
aggregates the updates. The local update performed at client t consists in performing the steps
in (8) and (9) and updating the local estimates of θm through a solver which approximates the exact
minimization in (10) using only the local dataset St (see line 7). FedEM can operate with different
local solvers—even different across clients—as far as they satisfy some local improvement guarantees
(see the discussion in App. H). In what follows, we restrict our focus on the practically important
case where the local solver performs multiple stochastic gradient descent updates (local SGD [60]).
Under the following standard assumptions (see e.g., [66]), FedEM converges to a stationary point of f .
Below, we use the more compact notation l(θ; s(i)
Assumption 4. The negative log-likelihood f is bounded below by f ∗ ∈ R.
Assumption 5. (Smoothness) For all t ∈ [T ] and i ∈ [nt], the function θ (cid:55)→ l(θ; s(i)
and twice continuously differentiable.
Assumption 6. (Unbiased gradients and bounded variance) Each client t ∈ [T ] can sample a random
batch ξ from St and compute an unbiased estimator gt(θ, ξ) of the local gradient with bounded
variance, i.e., Eξ[gt(θ, ξ)] = 1
t )(cid:107)2 ≤ σ2.
nt
Assumption 7. (Bounded dissimilarity) There exist β and G such that for any set of weights α ∈ ∆M :

t ) and Eξ(cid:107)gt(θ, ξ) − 1
nt

t ) (cid:44) l(hθ(x(i)

i=1 ∇θl(θ; s(i)

i=1 ∇θl(θ; s(i)

t ) is L-smooth

t ), y(i)
t ).

(cid:80)nt

(cid:80)nt

T
(cid:88)

t=1

nt
n

(cid:13)
(cid:13)
(cid:13)

1
nt

nt(cid:88)

M
(cid:88)

i=1

m=1

(cid:13)
2
αm · l(θ; s(i)
(cid:13)
t )
(cid:13)

≤ G2 + β2(cid:13)
(cid:13)
(cid:13)

1
n

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

(cid:13)
2
αm · l(θ; s(i)
(cid:13)
t )
(cid:13)

.

6

Algorithm 1: FedEM (see also the more detailed Alg. 2 in App. D.1)
Input
Output : θK

m, m ∈ [M ]

: Data S1:T ; number of mixture distributions M ; number of communication rounds K

1 for iterations k = 1, . . . , K do
server broadcasts θk−1
2
for tasks t = 1, . . . , T in parallel over T clients do

m , 1 ≤ m ≤ M , to the T clients;

3

4

5

6

7

8

9

10

for component m = 1, . . . , M do

t (z(i)
tm as in (9);

update qk
update πk
m,t ← LocalSolver(m, θk−1
θk

m , qk

t , St);

t = m) as in (8), ∀i ∈ {1, . . . , nt};

client t sends θk

m,t, 1 ≤ m ≤ M , to the server;

for component m = 1, . . . , M do

m ← (cid:80)T
θk

t=1

nt
n × θk

m,t;

Assumption 7 limits the level of dissimilarity of the different tasks, similarly to what is done in [66].

Theorem 3.2. Under Assumptions 1–7, when clients use SGD as local solver with learning rate
η = a0√
, after a large enough number of communication rounds K, FedEM’s iterates satisfy:
K

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇Θf (cid:0)Θk, Πk(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

k=1

∆Πf (Θk, Πk) ≤ O

(cid:18) 1

K 3/4

(cid:19)

,

(11)

where the expectation is over the random batches samples, and ∆Πf (Θk, Πk) (cid:44) f (cid:0)Θk, Πk(cid:1) −
f (cid:0)Θk, Πk+1(cid:1) ≥ 0.

Theorem 3.2 (proof in App. G.1) expresses the convergence of both sets of parameters (Θ and Π)
to a stationary point of f . Indeed, the gradient of f with respect to Θ becomes arbitrarily small
(left inequality in (11)) and the update in Eq. (9) leads to arbitrarily small improvements of f (right
inequality in (11)).

We conclude this section observing that FedEM allows an unseen client, i.e., a client tnew /∈ [T ] arriving
after the distributed training procedure, to learn its personalized model. The client simply retrieves
the learned components’ parameters ΘK and computes its personalized weights πtnew (starting for
example from a uniform initialization) through one E-step (8) and the ﬁrst update in the M-step (9).

3.3 Fully Decentralized Algorithm

In some cases, clients may want to communicate directly in a peer-to-peer fashion instead of relying
on the central server mediation [see 28, Section 2.1]. In fact, fully decentralized schemes may
provide stronger privacy guarantees [12] and speed-up training as they better use communication
resources [41, 46] and reduce the effect of stragglers [50]. For these reasons, they have attracted
signiﬁcant interest recently in the machine learning community [41, 63, 42, 62, 3, 51, 46, 31].
We refer to [49] for a comprehensive survey of fully decentralized optimization (also known as
consensus-based optimization), and to [31] for a uniﬁed theoretical analysis of decentralized SGD.

We propose D-FedEM (Alg. 4 in App. D.2), a fully decentralized version of our federated expectation
maximization algorithm. As in FedEM, the M-step for Θ update is replaced by an approximate
maximization step consisting of local updates. The global aggregation step in FedEM (Alg. 1, line 10)
is replaced by a partial aggregation step, where each client computes a weighted average of its current
components and those of a subset of clients (its neighborhood), which may vary over time. The
convergence of decentralized optimization schemes requires certain assumptions to guarantee that
each client can inﬂuence the estimates of other clients over time. In our paper, we consider the
general assumption in [31, Assumption 4] (restated as Assumption 8 in App. E for completeness). For
instance, this assumption is satisﬁed if the graph of clients’ communications is strongly connected
every τ rounds.

D-FedEM converges to a stationary point of f (formal statement in App. E and proof in App. G.2).

7

Theorem 3.3 (Informal). In the same setting of Theorem 3.2 and under the additional Assumption 8,
t )1≤t≤T converge to a common value ¯Θk. Moreover, ¯Θk and Πk
D-FedEM’s individual estimates (Θk
converge to a stationary point of f .

3.4 Federated Surrogate Optimization

FedEM and D-FedEM can be seen as particular instances of a more general framework—of potential
interest for other applications—that we call federated surrogate optimization.

The standard majorization-minimization principle [34] iteratively minimizes, at each iteration k, a
surrogate function gk majorizing the objective function f . The work [43] studied this approach when
each gk is a ﬁrst-order surrogate of f (the formal deﬁnition from [43] is given in App. F.1).

Our novel federated surrogate optimization framework considers that the objective function f is a
weighted sum f = (cid:80)T
t=1 ωtft of T functions and iteratively minimizes f in a distributed fashion
using partial ﬁrst-order surrogates gk
t is not
required to be a ﬁrst order surrogate wrt the whole set of parameters, as deﬁned formally below.
Deﬁnition 1 (Partial ﬁrst-order surrogate). A function g(u, v) : Rdu × V → R is a partial-ﬁrst-order
surrogate of f (u, v) wrt u near (u0, v0) ∈ Rdu × V when the following conditions are satisﬁed:

t for each function ft. “Partial” refers to the fact that gk

1. g(u, v) ≥ f (u, v) for all u ∈ Rdu and v ∈ V;
2. r(u, v) (cid:44) g(u, v) − f (u, v) is differentiable and L-smooth with respect to u. Moreover,

we have r(u0, v0) = 0 and ∇ur(u0, v0) = 0.

3. g(u, v0) − g(u, v) = dV (v0, v) for all u ∈ Rdu and v ∈ arg minv(cid:48)∈V g(u, v(cid:48)), where dV

is non-negative and dV (v, v(cid:48)) = 0 ⇐⇒ v = v(cid:48).

Under the assumption that each client t can compute a partial ﬁrst-order surrogate of ft, we propose
algorithms for federated surrogate optimization in both the client-server setting (Alg. 3) and the fully
decentralized one (Alg. 5) and prove their convergence under mild conditions (App. G.1 and G.2).
FedEM and D-FedEM can be seen as particular instances of these algorithms and Theorem. 3.2 and
Theorem. 3.3 follow from the more general convergence results for federated surrogate optimization.
We can also use our framework to analyze the convergence of other FL algorithms such as pFedMe
[16], as we illustrate in App. F.3.

4 Experiments

Datasets and models. We evaluated our method on ﬁve federated benchmark datasets spanning a
wide range of machine learning tasks: image classiﬁcation (CIFAR10 and CIFAR100 [33]), handwrit-
ten character recognition (EMNIST [8] and FEMNIST [7]),5 and language modeling (Shakespeare
[7, 47]). Shakespeare dataset (resp. FEMNIST) was naturally partitioned by assigning all lines
from the same characters (resp. all images from the same writer) to the same client. We created
federated versions of CIFAR10 and EMNIST by distributing samples with the same label across
the clients according to a symmetric Dirichlet distribution with parameter 0.4, as in [65]. For CI-
FAR100, we exploited the availability of “coarse” and “ﬁne” labels, using a two-stage Pachinko
allocation method [39] to assign 600 sample to each of the 100 clients, as in [54]. We also evaluated
our method on a synthetic dataset verifying Assumptions 1–3. For all tasks, we randomly split
each local dataset into training (60%), validation (20%) and test (20%) sets. Table 1 summarizes
datasets, models, and number of clients (more details can be found in App. I.1). Code is available at
https://github.com/omarfoq/FedEM.

Other FL approaches. We compared our algorithms with global models trained with FedAvg [47]
and FedProx [38] as well as different personalization approaches: a personalized model trained only
on the local dataset, FedAvg with local tuning (FedAvg+) [27], Clustered FL [56] and pFedMe [16].
For each method and each task, the learning rate and the other hyperparameters were tuned via
grid search (details in App. I.2). FedAvg+ updated the local model through a single pass on the
local dataset. Unless otherwise stated, the number of components considered by FedEM was M = 3,
training occurred over 80 communication rounds for Shakespeare and 200 rounds for all other datasets.

5For training, we sub-sampled 10% and 15% from EMNIST and FEMNIST datasets respectively.

8

Table 1: Datasets and models (details in App. I.1).

Dataset

Task

Clients

Total samples

Model

FEMNIST [7]
EMNIST [8]
CIFAR10 [33]
CIFAR100 [33]
Shakespeare [7, 47]
Synthetic

Handwritten character recognition
Handwritten character recognition
Image classiﬁcation
Image classiﬁcation
Next-Character Prediction
Binary Classiﬁcation

539
100
80
100
778
300

120, 772
81, 425
60, 000
60, 000
4, 226, 158
1, 570, 507

2-layer CNN + 2-layer FFN
2-layer CNN + 2-layer FFN
MobileNet-v2 [55]
MobileNet-v2 [55]
Stacked-LSTM [25]
Linear model

Table 2: Test accuracy: average across clients / bottom decile.

Dataset

Local

FedAvg [47]

FedProx [38]

FedAvg+ [27]

Clustered FL [56]

pFedMe [16]

FedEM (Ours)

FEMNIST
EMNIST
CIFAR10
CIFAR100
Shakespeare
Synthetic

71.0 / 57.5
71.9 / 64.3
70.2 / 48.7
31.5 / 19.9
32.0 / 16.6
65.7 / 58.4

78.6 / 63.9
82.6 / 75.0
78.2 / 72.4
40.9 / 33.2
46.7 / 42.8
68.2 / 58.9

78.9 / 64.0
83.0 / 75.4
78.0 / 70.8
41.0 / 33.2
45.7 / 41.9
68.2 / 59.0

75.3 / 53.0
83.1 / 75.8
82.3 / 70.6
39.0 / 28.3
40.0 / 25.5
68.9 / 60.2

73.5 / 55.1
82.7 / 75.0
78.6 / 71.2
41.5 / 34.1
46.6 / 42.7
69.1 / 59.0

74.9 / 57.6
83.3 / 76.4
81.7 / 73.6
41.8 / 32.5
41.2 / 36.8
69.2 / 61.2

79.9 / 64.8
83.5 / 76.6
84.3 / 78.1
44.1 / 35.0
46.7 / 43.0
74.7 / 66.7

At each round, clients train for one epoch. Results for D-FedEM are in App. J.1. A comparison with
MOCHA [59], which can only train linear models, is presented in App. J.2.

Average performance of personalized models. The performance of each personalized model
(which is the same for all clients in the case of FedAvg and FedProx) is evaluated on the local test
dataset (unseen at training). Table 2 shows the average weighted accuracy with weights proportional
to local dataset sizes. We observe that FedEM obtains the best performance across all datasets.

Fairness across clients. FedEM’s improvement in terms of average accuracy could be the result of
learning particularly good models for some clients at the expense of bad models for other clients.
Table 2 shows the bottom decile of the accuracy of local models, i.e., the (T /10)-th worst accuracy
(the minimum accuracy is particularly noisy, notably because some local test datasets are very small).
Even clients with the worst personalized models are still better off when FedEM is used for training.

Clients sampling. In cross-device federated learning, only a subset of clients may be available at
each round. We ran CIFAR10 experiments with different levels of participation: at each round a
given fraction of all clients were sampled uniformly without replacement. We restrict the comparison
to FedEM and FedAvg+, as 1) FedAvg+ performed better than FedProx and FedAvg in the previous
CIFAR10 experiments, 2) it is not clear how to extend pFedMe and Clustered FL to handle client
sampling. Results in Fig. 1 (left) show that FedEM is more robust to low clients’ participation levels.
We provide additional results on client sampling, including a comparison with APFL [14], in App. J.6.

Generalization to unseen clients. As discussed in Section 3.2, FedEM allows new clients arriving
after the distributed training to easily learn their personalized models. With the exception of FedAvg+,
it is not clear how the other personalized FL algorithms should be extended to tackle the same goal
(see discussion in App. J.3). In order to evaluate the quality of new clients’ personalized models, we
performed an experiment where only 80% of the clients (“old” clients) participate to the training. The
remaining 20% join the system in a second phase and use their local training datasets to learn their
personalized weights. Table 3 shows that FedEM allows new clients to learn a personalized model
at least as good as FedAvg’s global one and always better than FedAvg+’s one. Unexpectedly, new
clients achieve sometimes a signiﬁcantly higher test accuracy than old clients (e.g., 47.5% against
44.1% on CIFAR100). Our investigation in App. J.3 suggests that, by selecting their mixture weights
on local datasets that were not used to train the components, new clients can compensate for potential
overﬁtting in the initial training phase. We also investigate in App. J.3 the effect of the local dataset
size on the accuracy achieved by unseen clients, showing that personalization is effective even when
unseen clients have small datasets.

Effect of M . A limitation of FedEM is that each client needs to update and transmit M components at
each round, requiring roughly M times more computation and M times larger messages. Nevertheless,
the number of components to consider in practice is quite limited. We used M = 3 in our previous
experiments, and Fig. 1 (right) shows that larger values do not yield much improvement and M = 2
already provides a signiﬁcant level of personalization. In all experiments above, the number of
communication rounds allowed all approaches to converge. As a consequence, even if other methods

9

Table 3: Average test accuracy across clients unseen at training (train accuracy in parenthesis).

Dataset

FedAvg [47]

FedAvg+ [27]

FedEM (Ours)

FEMNIST
EMNIST
CIFAR10
CIFAR100
Shakespeare
Synthetic

78.3 (80.9)
83.4 (82.7)
77.3 (77.5)
41.1 (42.1)
46.7 (47.1)
68.6 (70.0)

74.2 (84.2)
83.7 (92.9)
80.4 (80.5)
36.5 (55.3)
40.2 (93.0)
69.1 (72.1)

79.1 (81.5)
84.0 (83.3)
85.9 (90.7)
47.5 (46.6)
46.7 (46.6)
73.0 (74.1)

Figure 1: Effect of client sampling rate (left) and FedEM number of mixture components M (right)
on the test accuracy for CIFAR10 [33].

trained over M = 3 times more rounds—in order to have as much computation and communication as
FedEM—the conclusions would not change. As a ﬁnal experiment, we considered a time-constrained
setting, where FedEM is limited to run one third (= 1/M ) of the rounds (Table 7 in App. J.5). Even if
FedEM does not reach its maximum accuracy, it still outperforms the other methods on 3 datasets.

5 Conclusion

In this paper, we proposed a novel federated MTL approach based on the ﬂexible assumption that
local data distributions are mixtures of underlying distributions. Our EM-like algorithms allow clients
to jointly learn shared component models and personalized mixture weights in client-server and
fully decentralized settings. We proved convergence guarantees for our algorithms through a general
federated surrogate optimization framework which can be used to analyze other FL formulations.
Extensive empirical evaluation shows that our approach learns models with higher accuracy and
fairness than state-of-the-art FL algorithms, even for clients not present at training time.

In future work, we aim to reduce the local computation and communication of our algorithms. Aside
from standard compression schemes [22], a promising direction is to limit the number of component
models that a client updates/transmits at each step. This could be done in an adaptive manner based on
the client’s current mixture weights. A simultaneously published work [15] proposes a federated EM
algorithm (also called FedEM), which does not address personalization but reduces communication
requirements by compressing appropriately deﬁned complete data sufﬁcient statistics.

A second interesting research direction is to study personalized FL approaches under privacy con-
straints (quite unexplored until now with the notable exception of [3]). Some features of our
algorithms may be beneﬁcial for privacy (e.g., the fact that personalized weights are kept locally and
that all users contribute to all shared models). We hope to design differentially private versions of our
algorithms and characterize their privacy-utility trade-offs.

6 Acknowledgements

This work has been supported by the French government, through the 3IA Côte d’Azur Investments
in the Future project managed by the National Research Agency (ANR) with the reference number
ANR-19-P3IA-0002, and through grants ANR-16-CE23-0016 (Project PAMELA) and ANR-20-
CE23-0015 (Project PRIDE). The authors are grateful to the OPAL infrastructure from Université
Côte d’Azur for providing computational resources and technical support.

10

References

[1] Durmus Alp Emre Acar et al. “Debiasing Model Updates for Improving Personalized Federated
Training”. In: Proceedings of the 38th International Conference on Machine Learning. Ed. by
Marina Meila and Tong Zhang. Vol. 139. Proceedings of Machine Learning Research. PMLR,
July 2021, pp. 21–31. URL: https://proceedings.mlr.press/v139/acar21a.html.

[2] Rie Kubota Ando and Tong Zhang. “A Framework for Learning Predictive Structures from
Multiple Tasks and Unlabeled Data”. In: Journal of Machine Learning Research 6.61 (2005),
pp. 1817–1853.

[3] Aurélien Bellet, Rachid Guerraoui, Mahsa Taziki, and Marc Tommasi. “Personalized and

Private Peer-to-Peer Machine Learning”. In: AISTATS. 2018.

[4] Shai Ben-David, Tyler Lu, and D. Pál. “Does Unlabeled Data Provably Help? Worst-case

Analysis of the Sample Complexity of Semi-Supervised Learning”. In: COLT. 2008.

[5] Stephen Boyd, Persi Diaconis, and Lin Xiao. “Fastest Mixing Markov Chain on A Graph”. In:

SIAM REVIEW 46 (2003), pp. 667–689.

[6] Sébastien Bubeck. Convex Optimization: Algorithms and Complexity. 2015. arXiv: 1405.4980

[math.OC].

[7] Sebastian Caldas et al. “Leaf: A benchmark for federated settings”. In: arXiv preprint
arXiv:1812.01097 (2018). Presented at the 2nd International Workshop on Federated Learning
for Data Privacy and Conﬁdentiality (in conjunction with NeurIPS 2019).

[8] Gregory Cohen, Saeed Afshar, Jonathan Tapson, and Andre Van Schaik. “EMNIST: Extending
MNIST to handwritten letters”. In: 2017 International Joint Conference on Neural Networks
(IJCNN). IEEE. 2017, pp. 2921–2926.

[9] Luca Corinzia and Joachim M. Buhmann. Variational Federated Multi-Task Learning. 2019.

arXiv: 1906.06268 [cs.LG].

[10] Corinna Cortes, Yishay Mansour, and Mehryar Mohri. “Learning Bounds for Impor-
tance Weighting”. In: Advances in Neural Information Processing Systems. Ed. by J. Laf-
ferty, C. Williams, J. Shawe-Taylor, R. Zemel, and A. Culotta. Vol. 23. Curran Asso-
ciates, Inc., 2010. URL: https : / / proceedings . neurips . cc / paper / 2010 / file /
59c33016884a62116be975a9bb8257e3-Paper.pdf.

[11] Corinna Cortes, Mehryar Mohri, Michael Riley, and Afshin Rostamizadeh. “Sample Selection

Bias Correction Theory”. In: ALT. 2008.

[12] Edwige Cyffers and Aurélien Bellet. Privacy Ampliﬁcation by Decentralization. Presented
at the Privacy Preserving Machine Learning workshop (in conjunction with NeurIPS 2020).
2021. arXiv: 2012.05326 [cs.LG].

[13] Malte Darnstädt, H. U. Simon, and Balázs Szörényi. “Unlabeled Data Does Provably Help”.

In: STACS. 2013.

[14] Yuyang Deng, Mohammad Mahdi Kamani, and Mehrdad Mahdavi. “Adaptive Personalized

Federated Learning”. In: arXiv preprint arXiv:2003.13461 (2020).

[15] Aymeric Dieuleveut, Gersende Fort, Eric Moulines, and Geneviève Robin. “Federated Expec-
tation Maximization with heterogeneity mitigation and variance reduction”. In: Advances in
Neural Information Processing Systems. Vol. 34. 2021.

[16] Canh T Dinh, Nguyen H Tran, and Tuan Dung Nguyen. “Personalized Federated Learning
with Moreau Envelopes”. In: 34th Conference on Neural Information Processing Systems
(NeurIPS 2020). 2020.

[17] Canh T Dinh, Tung T Vu, Nguyen H Tran, Minh N Dao, and Hongyu Zhang. “FedU: A
Uniﬁed Framework for Federated Multi-Task Learning with Laplacian Regularization”. In:
arXiv preprint arXiv:2102.07148 (2021).

[18] P. Erdös and A. Rényi. “On Random Graphs I”. In: Publicationes Mathematicae Debrecen 6

(1959), p. 290.

[19] Alireza Fallah, Aryan Mokhtari, and Asuman Ozdaglar. “Personalized federated learning:
A meta-learning approach”. In: 34th Conference on Neural Information Processing Systems
(NeurIPS 2020). 2020.

[20] Avishek Ghosh, Jichan Chung, Dong Yin, and Kannan Ramchandran. “An Efﬁcient Framework

for Clustered Federated Learning”. In: NeurIPS. 2020.

11

[21] Christina Göpfert, Shai Ben-David, Olivier Bousquet, Sylvain Gelly, Ilya Tolstikhin, and Ruth
Urner. “When can unlabeled data improve the learning rate?” In: Conference on Learning
Theory. PMLR. 2019, pp. 1500–1518.

[22] Farzin Haddadpour, Mohammad Mahdi Kamani, Aryan Mokhtari, and Mehrdad Mahdavi.
“Federated Learning with Compression: Uniﬁed Analysis and Sharp Guarantees”. In: ICML.
2021.

[23] Filip Hanzely, Slavomıér Hanzely, Samuel Horváth, and Peter Richtárik. “Lower bounds
and optimal algorithms for personalized federated learning”. In: 34th Conference on Neural
Information Processing Systems (NeurIPS 2020). 2020.

[24] Filip Hanzely and Peter Richtárik. “Federated Learning of a Mixture of Global and Local

Models”. In: (2020). arXiv: 2002.05516 [cs.LG].

[25] Sepp Hochreiter and Jürgen Schmidhuber. “Long Short-Term Memory”. In: Neural Computa-

tion 9.8 (1997), pp. 1735–1780.

[26] Yutao Huang et al. “Personalized cross-silo federated learning on non-iid data”. In: Proceedings

of the AAAI Conference on Artiﬁcial Intelligence. Vol. 35. 9. 2021, pp. 7865–7873.

[27] Yihan Jiang, Jakub Koneˇcný, Keith Rush, and Sreeram Kannan. “Improving federated learning
personalization via model agnostic meta learning”. In: arXiv preprint arXiv:1909.12488 (2019).
Presented at NeurIPS FL workshop 2019.

[28] Peter Kairouz et al. “Advances and Open Problems in Federated Learning”. In: Foundations
and Trends® in Machine Learning 14.1–2 (2021), pp. 1–210. ISSN: 1935-8237. DOI: 10.
1561/2200000083. URL: http://dx.doi.org/10.1561/2200000083.

[29] Sai Praneeth Karimireddy, Satyen Kale, Mehryar Mohri, Sashank Reddi, Sebastian Stich,
and Ananda Theertha Suresh. “SCAFFOLD: Stochastic controlled averaging for federated
learning”. In: International Conference on Machine Learning. PMLR. 2020, pp. 5132–5143.
[30] Mikhail Khodak, Maria-Florina F Balcan, and Ameet S Talwalkar. “Adaptive gradient-based
meta-learning methods”. In: Advances in Neural Information Processing Systems. 2019,
pp. 5917–5928.

[31] Anastasia Koloskova, N. Loizou, Sadra Boreiri, M. Jaggi, and S. Stich. “A Uniﬁed Theory of

[32]

Decentralized SGD with Changing Topology and Local Updates”. In: ICML. 2020.
Jakub Koneˇcný, H Brendan McMahan, Felix X Yu, Peter Richtárik, Ananda Theertha Suresh,
and Dave Bacon. “Federated learning: Strategies for improving communication efﬁciency”.
In: arXiv preprint arXiv:1610.05492 (2016). Presented at NIPS 2016 Workshop on Private
Multi-Party Machine Learning.

[33] Alex Krizhevsky. “Learning multiple layers of features from tiny images”. MSc thesis. 2009.
[34] Kenneth Lange, David R. Hunter, and Ilsoon Yang. “Optimization Transfer Using Surrogate
Objective Functions”. In: Journal of Computational and Graphical Statistics 9.1 (2000), pp. 1–
20. ISSN: 10618600. URL: http://www.jstor.org/stable/1390605.

[35] Steffen L. Lauritzen. Graphical models. English. Oxford Statistical Science Series 17. Claren-

don Press, 1996. ISBN: 0198522193.

[36] Tian Li, Shengyuan Hu, Ahmad Beirami, and Virginia Smith. “Ditto: Fair and robust federated
learning through personalization”. In: International Conference on Machine Learning. PMLR.
2021, pp. 6357–6368.

[37] Tian Li, Anit Kumar Sahu, Ameet Talwalkar, and Virginia Smith. “Federated learning: Chal-
lenges, methods, and future directions”. In: IEEE Signal Processing Magazine 37.3 (2020),
pp. 50–60.

[38] Tian Li, Anit Kumar Sahu, Manzil Zaheer, Maziar Sanjabi, Ameet Talwalkar, and Virginia
Smith. “Federated Optimization in Heterogeneous Networks”. In: Third MLSys Conference.
2020.

[39] Wei Li and Andrew McCallum. “Pachinko Allocation: DAG-Structured Mixture Models
of Topic Correlations”. In: Proceedings of the 23rd International Conference on Machine
Learning. ICML ’06. Pittsburgh, Pennsylvania, USA: Association for Computing Machinery,
2006, pp. 577–584. ISBN: 1595933832. DOI: 10.1145/1143844.1143917. URL: https:
//doi.org/10.1145/1143844.1143917.

[40] Xiaoxiao Li, Meirui JIANG, Xiaofei Zhang, Michael Kamp, and Qi Dou. “FedBN: Federated
Learning on Non-IID Features via Local Batch Normalization”. In: International Conference
on Learning Representations. 2020.

12

[41] Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, and Ji Liu. “Can Decentral-
ized Algorithms Outperform Centralized Algorithms? A Case Study for Decentralized Parallel
Stochastic Gradient Descent”. In: Proceedings of the 31st International Conference on Neural
Information Processing Systems. NIPS’17. Long Beach, California, USA: Curran Associates
Inc., 2017, pp. 5336–5346. ISBN: 9781510860964.

[42] Xiangru Lian, Wei Zhang, Ce Zhang, and Ji Liu. “Asynchronous Decentralized Parallel

[43]

Stochastic Gradient Descent”. In: ICML. 2018.
Julien Mairal. “Optimization with ﬁrst-order surrogate functions”. In: International Conference
on Machine Learning. 2013, pp. 783–791.

[44] Yishay Mansour, Mehryar Mohri, Jae Ro, and Ananda Theertha Suresh. “Three approaches for
personalization with applications to federated learning”. In: arXiv preprint arXiv:2002.10619
(2020).

[45] Sébastien Marcel and Yann Rodriguez. “Torchvision the Machine-Vision Package of Torch”. In:
Proceedings of the 18th ACM International Conference on Multimedia. MM ’10. Firenze, Italy:
Association for Computing Machinery, 2010, pp. 1485–1488. ISBN: 9781605589336. DOI:
10.1145/1873951.1874254. URL: https://doi.org/10.1145/1873951.1874254.

[46] Othmane Marfoq, Chuan Xu, Giovanni Neglia, and Richard Vidal. “Throughput-Optimal
Topology Design for Cross-Silo Federated Learning”. In: Advances in Neural Information
Processing Systems. Ed. by H. Larochelle, M. Ranzato, R. Hadsell, M. F. Balcan, and H. Lin.
Vol. 33. Curran Associates, Inc., 2020, pp. 19478–19487. URL: https://proceedings.
neurips.cc/paper/2020/file/e29b722e35040b88678e25a1ec032a21-Paper.pdf.

[47] Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hampson, and Blaise Aguera y Arcas.
“Communication-efﬁcient learning of deep networks from decentralized data”. In: Artiﬁcial
Intelligence and Statistics. PMLR. 2017, pp. 1273–1282.

[48] Mehryar Mohri, Gary Sivek, and Ananda Theertha Suresh. “Agnostic Federated Learning”. In:

International Conference on Machine Learning. 2019, pp. 4615–4625.

[49] A. Nedi´c, A. Olshevsky, and M. G. Rabbat. “Network Topology and Communication-
Computation Tradeoffs in Decentralized Optimization”. In: Proceedings of the IEEE 106.5
(2018), pp. 953–976. DOI: 10.1109/JPROC.2018.2817461.

[50] Giovanni Neglia, Gianmarco Calbi, Don Towsley, and Gayane Vardoyan. “The Role of Network
Topology for Distributed Machine Learning”. In: IEEE INFOCOM 2019 - IEEE Conference on
Computer Communications. 2019, pp. 2350–2358. DOI: 10.1109/INFOCOM.2019.8737602.
[51] Giovanni Neglia, Chuan Xu, Don Towsley, and Gianmarco Calbi. “Decentralized gradient

methods: does topology matter?” In: AISTATS. 2020.

[52] Y. Nesterov. Introductory Lectures on Convex Optimization: A Basic Course. 1st ed. Applied
Optimization. Springer, 2003. URL: http://gen.lib.rus.ec/book/index.php?md5=
488d3c36f629a6e021fc011675df02ef.

[53] Adam Paszke et al. “PyTorch: An Imperative Style, High-Performance Deep Learning Li-
brary”. In: Advances in Neural Information Processing Systems 32. Ed. by H. Wallach, H.
Larochelle, A. Beygelzimer, F. d’Alché-Buc, E. Fox, and R. Garnett. Curran Associates, Inc.,
2019, pp. 8024–8035. URL: http://papers.neurips.cc/paper/9015- pytorch- an-
imperative-style-high-performance-deep-learning-library.pdf.

[54] Sashank J. Reddi et al. “Adaptive Federated Optimization”. In: International Conference
on Learning Representations. 2021. URL: https : / / openreview . net / forum ? id =
LkFG3lB13U5.

[55] Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen.
“Mobilenetv2: Inverted residuals and linear bottlenecks”. In: Proceedings of the IEEE confer-
ence on computer vision and pattern recognition. 2018, pp. 4510–4520.

[56] Felix Sattler, Klaus-Robert Müller, and Wojciech Samek. “Clustered Federated Learning:
Model-Agnostic Distributed Multitask Optimization Under Privacy Constraints”. In: IEEE
Transactions on Neural Networks and Learning Systems (2020).

[57] Aviv Shamsian, Aviv Navon, Ethan Fetaya, and Gal Chechik. “Personalized Federated Learning
using Hypernetworks”. In: Proceedings of the 38th International Conference on Machine
Learning. Ed. by Marina Meila and Tong Zhang. Vol. 139. Proceedings of Machine Learning
Research. PMLR, July 2021, pp. 9489–9502. URL: https://proceedings.mlr.press/
v139/shamsian21a.html.

13

[58] Khe Chai Sim, Petr Zadrazil, and Françoise Beaufays. “An Investigation Into On-device
Personalization of End-to-end Automatic Speech Recognition Models”. In: INTERSPEECH.
2019.

[59] Virginia Smith, Chao-Kai Chiang, Maziar Sanjabi, and Ameet Talwalkar. “Federated Multi-
Task Learning”. In: Proceedings of the 31st International Conference on Neural Information
Processing Systems. NIPS’17. Long Beach, California, USA: Curran Associates Inc., 2017,
pp. 4427–4437. ISBN: 9781510860964.

[60] Sebastian U Stich. “Local SGD Converges Fast and Communicates Little”. In: International

Conference on Learning Representations. 2018.

[61] Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul Buenau, and Motoaki Kawan-
abe. “Direct Importance Estimation with Model Selection and Its Application to Covariate
Shift Adaptation”. In: NIPS. 2008.

[62] Hanlin Tang, Xiangru Lian, Ming Yan, Ce Zhang, and Ji Liu. “D2: Decentralized Training

over Decentralized Data”. In: ICML. 2018.

[63] Paul Vanhaesebrouck, Aurélien Bellet, and Marc Tommasi. “Decentralized Collaborative

Learning of Personalized Models over Networks”. In: AISTATS. 2017.

[64] Robin Vogel, Mastane Achab, Stéphan Clémençon, and Charles Tillier. “Weighted Emprirical

Risk Minimization: Transfer Learning based on Importance Sampling”. In: ESANN. 2020.

[65] Hongyi Wang, Mikhail Yurochkin, Yuekai Sun, Dimitris Papailiopoulos, and Yasaman Khaza-
eni. “Federated Learning with Matched Averaging”. In: International Conference on Learning
Representations. 2020. URL: https://openreview.net/forum?id=BkluqlSFDS.
Jianyu Wang, Qinghua Liu, Hao Liang, Gauri Joshi, and H Vincent Poor. “Tackling the
objective inconsistency problem in heterogeneous federated optimization”. In: 34th Conference
on Neural Information Processing Systems (NeurIPS 2020). 2020.

[66]

[67] Valentina Zantedeschi, Aurélien Bellet, and Marc Tommasi. “Fully Decentralized Joint Learn-
ing of Personalized Models and Collaboration Graphs”. In: ed. by Silvia Chiappa and Roberto
Calandra. Vol. 108. Proceedings of Machine Learning Research. Online: PMLR, Aug. 2020,
pp. 864–874. URL: http://proceedings.mlr.press/v108/zantedeschi20a.html.

[68] Michael Zhang, Karan Sapra, Sanja Fidler, Serena Yeung, and Jose M Alvarez. “Personalized
Federated Learning with First Order Model Optimization”. In: International Conference on
Learning Representations. 2020.

[70]

[69] Yu Zhang and Dit Yan Yeung. “A Convex Formulation for Learning Task Relationships in
Multi-task Learning”. In: Proceedings of the 26th Conference on Uncertainty in Artiﬁcial
Intelligence, UAI 2010. 2010, p. 733.
Jiayu Zhou, Jianhui Chen, and Jieping Ye. “Clustered Multi-Task Learning Via Alternating
Structure Optimization”. In: Advances in Neural Information Processing Systems. Ed. by
J. Shawe-Taylor, R. Zemel, P. Bartlett, F. Pereira, and K. Q. Weinberger. Vol. 24. Curran
Associates, Inc., 2011. URL: https://proceedings.neurips.cc/paper/2011/file/
a516a87cfcaef229b342c437fe2b95f7-Paper.pdf.

14

Appendix

Table of Contents

A Proof of Proposition 2.1

B Relation with Other Multi-Task Learning Frameworks

C Centralized Expectation Maximization

D Detailed Algorithms

D.1 Client-Server Algorithm .
.
D.2 Fully Decentralized Algorithm .

.

.

.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

E Details on the Fully Decentralized Setting

F Federated Surrogate Optimization

F.1 Reminder on Basic (Centralized) Surrogate Optimization .
F.2 Novel Federated Version .
.
F.3

.
.
.
Illustration: Analyzing pFedMe with Federated Surrogate Optimization .

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

G Convergence Proofs

G.1 Client-Server Setting .
.
G.2 Fully Decentralized Setting .
.
G.3 Supporting Lemmas .

.

.

.

.

.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

H Distributed Surrogate Optimization with Black-Box Solver
.
.
.
.

H.1 Supporting Lemmas .
H.2 Proof of Theorem H.1(cid:48)
H.3 Proof of Theorem H.1 .

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

I Details on Experimental Setup
.
I.1 Datasets and Models .
.
Implementation Details
I.2

.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

.
.

J Additional Experimental Results

.
.
.

.
.
.

.
.

.
.
.

.
.
.

.
.

.

.

J.1
.
.
J.2 Comparison with MOCHA .
.
J.3 Generalization to Unseen Clients
J.4
.
.
J.5 Effect of M in Time-Constrained Setting .
J.6 Additional Results under Client Sampling .
.
J.7 Convergence Plots .

Fully Decentralized Federated Expectation-Maximization .
.
.
.
.
.
.
.

FedEM and Clustering .

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.
.
.
.

.
.
.

.
.
.

.
.
.

.
.
.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

.
.
.

.
.
.

.
.
.

.
.

.
.
.
.
.
.
.

15

16

20

22

25
25
27

29

30
30
30
31

32
32
45
59

63
64
67
68

69
69
70

71
71
71
71
72
72
74
74

(12)

(13)

(14)

A Proof of Proposition 2.1

For h ∈ H and (x, y) ∈ X × Y, let ph (y|x) denote the conditional probability distribution of y given
x under model h, i.e.,

ph (y|x) (cid:44) ech(x) × exp

− l (h (x) , y)

(cid:110)

(cid:111)
,

where

ch (x) (cid:44) − log

(cid:20)(cid:90)

(cid:110)

exp

− l (h (x) , y)

(cid:111)

(cid:21)

d y

.

y∈Y

We also remind that the entropy of a probability distribution q over Y is given by

H (q) (cid:44) −

(cid:90)

y∈Y

q (y) · log q (y) d y,

and that the Kullback-Leibler divergence between two probability distributions q1 and q2 over Y is
given by

KL (q1||q2) (cid:44)

(cid:90)

y∈Y

q1 (y) · log

q1 (y)
q2 (y)

d y.

(15)

Proposition 2.1. Let l(·, ·) be the mean squared error loss, the logistic loss or the cross-entropy loss,
and ˘Θ and ˘Π be a solution of the following optimization problem:

minimize
Θ,Π

E
t∼DT

E
(x,y)∼Dt

[− log pt(x, y|Θ, πt)] ,

where DT is any distribution with support T . Under Assumptions 1, 2, and 3, the predictors

h∗
t =

M
(cid:88)

m=1

˘πtmh˘θm

,

∀t ∈ T

minimize E(x,y)∼Dt [l(ht(x), y)] and thus solve Problem (1).

(4)

(5)

Proof. We prove the result for each of the three possible cases of the loss function. We verify that ch
does not depend on h in each of the three cases, then we use Lemma A.3 to conclude.

Mean Squared Error Loss This is the case of a regression problem where Y = Rd for some
d > 0. For x, y ∈ X × Y and h ∈ H, we have

ph (y|x) =

1

(cid:113)

(2π)d

(cid:40)

· exp

−

(cid:107)h (x) − y(cid:107)2
2

(cid:41)

,

and

ch (x) = − log

(cid:18)(cid:113)

(cid:19)

(2π)d

(16)

(17)

Logistic Loss This is the case of a binary classiﬁcation problem where Y = {0, 1}. For x, y ∈
X × Y and h ∈ H, we have

and

ph (y|x) = (h (x))y · (1 − h (x))1−y ,

ch (x) = 0

(18)

(19)

Cross-entropy loss This is the case of a classiﬁcation problem where Y = [L] for some L > 1.
For x, y ∈ X × Y and h ∈ H, we have

and

ph (y|x) =

L
(cid:89)

l=1

(h (x))

1{y=l} ,

ch (x) = 0

16

(20)

(21)

(23)

(24)

(25)

(26)

(27)

(28)

(29)

Conclusion For t ∈ T , consider a predictor h∗
Lemma A.3, for (x, y) ∈ X × Y, we have

t minimizing E(x,y)∼Dt [l(ht(x), y)]. Using

ph∗

t

(y|x) =

M
(cid:88)

m=1

˘πtm · pm

(cid:16)

y|x, ˘θm

(cid:17)

.

(22)

We multiply both sides of this equality by y and we integrate over y ∈ Y. Note that in all three cases
we have

(cid:90)

∀x ∈ X ,

y · ph (·|x) d y = h(x).

y∈Y

h∗
t =

M
(cid:88)

m=1

˘πtmh˘θm

,

∀t ∈ T .

It follows that

Supporting Lemmas

Lemma A.1. Suppose that Assumptions 1 and 3 hold, and consider ˘Θ and ˘Π to be a solution of
Problem (4). Then

pt(x, y| ˘Θ, ˘πt) = pt(x, y|Θ∗, π∗

t ), ∀t ∈ T .

Proof. For t ∈ T ,
(cid:105)
(cid:104)
− log pt(x, y| ˘Θ, ˘πt)

E
(x,y)∼Dt

(cid:90)

= −

(x,y)∈X ×Y

(cid:90)

= −

(x,y)∈X ×Y

(cid:90)

−

(x,y)∈X ×Y
(cid:16)

pt(x, y|Θ∗, π∗

t ) · log pt(x, y| ˘Θ, ˘πt) d x d y

pt(x, y|Θ∗, π∗

t ) · log

pt(x, y| ˘Θ, ˘πt)
pt(x, y|Θ∗, π∗
t )

d x d y

pt(x, y|Θ∗, π∗

t ) · log pt(x, y|Θ∗, π∗

t ) d x d y

= KL

pt (·|Θ∗, π∗

t ) (cid:107)pt

(cid:0) · | ˘Θ, ˘πt

(cid:1)(cid:17)

+ H [pt (·|Θ∗, π∗

t )] ,

Since the KL divergence is non-negative, we have

(cid:104)

E
(x,y)∼Dt

− log pt(x, y| ˘Θ, ˘πt)

(cid:105)

≥ H [pt (·|Θ∗, π∗

t )] =

E
(x,y)∼Dt

[− log pt(x, y|Θ∗, π∗

t )] .

(30)

Taking the expectation over t ∼ DT , we write
(cid:105)
− log pt(x, y| ˘Θ, ˘πt)

(cid:104)

E
t∼DT

E
(x,y)∼Dt

≥ E
t∼DT

E
(x,y)∼Dt

[− log pt(x, y|Θ∗, π∗

t )] .

(31)

Since ˘Θ and ˘Π is a solution of Problem (4), we also have

E
t∼DT

E
(x,y)∼Dt

(cid:104)

(cid:105)
− log pt(x, y| ˘Θ, ˘πt)

≤ E
t∼DT

E
(x,y)∼Dt

[− log pt(x, y|Θ∗, π∗

t )] .

(32)

Combining (31), (32), and (29), we have

(cid:16)

KL

E
t∼DT

pt (·|Θ∗, π∗

t ) (cid:107)pt

(cid:0) · | ˘Θ, ˘πt

(cid:1)(cid:17)

= 0.

(33)

Since KL divergence is non-negative, and the support of DT is the countable set T , it follows that

Thus,

∀t ∈ T , KL

(cid:16)

pt (·|Θ∗, π∗

t ) (cid:107)pt

(cid:0) · | ˘Θ, ˘πt

(cid:1)(cid:17)

= 0.

pt(x, y| ˘Θ, ˘πt) = pt(x, y|Θ∗, π∗

t ),

∀t ∈ T .

(34)

(35)

17

Lemma A.2. Consider M probability distributions on Y, that we denote qm, m ∈ [M ], and
α = (α1, . . . , αm) ∈ ∆M . For any probability distribution q over Y, we have

M
(cid:88)

m=1

(cid:32)

αm · KL

qm(cid:107)

(cid:33)

αm(cid:48) · qm(cid:48)

≤

M
(cid:88)

m(cid:48)=1

M
(cid:88)

m=1

αm · KL (qm(cid:107)q) ,

(36)

with equality if and only if,

q =

M
(cid:88)

m=1

αm · qm.

Proof.

M
(cid:88)

m=1

αm · KL (qm(cid:107)q) −

M
(cid:88)

m=1

(cid:32)

αm · KL

qm(cid:107)

(cid:33)

αm(cid:48) · qm(cid:48)

M
(cid:88)

m(cid:48)=1

=

M
(cid:88)

m=1

(cid:34)

(cid:32)

αm ·

KL (qm(cid:107)q) − KL

qm(cid:107)

(cid:33)(cid:35)

αm(cid:48) · qm(cid:48)

M
(cid:88)

m(cid:48)=1

M
(cid:88)

m=1
(cid:90)

= −

= −

(cid:90)

αm

y∈Y

(cid:32)

qm (y) · log

(cid:33)

(cid:80)M

q (y)
m(cid:48)=1 αm(cid:48) · qm(cid:48) (y)
(cid:32)

(cid:41)

(cid:40) M
(cid:88)

αm · qm (y)

· log

q (y)
m(cid:48)=1 αm(cid:48) · qm(cid:48) (y)

(cid:80)M

y∈Y
(cid:32) M
(cid:88)

= KL

m=1

(cid:33)

αm · qm(cid:107)q

≥ 0.

m=1

The equality holds, if and only if,

q =

M
(cid:88)

m=1

αm · qm.

(37)

(38)

(39)

(40)

(41)

(42)

(cid:33)

d y

Lemma A.3. Consider ˘Θ and ˘Π to be a solution of Problem (4). Under Assumptions 1, 2, and 3,
t , t ∈ T , minimizing E(x,y)∼Dt [l(ht(x), y)],
if ch does not depend on h ∈ H, then the predictors h∗
verify for (x, y) ∈ X × Y

ph∗

t

(y|x) =

M
(cid:88)

m=1

˘πtm · pm

(cid:16)

y|x, ˘θm

(cid:17)

.

(43)

Proof. For t ∈ T and ht ∈ H, under Assumptions 1, 2, and 3, we have

l(ht(x), y) · pt (x, y|Θ∗, π∗

t ) d x d y.

(44)

l(ht(x), y) · pt

(cid:16)

x, y| ˘Θ, ˘πt

(cid:17)

d x d y.

E(x,y)∼Dt [l(ht(x), y)] =

Using Lemma A.1, it follows that

E(x,y)∼Dt [l(ht(x), y)] =

(cid:90)

x,y∈X ×Y

(cid:90)

x,y∈X ×Y

Thus, using Assumptions 1 and 2 we have,
E(x,y)∼Dt [l(ht(x), y)]

(cid:90)

=

=

l(ht(x), y) · pt

(cid:16)

x, y| ˘Θ, ˘πt

(cid:17)

d x d y

x,y∈X ×Y

(cid:90)

x,y∈X ×Y

l(ht(x), y) ·

(cid:32) M
(cid:88)

m=1

˘πtm · pm

(cid:16)

y|x, ˘θm

(cid:33)

(cid:17)

p (x) d x d y

18

(45)

(46)

(47)

(48)

(cid:90)

=

x∈X

(cid:90)

=

(cid:34) M
(cid:88)

m=1

(cid:34) M
(cid:88)

x∈X

m=1

(cid:90)

˘πtm

l(ht(x), y) · pm

(cid:16)

y|x, ˘θm

(cid:17)

(cid:35)

d y

p (x) d x

y∈Y

(cid:26)

˘πtm

cht (x) −

(cid:90)

y∈Y

(cid:16)
y|x, ˘θm

(cid:17)

pm

(cid:27)(cid:35)

log pht (y|x) d y

p (x) d x

(cid:34)

(cid:34)

(cid:90)

=

x∈X

(cid:90)

=

x∈X

(cid:90)

+

cht (x) −

cht (x) +

M
(cid:88)

m=1

M
(cid:88)

m=1

(cid:90)

˘πtm

y∈Y

(cid:16)
y|x, ˘θm

(cid:17)

pm

(cid:35)

log pht (y|x) d y

p (x) d x

˘πtm · H

(cid:16)

(cid:16)

pm

·|x, ˘θm

(cid:35)

(cid:17)(cid:17)

p (x) d x

(cid:34) M
(cid:88)

˘πtm · KL

(cid:16)

pm

(cid:0) · |x, ˘θm

(cid:1)(cid:107)pht (·|x)

(cid:35)

(cid:17)

p (x) d x.

x∈X

m=1

Let h◦

t be a predictor satisfying the following equality:

ph◦

t

(y|x) =

M
(cid:88)

m=1

˘πtm · pm

(cid:16)

y|x, ˘θm

(cid:17)

.

Using Lemma A.2, we have

˘πtm · KL

(cid:16)

pm

(cid:0) · |x, ˘θm

(cid:17)
(cid:1)(cid:107)pht (·|x)

≥

M
(cid:88)

m=1

M
(cid:88)

m=1

˘πtm · KL

(cid:16)

pm

(cid:0) · |x, ˘θm

(cid:1)(cid:107)ph◦

t

(cid:17)

(·|x)

with equality if and only if

Since ch does not depend on h, replacing (53) in (52), it follows that

pht (·|x) = ph◦

t

(·|x) .

(49)

(50)

(51)

(52)

(53)

(54)

E(x,y)∼Dt [l(ht(x), y)] ≥ E(x,y)∼Dt [l(h◦

This inequality holds for any predictor ht and in particular for h∗
for which it also holds the opposite inequality, then:

t (x), y)] .
(55)
t ∈ arg min E(x,y)∼Dt [l(ht(x), y)],

(56)

(57)

E(x,y)∼Dt [l(h∗

t (x), y)] = E(x,y)∼Dt [l(h◦

t (x), y)] ,

and the equality implies that

ph∗

t

(·|x) = ph◦

t

(·|x) =

˘πtm · pm

(cid:16)

·|x, ˘θm

(cid:17)

.

M
(cid:88)

m=1

19

B Relation with Other Multi-Task Learning Frameworks

In this appendix, we give more details about the relation of our formulation with existing frameworks
for (federated) MTL sketched in Section 2.3. We suppose that Assumptions 1–3 hold and that each
client learns a predictor of the form (5). Note that this is more general than [67], where each client
learns a personal hypothesis as a weighted combination of a set of M base known hypothesis, since
the base hypothesis and not only the weights are learned in our case.

Alternating Structure Optimization [70]. Alternating structure optimization (ASO) is a popular
MTL approach that learns a shared low-dimensional predictive structure on hypothesis spaces from
multiple related tasks, i.e., all tasks are assumed to share a common feature space P ∈ Rd(cid:48)×d, where
d(cid:48) ≤ min(T, d) is the dimensionality of the shared feature space and P has orthonormal columns
(P P (cid:124) = Id(cid:48)), i.e., P is semi-orthogonal matrix. ASO leads to the following formulation:

minimize
W,P :P P (cid:124)=Id(cid:48)

t=1

i=1

T
(cid:88)

nt(cid:88)

(cid:16)

l

hwt

(cid:16)

x(i)
t

(cid:17)

, y(i)
t

(cid:17)

+ α (tr (W W (cid:124)) − tr (W P (cid:124)P W (cid:124))) + β tr (W W (cid:124)) ,

(58)
where α ≥ 0 is the regularization parameter for task relatedness and β ≥ 0 is an additional L2
regularization parameter.

When the hypothesis (hθ)θ are assumed to be linear, Eq. (5) can be written as W = ΠΘ. Writing
the LQ decomposition6 of matrix Θ, i.e., Θ = LQ, where L ∈ RM ×M is a lower triangular matrix
and Q ∈ RM ×d is a semi-orthogonal matrix (QQ(cid:124) = IM ), (5) becomes W = ΠLQ ∈ RT ×d, thus,
W = W Q(cid:124)Q, leading to the constraint (cid:107)W − W Q(cid:124)Q(cid:107)2
F = tr (W W (cid:124)) − tr (W Q(cid:124)QW (cid:124)) = 0.
If we assume (cid:107)θm(cid:107)2
2 to be bounded by a constant B > 0 for all m ∈ [M ], we get the constraint
(cid:16)
tr (W W (cid:124)) ≤ T B. It means that minimizing (cid:80)T
, y(i)
under our Assump-
t
tion 1 can be formulated as the following constrained optimization problem

(cid:16)
x(i)
t

i=1 l

(cid:80)nt

hwt

t=1

(cid:17)

(cid:17)

minimize
W,Q:QQ(cid:124)=IM

subject to

T
(cid:88)

nt(cid:88)

(cid:16)

l

hwt

(cid:16)

x(i)
t

(cid:17)

, y(i)
t

(cid:17)

,

i=1

t=1
tr {W W (cid:124)} − tr {W Q(cid:124)QW (cid:124)} = 0,
tr (W W (cid:124)) ≤ T B.

(59)

Thus, there exists Lagrange multipliers α ∈ R and β > 0, for which Problem (59) is equivalent to
the following regularized optimization problem

minimize
W,Q:QQ(cid:124)=IM

T
(cid:88)

nt(cid:88)

t=1

i=1

(cid:16)

l

hwt

(cid:16)

x(i)
t

(cid:17)

, y(i)
t

(cid:17)

which is exactly Problem (58).

+ α (tr {W W (cid:124)} − tr {W Q(cid:124)QW (cid:124)}) + β tr {W W (cid:124)} ,

(60)

Federated MTL via task relationships. The ASO formulation above motivated the authors of [59]
to learn personalized models by solving the following problem

min
W,Ω

T
(cid:88)

nt(cid:88)

t=1

i=1

(cid:16)

l

hwt

(cid:16)

x(i)
t

(cid:17)

, y(i)
t

(cid:17)

+ λ tr (W ΩW (cid:124)) ,

(61)

Two alternative MTL formulations are presented in [59] to justify Problem (61): MTL with prob-
abilistic priors [69] and MTL with graphical models [35]. Both of them can be covered using our
Assumption 1 as follows:

• Considering T = M and Π = IM in Assumption 1 and introducing a prior on Θ of the

form

Θ ∼

(cid:16)(cid:89)

N (cid:0)0, σ2Id

(cid:1)(cid:17)

MN (Id ⊗ Ω)

(62)

lead to a formulation similar to MTL with probabilistic priors [69].

6Note that when Θ is a full rank matrix, this decomposition is unique.

20

• Two tasks t and t(cid:48) are independent if (cid:104)πt, πt(cid:48)(cid:105) = 0, thus using Ωt,t(cid:48) = (cid:104)πt, πt(cid:48)(cid:105) leads to the

same graphical model as in [35].

Several personalized FL formulations, e.g., pFedMe[16], FedU [17] and the formulation studied in
[24] and in [23], are special cases of formulation (62).

21

C Centralized Expectation Maximization

Proposition 3.1. Under Assumptions 1 and 2, at the k-th iteration the EM algorithm updates
parameter estimates through the following steps:

E-step:

qk+1
t

(z(i)

t = m) ∝ πk

tm · exp

(cid:16)

−l(hθk

m

(x(i)

t ), y(i)
t )

(cid:17)

,

t ∈ [T ], m ∈ [M ], i ∈ [nt]

(8)

M-step:

πk+1
tm =

,

t ∈ [T ], m ∈ [M ]

(9)

θk+1
m ∈ arg min

qk+1
t

(z(i)

t = m)l(cid:0)hθ(x(i)

t ), y(i)

t

(cid:1),

m ∈ [M ] (10)

t = m)

(cid:80)nt

t

(z(i)
i=1 qk+1
nt
T
(cid:88)

nt(cid:88)

θ∈Rd

t=1

i=1

Proof. The objective is to learn parameters { ˘Θ, ˘Π} from the data S1:T by maximizing the likelihood
p (S1:T |Θ, Π). We introduce functions qt(z), t ∈ [T ] such that qt ≥ 0 and (cid:80)M
z=1 qt(z) = 1 in the
expression of the likelihood. For Θ ∈ RM ×d and Π ∈ ∆T ×M , we have

log p(S1:T |Θ, Π) =

=

≥

=

T
(cid:88)

nt(cid:88)

t=1

i=1

T
(cid:88)

nt(cid:88)

log pt

(cid:16)

s(i)
t

|Θ, πt

(cid:17)





M
(cid:88)





log

(cid:16)

s(i)
t

pt

qt

t=1

i=1

m=1

(cid:16)

qt

(cid:17)

z(i)
t = m

log

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

(cid:17)



 qt

(cid:16)

z(i)
t = m

(cid:17)





, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m
(cid:16)

(cid:17)

pt

s(i)
t

(cid:17)

, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m

(cid:17)

qt

(cid:16)

qt

(cid:17)

z(i)
t = m

log pt

(cid:16)

s(i)
t

, z(i)

t = m|Θ, πt

(cid:17)

T
(cid:88)

nt(cid:88)

M
(cid:88)

−

(cid:16)

qt

z(i)
t = m

(cid:17)

log qt

(cid:16)

z(i)
t = m

(cid:17)

(63)

(64)

(65)

(66)

i=1

t=1
(cid:44) L(Θ, Π, Q1:T ),

m=1

(67)
where we used Jensen’s inequality because log is concave. L(Θ, Π, Q1:T ) is an evidence lower bound.
The centralized EM-algorithm corresponds to iteratively maximizing this bound with respect to Q1:T
(E-step) and with respect to {Θ, Π} (M-step).

E-step. The difference between the log-likelihood and the evidence lower bound L(Θ, Π, Q1:T )
can be expressed in terms of a sum of KL divergences:
logp(S1:T |Θ, Π) − L(Θ, Π, Q1:T ) =

=

=

=

=

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

t=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

t=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

t=1

m=1

T
(cid:88)

nt(cid:88)

t=1

i=1






log pt

(cid:16)

s(i)
t

|Θ, πt

M
(cid:88)

(cid:17)

−

(cid:16)

qt

(cid:17)

z(i)
t = m

log

m=1

(cid:16)

qt

(cid:17)

z(i)
t = m



log pt

(cid:16)

s(i)
t

|Θ, πt

(cid:17)

− log

(cid:16)

qt

(cid:17)

z(i)
t = m

log

(cid:16)

pt

s(i)
t
(cid:16)

|Θ, πt

(cid:17)

(cid:16)

· qt

z(i)
t = m

(cid:16)

qt

(cid:17)

z(i)
t = m

log

(cid:16)

pt

t = m|Θ, πt
(cid:17)

pt

, z(i)

s(i)
t
(cid:16)
z(i)
qt
t = m
t = m|s(i)
z(i)

t

(cid:17)

, Θ, πt

22

(cid:16)

s(i)
t

pt

qt

(cid:16)

s(i)
t

pt

qt
(cid:17)

(cid:17)

, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m

(cid:17)

, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m

(cid:17)

(cid:17)






(cid:17)





(68)

(69)

(70)

(71)

=

T
(cid:88)

nt(cid:88)

t=1

i=1

KL

(cid:16)

(cid:16)

qt

z(i)
t

(cid:17)

||pt

(cid:16)

z(i)
t

|s(i)
t

, Θ, πt

(cid:17)(cid:17)

≥ 0.

For ﬁxed parameters {Θ, Π}, the maximum of L(Θ, Π, Q1:T ) is reached when

T
(cid:88)

nt(cid:88)

t=1

i=1

KL

(cid:16)

(cid:16)

qt

z(i)
t

(cid:17)

||pt

(cid:16)

z(i)
t

|s(i)
t

, Θ, πt

(cid:17)(cid:17)

= 0.

Thus for t ∈ [T ] and i ∈ [nt], we have:
qt(z(i)

t = m) = pt(z(i)
pt(s(i)
t

t

t = m|s(i)
|z(i)

, Θ, πt)
t = m, Θ, πt) × pt(z(i)
s(i)
t

|Θ, πt

pt

(cid:17)

(cid:16)

t = m|Θ, πt)

=

=

=

=

(cid:80)M

pm(s(i)
t
m(cid:48)=1 pm(cid:48)(s(i)
(cid:16)

pm

|θm) × πtm

t ) × πtm(cid:48)
(cid:17)
|x(i)
t
y(i)
t

|x(i)
t

, θm

y(i)
t
(cid:16)

(cid:80)M

m(cid:48)=1 pm(cid:48)
(cid:16)

pm

(cid:80)M

m(cid:48)=1 pm(cid:48)

y(i)
t
(cid:16)

|x(i)
t
y(i)
t

, θm(cid:48)
(cid:17)

, θm

|x(i)
t

, , θm(cid:48)

× pm
(cid:17)

(cid:16)

(cid:17)

x(i)
t
(cid:16)

× pm(cid:48)
(cid:17)
(cid:16)

x(i)
t
(cid:16)

× p

× p
(cid:17)

× πtm
(cid:17)

x(i)
t

× πtm(cid:48)

× πtm
(cid:17)

x(i)
t

,

× πtm(cid:48)

where (77) relies on Assumption 2. It follows that

qt(z(i)

t = m) = pt(z(i)

t = m|s(i)

t

, Θ, πt) =

(cid:16)

pm

|x(i)
y(i)
t
t
(cid:16)
y(i)
t

(cid:17)

, θm

× πtm
(cid:17)

(cid:80)M

m(cid:48)=1 pm(cid:48)

|x(i)
t

, θm(cid:48)

× πtm(cid:48)

(72)

(73)

(74)

(75)

(76)

(77)

.

(78)

M-step. We maximize now L(Θ, Π, Q1:T ) with respect to {Θ, Π}. By dropping the terms not
depending on {Θ, Π} in the expression of L(Θ, Π, Q1:T ) we write:
L(Θ, Π, Q1:T )
M
T
(cid:88)
(cid:88)

nt(cid:88)

(cid:16)

(cid:16)

(cid:17)

(cid:17)

qt

z(i)
t = m

log pt

s(i)
t

, z(i)

t = m|Θ, πt

+ c

(79)

=

t=1

i=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

T
(cid:88)

nt(cid:88)

M
(cid:88)

t=1

i=1

m=1

=

=

=

=

(cid:16)

qt

z(i)
t = m

(cid:17) (cid:104)

log pt

(cid:16)

s(i)
t

|z(i)

t = m, Θ, πt

(cid:17)

+ log pt

(cid:16)
z(i)
t = m|Θ, πt

(cid:17) (cid:105)

+ c

(cid:16)

qt

z(i)
t = m

(cid:17) (cid:104)

log pθm

(cid:17)

(cid:16)

s(i)
t

+ log πtm

(cid:105)

+ c

(cid:16)

qt

z(i)
t = m

(cid:17) (cid:104)

log pθm

(cid:16)

qt

z(i)
t = m

(cid:17) (cid:104)

log pθm

(cid:16)

(cid:16)

y(i)
t

|x(i)
t

y(i)
t

|x(i)
t

(cid:17)

(cid:17)

+ log pm

(cid:17)

(cid:16)

x(i)
t

+ log πtm

(cid:105)

+ c

+ log πtm

(cid:105)

+ c(cid:48),

(80)

(81)

(82)

(83)

(84)

where c and c(cid:48) are constant not depending on {Θ, Π}.

Thus, for t ∈ [T ] and m ∈ [M ], by solving a simple optimization problem we update πtm as follows:

πtm =

(cid:80)nt

i=1 qt(z(i)

t = m)

nt

23

.

(85)

hθ(x(i)

t ), y(i)

t

(cid:17)

.

(86)

On the other hand, for m ∈ [M ], we update θm by solving:

θm ∈ arg min

θ∈Rd

T
(cid:88)

nt(cid:88)

t=1

i=1

qt(z(i)

t = m) × l

(cid:16)

24

D Detailed Algorithms

D.1 Client-Server Algorithm

Alg. 2 is a detailed version of Alg. 1 (FedEM), with local SGD used as local solver.

Alg. 3 gives our general algorithm for federated surrogate optimization, from which Alg. 2 is derived.

Algorithm 2: FedEM: Federated Expectation-Maximization
Input

: Data S1:T ; number of mixture components M ; number of communication rounds K;
number of local steps J
m for 1 ∈ [M ]; πK
t

for t ∈ [T ]

Output :θK
// Initialization

m ∈ Rd for 1 ≤ m ≤ M ;
1 server randomly initialize θ0
2 for tasks t = 1, . . . , T in parallel over T clients do
3

Randomly initialize π0

t ∈ ∆M ;

// Main loop

4 for iterations k = 1, . . . , K do
server broadcasts θk−1
5
for tasks t = 1, . . . , T in parallel over T clients do

m , 1 ≤ m ≤ M to the T clients;

6

7

8

9

10

11

12

13

14

for component m = 1, . . . , M do

// E-step
for sample i = 1, . . . , nt do
πk

(cid:16)

(cid:17)

qk
t

z(i)
t = m

←

(cid:16)

tm·exp

−l(hθk
m
(cid:18)

(cid:17)

(x(i)

t ),y(i)
t )
t ),y(i)
(x(i)
t )

(cid:19) ;

(cid:80)M

m(cid:48)=1 πk

tm(cid:48) ·exp

−l(hθk
m(cid:48)

// M-step
(cid:80)nt
πk
tm ←
m,t ← LocalSolver(J, m, θk−1
θk

t (z(i)
nt

t =m)

i=1 qk

;

t , St) ;
m,t, 1 ≤ m ≤ M to the server;

m , qk

client t sends θk

for component m = 1, . . . , M do

m ← (cid:80)T
θk

t=1

nt
n · θk

m,t;

15 Function LocalSolver(J, m, θ, q, S):
16

for j = 0, . . . , J − 1 do

17

18

19

Sample indexes I uniformly from 1, . . . , |S|;
i∈I q(z(i) = m) · ∇θl (cid:0)hθ
θ ← θ − ηk−1,j

(cid:80)

return θ;

(cid:0)x(i)(cid:1) , y(i)(cid:1);

25

Algorithm 3: Federated Surrogate Optimization

: u0 ∈ Rdu; V0 = (cid:0)v0

(cid:1)

1≤t≤T ∈ V T ; number of iterations K; number of local steps J

t

Input
Output : uK; vK
t

1 for iterations k = 1, . . . , K do
2

server broadcasts uk−1 to the T clients;
for tasks t = 1, . . . , T in parallel over T clients do
Compute partial ﬁrst-order surrogate function gk
(cid:0)uk−1, v(cid:1);
vk

v∈V

gk
t ← arg min
t
t ← LocalSolver(J, uk−1
uk
client t sends uk
t to the server;
t=1 ωt · uk
t ;

t

uk ← (cid:80)T

, vk−1
t

, gk

t , St);

3

4

5

6

7

8

t of ft near (cid:8)uk−1, vk−1

t

(cid:9);

9 Function LocalSolver(J, u, v, g, S):
10

for j = 0, . . . , J − 1 do

11

12

13

sample ξk−1,j from S;
u ← u − ηk−1,j · ∇ug(u, v; ξk−1,j);

return Θ;

26

D.2 Fully Decentralized Algorithm

Alg. 4 shows D-FedEM, the fully decentralization version of our federated expectation maximization
algorithm.

Alg. 5 gives our general fully decentralized algorithm for federated surrogate optimization, from
which Alg. 4 is derived.

Algorithm 4: D-FedEM: Fully Decentralized Federated Expectation-Maximization
Input

: Data S1:T ; number of mixture components M ; number of iterations K; number of
local steps J; mixing matrix distributions W k for k ∈ [K]

Output : θK
// Initialization

m,t for m ∈ [M ] and t ∈ [T ]; πt for t ∈ [T ]

1 for tasks t = 1, . . . , T in parallel over T clients do
2

Randomly initialize Θt = (θm,t)1≤m≤M ∈ RM ×d ;
t ∈ ∆M ;
Randomly initialize π0

3

// Main loop

4 for iterations k = 1, . . . , K do

// Select the communication topology and the aggregation weights
Sample W k−1 ∼ W k−1;
for tasks t = 1, . . . , T in parallel over T clients do

for component m = 1, . . . , M do

// E-step
for sample i = 1, . . . , nt do
πk

(cid:16)

(cid:17)

qk
t

z(i)
t = m

←

(cid:16)

tm·exp

−l(hθk
m
(cid:18)

(cid:17)

(x(i)

t ),y(i)
t )
t ),y(i)
(x(i)
t )

(cid:19) ;

(cid:80)M

m(cid:48)=1 πk

tm(cid:48) ·exp

−l(hθk
m(cid:48)

2

;

i=1 qk

t =m)

t (z(i)
nt

// M-step
(cid:80)nt
πk
tm ←
θk− 1
m,t ← LocalSolver(J, m, θk−1
Send θk− 1
m,t , 1 ≤ m ≤ M to neighbors;
Receive θk− 1
for component m = 1, . . . , M do

2

2

m,s , 1 ≤ m ≤ M from neighbors;

m,t , qk

t , St, t);

m,t ← (cid:80)T
θk

s=1 wk−1

s,t

· θk− 1
m,s ;

2

5

6

7

8

9

10

11

12

13

14

15

16 Function LocalSolver(J, m, θ, q, S, t):
17

for j = 0, . . . , J − 1 do

18

19

20

Sample indexes I uniformly from 1, . . . , |S|;
(cid:80)
θ ← θ − nt

i∈I q(z(i) = m) · ∇θl (cid:0)hθ

n · ηk−1,j

return θ;

(cid:0)x(i)(cid:1) , y(i)(cid:1);

27

Algorithm 5: Fully-Decentralized Federated Surrogate Optimization

Input

: u0 ∈ Rdu; V0 = (cid:0)v0
t
mixing matrix distributions W k for k ∈ [K]

(cid:1)

1≤t≤T ∈ V T ; number of iterations K; number of local step J;

Output : uK
t

for t ∈ [T ]; vK
t

1 for iterations k = 1, . . . , K do

for t ∈ [T ]

// Select the communication topology and the aggregation weights
Sample W k−1 ∼ W k−1;
for tasks t = 1, . . . , T in parallel over T clients do
compute partial ﬁrst-order surrogate function gk
vk

t of ft near (cid:8)uk−1

(cid:0)uk−1

, vk−1
t

, v(cid:1);

(cid:9);

t

2

3

4

5

6

7

8

9

gk
t

2

t

v∈V

t ← arg min
uk− 1
t ← LocalSolver(J, uk−1
Send uk− 1
to neighbors;
Receive uk− 1
t ← (cid:80)T
uk

from neighbors;
ts × uk− 1

s=1 wk−1

;

s

s

t

t

2

2

2

, vk−1
t

, gk

t , t);

10 Function LocalSolver(J, u, v, g, S, t):
11

for j = 0, . . . , J − 1 do

12

13

14

sample ξk−1,j from S ;
u ← u − ωt · ηk−1,j∇ug(u, v, ξk−1,j);

return u;

28

E Details on the Fully Decentralized Setting

As mentioned in Section 3.3, the convergence of decentralized optimization schemes requires certain
assumptions on the sequence of mixing matrices (W k)k>0, to guarantee that each client can inﬂuence
the estimates of other clients over time. In our paper, we consider the following general assumption.
Assumption 8 ([31, Assumption 4]). Symmetric doubly stochastic mixing matrices are drawn at
each round k from (potentially different) distributions W k ∼ W k and there exists two constants
p ∈ (0, 1], and integer τ ≥ 1 such that for all Ξ ∈ RM ×d×T and all integers l ∈ {0, . . . , K/τ }:

where Wl,τ (cid:44) W (l+1)τ −1 . . . W lτ , ¯Ξ (cid:44) Ξ 11(cid:124)
distributions W k ∼ W k.

E (cid:13)

F ≤ (1 − p) (cid:13)
(cid:13)ΞWl,τ − ¯Ξ(cid:13)
2
(cid:13)
T , and the expectation is taken over the random

(cid:13)Ξ − ¯Ξ(cid:13)
2
F ,
(cid:13)

(87)

Assumption 8 expresses the fact that the sequence of mixing matrices, on average and every τ
communication rounds, brings the values in the columns of Ξ closer to their row-wise average
(thereby mixing the clients’ updates over time). For instance, the assumption is satisﬁed if the
communication graph is strongly connected every τ rounds, i.e., the graph ([T ], E), where the edge
(i, j) belongs to the graph if wh

i,j > 0 for some h ∈ {k + 1, . . . , k + τ } is connected.

We provide below the rigorous statement of Theorem 3.3, which was informally presented in
Section 3.3. It shows that D-FedEM converges to a consensus stationary point of f (proof in App. G.2).
Theorem 3.3. Under Assumptions 1–8, when clients use SGD as local solver with learning rate
η = a0√
, D-FedEM’s iterates satisfy the following inequalities after a large enough number of
K
communication rounds K:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇Θf (cid:0) ¯Θk, Πk(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

nt
n

KL (cid:0)πk

t , πk−1
t

(cid:1) ≤ O

(cid:19)

(cid:18) 1
K

,

(88)

where ¯Θk = (cid:2)Θk
i.e., to ¯Θk:

1, . . . Θk
T

(cid:3) · 11(cid:124)

T . Moreover, individual estimates (cid:0)Θk

t

(cid:1)

1≤t≤T converge to consensus,

E

min
k∈[K]

T
(cid:88)

t=1

(cid:13)
(cid:13)Θk

t − ¯Θk(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

.

29

F Federated Surrogate Optimization

In this appendix, we give more details on the federated surrogate optimization framework introduced
in Section 3.4. In particular, we provide the assumptions under which Alg. 3 and Alg. 5 converge.
We also illustrate how our framework can be used to study existing algorithms.

F.1 Reminder on Basic (Centralized) Surrogate Optimization

In this appendix, we recall the (centralized) ﬁrst-order surrogate optimization framework introduced
in [43]. In this framework, given a continuous function f : Rd (cid:55)→ R, we are interested in solving

using the majoration-minimization scheme presented in Alg. 6.

min
θ∈Rd

f (θ)

Algorithm 6: Basic Surrogate Optimization
: θ0 ∈ Rd; number of iterations K;

Input
Output : θK

1 for iterations k = 1, . . . , K do
2

Compute gk, a surrogate function of f near θk−1;
Update solution: θk ∈ arg minθ gk(θ);

3

This procedure relies on surrogate functions, that approximate well the objective function in a
neighborhood of a point. Reference [43] focuses on ﬁrst-order surrogate functions deﬁned below.
Deﬁnition F.1 (First-Order Surrogate [43]). A function g : Rd (cid:55)→ R is a ﬁrst order surrogate of f
near θk ∈ Rd when the following is satisﬁed:

• Majorization: we have g(θ(cid:48)) ≥ f (θ(cid:48)) for all θ(cid:48) ∈ arg minθ∈Rd g(θ). When the more

general condition g ≥ f holds, we say that g is a majorant function.

• Smoothness: the approximation error r (cid:44) g − f is differentiable, and its gradient is

L-Lipschitz. Moreover, we have r(θk) = 0 and ∇r(θk) = 0.

F.2 Novel Federated Version

As discussed in Section 3.4, our novel federated surrogate optimization framework minimizes an
objective function (u, v1:T ) (cid:55)→ f (u, v1:T ) that can be written as a weighted sum f (u, v1:T ) =
(cid:80)T
t=1 ωtft (u, vt) of T functions. We suppose that each client t ∈ [T ] can compute a partial ﬁrst
order surrogate of ft, deﬁned as follows.
Deﬁnition 1 (Partial ﬁrst-order surrogate). A function g(u, v) : Rdu × V → R is a partial ﬁrst-order
surrogate of f (u, v) wrt u near (u0, v0) ∈ Rdu × V when the following conditions are satisﬁed:

1. g(u, v) ≥ f (u, v) for all u ∈ Rdu and v ∈ V;
2. r(u, v) (cid:44) g(u, v) − f (u, v) is differentiable and L-smooth with respect to u. Moreover,

we have r(u0, v0) = 0 and ∇ur(u0, v0) = 0.

3. g(u, v0) − g(u, v) = dV (v0, v) for all u ∈ Rdu and v ∈ arg minv(cid:48)∈V g(u, v(cid:48)), where dV

is non-negative and dV (v, v(cid:48)) = 0 ⇐⇒ v = v(cid:48).

Under the assumption that each client t can compute a partial ﬁrst order surrogate of ft, we propose
algorithms for federated surrogate optimization in both the client-server setting (Alg. 3) and the fully
decentralized one (Alg. 5). Both algorithms are iterative and distributed: at each iteration k > 0, client
(cid:9)) for
t ∈ [T ] computes a partial ﬁrst-order surrogate gk
federated surrogate optimization in Alg. 3 (resp. for fully decentralized surrogate optimization in
Alg 5).

t of ft near (cid:8)uk−1, vk−1

(cid:9) (resp. (cid:8)uk−1

, vk−1
t

t

t

The convergence of those two algorithms requires the following standard assumptions. Each of them
generalizes one of the Assumptions 4–7 for our EM algorithms.

30

Assumption 4(cid:48). The objective function f is bounded below by f ∗ ∈ R.
Assumption 5(cid:48). (Smoothness) For all t ∈ [T ] and k > 0, gk
Assumption 6(cid:48). (Unbiased gradients and bounded variance) Each client t ∈ [T ] can sample a
random batch ξ from St and compute an unbiased estimator ∇ugk
t (u, v; ξ) of the local gradient with
bounded variance, i.e., Eξ[∇ugk
t (u, v)(cid:107)2 ≤
σ2.
Assumption 7(cid:48). (Bounded dissimilarity) There exist β and G such that

t (u, v) and Eξ(cid:107)∇ugk

t is L-smooth wrt to u.

t (u, v; ξ)] = ∇ugk

t (u, v; ξ)−∇ugk

T
(cid:88)

t=1

ωt ·

(cid:13)
(cid:13)∇ugk
(cid:13)

t (u, v)

(cid:13)
2
(cid:13)
(cid:13)

≤ G2 + β2(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · ∇ugk

t (u, v)

(cid:13)
2
(cid:13)
(cid:13)

.

Under these assumptions a parallel result to Theorem. 3.2 holds for the client-server setting.
Theorem 3.2(cid:48). Under Assumptions 4(cid:48)–7(cid:48), when clients use SGD as local solver with learning rate
η = a0√
, after a large enough number of communication rounds K, the iterates of federated
K
surrogate optimization (Alg. 3) satisfy:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)uk, vk

1:T

(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

k=1

∆vf (uk, vk

1:T ) ≤ O

where the expectation is over the random batches samples, and ∆vf (uk, vk
f (cid:0)uk, vk+1

(cid:1) ≥ 0.

1:T

(cid:18) 1

(cid:19)

,

(89)

K 3/4
1:T ) (cid:44) f (cid:0)uk, vk

1:T

(cid:1) −

In the fully decentralized setting, if in addition to Assumptions 4(cid:48)-7(cid:48), we suppose that Assumption 8
holds, a parallel result to Theorem. 3.3 holds.
Theorem 3.3(cid:48). Under Assumptions 4(cid:48)–7(cid:48) and Assumption 8, when clients use SGD as local solver
with learning rate η = a0√
, after a large enough number of communication rounds K, the iterates of
K
fully decentralized federated surrogate optimization (Alg. 5) satisfy:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤ O

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

T
(cid:88)

ωt · dV

(cid:0)vk

t , vk+1
t

(cid:1) ≤ O

(cid:19)

,

(cid:18) 1
K

k=1

t=1

where ¯uk = 1
T

(cid:80)T

t=1 uk

t . Moreover, local estimates (cid:0)uk

t

(cid:1)

(90)
1≤t≤T converge to consensus, i.e., to ¯uk:

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
(cid:13)

≤ O

(cid:18) 1
√
K

(cid:19)

.

The proofs of Theorem 3.2(cid:48) and Theorem 3.3(cid:48) are in Section G.1 and Section G.2, respectively.

F.3 Illustration: Analyzing pFedMe with Federated Surrogate Optimization

In this section, we show that pFedMe [16] can be studied through our federated surrogate optimization
framework. With reference to the general formulation of pFedMe in [16, Eq. (2) and (3)], consider

gk
t (w) = ft

(cid:0)θk−1(cid:1) +
(cid:110)

λ
2

ft (θ) + λ

· (cid:13)
(cid:13)θk−1 − ω(cid:13)
2
(cid:13)
(cid:13)θ − ωk−1(cid:13)
2 · (cid:13)
(cid:13)

2(cid:111)

,

(91)

. We can verify that gk

t is a

where θk−1 = prox ft
ﬁrst-order surrogate of ft near θk−1:

(cid:0)ωk−1(cid:1) (cid:44) arg minθ

λ

1. It is clear that gk
t
2. Since θk−1 = prox ft

(cid:0)θk−1(cid:1) = ft

(cid:0)θk−1(cid:1).

(cid:0)ωk−1(cid:1), using the envelope theorem (assuming that ft is proper,
(cid:0)ωk−1(cid:1) = λ (cid:0)θk−1 − ωk−1(cid:1) =

λ

convex and lower semi-continuous), it follows that ∇ft
∇gk
k

(cid:0)ωk−1(cid:1).

Therefore, pFedMe can be seen as a particular case of the federated surrogate optimization algorithm
(Alg. 3), to which our convergence results apply.

31

G Convergence Proofs

We study the client-server setting and the fully decentralized setting in Section G.1 and Section G.2,
respectively.
In both cases, we ﬁrst prove the more general result for the federated surrogate
optimization introduced in App. F, and then derive the speciﬁc result for FedEM and D-FedEM.

G.1 Client-Server Setting

G.1.1 Additional Notations

Remark 2. For convenience and without loss of generality, we suppose in this section that ω ∈ ∆T ,
i.e., ∀t ∈ [T ], ωt ≥ 0 and (cid:80)T

t(cid:48)=1 ωt(cid:48) = 1.

At iteration k > 0, we use uk−1,j

t

to denote the j-th iterate of the local solver at client t ∈ [T ], thus

and

uk−1,0
t

= uk−1,

uk =

T
(cid:88)

t=1

ωt · uk−1,J
t

.

(92)

(93)

At iteration k > 0, the local solver’s updates at client t ∈ [T ] can be written as (for 0 ≤ j ≤ J − 1):

uk−1,j+1

t

= uk−1,j
t

− ηk−1,j∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

; ξk−1,j
t

(cid:17)

,

(94)

is the batch drawn at the j-th local update of uk−1

.

t

t

where ξk−1,j
We introduce ηk−1 = (cid:80)J−1
t ∈ [T ] as,

j=0 ηk−1,j, and we deﬁne the normalized update of the local solver at client

ˆδk−1
t

(cid:44) −

uk−1,J
t

− uk−1,0
t

ηk−1

=

(cid:80)J−1

j=0 ηk−1,j · ∇ugk
t
(cid:80)J−1

(cid:16)

j=0 ηk−1,j

uk−1,j
t

, vk−1
t

; ξk−1,j
t

and also deﬁne

With this notation,

δk−1
t

(cid:44)

(cid:80)J−1

j=0 ηk−1,j · ∇ugk
t
ηk−1

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

.

uk − uk−1 = −ηk−1 ·

T
(cid:88)

t=1

ωt · ˆδk−1
t

.

Finally, we deﬁne gk, k > 0 as

gk (u, v1:T ) (cid:44)

T
(cid:88)

t=1

ωt · gk

t (u, vt) .

Note that gk is a convex combination of functions gk

t , t ∈ [T ].

G.1.2 Proof of Theorem 3.2(cid:48)

(cid:17)

,

(95)

(96)

(97)

(98)

Lemma G.1. Suppose that Assumptions 5(cid:48)–7(cid:48) hold. Then, for k > 0, and (ηk,j)0≤j≤J−1 such that
ηk (cid:44) (cid:80)J−1
, the updates of federated surrogate optimization (Alg 3)
verify
(cid:34)

j=0 ηk,j ≤ min

(cid:110) 1
√
2

1
4Lβ

(cid:111)

2L

(cid:35)

,

f (uk, vk

1:T ) − f (uk−1, vk−1
1:T )

E

≤

ηk−1

−

1
4

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

1
ηk−1

T
(cid:88)

t=1

ωt · dV

(cid:0)vk−1

t

, vk
t

(cid:1)

32

+ 2ηk−1L





J−1
(cid:88)

j=0

η2
k−1,j
ηk−1

L + 1


 σ2 + 4η2

k−1L2G2.

(99)

Proof. This proof uses standard techniques from distributed stochastic optimization. It is inspired by
[66, Theorem 1].
For k > 0, gk is L-smooth wrt u, because it is a convex combination of L-smooth functions
gk
t , t ∈ [T ]. Thus, we write

gk (cid:0)uk, vk−1

1:T

(cid:1) − gk (cid:0)uk−1, vk−1

1:T

(cid:1) ≤

(cid:28)

uk − uk−1, ∇ugk(uk−1, vk−1
1:T )

(cid:29)

+

L
2

(cid:13)uk − uk−1(cid:13)
(cid:13)
2
(cid:13)

,

(100)
where < u, u(cid:48) > denotes the scalar product of vectors u and u(cid:48). Using Eq. (97), and taking the
expectation over random batches

, we have

(cid:17)

(cid:16)
ξk−1,j
t

0≤j≤J−1
1≤t≤T

(cid:104)

E

gk(cid:0)uk, vk−1

1:T

(cid:1) − gk (cid:0)uk−1, vk−1

1:T

(cid:1) (cid:105)

≤

(cid:28) T

(cid:88)

− ηk−1 E

t=1

(cid:124)

ωt · ˆδk−1
t

, ∇ugk(uk−1, vk−1
1:T )

(cid:29)

(cid:123)(cid:122)
(cid:44)T1

(cid:125)

+

Lη2
k−1
2

· E

(cid:124)

We bound each of those terms separately. For T1 we have

(cid:28) T

(cid:88)

T1 = E

ωt · ˆδk−1
t

, ∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)

(cid:29)

t=1
(cid:28) T

(cid:88)

= E

t=1

ωt ·

(cid:16)ˆδk−1

t − δk−1

t

(cid:17)

, ∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)

(cid:29)

(cid:28) T

(cid:88)

+ E

ωt · δk−1
t

, ∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)

(cid:29)

.

t=1

Because stochastic gradients are unbiased (Assumption 6(cid:48)), we have

thus,

E

(cid:104)ˆδk−1

t − δk−1

t

(cid:105)

= 0,

(cid:28) T

(cid:88)

T1 = E

ωt · δk−1
t

, ∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)

(cid:29)

t=1



(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)



+ E

=

1
2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

2



−

E

1
2

(cid:13)
(cid:13)
∇ugk (cid:0)uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)

1:T

(cid:1) −

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

For T2 we have for k > 0,

T2 = E

= E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

T
(cid:88)

t=1

ωt · ˆδk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:16)ˆδk−1

t − δk−1

t

ωt ·

(cid:17)

+

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

33

ωt · ˆδk−1
t

T
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

t=1

(cid:123)(cid:122)
(cid:44)T2

.

(101)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:125)

(102)

(103)

(104)

(105)

(106)

(107)

(108)

(cid:29)

(109)

(110)

(111)

(112)

(113)

(cid:17)(cid:105)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ 2 E

= 2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
T
(cid:88)

t=1

T
(cid:88)

t=1

(cid:16)ˆδk−1

t − δk−1

t

ωt ·

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ 2 E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

t · E
ω2

(cid:13)
ˆδk−1
t − δk−1
(cid:13)
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

+ 2

(cid:88)

(cid:28)

ωtωs E

ˆδk−1
t − δk−1

t

1≤s(cid:54)=t≤T

, ˆδk−1

s − δk−1

s

+ 2 E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωtδk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Since clients sample batches independently, and stochastic gradients are unbiased (Assumption 6(cid:48)),
we have

(cid:28)

E

ˆδk−1
t − δk−1

t

, ˆδk−1

s − δk−1

s

= 0,

(cid:29)

thus,

T2 ≤ 2

= 2

T
(cid:88)

t=1

T
(cid:88)

t=1

t · E
ω2

(cid:13)
ˆδk−1
t − δk−1
(cid:13)
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

+ 2 E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωtδk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ω2
t

E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:104)
∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

; ξk−1,j
t

+ 2 E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωtδk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Using Jensen inequality, we have

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:104)
∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

; ξk−1,j
t

(cid:17)(cid:105)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,j
t

, vk−1
t

(cid:17)

(cid:16)

− ∇ugk
t

uk−1,j
t

, vk−1
t

; ξk−1,j
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

,

(114)

and since the variance of stochastic gradients is bounded by σ2 (Assumption 6(cid:48)), it follows that

E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:104)
∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

; ξk−1,j
t

(cid:17)(cid:105)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

σ2 = σ2.

Replacing back in the expression of T2, we have

T2 ≤ 2

T
(cid:88)

t=1

t σ2 + 2 E
ω2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Finally, since 0 ≤ ωt ≤ 1, t ∈ [T ] and (cid:80)T

t=1 ωt = 1, we have

T2 ≤ 2σ2 + 2 E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

(115)

(116)

(117)

Having bounded T1 and T2, we can replace Eq. (106) and Eq. (117) in Eq. (101), and we get
ηk−1
2

1:T ) − gk(uk−1, vk−1
1:T )

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1

(cid:104)
E
gk(uk, vk−1

k−1Lσ2

+ η2

(cid:1)(cid:13)
2
(cid:13)

≤ −

1:T

(cid:105)

34

−

ηk−1
2

(1 − 2Lηk−1) · E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+

ηk−1
2

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1
E
(cid:13)

1:T

(cid:1) −

T
(cid:88)

t=1

ωt · δk−1
t

(cid:13)
2
(cid:13)
(cid:13)

.

≤ 1

2L , we have

As ηk−1 ≤ 1
√

2

2L

(cid:104)
E
gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

(cid:105)

≤ −

ηk−1
2

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+ η2

k−1Lσ2

+

ηk−1
2
Replacing ∇ugk (cid:0)uk−1, vk−1
t=1 ωt · ∇ugk
t
bound the last term in the RHS of Eq. (119), we have

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1
E
(cid:13)
(cid:1) = (cid:80)T

1:T

1:T

(cid:1) −

T
(cid:88)

t=1

ωtδk−1
t

(cid:13)
2
(cid:13)
(cid:13)

.

(cid:0)uk−1, vk−1

(cid:1), and using Jensen inequality to

t

(cid:104)
E
gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

(cid:105)

≤ −

ηk−1
2

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+ η2

k−1Lσ2

+

ηk−1
2

T
(cid:88)

t=1

(cid:13)
ωt · E
(cid:13)∇ugk
(cid:13)
(cid:124)

t

(cid:0)uk−1, vk−1
(cid:123)(cid:122)
(cid:44)T3

t

(cid:1) − δk−1

t

.

(cid:13)
2
(cid:13)
(cid:13)
(cid:125)

We now bound the term T3:
(cid:0)uk−1, vk−1

t

(cid:1) − δk−1

t

(cid:13)
2
(cid:13)
(cid:13)

t

= E

(cid:13)
T3 = E
(cid:13)∇ugk
(cid:13)
(cid:13)
(cid:13)
(cid:13)
∇ugk
(cid:13)
t
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
J−1
(cid:88)

J−1
(cid:88)

= E

j=0

≤

ηk−1,j
ηk−1

j=0

J−1
(cid:88)

j=0

≤

(cid:0)uk−1, vk−1

t

(cid:1) −

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:16)

∇ugk
t

uk−1,j
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ηk−1,j
ηk−1

(cid:104)

∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)(cid:105)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

E

(cid:13)
(cid:13)∇ugk
(cid:13)

t

(cid:0)uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

ηk−1,j
ηk−1

L2E

(cid:13)
(cid:13)uk−1 − uk−1,j
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

,

(118)

(119)

(120)

(121)

(122)

(123)

(124)

(125)

where the ﬁrst inequality follows from Jensen inequality and the second one follow from the
(cid:13)
(cid:13)
L-smoothness of gk
(cid:13) for j ∈
{0, . . . , J − 1} and t ∈ [T ],
(cid:13)
(cid:13)
(cid:13)uk−1 − uk−1,j
(cid:13)uk−1,j
(cid:13)
(cid:13)

t (Assumption 5(cid:48)). We bound now the term E

(cid:13)
(cid:13)uk−1 − uk−1,j
(cid:13)

− uk−1,0
t

(126)

(cid:13)
2
(cid:13)
(cid:13)

(cid:13)
2
(cid:13)
(cid:13)

= E

E

t

t

t

(cid:16)

uk−1,l+1

t

− uk−1,l
t

(cid:17)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ηk−1,l∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

; ξk−1,l
t

(cid:17)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

l=0

j−1
(cid:88)

j−1
(cid:88)

= E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
l=0
(cid:13)
(cid:13)
≤ 2E
(cid:13)
(cid:13)
(cid:13)

= E

j−1
(cid:88)

l=0

ηk−1,l

(cid:104)

∇ugk
t

(cid:16)
uk−1,l
t

, vk−1
t

; ξk−1,l
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)(cid:105)

+ 2E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

j−1
(cid:88)

l=0

ηk−1,l∇ugk
t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

35

(127)

(128)

(129)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:16)
uk−1,l
t

, vk−1
t

; ξk−1,l
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 2

j−1
(cid:88)

l=0

η2
k−1,l

E

(cid:13)
(cid:13)
∇ugk
(cid:13)
(cid:13)
t
(cid:13)
(cid:13)
(cid:13)
+ 2E
(cid:13)
(cid:13)
(cid:13)

j−1
(cid:88)

l=0

ηk−1,l∇ugk
t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ 2σ2

j−1
(cid:88)

l=0

k−1,l + 2E
η2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

j−1
(cid:88)

l=0

ηk−1,l∇ugk
t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

,

where, in the last two steps, we used the fact that stochastic gradients are unbiased and have bounded
variance (Assumption 6(cid:48)). We bound now the last term in the RHS of Eq. (131),
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ηk−1,l∇ugk
t

uk−1,l
t

, vk−1
t

j−1
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

E

(cid:16)

(cid:17)

(cid:32) j−1
(cid:88)

l(cid:48)=0

E

l=0
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:32) j−1
(cid:88)

(cid:33)

ηk−1,l(cid:48)

·

j−1
(cid:88)

l=0

ηk−1,l
l(cid:48)=0 ηk−1,l(cid:48)

(cid:80)j−1

(cid:16)

∇ugk
t

uk−1,l
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:33)2

ηk−1,l(cid:48)

j−1
(cid:88)

·

l=0

ηk−1,l
l(cid:48)=0 ηk−1,l(cid:48)

(cid:80)j−1

E

(cid:13)
(cid:13)∇ugk
(cid:13)

t

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

ηk−1,l

ηk−1,l

(cid:33)

(cid:33)

·

·

j−1
(cid:88)

l=0

j−1
(cid:88)

l=0

ηk−1,lE

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,l
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

(cid:13)
ηk−1,lE
(cid:13)∇ugk
(cid:13)

t

(cid:16)

uk−1,0
t

, vk−1
t

(cid:17)

≤

=

=

l(cid:48)=0
(cid:32)j−1
(cid:88)

l=0
(cid:32)j−1
(cid:88)

l=0

(cid:16)

(cid:33)

− ∇ugk
t

uk−1,0
t

, vk−1
t

≤2

(cid:32)j−1
(cid:88)

l=0

ηk−1,l

·

j−1
(cid:88)

l=0

ηk−1,l ·

(cid:17)

(cid:34)

(cid:16)

+ ∇ugk
t

uk−1,l
t

, vk−1
t

(cid:17) (cid:13)
2
(cid:13)
(cid:13)

E

(cid:13)
(cid:13)∇ugk
(cid:13)

t

(cid:16)

uk−1,0
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

+ E

(cid:13)
(cid:13)∇ugk
(cid:13)
(cid:33)

t

ηk−1,l

·

=2

(cid:32)j−1
(cid:88)

l=0

(cid:16)

uk−1,l
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:16)

uk−1,0
t

, vk−1
t

2 (cid:35)
(cid:17)(cid:13)
(cid:13)
(cid:13)

(cid:34)

ηk−1,l ·

j−1
(cid:88)

l=0

E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

+ E

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,l
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:0)uk−1, vk−1

t

2 (cid:35)
(cid:1)(cid:13)
(cid:13)
(cid:13)

(cid:32)j−1
(cid:88)

≤2

ηk−1,l

(cid:33) j−1
(cid:88)

ηk−1,l

(cid:34)

E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

+ L2E

l=0
(cid:32)j−1
(cid:88)

=2L2

l=0
(cid:33) j−1
(cid:88)

ηk−1,l

ηk−1,l · E

(cid:13)
(cid:13)uk−1,l
(cid:13)

t

− uk−1(cid:13)
2
(cid:13)
(cid:13)

l=0

+ 2

(cid:32)j−1
(cid:88)

l=0

l=0

(cid:33)2

ηk−1,l

E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

,

(cid:13)
(cid:13)uk−1,l
(cid:13)

t

2 (cid:35)
− uk−1(cid:13)
(cid:13)
(cid:13)

(130)

(131)

(132)

(133)

(134)

(135)

(136)

(137)

(138)

(139)

where the ﬁrst inequality is obtained using Jensen inequality, and the last one is a result of the
L-smoothness of gt (Assumption 5(cid:48)). Replacing Eq. (139) in Eq. (131), we have

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1 − uk−1,j
· E
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 2σ2





J−1
(cid:88)

j=0

ηk−1,j
ηk−1

·

j−1
(cid:88)

l=0



η2
k−1,l



36

+ 4L2

(cid:32)

J−1
(cid:88)

j=0

ηk−1,j
ηk−1



+ 4



J−1
(cid:88)

j=0

ηk−1,j
ηk−1

l=0
(cid:32)j−1
(cid:88)

l=0

j−1
(cid:88)

(cid:33)

ηk−1,l

·

(cid:32)j−1
(cid:88)

l=0

ηk−1,l · E

(cid:13)
(cid:13)uk−1,l
(cid:13)

t

− uk−1
t

2(cid:33)
(cid:13)
(cid:13)
(cid:13)

(cid:33)2

 · E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1

t

, vk−1
t

(cid:1)(cid:13)
2
(cid:13)

.

(140)

ηk−1,l

Since (cid:80)j−1

l=0 ηk−1,l · E

(cid:13)
(cid:13)uk−1,l
(cid:13)

t

− uk−1
t

(cid:13)
2
(cid:13)
(cid:13)

≤ (cid:80)J−1

j=0 ηk−1,j · E

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1 − uk−1,j
· E
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 2σ2





J−1
(cid:88)

j=0

ηk−1,j
ηk−1

·

j−1
(cid:88)

l=0

η2
k−1,l



− uk−1
t

(cid:13)
2
(cid:13)
(cid:13)

, we have

t

(cid:13)
(cid:13)uk−1,j
(cid:13)


+ 4L2





J−1
(cid:88)

j=0

ηk−1,j
ηk−1

j−1
(cid:88)

l=0



ηk−1,l

 ·





J−1
(cid:88)

j=0

ηk−1,j · E

(cid:13)
(cid:13)uk−1,j
(cid:13)

t

− uk−1(cid:13)
2
(cid:13)
(cid:13)







J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:32)j−1
(cid:88)

l=0

ηk−1,l

(cid:33)2

 · E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(141)

+ 4



We use Lemma G.11 to simplify the last expression, obtaining

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1 − uk−1,j
· E
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 2σ2 ·




J−1
(cid:88)



j=0

η2
k−1,j






+ 4η2

k−1

E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

+ 4ηk−1L2 ·

J−1
(cid:88)

j=0

ηk−1,jE

(cid:13)
(cid:13)uk−1,j
(cid:13)

t

− uk−1(cid:13)
2
(cid:13)
(cid:13)

.

(142)

Rearranging the terms, we have

(cid:0)1 − 4η2

k−1L2(cid:1) ·

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1 − uk−1,j
· E
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 2σ2 ·




J−1
(cid:88)



j=0

η2
k−1,j






+ 4η2

k−1 · E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(143)

Finally, replacing Eq. (143) into Eq. (125), we have

(cid:0)1 − 4η2

k−1L2(cid:1) · T3 ≤ 2σ2L2 ·





J−1
(cid:88)


 + 4η2

k−1L2 · E (cid:13)

(cid:13)∇ugk
t

η2
k−1,j

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(144)

For ηk−1 small enough, in particular if ηk−1 ≤ 1
√

2

2L

, then 1

2 ≤ 1 − 4η2

k−1L2, thus

j=0

T3
2

≤ 2σ2L2 ·





J−1
(cid:88)


 + 4η2

k−1L2 · E (cid:13)

(cid:13)∇ugk
t

η2
k−1,j

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(145)

j=0

Replacing the bound of T3 from Eq. (145) into Eq. (120), we have obtained
(cid:105)

(cid:104)
E
gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

≤ −

E (cid:13)

(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

ηk−1
2

+ 4η3

k−1L2

T
(cid:88)

t=1

ωt · E (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)





J−1
(cid:88)

η2
k−1,jL + ηk−1


 · σ2.

(146)

+ 2ηk−1L

j=0

37

Using Assumption 7(cid:48), we have

(cid:104)
E
gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

(cid:105)

≤ −

ηk−1
2

+ 4η3

k−1L2β2 · E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

E (cid:13)

(cid:1)(cid:13)
2
(cid:13)

1:T

(cid:13)∇ugk (cid:0)uk−1, vk−1
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:0)uk−1, vk−1

(cid:1)

t

ωt · ∇ugk
t





J−1
(cid:88)

η2
k−1,jL + ηk−1


 · σ2 + 4η3

k−1L2G2.

+ 2ηk−1L

Dividing by ηk−1, we get

j=0

(cid:104) gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

E

(cid:105)

≤

8η2

k−1L2β2 − 1
2

E (cid:13)

(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

ηk−1

+ 2ηk−1L





J−1
(cid:88)

j=0

η2
k−1,j
ηk−1

L + 1


 · σ2 + 4η2

k−1L2G2.

For ηk−1 small enough, if ηk−1 ≤ 1

k−1L2β2 − 1 ≤ 1

2 . Thus,

(cid:104) gk(uk, vk−1

1:T ) − gk(uk−1, vk−1
1:T )

E

(cid:13)∇ugk (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

4Lβ , then 8η2
(cid:105)

≤ −

E (cid:13)

1
4

 · σ2 + 4η2

k−1L2G2.

ηk−1

+ 2ηk−1L





J−1
(cid:88)

j=0

η2
k−1,j
ηk−1

L + 1

(cid:1)(cid:13)
2
(cid:13)

(147)

(148)

(149)

Since for t ∈ [T ], gk

t is a partial ﬁrst-order surrogate of ft near (cid:8)uk−1, vk−1

t

(cid:9), we have (see Def. 1)

gk
t
∇ugk
t

t

(cid:0)uk−1, vk−1
(cid:0)uk−1, vk−1
(cid:0)uk, vk−1
gk
t

t

t

t

(cid:1) = ft
(cid:1) = ∇uft
(cid:1) = gk

(cid:0)uk−1, vk−1

(cid:1) ,
(cid:0)uk−1, vk−1
(cid:1) + dV

(cid:0)uk, vk

t

t

t

(cid:1) ,
(cid:0)vk−1

t

, vk
t

(cid:1) .

Multiplying by ωt and summing over t ∈ [T ], we have
(cid:1) = f (cid:0)uk−1, vk−1
gk (cid:0)uk−1, vk−1
(cid:1) ,
(cid:1) = ∇uf (cid:0)uk−1, vk−1
∇ugk (cid:0)uk−1, vk−1

1:T

1:T

1:T

(cid:1) ,

1:T

gk (cid:0)uk, vk−1

1:T

(cid:1) = gk (cid:0)uk, vk

1:T

(cid:1) +

T
(cid:88)

t=1

ωt · dV

(cid:0)vk−1

t

, vk
t

(cid:1) .

Replacing Eq. (153), Eq. (154) and Eq. (155) in Eq. (149), we have

(cid:34)

E

gk(uk, vk

1:T ) − f (uk−1, vk−1
1:T )

ηk−1

(cid:35)

≤

−

1
4

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

+ 2ηk−1L










J−1
(cid:88)

j=0

η2
k−1,j
ηk−1






L + 1

ωt · dV

T
(cid:88)

1
ηk−1

 · σ2 + 4η2

t=1

k−1L2G2.

(cid:0)vk−1

t

, vk
t

(cid:1)

Using again Deﬁnition 1, we have

gk(uk, vk

1:T ) ≥ f (uk, vk

1:T ),

thus,
(cid:34)

E

f (uk, vk

1:T ) − f (uk−1, vk−1
1:T )

ηk−1

(cid:35)

≤

38

(150)

(151)

(152)

(153)

(154)

(155)

(156)

(157)

−

1
4

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

1
ηk−1

T
(cid:88)

t=1

ωt · dV

(cid:0)vk−1

t

, vk
t

(cid:1)

+ 2ηk−1L





J−1
(cid:88)

j=0

η2
k−1,j
ηk−1

L + 1


 · σ2 + 4η2

k−1L2G2.

Lemma G.2. For k ≥ 0 and t ∈ [T ], the iterates of Alg. 3 verify

0 ≤ dV

(cid:0)vk+1

t

, vk
t

(cid:1) ≤ ft

(cid:0)uk, vk

t

(cid:1) − ft(uk, vk+1

t

)

(158)

(159)

Proof. Since vk+1
{uk−1, vk−1

t

}, we have

t

∈ arg minv∈V gk
t

(cid:0)uk−1, v(cid:1), and gk

t is a partial ﬁrst-order surrogate of ft near

thus,

gk
t

(cid:0)uk−1, vk−1

t

(cid:1) − gk

t

(cid:0)uk−1, vk

t

(cid:1) = dV

(cid:0)vk−1

t

, vk
t

(cid:1) ,

ft

(cid:0)uk−1, vk−1

t

(cid:1) − ft

(cid:0)uk−1, vk

t

(cid:1) ≥ dV

(cid:0)vk−1

t

, vk
t

(cid:1) ,

where we used the fact that

and,

gk
t

(cid:0)uk−1, vk−1

t

(cid:1) = ft

(cid:0)uk−1, vk−1

t

(cid:1) ,

gk
t

(cid:0)uk−1, vk

t

(cid:1) ≥ ft

(cid:0)uk−1, vk

t

(cid:1) .

(160)

(161)

(162)

(163)

Theorem 3.2(cid:48). Under Assumptions 4(cid:48)–7(cid:48), when clients use SGD as local solver with learning rate
η = a0√
, after a large enough number of communication rounds K, the iterates of federated
K
surrogate optimization (Alg. 3) satisfy:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)uk, vk

1:T

(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

k=1

E (cid:2)∆vf (uk, vk

1:T )(cid:3) ≤ O

(cid:18) 1

K 3/4

(cid:19)

,

where the expectation is over the random batches samples, and ∆vf (uk, vk
f (cid:0)uk, vk+1

(cid:1) ≥ 0.

1:T

1:T ) (cid:44) f (cid:0)uk, vk

1:T

(89)
(cid:1) −

Proof. For K large enough, η = a0√
K
are satisﬁed. Lemma G.1 and non-negativity of dV lead to

J min

≤ 1

2L

,

1
4Lβ

(cid:110) 1
√
2

(cid:111)

, thus the assumptions of Lemma G.1

(cid:104) f (uk, vk

1:T ) − f (uk−1, vk−1
1:T )

E

Jη

(cid:105)

≤ −

1
4

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+ 2ηL (ηL + 1) · σ2 + 4J 2η2L2G2.

Rearranging the terms and summing for k ∈ [K], we have

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

(cid:104) f (u0, v0

1:T ) − f (uK, vK

1:T )

(cid:105)

≤ 4E

JηK
1:T ) − f ∗
JηK
where we use Assumption 4(cid:48) to obtain (166). Thus,

(cid:104) f (u0, v0

≤ 4E

+ 8

(cid:105)

+ 8

ηL (ηL + 1) · σ2 + 2J 2η2L2G2
K

ηL (ηL + 1) · σ2 + 2J 2η2L2G2
K

,

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

= O

(cid:18) 1
√
K

(cid:19)

.

39

(164)

(165)

(166)

(167)

To prove the second part of Eq. (89), we ﬁrst decompose ∆v (cid:44) f (cid:0)uk, vk
follow,

1:T

(cid:1) − f (cid:0)uk, vk+1

1:T

(cid:1) ≥ 0 as

∆v = f (cid:0)uk, vk
(cid:124)

1:T

(cid:1) − f (cid:0)uk+1, vk+1

1:T

(cid:123)(cid:122)
(cid:44)T k
1

(cid:1)

(cid:125)

(cid:124)

+ f (cid:0)uk+1, vk+1

1:T

(cid:1) − f (cid:0)uk, vk+1
(cid:123)(cid:122)
(cid:44)T k
2

1:T

Using again Lemma G.1 and Eq. (167), it follows that

1
K

K
(cid:88)

k=1

E (cid:2)T k

1

(cid:3) ≤ O

(cid:19)

.

(cid:18) 1
K

.

(cid:1)

(cid:125)

(168)

(169)

2 , we use the fact that f is 2L-smooth (Lemma G.12) w.r.t. u and Cauchy-Schwartz inequality.

For T k
Thus, for k > 0, we write
2 = f (cid:0)uk+1, vk+1
T k

1:T

≤ (cid:13)

(cid:13)∇uf (cid:0)uk+1, vk+1

(cid:13)uk+1 − uk(cid:13)

(cid:13) + 2L2 (cid:13)

(cid:13)uk+1 − uk(cid:13)
2
(cid:13)

.

(cid:1)

(cid:1) − f (cid:0)uk, vk+1
(cid:13) · (cid:13)
(cid:1)(cid:13)

1:T

1:T

Summing over k and taking expectation:

1
K

K
(cid:88)

k=1

E (cid:2)T k

2

(cid:3) ≤

1
K

K
(cid:88)

k=1

E (cid:2)(cid:13)

(cid:13)∇uf (cid:0)uk+1, vk+1

1:T

(cid:13) · (cid:13)
(cid:1)(cid:13)

(cid:13)uk+1 − uk(cid:13)
(cid:3)
(cid:13)

1
K

K
(cid:88)

k=1

(cid:118)
(cid:117)
(cid:117)
(cid:116)

K
(cid:88)

+

≤

1
K

k=1

K
(cid:88)

k=1

+

1
K

2L2 E

(cid:104)(cid:13)
(cid:13)uk+1 − uk(cid:13)
(cid:13)

2(cid:105)

E

(cid:104)(cid:13)
(cid:13)∇uf (cid:0)uk+1, vk+1

1:T

2(cid:105)

(cid:1)(cid:13)
(cid:13)

2L2 E

(cid:104)(cid:13)
(cid:13)uk+1 − uk(cid:13)
(cid:13)

2(cid:105)

,

(cid:118)
(cid:117)
(cid:117)
(cid:116)

K
(cid:88)

k=1

(cid:104)

(cid:107)uk+1 − uk(cid:107)2(cid:105)

E

(170)

(171)

(172)

(173)

where the second inequality follows from Cauchy-Schwarz inequality. From Eq. (143), with ηk−1 =
Jη, we have for t ∈ [T ]

(cid:13)
2
(cid:13)
(cid:13)
Multiplying the previous by ωt and summing for t ∈ [T ], we have

≤ 4σ2Jη2 + 8J 3η2 · E (cid:13)

(cid:13)
(cid:13)uk − uk−1,J
E
(cid:13)

(cid:13)∇ugk
t

t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(174)

T
(cid:88)

t=1

(cid:13)
(cid:13)uk−1 − uk−1,J
ωt · E
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 4J 2σ2η2 + 8J 3η2 ·

T
(cid:88)

t=1

ωtE (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(175)

Using Assumption 7(cid:48), it follows that

T
(cid:88)

t=1

(cid:13)
(cid:13)uk−1 − uk−1,J
ωtE
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

≤ 4J 2η2 (cid:0)2JG2 + σ2(cid:1) + 8J 3η2β2E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(176)
(cid:9),
t is a partial ﬁrst-order of ft near (cid:8)uk−1, vk−1

(cid:0)uk−1, vk−1

ωt∇ugk
t

t=1

(cid:1)

.

t

t

Finally using Jensen inequality and the fact that gk
we have

E

(cid:13)
(cid:13)

(cid:13)uk−1 − uk(cid:13)

2
(cid:13)
(cid:13)

From Eq. (167) and η ≤ O(1/

√

≤ 4J 2η2 (cid:0)2JG2 + σ2(cid:1) + 8J 3η2β2E (cid:13)

(cid:13)∇uf (cid:0)uk−1, vk−1

1:T

K), we obtain

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)uk−1 − uk(cid:13)
2
(cid:13)

≤ O (1) ,

Replacing the last inequality in Eq. (173) and using again Eq. (167), we obtain

1
K

K
(cid:88)

k=1

E (cid:2)T k

2

(cid:3) ≤ O

(cid:18) 1

K 3/4

(cid:19)

.

40

(cid:1)(cid:13)
2
(cid:13)

.

(177)

(178)

(179)

Combining Eq. (169) and Eq. (179), it follows that

1
K

K
(cid:88)

k=1

E (cid:2)∆vf (uk, vk

1:T )(cid:3) ≤ O

(cid:18) 1

K 3/4

(cid:19)

.

(180)

G.1.3 Proof of Theorem 3.2

In this section, f denotes the negative log-likelihood function deﬁned in Eq. (6). Moreover, we
introduce the negative log-likelihood at client t as follows

ft(Θ, Π) (cid:44) −

log p(St|Θ, Π)
n

(cid:44) −

1
nt

nt(cid:88)

i=1

log p(s(i)
t

|Θ, πt).

(181)

Theorem 3.2. Under Assumptions 1–7, when clients use SGD as local solver with learning rate
η = a0√
, after a large enough number of communication rounds K, FedEM’s iterates satisfy:
K

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇Θf (cid:0)Θk, Πk(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

k=1

∆Πf (Θk, Πk) ≤ O

(cid:18) 1

K 3/4

(cid:19)

,

(11)

where the expectation is over the random batches samples, and ∆Πf (Θk, Πk) (cid:44) f (cid:0)Θk, Πk(cid:1) −
f (cid:0)Θk, Πk+1(cid:1) ≥ 0.

Proof. We prove this result as a particular case of Theorem 3.2(cid:48). To this purpose, in this section, we
consider that V (cid:44) ∆M , u = Θ ∈ RdM , vt = πt, and ωt = nt/n for t ∈ [T ]. For k > 0, we deﬁne
gk
t as follows:

(cid:16)

gk
t

Θ, πt

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)
·

l

(cid:16)

i=1

m=1

hθm(x(i)

t ), y(i)

t

+ log qk
t

(cid:17)

(cid:16)

− log pm(x(i)

t ) − log πt

(cid:17)

z(i)
t = m

(cid:19)

− c

,

(182)

where c is the same constant appearing in Assumption 3, Eq. (3). With this deﬁnition, it is easy
to check that the federated surrogate optimization algorithm (Alg. 3) reduces to FedEM (Alg. 2).
Theorem 3.2 then follows immediately from Theorem 3.2(cid:48), once we verify that (cid:0)gk
1≤t≤T satisfy
the assumptions of Theorem 3.2(cid:48).
Assumption 4(cid:48), Assumption 6(cid:48), and Assumption 7(cid:48) follow directly from Assumption 4, Assumption 6,
and Assumption 7, respectively. Lemma G.3 shows that for k > 0, gk is smooth w.r.t. Θ and then
Assumption 5(cid:48) is satisﬁed. Finally, Lemmas G.4–G.6 show that for t ∈ [T ] gk
t is a partial ﬁrst-order
surrogate of ft w.r.t. Θ near (cid:8)Θk−1, πt

(cid:9) with dV (·, ·) = KL(·(cid:107)·).

(cid:1)

t

Lemma G.3. Under Assumption 5, for t ∈ [T ] and k > 0, gk

t is L-smooth w.r.t Θ.

Proof. gk
L-smooth.

t is a convex combination of L-smooth function θ (cid:55)→ l(θ; s(i)

t ), i ∈ [nt]. Thus it is also

Lemma G.4. Suppose that Assumptions 1–3, hold. Then, for t ∈ [T ], Θ ∈ RM ×d and πt ∈ ∆M

t (Θ, πt) (cid:44) gk
rk

t (Θ, πt) − ft (Θ, πt) =

where KL is Kullback–Leibler divergence.

1
nt

nt(cid:88)

i=1

41

KL

(cid:16)

(cid:16)

qk
t

z(t)
i

(cid:17)

(cid:107)pt

(cid:16)

z(t)
i

|s(t)
i

, Θ, πt

(cid:17)(cid:17)

,

Proof. Let k > 0 and t ∈ [T ], and consider Θ ∈ RM ×d and πt ∈ ∆M , then

(cid:16)

gk
t

Θ, πt

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)

(cid:16)

l

·

i=1

m=1

hθm (x(i)

t ), y(i)

t

(cid:17)

− log pm(x(i)

t ) − log πt

+ log qk
t

(cid:16)

z(i)
t = m

(cid:17)

(cid:19)

− c

,

(183)

=

1
nt

nt(cid:88)

M
(cid:88)

i=1

m=1

=

1
nt

nt(cid:88)

M
(cid:88)

i=1

m=1

=

1
nt

nt(cid:88)

M
(cid:88)

i=1

m=1

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)

·

− log pm

(cid:16)
y(i)
t

|x(i)
t

, θm

(cid:17)

− log pm(x(i)

t ) − log πt

+ log qk
t

(cid:16)

z(i)
t = m

(cid:17) (cid:19)

(184)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)

·

− log pm

(cid:16)
y(i)
t

|x(i)
t

, θm

(cid:17)

· pm(x(i)

t ) · pt

(cid:16)

(cid:17)

z(i)
t = m

+ log qk
t

(cid:16)

z(i)
t = m

(cid:17) (cid:19)

(185)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:16)

·

log qk
t

(cid:16)

(cid:17)

z(i)
t = m

− log pt

(cid:16)

s(i)
t

, z(i)

(cid:12)
(cid:12)
(cid:12) Θ, πt)
t = m

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

t=1

m=1

(cid:16)

qk
t

(cid:17)

z(i)
t = m

log

qk
t
s(i)
t

(cid:16)

pt

(cid:16)

z(i)
t = m

(cid:17)

, z(i)

t = m|Θ, πt

(cid:17) .

Thus,
(cid:16)
rk
t

Θ, πt

(cid:17)

(cid:44) gk

t (Θ, πt) − ft (Θ, πt)

= −

1
nt

nt(cid:88)

M
(cid:88)

t=1

m=1


qk
t

(cid:16)

(cid:17)

z(i)
t = m

· log

(cid:16)

s(i)
t

pt

qk
t

, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m

(cid:17)

(cid:17)





+

1
nt

nt(cid:88)

i=1

log pt

(cid:16)

s(i)
t

|Θ, πt

(cid:17)

(cid:32)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

log pt

(cid:16)
s(i)
t

|Θ, πt

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

t=1

m=1

=

=

1
nt

1
nt

nt(cid:88)

M
(cid:88)

t=1

m=1

nt(cid:88)

M
(cid:88)

t=1

m=1

Thus,

(cid:16)

s(i)
t

pt

− log

(cid:17)

(cid:33)

, z(i)
(cid:16)

t = m|Θ, πt
z(i)
t = m
(cid:17)

(cid:17)

qk
t
(cid:16)

z(i)
t = m

(cid:16)

qk
t

(cid:17)

z(i)
t = m

log

(cid:16)

qk
t

(cid:17)

z(i)
t = m

· log

(cid:16)

pt

(cid:16)

pt

|Θ, πt

(cid:17)

· qk
t

s(i)
t
(cid:16)

pt

(cid:17)

t = m|Θ, πt
(cid:17)

, z(i)
s(i)
t
(cid:16)
z(i)
qk
t = m
t
t = m|s(i)
z(i)

t

, Θ, πt

(cid:17) .

rk
t (Θ, πt) =

1
nt

nt(cid:88)

i=1

(cid:16)

KL

t (·)(cid:107)pt(·|s(t)
qk

i

(cid:17)

, Θ, πt)

≥ 0.

(186)

(187)

(188)

(189)

(190)

(191)

(192)

(193)

The following lemma shows that gk
Deﬁnition 1.

t and gk (as deﬁned in Eq. 98) satisfy the ﬁrst two properties in

42

(cid:0)Θk−1, πk−1

Lemma G.5. Suppose that Assumptions 1–3 and Assumption 5 hold. For all k ≥ 0 and t ∈ [T ],
(cid:1) = 0 and
gk
t is a majorant of ft and rk
t
∇Θrk
t
The same holds for gk, i.e., gk is a majorant of f , rk (cid:44) gk−f is L-smooth in Θ, rk (cid:0)Θk−1, Πk−1(cid:1) = 0
and ∇Θrk (cid:0)Θk−1, Πk−1(cid:1) = 0

t − ft is L-smooth in Θ. Moreover rk
t

(cid:0)Θk−1, πk−1

(cid:1) = 0.

(cid:44) gk

t

t

Proof. For t ∈ [T ], consider Θ ∈ RM ×d and πt ∈ ∆M , we have (Lemma G.4)

t (Θ, πt) (cid:44) gk
rk

t (Θ, πt) − ft (Θ, πt) =

1
nt

nt(cid:88)

i=1

KL

(cid:16)

(cid:16)

qk
t

z(t)
i

(cid:17)

(cid:107)pt

(cid:16)

z(i)
t

|s(i)
t

, Θ, πt

(cid:17)(cid:17)

.

(194)

Since KL divergence is non-negative, it follows that gk

t is a majorant of ft, i.e.,

Moreover since, qk
t

(cid:16)

z(i)
t

∀ Θ ∈ RM ×d, πt ∈ ∆M : gk
(cid:17)

(cid:16)

z(i)
t

|s(i)
t

, Θk−1, πk−1

t

= pt

t (Θ, π) ≥ ft (Θ, πt) .

(cid:17)

for k > 0, it follows that

rk
t

(cid:0)Θk−1, πk−1

t

(cid:1) = 0.

For i ∈ [nt] and m ∈ [M ], from Eq. 78, we have

(cid:16)
t = m|s(i)
z(i)

t

pt

, Θ, πt

(cid:17)

=

=

=

(cid:80)M

m(cid:48)=1 pm(cid:48)

exp

(cid:104)
−l
(cid:104)

(cid:80)M

m(cid:48)=1 exp

(cid:104)

exp

−l
(cid:104)

(cid:80)M

m(cid:48)=1 exp

(cid:16)

pm

(cid:17)

, θm

|x(i)
t

, θm(cid:48)

× πtm
(cid:17)

|x(i)
y(i)
t
t
(cid:16)
y(i)
t
(cid:16)

× πtm(cid:48)
(cid:17)(cid:105)

hθm(x(i)

t

t ), y(i)
hθm(cid:48) (x(i)
t ), y(i)
hθm(cid:48) (x(i)

t

(cid:16)

−l
(cid:16)

(cid:16)

−l

hθm (x(i)

t ), y(i)
(cid:17)

t

× πtm
(cid:17)(cid:105)

× πtm(cid:48)
(cid:105)

+ log πtm

t ), y(i)

t

(cid:17)

+ log πtm(cid:48)

(cid:105) .

For ease of notation, we introduce

(cid:16)

li(θ) (cid:44) l

hθ(x(i)

t ), y(i)

t

(cid:17)

,

θ ∈ Rd, m ∈ [M ], i ∈ [nt],

and,

γm (Θ) (cid:44) pt

(cid:16)

t = m|s(i)
z(i)

t

, Θ, πt

(cid:17)

,

m ∈ [M ],

ϕi (Θ) (cid:44) KL

(cid:16)

(cid:16)

qk
t

z(t)
i

(cid:17)

(cid:107)pt

(cid:16)

z(i)
t

|s(i)
t

, Θ, πt

(cid:17)(cid:17)

.

For i ∈ [nt], function li is differentiable because smooth (Assum 5), thus γm, m ∈ [M ] is differen-
tiable as the composition of the softmax function and the function {Θ (cid:55)→ −li (Θ) + log πtm}. Its
gradient is given by

(cid:26) ∇θmγm (Θ) = −γm (Θ) · (1 − γm (Θ)) · ∇li (θm) ,

∇θm(cid:48) γm (Θ) = γm (Θ) · γm(cid:48) (Θ) · ∇li (θm) ,

m(cid:48) (cid:54)= m.

Thus for m ∈ [M ], we have

∇θmϕi (Θ) =

=

M
(cid:88)

m(cid:48)=1
(cid:88)

(cid:16)

i = m(cid:48)(cid:17)
z(t)

·

qk
t

∇θmγm(cid:48) (Θ)
γm(cid:48) (Θ)

m(cid:48)=1
m(cid:48)(cid:54)=m

(cid:20)
qk
t

(cid:16)

i = m(cid:48)(cid:17)
z(t)

·

γm (Θ) · γm(cid:48) (Θ)
γm(cid:48) (Θ) ·

(cid:21)

· ∇li (θm)

43

(195)

(196)

(197)

(198)

(199)

(200)

(201)

(202)

(203)

(204)






(cid:16)

− qk
t

(cid:16)

z(t)
i = m

(cid:17)

·

γm (Θ) · (1 − γm (Θ))
γm (Θ)

· ∇li (θm) .

Using the fact that (cid:80)M

m(cid:48)=1 qk
t

(cid:17)

= 1, it follows that

(cid:16)
z(t)
i = m
(cid:16)

∇θm ϕi (Θ) =

γm (Θ) − qk
t

(cid:16)

(cid:17)(cid:17)

z(t)
i = m

· ∇li (θm) .

(205)

(206)

Since li, i ∈ [nt] is twice continuously differentiable (Assumption 5), and γm, m ∈ [M ] is
differentiable, then φi, i ∈ [nt] is twice continuously differentiable. We use H (ϕi (Θ)) ∈ RdM ×dM
(resp. H (li (θ)) ∈ Rd×d) to denote the Hessian of ϕ (resp. li) at Θ (resp. θ). The Hessian of ϕi is a
block matrix given by
(cid:17)

(cid:17)(cid:124)

(cid:16)

(cid:17)

(cid:16)

(cid:16)

H (ϕi (Θ))

= −γm (Θ) · (1 − γm (Θ)) ·

·

∇li(θm)






m,m

(cid:16)

+

γm(Θ) − qk
t

(cid:16)

(cid:16)

H (ϕi (Θ))

(cid:17)

m,m(cid:48)

= γm (Θ) · γm(cid:48) (Θ) ·

∇li(θm)
(cid:17)(cid:17)

z(t)
i = m
(cid:16)

∇li(θm(cid:48))

(cid:17)

·

· H (li (θm))
(cid:17)(cid:124)
(cid:16)

∇li(θm)

,

We introduce the block matrix ˜H ∈ RdM ×dM , deﬁned by

˜Hm,m = −γm (Θ) ·

(cid:16)

(cid:17)

(cid:16)

·

(cid:17)

1 − γm (Θ)
(cid:16)

∇li(θm)
(cid:16)
(cid:17)

· (∇li(θm))
(cid:17)(cid:124)

˜Hm,m(cid:48) = γm (Θ) · γm (Θ) ·

∇θli(θm)

·

∇li(θm(cid:48))

,

m(cid:48) (cid:54)= m.

(207)

(208)

(cid:124)

m(cid:48) (cid:54)= m,

Eq. (207) can be written as






H (ϕi (Θ))
(cid:17)

H (ϕi (Θ))

(cid:16)

m,m(cid:48)

(cid:17)

− ˜Hm,m =

(cid:16)

γm(Θ) − qk
t

(cid:16)
z(t)
i = m

(cid:17)(cid:17)

· H (li (θm))

m,m

− ˜Hm,m(cid:48) = 0,

m(cid:48) (cid:54)= m.

(209)
We recall that a twice differentiable function is L smooth if and only if the eigenvalues of its Hessian
are smaller then L, see e.g., [52, Lemma 1.2.2] or [6, Section 3.2]. Since li and also −li are L-smooth
(Assumption 5), we have for θ ∈ Rd,

Using Lemma G.15, we can conclude that matrix ˜H is semi-deﬁnite negative. Since

−L · Id (cid:52) H (li (θ)) (cid:52) L · Id.

−1 ≤ γm(Θ) − qk
t

(cid:16)

(cid:17)
z(t)
i = m

≤ 1,

(210)

(211)

it follows that

The last equation proves that ϕi is L-smooth. Thus rk
of L-smooth function.
Moreover, since rk
of (cid:8)Θ (cid:55)→ rk
For Θ ∈ RM ×d and Π ∈ ∆T ×M , we have
rk (Θ, Π) (cid:44) gk (Θ, Π) − f (Θ, Π)

) = 0 and ∀Θ, Π; rk
t (Θk−1, πk−1

t (Θk−1, πk−1
t

(cid:1)(cid:9). Thus, ∇Θrk

(cid:0)Θ, πk−1

t

t

t

H (ϕi (Θ)) (cid:52) L · IdM .

(212)
t is L-smooth with respect to Θ as the average

t (Θ, πt) ≥ 0, it follows that Θk−1 is a minimizer
) = 0.

(cid:44)

=

T
(cid:88)

t=1

T
(cid:88)

t=1

nt
n

nt
n

· (cid:2)gk

t (Θ, πt) − ft (Θ, πt)(cid:3)

rk
t (Θ, πt) .

(213)

(214)

(215)

We see that rk is a weighted average of (cid:0)rk
moreover rk
t

(cid:0)Θk−1, Πk−1(cid:1) = 0 and ∇Θrk

(cid:1)
1≤t≤T . Thus, rk
(cid:0)Θk−1, Πk−1(cid:1) = 0.

t

t

t is L-smooth in Θ, rk (Θ, Π) ≥ 0,

44

The following lemma shows that gk
Lemma G.6. Suppose that Assumption 1 holds and consider Θ ∈ RM ×d and Π ∈ ∆T ×M , for
k > 0, the iterates of Alg. 3 verify

t and gk satisfy the third property in Deﬁnition 1.

gk (Θ, Π) = gk (cid:0)Θ, Πk(cid:1) +

T
(cid:88)

t=1

nt
n

KL (cid:0)πk

t , πt

(cid:1) .

Proof. For t ∈ [T ] and k > 0, consider Θ ∈ RM ×d and πt ∈ ∆M such that ∀m ∈ [M ]; πtm (cid:54)= 0,
we have

t (Θ, πt) − gk
gk
t

(cid:0)Θ, πk

t

(cid:1) =

(cid:40)

M
(cid:88)

m=1

(cid:124)

1
nt

nt(cid:88)

i=1

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:123)(cid:122)

=πk

tm (Proposition 3.1)

× (cid:0)log πk

tm − log πtm

(cid:1)

(216)

(cid:41)

(cid:125)

=

M
(cid:88)

m=1

πk
tm log

πk
tm
πtm

We multiply by nt

= KL (cid:0)πk
n and some for t ∈ [T ]. It follows that

t , πt

(cid:1) .

gk (cid:0)Θ, Πk(cid:1) +

T
(cid:88)

t=1

nt
n

KL (cid:0)πk

t , πt

(cid:1) = gk (Θ, Π) .

(217)

(218)

(219)

G.2 Fully Decentralized Setting

G.2.1 Additional Notations

Remark 3. For convenience and without loss of generality, we suppose in this section that ωt =
1, t ∈ [T ].

We introduce the following matrix notation:

Uk (cid:44) (cid:2)uk
(cid:3) ∈ Rdu×T
1, . . . , uk
T
¯Uk (cid:44) (cid:2)¯uk, . . . , ¯uk(cid:3) ∈ Rdu×T
(cid:0)uk
1:T = (cid:0)vk

1:T ; ξk(cid:1) (cid:44) (cid:2)∇ugk
t and vk
t=1 uk

1 ; ξk
1
1≤t≤T ∈ V T .

1, vk
(cid:1)

1

t

(cid:1) , . . . , ∇ugk

T

∂gk (cid:0)Uk, vk
(cid:80)T

where ¯uk = 1
T

(220)

(221)

(222)

(cid:1)(cid:3) ∈ Rdu×T

(cid:0)uk

T , vk

T ; ξk
T

the j-th iterate of the local solver at global iteration k at client t ∈ [T ], and by

t

We denote by uk−1,j
Uk−1,j the matrix whose column t is uk−1,j
= uk−1
t

uk−1,0
t

t

, thus,

;

Uk−1,0 = Uk−1,

and,

T
(cid:88)

uk

t =

wk−1

st uk−1,J
s

;

Uk = Uk−1,J W k−1.

s=1
Using this notation, the updates of Alg. 5 can be summarized as


Uk−1 −

Uk =

J−1
(cid:88)

j=0

ηk−1,j∂gk (cid:0)Uk−1,j, v1:T ; ξk−1,j(cid:1)


 W k−1.

(223)

(224)

(225)

Similarly to the client-server setting, we deﬁne the normalized update of local solver at client t ∈ [T ]:

ˆδk−1
t

(cid:44) −

uk−1,J
t

− uk−1,0
t

ηk−1

=

(cid:80)J−1

j=0 ηk−1,j∇ugk
t
(cid:80)J−1

(cid:16)

j=0 ηk−1,j

uk−1,j
t

, vk

t ; ξk−1,j

t

(cid:17)

,

(226)

45

and

δk−1
t

(cid:44)

(cid:80)J−1

j=0 ηk−1,j∇ugk
t
ηk−1

(cid:16)

uk−1,j
t

, vk
t

(cid:17)

.

Because clients updates are independent, and stochastic gradient are unbiased, it is clear that

E

(cid:104)
t − ˆδk−1
δk−1

t

(cid:105)

= 0,

and that

∀ t, s ∈ [T ] s.t. s (cid:54)= t, E(cid:104)δk−1

t − ˆδk−1

t

, δk−1

s − ˆδk−1

s

(cid:105) = 0.

We introduce the matrix notation,
(cid:105)
(cid:104)ˆδk−1

, . . . , ˆδk−1

ˆΥk−1 (cid:44)

1

T

∈ Rdu×T ;

Υk−1 (cid:44) (cid:2)δk−1

1

, . . . , δk−1

T

(cid:3) ∈ Rdu×T .

Using this notation, Eq. (225) becomes
(cid:104)

Uk =

Uk−1 − ηk−1 ˆΥk−1(cid:105)

W k−1.

G.2.2 Proof of Theorem 3.3(cid:48)

(227)

(228)

(229)

(230)

(231)

1:T

(cid:1)(cid:13)
2
(cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

) and a term measuring the distance to consensus, i.e., E (cid:80)T

In fully decentralized optimization, proving the convergence usually consists in deriving a re-
currence on a term measuring the optimality of the average iterate (in our case this term is
E (cid:13)
t − ¯uk(cid:13)
2
.
(cid:13)
In what follows we obtain those two recurrences, and then prove the convergence.
Lemma G.7 (Average iterate term recursion). Suppose that Assumptions 5(cid:48)–7(cid:48) and Assumption 8
hold. Then, for k > 0, and (ηk,j)1≤j≤J−1 such that ηk (cid:44) (cid:80)J−1
, the
updates of fully decentralized federated surrogate optimization (Alg. 5) verify

j=0 ηk,j ≤ min

(cid:110) 1
√
2

(cid:13)
(cid:13)uk

1
8Lβ

t=1

(cid:111)

2L

,

(cid:34)
f (¯uk, vk

(cid:35)
1:T ) − f (¯uk−1, vk−1
1:T )

E

−

ηk−1
8

E (cid:13)

(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

≤ −

1
T

(cid:1)(cid:13)
2
(cid:13)

+

T
(cid:88)

E dV

(cid:0)vk

t , vk−1
t

(cid:1)

t=1
(12 + T ) ηk−1L2
4T

·

T
(cid:88)

t=1

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

J−1
(cid:88)

L · η2

k−1,j

ηk−1

j=0


 σ2 +

+ 1

16η3
k−1L2
T

G2.

Proof. We multiply both sides of Eq. (231) by 11(cid:124)

T , thus for k > 0 we have,

Uk ·

W k−1 11(cid:124)
11(cid:124)
T
T
since W k−1 is doubly stochastic (Assumption 8), i.e., W k−1 11(cid:124)
T = 11(cid:124)
11(cid:124)
T

Uk−1 − ηk−1 ˆΥk−1(cid:105)
(cid:104)

¯Uk = ¯Uk−1 − ηk−1 ˆΥk−1 ·

=

,

,

T , is follows that,

thus,

¯uk = ¯uk−1 −

ηk−1
T

·

T
(cid:88)

t=1

ˆδk−1
t

.

Using the fact that gk is L-smooth with respect to u (Assumption 5(cid:48)), we write

(cid:34)
gk (cid:0)¯uk, vk−1

1:T

E

(cid:35)

(cid:1)

(cid:34)
= E

gk

(cid:32)

¯uk−1 −

ηk−1
T

T
(cid:88)

t=1

(cid:33) (cid:35)

ˆδk−1
t

, vk−1
1:T

≤ gk(¯uk−1, vk−1

1:T ) − E

(cid:28)

∇ugk(¯uk−1, vk−1

1:T ),

ηk−1
T

T
(cid:88)

t=1

(cid:29)

ˆδk−1
t

46

(232)

(233)

(234)

(235)

(236)

+

E

L
2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ηk−1
T

T
(cid:88)

t=1

ˆδk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:28)

= gk(¯uk−1, vk−1

1:T ) − ηk−1 E

+

η2
k−1 · L
2T 2

E

(cid:124)

(cid:124)

ˆδk−1
t

T
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

t=1

(cid:123)(cid:122)
(cid:44)T2

,

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:125)

∇ugk(¯uk−1, vk−1

1:T ),

(cid:123)(cid:122)
(cid:44)T1

1
T

T
(cid:88)

t=1

ˆδk−1
t

(cid:29)

(cid:125)

(237)

(238)

where the expectation is taken over local random batches. As in the client-server case, we bound the
terms T1 and T2. First, we bound T1, for k > 0, we have

(cid:28)

T1 = E

∇ugk(¯uk−1, vk−1

1:T ),

(cid:29)

ˆδk−1
t

1
T

T
(cid:88)

t=1

(cid:28)

= E

(cid:124)

∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1) ,

(cid:16)ˆδk−1

t − δk−1

t

T
(cid:88)

1
T
(cid:123)(cid:122)
t −ˆδk−1

t=1

t

=0, because E[δk−1

]=0

(cid:17)(cid:29)

(cid:125)

(cid:28)

+ E

∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1) ,

(cid:29)

δk−1
t

1
T

T
(cid:88)

t=1

(cid:28)

= E

∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1) ,

(cid:29)

δk−1
t

1
T

T
(cid:88)

t=1

=

1
2

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

E

1
2

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
T

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

−

E

1
2

(cid:13)
(cid:13)
∇ugk (cid:0)¯uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)

1:T

(cid:1) −

1
T

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

We bound now T2. For k > 0, we have,
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T2 = E

ˆδk−1
t

T
(cid:88)

t=1

T
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
t=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
T
(cid:88)

T
(cid:88)

t=1

t=1

= E

≤ 2E

= 2 ·

(cid:16)ˆδk−1

t − δk−1

t

T
(cid:88)

(cid:17)

+

δk−1
t

(cid:16)ˆδk−1

t − δk−1

t

(cid:17)

t=1
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ 2 · E

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

E

(cid:13)
ˆδk−1
t − δk−1
(cid:13)
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

+ 2

(cid:88)

1≤t(cid:54)=s≤T

(cid:28)

E

(cid:124)

ˆδk−1
t − δk−1

t

, ˆδk−1

s − δk−1

s

(cid:123)(cid:122)
=0; because of Eq. (229)

+ 2E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

= 2 ·

T
(cid:88)

t=1

E

(cid:13)
ˆδk−1
t − δk−1
(cid:13)
(cid:13)

t

(cid:13)
2
(cid:13)
(cid:13)

+ 2 · E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

47

(239)

(240)

(241)

(242)

(243)

(244)

(245)

(246)

(247)

(cid:29)

(cid:125)

= 2 · E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ 2 ·

(cid:32)

T
(cid:88)

t=1

1
η2
k−1

E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηk−1,j ·

(cid:104)

∇ugk
t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

(cid:16)

− ∇ugk
t

uk−1,j
t

, vk−1
t

; ξk−1,j
t

(cid:17) (cid:105)

2(cid:33)
.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(248)

Since batches are sampled independently, and stochastic gradients are unbiased with ﬁnite variance
(Assumption 6(cid:48)), the last term in the RHS of the previous equation can be bounded using σ2, leading
to

T2 ≤ 2 ·

T
(cid:88)

t=1

(cid:34) (cid:80)J−1

j=0 η2
η2
k−1

k−1,j

(cid:35)

σ2

+ 2 · E

= 2T · σ2 ·

(cid:32) T

(cid:88)

·

t=1

(cid:80)J−1

j=0 η2
η2
k−1

k−1,j

(cid:33)

≤ 2T · σ2 + 2 · E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ 2E

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

Replacing Eq. (242) and Eq. (251) in Eq. (238), we have

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:21)

≤

−

ηk−1
2

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

ηk−1
2

(1 − 2Lηk−1) E

+

L
T

k−1σ2 +
η2

ηk−1
2

E

(cid:13)
(cid:13)
∇ugk (cid:0)¯uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)

1:T

(cid:1) −

1
T

T
(cid:88)

t=1

δk−1
t

For ηk−1 small enough, in particular for ηk−1 ≤ 1

2L , we have

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:35)

≤

T
(cid:88)

t=1

δk−1
t

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

1
T

.

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

−

+

ηk−1
2

E (cid:13)

ηk−1
2

E

1:T

(cid:13)∇ugk (cid:0)¯uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:0)∇ugk

T
(cid:88)

1
T

t=1

t

(cid:1)(cid:13)
2
(cid:13)

+

L
T

k−1σ2
η2

(cid:0)¯uk−1, vk−1

t

(cid:1) − δk−1

t

(cid:1)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

(249)

(250)

(251)

(252)

(253)

We use Jensen inequality to bound the last term in the RHS of the previous equation, leading to

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:35)

≤

−

+

ηk−1
2

ηk−1
2T

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

L
T

k−1σ2
η2

·

T
(cid:88)

t=1

(cid:13)∇ugk
t

E (cid:13)
(cid:124)

(cid:0)¯uk−1, vk−1
(cid:123)(cid:122)
T3

t

(cid:1) − δk−1

t

.

(cid:13)
2
(cid:13)
(cid:125)

We bound now the term T3:
T3 = E (cid:13)
(cid:0)¯uk−1, vk−1
(cid:13)∇ugk
t
(cid:13)
(cid:13)
(cid:13)
∇ugk
(cid:13)
t
(cid:13)
(cid:13)

(cid:0)¯uk−1, vk−1

= E

t

t

(cid:1) − δk−1

t

(cid:13)
2
(cid:13)

(cid:1) −

(cid:80)J−1

j=0 ηk−1,j · ∇ugk
t
ηk−1

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

48

(254)

(255)

(256)

= E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:104)

·

∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)(cid:105)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

Using Jensen inequality, it follows that

T3 ≤

=

J−1
(cid:88)

j=0

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

· E

(cid:13)
(cid:13)∇ugk
(cid:13)

t

ηk−1,j
ηk−1

· E

(cid:13)
(cid:13)
∇ugk
(cid:13)
(cid:13)
t
(cid:13)

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)

+ ∇ugk
t

(cid:0)uk−1

t

, vk−1
t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ 2 · E

(cid:13)
(cid:13)
∇ugk
(cid:13)
(cid:13)
t
(cid:13)

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇ugk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

+ 2 ·

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

· E

(cid:13)
(cid:13)
∇ugk
(cid:13)
(cid:13)
t
(cid:13)

(cid:0)uk−1

t

, vk−1
t

(cid:1) − ∇ugk

t

(cid:16)

uk−1,j
t

, vk−1
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≤ 2L2 · E (cid:13)

(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

+ 2L2 ·

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

· E

(cid:13)
(cid:13)uk−1,j
(cid:13)

t

− uk−1,0
t

(cid:13)
2
(cid:13)
(cid:13)

,

(257)

(258)

(259)

(260)

(261)

where we used the L-smoothness of gk

centralized case (Lemma G.1), we bound terms
exactly the same steps as in the proof of Lemma G.1, Eq. (143) holds with uk−1,0
i.e.,

t (Assumption 5(cid:48)) to obtain the last inequality. As in the
(cid:13)
2
(cid:13)
, j ∈ {0, . . . , J − 1}. Using
(cid:13)
instead of uk−1

(cid:13)
(cid:13)uk−1,j
(cid:13)

− uk−1,0
t

t

t

t

,

(cid:0)1 − 4η2

k−1L2(cid:1) ·

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1,0
· E
(cid:13)

t

− uk−1,j
t

(cid:13)
2
(cid:13)
(cid:13)

≤ 2σ2 ·




J−1
(cid:88)



j=0

η2
k−1,j






+ 4η2

k−1 · E

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,0
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

.

For ηk−1 small enough, in particular for ηk−1 ≤ 1
√

2

2L

, we have

J−1
(cid:88)

j=0

ηk−1,j
ηk−1

(cid:13)
(cid:13)uk−1,0
· E
(cid:13)

t

− uk−1,j
t

(cid:13)
2
(cid:13)
(cid:13)

≤ 8η2

k−1 · E

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,0
t

, vk−1
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

+ 4σ2 ·




J−1
(cid:88)



j=0

η2
k−1,j






≤ 8η2

k−1 · E

+ 4σ2 ·

t

(cid:13)
(cid:13)∇ugk
(cid:13)



J−1
(cid:88)



j=0

(cid:16)

uk−1,0
t



η2
k−1,j



(cid:17)

, vk−1
t

− ∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1) + ∇ugk

t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)
(cid:13)

≤ 16η2

k−1 · E

(cid:16)

(cid:13)
(cid:13)∇ugk
(cid:13)

t

uk−1,0
t

, vk−1
t

(cid:17)

− ∇ugk
t

(cid:0)¯uk−1, vk−1

t

+ 16η2

k−1 · (cid:13)

(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

+ 4σ2 ·




J−1
(cid:88)



j=0

(cid:1)(cid:13)
2
(cid:13)
(cid:13)





η2
k−1,j

≤ 16η2

k−1L2 · E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+ 16η2

k−1 · (cid:13)

(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

49

(262)

(263)

(264)

(265)

+ 4σ2 ·




J−1
(cid:88)



j=0

η2
k−1,j






,

(266)

where the last inequality follows from the L-smoothness of gk
have

t . Replacing Eq. (266) in Eq. (261), we

T3 ≤ 32η2

k−1L4 · E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)




J−1
(cid:88)

+ 8L2σ2 ·






η2
k−1,j

j=0


+ 2L2 · E (cid:13)

+ 32η2

k−1L2 · E (cid:13)

(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

.

(267)

For ηk small enough, in particular if ηk ≤ 1
√

2

2L

we have,

T3 ≤ 6L2E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+ 8L2σ2

J−1
(cid:88)

j=0

Replacing Eq. (268) in Eq. (254), we have

k−1,j + 32η2
η2

k−1L2 (cid:13)

(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(268)

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:35)

≤

3ηk−1L2
T

·

T
(cid:88)

t=1

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

−

ηk−1
2

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

16η3
k−1L2
T

T L · η2
ηk−1

k−1,j


 σ2

+ 1

(cid:13)
(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

.

(269)

J−1
(cid:88)

j=0

T
(cid:88)

t=1

We use now Assumption 7(cid:48) to bound the last term in the RHS of the previous equation, leading to

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:35)

≤

·

T
(cid:88)

E (cid:13)

3ηk−1L2
T
ηk−1 · (cid:0)1 − 32η2

t=1

−

2

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

J−1
(cid:88)

j=0

T L · η2
ηk−1

k−1,j


 σ2

+ 1

k−1L2β2(cid:1)

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

16η3
k−1L2
T

G2.

(270)

For ηk−1 small enough, in particular, if ηk−1 ≤ 1

8Lβ , we have

(cid:34)
gk(¯uk, vk−1

E

1:T ) − gk(¯uk−1, vk−1
1:T )

(cid:35)

≤

−

ηk−1
4

E (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

3ηk−1L2
T

·

T
(cid:88)

t=1

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

J−1
(cid:88)

j=0

T L · η2
ηk−1

k−1,j


 σ2 +

+ 1

16η3
k−1L2
T

G2.

We use Lemma G.14 to get

(271)

(cid:34)
gk(¯uk, vk−1

E

1:T ) − f (¯uk−1, vk−1
1:T )

(cid:35)

≤

−

ηk−1
8

E (cid:13)

(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

(12 + T ) ηk−1L2
4T

·

T
(cid:88)

t=1

50

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

J−1
(cid:88)

L · η2

k−1,j

ηk−1

j=0


 σ2 +

+ 1

k−1L2
16η3
T

G2.

Finally, since gk

t is a partial ﬁrst-order surrogate of ft near (cid:8)uk−1, vk−1

t

(cid:9), we have

(cid:34)
f (¯uk, vk

(cid:35)
1:T ) − f (¯uk−1, vk−1
1:T )

E

−

ηk−1
8

E (cid:13)

(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

≤ −

1
T

(cid:1)(cid:13)
2
(cid:13)

+

T
(cid:88)

E dV

(cid:0)vk

t , vk−1
t

(cid:1)

t=1
(12 + T ) ηk−1L2
4T

·

T
(cid:88)

t=1

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

η2
k−1L
T



4

J−1
(cid:88)

L · η2

k−1,j

ηk−1

j=0


 σ2 +

+ 1

16η3
k−1L2
T

G2.

(272)

(273)

Lemma G.8 (Recursion for consensus distance, part 1). Suppose that Assumptions 5(cid:48)–7(cid:48) and Assump-
tion 8 hold. For k ≥ τ , consider m = (cid:4) k
j=0 ηk,j ≤
then, the updates of fully decentralized federated surrogate optimization (Alg 5)

(cid:5) − 1 and (ηk,j)1≤j≤J−1 such that ηk (cid:44) (cid:80)J−1

(cid:110) 1

(cid:111)

τ

4L ,

1
4Lβ

min
verify

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 −

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F + 44τ
(cid:13)

(cid:18)

1 +

+ T · σ2 ·

k−1
(cid:88)

l=mτ






l + 16τ L2
η2

(cid:18)

1 +

(cid:19)

2
p

2
p

·

(cid:19)

L2

k−1
(cid:88)

η2
l

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

l=mτ




J−1
(cid:88)



j=0







(cid:18)

+ 16τ

1 +

η2
l,j





(cid:19)

2
p

G2

k−1
(cid:88)

l=mτ

η2
l

(274)

(275)

(276)

(cid:18)

+ 16τ

1 +

(cid:19)

2
p

β2

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)∇uf (cid:0)¯ul,j, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

Proof. For k ≥ τ , and m = (cid:4) k

τ

(cid:5) − 1, we have

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

F = E (cid:13)
t − ¯uk(cid:13)
2
(cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
(cid:13)

F

= E (cid:13)
≤ E (cid:13)

(cid:13)Uk − ¯Umτ − (cid:0) ¯Uk − ¯Umτ (cid:1)(cid:13)
2
(cid:13)
(cid:13)Uk − ¯Umτ (cid:13)
2
F ,
(cid:13)
(cid:13)A − ¯A(cid:13)
F = (cid:13)
2
(cid:13)

T

F

where we used the fact that (cid:13)
obtain the last inequality. Using Eq. (231) recursively, we have

(cid:13)A · (cid:0)I − 11(cid:124)

(cid:1)(cid:13)
(cid:13)F ≤ (cid:13)

(cid:13)I − 11(cid:124)

T

(cid:13)
(cid:13)2 · (cid:107)A(cid:107)2

F = (cid:107)A(cid:107)2

F to

Uk = Umτ

(cid:40) k−1
(cid:89)

(cid:41)

−

W l(cid:48)

k−1
(cid:88)

(cid:40)k−1
(cid:89)

(cid:41)

.

W l(cid:48)

ηl ˆΥl

l(cid:48)=mτ

l=mτ

l(cid:48)=l

Thus,

T
(cid:88)

E

t=1

≤ E

(cid:13)
(cid:13)
Umτ
(cid:13)
(cid:13)
(cid:13)
(cid:40) k−1
(cid:89)

W l(cid:48)

(cid:13)
(cid:13)uk
(cid:13)

t − ¯uk(cid:13)
2
(cid:13)
(cid:13)

F

(cid:13)
(cid:13)
= E
Umτ
(cid:13)
(cid:13)
(cid:13)

(cid:40) k−1
(cid:89)

(cid:41)

W l(cid:48)

− ¯Umτ −

l(cid:48)=mτ

k−1
(cid:88)

(cid:40)k−1
(cid:89)

W l(cid:48)

ηl ˆΥl

l=mτ

l(cid:48)=l

(cid:41)

− ¯Umτ −

k−1
(cid:88)

(cid:40)k−1
(cid:89)

(cid:41)

W l(cid:48)

ηlΥl

l(cid:48)=mτ

l=mτ

l(cid:48)=l

51

(277)

(278)

2
(cid:41)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

k−1
(cid:88)

+

(cid:16)

Υl − ˆΥl(cid:17)

ηl

(cid:40)k−1
(cid:89)

l(cid:48)=l

W l(cid:48)

k−1
(cid:88)

(cid:41) (cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

ηlΥl

(cid:40)k−1
(cid:89)

W l(cid:48)

(cid:41)

W l(cid:48)

− ¯Umτ −

(279)

2
(cid:41)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

= E

(cid:13)
(cid:13)
Umτ
(cid:13)
(cid:13)
(cid:13)

l=mτ
(cid:40) k−1
(cid:89)

l(cid:48)=mτ
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k−1
(cid:88)

l=mτ

+ E

(cid:16)

Υl − ˆΥl(cid:17)

ηl

l=mτ
(cid:40)k−1
(cid:89)

W l(cid:48)

l(cid:48)=l

l(cid:48)=l
2
(cid:41)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

− ¯Umτ −

k−1
(cid:88)

ηlΥl

(cid:28)

+ 2E

Umτ

(cid:40) k−1
(cid:89)

(cid:41)

W l(cid:48)

l(cid:48)=mτ

(cid:40)k−1
(cid:89)

(cid:41)

,

W l(cid:48)

l(cid:48)=l

l=mτ

k−1
(cid:88)

l=mτ

(cid:16)

Υl − ˆΥl(cid:17)

ηl

(cid:40)k−1
(cid:89)

l(cid:48)=l

(cid:41) (cid:29)

W l(cid:48)

.

F

(280)

Since stochastic gradients are unbiased, the last term in the RHS of the previous equation is equal to
zero. Using the following standard inequality for Euclidean norm with α > 0,

(cid:107)a + b(cid:107)2 ≤ (1 + α) (cid:107)a(cid:107)2 + (cid:0)1 + α−1(cid:1) (cid:107)b(cid:107)2 ,

we have

(281)

(282)

(283)

(284)

(cid:40)k−1
(cid:89)

l(cid:48)=l

W l(cid:48)

2
(cid:41)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk
(cid:13)

t − ¯uk(cid:13)
2
(cid:13)
(cid:13)

F

≤

(1 + α) E

(cid:13)
(cid:13)
Umτ
(cid:13)
(cid:13)
(cid:13)

(cid:40) k−1
(cid:89)

(cid:41)

W l(cid:48)

− ¯Umτ

+ (cid:0)1 + α−1(cid:1) E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k−1
(cid:88)

ηlΥl

l=mτ

l(cid:48)=mτ
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

E

η2
l

k−1
(cid:88)

+

l=mτ

(cid:16)

Υl − ˆΥl(cid:17)

W l(cid:48)

2
(cid:41)(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

.

2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
F
(cid:40)k−1
(cid:89)

l(cid:48)=l

F
l≥0 are doubly stochastic, we have

Since k ≥ (m + 1)τ and matrices (cid:0)W l(cid:1)

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(cid:13)
(cid:13)
(cid:13)
Umτ
(cid:13)
(cid:13)
(cid:13)
k−1
(cid:88)

E

η2
l






(m+1)τ −1
(cid:89)

W l(cid:48)

l(cid:48)=mτ






− ¯Umτ

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

+ (cid:0)1 + α−1(cid:1) E

(cid:13)
(cid:13)

(cid:13)Υl − ˆΥl(cid:13)

2
(cid:13)
(cid:13)

F

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

k−1
(cid:88)

ηlΥl

l=mτ

(1 + α) E

+

l=mτ

≤ (1 + α) E

(cid:13)
(cid:13)
(cid:13)
Umτ
(cid:13)
(cid:13)
(cid:13)






(m+1)τ −1
(cid:89)

W l(cid:48)

l(cid:48)=mτ






− ¯Umτ

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

F

+ (cid:0)1 + α−1(cid:1) · (k − mτ )

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)Υl(cid:13)
2
(cid:13)

F

k−1
(cid:88)

+

l=mτ

E

η2
l

(cid:13)
(cid:13)

(cid:13)Υl − ˆΥl(cid:13)

2
(cid:13)
(cid:13)

F

,

(285)

where we use the fact that (cid:107)AB(cid:107)F ≤ (cid:107)A(cid:107)2 (cid:107)B(cid:107)F and that (cid:107)A(cid:107) = 1 when A is a doubly stochastic
matrix to obtain the ﬁrst inequality, and Cauchy-Schwarz inequality to obtain the second one. Using
Assumption 8 to bound the ﬁrst term of the RHS of the previous equation and the fact that that
k ≤ (m + 2)τ , it follows that

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

52

(1 + α)(1 − p)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
F + 2τ (cid:0)1 + α−1(cid:1)
2
(cid:13)

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)Υl(cid:13)
2
(cid:13)

F

k−1
(cid:88)

+

l=mτ

E

η2
l

(cid:13)
(cid:13)

(cid:13)Υl − ˆΥl(cid:13)

2
(cid:13)
(cid:13)

F

.

(286)

We use the fact that stochastic gradients have bounded variance (Assumption 6(cid:48)) to bound
(cid:13)Υl − ˆΥl(cid:13)
E

as follows,

2
(cid:13)
(cid:13)

(cid:13)
(cid:13)

F

E

(cid:13)
(cid:13)

(cid:13)Υl − ˆΥl(cid:13)

2
(cid:13)
(cid:13)

F

T
(cid:88)

E

=

(cid:13)
(cid:13)δl
(cid:13)

t − ˆδl

t

(cid:13)
2
(cid:13)
(cid:13)

E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

J−1
(cid:88)

j=0

ηl,j
ηl

·

(cid:32)

∇ugl+1
t

(cid:16)

ul,j
t

, vk−1
t

(cid:17)

− ∇ugl+1

t

(cid:16)

ul,j
t

, vl

t; ξl,j

t

(cid:17)

(cid:33)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

J−1
(cid:88)

t=1

j=0

T
(cid:88)

J−1
(cid:88)

(cid:32)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

∇ugl+1
t

(cid:16)

ul,j
t

, vk−1
t

(cid:17)

− ∇ugl+1

t

(cid:16)

ul,j
t

, vl

t; ξl,j

t

(cid:17)

(cid:33)(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ηl,j
ηl

ηl,j
ηl

· E

σ2

t=1

T
(cid:88)

t=1

=

≤

≤

t=1
j=0
= T · σ2,

(287)

(288)

(289)

(290)

(291)

where we used Jensen inequality to obtain the ﬁrst inequality and Assumption 6(cid:48) to obtain the second
inequality. Replacing back in Eq. (286), we have

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 + α)(1 − p)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
F + 2τ (cid:0)1 + α−1(cid:1)
2
(cid:13)

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)Υl(cid:13)
2
F + T · σ2 ·
(cid:13)

(cid:40) k−1
(cid:88)

(cid:41)

η2
l

.

l=mτ

The last step of the proof consists in bounding E (cid:13)

(cid:13)Υl(cid:13)
2
F for l ∈ {mτ, . . . , k − 1},
(cid:13)

E (cid:13)

(cid:13)Υl(cid:13)
2
F =
(cid:13)

=

≤

≤

T
(cid:88)

t=1

T
(cid:88)

t=1

T
(cid:88)

E (cid:13)

(cid:13)δl
t

(cid:13)
2
(cid:13)

J−1
(cid:88)

j=0

E

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
J−1
(cid:88)

ηl,j
ηl

ηl,j
ηl

t=1

j=0

T
(cid:88)

J−1
(cid:88)

t=1

j=0

· ∇ugl+1

t

(cid:16)

ul,j
t

, vl
t

ηl,j
ηl

· E

(cid:13)
(cid:13)∇ugl+1
(cid:13)

t

(cid:16)

ul,j
t

, vl
t

(cid:17)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

· E

(cid:13)
(cid:13)∇ugl+1
(cid:13)

t

(cid:16)

(cid:17)

ul,j
t

, vl
t

− ∇uft

(cid:0)ul

t, vl
t

(cid:1) + ∇uft

(cid:0)ul

t, vl
t

(cid:1)(cid:13)
2
(cid:13)
(cid:13)

≤ 2

T
(cid:88)

J−1
(cid:88)

t=1

j=0

ηl,j
ηl

· E

(cid:13)
(cid:13)∇ugl+1
(cid:13)

t

(cid:16)

(cid:17)

ul,j
t

, vl
t

− ∇uft

(cid:0)ul

t, vl
t

(cid:1)(cid:13)
2
(cid:13)
(cid:13)

+ 2

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)ul

t, vl
t

(cid:1)(cid:13)
2
(cid:13)

.

53

(292)

(293)

(294)

(295)

(296)

(297)

Since gl+1

t

is a ﬁrst order surrogate of f near (cid:8)ul

t, vl
t

(cid:9), we have

E (cid:13)

(cid:13)Υl(cid:13)
2
F ≤ 2
(cid:13)

T
(cid:88)

J−1
(cid:88)

t=1

j=0

ηl,j
ηl

· E

(cid:13)
(cid:13)∇ugl+1
(cid:13)

t

(cid:16)

(cid:17)

ul,j
t

, vl
t

− ∇ugl+1

t

(cid:16)

ul,0
t

, vl
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

+ 2

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)ul

t, vl
t

(cid:1) − ∇uft

(cid:0)¯ul, vl

t

(cid:1) + ∇uft

(cid:0)¯ul, vl

t

(cid:1)(cid:13)
2
(cid:13)

(298)

≤ 2

T
(cid:88)

J−1
(cid:88)

t=1

j=0

ηl,j
ηl

· E

(cid:13)
(cid:13)∇ugl+1
(cid:13)

t

(cid:16)

(cid:17)

ul,j
t

, vl
t

− ∇ugl+1

t

(cid:16)

ul,0
t

, vl
t

(cid:17)(cid:13)
2
(cid:13)
(cid:13)

+ 4

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)ul

t, vl
t

(cid:1) − ∇uft

(cid:0)¯ul, vl

t

(cid:1)(cid:13)
2
(cid:13)

+ 4

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul, vl

t

(cid:1)(cid:13)
2
(cid:13)

.

(299)

Since f is 2L-smooth w.r.t u (Lemma G.12) and g is L-smooth w.r.t u (Assumption 5(cid:48)), we have

E (cid:13)

(cid:13)Υl(cid:13)
2
F ≤ 2
(cid:13)

T
(cid:88)

J−1
(cid:88)

t=1

j=0

ηl,j
ηl

· L2 E

(cid:13)
(cid:13)ul,j
(cid:13)

t − ul,0

t

(cid:13)
2
(cid:13)
(cid:13)

+ 16L2 ·

T
(cid:88)

t=1

E (cid:13)

(cid:13)ul

t − ¯ul(cid:13)
2
(cid:13)

+ 4

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul, vl

t

(cid:1)(cid:13)
2
(cid:13)

.

We use Eq. (266) to bound the ﬁrst term in the RHS of the previous equation, leading to

E (cid:13)

(cid:13)Υl(cid:13)
2
F ≤ 32η2
(cid:13)

l L2

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇ugl+1

t

(cid:0)¯ul,j, vl

t

(cid:1)(cid:13)
2
(cid:13)

+ 16L2 (cid:0)1 + 2η2

l L2(cid:1) ·

T
(cid:88)

t=1

E (cid:13)

(cid:13)ul

t − ¯ul(cid:13)
2
(cid:13)




J−1
(cid:88)



j=0






.

η2
l,j

+ 4

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul, vl

t

(cid:1)(cid:13)
2
(cid:13)

+ 8T L2σ2 ·

Using Lemma G.14, we have

E (cid:13)

(cid:13)Υl(cid:13)
2
F ≤ 4 (cid:0)1 + 16η2
(cid:13)

l L2(cid:1) ·

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul,j, vl

t

(cid:1)(cid:13)
2
(cid:13)

+ 16L2 (cid:0)1 + 6η2

l L2(cid:1) ·

T
(cid:88)

t=1

E (cid:13)

(cid:13)ul

t − ¯ul(cid:13)
2
(cid:13)

+ 8L2σ2T ·




J−1
(cid:88)



j=0






.

η2
l,j

(300)

(301)

(302)

For ηl small enough, in particular, for ηl ≤ 1

4L , we have

E (cid:13)

(cid:13)Υl(cid:13)
2
F ≤ 8
(cid:13)

T
(cid:88)

t=1

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul,j, vl

t

(cid:1)(cid:13)
2
(cid:13)

+ 22L2 E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
F + 8L2σ2T
(cid:13)




J−1
(cid:88)



j=0






η2
l,j

.

(303)

Replacing Eq. (303) in Eq. (292), we have

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 + α)(1 − p)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
F + 44τ (cid:0)1 + α−1(cid:1) L2
2
(cid:13)

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

E (cid:13)

(cid:13)∇uft

(cid:0)¯ul,j, vl

t

(cid:1)(cid:13)
2
(cid:13)

η2
l

T
(cid:88)

t=1

+ 16τ (cid:0)1 + α−1(cid:1)

k−1
(cid:88)

l=mτ




+ T · σ2 ·

k−1
(cid:88)

l=mτ



l + 16τ L2 (cid:0)1 + α−1(cid:1) ·
η2

54




J−1
(cid:88)



j=0











.

η2
l,j

(304)

Using Lemma G.13 and considering α = p

2 , we have

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 −

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F + 44τ
(cid:13)

(cid:18)

1 +

+ T · σ2 ·

k−1
(cid:88)

l=mτ






l + 16τ L2
η2

(cid:18)

1 +

(cid:19)

2
p

2
p

·

(cid:19)

L2

k−1
(cid:88)

η2
l

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

l=mτ




J−1
(cid:88)



j=0







(cid:18)

+ 16τ

1 +

η2
l,j





(cid:19)

2
p

G2

k−1
(cid:88)

l=mτ

η2
l

(cid:18)

+ 16τ

1 +

(cid:19)

2
p

β2

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)∇uf (cid:0)¯ul,j, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(305)

Lemma G.9 (Recursion for consensus distance, part 2). Suppose that Assumptions 5(cid:48)–7(cid:48) and As-
sumption 8 hold. Consider m = (cid:4) k
j=0 ηk,j ≤
, the updates of fully decentralized federated surrogate optimization (Alg 5) verify

(cid:5), then, for (ηk,j)1≤j≤J−1 such that ηk (cid:44) (cid:80)J−1

(cid:110) 1

min

(cid:111)

τ

4L ,

1
4Lβ

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 +

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F + 44τ
(cid:13)

(cid:18)

1 +

+ T · σ2 ·

k−1
(cid:88)

l=mτ






l + 16τ L2
η2

(cid:18)

1 +

(cid:19)

2
p

2
p

·

(cid:19)

L2

k−1
(cid:88)

η2
l

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

l=mτ




J−1
(cid:88)



j=0







(cid:18)

+ 16τ

1 +

η2
l,j





(cid:19)

2
p

G2

k−1
(cid:88)

l=mτ

η2
l

(cid:18)

+ 16τ

1 +

(cid:19)

2
p

β2

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)∇uf (cid:0)¯ul,j, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(306)

Proof. We use exactly the same proof as in Lemma G.8, with the only difference that Eq. (284)–
Eq. (286) is replaced by

T
(cid:88)

E

t=1

(cid:13)
(cid:13)uk

t − ¯uk(cid:13)
2
F ≤
(cid:13)

(1 + α)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
F + 2τ (cid:0)1 + α−1(cid:1)
2
(cid:13)

k−1
(cid:88)

l=mτ

η2
l

E (cid:13)

(cid:13)Υl(cid:13)
2
(cid:13)

F

k−1
(cid:88)

+

l=mτ

E

η2
l

,

(cid:13)
(cid:13)

(cid:13)Υl − ˆΥl(cid:13)

2
(cid:13)
(cid:13)
l(cid:48)=mτ W l(cid:48)(cid:111)

F
(cid:110)(cid:81)(m+1)τ −1

resulting from the fact that

is a doubly stochastic matrix.

(307)

Lemma G.10. Under Assum. 5(cid:48)-7(cid:48) and Assum 8. For ηk,j = η

η ≤ min

(cid:26) 1
4L

,

p
92τ L

,

1
4βL

,

1
√
32

J with
p
τ β

·

2

(cid:27)

,

the iterates of Alg. 5 veriﬁes

(12 + T )L2
4T

K
(cid:88)

k=0

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤
(cid:13)

1
16

K
(cid:88)

k=0

for some constant A > 0 and K > 0.

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

+16A·

12 + T
T

·

τ L2
p

(K +1)η2,

(308)

55

(cid:123)(cid:122)
(cid:44)A

(cid:123)(cid:122)
(cid:44)A

l = (cid:80)k−1
Proof. Note that for k > 0, ηk = (cid:80)J−1
Using Lemma G.8 and Lemma G.9, and the fact that p ≤ 1, we have for m = (cid:4) k

j=0 ηkj = η, and that (cid:80)k−1

l=mτ η2 ≤ 2τ · η2
(cid:5) − 1

l=mτ η2

τ

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤ (1 −
(cid:13)

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F +
(cid:13)

+η2 2τ

(cid:26)

T σ2

(cid:18)

1 +

16τ L2
J

(cid:18)

1 +

2
p

L2η2

132τ
p

(cid:19)(cid:19)

+ 16τ

k−1
(cid:88)

l=mτ
(cid:18)

1 +

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

(cid:19)

2
p

G2

(cid:27)

(cid:125)

E (cid:13)

(cid:13)∇uf (cid:0)¯ul, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(309)

(cid:124)

+

16τ
p

β2η2

k−1
(cid:88)

l=mτ

and for m = (cid:4) k

τ

(cid:5),

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤ (1 +
(cid:13)

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F +
(cid:13)

+η2 2τ

(cid:26)

T σ2

(cid:18)

1 +

16τ L2
J

(cid:18)

1 +

2
p

L2η2

132τ
p

(cid:19)(cid:19)

+ 16τ

k−1
(cid:88)

l=mτ
(cid:18)

1 +

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

(cid:19)

2
p

G2

(cid:27)

(cid:125)

E (cid:13)

(cid:13)∇uf (cid:0)¯ul, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(310)

(cid:124)

+

16τ
p

β2

η2

(cid:124) (cid:123)(cid:122) (cid:125)
(cid:44)D

k−1
(cid:88)

l=mτ

Using the fact that η ≤ p

92τ L , it follows that for m = (cid:4) k

τ

(cid:5) − 1

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤ (1 −
(cid:13)

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F +
(cid:13)

p
64τ

k−1
(cid:88)

l=mτ

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

+η2A + Dη2

k−1
(cid:88)

l=mτ

and for m = (cid:4) k

τ

(cid:5),

E (cid:13)

(cid:13)∇uf (cid:0)¯ul, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

,

(311)

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤ (1 +
(cid:13)

p
2

)E (cid:13)

(cid:13)Umτ − ¯Umτ (cid:13)
2
F +
(cid:13)

p
64τ

k−1
(cid:88)

l=mτ

E (cid:13)

(cid:13)Ul − ¯Ul(cid:13)
2
(cid:13)

F

+η2A + Dη2

k−1
(cid:88)

l=mτ

E (cid:13)

(cid:13)∇uf (cid:0)¯ul, vl

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(312)

The rest of the proof follows using [31, Lemma 14] with B = (12+T )L2
p -slow7) steps-size η ≤ 1

Dτ and constant weights ωk = 1.

τ β = 1

(cid:113) p/8

4T

16

8τ

√

p

32

2

, b = 1

8 , constant (thus

Theorem 3.3(cid:48). Under Assumptions 4(cid:48)–7(cid:48) and Assumption 8, when clients use SGD as local solver
with learning rate η = a0√
, after a large enough number of communication rounds K, the iterates of
K
fully decentralized federated surrogate optimization (Alg. 5) satisfy:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤ O

(cid:18) 1
√
K

(cid:19)

,

(313)

7The notion of τ -slow decreasing sequence is deﬁned in [31, Deﬁntion 2].

56

and,

where ¯uk = 1
T

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

ωt · E dV

(cid:0)vk

t , vk+1
t

(cid:1) ≤ O

(cid:19)

,

(cid:18) 1
K

(314)

(cid:80)T

t=1 uk

t . Moreover, local estimates (cid:0)uk

t

(cid:1)

1≤t≤T converge to consensus, i.e., to ¯uk:

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

E (cid:13)

(cid:13)uk

t − ¯uk(cid:13)
2
(cid:13)

≤ O

(cid:18) 1
√
K

(cid:19)

.

(315)

Proof. We prove ﬁrst the convergence to a stationary point in u, i.e. Eq. (313), using [31, Lemma
17], then we prove Eq. (314) and Eq. (315).
(cid:110) 1

Note that for K large enough, η ≤ min

(cid:111)
.

4L ,

p
92τ L ,

1
4βL ,

1
√
32

2

· p
τ β

Proof of Eq. 313. Rearranging the terms in the result of Lemma G.7 and dividing it by η we have

(cid:34)
· E

1
η

f (¯uk, vk

1:T ) − f (¯uk−1, vk−1
1:T )

≤ −

(cid:35)

1
8

E (cid:13)

(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

+

(12 + T ) L2
4T

· E (cid:13)

(cid:13)Uk−1 − ¯Uk−1(cid:13)
2
(cid:13)

+

ηL
T

(cid:18) 4L
J

(cid:19)

+ 1

σ2 +

16η2L2
T

G2.

(316)

Summing over k ∈ [K + 1], we have

(cid:34)
· E

1
η

f (¯uK+1, vK+1

1:T ) − f (¯u0, v0

(cid:35)
1:T )

≤ −

1
8

K
(cid:88)

k=0

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

+

+

(12 + T ) L2
4T

K
(cid:88)

·

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
(cid:13)

+

(K + 1)ηL
T

(cid:18) 4L
J

(cid:19)

σ2

+ 1

k=0
16(K + 1) · η2L2
T

G2.

Using Lemma G.10, we have

(cid:34)
· E

1
η

f (¯uK+1, vK+1

1:T ) − f (¯u0, v0

(cid:35)
1:T )

≤ −

1
16

K
(cid:88)

k=0

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

+ 16A ·

12 + T
T

·

τ L2
p

+

16(K + 1)η2L2
T

G2.

(K + 1)η2 +

(K + 1)ηL
T

(cid:18) 4L
J

(cid:19)

σ2

+ 1

Using Assumption 4(cid:48), it follows that

1
16

K
(cid:88)

k=0

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤

f (¯u0, v0
1:T ) − f ∗
η

(317)

(318)

+ 16A ·

12 + T
T

·

τ L2
p

(K + 1)η2 +

(K + 1)ηL
T

(cid:18) 4L
J

(cid:19)

+ 1

σ2 +

16(K + 1)η2L2
T

G2.

We divide by K + 1 and we have

1
16(K + 1)

K
(cid:88)

k=0

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤

+ 16A ·

12 + T
T

·

τ L2
p

η2 +

f (¯u0, v0

1:T ) − f ∗

η(K + 1)
(cid:18) 4L
J

ηL
T

+ 1

(cid:19)

σ2 +

16η2L2
T

G2.

The ﬁnal result follows from [31, Lemma 17].

57

(319)

(320)

Proof of Eq. 315. We multiply Eq. (308) (Lemma G.10) by

1

K+1 , and we have

1
K + 1

K
(cid:88)

k=0

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤
(cid:13)

1
16(K + 1)

K
(cid:88)

k=0

E (cid:13)

(cid:13)∇uf (cid:0)¯uk, vk

1:T

(cid:1)(cid:13)
2
F +
(cid:13)

64Aτ
p(K + 1)

Kη2,

(321)

since η ≤ O

(cid:17)

(cid:16) 1√

K

, using Eq. (313), it follows that

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)Uk − ¯Uk(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

.

Thus,

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

E (cid:13)

(cid:13)uk

t − ¯uk(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

.

Proof of Eq. 314. Using the result of Lemma G.7 we have

(322)

(323)

1
T

T
(cid:88)

t=1

E (cid:2)dV

(cid:0)vk

t , vk−1
t

(cid:34)
(cid:1)(cid:3) ≤ E
f (¯uk−1, vk−1

1:T ) − f (¯uk, vk

(cid:35)
1:T )

·

T
(cid:88)

t=1

E (cid:13)

(cid:13)uk−1

t − ¯uk−1(cid:13)
2
(cid:13)

+

+

(12 + T ) ηk−1L2
4T


η2
k−1L
T

4

J−1
(cid:88)

L · η2

k−1,j

ηk−1

j=0


 σ2 +

+ 1

16η3
k−1L2
T

G2.

(324)

The ﬁnal result follows from the fact that η = O

(cid:17)

(cid:16) 1√

K

and Eq. (315).

G.2.3 Proof of Theorem 3.3

We state the formal version of Theorem 3.3, for which only an informal version was given in the
main text.
Theorem 3.3. Under Assumptions 1–8, when clients use SGD as local solver with learning rate
η = a0√
, D-FedEM’s iterates satisfy the following inequalities after a large enough number of
K
communication rounds K:

1
K

K
(cid:88)

k=1

E (cid:13)

(cid:13)∇Θf (cid:0) ¯Θk, Πk(cid:1)(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

,

1
K

K
(cid:88)

T
(cid:88)

k=1

t=1

nt
n

KL (cid:0)πk

t , πk−1
t

(cid:1) ≤ O

(cid:19)

(cid:18) 1
K

, (325)

where ¯Θk = (cid:2)Θk
i.e., to ¯Θk:

1, . . . Θk
T

(cid:3) · 11(cid:124)

T . Moreover, individual estimates (cid:0)Θk

t

(cid:1)

1≤t≤T converge to consensus,

E

min
k∈[K]

T
(cid:88)

t=1

(cid:13)
(cid:13)Θk

t − ¯Θk(cid:13)
2
F ≤ O
(cid:13)

(cid:18) 1
√
K

(cid:19)

.

Proof. We prove this result as a particular case of Theorem 3.3(cid:48). To this purpose, we consider that
V (cid:44) ∆M , u = Θ ∈ RdM , vt = πt, and ωt = nt/n for t ∈ [T ]. For k > 0, we deﬁne gk
t as follow,

(cid:16)

gk
t

Θ, πt

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)
·

l

(cid:16)

i=1

m=1

hθm(x(i)

t ), y(i)

t

+ log qk
t

(cid:17)

(cid:16)

− log pm(x(i)

t ) − log πt

(cid:17)

z(i)
t = m

(cid:19)

− c

,

(326)

where c is the same constant appearing in Assumption 3, Eq. (3). With this deﬁnition, it is easy
to check that the federated surrogate optimization algorithm (Alg. 5) reduces to D-FedEM (Alg. 4).

58

Theorem 3.3 then follows immediately from Theorem 3.3(cid:48), once we verify that (cid:0)gk
the assumptions of Theorem 3.3(cid:48).
Assumption 4(cid:48), Assumption 6(cid:48), and Assumption 7(cid:48) follow directly from Assumption 4, Assumption 6,
and Assumption 7, respectively. Lemma G.3 shows that for k > 0, gk is smooth w.r.t. Θ and then
Assumption 5(cid:48) is satisﬁed. Finally, Lemmas G.4–G.6 show that for t ∈ [T ] gk
t is a partial ﬁrst-order
surrogate of ft near (cid:8)Θk−1

(cid:9) with dV (·, ·) = KL(·(cid:107)·).

1≤t≤T satisfy

, πt

(cid:1)

t

t

G.3 Supporting Lemmas

Lemma G.11. Consider J ≥ 2 and positive real numbers ηj, j = 0, . . . , J − 1, then:

1
(cid:80)J−1
j=0 ηj

1
(cid:80)J−1
j=0 ηj

J−1
(cid:88)

·

(cid:40)

ηj ·

j−1
(cid:88)

(cid:41)

ηl

≤

j=0

J−1
(cid:88)

·

(cid:40)

ηj ·

l=0

j−1
(cid:88)

l=0

(cid:41)

η2
l

≤

j=0



ηj ·



(cid:32)j−1
(cid:88)

ηl

l=0

(cid:33)2




≤

1
(cid:80)J−1
j=0 ηj

J−1
(cid:88)

·

j=0

Proof. For the ﬁrst inequality,

J−2
(cid:88)

j=0

J−2
(cid:88)

j=0

J−1
(cid:88)

ηj,

ηj

2,

J−2
(cid:88)

ηj.

ηj ·

j=0

j=0

1
(cid:80)J−1
j=0 ηj

J−1
(cid:88)

·

j=0

(cid:40)

ηj ·

j−1
(cid:88)

l=0

(cid:41)

ηl

≤

1
(cid:80)J−1
j=0 ηj

·

(cid:40)

J−1
(cid:88)

j=0

ηj ·

J−2
(cid:88)

l=0

(cid:41)

ηl

=

J−2
(cid:88)

l=0

ηl.

For the second inequality

1
(cid:80)J−1
j=0 ηj

·

(cid:40)

J−1
(cid:88)

j=0

ηj ·

j−1
(cid:88)

l=0

(cid:41)

η2
l

≤

1
(cid:80)J−1
j=0 ηj

J−1
(cid:88)

·

j=0

(cid:40)

ηj ·

J−2
(cid:88)

l=0

(cid:41)

η2
l

=

J−2
(cid:88)

l=0

η2
l .

For the third inequality,

1
(cid:80)J−1
j=0 ηj

J−1
(cid:88)

·

j=0






(cid:32)j−1
(cid:88)

ηl

ηj ·

l=0

(cid:33)2




≤

≤

≤






(cid:32)J−2
(cid:88)

ηl

ηj ·

l=0

(cid:33)2




J−1
(cid:88)

j=0

·

1
(cid:80)J−1
j=0 ηj

2



J−2
(cid:88)



ηj



j=0

J−1
(cid:88)

J−2
(cid:88)

ηj.

ηj ·

j=0

j=0

(327)

(328)

(329)

(330)

(331)

Lemma G.12. Suppose that g is a partial ﬁrst-order surrogate of f , and that g is L-smooth, where
L is the constant appearing in Deﬁnition 1, then f is 2L-smooth.

Proof. The difference between f and g is L-smooth, and g is L-smooth, thus f is 2L-smooth as the
sum of two L-smooth functions.

Lemma G.13. Consider f = (cid:80)T
Rdu × V, and t ∈ [T ], ft admits a partial ﬁrst-order surrogate g{u,v}
g{u,v} = (cid:80)T

t=1 ωt · ft, for weights ω ∈ ∆T . Suppose that for all (u, v) ∈
near {u, v}, and that

veriﬁes Assumption 7(cid:48) for t ∈ [T ]. Then f also veriﬁes Assumption 7(cid:48).

t

t=1 ωt · g{u,v}

t

59

Proof. Consider arbitrary u, v ∈ Rdu × V, and for t ∈ [T ], consider g{u,v} to be a partial ﬁrst-order
surrogate of ft near {u, v}. We write Assumption 7(cid:48) for g{u,v},

T
(cid:88)

t=1

ωt ·

(cid:13)
(cid:13)∇ug{u,v}
(cid:13)

t

(u, v)

(cid:13)
2
(cid:13)
(cid:13)

≤ G2 + β2(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · ∇ug{u,v}

t

(u, v)

(cid:13)
2
(cid:13)
(cid:13)

.

Since g{u,v}
t

is a partial ﬁrst-order surrogate of ft near {u, v}, it follows that

T
(cid:88)

t=1

ωt ·

(cid:13)
(cid:13)
(cid:13)∇uft(u, v)

(cid:13)
2
(cid:13)
(cid:13)

≤ G2 + β2(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · ∇uft(u, v)

(cid:13)
2
(cid:13)
(cid:13)

.

(332)

(333)

Remark 4. Note that the assumption of Lemma G.13 is implicitly veriﬁed in Alg. 3 and Alg. 5, where
we assume that every client t ∈ T canfunction compute a partial ﬁrst-order surrogate of its local
objective ft near any iterate (u, v) ∈ Rdu × V.
Lemma G.14. For k > 0, the iterates of Alg. 5, verify the following inequalities:

gk (cid:0)¯uk−1, vk−1

1:T

(cid:1) ≤ f (cid:0)¯uk−1, vk−1

1:T

(cid:1) +

L
2

T
(cid:88)

t=1

ωt

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

,

(cid:13)
(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

and,

≤ 2 (cid:13)

(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:13)
(cid:13)∇ugk (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

≤ 2 (cid:13)

(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

Proof. For k > 0 and t ∈ [T ], we have

(cid:1)(cid:13)
2
(cid:13)

+ 2L2

(cid:1)(cid:13)
2
(cid:13)

+ 2L2

T
(cid:88)

t=1

T
(cid:88)

t=1

ωt

(cid:13)
(cid:13)¯uk−1 + uk−1

t

(cid:13)
2
(cid:13)

,

ωt

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

,

(cid:0)uk−1

t

, vk−1
t

(cid:1) .

(334)

(335)

(336)

(cid:16)

gk
t

(cid:17)

t

¯uk−1, vk−1

=
(cid:0)¯uk−1, vk−1

t

gk
t
= ft

= ft

Since gk
t

t

t

(cid:0)¯uk−1, vk−1
(cid:0)¯uk−1, vk−1
t
(cid:0)uk
t , vk−1
t
(cid:0)¯uk−1, vk−1

(cid:1) + rk
(cid:1) + rk
(cid:0)uk
(cid:1) = ft

(cid:1) = ft

t

t

gk
t

(cid:1) + ft

(cid:0)¯uk−1, vk−1

t

(cid:0)¯uk−1, vk−1

(cid:1)

t

(cid:1) − ft
(cid:1)
(cid:1) − rk

(cid:0)¯uk−1, vk−1
(cid:0)¯uk−1, vk−1

t

t

(cid:0)uk−1
(cid:1) (Deﬁnition 1), it follows that

, vk−1
t

(cid:1) + rk

t

t

t

t , vk−1
t
(cid:0)¯uk−1, vk−1

t

(cid:1) + rk

t

(cid:0)¯uk−1, vk−1

t

(cid:1) − rk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1) .

(337)

Because rk

t is L-smooth in u (Deﬁnition 1), we have

rk
t

(cid:0)¯uk−1, vk−1

t

(cid:1) −rk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1) ≤

(cid:28)

∇urk
t

(cid:0)uk−1

t

, vk−1
t

(cid:1) , ¯uk−1 − uk−1

t

(cid:29)

+

L
2

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

.

Since gk

t is a partial ﬁrst order surrogate of We have ∇urk
t

(cid:0)uk−1

t

, vk−1
t

(cid:1) = 0, thus

gk
t

(cid:0)¯uk−1, vk−1

t

(cid:1) ≤ ft

(cid:0)¯uk−1, vk−1

t

(cid:1) +

L
2

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

.

Multiplying by ωt and summing for t ∈ [T ], we have

(338)

(339)

gk (cid:0)¯uk−1, vk−1

1:T

(cid:1) ≤ f (cid:0)¯uk−1, vk−1

1:T

(cid:1) +

L
2

T
(cid:88)

t=1

ωt

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

,

(340)

and the ﬁrst inequality is proved.

60

Writing the gradient of Eq. (337), we have
(cid:0)¯uk−1, vk−1

(cid:0)¯uk−1, vk−1

(cid:1) = ∇uft

∇ugk
t

t

t

(cid:1) + ∇urk

t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇urk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1) . (341)

Multiplying by ωt and summing for t ∈ [T ], we have
∇ugk (cid:0)¯uk−1, vk−1

(cid:1) = ∇uf (cid:0)¯uk−1, vk−1

(cid:1) +

1:T

1:T

+

T
(cid:88)

t=1

ωt

(cid:2)∇urk

t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇urk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)(cid:3) .

(342)

Thus,

(cid:13)
(cid:13)
∇ugk (cid:0)¯uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)

1:T

(cid:1)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

=

(cid:13)
(cid:13)
∇uf (cid:0)¯uk−1, vk−1
(cid:13)
(cid:13)
(cid:13)

1:T

(cid:1) +

T
(cid:88)

t=1

ωt

(cid:2)∇urk

t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇urk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)(cid:3)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

≥

≥

≥

1
2

1
2

1
2

(cid:13)
(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

(cid:13)
(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

−

T
(cid:88)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)
T
(cid:88)

t=1

ωt

(cid:2)∇urk

t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇urk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)(cid:3)

(cid:13)
2
(cid:13)
(cid:13)
(cid:13)
(cid:13)

ωt

(cid:13)
(cid:13)∇urk
t

(cid:0)¯uk−1, vk−1

t

(cid:1) − ∇urk

t

(cid:0)uk−1

t

, vk−1
t

(cid:1)(cid:13)
2
(cid:13)

t=1

(cid:13)
(cid:13)∇uf (cid:0)¯uk−1, vk−1

1:T

(cid:1)(cid:13)
2
(cid:13)

− L2

T
(cid:88)

t=1

ωt

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

,

(343)

(344)

(345)

(346)

where (344) follows from (cid:107)a(cid:107)2 = (cid:107)a + b − b(cid:107)2 ≤ 2 (cid:107)a + b(cid:107)2 + 2 (cid:107)b(cid:107)2. Thus,

(cid:13)
(cid:13)∇uft

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

≤ 2 (cid:13)

(cid:13)∇ugk
t

(cid:0)¯uk−1, vk−1

t

(cid:1)(cid:13)
2
(cid:13)

+ 2L2

T
(cid:88)

t=1

ωt

(cid:13)
(cid:13)¯uk−1 − uk−1

t

(cid:13)
2
(cid:13)

.

(347)

The proof of the last inequality is similar, it leverages (cid:107)a + b(cid:107)2 ≤ 2 (cid:107)a(cid:107)2 + 2 (cid:107)a(cid:107)2 to upper bound
(343).

Lemma G.15. Consider u1, . . . , uM ∈ Rd and α = (α1, . . . , αM ) ∈ ∆M . Deﬁne the block matrix
H with

(cid:26) Hm,m = −αm · (1 − αm) · um · u(cid:124)
m

(cid:124)
m(cid:48);
Hm,m(cid:48) = αm · αm(cid:48) · um · u

m(cid:48) (cid:54)= m,

then H is a semi-deﬁnite negative matrix.

Proof. Consider x = [x1, . . . , xM ] ∈ RdM , we want to prove that

x(cid:124) · H · x ≤ 0.

We have:

X(cid:124) · H · X =

M
(cid:88)

M
(cid:88)

m=1

m(cid:48)=1


x(cid:124)
m · Hm,m(cid:48) · xm(cid:48)

=

=

M
(cid:88)

m=1

M
(cid:88)

m=1

x(cid:124)
m · Hm,m · xm +





M
(cid:88)

m(cid:48)=1
m(cid:48)(cid:54)=m

x(cid:124)
m · Hm,m · xm(cid:48)

(−αm · (1 − αm) · x(cid:124)

m · um · u(cid:124)

m · xm)

61







(348)

(349)

(350)

(351)

(352)









+

M
(cid:88)

m=1



M
(cid:88)

m(cid:48)=1
m(cid:48)(cid:54)=m

(αm · αm(cid:48) · x(cid:124)

(cid:124)
m(cid:48) · xm(cid:48))
m · um · u





(353)



=

M
(cid:88)

m=1

−αm · (1 − αm) · (cid:104)xm, um(cid:105)2 + αm · (cid:104)xm, um(cid:105)





M
(cid:88)

m(cid:48)=1
m(cid:48)(cid:54)=m

αm(cid:48) · (cid:104)xm(cid:48), um(cid:48)(cid:105)





.

Since α ∈ ∆M ,

∀m ∈ [M ],

M
(cid:88)

m(cid:48)=1
m(cid:48)(cid:54)=m

αm(cid:48) = (1 − αm) ,

thus,

x(cid:124) · H · x =

=

=

M
(cid:88)

m=1

M
(cid:88)

αm · (cid:104)xm, um(cid:105) ·

M
(cid:88)

m(cid:48)=1
m(cid:48)(cid:54)=m

αm(cid:48)

(cid:16)

(cid:104)xm(cid:48), um(cid:48)(cid:105) − (cid:104)xm, um(cid:105)

(cid:17)

αm · (cid:104)xm, um(cid:105) ·

M
(cid:88)

(cid:16)

αm(cid:48)

(cid:104)xm(cid:48), um(cid:48)(cid:105) − (cid:104)xm, um(cid:105)

(cid:17)

m(cid:48)=1
(cid:33)2

αm · (cid:104)xm, um(cid:105)

−

m=1
(cid:32) M
(cid:88)

m=1

M
(cid:88)

m=1

αm · (cid:104)xm, um(cid:105)2.

(354)

(355)

(356)

(357)

(358)

Using Jensen inequality, we have x(cid:124) · H · x ≤ 0.

62

H Distributed Surrogate Optimization with Black-Box Solver

In this section, we cover the scenario where the local SGD solver used in our algorithms (Alg. 3 and
Alg. 5) is replaced by a (possibly non-iterative) black-box solver that is guaranteed to provide a local
inexact solution of

∀m ∈ [M ], minimize

θ∈Rd

nt(cid:88)

i=1

qk(zi

t = m) · l(hθ(x(i)

t ), y(i)
t ),

(359)

with the following approximation guarantee.
Assumption 9 (Local α-approximate solution). There exists 0 < α < 1 such that for t ∈ [T ],
m ∈ [M ] and k > 0,
nt(cid:88)

(cid:110)

(cid:111)

qk(zi

t = m)·

l(hθk

m,t

(x(i)

t ), y(i)

t ) − l(hθk

(x(i)

t ), y(i)
t )

≤

m,t,∗

i=1

α ·

nt(cid:88)

i=1

qk(zi

t = m) ·

(cid:110)

l(hθk−1

m

(x(i)

t ), y(i)

t ) − l(hθk

m,t,∗

(x(i)

t ), y(i)
t )

(cid:111)

,

(360)

where θk
solver at client t and θk−1

m,t,∗ ∈ arg minθ∈Rd

t = m) · l(hθ(x(i)
m is its starting point (see Alg. 2).

i=1 qk(zi

(cid:80)nt

t ), y(i)

t ), θk

m,t is the output of the local

We further assume strong convexity.

Assumption 10. For t ∈ [T ] and i ∈ [nt], we suppose that θ (cid:55)→ l
convex.

(cid:16)

(cid:16)

hθ

x(i)
t

(cid:17)

, y(i)
t

(cid:17)

is µ-strongly

Assumption 9 is equivalent to the γ-inexact solution used in [37] (Lemma. H.2), when local functions
(Φt)1≤t≤T are assumed to be convex. We also need to have G2 = 0 in Assumption 7 as in [38,
Deﬁnition 3], in order to ensure the convergence of Alg. 2 and Alg. 4 to a stationary point of f , as
shown by [66, Theorem. 2].8
Theorem H.1. Suppose that Assumptions 1–7, 9 and 10 hold with G2 = 0 and α < 1
updates of federated surrogate optimization converge to a stationary point of f , i.e.,

β2κ4 , then the

and

lim
k→+∞

(cid:13)∇Θf (Θk, Πk)(cid:13)
(cid:13)
2
F = 0,
(cid:13)

lim
k→+∞

T
(cid:88)

t=1

nt
n

KL (cid:0)πk

t , πk−1
t

(cid:1) = 0.

(361)

(362)

As in App. G, we provide the analysis for the general case of federated surrogate optimization (Alg. 3)
before showing that FedEM (Alg. 2) is a particular case.
We suppose that, at iteration k > 0, the partial ﬁrst-order surrogate functions gk
t , t ∈ [T ] used
in Alg. 3 veriﬁes, in addition to Assumptions 4(cid:48)–7(cid:48), the following assumptions that generalize
Assumptions 9 and 10,
Assumption 9(cid:48) (Local α-inexact solution). There exists 0 < α < 1 such that for t ∈ [T ] and k > 0,
t,∗, v) ≤ α · (cid:8)gk

(cid:0)uk−1, v(cid:1) − gk

t,∗, v(cid:1)(cid:9) ,

∀v ∈ V, gk

t (uk

(363)

(cid:0)uk

t

t

where uk

t,∗ ∈ arg minu∈Rdu gk
t

t , v) − gk
(cid:0)u, vk

t (uk
(cid:1).

t

Assumption 10(cid:48). For t ∈ [T ] and k > 0, gk

t is µ-strongly convex in u.

Under these assumptions a parallel result to Theorem. H.1 holds.

8As shown by [66, Theorem. 2], the convergence is guaranteed in two scenarios: 1) G2 = 0, 2) All clients
use take the same number of local steps using the same local solver. Note that we allow each client to use an
arbitrary approximate local solver.

63

Theorem H.1(cid:48). Suppose that Assumptions 4(cid:48)–7(cid:48), Assumptions 9(cid:48) and 10(cid:48) hold with G2 = 0 and
α < 1
β2κ4 , then the updates of federated surrogate optimization converges to a stationary point of f ,
i.e.,

lim
k→+∞

(cid:13)
(cid:13)∇uf (uk, vk

1:T )(cid:13)
2
(cid:13)

= 0,

and

H.1 Supporting Lemmas

lim
k→+∞

T
(cid:88)

t=1

ωt · dV

(cid:0)vk

t , vk−1
t

(cid:1) = 0.

First, we prove the following result.
Lemma H.2. Under Assumptions 5(cid:48), 9(cid:48) and 10(cid:48), the iterates of Alg. 2 verify for k > 0 and t ∈ [T ],

∀v ∈ V, (cid:13)

(cid:13)∇ugk
t

where κ = L/µ.

(cid:0)uk

t , v(cid:1)(cid:13)

(cid:13) ≤

√

ακ · (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, v(cid:1)(cid:13)
(cid:13) ,

(366)

Proof. Consider v ∈ V. Since gk
t , v(cid:1)(cid:13)
2
F ≤ 2L (cid:0)gk
(cid:13)

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

t

t is L-smooth in u (Assumption 5(cid:48)), we have using Assumption 9(cid:48),
(cid:0)uk

(cid:0)uk−1, v(cid:1) − gk

t,∗, v(cid:1)(cid:1) ≤ 2Lα (cid:0)gk

t , v(cid:1) − gk

t,∗, v(cid:1)(cid:1) .

(cid:0)uk

(cid:0)uk

t

t

t

Since Φk

t is µ-strongly convex (Assumption 10(cid:48)), we can use Polyak-Lojasiewicz (PL) inequality,

gk
t

(cid:0)uk−1

t

, v(cid:1) −

1
2µ

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk−1, v(cid:1)(cid:13)
2
(cid:13)

≤ gk
t

(cid:0)uk−1

t,∗ , v(cid:1) ,

thus,

2µ (cid:0)gk

t

(cid:0)uk−1

t

, v(cid:1) − gk

t

(cid:0)uk

t,∗, v(cid:1)(cid:1) ≤ (cid:13)

(cid:13)∇ugk
t

(cid:0)uk−1, v(cid:1)(cid:13)
2
(cid:13)

.

Combining Eq. (367) and Eq. (369), we have

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk−1, v(cid:1)(cid:13)
2
(cid:13)

≤

L
µ

α (cid:13)

(cid:13)∇ugk−1
t

(cid:0)uk−1, v(cid:1)(cid:13)
2
(cid:13)

,

thus,

(cid:13)
(cid:13)∇ugk

t (uk

t , v)(cid:13)

(cid:13) ≤

√

ακ (cid:13)

(cid:13)∇ugk

t (uk−1, v)(cid:13)
(cid:13) .

Lemma H.3. Suppose that Assumptions 5(cid:48), 7(cid:48), 9(cid:48) and 10(cid:48) hold with G2 = 0. Then,
∗, vk(cid:1)(cid:9) ,

∗, vk(cid:1) ≤ ˜α × (cid:8)gk (cid:0)uk−1, vk−1(cid:1) − gk (cid:0)uk

gk (cid:0)uk, vk(cid:1) − gk (cid:0)uk

where ˜α = β2κ4α, and uk
∗

(cid:44) arg minu gk (cid:0)u, vk

1:T

(cid:1) where gk is deﬁned in (98)

Proof. Consider k > 0 and t ∈ [T ]. Since gt is µ-convex in u (Assumption 10(cid:48)), we write

(cid:13)
(cid:13)uk

t − uk
∗

(cid:13)
(cid:13)F ≤

≤

≤

1
µ
1
µ
√

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

t , vk
t

(cid:1) − ∇ugk

t

(cid:0)uk

∗, vk
t

(cid:1)(cid:13)
(cid:13)

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

ακ
µ

(cid:13)
(cid:13)∇ugk
t

t , vk
t

(cid:1)(cid:13)
(cid:13) +

1
µ
(cid:0)uk−1, vk

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

∗, vk
t

(cid:1)(cid:13)
(cid:13)

(cid:1)(cid:13)
(cid:13) +

t

1
µ

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

∗, vk
t

(cid:1)(cid:13)
(cid:13) ,

where the last inequality is a result of Lemma H.2. Using Jensen inequality, we have

(cid:13)
(cid:13)uk − uk
∗

(cid:13)
(cid:13)F =

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

T
(cid:88)

t=1

ωt · (cid:0)uk

t − uk
∗

(cid:1)

(cid:13)
(cid:13)
(cid:13)
(cid:13)
(cid:13)

64

(364)

(365)

(367)

(368)

(369)

(370)

(371)

(372)

(373)

(374)

(375)

(376)

≤

≤

T
(cid:88)

t=1

T
(cid:88)

t=1

ωt · (cid:13)

(cid:13)uk

t − uk
∗

(cid:13)
(cid:13)

(cid:26) √
ακ
µ

ωt ·

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk−1, vk

t

(cid:1)(cid:13)
(cid:13) +

(cid:13)
(cid:13)∇ugk
t

(cid:0)uk

∗, vk
t

(cid:27)

(cid:1)(cid:13)
(cid:13)

.

1
µ

√

Using Assumption 7(cid:48) and Jensen inequality with the "

·" function, it follows that

(cid:13)
(cid:13)uk − uk
∗

(cid:13)
(cid:13) ≤

=

√

√

ακ

ακ

β
µ
β
µ

(cid:13)
(cid:13)∇ugk (cid:0)uk, vk

1:T

(cid:1)(cid:13)
(cid:13) +

β
µ

(cid:13)
(cid:13)∇ugk (cid:0)uk

∗, vk
1:T

(cid:1)(cid:13)
(cid:13)

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk

1:T

(cid:1)(cid:13)
(cid:13) .

Since gk is L-smooth in u as a convex combination of L-smooth function, we have
(cid:13)
(cid:13)∇ugk (cid:0)uk, vk

(cid:1) − ∇ugk (cid:0)uk

(cid:13) = (cid:13)
(cid:1)(cid:13)

∗, vk
1:T

(cid:1)(cid:13)
(cid:13)

1:T

1:T

(cid:13)∇ugk (cid:0)uk−1, vk
≤ L (cid:13)
(cid:13)uk − uk
∗
√
ακ3 (cid:13)

≤ β

(cid:13)
(cid:13)

(cid:13)∇ugk (cid:0)uk−1, vk

1:T

(cid:1)(cid:13)
(cid:13) .

Using Polyak-Lojasiewicz (PL), we have

gk (cid:0)uk, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1) ≤

1
2µ

(cid:13)
(cid:13)∇ugk (cid:0)uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤

β2ακ3
2µ

Using the L-smoothness of gk in u, we have

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

≤ 2L (cid:2)gk (cid:0)uk−1, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1)(cid:3) .

Thus,

gk (cid:0)uk, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1) ≤ β2κ4α
(cid:124) (cid:123)(cid:122) (cid:125)
(cid:44) ˜α

(cid:0)gk (cid:0)uk−1, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1)(cid:1) .

Since vk

t = arg minv∈V gk
t

(cid:0)uk−1, v(cid:1), it follows that
(cid:1) ≤ gk
(cid:0)uk−1, vk

gk
t

t

t

(cid:0)uk−1, vk−1

(cid:1) .

t

Thus,

gk (cid:0)uk, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1) ≤ ˜α × (cid:8)gk (cid:0)uk−1, vk−1

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1)(cid:9) .

(cid:13)
(cid:13)∇ugk (cid:0)uk−1, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

.

(cid:44) gk

For t ∈ [T ] and k > 0, we introduce rk
t
is a partial ﬁrst-order surrogate of ft, it follows that rk
t
and L-smooth in u.
Lemma H.4. Suppose that Assumptions 4(cid:48) and 5(cid:48) hold and that
gk(uk, vk

1:T ) ≤ gk(uk−1, vk−1

t

1:T ), ∀k > 0,

t − ft and rk (cid:44) gk − f = (cid:80)T
(cid:0)uk−1, vk−1

(cid:0)gk
t=1 ωt
(cid:1) = 0 and that rk

(cid:1). Since gk
t − ft
t
t is non-negative

then

lim
k→∞

rk(uk, vk
1:T )(cid:13)
2
(cid:13)

(cid:13)
(cid:13)∇urk(uk, vk

1:T ) =0

=0

lim
k→∞

If we moreover suppose that Assumption 10(cid:48) holds and that there exists 0 < ˜α < 1 such that for all
k > 0,

gk(uk, vk

1:T ) − gk(uk

∗, vk

1:T ) ≤ ˜α × (cid:0)gk(uk−1, vk−1

1:T ) − gk(uk

∗, vk

1:T )(cid:1) ,

then,

lim
k→∞

where uk

∗ is the minimizer of u (cid:55)→ gk (cid:0)u, vk

1:T

(cid:13)
2
(cid:13)

= 0

(cid:13)
(cid:13)uk − uk
∗
(cid:1).

65

(377)

(378)

(379)

(380)

(381)

(382)

(383)

(384)

(385)

(386)

(387)

(388)

(389)

(390)

(391)

(392)

(393)

Proof. Since gt is a partial ﬁrst-order surrogate of f near (cid:8)uk−1, vk−1
(cid:9) for t ∈ [T ] and k > 0, it
follows that gk is a majorant of f and that gk(uk−1, vk−1) = f (uk−1, vk−1). Thus, the following
holds,

t

f (uk, vk) ≤ gk(uk, vk) ≤ gk(uk−1, vk−1) = f (uk−1, vk−1),

(394)
k≥0 is a non-increasing sequence. Since f is bounded below
k≥0 is convergent. Denote by f ∞ its limit. The sequence

It follows that the sequence (cid:0)f (cid:0)uk, vk(cid:1)(cid:1)
(Assum. 4(cid:48)), it follows that (cid:0)f (cid:0)uk, vk(cid:1)(cid:1)
(cid:0)gk(uk, vk)(cid:1)
k≥0 also converges to f ∞.

Proof of Eq. 390 Using the fact that gk(uk, vk) ≤ gk(uk−1, vk), we write for k > 0,

f (uk, vk

1:T ) + rk(uk, vk

1:T ) = gk(uk, vk

1:T ) ≤ gk(uk−1, vk−1

1:T ) = f (uk−1, vk−1

1:T ),

Thus,

rk(uk, vk

1:T ) ≤ f (uk−1, vk−1

1:T ) − f (uk, vk),

By summing over k then passing to the limit when k → +∞, we have

∞
(cid:88)

k=1

rk(uk, vk

1:T ) ≤ f (u0, v0

1:T ) − f ∞,

(395)

(396)

(397)

Finally since rk(uk, vk
converges to zero, i.e.,

1:T ) is non negative for k > 0, the sequence (cid:0)rk(uk, vk

1:T )(cid:1)

lim
k→∞

rk(uk, vk

1:T ) = 0.

k≥0 necessarily

(398)

Proof of Eq. 391 Because the L-smoothness of u (cid:55)→ rk (cid:0)u, vk

1:T

(cid:1), we have

(cid:18)

rk

uk −

1
L

∇urk (cid:0)uk, vk

1:T

(cid:1) , vk

1:T

(cid:19)

≤ rk (cid:0)uk, vk

1:T

(cid:1) −

1
2L

(cid:13)
(cid:13)∇urk (cid:0)uk, vk

1:T

(cid:1)(cid:13)
2
(cid:13)

(399)

Thus,

(cid:13)
(cid:13)∇urk (cid:0)uk, vk

1:T

(cid:1)(cid:13)
2
F ≤ 2L
(cid:13)

(cid:18)

rk (cid:0)uk, vk

1:T

(cid:1) − rk

(cid:18)

uk −

1
L

∇urk (cid:0)uk, vk

1:T

(cid:1) , vk

1:T

(cid:19)(cid:19)

≤ 2Lrk (cid:0)uk, vk

1:T

(cid:1) ,

because rk is a non-negative function (Deﬁnition 1). Finally, using Eq. (390), it follows that

(cid:13)
(cid:13)∇urk(uk, vk

1:T )(cid:13)
2
(cid:13)

= 0.

lim
k→∞

Proof of Eq. 393 We suppose now that there exists 0 < ˜α < 1 such that

∀k > 0, gk(uk, vk

1:T ) − gk(uk

∗, vk

1:T ) ≤ ˜α (cid:0)gk(uk−1, vk−1

1:T ) − gk(uk

∗, vk

1:T )(cid:1) ,

It follows that,

then,

gk(uk, vk

1:T ) − ˜αgk(uk−1, vk−1

1:T ) ≤ (1 − ˜α)gk(uk

∗, vk

1:T ),

gk(uk

∗, vk

1:T ) ≥

1
1 − ˜α

× (cid:2)gk(uk, vk

1:T ) − ˜α × gk(uk−1, vk−1

1:T )(cid:3) ,

and by using the deﬁnition of gk we have,

gk(uk

∗, vk

1:T ) ≥

1
1 − ˜α

× (cid:2)gk(uk, vk

1:T ) − ˜α × f (uk−1, vk−1

1:T )(cid:3) ,

Since gk (cid:0)uk

∗, vk

1:T

(cid:1) ≤ gk (cid:0)uk, vk

1:T

(cid:1) ≤ gk (cid:0)uk−1, vk−1

1:T

(cid:1), we have

gk(uk

∗, vk

1:T ) ≤ gk(uk−1, vk−1

1:T ) = f (uk−1, vk−1

1:T ).

66

(400)

(401)

(402)

(403)

(404)

(405)

(406)

(407)

From Eq. (406) and Eq. (407), it follows that,

1
1 − ˜α

× (cid:2)gk(uk, vk

1:T ) − ˜α × f (uk−1, vk−1

1:T )(cid:3) ≤ gk(uk

∗, vk

1:T ) ≤ f (uk−1, vk−1

1:T ),

(408)

Finally, since f (cid:0)uk−1, vk−1
that,

1:T

(cid:1) −−−−−→

k→+∞

f ∞ and gk (cid:0)uk, vk

1:T

(cid:1) −−−−−→

k→+∞

f ∞, it follows from Eq. (408)

gk (cid:0)uk

∗, vk
1:T

(cid:1) = f ∞.

lim
k→∞

Since gk is µ-strongly convex in u (Assumption 10), we write

µ
2

(cid:13)
(cid:13)uk − uk
∗

(cid:13)
2
(cid:13)

≤ gk (cid:0)uk, vk

1:T

(cid:1) − gk (cid:0)uk

∗, vk
1:T

(cid:1) ,

It follows that,

lim
k→+∞

(cid:13)
(cid:13)uk − uk
∗

(cid:13)
2
(cid:13)

= 0.

H.2 Proof of Theorem H.1(cid:48)

Combining the previous lemmas we prove the convergence of Alg. 3 with a black box solver.
Theorem H.1(cid:48). Suppose that Assumptions 4(cid:48)–7(cid:48), Assumptions 9(cid:48) and 10(cid:48) hold with G2 = 0 and
α ≤ 1
β2κ4 , then the updates of federated surrogate optimization (Alg. 3) converge to a stationary
point of f , i.e.,

lim
k→+∞

(cid:13)
(cid:13)∇uf (uk, vk

1:T )(cid:13)
2
(cid:13)

= 0,

and,

Proof.

lim
k→+∞

T
(cid:88)

t=1

ωt · dV

(cid:0)vk

t , vk−1
t

(cid:1) = 0.

f (uk, vk

1:T ) = gk(uk, vk

1:T ) − rk(uk, vk

1:T ).

Computing the gradient norm, we have,
(cid:13) = (cid:13)
(cid:13)
(cid:13)∇uf (uk, vk
≤ (cid:13)

(cid:13)∇ugk(uk, vk
(cid:13)∇ugk(uk, vk

1:T )(cid:13)

1:T ) − ∇urk(uk, vk
1:T )(cid:13)

1:T )(cid:13)
(cid:13)
1:T )(cid:13)
(cid:13)∇urk(uk, vk
(cid:13) .

(cid:13) + (cid:13)

Since gk is L-smooth in u, we write
1:T )(cid:13)
(cid:13)
(cid:13)∇ugk(uk, vk

(cid:13) = (cid:13)

(cid:13)∇ugk(uk, vk) − ∇ugk(uk
(cid:13)
(cid:13) .

(cid:13)uk − uk
∗

≤ L (cid:13)

∗, vk

1:T )(cid:13)
(cid:13)

Thus by replacing Eq. (418) in Eq. (416), we have

(cid:13)
(cid:13)∇uf (uk, vk
(cid:13)uk − uk
∗
Using Lemma H.3, there exists 0 < ˜α < 1, such that

(cid:13) ≤ L2 (cid:13)

1:T )(cid:13)

(cid:13)
2
(cid:13)

+ (cid:13)

(cid:13)∇urk(uk, vk

1:T )(cid:13)
(cid:13) .

(cid:2)gk(uk, vk

∗, vk
Thus, the conditions of Lemma H.4 hold, and we can use Eq. (391) and (393), i.e.

1:T )(cid:3) ≤ ˜α × (cid:2)gk(uk−1, vk−1

1:T ) − gk(uk

1:T ) − gk(uk

∗, vk

1:T )(cid:3) .

(cid:13)
(cid:13)∇urk(uk, vk

1:T )(cid:13)
2
(cid:13)
(cid:13)
2
(cid:13)

(cid:13)
(cid:13)uk − uk
∗

−−−−−→
k→+∞

0

−−−−−→
k→+∞

0.

Finally, combining this with Eq. (419), we get the ﬁnal result
1:T )(cid:13)

(cid:13)
(cid:13)∇uf (uk, vk

(cid:13) = 0.

lim
k→+∞

67

(409)

(410)

(411)

(412)

(413)

(414)

(415)

(416)

(417)

(418)

(419)

(420)

(421)

(422)

(423)

t is a partial ﬁrst-order surrogate of ft near (cid:8)uk−1, vk−1

t

Since gk
that

(cid:9) for k > 0 and t ∈ [T ], it follows

T
(cid:88)

t=1

ω · dV

(cid:0)vk

t , vk−1
t

(cid:1) = gk (cid:0)uk−1, vk−1

1:T

(cid:1) − gk (cid:0)uk−1, vk

1:T

(cid:1)

≤ gk (cid:0)uk−1, vk−1

1:T

(cid:1) − gk (cid:0)uk, vk

1:T

(cid:1)

Thus,

T
(cid:88)

t=1

ωt · dV

(cid:0)vk

t , vk−1
t

(cid:1) ≤ f (cid:0)uk−1, vk−1

1:T

(cid:1) − f (cid:0)uk, vk

1:T

(cid:1)

Since dV

(cid:0)vk

t , vk−1
t

(cid:1) is non-negative for k > 0 and t ∈ [T ], it follows that

lim
k→+∞

T
(cid:88)

t=1

ωt · dV

(cid:0)vk

t , vk−1
t

(cid:1) = 0

(424)

(425)

(426)

(427)

H.3 Proof of Theorem H.1

Theorem H.1. Suppose that Assumptions 1–7 and Assumptions 9, 10 hold with G2 = 0 and
α ≤ 1

β2κ5 , then the updates of FedEM (Alg. 2) converge to a stationary point of f , i.e.,

and,

lim
k→+∞

(cid:13)∇Θf (Θk, Πk)(cid:13)
(cid:13)
2
F = 0,
(cid:13)

lim
k→+∞

T
(cid:88)

t=1

nt
n

KL (cid:0)πk

t , πk−1
t

(cid:1) = 0.

(428)

(429)

Proof. We prove this result as a particular case of Theorem H.1(cid:48). To this purpose, we consider that
V (cid:44) ∆M , u = Θ ∈ RdM , vt = πt, and ωt = nt/n for t ∈ [T ]. For k > 0, we deﬁne gk

t as follow,

(cid:16)

gk
t

Θ, πt

(cid:17)

=

1
nt

nt(cid:88)

M
(cid:88)

(cid:16)

qk
t

(cid:17)

z(i)
t = m

(cid:18)
·

l

(cid:16)

i=1

m=1

hθm(x(i)

t ), y(i)

t

+ log qk
t

(cid:17)

(cid:16)

− log pm(x(i)

t ) − log πt

(cid:17)

z(i)
t = m

(cid:19)

− c

,

(430)

where c is the same constant appearing in Assumption 3, Eq. (3). With this deﬁnition, it is easy
to check that the federated surrogate optimization algorithm (Alg. 3) reduces to FedEM (Alg. 2).
Theorem H.1 then follows immediately from Theorem H.1(cid:48), once we verify that (cid:0)gk
1≤t≤T satisfy
the assumptions of Theorem H.1(cid:48).
Assumption 4(cid:48), Assumption 6(cid:48), Assumption 7(cid:48), Assumption 9(cid:48) and Assumption 10(cid:48) follow directly
from Assumption 4, Assumption 6, Assumption 7, Assumption 9 and Assumption 10, respectively.
Lemma G.3 shows that for k > 0, gk is smooth w.r.t. Θ and then Assumption 5(cid:48) is satisﬁed. Finally,
Lemmas G.4–G.6 show that for t ∈ [T ] gk
t is a partial ﬁrst-order surrogate of ft w.r.t. Θ near
(cid:9) with dV (·, ·) = KL(·(cid:107)·).
(cid:8)Θk−1, πt

(cid:1)

t

68

I Details on Experimental Setup

I.1 Datasets and Models

In this section we provide detailed description of the datasets and models used in our experiments.
We used a synthetic dataset, verifying Assumptions 1-3, and ﬁve "real" datasets (CIFAR-10/CIFAR-
100 [33], sub part of EMNIST [8], sub part of FEMNIST [7, 47] and Shakespeare [7, 47]) from
which, two (FEMNIST and Shakespeare) has natural client partitioning. Below, we give a detailed
description of the datasets and the models / tasks considered for each of them.

I.1.1 CIFAR-10 / CIFAR-100

CIFAR-10 and CIFAR-100 are labeled subsets of the 80 million tiny images dataset. They both
share the same 60, 000 input images. CIFAR-100 has a ﬁner labeling, with 100 unique labels, in
comparison to CIFAR-10, having 10 unique label. We used Dirichlet allocation [65], with parameter
α = 0.4 to partition CIFAR-10 among 80 clients. We used Pachinko allocation [54] with parameters
α = 0.4 and β = 10 to partition CIFAR-100 on 100 clients. For both of them we train MobileNet-
v2 [55] architecture with an additional linear layer. We used TorchVision [45] implementation of
MobileNet-v2.

I.1.2 EMNIST

EMNIST (Extended MNIST) is a 62-class image classiﬁcation dataset, extending the classic MNIST
dataset. In our experiments, we consider 10% of the EMNIST dataset, that we partition using
Dirichlet allocation of parameter α = 0.4 over 100 clients. We train the same convolutional network
as in [54]. The network has two convolutional layers (with 3 × 3 kernels), max pooling, and dropout,
followed by a 128 unit dense layer.

I.1.3 FEMNIST

FEMNIST (Federated Extended MNIST) is a 62-class image classiﬁcation dataset built by partitioning
the data of Extended MNIST based on the writer of the digits/characters. In our experiments, we
used a subset with 15% of the total number of writers in FEMNIST. We train the same convolutional
network as in [54]. The network has two convolutional layers (with 3 × 3 kernels), max pooling, and
dropout, followed by a 128 unit dense layer.

I.1.4 Shakespeare

This dataset is built from The Complete Works of William Shakespeare and is partitioned by the
speaking roles [47]. In our experiments, we discarded roles with less than two sentences. We consider
character-level based language modeling on this dataset. The model takes as input a sequence of
200 English characters and predicts the next character. The model embeds the 80 characters into
a learnable 8-dimensional embedding space, and uses two stacked-LSTM layers with 256 hidden
units, followed by a densely-connected layer. We also normalized each character by its frequency of
appearance.

I.1.5 Synthetic dataset

Our synthetic dataset has been generated according to Assumptions 1–3 as follows:

1. Sample weight πt ∼ Dir (α) , t ∈ [T ] from a symmetric Dirichlet distribution of parameter

α ∈ R+

2. Sample θm ∈ Rd ∼ U

(cid:16)

[−1, 1]d(cid:17)

, m ∈ [M ] for uniform distribution over [−1, 1]d.

3. Sample mt, t ∈ [T ] from a log-normal distribution with mean 4 and sigma 2, then set

nt = min (50 + mt, 1000).

4. For t ∈ [T ] and i ∈ [nt], draw x(i)

t ∼ U

(cid:16)

[−1, 1]d(cid:17)

and (cid:15)(i)

t ∼ N (0, Id).

5. For t ∈ [T ] and i ∈ [nt], draw z(i)

t ∼ M (πt).

69

Table 4: Average computation time and used GPU for each dataset.

Dataset

GPU Simulation time

Shakespeare [7, 47]
FEMNIST [7]
EMNIST [8]
CIFAR10 [33]
CIFAR100 [33]
Synthetic

Quadro RTX 8000
Quadro RTX 8000
GeForce GTX 1080 Ti
GeForce GTX 1080 Ti
GeForce GTX 1080 Ti
GeForce GTX 1080 Ti

4h42min
1h14min
46min
2h37min
3h9min
20min

Table 5: Learning rates η used for the experiments in Table 2. Base-10 logarithms are reported.

Dataset

FedAvg [47]

FedProx [38]

FedAvg+ [27]

Clustered FL [56]

pFedMe [16]

FedEM (Ours)

FEMNIST
EMNIST
CIFAR10
CIFAR100
Shakespeare
Synthetic

−1.5
−1.5
−1.5
−1.0
−1.0
−1.0

−1.5
−1.5
−1.5
−1.0
−1.0
−1.0

−1.5
−1.5
−1.5
−1.0
−1.0
−1.0

−1.5
−1.5
−1.5
−1.0
−1.0
−1.0

−1.5
−1.5
−1.0
−1.0
−1.0
−1.0

−1.0
−1.0
−1.0
−0.5
−0.5
−1.0

6. For ∈ [T ] and i ∈ [nt], draw y(i)

t ∼ B

(cid:16)

sigmoid

(cid:16)

(cid:104)x(i)
t

, θz(i)

t

(cid:105) + (cid:15)(i)
t

(cid:17)(cid:17)
.

I.2 Implementation Details

I.2.1 Machines

We ran the experiments on a CPU/GPU cluster, with different GPUs available (e.g., Nvidia Tesla
V100, GeForce GTX 1080 Ti, Titan X, Quadro RTX 6000, and Quadro RTX 8000). Most experiments
with CIFAR10/CIFAR-100 and EMNIST were run on GeForce GTX 1080 Ti cards, while most
experiments with Shakespeare and FEMNIST were run on the Quadro RTX 8000 cards. For each
dataset, we ran around 30 experiments (not counting the development/debugging time). Table 4
gives the average amount of time needed to run one simulation for each dataset. The time needed
per simulation was extremely long for Shakespeare dataset, because we used a batch size of 128.
We remarked that increasing the batch size beyond 128 caused the model to converge to poor local
minima, where the model keeps predicting a white space as next character.

I.2.2 Libraries

We used PyTorch [53] to build and train our models. We also used Torchvision [45] implementation
of MobileNet-v2 [55], and for image datasets preprossessing. We used LEAF [7] to build FEMNIST
dataset and the federated version of Shakespeare dataset.

I.2.3 Hyperparameters

For each method and each task,
the learning rate was set via grid search on the set
(cid:8)10−0.5, 10−1, 10−1.5, 10−2, 10−2.5, 10−3(cid:9). FedProx and pFedMe’s penalization parameter µ was
tuned via grid search on (cid:8)101, 100, 10−1, 10−2, 10−3(cid:9). For Clustered FL, we used the same values
of tolerance as the ones used in its ofﬁcial implementation [56]. We found tuning tol1 and tol2
particularly hard: no empirical rule is provided in [56], and the few random setting we tried did not
show any improvement in comparison to the default ones. For each dataset and each method, Table 5
reports the learning rate η that achieved the corresponding result in Table 2.

70

Table 6: Test accuracy: average across clients.

Dataset

Local

FedAvg [47]

FedAvg+ [27]

Clustered FL [56]

pFedMe [16]

FedEM (Ours)

D-FedEM (Ours)

FEMNIST
EMNIST
CIFAR10
CIFAR100
Shakespeare
Synthetic

71.0
71.9
70.2
31.5
32.0
65.7

78.6
82.6
78.2
40.9
46.7
68.2

75.3
83.1
82.3
39.0
40.0
68.9

73.5
82.7
78.6
41.5
46.6
69.1

74.9
83.3
81.7
41.8
41.2
69.2

79.9
83.5
84.3
44.1
46.7
74.7

77.2
83.5
77.0
43.9
45.4
73.8

J Additional Experimental Results

J.1 Fully Decentralized Federated Expectation-Maximization

D-FedEM considers the scenario where clients communicate directly in a peer-to-peer fashion instead
of relying on the central server mediation. In order to simulate D-FedEM, we consider a binomial
Erd˝os-Rényi graph [18] with parameter p = 0.5, and we set the mixing weight using Fast Mixing
Markov Chain [5] rule. We report the result of this experiment in Table 6, showing the average
weighted accuracy with weight proportional to local dataset sizes. We observe that D-FedEM often
performs better than other FL approaches and slightly worst than FedEM, except on CIFAR-10 where
it has low performances.

J.2 Comparison with MOCHA

In the case of synthetic dataset, for which train a linear model, we compare FedEM with
MOCHA [59]. We implemented MOCHA in Python following the ofﬁcial implementation 9 in MATLAB.
We tuned the parameter λ of MOCHA on a holdout validation set via grid search in
{101, 100, 10−1, 10−2, 10−3}, and we found that the optimal value of λ is 100. For this value, we
ran MOCHA on the synthetic dataset with three different seeds, and we found that the average accuracy
is 73.4 ± 0.05 in comparison to 74.7 ± 0.01 achieved by FedEM. Note that MOCHA is the second best
method after FedEM on this dataset. Unfortunately, MOCHA only works for linear models.

J.3 Generalization to Unseen Clients

Table 3 shows that FedEM allows new clients to learn a personalized model at least as good as FedAvg’s
global one and always better than FedAvg+’s one. Unexpectedly, new clients achieve sometimes a
signiﬁcantly higher test accuracy than old clients (e.g., 47.5% against 44.1% on CIFAR100).

In order to better understand this difference, we looked at the distribution of FedEM personalized
weights for the old clients and new ones. The average distribution entropy equals 0.27 and 0.92 for
old and new clients, respectively. This difference shows that old clients tend to have more skewed
distributions, suggesting that some components may be overﬁtting the local training dataset leading
the old clients to give them a high weight.

We also considered a setting where unseen clients progressively collect their own dataset. We
investigate the effect of the number of samples on the average test accuracy across unseen clients,
starting from no local data (and therefore using uniform weights to mix the M components) and
progressively adding more labeled examples until the full local labeled training set is assumed to be
available. Figure 2 shows that FedEM achieves a signiﬁcant level of personalization as soon as clients
collect a labeled dataset whose size is about 20% of what the original clients used for training.

As we mentioned in the main text, it is not clear how the other personalized FL algorithms (e.g.,
pFedMe and Clustered FL) should be extended to handle unseen clients. For example, the global
model learned by pFedMe during training can then be used to perform some “ﬁne-tuning” at the
new clients, but how exactly? The original pFedMe paper [16] does not even mention this issue. For
example, the client could use the global model as initial vector for some local SGD steps (similarly to
what done in FedAvg+ or the MAML approaches) or it could perform a local pFedMe update (lines
6-9 in [16, Alg. 1]). The problem is even more complex for Clustered FL (and again not discussed
in [56]). The new client should be assigned to one of the clusters identiﬁed. One can think to compute

9https://github.com/gingsmith/fmtl

71

Figure 2: Effect of the number of samples on the average test accuracy across clients unseen at
training on CIFAR100 dataset.

the cosine distances of the new client from those who participated in training, but this would require
the server to maintain not only the model learned, but also the last-iteration gradients of all clients
that participated in the training. Moreover, it is not clear which metric should be considered to
assign the new client to a given cluster (perhaps the average cosine similarity from all clients in the
cluster?). This is an arbitrary choice as [56] does not provide a criterion to assign clients to a cluster,
but only to decide if a given cluster should be split in two new ones. It appears that many options
are possible and they deserve separate investigation. Despite these considerations, we performed an
additional experiment extending pFedMe to unseen clients as described in the second option above on
CIFAR-100 dataset with a sampling rate of 20%. pFedMe achieves a test accuracy of 40.5% ± 1.66%,
in comparison to 38.9% ± 0.97% for FedAvg and 42.7% ± 0.33% for FedEM. FedEM thus performs
better on unseen clients, and pFedMe’s accuracy shows a much larger variability.

J.4 FedEM and Clustering

We performed additional experiments with synthetic datasets to check if FedEM recovers clusters
in practice. We modiﬁed the synthetic dataset generation so that the mixture weight vector πt
of each client t has a single entry equal to 1 that is selected uniformly at random. We consider
two scenarios both with T = 300 client, the ﬁrst with M = 2 component and the second with
M = 3 components. In both cases FedEM recovered almost the correct Π∗ and Θ∗: we have
≤ 10−8. A simple cluster-
cosine_distance
ing algorithm that assigns each client to the component with the largest mixture weight achieves
100% accuracy, i.e., it partitions the clients in sets coinciding with the original clusters.

≤ 10−2 and cosine_distance

(cid:17)
Θ∗, ˘Θ

Π∗, ˘Π

(cid:17)

(cid:16)

(cid:16)

J.5 Effect of M in Time-Constrained Setting

Recall that in FedEM, each client needs to update and transmit M components at each round, requiring
roughly M times more computation and M times larger messages than the competitors in our study.
In this experiment, we considered a challenging time-constrained setting, where FedEM is limited to
run one third (= 1/M ) of the rounds of the other methods. The results in Table 7 show that even if
FedEM does not reach its maximum accuracy, it still outperforms the other methods on 3 datasets.

We additionally compared FedEM with a model having the same number of parameters in order to
check if FedEM’s advantage comes from the additional model parameters rather than by its speciﬁc
formulation. To this purpose, we trained Resnet-18 and Resnet-34 on CIFAR10. The ﬁrst one has
about 3 times more parameters than MobileNet-v2 and then roughly as many parameters as FedEM
with M = 3. The second one has about 6 times more parameters than FedEM with M = 3. We

72

Table 7: Test and train accuracy comparison across different tasks. For each method, the best test
accuracy is reported. For FedEM we run only K
M rounds, where K is the total number of rounds
for other methods–K = 80 for Shakespeare and K = 200 for all other datasets–and M = 3 is the
number of components used in FedEM.

Dataset

Local

FedAvg [47]

FedProx [38]

FedAvg+ [27]

FEMNIST [7]
EMNIST [8]
CIFAR10 [33]
CIFAR100 [33]
Shakespeare [7]
Synthetic

71.0 (99.2)
71.9 (99.9)
70.2 (99.9)
31.5 (99.9)
32.0 (95.3)
65.7 (91.0)

78.6 (79.5)
82.6 (86.5)
78.2 (96.8)
41.0 (78.5)
46.7 (48.7)
68.2 (68.7)

78.6 (79.6)
82.7 (86.6)
78.0 (96.7)
40.9 (78.6)
45.7 (47.3)
68.2 (68.7)

75.3 (86.0)
83.1 (93.5)
82.3 (98.9)
39.0 (76.7)
40.0 (93.1)
68.9 (71.0)

Clustered
FL [56]

73.5 (74.3)
82.7 (86.6)
78.6 (96.8)
41.5 (78.9)
46.6 (48.7)
69.1 (85.1)

pFedMe [16]

FedEM (Ours)

74.9 (91.9)
83.3 (91.1)
81.7 (99.8)
41.8 (99.6)
41.2 (42.1)
69.2 (72.8)

74.0 (80.9)
82.7 (89.4)
82.5 (92.2)
42.0 (72.9)
43.8 (44.6)
73.2 (74.7)

observed that both architectures perform even worse than MobileNet-v2, so the comparison with these
larger models does not suggest that FedEM’s advantage comes from the larger number of parameters.

We note that there are many possible choices of (more complex) model architectures, and ﬁnding one
that works well for the task at hand is quite challenging due to the large search space, the bias-variance
trade-off, and the speciﬁcities of the FL setting.

73

Table 8: Test accuracy under 20% client sampling: average across clients with +/- standard deviation
over 3 independent runs. All experiments with 1200 communication rounds.

Dataset

FedAvg [47]

FedAvg+ [27]

pFedMe [16]

APFL [14]

FedEM (Ours)

CIFAR10 [33]
CIFAR100 [33]
Synthetic

73.1 ± 0.14
40.6 ± 0.17
68.2 ± 0.02

77.7 ± 0.16
39.7 ± 0.75
69.0 ± 0.03

77.8 ± 0.07
39.9 ± 0.08
69.1 ± 0.03

78.2 ± 0.27
40.3 ± 0.71
69.1 ± 0.04

82.1 ± 0.13
43.2 ± 0.23
74.7 ± 0.01

Figure 3: Train loss, train accuracy, test loss, and test accuracy for CIFAR10 [33]. .

J.6 Additional Results under Client Sampling

In our experiments, except for Figure 1, we considered that all clients participate at each round. We
run extra experiments with client sampling, by allowing only 20% of the clients to participate at each
round. We also incorporate APFL [14] into the comparison. Table 8 summarizes our ﬁndings, giving
the average and standard deviation of the test accuracy across 3 independent runs.

J.7 Convergence Plots

Figures 3 to 8 show the evolution of average train loss, train accuracy, test loss, and test accuracy
over time for each experiment shown in Table 2.

74

Figure 4: Train loss, train accuracy, test loss, and test accuracy for CIFAR100 [33].

Figure 5: Train loss, train accuracy, test loss, and test accuracy for EMNIST [8].

75

Figure 6: Train loss, train accuracy, test loss, and test accuracy for FEMNIST [7, 47].

Figure 7: Train loss, train accuracy, test loss, and test accuracy for Shakespeare [7, 47].

76

Figure 8: Train loss, train accuracy, test loss, and test accuracy for synthetic dataset.

77

