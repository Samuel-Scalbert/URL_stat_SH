The Tractability of SHAP-Score-Based Explanations
over Deterministic and Decomposable Boolean Circuits
Marcelo Arenas, Pablo Barceló, Leopoldo Bertossi, Mikaël Monet

To cite this version:

Marcelo Arenas, Pablo Barceló, Leopoldo Bertossi, Mikaël Monet. The Tractability of SHAP-Score-
Based Explanations over Deterministic and Decomposable Boolean Circuits. AAAI 2021 - 35th Con-
ference on Artificial Intelligence, Feb 2021, Virtual, France. ￿hal-03147623￿

HAL Id: hal-03147623

https://inria.hal.science/hal-03147623

Submitted on 20 Feb 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

0
2
0
2
c
e
D
0
1

]
I

A
.
s
c
[

2
v
5
4
0
4
1
.
7
0
0
2
:
v
i
X
r
a

The Tractability of SHAP-Score-Based Explanations over Deterministic and
Decomposable Boolean Circuits

Marcelo Arenas1,2,3, Pablo Barcel´o2,3, Leopoldo Bertossi4,3, Mika¨el Monet5
1 Department of Computer Science, Universidad Cat´olica de Chile
2 Institute for Mathematical and Computational Engineering, Universidad Cat´olica de Chile
3 IMFD Chile
4 Universidad Adolfo Ib´a˜nez, FIC, Chile
5 Inria Lille – Nord Europe & UMR 9189 CRIStAL, France

Abstract

Scores based on Shapley values are widely used for provid-
ing explanations to classiﬁcation results over machine learn-
ing models. A prime example of this is the inﬂuential SHAP-
score, a version of the Shapley value that can help explain
the result of a learned model on a speciﬁc entity by assigning
a score to every feature. While in general computing Shap-
ley values is a computationally intractable problem, it has re-
cently been claimed that the SHAP-score can be computed in
polynomial time over the class of decision trees. In this paper,
we provide a proof of a stronger result over Boolean models:
the SHAP-score can be computed in polynomial time over
deterministic and decomposable Boolean circuits. Such cir-
cuits, also known as tractable Boolean circuits, generalize a
wide range of Boolean circuits and binary decision diagrams
classes, including binary decision trees, Ordered Binary De-
cision Diagrams (OBDDs) and Free Binary Decision Dia-
grams (FBDDs). We also establish the computational limits
of the notion of SHAP-score by observing that, under a mild
condition, computing it over a class of Boolean models is al-
ways polynomially as hard as the model counting problem
for that class. This implies that both determinism and decom-
posability are essential properties for the circuits that we con-
sider, as removing one or the other renders the problem of
computing the SHAP-score intractable (namely, #P-hard).

1 Introduction
Explainable artiﬁcial intelligence has become an active area
of research. Central to it is the observation that artiﬁcial in-
telligence (AI) and machine learning (ML) models cannot
always be blindly applied without being able to interpret and
explain their results. For example, when someone applies for
a loan and sees their application rejected by an algorithmic
decision-making system, the system should be able to pro-
vide an explanation for that decision. Explanations can be
global – focusing on the general input/output relation of the
model –, or local – focusing on how features affect the deci-
sion of the model for a speciﬁc input. Recent literature has
strengthened the importance of the latter by showing their
ability to provide explanations that are often overlooked by
global explanations (Molnar 2020).

One natural way of providing local explanations for clas-
siﬁcation models consists in assigning numerical scores to
the feature values of an entity that has gone through the

classiﬁcation process. Intuitively, the higher the score of a
feature value, the more relevant it should be considered.
It is in this context that the SHAP-score has been intro-
duced (Lundberg and Lee 2017; Lundberg et al. 2020). This
recent notion has rapidly gained attention and is becoming
inﬂuential. There are two properties of the SHAP-score that
support its rapid adoption. First, its deﬁnition is quite gen-
eral and can be applied to any kind of classiﬁcation model.
Second, the deﬁnition of the SHAP-score is grounded on
the well-known Shapley value (Shapley 1953; Roth 1988),
that has already been used successfully in several do-
mains of computer science; see, e.g., (Hunter and Konieczny
2010; Livshits et al. 2020; Michalak et al. 2013; Cesari et al.
2018). Thus, SHAP-scores have a clear, intuitive, combina-
torial meaning, and inherit all the desirable properties of the
Shapley value.

For a given classiﬁer M , entity e and feature x,
the SHAP-score SHAP(M, e, x) intuitively represents the
importance of the feature value e(x) to the classiﬁcation
result M (e). In its general formulation, SHAP(M, e, x)
is a weighted average of differences of expected values
of the outcomes (c.f. Section 2 for its formal deﬁnition).
Unfortunately, computing quantities that are based on the
notion of Shapley value is in general intractable. Indeed,
in many scenarios the computation turns out to be #P-
hard (Faigle and Kern 1992; Deng and Papadimitriou 1994;
Livshits et al. 2020; Bertossi et al. 2020), which makes the
notion difﬁcult to use – if not impossible – for practical pur-
poses (Arora and Barak 2009). Therefore, a natural question
is: For what kinds of classiﬁcation models the computation
of the SHAP-score can be done efﬁciently? This is the sub-
ject of this paper.

In this work, we focus on classiﬁers working with binary
feature values (i.e., propositional features that can take the
values 0 or 1), and that return 1 (accept) or 0 (reject) for
each entity. We will call these Boolean classiﬁers. The sec-
ond assumption that we make is that the underlying prob-
ability distribution on the population of entities is what we
call a product distribution, where each binary feature x has
a probability p(x) of being equal to 1, independently of the
other features. We note here that the restriction to binary in-
puts can be relevant in many practical scenarios where the
features are of a propositional nature.

 
 
 
 
 
 
More speciﬁcally, we investigate Boolean classiﬁers de-
ﬁned as deterministic and decomposable Boolean circuits, a
widely studied model in knowledge compilation (Darwiche
2001; Darwiche and Marquis 2002). Such circuits encom-
pass a wide range of Boolean models and binary deci-
sion diagrams classes that are considered in knowledge
compilation, and in AI more generally. For instance, they
generalize binary decision trees, ordered binary decision
diagrams (OBDDs), free binary decision diagrams (FB-
DDs), and deterministic and decomposable negation normal
norms (d-DNNFs) (Darwiche 2001; Amarilli et al. 2020;
Darwiche and Hirth 2020). These circuits are also known
under the name of tractable Boolean circuits, that is used in
recent literature (Shih, Darwiche, and Choi 2019; Shi et al.
2020; Shih, Choi, and Darwiche 2018b,a; Shih et al. 2019;
Peharz et al. 2020). We provide an example of a determin-
istic and decomposable Boolean circuit next (and give the
formal deﬁnition in Section 2).

Example 1.1. We want to classify papers submitted to
a conference as rejected (Boolean value 0) or accepted
(Boolean value 1). Papers are described by features fg, dtr,
nf and na, which stand for “follows guidelines”, “deep the-
oretical result”, “new framework” and “nice applications”,
respectively. The Boolean classiﬁer for the papers is given
by the Boolean circuit in Figure 1. The input of this cir-
cuit are the features fg, dtr, nf and na, each of which can
take value either 0 or 1, depending on whether the feature is
present (1) or absent (0). The nodes with labels ¬, ∨ or ∧ are
logic gates, and the associated Boolean value of each one of
them depends on the logical connective represented by its
label and the Boolean values of its inputs. The output value
of the circuit is given by the top node in the ﬁgure.

The Boolean circuit in Figure 1 is said to be decompos-
able, because for each ∧-gate, the sets of features of its in-
puts are pairwise disjoint. For instance, in the case of the top
node in Figure 1, the left-hand side input has {fg} as its set
of features, while its right-hand side input has {dtr, nf, na}
as its set of features, which are disjoint. Also, this circuit is
said to be deterministic, which means that for every ∨-gate,
two (or more) of its inputs cannot be given value 1 by the
same Boolean assignment for the features. For instance, in
the case of the only ∨-gate in Figure 1, if a Boolean assign-
ment for the features gives value 1 to its left-hand side input,
then feature dtr has to be given value 1 and, thus, such an as-
signment gives value 0 to the right-hand side input of the ∨-
gate. In the same way, it can be shown that if a Boolean
assignment for the features gives value 1 to the right-hand
side input of this ∨-gate, then it gives value 0 to its left-hand
side input.

Readers who are not familiar with knowledge compila-
tion can simply think about deterministic and decomposable
circuits as a tool for establishing in a uniform manner the
tractability of computing SHAP-scores on several Boolean
classiﬁer classes. Our main contributions are the following:

1. We provide a polynomial

time algorithm that com-
putes the SHAP-score for deterministic and decompos-
able Boolean circuits, in the special case of uniform prob-

fg

∧

dtr

∨

¬

nf

∧

na

Figure 1: A deterministic and decomposable Boolean Circuit
as a classiﬁer.

ability distributions (that is, when each p(x) is 1
2 ). In par-
ticular, this provides a precise proof of the claim made in
(Lundberg et al. 2020) that the SHAP-score for Boolean
classiﬁers given as decision trees can be computed in
polynomial time. Moreover, we also obtain as a corollary
that the SHAP-score for Boolean classiﬁers given as OB-
DDs, FBDDs and d-DNNFs can be computed in polyno-
mial time.

2. We observe that computing the SHAP-score on Boolean
circuits in a class is always polynomially as hard as the
model counting problem for that class (under a mild con-
dition). By using this observation, we obtain that each one
of the determinism assumption and the decomposability
assumption is necessary for tractability.

3. Last, we show that the results above (and most interest-
ingly, the polynomial-time algorithm) can be extended to
the SHAP-score deﬁned on product distributions for the
entity population.

Our contributions should be compared to the results ob-
tained in the contemporaneous paper (Van den Broeck et al.
2020). There, the authors establish the following theorem:
for every class C of classiﬁers and under product distribu-
tions, the problem of computing the SHAP-score for C is
polynomial-time equivalent to the problem of computing the
expected value for the models in C. Since computing expec-
tations is in polynomial time for tractable Boolean circuits,
this in particular implies that computing the SHAP-score is
in polynomial time for the circuits that we consider; in other
words, their results capture ours. However, there is a funda-
mental difference in the approach taken to show tractability:
their reduction uses multiple oracle calls to the problem of
computing expectations, whereas we provide a more direct
algorithm to compute the SHAP-score on these circuits.

Our algorithm for computing the SHAP-score could be
used in practical scenarios. Indeed, recently, some classes
of classiﬁers have been compiled into tractable Boolean cir-
cuits. This is the case, for instance, of Bayesian Classi-
ﬁers (Shih, Choi, and Darwiche 2018a), Binary Neural Net-
works (Shi et al. 2020), and Random Forests (Choi et al.
2020). The idea is to start with a Boolean classiﬁer M given
in a formalism that is hard to interpret – for instance a Bi-
nary neural network – and to compute a tractable Boolean
circuit M ′ that is equivalent to M (this computation can be

2

expensive). One can then use M ′ and the nice properties of
tractable Boolean circuits to interpret the decisions of the
model. Hence, this makes it possible to apply the results in
this paper on the SHAP-score to those classes of classiﬁers.

Paper structure. We give preliminaries in Section 2.
In Section 3, we prove that the SHAP-score can be com-
puted in polynomial time for deterministic and decompos-
able Boolean circuits for uniform probability distributions.
In Section 4 we establish the limits of the tractable compu-
tation of the SHAP-score. Next we show in Section 5 that
our results extend to the setting where we consider product
distributions. We conclude and discuss future work in Sec-
tion 6.

2 Preliminaries

2.1 Entities, distributions and classiﬁers
Let X be a ﬁnite set of features, also called variables. An
entity over X is a function e : X → {0, 1}. We denote
by ent(X) the set of all entities over X. On this set, we con-
sider the uniform probability distribution, i.e., for an event
E ⊆ ent(X), we have that P (E) := |E|
2|X| . We will come
back to this assumption in Section 5, where we will con-
sider the more general product distributions (we start with
the uniform distribution to ease the presentation).

A Boolean classiﬁer M over X is a function M :
ent(X) → {0, 1} that maps every entity over X to 0 or 1.
We say that M accepts an entity e when M (e) = 1, and that
it rejects it if M (e) = 0. Since we consider ent(X) to be a
probability space, M can be regarded as a random variable.

2.2 The SHAP-score over Boolean classiﬁers
Let M : ent(X) → {0, 1} be a Boolean classiﬁer over the
set X of features. Given an entity e over X and a subset S ⊆
X of features, the set cw(e, S) := {e′ ∈ ent(X) | e′(x) =
e(x) for each x ∈ S} contains those entities that coincide
with e over each feature in S. In other words, cw(e, S) is the
set of entities that are consistent with e on S. Then, given an
entity e ∈ ent(X) and S ⊆ X, we deﬁne the expected value
of M over X \ S with respect to e as

φ(M, e, S) := E

M (e′) | e′ ∈ cw(e, S)

.

Since we consider the uniform distribution over ent(X),

(cid:2)

(cid:3)

we have that

φ(M, e, S) =

1

2|X\S| M (e′).

e′∈cw(e,S)
X
Intuitively, φ(M, e, S) is the probability that M (e′) = 1,
conditioned on the inputs e′ ∈ ent(X) to coincide with e
over each feature in S. This function is then used in the gen-
eral formula of the Shapley value (Shapley 1953; Roth 1988)
to obtain the SHAP-score for feature values in e.
Deﬁnition 2.1. Given a Boolean classiﬁer M over a set of
features X, an entity e over X, and a feature x ∈ X, the
SHAP score of feature x on e with respect to M is deﬁned as

SHAP(M, e, x) :=

|S|! (|X| − |S| − 1)!
|X|!

(cid:18)

XS⊆X\{x}

φ(M, e, S ∪ {x}) − φ(M, e, S)

.
(cid:19)

(1)

Thus, SHAP(M, e, x) is a weighted average of the con-
tribution of feature x on e to the classiﬁcation result, i.e., of
the differences between having it and not, under all possi-
ble permutations of the other feature values. Observe that,
from this deﬁnition, a high positive value of SHAP(M, e, x)
intuitively means that setting x to e(x) strongly leans the
classiﬁer towards acceptance, while a high negative value
of SHAP(M, e, x) means that setting x to e(x) strongly
leans the classiﬁer towards rejection.

2.3 Deterministic and decomposable Boolean

circuits

A Boolean circuit over a set of variables X is a directed
acyclic graph C such that

(i) Every node without incoming edges is either a variable
gate or a constant gate. A variable gate is labeled with
a variable from X, and a constant gate is labeled with
either 0 or 1;

(ii) Every node with incoming edges is a logic gate, and is
labeled with a symbol ∧, ∨ or ¬. If it is labeled with the
symbol ¬, then it has exactly one incoming edge;1
(iii) Exactly one node does not have any outgoing edges, and

this node is called the output gate of C.

Such a Boolean circuit C represents a Boolean classiﬁer in
the expected way – we assume the reader to be familiar with
Boolean logic –, and we write C(e) for the value in {0, 1} of
the output gate of C when we evaluate C over the entity e.
Several restrictions of Boolean circuits with good compu-
tational properties have been studied. Let C be a Boolean
circuit over a set of variables X and g a gate of C. The
Boolean circuit Cg over X is deﬁned by considering the sub-
graph of C induced by the set of gates g′ in C for which there
exists a path from g′ to g in C. Notice that g is the output gate
of Cg. The set var(g) is deﬁned as the set of variables x ∈ X
such that there exists a variable gate with label x in Cg.
Then, an ∨-gate g of C is said to be deterministic if for
every pair g1, g2 of distinct input gates of g, the Boolean
circuits Cg1 and Cg2 are disjoint in the sense that there is no
entity e that is accepted by both Cg1 and Cg2 (that is, there
is no entity e ∈ ent(X) such that Cg1 (e) = Cg2 (e) = 1).
The circuit C is called deterministic if every ∨-gate of C is
deterministic. An ∧-gate g of C is said to be decomposable
if for every pair g1, g2 of distinct input gates of g, we have
that var(g1) ∩ var(g2) = ∅. Then, C is called decomposable
if every ∧-gate of C is decomposable.

1Recall that the fan-in of a gate is the number of its input gates.
In our deﬁnition of Boolean circuits, we allow unbounded fan-in ∧-
and ∨-gates.

3

Example 2.2. In Example 1.1, we explained at an intu-
itive level why the Boolean circuit in Figure 1 is determinis-
tic and decomposable. By using the terminology deﬁned in
the previous paragraph, it can be formally checked that this
Boolean circuit indeed satisﬁes these conditions.

As mentioned before, deterministic and decomposable
Boolean circuits generalize many decision diagrams and
Boolean circuits classes. We refer to (Darwiche 2001;
Amarilli et al. 2020) for detailed studies of knowledge com-
pilation classes and of their precise relationships. For the
reader’s convenience, we explain in the supplementary ma-
terial how FBDDs and binary decision trees can be encoded
in linear time as deterministic and decomposable Boolean
circuits.

3 Tractable Computation of the SHAP-Score
In this section, we prove our ﬁrst tractability result, namely,
that computing the SHAP-score for Boolean classiﬁers
given as deterministic and decomposable Boolean circuits
can be done in polynomial time, for uniform probability dis-
tributions. Formally:
Theorem 3.1. The following problem can be solved in poly-
nomial time. Given as input a deterministic and decompos-
able Boolean circuit C over a set of features X, an en-
tity e : X → {0, 1}, and a feature x ∈ X, compute the
value SHAP(C, e, x).

In particular, since binary decision trees, OBDDs, FBDDs
and d-DNNFs are all restricted kinds of deterministic and
decomposable circuits, we obtain as a consequence of The-
orem 3.1 that this problem is also in polynomial time for
these classes. For instance, for binary decision trees we ob-
tain:
Corollary 3.2. The following problem can be solved in poly-
nomial time. Given as input a binary decision tree T over a
set of features X, an entity e : X → {0, 1}, and a fea-
ture x ∈ X, compute the value SHAP(T, e, x).

The authors of (Lundberg et al. 2020) give a proof of
this result, but, unfortunately, with few details to fully un-
derstand it. Moreover, it is important to notice that Theo-
rem 3.1 is a nontrivial extension of the result for decision
trees, as it is known that deterministic and decomposable
circuits can be exponentially more succinct than binary de-
cision trees (in fact, than FBDDs) at representing Boolean
classiﬁers (Darwiche 2001; Amarilli et al. 2020).

In order to prove Theorem 3.1, we need to introduce some
notation. Let M be a Boolean classiﬁer over a set of fea-
tures X. We write SAT(M ) ⊆ ent(X) for the set of enti-
ties that are accepted by M , and #SAT(M ) for the cardi-
nality of this set. Let e, e′ ∈ ent(X) be a pair of entities
over X. We deﬁne sim(e, e′) := {x ∈ X | e(x) = e′(x)}
to be the set of features on which e and e′ coincide. Given
a Boolean classiﬁer M over X, an entity e ∈ ent(X) and a
natural number k ≤ |X|, we deﬁne the set SAT(M, e, k) :=
SAT(M ) ∩ {e′ ∈ ent(X) |
|sim(e, e′)| = k}, in other
words, the set of entities e′ that are accepted by M and
which coincide with e in exactly k features. Naturally, we
write #SAT(M, e, k) for the size of SAT(M, e, k).

Example 3.3. Let M be the Boolean classiﬁer represented
by the circuit in Example 1.1. Then SAT(M ) is the set
containing all papers that are accepted according to M , so
that #SAT(M ) = 5. Now, consider the entity e such that
e(fg) = 1, e(dtr) = 1, e(nf) = 0 and e(na) = 1. Then
one can check that #SAT(M, e, 0) = 0, #SAT(M, e, 1) =
0, #SAT(M, e, 2) = 2, #SAT(M, e, 3) = 2 and
#SAT(M, e, 4) = 1.

Our proof of Theorem 3.1 is technical and is divided into
two modular parts. The ﬁrst part, which is developed in Sec-
tion 3.1, consists in showing that the problem of comput-
ing SHAP(·, ·, ·) can be reduced in polynomial time to that
of computing #SAT(·, ·, ·). This part of the proof is a se-
quence of formula manipulations, and it only uses the fact
that deterministic and decomposable circuits can be efﬁ-
ciently conditioned on a variable value (to be deﬁned in Sec-
tion 3.1). In the second part of the proof, which is developed
in Section 3.2, we show that computing #SAT(·, ·, ·) can be
done in polynomial time for deterministic and decompos-
able Boolean circuits. It is in this part that the properties of
deterministic and decomposable circuits are really used.

3.1 Reducing SHAP(·, ·, ·) to #SAT(·, ·, ·)

In this section, we show that for deterministic and decom-
posable Boolean circuits, the computation of the SHAP-
score can be reduced in polynomial time to the computa-
tion of #SAT(·, ·, ·). To achieve this, we will need two more
deﬁnitions. Let M be a Boolean classiﬁer over a set of fea-
tures X and x ∈ X, and let Boolean classiﬁers M+x :
ent(X \ {x}) → {0, 1} and M−x : ent(X \ {x}) →
{0, 1} be deﬁned as follows. For e ∈ ent(X \ {x}), we
write e+x and e−x the entities over X such that e+x(x) =
1, e−x(x) = 0 and e+x(y) = e−x(y) = e(y) for every y ∈
X \ {x}. Then deﬁne M+x(e) := M (e+x) and M−x(e) :=
M (e−x). In the literature, M+x (resp., M−x) is called the
conditioning by x (resp., by ¬x) of M . Conditioning can
be done in linear time for a Boolean circuit C by replac-
ing every gate with label x by a constant gate with label 1
(resp., 0). We write C+x (resp., C−x) for the Boolean circuit
obtained via this transformation. One can easily check that,
if C is deterministic and decomposable, then C+x and C−x
are deterministic and decomposable as well.

We now introduce the second deﬁnition needed for the
proof. For a Boolean classiﬁer M over a set of variables X,
an entity e ∈ ent(X) and an integer k ≤ |X|, we deﬁne

H(M, e, k) :=

M (e′).

(2)

S⊆X
X
|S|=k X

e′∈cw(e,S)

We ﬁrst explain how computing SHAP(·, ·, ·) can be reduced
in polynomial time to the problem of computing H(·, ·, ·),
and then how computing H(·, ·, ·) can be reduced in polyno-
mial time to computing #SAT(·, ·, ·).

Reducing from SHAP(·, ·, ·) to H(·, ·, ·). We need to
compute SHAP(C, e, x), for a given deterministic and de-
composable circuit C over a set of variables X, entity e ∈

4

k=0
X

ent(X), and feature x ∈ X. Let n = |X|, and deﬁne
Diﬀk(C, e, x) :=

(φ(C, e, S ∪{x})− φ(C, e, S)).

XS⊆X\{x}
|S|=k

Then by the deﬁnition of the SHAP-score in (1), we have:

SHAP(C, e, x) =

n−1

k!(n − k − 1)!
n!

Diﬀk(C, e, x).

Observe that all arithmetical terms (such as k! or n!) can
be computed in polynomial time: this is simply because n
is given in unary, as it is bounded by the size of the cir-
cuit. Therefore, it is enough to show how to compute in
polynomial time the quantities Diﬀk(C, e, x) for each k ∈
{0, . . . , n − 1}, as n = |X| is bounded by the size
of the input (C, e, x). By deﬁnition of φ(·, ·, ·), we have
that Diﬀk(C, e, x) = α − β, where:

α =

β =

XS⊆X\{x}
|S|=k

XS⊆X\{x}
|S|=k

1
2n−(k+1)

1
2n−k

C(e′)

e′∈cw(e,S∪{x})
X

C(e′).

e′∈cw(e,S)
X

Next we show how the computation of α and β can be re-
duced in polynomial-time to the computation of H(·, ·, ·).
For an entity e ∈ ent(X) and S ⊆ X, let e|S be the en-
tity over S that is obtained by restricting e to the domain S
(that is, formally e|S ∈ ent(S) and e|S(y) := e(y) for ev-
ery y ∈ S). Then, starting with β, we have that:

β =

XS⊆X\{x}
|S|=k

=

(cid:20) XS⊆X\{x}
|S|=k

1
2n−k

1
2n−k

C(e′)

e′∈cw(e,S)
X

C(e′)
(cid:21)

e′∈cw(e,S)
X
e′(x)=1

1
2n−k

+

(cid:20) XS⊆X\{x}
|S|=k

C(e′)
(cid:21)

e′∈cw(e,S)
X
e′(x)=0

1
2n−k

=

(cid:20)

XS⊆X\{x}
|S|=k

1
2n−k

+

(cid:20)

e′′∈cw(e

|X\{x},S)

X

C+x(e′′)
(cid:21)

XS⊆X\{x}
|S|=k

e′′∈cw(e

|X\{x},S)

X

C−x(e′′)
(cid:21)

=

1
2n−k

(cid:18)

H(C+x, e|X\{x}, k) + H(C−x, e|X\{x}, k)

.
(cid:19)

The last equality is obtained by using the deﬁnition
of H(·, ·, ·). A similar analysis allows us to conclude that:

1
2n−(k+1)
1
2n−(k+1)

α = 




H(C+x, e|X\{x}, k),
H(C−x, e|X\{x}, k),

if C(e) = 1

if C(e) = 0

.

5

Hence, if we can compute in polynomial time H(·, ·, ·)
for deterministic and decomposable Boolean circuits, then
we can compute α and β in polynomial time (because C+x
and C−x can be computed in linear time from C, and they
are deterministic and decomposable as well). Thus, we can
compute Diﬀk(C, e, x) in polynomial time for each k ∈
{0, . . . , n − 1} and, hence, SHAP(C, e, x) as well. In con-
clusion, SHAP(C, e, x) can be computed in polynomial time
if there is a polynomial-time algorithm to compute H(·, ·, ·)
for deterministic and decomposable Boolean circuits.

Reducing from H(·, ·, ·) to #SAT(·, ·, ·). We now show
that computing H(·, ·, ·) can be reduced in polynomial time
to computing #SAT(·, ·, ·). Given as input a determinis-
tic and decomposable circuit C over a set of variables X,
an entity e ∈ ent(X), and an integer k ≤ |X|, recall
the deﬁnition of H(C, e, x) in (2). Then consider an en-
tity e′′ ∈ ent(X) and reason about how many times e′′
will occur as a summand in the expression (2). First of
all, it is clear that if |sim(e, e′′)| < k, then e′′ will not
appear in the sum; this is because if e′ ∈ cw(e, S) for
some S ⊆ X such that |S| = k, then S ⊆ sim(e, e′)
and, thus, k ≤ |sim(e, e′)|. Now, how many times does an
entity e′′ ∈ ent(X) such that |sim(e, e′′)| ≥ k occur as
a summand in the expression? The answer is simple: once
|sim(e,e′′)|
per S ⊆ sim(e, e′′) of size k. Since there are
k
such sets S, we obtain that H(C, e, k) is equal to
(cid:0)

(cid:1)

|sim(e, e′′)|
k

· C(e′′)

(cid:19)

e′′∈ent(X)
X
|sim(e,e′′)|≥k

(cid:18)

=

=

=

|sim(e, e′′)|
k

(cid:19)

e′′∈SAT(C)
X
|sim(e,e′′)|≥k

(cid:18)

n

ℓ=k
X

e′′∈SAT(C)
X
|sim(e,e′′)|=ℓ

(cid:18)

|sim(e, e′′)|
k

(cid:19)

n

n

ℓ
k

ℓ=k (cid:18)
X

1 =

(cid:19) X

e′′∈SAT(C)
|sim(e,e′′)|=ℓ

ℓ=k (cid:18)
X

ℓ
k

· #SAT(C, e, ℓ),

(cid:19)

with the last equality being obtained by using the deﬁnition
of #SAT(·, ·, ·). This concludes the reduction of this section
and, hence, the ﬁrst part of the proof.

3.2 Computing #SAT(·, ·, ·) in polynomial time
We now take care of the second part of the proof of The-
orem 3.1, i.e., proving that computing #SAT(·, ·, ·) for de-
terministic and decomposable Boolean circuits can be done
in polynomial time. To do this, given a deterministic and
decomposable Boolean circuit C, we ﬁrst perform two pre-
processing steps on C, which will simplify the proof.

• Rewriting to fan-in at most 2. First, we modify the cir-
cuit C so that the fan-in of every ∨- and ∧-gate is at
most 2. This can simply be done in linear time by rewrit-
ing every ∧-gate (resp., and ∨-gate) of fan-in m > 2 with

a chain of m − 1 ∧-gates (resp., ∨-gates) of fan-in 2. It
is clear that the resulting Boolean circuit is deterministic
and decomposable. Hence, from now on we assume that
the fan-in of every ∨- and ∧-gate of C is at most 2.

• Smoothing the circuit. A deterministic and decompos-
able circuit C is smooth (Darwiche 2001; Shih et al.
2019) if for every ∨-gate g and input gates g1, g2 of g,
we have that var(g1) = var(g2), and we call such an ∨-
gate smooth. A standard construction allows to trans-
form in polynomial time a deterministic and decompos-
able Boolean circuit C into an equivalent smooth deter-
ministic and decomposable Boolean circuit, and where
each gate has fan-in at most 2. Thus, from now on we also
assume that C is smooth. We illustrate how the construc-
tion works in Example 3.4 . Full details can be found in
the supplementary material (namely, in Section E.2, para-
graph Smoothing the circuit).

We have all the ingredients to prove that #SAT(·, ·, ·)
can be computed in polynomial time. Let C be a determin-
istic and decomposable Boolean circuit over a set of vari-
ables X, e ∈ ent(X), ℓ a natural number such that ℓ ≤ |X|
and n = |X|. For a gate g of C, let Rg be the Boolean cir-
cuit over var(g) that is deﬁned by considering the subgraph
of C induced by the set of gates g′ in C for which there
exists a path from g′ to g in C. Notice that Rg is a determin-
istic and decomposable Boolean circuit with output gate g.
Moreover, for a gate g and natural number k ≤ |var(g)|,
:= #SAT(Rg, e|var(g), k), which we recall is
deﬁne αk
g
the number of entities e′ ∈ ent(var(g)) such that e′ satis-
ﬁes Rg and |sim(e|var(g), e′)| = k. We will show how to
compute all the values αk
g for every gate g of C and k ∈
{0, . . . , |var(g)|} in polynomial time. This will conclude
the proof since, for the output gate gout of C, we have
gout = #SAT(C, e, ℓ). Next we explain how to com-
that αℓ
pute these values in a bottom-up manner.

g = 1 − e(y) and α1

Then var(g) = ∅ and α0

that var(g) = {y}. Then α0

Variable gate. g is a variable gate with label y ∈ X, so
g = e(y).
Constant gate. g is a constant gate with label a ∈ {0, 1}.
g = a.2
¬-gate. g is a ¬-gate with input gate g′. Then var(g) =
var(g′), and the values αk
g′ for k ∈ {0, . . . , |var(g)|}
have already been computed. Fix k ∈ {0, . . . , |var(g)|}.
is equal to the number of entities e′ ∈
Since
ent(var(g)) such that |sim(e|var(g), e′)| = k, we have that
|var(g)|
k

|var(g)|
k

− αk
g′ .

g =

αk

(cid:0)

(cid:1)

(cid:19)

(cid:18)
|var(g)|
k

Therefore, given that
can be computed in poly-
nomial time since k ≤ |var(g)| ≤ n = |X|, we have an
(cid:1)
efﬁcient way to compute αk
g .
∨-gate. g is an ∨-gate. By assumption, g is deter-
ministic, smooth and has fan-in at most 2. If g has

(cid:0)

2We recall the mathematical convention that there is a unique
function with the empty domain and, hence, a unique entity over ∅.

e

6

∈

each k

g = αk
g′

then clearly var(g) = var(g′)
only one input g′,
for every k ∈ {0, . . . , |var(g)|}.
and αk
Thus, assume that g has exactly two input gates g1
and g2, and recall that var(g1) = var(g2) = var(g),
and αk
because g is smooth. Also, recall that αk
,
g2
g1
{0, . . . , |var(g)|}, have
for
already
{0, . . . , |var(g)|}.
been
∈
k
and smooth, we
is deterministic
Given that
SAT(Rg1 ) ∪ SAT(Rg2 ),
have that SAT(Rg)
=
where SAT(Rg1 ) ∩ SAT(Rg2 ) = ∅. By intersecting these
three sets with the set {e′ ∈ var(g) | |sim(e|var(g), e′)| =
k}, we
=
SAT(Rg1 , e|var(g), k) ∪ SAT(Rg2 , e|var(g), k), where
SAT(Rg1 , e|var(g), k) ∩ SAT(Rg2 , e|var(g), k) = ∅. Hence:

computed. Fix
g

SAT(Rg, e|var(g), k)

obtain

that

#SAT(Rg, e|var(g), k) =

#SAT(Rg1 , e|var(g), k) + #SAT(Rg2 , e|var(g), k),

g1 + αk
g = αk
or, in other words, we have that αk
we have an efﬁcient way to compute αk
g .

g2 . Hence,

∧-gate. g is an ∧-gate. By assumption, recall that g is de-
composable and has fan-in at most 2. If g has only one
input g′, then clearly var(g) = var(g′) and αk
g = αk
g′
for every k ∈ {0, . . . , |var(g)|}. Thus, assume that g
has exactly two input gates g1 and g2. Recall then that
g2 , for each i ∈ {0, . . . , |var(g1)|}
the values αi
and j ∈ {0, . . . , |var(g2)|}, have already been computed.
Fix k ∈ {0, . . . , |var(g)|}. Given that g is a decompos-
able ∧-gate, in this case it is possible to prove that:

g1 and αj

αk

g =

g1 · αj
αi

g2 .

(3)

Xi∈{0,...,|var(g1)|}
j∈{0,...,|var(g2)|}
i+j=k

The complete proof of this property can be found in Ap-
pendix B. Therefore, as in the previous cases, we conclude
that there is an efﬁcient way to compute αk
g .

This concludes the proof that #SAT(·, ·, ·) can be com-
puted in polynomial time for deterministic and decompos-
able Boolean circuits and, hence, the proof of Theorem 3.1.

Example 3.4. We illustrate how the algorithm for com-
puting the SHAP-score operates on the Boolean circuit C
that C is deﬁned over
given in Example 1.1. Recall
X = {fg, dtr, nf, na}, and assume we want
to com-
pute SHAP(C, e, nf) for the entity e with e(x) = 1
for each x ∈ X. By the polynomial time reductions
shown in Section 3.1, to compute SHAP(C, e, nf) it sufﬁces
to compute H(C−nf, e
|X\{nf}, ℓ)
for each ℓ ∈ {0, . . . , 3}, which in turn reduces
to the computation of #SAT(C−nf, e
|X\{nf}, ℓ) and
#SAT(C+nf, e
|X\{nf}, ℓ) for each ℓ ∈ {0, . . . , 3}. In
what
follows, we show how to compute the values
#SAT(C+nf, e

|X\{nf}, ℓ) and H(C+nf, e

|X\{nf}, ℓ).

For the sake of presentation, let D := C+nf and e⋆ =
|X\{nf}, so that we need to compute #SAT(D, e⋆, ℓ) for

α0 = 0
α1 = 0
α2 = 2
α3 = 1

α0 = 0
α1 = 1
α2 = 1

∧

∧

dtr

α0 = 0
α1 = 1

¬ α0 = 1
α1 = 0

na α0 = 0
α1 = 1

α0 = 0
α1 = 1

fg

α0 = 1
α1 = 1

∨

na

α0 = 0
α1 = 1

α0 = 0
α1 = 2
α2 = 1

∨

¬

α0 = 1
α1 = 0

1

α0 = 1

∧

α0 = 0
α1 = 1
α2 = 0

∧ α0 = 0
α1 = 1

na

α0 = 0
α1 = 1

Figure 2: Execution of our algorithm to compute #SAT(·,
·, ·) over the Boolean circuit C+nf from Example 3.4.

each ℓ ∈ {0, . . . , 3}. Notice that the values to be com-
puted are #SAT(D, e⋆, 0) = 0, #SAT(D, e⋆, 1) = 0,
#SAT(D, e⋆, 2) = 2 and #SAT(D, e⋆, 3) = 1. To com-
pute #SAT(D, e⋆, ℓ), we ﬁrst need to replace feature nf by
constant 1 in C to generate D = C+nf, and then we need to
transform D into a Boolean circuit that is smooth and where
each gate has fan-in at most 2. The result of this process is
shown in Figure 2, where the green node is added when re-
placing feature nf by constant 1, the gray node is added to
satisfy the restriction that each gate has fan-in at most 2, and
the blue nodes are added to have a smooth Boolean circuit.
The algorithm to compute #SAT(D, e⋆, ℓ) runs in a
bottom-up fashion on the Boolean circuit, computing for
g for k ∈ {0, . . . , |var(g)|}. We
each gate g the values αk
show these values next to each node in Figure 2, but omit-
ting gate subscripts. For instance, for a variable gate g with
label na, we have that var(g) = {na}, α0
g = 1,
|var(g)(na) = e⋆(na) = 1. Notice that for the out-
given that e⋆
put gate gout of the Boolean circuit, which is its top gate, we
have that #SAT(D, e⋆, ℓ) = αℓ
gout for each ℓ ∈ {0, . . . , 3},
which were the values to be computed.

g = 0 and α1

4 Limits on the Tractable Computation of

the SHAP-Score

We have shown that the SHAP-score can be computed in
polynomial time for deterministic and decomposable cir-
cuits. A natural question, then, is whether both determinism
and decomposability are necessary for this positive result to
hold. In this section we show this to be case, at least under
standard complexity assumptions. Recall that #P consists
of the class of functions that can be deﬁned by counting
the number of accepting paths of a non-deterministic Tur-
ing machine that works in polynomial time. The notion of

hardness for the class #P is deﬁned in terms of polynomial
time Turing reductions. Under widely-held complexity as-
sumptions, #P-hard problems cannot be solved in polyno-
mial time (Arora and Barak 2009). We can then prove the
following:
Theorem 4.1. The following problems are #P-hard.
1. Given as input a decomposable Boolean circuit C over
a set of features X, an entity e : X → {0, 1}, and a
feature x ∈ X, compute the value SHAP(C, e, x).

2. Given as input a deterministic Boolean circuit C over a
set of features X, an entity e : X → {0, 1}, and a fea-
ture x ∈ X, compute the value SHAP(C, e, x).
To prove Theorem 4.1, we start by showing that there is
a polynomial-time reduction from the problem of comput-
ing the number of entities that satisfy M , for M an arbi-
trary Boolean classiﬁer, to the problem of computing the
SHAP-score over M . This holds under the mild condition
that M (e) can be computed in polynomial time for an input
entity e, which is satisﬁed for all the Boolean circuits and
binary decision diagrams classes considered in this paper.
The proof of this result follows from well-known properties
of Shapley values. (A closely related result can be found as
Theorem 5.1 in (Bertossi et al. 2020)).
Lemma 4.2. Let M be a Boolean classiﬁer over a set of
features X. Then for every e ∈ ent(X) we have:

#SAT(M ) = 2|X|

M (e) −

(cid:18)

SHAP(M, e, x)

.
(cid:19)

x∈X
X

We prove Lemma 4.2 in the supplementary material.
Item (1) in Theorem 4.1 follows then by the following two
facts: (a) Counting the number of entities that satisfy a
DNF formula is a #P-hard problem (Provan and Ball 1983),
and (b) DNF formulae are particular kinds of decomposable
Boolean circuits. Analogously, item (2) in Theorem 4.1 can
be obtained from the following two facts: (a) Counting the
number of entities that satisfy a 3-CNF formula is a #P-hard
problem, and (b) from every 3-CNF formula ψ, we can build
in polynomial time an equivalent deterministic Boolean cir-
cuit Cψ. Details can be found in the supplementary material.

5 Tractability for the Product Distribution
In Section 2, we introduce the uniform distribution, and used
it so far as a basis for the SHAP-score. Another probabil-
ity space that is often considered on ent(X) is the prod-
uct distribution, deﬁned as follows. Let p : X → [0, 1]
be a function that associates to every feature x ∈ X a
value p(x) ∈ [0, 1]; intuitively, the probability that x takes
value 1. Then, the product distribution generated by p is the
probability distribution Πp over ent(X) such that, for ev-
ery e ∈ ent(X),

Πp(e) :=

p(x)

·

(1 − p(x))

.

(cid:18) Y
x∈X
e(x)=1

(cid:19)

(cid:18) Y
x∈X
e(x)=0

(cid:19)

That is, the product distribution that is determined by pre-
speciﬁed marginal distributions, and that makes the fea-
tures take values independently from each other. Observe

7

the effect of the probability distribution on the SHAP-
score: intuitively, the higher the probability of an entity,
the more impact this entity will have on the computation.
This can be used, for instance, to avoid bias in the explana-
tions (Lundberg and Lee 2017; Bertossi et al. 2020).

Notice that the uniform space is a special case of prod-
uct space, with Πp invoking p(x) := 1/2 for every x ∈ X.
Thus, our hardness results from Theorem 4.1 also hold in the
case where the probabilities p(x) are given as input. What is
more interesting is the fact that our tractability result from
Theorem 3.1 extends to product distributions. Formally:
Theorem 5.1. The following problem can be solved in
polynomial time. Given as input a deterministic and de-
composable circuit C over a set of features X, rational
probability values p(x) for every feature x ∈ X, an en-
tity e : X → {0, 1}, and a feature x ∈ X, compute the
value SHAP(C, e, x) under the probability distribution Πp.
The proof of Theorem 5.1 is more involved than that of
Theorem 3.1, and is provided in the supplementary mate-
rial. In particular, the main difﬁculty is that φ(M, e, S) is no
2|X\S| M (e′) (as it was the case
longer equal to
for the uniform space), because the entities do not all have
the same probability. This prevents us from being able to re-
duce to the computation of #SAT(·, ·, ·). Instead, we use a
different deﬁnition of H(·, ·, ·), and prove that it can directly
be computed in a bottom-up fashion on the circuits. We show
in Algorithm 1 our algorithm to compute the SHAP score
for deterministic and decomposable Boolean circuits under
product distributions, which can be extracted from the proof
in the supplementary material. Notice that by using the tech-
niques presented in Section 3, the ﬁrst step of the algorithm
transforms the input circuit C into an equivalent smooth cir-
cuit D where each ∨-gate and ∧-gate has fan-in 2.

e′∈cw(e,S)

P

1

6 Extensions and Future Work
We leave open many interesting directions for future work.
For instance, we intend to extend our algorithm for ef-
ﬁciently computing the SHAP-score to work with non-
Boolean classiﬁers, and to consider more general proba-
bility distributions that could better capture possible cor-
relations and dependencies between features. We also aim
to provide an experimental comparison of our algorithm,
but specialized for decision trees, with the one provided
in (Lundberg et al. 2020, Alg. 2). Last, we intend to test our
algorithm on real-world scenarios.

Acknowledgments

Pablo Barcel´o was funded by Fondecyt grant 1200967.

References
Amarilli, A.; Capelli, F.; Monet, M.; and Senellart, P. 2020.
Connecting knowledge compilation classes and width pa-
rameters. Theory Comput. Syst. 64(5): 861–914.
Arora, S.; and Barak, B. 2009. Computational Complexity -
A Modern Approach. Cambridge University Press.
Bertossi, L.; Li, J.; Schleich, M.; Suciu, D.; and Vagena,
Causality-based explanation of classiﬁcation
Z. 2020.

Algorithm 1: SHAP-scores for deterministic and de-
composable Boolean circuits

Input

: Deterministic and decomposable Boolean

circuit C over features X with ouput
gate gout, rational probability values p(x)
for all x ∈ X, entity e ∈ ent(X), and
feature x ∈ X.

Output: The value SHAP(C, e, x) under the
probability distribution Πp.

1 Transform C into an equivalent smooth circuit D
where each ∨-gate and ∧-gate has fan-in 2;
2 Compute the set var(g) for every gate g in D;
g and δℓ
3 Compute values γℓ
and ℓ ∈ {0, . . . , |var(g) \ {x}|} by bottom-up
induction on D as follows:

g for every gate g in D

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

if g is a constant gate with label a ∈ {0, 1} then

g , δ0
γ0

g ← a;

else if g is a variable gate with var(g) = {x}
then
γ0
g ← 1;
δ0
g ← 0;

else if g is a variable gate with var(g) = {y} and
y 6= x then
g , δ0
γ0
g , δ1
γ1

g ← p(y);
g ← e(y);

else if g is a ¬-gate with input gate g′ then
for ℓ ∈ {0, . . . , |var(g) \ {x}|} do
|var(g)\{x}|
ℓ
|var(g)\{x}|
(cid:0)
ℓ
(cid:0)

− γℓ
g′ ;
− δℓ
g′ ;

γℓ
g ←
δℓ
g ←

end

(cid:1)
(cid:1)

else if g is an ∨-gate with input gates g1, g2 then

for ℓ ∈ {0, . . . , |var(g) \ {x}|} do

g ← γℓ
γℓ
g ← δℓ
δℓ

g1 + γℓ
;
g2
g1 + δℓ
g2 ;

end

else if g is an ∧-gate with input gates g1, g2 then

γℓ
g ←

for ℓ ∈ {0, . . . , |var(g) \ {x}|} do
ℓ1∈{0,...,|var(g1)\{x}|}
ℓ2∈{0,...,|var(g2)\{x}|}
ℓ1+ℓ2=ℓ
ℓ1∈{0,...,|var(g1)\{x}|}
ℓ2∈{0,...,|var(g2)\{x}|}
ℓ1+ℓ2=ℓ

δℓ
g ←

P

P

end

g1 · γℓ2
γℓ1
g2 ;

g1 · δℓ2
δℓ1
g2 ;

k! (|X| − k − 1)!
|X|!

·

(cid:2)

(e(x) − p(x))(γk

gout − δk

gout)

;

(cid:3)

26
27 end
28 return
|X|−1

k=0
X

8

Roth, A. E. 1988. The Shapley value: essays in honor of
Lloyd S. Shapley. Cambridge University Press.
Shapley, L. S. 1953. A value for n-person games. Contribu-
tions to the Theory of Games 2(28): 307–317.

Shi, W.; Shih, A.; Darwiche, A.; and Choi, A. 2020. On
tractable representations of binary neural networks. arXiv
preprint arXiv:2004.02082 .

Shih, A.; Choi, A.; and Darwiche, A. 2018a. A symbolic
approach to explaining Bayesian network classiﬁers. In Pro-
ceedings IJCAI, 5103–5111.
Shih, A.; Choi, A.; and Darwiche, A. 2018b. Formal ver-
In International
iﬁcation of Bayesian network classiﬁers.
Conference on Probabilistic Graphical Models, 427–438.
Shih, A.; Darwiche, A.; and Choi, A. 2019. Verifying bina-
rized neural networks by Angluin-style learning. In Interna-
tional Conference on Theory and Applications of Satisﬁabil-
ity Testing, 354–370. Springer.

Shih, A.; Van den Broeck, G.; Beame, P.; and Amarilli, A.
2019. Smoothing structured decomposable circuits. In Ad-
vances in Neural Information Processing Systems, 11416–
11426.
Van den Broeck, G.; Lykov, A.; Schleich, M.; and Suciu, D.
2020. On the Tractability of SHAP Explanations. arXiv
preprint arXiv:2009.08634 .

outcomes.
Data Management
DEEM@SIGMOD 2020, 6:1–6:10.

In Proceedings of the Fourth Workshop on
for End-To-End Machine Learning,

Cesari, G.; Algaba, E.; Moretti, S.; and Nepomuceno, J. A.
2018. An application of the Shapley value to the analysis of
co-expression networks. Applied network science 3(1): 35.

Choi, A.; Shih, A.; Goyanka, A.; and Darwiche, A. 2020.
On Symbolically Encoding the Behavior of Random Forests.
CoRR abs/2007.01493.

Darwiche, A. 2001. On the tractable counting of theory
models and its application to truth maintenance and belief
revision. J. Applied Non-Classical Logics 11(1-2).

Darwiche, A.; and Hirth, A. 2020. On the reasons behind
decisions. arXiv preprint arXiv:2002.09284 .

Darwiche, A.; and Marquis, P. 2002. A Knowledge Compi-
lation Map. J. Artif. Intell. Res. 17: 229–264.

Deng, X.; and Papadimitriou, C. H. 1994. On the complexity
of cooperative solution concepts. Mathematics of operations
research 19(2): 257–266.

Faigle, U.; and Kern, W. 1992. The Shapley value for coop-
erative games under precedence constraints. International
Journal of Game Theory 21(3): 249–266.

Hunter, A.; and Konieczny, S. 2010. On the measure of con-
ﬂicts: Shapley inconsistency values. Artiﬁcial Intelligence
174(14): 1007–1026.

Livshits, E.; Bertossi, L. E.; Kimelfeld, B.; and Sebag, M.
2020. The Shapley value of tuples in query answering. In
23rd International Conference on Database Theory, ICDT
2020, March 30-April 2, 2020, Copenhagen, Denmark, vol-
ume 155, 20:1–20:19.

Lundberg, S. M.; Erion, G.; Chen, H.; DeGrave, A.; Prutkin,
J. M.; Nair, B.; Katz, R.; Himmelfarb, J.; Bansal, N.; and
Lee, S.-I. 2020. From local explanations to global under-
standing with explainable AI for trees. Nature machine in-
telligence 2(1): 2522–5839.

Lundberg, S. M.; and Lee, S.-I. 2017. A uniﬁed approach to
interpreting model predictions. In Advances in neural infor-
mation processing systems, 4765–4774.

Michalak, T. P.; Aadithya, K. V.; Szczepanski, P. L.; Ravin-
dran, B.; and Jennings, N. R. 2013. Efﬁcient computation
of the Shapley value for game-theoretic network centrality.
Journal of Artiﬁcial Intelligence Research 46: 607–650.

Interpretable machine learning:
Molnar, C. 2020.
A guide for making black box models explainable.
https://christophm.github.io/interpretable-ml-book.

Peharz, R.; Lang, S.; Vergari, A.; Stelzner, K.; Molina,
A.; Trapp, M.; Van den Broeck, G.; Kersting, K.; and
Ghahramani, Z. 2020. Einsum networks: Fast and scalable
learning of tractable probabilistic circuits. arXiv preprint
arXiv:2004.06231 .

Provan, J. S.; and Ball, M. O. 1983. The complexity of
counting cuts and of computing the probability that a graph
is connected. SIAM Journal on Computing 12(4): 777–788.

9

Supplementary Material: Technical Appendix

A Encoding Binary Decision Trees and FBDDs into Deterministic and Decomposable Boolean

Circuits

In this appendix, we explain why binary decision trees and free binary decision diagrams (FBDDs) are special kinds of deter-
ministic and decomposable Boolean circuits. First we need to deﬁne these formalisms.

Binary Decision Diagrams. A binary decision diagram (BDD) over a set of variables X is a rooted directed acyclic
graph D such that: (i) each internal node is labeled with a variable from X, and has exactly two outgoing edges: one
labeled 0, the other one labeled 1; and (ii) each leaf is labeled either 0 or 1. Such a BDD represents a Boolean classi-
ﬁer in the following way. Let e be an entity over X, and let πe = u1, . . . , um be the unique path in D satisfying the
following conditions: (a) u1 is the root of D; (b) um is a leaf of D; and (c) for every i ∈ {1, . . . , m − 1}, if the label
of ui is x ∈ X, then the label of the edge (ui, ui+1) is equal to e(x). Then the value of e in D, denoted by D(e), is
deﬁned as the label of the leaf um. Moreover, a binary decision diagram D is free (FBDD) if for every path from the root
to a leaf, no two nodes on that path have the same label, and a binary decision tree is an FBDD whose underlying graph is a tree.

As we show next, FBDDs can be encoded in linear time as deterministic and decomposable Boolean circuits.

Encoding FBDDs into deterministic and decomposable Boolean circuits (Folklore). Given an FBDD D over a set of
variables X, we explain how D can be encoded as a deterministic and decomposable Boolean circuit C over X. Notice that
the technique used in this example also apply to binary decision trees, as they are a particular case of FBDDs. The construction
of C is done by traversing the structure of D in a bottom-up manner. In particular, for every node u of D, we construct a
deterministic and decomposable circuit α(u) that is equivalent to the FBDD represented by the subgraph of D rooted at u.
More precisely, for a leaf u of D that is labeled with ℓ ∈ {0, 1}, we deﬁne α(u) to be the Boolean circuit consisting of only one
constant gate with label ℓ. For an internal node u of D labeled with variable x ∈ X, let u0 and u1 be the nodes that we reach
from u by following the 0- and 1-labeled edge, respectively. Then α(u) is the Boolean circuit depicted in the following ﬁgure:

∨

∧

∧

α(u0)

x

α(u1)

¬

x

It is clear that the circuit that we obtain is equivalent to the input FBDD. We now argue that this circuit is deterministic
and decomposable. For the ∨-gate shown in the ﬁgure, if an entity e is accepted by the Boolean circuit in its left-hand size,
then e(x) = 0, while if an entity e is accepted by the Boolean circuit in its right-hand size, then e(x) = 1. Hence, we have
that this ∨-gate is deterministic, from which we conclude that α(u) is deterministic, as α(u0) and α(u1) are also deterministic
by construction. Moreover, the ∧-gates shown in the ﬁgure are decomposable as variable x is mentioned neither in α(u0) nor
in α(u1): this is because D is a free BDD. Thus, we conclude that α(u) is decomposable, as α(u0) and α(u1) are decomposable
by construction. Finally, if uroot is the root of D, then by construction we have that α(uroot) is a deterministic and decomposable
Boolean circuit equivalent to D. Note that this encoding can trivially be done in linear time. Thus, we often say, by abuse of
terminology, that “FBDDs (or binary decision trees) are restricted kinds of deterministic and decomposable circuits”.

B Proof of Theorem 3.1
To complete the proof of Theorem 3.1, we need to prove equation (3). Recall that in this case, we have that g is an ∧-gate,
which is decomposable and has fan-in at most 2. Moreover, we assume that g has exactly two input gates g1 and g2, and we
ﬁx k ∈ {0, . . . , |var(g)|}.

To prove equation (3), we need the following notation. For two disjoint sets of variables X1, X2 and entities e1 ∈
ent(X1), e2 ∈ ent(X2), we denote by e1 ∪ e2 the entity over X1 ∪ X2 that coincides with e1 over X1 and with e2 over X2
(that is, e1 ∪ e2 ∈ ent(X1 ∪ X2), (e1 ∪ e2)(x1) = e1(x1) for every x1 ∈ X1, and (e1 ∪ e2)(x2) = e2(x2) for every x2 ∈ X2).
Moreover, for two sets S1 ⊆ ent(X1), S2 ⊆ ent(X2), we denote by S1 ⊗ S2 the set of entities over X1 ∪ X2 deﬁned as

S1 ⊗ S2 := {e1 ∪ e2 | e1 ∈ S1 and e2 ∈ S2}.

10

Given that g is a decomposable ∧-gate, we have that:

Moreover, we have that SAT(Rg, e|var(g), k) = SAT(Rg) ∩ {e′ ∈ var(g) | |sim(e|var(g), e′)| = k} and

SAT(Rg) = SAT(Rg1 ) ⊗ SAT(Rg2 ).

SAT(Rg1 ) ⊗ SAT(Rg2 )

∩ {e′ ∈ var(g) | |sim(e|var(g), e′)| = k}

(cid:0)

= {e1 ∪ e2 | e1 ∈ SAT(Rg1 ) and e2 ∈ SAT(Rg2 )} ∩ {e′ ∈ var(g) | |sim(e|var(g), e′)| = k}
= {e1 ∪ e2 | e1 ∈ SAT(Rg1 ), e2 ∈ SAT(Rg2 ), and |sim(e|var(g), e1 ∪ e2)| = k}
= {e1 ∪ e2 | e1 ∈ SAT(Rg1 ), e2 ∈ SAT(Rg2 ), and there exist i ∈ {0, . . . , |var(g1)|},

(cid:1)

j ∈ {0, . . . , |var(g2)|} such that |sim(e|var(g1), e1)| = i, |sim(e|var(g2), e2)| = j, and i + j = k}

=

=

{e1 | e1 ∈ SAT(Rg1 ) and |sim(e|var(g1), e1)| = i} ⊗

{e2 | e2 ∈ SAT(Rg2 ) and |sim(e|var(g2), e2)| = j}

SAT(Rg1 , e|var(g1), i) ⊗ SAT(Rg2 , e|var(g2), j).

[i∈{0,...,|var(g1)|}
j∈{0,...,|var(g2)|}
i+j=k

[i∈{0,...,|var(g1)|}
j∈{0,...,|var(g2)|}
i+j=k

Combining the previous results, we obtain that

SAT(Rg, e|var(g), k) =

SAT(Rg1 , e|var(g1), i) ⊗ SAT(Rg2 , e|var(g2), j).

Thus, given that for every pair i1, i2 ∈ {0, . . . , |var(g1)|} such that i1 6= i2, it holds that

[i∈{0,...,|var(g1)|}
j∈{0,...,|var(g2)|}
i+j=k

(and similarly for Rg2 ), we conclude by the deﬁnitions of αk

SAT(Rg1 , e|var(g1), i1) ∩ SAT(Rg1 , e|var(g1), i2) = ∅
g , αi

g2 that

g1 , αj

αk

g =

g1 · αj
αi

g2 ,

Xi∈{0,...,|var(g1)|}
j∈{0,...,|var(g2)|}
i+j=k

which was to be shown.

C Proof of Lemma 4.2
The validity of the equation from Lemma 4.2 will be consequence of the following property of the SHAP-score: for every
Boolean classiﬁer M over X, entity e ∈ ent(X) and feature x ∈ X, it holds that

SHAP(M, e, x) = φ(M, e, X) − φ(M, e, ∅).

(4)

x∈X
X

This property is often called the efﬁciency property of the Shapley value. Although this is folklore, we prove Equation (4) here
for the reader’s convenience. For a permutation π : X → {1, . . . , n} and x ∈ X, let Sx
π denote the set of features that appear
before x in π. Formally, Sx
π := {y ∈ X | π(y) < π(x)}. Then, letting Π(X) be the set of all permutations π : X → {1, . . . , n},
observe that the deﬁnition of SHAP-score from Deﬁnition 2.1 can be rewritten as

Hence, we have that

SHAP(M, e, x) =

SHAP(M, e, x) =

x∈X
X

=

1
n!

1
n!

1
n!

φ(M, e, Sx

π ∪ {x}) − φ(M, e, Sx
π)

.

Xπ∈Π(X)

(cid:0)

(cid:1)

x∈X
X

Xπ∈Π(X)

φ(M, e, Sx

π ∪ {x}) − φ(M, e, Sx
π)

(cid:0)
φ(M, e, Sx

(cid:1)
π ∪ {x}) − φ(M, e, Sx
π)

x∈X
Xπ∈Π(X) X

(cid:0)

11

(cid:1)

where the last equality is obtained by noticing that the inner sum is a telescoping sum. This establishes Equation (4). Now, we
simply use the deﬁnition of φ(·, ·, ·) in this equation to obtain

=

1
n!

Xπ∈Π(X)

(cid:0)

φ(M, e, X) − φ(M, e, ∅)

,

(cid:1)

SHAP(M, e, x) = M (e) −

x∈X
X

= M (e) −

M (e′)

1
2n

e′∈ent(X)
X
#SAT(M )
2n

,

thus proving Lemma 4.2.

D Proof of Theorem 4.1
We have already explained in the body of this article why Item (1) of Theorem 4.1 holds. We now justify that (2) holds, by
proving that from every 3-CNF formula ψ, we can build in polynomial time an equivalent deterministic Boolean circuit Cψ.

Given a clause γ = (ℓ1 ∨ ℓ2 ∨ ℓ3) consisting of three literals, deﬁne d(γ) as the propositional formula

(ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3) ∨ (ℓ1 ∧ ℓ2 ∧ ℓ3),

where x = ¬x and ¬x = x, for each propositional variable x. Clearly, γ and d(γ) are equivalent formulae. Moreover, given a
propositional formula ψ = γ1 ∧ · · · ∧ γk in 3-CNF, where each γi is a clause with three literals, deﬁne d(ψ) as the propositional
formula d(γ1) ∧ · · · ∧ d(γk). Clearly, ψ and d(ψ) are equivalent formulae, from which we have that #SAT(ψ) = #SAT(d(ψ)).
Moreover, d(ψ) can be directly transformed into a deterministic Boolean Circuit Cd(ψ). Hence, from the fact that Cd(ψ) can
be constructed in polynomial time from an input propositional formula ψ in 3-CNF, and the fact that #SAT(·) is #P-hard for
3-CNFs, we have that Theorem 4.1 (2) holds from Lemma 4.2.

E Proof of Theorem 5.1
In this section, we prove that computing the SHAP-score for Boolean classiﬁers given as deterministic and decomposable
Boolean circuits can be done in polynomial time for product distributions; see Theorem 5.1 for the formal statement. As
mentioned in Section 5, the proof will be slightly more involved than that of Theorem 3.1; this is because not all entities have
the same probability, and this prevents us from reducing to #SAT(·, ·, ·). Instead, we will use a different deﬁnition of H(·, ·, ·)
and show that it can directly be computed bottom-up on the circuits.

But before that, we introduce new notation that will be more convenient for this proof. For a Boolean classiﬁer M over

features X, probability distribution3 D : ent(X) → [0, 1], entity e ∈ ent(X) and set S ⊆ X, we deﬁne

φD(M, e, S) := Ee′∼D

M (e′) | e′ ∈ cw(e, S)

.

Notice that we now use the notation Ee′∼D[f (e′)] for expected value of a random variable f , instead of the simpler E[f (e′)] that
(cid:2)
we used in the body of the paper. This is because we will sometimes need to make explicit what is the probability distribution
to consider. Then given a Boolean classiﬁer M over a set of features X, a probability distribution D over ent(X), an entity e
over X, and a feature x ∈ X, the Shapley value of feature x in e with respect to M under D is deﬁned as

(cid:3)

SHAPD(M, e, x) :=

|S|! (|X| − |S| − 1)!
|X|!

XS⊆X\{x}

(cid:18)

φD(M, e, S ∪ {x}) − φD(M, e, S)

(5)

.
(cid:19)

Note that by taking D to be the uniform probability distribution on ent(X), we obtain the deﬁnition that we considered in
Section 2. In this section we will consider the product distributions Πp as deﬁned in Section 5. With these notation in place, we
can now start the proof.

For a Boolean classiﬁer M over a set of variables X, a probability distribution D over ent(X), an entity e ∈ ent(X) and a

natural number k ≤ |X|, deﬁne

HD(M, e, k) :=

Ee′∼D[M (e′) | e′ ∈ cw(e, S)].

S⊆X
X
|S|=k

3Note that D : ent(X) → [0, 1] is actually a probability mass function, but we will abuse notation to simplify the presentation.

12

Our proof of Theorem 5.1 is divided into two modular parts. The ﬁrst part, which is developed in Section E.1, consists in
showing that the problem of computing SHAPΠ·(·, ·, ·) can be reduced in polynomial time to that of computing HΠ·(·, ·, ·). This
part of the proof is again a sequence of formula manipulations, and it only uses the fact that deterministic and decomposable
circuits can be efﬁciently conditioned on a variable value. In the second part of the proof, which is developed in Section E.2,
we show that computing HΠ·(·, ·, ·) can be done in polynomial time for deterministic and decomposable Boolean circuits. It is
in this part that the magic of deterministic and decomposable circuits really operates.

E.1 Reducing in polynomial-time from SHAPΠ·(·, ·, ·) to HΠ·(·, ·, ·)
In this section, we show that for deterministic and decomposable Boolean circuits and under product distributions, the
computation of the SHAP-score can be reduced in polynomial time to the computation of HΠ· (·, ·, ·). We wish to com-
pute SHAPΠp (C, e, x), for a given deterministic and decomposable circuit C over a set of variables X, probability map-
ping p : X → [0, 1], entity e ∈ ent(X) and feature x ∈ X. Deﬁne

Diﬀk(C, e, x) :=

(φΠp (C, e, S ∪ {x}) − φΠp (C, e, S)),

XS⊆X\{x}
|S|=k

and let n = |X|. We then have

SHAPΠp (C, e, x) =

=

|S|!(n − |S| − 1)!
n!

(φΠp (C, e, S ∪ {x}) − φΠp (C, e, S))

XS⊆X\{x}
n−1

k=0
X

k!(n − k − 1)!
n!

Diﬀk(C, e, x).

Therefore, it is enough to show how to compute in polynomial time the quantities Diﬀk(C, e, x) for each k ∈ {0, . . . , n − 1}.
By deﬁnition of φΠ· (·, ·, ·) we have that

Diﬀk(C, e, x) =

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S ∪ {x})]

(†)

(cid:20) XS⊆X\{x}
|S|=k

(cid:21)

−

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S)]

.

(cid:20) XS⊆X\{x}
|S|=k

(cid:21)

In this expression, let α and β be the left- and right-hand side terms in the subtraction. For a set of features X, mapping p :
X → [0, 1] and S ⊆ X, we write p|S : S → [0, 1] for the mapping that is the restriction of p to S, and Πp|S : ent(S) → [0, 1]
for the corresponding product distribution on ent(S). Looking closer at β, we have that

β =

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S)]

XS⊆X\{x}
|S|=k

= p(x) ·

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S) and e′(x) = 1]

XS⊆X\{x}
|S|=k

+ (1 − p(x)) ·

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S) and e′(x) = 0]

XS⊆X\{x}
|S|=k

= p(x) ·

Ee′′∼Πp|X\{x}

[C+x(e′′) | e′′ ∈ cw(e|X\{x}, S)]

XS⊆X\{x}
|S|=k

+ (1 − p(x)) ·

Ee′′∼Πp|X\{x}

[C−x(e′′) | e′′ ∈ cw(e|X\{x}, S)]

XS⊆X\{x}
|S|=k

= p(x) · HΠp|X\{x}

(C+x, e|X\{x}, k) + (1 − p(x)) · HΠp|X\{x}

(C−x, e|X\{x}, k),

13

where the last equality is obtained simply by using the deﬁnition of H·(·, ·, ·). Hence, if we could compute in polynomial
time HΠ·(·, ·, ·) for deterministic and decomposable Boolean circuits, then we could compute β in polynomial time as C+x
and C−x can be computed in linear time from C, and they are deterministic and decomposable Boolean circuits as well. We
now inspect the term α, which we recall is

α =

Ee′∼Πp [C(e′) | e′ ∈ cw(e, S ∪ {x})].

XS⊆X\{x}
|S|=k

But then observe that, for S ⊆ X \ {x} and e′ ∈ cw(e, S ∪ {x}), it holds that

C(e′) =

C+x(e′
C−x(e′

|X\{x})
|X\{x})

(

if e(x) = 1
if e(x) = 0

.

Therefore, if e(x) = 1, we have that

α =

Ee′′∼Πp|X\{x}

[C+x(e′′) | e′′ ∈ cw(e|X\{x}, S)]

XS⊆X\{x}
|S|=k
= HΠp|X\{x}

(C+x, e|X\{x}, k)

whereas if e(x) = 0, we have that

α = HΠp|X\{x}

(C−x, e|X\{x}, k).

Hence, again, if we were able to compute in polynomial time HΠ·(·, ·, ·) for deterministic and decomposable Boolean circuits,
then we could compute α in polynomial time (as deterministic and decomposable Boolean circuits C+x and C−x can be
computed in linear time from C). But then we deduce from (†) that Diﬀk(C, e, x) could be computed in polynomial time
for each k ∈ {0, . . . , n − 1}, from which we have that SHAPΠp (C, e, x) could be computed in polynomial time, therefore
concluding the existence of the reduction claimed in this section.

E.2 Computing HΠ·(·, ·, ·) in polynomial time
We now take care of the second part of the proof of Theorem 5.1, i.e., proving that computing HΠ·(·, ·, ·) for deterministic and
decomposable Boolean circuits can be done in polynomial time. Formally:

Lemma E.1. The following problem can be solved in polynomial time. Given as input a deterministic and decomposable
Boolean circuit C over a set of variables X, rational probability values p(x) for each x ∈ X, an entity e ∈ ent(X) and a
natural number k ≤ |X|, compute the quantity HΠp (C, e, k).

We ﬁrst perform two preprocessing steps on C, which will simplify the proof. These are the same preprocessing steps that

we did in Section 3, but we added more details for the reader’s convenience.

Rewriting to fan-in at most 2. First, we modify the circuit C so that the fan-in of every ∨- and ∧-gate is at most 2. This can
simply be done in linear time by rewriting every ∧-gate (resp., and ∨-gate) of fan-in m > 2 with a chain of m − 1 ∧-gates
(resp., ∨-gates) of fan-in 2. It is clear that the resulting Boolean circuit is deterministic and decomposable. Hence, from now
on we assume that the fan-in of every ∨- and ∧-gate of C is at most 2.

Smoothing the circuit. Recall that a deterministic and decomposable circuit C is smooth if for every ∨-gate g and input
gates g1, g2 of g, we have that var(g1) = var(g2), and we call such an ∨-gate smooth. We modify as follows the circuit C so
that it becomes smooth. Recall that by the previous paragraph, we assume that the fan-in of every ∨-gate is at most 2. For
an ∨-gate g of C having two input gates g1, g2 violating the smoothness condition, deﬁne S1 := var(g1) \ var(g2) and S2 :=
var(g2) \ var(g1), and let dS1 , dS2 be Boolean circuits deﬁned as follows. If S1 = ∅, then dS1 consist of the single constant
gate 1. Otherwise, dS1 encodes the propositional formula ∧x∈S1(x∨¬x), but it is constructed in such a way that every ∧- and
∨-gate has fan-in at most 2. Boolean circuit dS2 is constructed exactly as dS1 but considering the set of variables S2 instead
of S1. Observe that var(dS1 ) = S1, var(dS2 ) = S2 and dS1 , dS2 always evaluate to 1. Then, we transform g into a smooth
∨-gate by replacing gate g1 by a decomposable ∧-gate (g1 ∧ dS2), and gate g2 by a decomposable ∧-gate (g2 ∧ dS1). This
does not change the Boolean classiﬁer computed. Moreover, since var(g1 ∧ dS2 ) = var(g2 ∧ dS1) = var(g1) ∪ var(g2), we
have that g is now smooth. Finally, the resulting Boolean circuit is deterministic and decomposable. Hence, by repeating the
previous procedure for each non-smooth ∨-gate, we conclude that C can be transformed into an equivalent smooth Boolean
circuit in polynomial time, which is deterministic and decomposable, and where each gate has fan-in at most 2. Thus, from
now on we also assume that C is smooth.

14

Proof of Lemma E.1. Let C be a deterministic and decomposable Boolean circuit C over a set of variables X, p : X → [0, 1]
be a rational probability mapping, e ∈ ent(X) and k a natural number such that k ≤ |X|, and let n = |X|. For a gate g of C,
let Rg be the Boolean circuit over var(g) that is deﬁned by considering the subgraph of C induced by the set of gates g′ in C
for which there exists a path from g′ to g in C.4 Notice that Rg is a deterministic and decomposable Boolean circuit with output
(Rg, e|var(g), l), which we recall is equal,
gate g. Moreover, for a gate g and natural number l ≤ |var(g)|, deﬁne αl
by deﬁnition, to

g := HΠp|var(g)

HΠp|var(g)

(Rg, e|var(g), l) =

XS⊆var(g)
|S|=l

Ee′∼Πp|var(g)

[Rg(e′) | e′ ∈ cw(e|var(g), S)].

We will show how to compute all the values αl
conclude the proof since, for the output gate gout of C, we have that αk
these values by bottom-up induction on C.
Variable gate. g is a variable gate with label y ∈ X, so that var(g) = {y}. Then for e′ ∈ ent({y}) we have Rg(e′) = e′(y),

g for every gate g of C and l ∈ {0, . . . , |var(g)|} in polynomial time. This will
gout = HΠp (C, e, k). Next we explain how to compute

therefore

and

α0

g =

Ee′∼Πp|{y}

[e′(y) | e′ ∈ cw(e|{y}, S)]

XS⊆{y}
|S|=0
= Ee′∼Πp|{y}
= Ee′∼Πp|{y}
= 1 · p(y) + 0 · (1 − p(y))
= p(y)

[e′(y) | e′ ∈ cw(e|{y}, ∅)]
[e′(y)]

α1

g =

Ee′∼Πp|{y}

[e′(y) | e′ ∈ cw(e|{y}, S)]

XS⊆{y}
|S|=1
= Ee′∼Πp|{y}
= e(y).

[e′(y) | e′ ∈ cw(e|{y}, {y})]

Constant gate. g is a constant gate with label a ∈ {0, 1}, and var(g) = ∅. We recall the mathematical convention that there is

a unique function with the empty domain and, hence, a unique entity over ∅. But then

α0

g =

Ee′∼Πp|∅

[a | e′ ∈ cw(e|∅, S)]

XS⊆∅
|S|=0
= Ee′∼Πp|∅
= a.

[a | e′ ∈ cw(e|∅, ∅)]

¬-gate. g is a ¬-gate with input gate g′. Notice that var(g) = var(g′). Then, since for e′ ∈ ent(var(g)) we have that Rg(e′) =

1 − Rg′ (e′), we have

αl

g =

XS⊆var(g)
|S|=l

Ee′∼Πp|var(g)

[1 − Rg′ (e′) | e′ ∈ cw(e|var(g), S)].

By linearity of expectations we deduce that

αl

g =

XS⊆var(g)
|S|=l

Ee′∼Πp|var(g)

[1 | e′ ∈ cw(e|var(g), S)]

Ee′∼Πp|var(g)

[Rg′ (e′) | e′ ∈ cw(e|var(g), S)]

−

XS⊆var(g)
|S|=l

4The only difference between Rg and Cg (deﬁned in Section 2) is that we formally regard Rg as a Boolean classiﬁer over var(g), while

we formally regarded Cg as a Boolean classiﬁer over X.

15

=

=

1

− αl
g′

(cid:3)

− αl
g′

(cid:2) XS⊆var(g)
|S|=l
|var(g)|
l

(cid:18)

(cid:19)

for every l ∈ {0, . . . , |var(g)|}. By induction, the values αl
can compute all the values αl

g for l ∈ {0, . . . , |var(g)|} in polynomial time.

g′ for l ∈ {0, . . . , |var(g)|} have already been computed. Thus, we

∨-gate. g is an ∨-gate. By assumption, recall that g is deterministic, smooth and has fan-in at most 2. If g has only one input g′,
then clearly var(g) = var(g′) and αl
g′ for every l ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input
gates g1 and g2, and recall that var(g1) = var(g2) = var(g), because g is smooth. Given that g is deterministic, observe that
for every e′ ∈ ent(var(g)) we have Rg(e′) = Rg1 (e′) + Rg1 (e′). But then for l ∈ {0, . . . , |var(g)|} we have

g = αl

αl

g =

XS⊆var(g)
|S|=l

XS⊆var(g)
|S|=l

=

Ee′∼Πp|var(g)

[Rg1 (e′) + Rg2 (e′) | e′ ∈ cw(e|var(g), S)]

Ee′∼Πp|var(g)

[Rg1 (e′) | e′ ∈ cw(e|var(g), S)]

Ee′∼Πp|var(g)

[Rg2 (e′) | e′ ∈ cw(e|var(g), S)]

+

XS⊆var(g)
|S|=l

= αl

g1 + αl

g2 ,

where the second equality is by linearity of the expectation, and the last equality is valid because g is smooth. By induction,
, for each l ∈ {0, . . . , |var(g)|}, have already been computed. Therefore, we can compute all the
the values αl
g1
values αl

g for l ∈ {0, . . . , |var(g)|} in polynomial time.

and αl
g2

∧-gate. g is an ∧-gate. By assumption, recall that g is decomposable and has fan-in at most 2. If g has only one input g′, then
clearly var(g) = var(g′) and αl
g′ for every l ∈ {0, . . . , |var(g)|}. Thus, assume that g has exactly two input gates g1
and g2. For e′ ∈ ent(var(g)) we have that Rg(e′) = Rg1 (e′
|var(g2)). Moreover, since var(g) = var(g1)∪var(g2)
and var(g1) ∩ var(g2) = ∅ (because g is decomposable), observe that every S ⊆ var(g) can be uniquely decomposed
into S1 ⊆ var(g1), S2 ⊆ var(g2) such that S = S1 ∪ S2. Henceforth, for l ∈ {0, . . . , |var(g)|} we have

|var(g1))·Rg2 (e′

g = αl

αl

g =

XS1⊆var(g1)
|S1|≤l

XS2⊆var(g2)
|S2|=|var(g)|−|S1|

Ee′∼Πp|var(g)

[Rg1 (e′

|var(g1)) · Rg2 (e′

|var(g2)) | e′ ∈ cw(e|var(g), S1 ∪ S2)].

But, by deﬁnition of the product distribution Πp|var(g) , we have that Rg1 (e′
variables, hence we deduce

|var(g1)) and Rg2 (e′

|var(g2)) are independent random

αl

g =

=

XS1⊆var(g1)
|S1|≤l

XS2⊆var(g2)
|S2|=|var(g)|−|S1|

Ee′∼Πp|var(g)
(cid:20)

[Rg1 (e′

|var(g1)) | e′ ∈ cw(e|var(g), S1 ∪ S2)]

× Ee′∼Πp|var(g)

[Rg2 (e′

|var(g2)) | e′ ∈ cw(e|var(g), S1 ∪ S2)]

.

(cid:21)

XS1⊆var(g1)
|S1|≤l

XS2⊆var(g2)
|S2|=|var(g)|−|S1|

Ee′′∼Πp|var(g1 )
(cid:20)

[Rg1 (e′′) | e′′ ∈ cw(e|var(g1), S1)]

where the last equality is simply by deﬁnition of the product distributions, and because Rg1 (e′
value e′
|var(g2)). But then

|var(g2), and similarly for Rg2 (e′

(cid:21)

|var(g1)) is independent of the

× Ee′′∼Πp|var(g2 )

[Rg2 (e′′) | e′′ ∈ cw(e|var(g2), S2)]

,

αl

g =

XS1⊆var(g1)
|S1|≤l

Ee′′∼Πp|var(g1 )

[Rg1 (e′′) | e′′ ∈ cw(e|var(g1), S1)] ×

XS2⊆var(g2)
|S2|=|var(g)|−|S1|

16

=

=

=

=

Ee′′∼Πp|var(g2 )
[Rg1 (e′′) | e′′ ∈ cw(e|var(g1), S1)] × α|var(g)|−|var(S1)|

g2

[Rg2 (e′′) | e′′ ∈ cw(e|var(g2), S2)]

Ee′′∼Πp|var(g1 )

XS1⊆var(g1)
|S1|≤l

Ee′′∼Πp|var(g1 )

[Rg1 (e′′) | e′′ ∈ cw(e|var(g1), S1)]

l

l1=0
X

l

l1=0
X

α|var(g)|−l1
g2

×

XS1⊆var(g1)
|S1|=l1

α|var(g)|−l1
g2

× αl1
g1

g1 · αl2
αl1
g2 .

Xl1∈{0,...,|var(g1)|}
l2∈{0,...,|var(g2)|}
l1+l2=l

By induction, the values αl1
g1
computed. Therefore, we can compute all the values αl

and αl2
g2

, for each l1 ∈ {0, . . . , |var(g1)|} and l2 ∈ {0, . . . , |var(g2)|}, have already been

g for l ∈ {0, . . . , |var(g)|} in polynomial time.

This concludes the proof of Lemma E.1 and, hence, the proof of Theorem 5.1.

17

