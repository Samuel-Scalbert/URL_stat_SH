Combination of explicit segmentation with Seq2Seq
recognition for fine analysis of children handwriting
Omar Krichen, Simon Corbillé, Eric Anquetil, Nathalie Girard, Elisa

Fromont, Pauline Nerdeux

To cite this version:

Omar Krichen, Simon Corbillé, Eric Anquetil, Nathalie Girard, Elisa Fromont, et al.. Combination of
explicit segmentation with Seq2Seq recognition for fine analysis of children handwriting. International
Journal on Document Analysis and Recognition, 2022, ￿10.1007/s10032-022-00409-4￿. ￿hal-03845144￿

HAL Id: hal-03845144

https://hal.science/hal-03845144

Submitted on 9 Nov 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Children handwriting analysis

1

Combination of explicit segmentation with Seq2Seq

recognition for ﬁne analysis of children handwriting

Omar Krichen2*†, Simon Corbill´e1†, ´Eric Anquetil2, Nathalie Girard1, ´Elisa
Fromont1 and Pauline Nerdeux2

1Univ Rennes 1, IRISA lab, Rennes, F-35000, France.
2INSA Rennes, IRISA lab, Rennes, F-35000, France.

Contributing authors: ﬁrstname.lastname@irisa.fr;
†These authors contributed equally to this work.

Abstract

We consider the task of analysing children handwriting in the context of a dictation task. The
objective is to detect orthographic and phonological errors. To achieve this goal, we extend an
existing handwriting analysis engine, based on an explicit segmentation of the handwritten input,
originally developed for children copying exercises. We present a new approach, based on the
combination of this analysis engine with a deep learning word recognition approach in order to
improve both the recognition and segmentation performance. Explicit segmentation needs prior knowl-
edge, and the deep network recognition predictions are a reliable approximation of the ground
truth which can guide the analysis process. We propose to combine multiple prior knowledge
strategies to further improve the analysis performance. Furthermore, we exploit the deep network
approximate implicit segmentation to optimise the existing analysis process in terms of complexity.

Keywords: Online handwriting recognition, Segmentation, Digital learning, Degraded handwriting,
Sequence-to-sequence, e-education

1 Introduction

This work aims at designing an educational system

targeted towards primary school children, in order

to help them master handwriting and spelling

skills. More speciﬁcally, we deal with online inter-

pretation of children handwritten French cur-

sive words. The interpretation task in hand is

a word analysis task, which diﬀers from the word

recognition task. Fig. 1 illustrates these diﬀerences.

In a recognition task, the objective of the sys-

tem is to predict the correct character sequence,

whereas the objective of the analysis task is to pro-

vide a qualitative evaluation. Consequently, the

segmentation quality is instrumental, to enable

the system to perform a ﬁne-grained analysis of

2

Children handwriting analysis

Fig. 2 Diﬀerence between a copy and a dictation task.

section 3. Our new targeted dictation task intro-

duces new challenges, as illustrated in Fig. 2.

The instruction is heard, not seen, by the pupil.

This may induce a lot more spelling mistakes. In

the ﬁgure, the written word ”mai” is a homo-

phone of the dictated instruction ”mes”. In this

dictation context, the instruction is not directly

exploitable to guide the analysis of the handwrit-

ten word. To provide a relevant and real-time

analysis for this dictation task, new prior knowl-

edge generation strategies are needed. We propose

to combine the aforementioned engine, with a

deep learning word recognition approach, namely

a Seq2Seq architecture. Our contributions consist

in exploiting this hybridisation in three diﬀerent

manners: 1) We deﬁne the Seq2Seq network recog-

nition process as a new prior knowledge generation

strategy, which will drive the analysis process;

2) We combine diﬀerent prior knowledge strate-

gies to further improve the system’s performance;

3) We exploit the Seq2Seq implicit segmenta-

tion to prune the explicit segmentation graph

and optimise analysis complexity. This paper is

organised as follows. Section 2 presents related

Fig. 1 Context: analysis of children handwriting: the
dictated instruction is ”alors” (”then” in French)

the pupil handwriting, such as highlighting in

red the spelling mistakes directly on the ink.

(c.f. Fig. 1). Therefore, the educational system

needs both an accurate recognition of the child’s

word but also a good segmentation at character

level to precisely locate the spelling mistakes. To

achieve this goal, we build on previous works on

children handwriting analysis for cursive French

words [1]. This approach is based on an explicit

segmentation of the input word. A segmentation

graph representing all possible segmentations of

the word into letters is created. For each node of

the graph, letters hypotheses are computed using

a letter recognition and analysis system. The anal-

ysis result is a set of n best possible pseudo-word

hypotheses. In order to be eﬃcient, the explicit

segmentation needs to be driven by prior knowl-

edge, especially to deal with degraded children

handwriting. Since the instruction to copy was dis-

played to the child, it served as prior knowledge

to guide the letter hypotheses computation phase.

This ”base system” is discussed in more details in

Children handwriting analysis

3

works about handwriting recognition and segmen-

lies in the fact that they are end-to-end train-

tation. Section 3 provides a detailed account of

able. There is no need to segment the data, and

the existing engine, while Section 4 describes the

the feature extraction is learned by the model.

deep learning model used for our task. Section

The two main deep learning approaches that

5 presents the approaches combination and our

tackle HTR are Connectionist Temporal Clas-

listed contributions. Experiments are presented in

siﬁcation (CTC) [6] and Sequence to Sequence

Section 6. Conclusion and future works are given

(Seq2Seq). The CTC approach divides input into

in Section 7.

frames for symbol prediction and computes a

2 Related works

This section presents the latest online and oﬄine

methods concerning handwriting recognition and

segmentation. Handwriting can be represented

oﬄine, through an image, or online through

a sequence of points. IAM datasets (oﬄine [2]

and online [3] versions) are composed of English

adult-written sentences, labelled at line level.

They are open and widely used to compare pure

recognition methods. To the best of our knowl-

edge, there are no available words datasets with

character-level annotation.

probability distribution over all possible outputs

alignments, while the Seq2Seq approach trans-

lates an input sequence represented by an image

into a sequence of characters. The CTC-based

architectures designed for online recognition use

Bidirectional Long-Short Term Memory [7]

(BLSTM). The authors of [8] show that this type

of architecture outperforms a traditional method

based on Hidden Markov Models, whereas the

authors of [9] use BLSTM with B´ezier curvers

encoding of online data to achieve state of the

art performances for online recognition on IAM-

OnDB [3]. The CTC-based architectures designed

for oﬄine recognition are slightly diﬀerent due

2.1 Handwriting text recognition

to the nature of the input data. Convolutional

Deep learning models outperform the previous

methods [4][5] on handwriting text recognition

(HTR) task. These traditional methods were

based on a bottom-up strategy, i.e. by using

expert knowledge to segment input data, then

recognising the character in each segmented ele-

ment. A great advantage of deep learning models

recurrent neural networks [10] [11] are based

on a convolutional neural network coupled with a

recurrent network with LSTM cell. The authors

of [12] use a Seq2Seq method based on an encoder-

decoder model with an attention module to do

oﬄine recognition. More recently, [13] and [14] use

transformers, which need a lot of synthetic data

to perform well, for oﬄine recognition. For our

4

Children handwriting analysis

work, we use a Seq2seq model since this archi-

and the instruction, the ﬁrst step of the analysis

tecture gets state of the art performances when

is the explicit segmentation process. A segmenta-

no synthetic data are used. The next part present

tion graph is constructed based on the extraction

methods which focus on handwriting segmenta-

of all possible cutting points around descending

tion.

2.2 Handwriting segmentation

zones [18], and represents a partition of all possible

segmentations given the extracted cutting points.

Fig. 4 illustrates the segmentation graph for the

The authors of [15] propose regularisation meth-

French handwritten word ”juste”. Every node of

ods on the CTC loss based on entropy and spacing

the graph represents a possible letter hypothesis.

to increase recognition performance and segmen-

The objective is to ﬁnd the best path in the graph

tation quality. They present a quantitative anal-

corresponding to the correct segmentation. For

ysis on recognition performance and qualitative

each node, conﬁdence-based classiﬁers [19] com-

analysis on segmentation performance. The

pute letters hypotheses. The analysis process is

authors of [16] use a convolutional prototype

generic and relies on prior knowledge generation

network and most aligned frame based CTC

strategies. Here, prior knowledge is instrumental,

training for handwriting recognition. They eval-

uate the recognition performance of their model

on IAM [2] dataset whereas the segmentation is

evaluated on a synthetic dataset representing a

sequence of digits from MNIST [17] dataset. In

this work, we choose to combine the Seq2Seq

model good recognition performances with the

explicit segmentation based existing engine [1]

presented in the introduction. The next section 3

presents the existing system.

3 Existing analysis engine

In this section, we present the existing analysis

Fig. 3 Existing analysis engine, here the instruction serves
as prior knowledge to guide the analysis

engine (for more details, see [1]). Fig. 3 illustrates

Fig. 4 Segmentation graph for the word ”juste”

its global principles. Given the handwritten input

Children handwriting analysis

5

especially in the context of degraded handwriting

This prior knowledge generation strategy enables

to avoid recognition confusion at the letter level.

to cover potential orthographic errors that sound

In a copying context, the prior knowledge

similar to the instruction. The limit of this strat-

strategy is straightforward. The instruction drives

egy resides in the fact that it could not cope with

the letter computation process by ﬁltering the

written words that were not phonetically similar

computed hypotheses that belong to the instruc-

to the dictated instruction. It is in order to over-

tion. The best segmentation path is the one

come this limitation that we choose to combine

which minimises the edit distance with the

the existing analysis engine with the outputs of

instruction. This strategy is best suited when the

a Seq2Seq model, namely the predicted word and

child correctly reproduces the instruction. A ﬁrst

the correspondent implicit segmentation. The new

adaptation of this engine to the dictation context

prior knowledge generation strategy will there-

was proposed in [20]. Two prior knowledge gen-

fore rely on the Seq2Seq predicted word to drive

eration strategies were deﬁned to deal with the

the generic analysis process. Section 4 describes

fact that driving the analysis by the instruction,

the Seq2Seq architecture used, whereas section 5

in a dictation context, becomes obsolete. The ﬁrst

presents the combination of the approaches and

strategy consisted in asking the child to type was

its impact.

he/she has written on the keyboard. This childtyp-

ing drives the analysis, since it is a pretty reliable

4 Deep learning model for

estimation of the ground truth. However, the

objective is to be free from user input and to rely

solely on the system capacities. The second prior

knowledge generation strategy was to generate,

for every instruction, a set of phonetically similar

pseudo-words. For example, if the instruction is

”alors” (then in French), the generated hypotheses

would be ”alaur, alor, alord, alort”. This gener-

ation is based on the Phonetisaurus engine [21],

a grapheme-to-phoneme WFST (Weighted Finite

State Transducer). A Recurrent Neural Network

Language Model (RNNLM) is used to extract

the best phonetic hypotheses for a given word.

handwriting recognition

Our Seq2Seq model

is derived from [12]

for the encoder decoder architecture with

hybrid Bahdanau attention mechanism [22]

and [10] [11] [23] [14] for the encoder architecture.

The encoder’s parameters result of an ablation

study where the number of convolutional, pooling,

blstm layers and dropout are tested.

The authors of [12] demonstrate that using

a joint training between encoder and decoder

improves recognition performance. The encoder is

trained with CTC loss [6] and the decoder with a

6

Children handwriting analysis

cross entropy. Thus, the model makes one pre-

diction with the encoder and one prediction

with the decoder. The ﬁnal loss is deﬁned as

follows:

Loss = λ ∗ Lossctc + (1 − λ) ∗ Losscrossentropy, with λ ∈ [0, 1]

Fig. 5 illustrates the connection with its three

main parts: 1) The Encoder performs the feature

extraction of the input image into a feature vec-

tor. This vector is used by the encoder to make a

word prediction; 2) The Attention module focuses

the decoder on a speciﬁc area in the feature vec-

tor; 3) The Decoder decodes the feature vector

and produces a word prediction.

The model takes as input a grayscale image

resized proportionally to have a height of 128 pix-

els. The encoder ﬁrst extracts spatial features with

convolutional layers, then temporal features with

recurrent layers, into a feature vector. This feature

vector is used by the encoder to make a prediction

and by the decoder through the attention module.

The table 1 details the encoder’s parameters.

Fig. 6 illustrates the attention mechanism. The

idea is to focus the decoder on a speciﬁc part of

Table 1 Conﬁguration of encoder: k is for kernel size, s
for stride, p for padding and d for dropout. All
convolution layers are followed by the Leaky ReLU
activation function, then a layer normalization.

Conﬁguration
height 128 * width
#ﬁlters:8, k:3*3, s:1, p:0
k:2*2, s:2, d:0.2
#ﬁlters:16, k:3*3, s:1, p:0
k:2*2, s:2, d:0.2
#ﬁlters:32, k:3*3, s:1, p:0
k:2*2, s:2, d:0.2
#ﬁlters:64, k:3*3, s:1, p:0, d:0.2
#ﬁlters:128, k:4*2, s:1, p:0, d:0.2

Type
Input
Convolution
Max pooling
Convolution
Max pooling
Convolution
Max pooling
Convolution
Convolution
Collapse Convolution #ﬁlters:128, k:9*1, s:1, p:0
Batch normalization
BLSTM
Fully connection

4 layers, 128 units, d:0.5
size alphabet + 1

the feature vector, and thus ideally use features

associated with a sub image representing one let-

ter. The attention module produces at each time

a context vector ct from the feature vector emit-

ted by the encoder and uses the hidden state of

the decoder st. At each time, the decoder uses

an embedding of the precedent prediction and the

precedent context vector to update the hidden

state st of the LSTM layer, then uses the hidden

Fig. 5 Global architecture of sequence to sequence model

Fig. 6 Details attention module and decoder: the input is
the feature vector produced by the encoder. The decoder
produces one character at a time. It starts with the spe-
cial character <sos>(start of sequence) and ends with
<eos>(end of sequence). FC stands for fully connected
layer, Tanh the tangent hyperbolic function and Embed the
embedding of one prediction

Children handwriting analysis

7

This motivates our choice to combine a deep

learning model, which does well recognition-wise,

with the existing analysis engine, which does well

segmentation-wise. Furthermore, even if the seg-

mentation of deep model is approximate, it can

be exploited to prune the explicit segmentation

graph. The next section describes the hybridiza-

Fig. 7 Example of segmentation for the encoder/decoder.

tion between the two systems.

state to concatenate with the current context vec-

tor to produce the symbol prediction at the time t.

The decoder’s alphabet uses two extra symbols for

the start and the end of the characters sequence

(<sos> and <eos>).

For the character segmentation aspect, an

approximation can be computed from the encoder

or decoder prediction. For the encoder, we com-

pute the receptive ﬁelds used to predict a charac-

5 Combining deep recognition

and explicit segmentation

In this section, we present the integration of

the Seq2Seq recognition results into the explicit

segmentation-based analysis process,

the new

prior knowledge generation strategies, as well as

the pruning of the explicit segmentation graph.

ter and extract the associated part of the image to

5.1 Seq2Seq prediction as prior

get the segmentation. For the decoder, we re-use

knowledge strategy

the attention map used by the decoder to predict

a character and ﬁnd its position in the associated

input image. Fig. 7 illustrate an example of seg-

mentation of the French word ”comme” by the

Seq2Seq model. The segmentation quality is aver-

age due to the fact the network is trained on the

recognition task. For the encoder, the letter ”o”

and ”m” are incomplete. The decoder segmenta-

tion contains a lot of overlap between the letters

”o” and ”e”. Section 6 details quantitative results

for the segmentation and recognition evaluation.

Fig. 8 illustrates the deﬁned prior knowledge

generation strategy, which consists in coupling

the explicit segmentation-based analysis approach

with the Seq2Seq recognition outputs. The pre-

dicted sequence for each written word drives the

generic analysis process, especially in the let-

ter hypotheses computation phase, and the word

paths search phase. Being a better approxima-

tion of the ground truth in a dictation context,

this deep prediction strategy improves the engine

performance, as we will see in section 6.

8

Children handwriting analysis

A valid interrogation would be to question

5.1.1 Deep prediction added value

the fact that our system now has two recognition

processes. A recognition process for each letter

hypothesis (with Evolve classiﬁer [24]), and a

Seq2Seq recognition on the whole word. Shouldn’t

we rely on one or the other? The ﬁnal goal is to

provide feedback to the pupils at the ink level,

therefore the segmentation process is as impor-

tant as the recognition process in our task. The

fact that the existing analysis system relies on an

explicit segmentation process, with a recognition

at letter level, ensures that the predicted result is

coherent in terms of letters localisation. However,

since we are faced with degraded children hand-

writing, the system needs some prior knowledge

to prioritise the relevant letters hypotheses, hence

the guidance of the analysis by the deep predicted

Fig. 9 illustrates the analysis of the written word

”zme”, given the dictated instruction ”cent” (hun-

dred), with the three strategies: a) Instruction

strategy with result=”cent”; b) Phonetic strategy

with result=”cent”; c) Deep recognition strategy

with result=”zme”. The instruction strategy is

well suited when there are no errors, but can’t

cope with the analysis of children mistakes. As for

the phonetic strategy, it is not well adapted to

this situation either, since the written word ”zme”

does not sound similar to the dictated instruction

”cent”. As for the third strategy, since the network

was able to predict the correct word, the injec-

tion of this prior knowledge enabled the engine to

correctly recognize and segment the word.

sequence.

5.2 Strategies combination

Until now, we have studied the case where the

Seq2Seq model

is able to predict the correct

Fig. 8 Deep prediction as prior knowledge strategy

Fig. 9 Results of analysis strategies for the word ”zme”,
given the instruction ”cent”

Children handwriting analysis

9

sequence, and therefore have a positive impact as

present now in detail the two steps of this fourth

prior knowledge on the analysis engine. However,

strategy.

there are cases where it is not able to correctly

interpret the input, such as in Fig. 10, which illus-

5.2.1 Fusion

trates the analysis results of the written word

We propose the fusion of the results of the three

”biin”, given the dictated instruction ”bien”. We

mentioned strategies to generate an alternative

can see that the ﬁrst two strategies ((a) and

approximation of the ground truth, which will

(b)) were only able to predict the ﬁrst written

serve as another prior knowledge source driving

letter ”b”, which is also the ﬁrst letter of the dic-

the analysis. This fusion is done in two steps: ﬁrst

tated instruction, whereas the third strategy (c)

by aligning the resulting character sequences using

was only able to predict the latter part of the

dynamic programming techniques, and second by

word ”iin”. Intuitively, since every strategy is best

introducing a voting algorithm called Rover [25],

suited to a speciﬁc scenario, it is fair to assume

which chooses to most occurring character in the

that they could be complementary. We propose

alignment. Fig. 11 illustrates the alignment and

therefore to combine these strategies into a fourth

fusion of the above cited strategies, with the

one, named fusion and competition. The latter

addition of the instruction and the deep model

represents two ways of combining strategies, ﬁrst

prediction. The fusion result corresponds to the

a conjunction by merging these prior knowledge,

ground truth ”biin”. Therefore, if used as prior

then a dis-junction by introducing a notion of

knowledge, it will enable the analysis engine to

competition between the strategies prediction. We

predict the correct word.

Fig. 11 Alignment and fusion of multiple prior knowledge
for the written word ”biin”

Fig. 10 Results of analysis strategies for the word ”biin”,
given the instruction ”bien”

10

Children handwriting analysis

5.2.2 Competition

of length n Pn is deﬁned as follows, where Sa(i) is

After the fusion step, which adds pertinent prior

knowledge information, we introduce the compe-

tition step, which enables the system to choose

the best strategy, depending on child production.

Fig. 12 illustrates this process. To choose the

the analysis score of the ith element of the path:

Sa(Pn)=(cid:112)(cid:81)n

i=0Sa(i) [1] .

Given these two metrics, we deﬁne a phonetic

score that combines edition score pertinence and

handwriting quality. The phonetic score is deﬁned

best prediction between instruction strategy, pho-

as follows:

netic strategy, deep prediction strategy, and the

fusion, we exploit metrics that are already present

in the existing analysis engine. As explained in

section 3, the result of each analysis process is

the segmentation path, which minimises the edi-

tion distance with the prior knowledge that guides

the instruction. This edition score consists of

a Damerau-Leveinshtein [26] distance computed

between the word hypothesis and the prior knowl-

edge (e.g. the instruction). In addition, optimised

costs are learned by the analyser [1]. Another indi-

cation is the handwriting quality, represented by

the analysis score. The analysis score Sa of a path

PhoneticScore(P)= Sa(P)*0.7 +

1
1 + EditScore(P)

* 0.3

The strategy chosen is the one where the predicted

segmentation path has the best phonetic score.

These parameters (0.7, 0.3) are chosen empiri-

cally to give more weight to the analysis score of

each strategy. We will see in detail the impact

of fusion and competition strategy in section 6.

In this section, we have presented the integration

of the Seq2Seq recognition results in the existing

analysis chain and the proposed strategies to opti-

mise the analysis process. Another output of the

Seq2Seq model is the result of the implicit segmen-

tation. We choose to use this segmentation result

in order to prune the existing analysis process seg-

mentation graph, which would enable to diminish

the complexity of the process. Since we are in the

context of real-time user interaction, the response

time of the system has to be acceptable to the

user. However, for long words, the analysis time

can be fastidious. Moreover, the fusion and compe-

tition strategy increases the analysis complexity.

We present in the next section this segmentation

Fig. 12 Fusion and competition strategy

graph pruning strategy.

Children handwriting analysis

11

”alors” is framed in red in Fig. 14. Each rectan-

gle represents the predicted letters as well as the

points used by the attention mechanism to recog-

nise it. This is used to prune the segmentation

graph. First, a deep matching score (which is in

fact an IoU score between the points in a graph

segmentation node and the points in a deep seg-

mentation node) is computed for each node of the

graph relatively to the deep segmentation, to ﬁnd

Fig. 13 Segmentation graph of written word ”alors”

5.3 Segmentation graph pruning

The word path search step of the analysis (c.f.

the best corresponding deep predicted letter. The

Fig. 8 in section 5) generates all the possi-

deep matching score is deﬁned as follows:

ble segmentation paths from the graph. From

DMScore(ngraph,ndeep)=

(cid:107)pointsn graph ∩ pointsn deep(cid:107)
(cid:107)pointsn graph ∪ pointsn deep(cid:107)

all the paths generated, the one minimising the

The best deep matching node for a graph

edit distance with the prior knowledge is cho-

segmentation

node

is

deﬁned

as

follows:

sen as the prediction of the written word. We

DeepMatch(nGraph) =

max
nDeep∈Deep

DM Score(nGraph, nDeep).

exploit the approximate implicit segmentation of

Given the computed deep matching scores, the

the Seq2Seq model to prune the segmentation

new segmentation paths search process consists in

graph. The implicit segmentation is not directly

selecting recursively, at each level, only the

exploitable to provide feedback, but can help opti-

nodes whose analysis hypotheses contain

mise the analysis process. The objective is to have

the matching deep node predicted letter,

a nice trade-oﬀ between the analysis process per-

formalised as follows:

formance and complexity. Fig. 13 illustrates the

SelectedNodes(leveli) = nGraph ∈ leveli, such as

word paths search process for the written word

DeepMatch(nGraph) ∈ AnalysisHypotheses(nGraph).

”alors”. For each node of the ﬁrst level of the

Fig. 14 illustrates this pruning process for part

graph (highlighted in blue rectangles), all pos-

of the segmentation graph. Dotted arrows repre-

sible segmentation nodes paths are recursively

sent the matching process at the ﬁrst level. Nodes

constructed. Each node having at most four letter

highlighted in red represent the discarded nodes,

hypotheses with their analysis score, all segmen-

since their analysis hypotheses do not contain the

tation paths (or word hypotheses) resulting from

predicted letter from the matched deep node. We

each segmentation node path are then generated.

can see that at the ﬁrst level of the graph, only

The Seq2Seq segmentation of the written word

the relevant nodes have been selected. This is due

12

Children handwriting analysis

Fig. 14 Pruning process for part of the graph

to the fact that the implicit segmentation of the

deep network was relatively consistent with the

explicit segmentation. In the example in Fig. 14,

without the pruning strategy, the number of pro-

cessed paths is 301, and goes down to only 18

paths when the pruning is activated. In both cases,

Fig. 15 Examples of cursive words written by children.

series. Each word is a sequence of points rep-

resented by their coordinates (x and y), their

pressure and their time. Unfortunately, these chil-

dren data are not publicly available due to RGPD

laws1. Fig. 15 illustrates examples of words in the

database (the instruction is in orange). We can see

that the handwriting is degraded because children

are still learning writing, and naturally they do

some mistakes. Another interesting aspect is the

the correct word and segmentation are predicted.

diversity of misspelling errors.

We will see more in detail its impact, as well as

the performance of the analysis engine in the next

section.

6 Experiments

6.1 Dataset

This work needs data annotated at charac-

ter level to evaluate the system on recognition

and segmentation aspects. To our knowledge,

Our dataset is split into 6812 words written by

more than 500 children for the training set and

1242 words written by more than 300 children for

the test set. Train and test datasets come from

diﬀerent data acquisition campaigns (and diﬀer-

ent classroom). There are no children data present

both in train and test set, this enables us to verify

the ability of the system to generalise on unseen

writing styles.

open datasets of children handwriting with char-

6.2 Deep learning model evaluation

acter annotation for words do not exist. For our

experiments, we use a private dataset, composed

of French cursive words written by children. The

data were collected in classrooms on pen-based

For each experiment, λ of hybrid loss is set to 0.5

as suggested in [12]. We evaluate our deep learn-

ing model on the IAM-OnDB dataset [3] which is

tablets and were recorded as multivariate time

1https://ec.europa.eu/info/law/law-topic/data-

protection/data-protection-eu fr

Children handwriting analysis

13

composed of adult handwritten English text. We

train the model on a combination of train set and

validation set with RMS prop optimiser during

200 epochs, then evaluate it on a test set. We set

the learning rate at 0.001 and the batch size at

16. We evaluate the encoder and the decoder of

our Seq2Seq model. The table 2 report the error

rate on the test set. We can see that the encoder

performs better than the decoder and outperforms

the state of the art without the use of language

model.

The deep learning model performs poorly with

only children data. We use the model trained

on IAM-OnDB then continue the training on the

children handwriting.

Cross-validation with k folds equal to 10 is

performed on the training set to evaluate the

robustness of the system. The training set is split

into 10 chunks. A fold is composed of a train-

ing part which represent 8 chunks, a validation

part of 1 chunk and a test part of 1 chunk. Each

fold results in a diﬀerent splitting of the training

set, thus all training set data are used for train-

ing and testing. For each fold, the validation set

is used to choose the best model. A fold is evalu-

ated on the test fold for the recognition task and

Table 2 Error rates on the IAM-OnDB test set in
comparison with the best of state of the art. CER is
Character Error Rate and WER is Word Error Rate

System
Without model language [9]
With model language [9]
Our Seq2Seq encoder
Our Seq2Seq decoder

CER (%) WER (%)
5.9
4.0
5.0
5.5

18.6
10.6
18.3
20.2

Table 3 Mean and standard deviation for the
recognition and segmentation (IoU) evaluation on
children handwriting. Recognition is evaluate on fold test
set and whole test set. Encoder and decoder from
Seq2Seq are evaluated in %.

Fold recognition rate
Test recognition rate
Segmentation rate (IoU)

Encoder
86.65 ±1.17
75.08 ±1.16
51.14 ±7.06

Decoder
86.32 ±1.25
69.20 ±2.17
45.91 ±3.19

the whole test set for the recognition and segmen-

tation task. The recognition is evaluated with a

recognition rate (100 - Word error rate) and the

intersection over union to evaluate the seg-

mentation (qualitative results are presented in

section 4). The table 3 reports the results. We use

the encoder prediction (label and segmentation)

for the next experiments because its recognition

rate are better on test fold. The recognition rate

is better in fold test set because the data in the

whole test set are from words written by unseen

written styles. The Seq2Seq model has a greater

recognition rate than the existing analysis engine

(see more details on results in section.6.4) while

the segmentation rate is too approximate to make

a precise feedback to the children. Combining the

Seq2Seq model with the existing analysis engine

makes it possible to have a model both eﬃcient

in recognition and segmentation. The next section

presents the results of the diﬀerent combination

strategies.

6.3 Segmentation evaluation

To study the segmentation from a qualitative

viewpoint, Fig. 16 illustrates the analysis results

14

Children handwriting analysis

of the written word ”gust”. We can see that the

Table 4 Segmentation (IoU) performance of each
strategy

raw deep segmentation (e) is approximate, com-

pared to the explicit segmentation driven by the

deﬁned strategies (a, b, c, d). In this example, the

phonetic strategy performed the best in terms of

edition and analysis score, and therefore was cho-

sen within the fusion and competition strategy.

Correct segmentation and ground truth detection

were performed.

We can observe the same results on the whole

dataset, in terms of quality of segmentation. As

the ground truth is annotated at the charac-

ter level, we can therefore study how well the

test set was segmented using the IoU metric.

Table 4 illustrates the quality of segmentation for

each strategy, from a quantitative viewpoint. Deep

prediction and fusion/competition strategies are

tested on the 10 models generated from the cross-

validation. Mean and standard deviation results

are reported.

Strategy
Raw Seq2Seq
Childtying strategy

Instruction strategy
Phonetic strategy

Segmentation rate (IoU)
51.14 ±7.06%
93.67%

88.66 %
88.72%

Deep prediction strategy
Fusion and competition

90.4% ±0.54%
92.82% ±0.28%

Table 5 Recognition performance of each strategy

Strategy
Childtying strategy

Instruction strategy
Phonetic strategy

Recognition rate
78.98%

64.09 %
66.42%

Deep prediction strategy
Fusion and competition

72.18% ±0.73%
83.28% ±0.51%

As we have seen, the raw Seq2Seq segmen-

tation rate is very approximate (51.14%). When

we integrate the deep recognition results into the

existing analysis engine, the segmentation perfor-

mance improves with an IOU of 90.4% (better

than instruction and phonetic strategies). This

demonstrates the merits of combining explicit seg-

mentation with the deep network recognition in

the analysis process. Finally, the fusion and com-

petition strategy (92.82%) comes a close second

to the Childtyping strategy, which refers to the

analysis being guided by the keyboard user input

(93.67%). We can consider childtyping analysis

performance as a sort of objective to reach for the

system, without the aid of the user.

6.4 Recognition evaluation

Table 5 presents the recognition performance of

each strategy, without the graph pruning, on the

Fig. 16 Segmentation results for the word ”gust”, given
the instruction ”juste”

test set. We can see that in a dictation context,

Children handwriting analysis

15

the instruction can’t guide the analysis eﬀec-

Table 6 Impact of pruning strategy.

tively, with a recognition rate of 64.09%. The

Strategy

Recognition
rate

Segmentation
rate (IoU)

Average
time (s)

phonetic analysis approach deals well with pho-

netically coherent misspellings, but fails to reach

the ceiling of childtyping recognition performance

Deep prediction
Fusion competition

72.18% ±0.73%
90.4% ±0.54%
83.28% ±0.511% 92.8% ±0.28%

1.34
4.74

Deep prediction
(pruning)

Fusion competition
(pruning)

70.87% ±2.3%

89.3% ±1.12%

0.37

79.87% ±0.94%

91.44% ±0.98% 0.67

(66.42%). Even if childtyping is a reliable approx-

not exploit the Seq2Seq results, contrary to the

imation of the ground truth, the combination of

other two strategies. As we have seen, the fusion

degraded handwriting and in some cases, typing

and competition strategy provides the best recog-

errors, explains the ceiling of 78.98%. The deep

nition and segmentation results (barring the child-

prediction strategy achieves better results than

typing strategy for segmentation), however the

the phonetic strategy (72.18%). It is interesting

analysis time (4.74s per word) is more than 3 times

to note that this strategy fails to achieve the

bigger than the deep prediction guidance strategy.

recognition performance of the raw Seq2Seq, how-

This is due to the fact that there are more segmen-

ever this is explained by the explicit segmentation

tation paths that are processed for this strategy.

aspect of the analysis engine. While the implicit

Integrating the pruning enables to decrease the

segmentation is quite approximate, the explicit

analysis time of the fusion strategy to an accept-

segmentation driven by the deep prediction is sig-

able 0.67s on average, while loosing about 2%

niﬁcantly better (c.f. table 4). Finally, the fusion

of recognition performance (80.87%), which is

and competition strategy has better performances

still better than the childtyping strategy.

than the childtyping one (83.28%).

The pruning results also in loosing about 1% of

6.5 Impact of the pruning strategy

segmentation precision. This is due to the approx-

imate nature of the implicit segmentation. The

The deep learning model takes an average of

same goes for pruning with the deep prediction

73 milliseconds per word to make a prediction.

guidance strategy. We can therefore conclude that

This computation is very fast, therefore, it is not

the pruning constitutes an acceptable trade-oﬀ

included in the following time analysis. Table 6

between analysis time and performance.

presents the recognition and segmentation per-

formance of the proposed strategies, as well as

6.6 Feedback typology

their average analysis time per word. In this table,

This section presents the pedagogical output of

we do not discuss the pruning with childtyping,

our system, providing visual feedbacks on the chil-

instruction, or phonetic strategies, since they do

dren mistakes. Since we are in an educational

16

Children handwriting analysis

Fig. 17 Segmentation graph of written word ”alors”

Table 7 Feedback generation pertinence

Conﬁdence

Ratio (avg)

Errors rate (avg)

High

1103.9 ±11(88.8%)

15.2%

Medium

55.4 ±4.4(4.5%)

Reject

82.7 ±9.48(6.7%)

0%

0%

context, we have to minimise the analysis system

Total feedback

1146 (93.34%)

14.7%

errors. Therefore, the degree of visual feedback

precision and detail displayed to the child depends

on the analysis conﬁdence. When the analysis

conﬁdence is low, we generate more generic feed-

backs,i.e. a warning on a zone of

incertitude,

system minimizes its error rate from 21.13% (c.f.

table 6) to 14.7%, which is positive. However, since

we are in an educational context, further work is

needed to improve this feedback error ratio.

or even no feedback at all. The feedback typol-

ogy is illustrated in Fig. 17 and decomposed into

7 Conclusion

three diﬀerent levels: 1) High conﬁdence: when

In this paper, we present an approach for the ﬁne

the predicted word path corresponds to the prior

analysis, i.e. recognition and segmentation, of chil-

knowledge strategy (e.g. the deep prediction) =⇒

dren handwritten words in a dictation context.

precise feedback is given; 2) Medium conﬁdence:

This context introduces new challenges, since the

when one letter distinguishes between the pre-

handwriting is more degraded than adult hand-

dicted word and the strategy =⇒ a warning is

writing, and the children are prone to misspelling

generated on an uncertain zone; 3) Reject: when

mistakes, which makes the analysis task much

the aforementioned conditions are not met =⇒

harder than in a copying context. An explicit seg-

no feedback is given to the child. More details on

mentation process is needed to provide precise

feedback generation can be seen in [20].

feedback on the child’s mistakes. This explicit seg-

Table 6.6 presents the feedback pertinence

mentation needs to be driven by prior knowledge.

results on the fusion competition strategy with

We propose to combine an existing explicit seg-

pruning. On one hand, the system has a high con-

mentation based analysis engine with a Seq2Seq

ﬁdence feedback degree of 88.88% on the test set

architecture to generate relevant prior knowledge

with an error rate of 15.2% on this type of feed-

and adapt the system to the dictation context.

back. On the other hand, the system has a low

Using the deep predicted character sequence as

degree of medium and reject feedback (4.5 and

prior knowledge compensates for the fact that the

6.7% respectively). Putting high and medium con-

dictated instruction cannot drive the analysis, as it

ﬁdence feedbacks altogether, we can see that the

has done for the copying context. We then propose

REFERENCES

17

to combine multiple strategies, the instruction,

recognition.

In Fifth International Confer-

phonetically similar pseudo-words, and the deep

ence on Document Analysis and Recognition,

prediction, in order to further improve analysis

ICDAR 1999, 20-22 September, 1999, Banga-

performances. Another contribution of this work

lore, India, pages 705–708. IEEE Computer

is to use the implicit segmentation of the Seq2Seq

Society.

to prune the analysis engine segmentation graph,

[3] M. Liwicki and H. Bunke. Iam-ondb - an on-

which resulted in optimising analysis complexity

line english sentence database acquired from

and time, while retaining good analysis perfor-

handwritten text on a whiteboard. In Eighth

mances,

in fact outperforming the childtyping

International Conference on Document Anal-

strategy, which constituted a ”high ceiling base-

ysis and Recognition (ICDAR 2005), 29

line” for our task in terms of recognition per-

August - 1 September 2005, Seoul, Korea,

formances. Our future works consist in further

pages 956–961. IEEE Computer Society.

experimenting the system in pilot French schools.

[4] C. C. Tappert, C. Y. Suen, and T. Wakahara.

Another objective is to improve the Seq2Seq per-

The state of the art in online handwrit-

formances, in terms of recognition and segmenta-

ing recognition. IEEE Trans. Pattern Anal.

tion, which will consequently improve the explicit

Mach. Intell., 12(8):787–808, 1990.

segmentation based analysis engine. We could rely

[5] R. Plamondon and S.N. Srihari. Online

on synthetic data to further improve the network

and oﬀ-line handwriting recognition: a com-

performances. Finally, we could explore the exten-

prehensive survey.

IEEE Transactions on

sion of this approach to languages other than

Pattern Analysis and Machine Intelligence,

French.

22(1):63–84, 2000.

References

[1] D. Simonnet, N. Girard, E. Anquetil,

M. Renault, and S. Thomas. Evaluation

of Children Cursive Handwritten Words for

e-Education. Pattern Recognition Letters,

121:133–139, 2019.

[2] U.-V Marti and H Bunke. A full english

sentence database for oﬀ-line handwriting

[6] A. Graves, S. Fern´andez, F. J. Gomez,

and J. Schmidhuber. Connectionist tem-

poral classiﬁcation:

labelling unsegmented

sequence data with recurrent neural net-

works.

In Machine Learning, Proceedings

of the Twenty-Third International Confer-

ence (ICML 2006), Pittsburgh, Pennsylvania,

USA, June 25-29, 2006, volume 148 of ACM

International Conference Proceeding Series,

pages 369–376. ACM.

18

REFERENCES

[7] S. Hochreiter and J. Schmidhuber. Long

Analysis and Recognition, ICDAR 2019, Syd-

short-term memory.

Neural Comput.,

ney, Australia, September 20-25, 2019, pages

9(8):1735–1780, 1997.

1286–1293. IEEE.

[8] A. Graves, M. Liwicki, S. Fern´andez,

[13] L. Kang, P. Riba, M. Rusi˜nol, A. Forn´es, and

R. Bertolami, H. Bunke, and J. Schmid-

M. Villegas. Pay attention to what you read:

huber.

A novel

connectionist

system

Non-recurrent handwritten text-line recogni-

for unconstrained handwriting recognition.

tion. CoRR, abs/2005.13044, 2020.

IEEE Trans. Pattern Anal. Mach. Intell.,

[14] K. Barrere, Y. Soullard, A. Lemaitre, and

31(5):855–868, 2009.

B. Co¨uasnon. Transformers for Historical

[9] V. Carbune, P. Gonnet, T. Deselaers, H. A.

Handwritten Text Recognition.

In Doc-

Rowley, A. N. Daryin, M. Calvo, L.-L. Wang,

toral Consortium - ICDAR 2021, Lausanne,

D. Keysers, S. Feuz, and P. Gervais. Fast

Switzerland, September. Nibal Nayef and

multi-language lstm-based online handwrit-

Jean-Christophe Burie.

ing recognition.

Int. J. Document Anal.

[15] H. Liu, S. Jin, and C. Zhang. Connec-

Recognit., 23(2):89–102, 2020.

tionist temporal classiﬁcation with maximum

[10] B. Shi, X. Bai, and C. Yao. An end-to-

entropy regularization. In Advances in Neural

end trainable neural network for image-based

Information Processing Systems 31: Annual

sequence recognition and its application to

Conference on Neural Information Processing

scene text recognition. IEEE Trans. Pattern

Systems 2018, NeurIPS 2018, December 3-8,

Anal. Mach. Intell., 39(11):2298–2304, 2017.

2018, Montr´eal, Canada, pages 839–849.

[11] J. Puigcerver. Are multidimensional recur-

[16] L. Gao, H. Zhang, and C.-L. Liu. Hand-

rent layers really necessary for handwritten

written text recognition with convolutional

text recognition?

In 14th IAPR Interna-

prototype network and most aligned frame

tional Conference on Document Analysis and

based CTC training.

In 16th International

Recognition, ICDAR 2017, Kyoto, Japan,

Conference on Document Analysis and Recog-

November 9-15, 2017, pages 67–72. IEEE.

nition, ICDAR 2021, Lausanne, Switzerland,

[12] J. Michael, R. Labahn, T. Gr¨uning, and

September 5-10, 2021, Proceedings, Part I,

J. Z¨ollner. Evaluating sequence-to-sequence

volume 12821 of Lecture Notes in Computer

models for handwritten text recognition. In

Science, pages 205–220. Springer.

2019 International Conference on Document

[17] Y. LeCun, L. Bottou, Y. Bengio, and

P. Haﬀner. Gradient-based learning applied

REFERENCES

19

to document

recognition.

Proc.

IEEE,

Conference Track Proceedings.

86(11):2278–2324, 1998.

[23] T. Bluche and R. O. Messina. Gated convolu-

[18] E. Anquetil and G. Lorette. On-line Hand-

tional recurrent neural networks for multilin-

writing Character Recognition System Based

gual handwriting recognition. In 14th IAPR

on Hierarchical Qualitative Fuzzy Modelling.

International Conference on Document Anal-

In Progress

in Handwriting Recognition,

ysis and Recognition, ICDAR 2017, Kyoto,

pages 109–116, 1997.

Japan, November 9-15, 2017, pages 646–651.

[19] D. Simonnet, E. Anquetil, and M. Bouillon.

IEEE.

Multi-Criteria Handwriting Quality Analysis

[24] A. Almaksour and ´E. Anquetil.

Improving

with Online Fuzzy Models. Pattern Recogni-

premise structure in evolving takagi-sugeno

tion, 69:310–324, 2017.

neuro-fuzzy classiﬁers. Evol. Syst., 2(1):25–

[20] O. Krichen, S. Corbill´e, E. Anquetil,

33, 2011.

N. Girard, and P. Nerdeux. Online analy-

[25] H. Schwenk and J.-L. Gauvain.

Improved

sis of children handwritten words in dictation

rover using language model information. 11

context.

In 14th International Workshop

2000.

on Graphics Recognition, Lausanne, Switzer-

[26] F. Damerau. A technique for computer

land, September 2021.

detection and correction of spelling errors.

[21] J. R. Novak, N. Minematsu, K. Hirose,

Commun. ACM, 7(3):171–176, 1964.

C. Hori, H. Kashioka, and P. R. Dixon.

Improving wfst-based G2P conversion with

Declarations

alignment constraints and RNNLM n-best

rescoring.

In INTERSPEECH 2012, 13th

Annual Conference of

the

International

Speech Communication Association, Port-

land, Oregon, USA, September 9-13, 2012,

pages 2526–2529. ISCA.

[22] D. Bahdanau, K. Cho, and Y. Bengio. Neu-

ral machine translation by jointly learning to

align and translate. In 3rd International Con-

ference on Learning Representations, ICLR

2015, San Diego, CA, USA, May 7-9, 2015,

• Funding: Partial funding was received from

the P2IA project (French government) for this

study.

• Conﬂict of interest/Competing interests:

The authors have no relevant ﬁnancial or non-

ﬁnancial interests to disclose

• Data availability: The datasets generated

during and/or analysed during the current

study are not publicly available due to privacy

laws (RGDP) in France.

20

REFERENCES

About the authors

Omar Krichen received his PhD degree from INSA Rennes in December 2020. He is currently holding a postDoc

position at the Institut National des Sciences Appliqu´ees (INSA) Rennes, within the IntuiDoc team, at the IRISA labo-

ratory. His research interests are online handriwiting recognition, structured documents interpretation, and intelligent

tutoring systems.

Simon Corbill´e is a French Ph.D student in Computer Science from the University Rennes 1 in Rennes, France. He

holds a engineering degree in Compute Science from Polytech, in Tours, France. He is in IntuiDoc research team at

the IRISA (Institut de Recherche en Informatique et Syst`emes Al´eatoires). His works concern handwriting recognition

for an education purpose.

Eric Anquetil received his engineering degree from INSA in 1993 and his Ph.D. degree in Computer Science from

the University of Rennes in 1997. He received his Accreditation to Supervise Research (HDR) in 2008. Currently he

is a full professor at INSA in Rennes. He is the head of IntuiDoc research team at the IRISA laboratory. His research

interests include: Pattern Recognition, Fuzzy logic, Evolving Classiﬁers; Handwriting, Gesture, Symbol and Drawing

Recognition; Digital Learning. He directed several scientiﬁc projects in collaboration with companies. He is member

of the IAPR association and of the GRCE French association on handwriting recognition.

Nathalie Girard is an associate professor in Computer Science department (ISTIC), at ”Universit´e de Rennes 1”. She

works at IRISA in the IntuiDoc research team, after having held lecturer and postdoctoral positions at La Rochelle

University, L3I laboratory and University of Tours, RFAI team, LIFAT laboratory. She obtained her Ph.D. in computer

science from La Rochelle University in 2013. Her research interests include data classiﬁcation, image recognition,

incremental learning, handwriting recognition, and user interaction, and user modelling. She is member the GRCE

French association on handwriting recognition.

Elisa Fromont is professor at ”Universit´e de Rennes 1” (UR1) since 2017 and a junior member of the Institut

Universitaire de France (IUF) (2019-2024). She works at IRISA in the Inria LACODAM team. From 2008 until 2017,

she was associate professor at Universit´e Jean Monnet in Saint-Etienne (UJM), France and worked at the Hubert

Curien research institute in the Data Intelligence team. She received her Research Habilitation (HDR) in 2015 from

UJM. From 2006 until 2008, she was a postdoctoral researcher in the Machine Learning group of the KUL (Belgium).

She received her PhD in 2005 from UR1. She is particularly interested in solving real world problems with data mining

techniques especially when the data are heterogeneous, multimodal, temporal, imbalanced, subject to concept drift,

... and when it is important to explain the model’s decision to an end-user.

Pauline Nerdeux is a French computer engineer at the Institut National des Sciences Appliqu´ees (INSA) in Rennes,

France; she holds an engineering degree from Ecole Centrale Marseille with a specialization in Image Processing. She is

a member of the Intuidoc research team at the Institut de Recherche en Informatique et Syst`emes Al´eatoires (IRISA)

laboratory.

