Tameness and the power of programs over monoids in
DA
Nathan Grosshans, Pierre Mckenzie, Luc Segoufin

To cite this version:

Nathan Grosshans, Pierre Mckenzie, Luc Segoufin. Tameness and the power of programs over
monoids in DA. Logical Methods in Computer Science, 2022, 18 (3), pp.14:1-14:34. ￿10.46298/lmcs-
18(3:14)2022￿. ￿hal-03114304v3￿

HAL Id: hal-03114304

https://hal.science/hal-03114304v3

Submitted on 5 May 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN
DA ∗

NATHAN GROSSHANS a, PIERRE MCKENZIE b, AND LUC SEGOUFIN c

a Fachbereich Elektrotechnik/Informatik, Universität Kassel, Kassel, Germany

e-mail address: nathan.grosshans@polytechnique.edu
URL: https://nathan.grosshans.me

b DIRO, Université de Montréal, Montréal, Canada
e-mail address: mckenzie@iro.umontreal.ca

c Inria, DI ENS, ENS, CNRS, PSL University, Paris, France
e-mail address: luc.segouﬁn@inria.fr

Abstract. The program-over-monoid model of computation originates with Barrington’s
proof that the model captures the complexity class NC1. Here we make progress in un-
derstanding the subtleties of the model. First, we identify a new tameness condition on a
class of monoids that entails a natural characterization of the regular languages recogniz-
able by programs over monoids from the class. Second, we prove that the class known as
DA satisﬁes tameness and hence that the regular languages recognized by programs over
monoids in DA are precisely those recognizable in the classical sense by morphisms from
QDA. Third, we show by contrast that the well studied class of monoids called J is not
tame. Finally, we exhibit a program-length-based hierarchy within the class of languages
recognized by programs over monoids from DA.

1. Introduction

A program of range n on alphabet Σ over a ﬁnite monoid M is a sequence of pairs (i, f ) where
1 ≤ i ≤ n and f : Σ → M is a function. This program assigns to each word w1w2 · · · wn the
monoid element obtained by multiplying out in M the elements f (wi), one per pair (i, f ), in
the order of the sequence. When an accepting set F ⊆ M is speciﬁed, the program naturally
deﬁnes the language Ln of words of length n assigned an element in F . A program sequence
(Pn)n∈N then deﬁnes the language formed by the union of the Ln.

A program over M is a generalization of a morphism from Σ∗ to M , and recognition
by a morphism equates with acceptance by a ﬁnite automaton. Moving from morphisms
to programs has a signiﬁcant impact on the expressive power as shown by the seminal
result of Barrington [Bar89]1 that polynomial-length program sequences over the group S5

∗

Key words and phrases: Programs over monoids, tameness, DA, lower bounds.
Revised and extended version of [GMS17] that includes a more inclusive deﬁnition of tameness, thus

strengthening the statement that J is not a tame variety, as explained in Section 3.

1in fact extending the scope of an observation made earlier by Maurer and Rhodes [MR65]

Preprint submitted to
Logical Methods in Computer Science

© N. Grosshans, P. McKenzie, and L. Segouﬁn
CC(cid:13) Creative Commons

2

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

capture the complexity class NC1 (of languages accepted by bounded fan-in Boolean circuits
of logarithmic depth).

Barrington’s result was followed by several results strengthening the correspondence
between circuit complexity and programs over ﬁnite monoids. The classes AC0 ⊂ ACC0 ⊆
NC1 were characterized by polynomial-length programs over the aperiodic, the solvable, and
all monoids respectively [Bar89, BT88]. More generally for any variety V of ﬁnite monoids
one can deﬁne the class P(V) of languages recognized by polynomial-length programs over
a monoid drawn from V. In particular, if A is the variety of ﬁnite aperiodic monoids, then
P(A) characterizes the complexity class AC0 [BT88].
It was further observed that in a
formal sense, understanding the regular languages of P(V) is suﬃcient to understand the
expressive power of P(V) (see [MPT91], but also [Str94] for a logical point of view).

In view of the above results it is plausible that algebraic automata theory methods could
help separating complexity classes within NC1. But although partial results in restricted
settings were obtained, no breakthrough was achieved this way.

The reason of course is that programs are much more complicated than morphisms:
programs can read the letter at an input position more than once, in non-left-to-right order,
possibly assigning a diﬀerent monoid element each time. This complication can be illustrated
with the following example. Consider the variety of ﬁnite monoids known as J. This is
the variety generated by the syntactic monoids of all languages deﬁned by the presence or
absence of certain subwords, where u is a subword of v if u can be obtained from v by
deleting letters [Sim75]. One deduces that monoids in J are unable to morphism-recognize
the language deﬁned by the regular expression (a + b)∗ac+. Yet a sequence of programs over
a monoid in J recognizes (a + b)∗ac+ by the following trick. Consider the language L of all
words having ca as a subword but having as subwords neither cca, caa nor cb. Being deﬁned
by the occurrence of subwords, L is recognized by a morphism ϕ : {a, b, c}∗ → M where
M ∈ J, i.e., for this ϕ there is an F ⊆ M such that L = ϕ−1(F ). Here is the trick: the
program of range n over M given by the sequence of instructions

(2, ϕ), (1, ϕ), (3, ϕ), (2, ϕ), (4, ϕ), (3, ϕ), (5, ϕ), (4, ϕ), · · · , (n, ϕ), (n − 1, ϕ),

using F as accepting set, deﬁnes the set of words of length n in (a + b)∗ac+. For instance,
on input abacc the program outputs ϕ(baabcacc) which is in F , while on inputs abbcc and
abacca the program outputs respectively ϕ(babbcbcc) and ϕ(baabcaccac) which are not in F .
(See [Gro20, Lemma 4.1] for a full proof of the fact that (a + b)∗ac+ ∈ P(J).)

The ﬁrst part of our paper addresses the question of what are the regular languages in
P(V). As mentioned above, this is the key to understanding the expressive power of P(V).
Observe ﬁrst that the class L(V) of all languages recognized by a morphism into a
monoid in V is trivially included in P(V). It turns out that P(V) always contains more
regular languages. For instance, because a program instruction (i, f ) operating on a word w
is “aware” of i, the program can have a behavior depending on some arithmetic properties
of i. Moreover, a program’s behavior can in general depend on the length of the input words
it treats. So in particular, as far as regular languages are concerned, a program for a given
input length can take into account the length of the input modulo some ﬁxed number k in
its acceptance set and each program instruction (i, f ) can depend on the value of i modulo k.
This can be formalized by assuming without loss of generality that membership can depend
on the length of the word w at hand modulo a ﬁxed number k and that each letter in w is
tagged with its position modulo k. Regular languages recognized this way are exactly the
languages recognized by a stamp (a surjective morphism from Σ∗ to M with Σ an alphabet

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

3

and M a ﬁnite monoid) in the variety of stamps V ∗ Mod, where ∗ is the wreath product
of stamps and Mod the variety of cyclic stamps into groups. In other words, L(V ∗ Mod)
is always included in P(V).

A program over a monoid can also recognize regular languages by changing its behavior
depending on bounded-length preﬁxes and suﬃxes arbitrarily. To formalize this, we introduce
the class EV of stamps that, modulo the beginning and the end of a word, behave essentially
like stamps into monoids from V. It is then not too hard to show that L(EV ∗ Mod) is
always included in P(V) when V does contain non-trivial monoids. Many varieties V are
such that P(V) cannot recognize more regular languages than those in L(EV ∗ Mod). This
is the case for example of the variety DA as we will see below.

Our ﬁrst result characterizes those varieties V having the property that P(V) does not
contain “many more” regular languages than does L(EV ∗ Mod). To this end we introduce
the notion of tameness for a variety of ﬁnite monoids V (Deﬁnition 3.9) and our ﬁrst result
shows that a variety of ﬁnite monoids V is tame if and only if P(V) ∩ Reg ⊆ L(QEV).
Here, L(QV) is the class of regular languages recognized by stamps in quasi-V. A stamp ϕ
from Σ∗ to M is in quasi-V if, though M might not be in V, its stable monoid induced by
ϕ is in V, i.e. there is a number k such that ϕ((Σk)∗) forms a submonoid of M which is in
V. For tame varieties V we do not know when the inclusion of L(EV ∗ Mod) in L(QEV)
is strict or not. In particular we do not know when the inclusion in our result is an equality.
As usual in this context, we conjecture that equality holds at least for local varieties V.

Our notion of a tame variety diﬀers subtly but fundamentally from the notion of p-
variety (program-variety). This notion goes back to Péladeau [Pél90] and can be stated
by saying that a variety of ﬁnite monoids V is a p-variety whenever any monoid that can
be “simulated” by programs over a monoid in V belongs itself to V. Equivalently, V is
a p-variety whenever any regular language in P(V) with a neutral letter (a letter which
can be inserted and deleted arbitrarily in words without changing their membership in the
language) is in fact morphism-recognized by a monoid in V. (The equivalence between the
two deﬁnitions is claimed without a proof in [Tes03] and [Gro18], see [PST97] for a proof in
one direction, the other direction requiring a standard argument.) While understanding the
neutral letter regular languages in P(V) for V ranging over all possible varieties of ﬁnite
monoids would suﬃce to solve most open questions about the internal structure of NC1, for
V to be a p-variety does not imply a precise characterization of all the regular languages in
P(V). It can be proved that if V is a p-variety then the regular languages in P(V) are all
in L(QLV), where LV is the inclusion-wise largest variety of ﬁnite semigroups containing
all monoids in V and only those monoids. For instance, DA is a p-variety [LTT06], and this
implies that P(DA) ∩ Reg ⊆ L(QLDA) as explained above. The latter inclusion is strict
and the correct characterization, namely L(QEDA), requires proving that DA is also tame
in our sense. Furthermore, there exist p-varieties for which unexpected (and interesting)
things happen when considering program-recognition of regular languages without neutral
letter, and this precisely because they aren’t tame. For example, P(J) ∩ Reg ⊆ L(QLJ)
with strict inclusion while it will follow from our result that P(J)∩Reg * L(QEJ) (knowing
that it is easy to check that L(QEJ) ⊆ L(QLJ)).

The situation for programs over ﬁnite semigroups of the form V∗D, where V is a variety
of ﬁnite monoids and D is the variety of ﬁnite deﬁnite (or righty trivial) semigroups, turns
out to be much simpler. Indeed, with the necessary adaptations to the notion of p-variety,
Péladeau, Straubing and Thérien [PST97] could show that for any p-variety of the form
V ∗ D we have P(V ∗ D) ∩ Reg = L(Q(V ∗ D)). Once our notion of tameness is adapted

4

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

for ﬁnite semigroups, it is possible to show that any p-variety of the form V ∗ D is tame.
Hence the result of [PST97] mentioned above follows from our result as for varieties of the
form V ∗ D we have, abusing notation, that E(V ∗ D) = V ∗ D and that L(Q(V ∗ D)) =
L(V ∗ D ∗ Mod) ⊆ P(V ∗ D). It is to be noted that programs over semigroups in V ∗ D
correspond to Straubing’s k-programs over monoids in V [Str00, Str01]. It is also possible
to prove that regular languages recognized by monoids from a k-program variety V, as for
p-varieties, are all in L(QLV). Interestingly, in order to get a tight characterization for the
regular languages recognized by k-programs over commutative monoids in [Str01], Straubing
determines not only which monoids can be simulated by such k-programs, but, in our terms,
which stable stamps those k-programs can “simulate”. Our notion of tameness also builds
upon stable stamps and, as we have advocated above, subsumes previous deﬁnitions of “good
behavior” of programs with respect to recognition of regular languages.

Tameness as deﬁned here is also a proper extension of the notion of sp-varieties of
monoids (Deﬁnition 3.3), a concept introduced in [GMS17] as our initial attempt to capture
the expected behavior of programs over small varieties. We will for instance see that the
variety of ﬁnite commutative monoids is tame but not an sp-variety.

Showing that a variety is tame can be a diﬃcult task. For instance showing that the
variety A is tame amounts to showing that the regular languages in AC0 are in L(QA),
which, as shown by Barrington, Compton, Straubing and Thérien [BCST92], follows from
the fact that modulo counting cannot be done in AC0 (the famous result initially proven by
Furst, Saxe and Sipser [FSS84] and independently by Ajtai [Ajt83]). Similarly much of the
structure of NC1 would in fact be resolved by showing the tameness of certain varieties (see
[MPT91, Corollary 4.13], [Str94, Conjecture IX.3.4]).

The present work is motivated by the need to better understand the subtle behaviors
of polynomial-length programs over monoids. We focus in this paper on the variety of
monoids DA. The importance of DA in algebraic automata theory and its connections
with other ﬁelds are well established (see [TT02b] for an eloquent testimony). In particular
P(DA) corresponds to languages accepted by decision trees of bounded rank [GT03]. It
is also known that regular languages with a neutral letter that are in P(DA) are also
in L(DA) [LTT06].

Our second result shows that the variety DA is tame. As it is easy to see that DA
is powerful enough to describe preﬁxes and suﬃxes of words up to some bounded length,
we get that L(EDA) = L(DA). Moreover, because DA is a local variety, QDA = DA ∗
Mod [DP13]. Altogether the tameness of DA implies that the regular languages in P(DA)
are precisely the languages in L(QDA).

Our third result is that, on the other hand, the variety of ﬁnite monoids J is not tame
as witnessed by the regular language (a + b)∗ac+ discussed above which is in P(J) but not in
L(QEJ). Characterizing the regular languages in P(J) remains an open problem, partially
solved in [Gro20].

Our ﬁnal result concerns P(DA). With Ck the class of languages recognized by programs
of length O(nk) over DA, we prove that C1 ⊂ C2 ⊂ · · · ⊂ Ck ⊂ · · · ⊂ P(DA) forms a strict
hierarchy. We also relate this hierarchy to another algebraic characterization of DA and
exhibit conditions on M ∈ DA under which any program over M can be rewritten as an
equivalent subprogram (made of a subsequence of the original sequence of instructions) of
length O(nk), reﬁning a result by Tesson and Thérien [TT02a].

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

5

Organization of the paper.

In Section 2 we deﬁne programs over monoids, p-
recognition by such programs and the necessary algebraic background. The deﬁnition of
tameness for a variety V is given in Section 3 with our ﬁrst result showing that regular
languages in P(V) are included in L(QEV) if and only if V is tame; we also brieﬂy discuss
the case of J, which isn’t tame. We show that DA is tame in Section 4. Finally, Section 5
contains the hierarchy results about P(DA).

2. Preliminaries

This section is dedicated to the introduction of the mathematical material used throughout
this paper. Concerning algebraic automata theory, we only quickly review the basics and
refer the reader to the two classical references of the domain by Eilenberg [Eil74, Eil76] and
Pin [Pin86].

General notations. Let i, j ∈ N be two natural numbers. We shall denote by [[i, j]] the set of
all natural numbers n ∈ N verifying i ≤ n ≤ j. We shall also denote by [i] the set [[1, i]].

Words and languages. Let Σ be a ﬁnite alphabet. We denote by Σ∗ the set of all ﬁnite words
over Σ. We also denote by Σ+ the set of all ﬁnite non empty words over Σ, the empty word
being denoted by ε. Since all our alphabets and words in this article are always ﬁnite, we
shall not mention it anymore from here on. Given some word w ∈ Σ, we denote its length by
|w| and, for any a ∈ Σ, by |w|a the number of occurrences of the letter a in w. A language
over Σ is a subset of Σ∗. A language is regular if it can be deﬁned using a regular expression.
Given a language L, its syntactic congruence ∼L is the relation on Σ∗ relating two words u
and v whenever for all x, y ∈ Σ∗, xuy ∈ L if and only if xvy ∈ L. It is easy to check that
∼L is an equivalence relation and a congruence for concatenation. The syntactic morphism
of L is the mapping sending any word u to its equivalence class in the syntactic congruence.
The quotient of a language L over Σ relative to the words u and v is the language,

denoted by u−1Lv−1, of the words w such that uwv ∈ L.

Monoids, semigroups and varieties. A semigroup is a non-empty set equipped with an asso-
ciative law that we will write multiplicatively. A monoid is a semigroup with an identity.
An example of a semigroup is Σ+, the free semigroup over Σ. Similarly Σ∗ is the free monoid
over Σ. With the exception of free monoids and semigroups, all monoids and semigroups
considered here are ﬁnite. A morphism ϕ from a semigroup S to a semigroup T is a func-
tion from S to T such that ϕ(xy) = ϕ(x)ϕ(y) for all x, y ∈ S. A morphism of monoids
additionally requires that the identity is preserved; unless otherwise stated, when we say
“morphism”, we always mean “monoid morphism”. Any morphism ϕ : Σ∗ → M for Σ an
alphabet and M some monoid is uniquely determined by the images of the letters of Σ by ϕ.
A semigroup T is a subsemigroup of a semigroup S if T is a subset of S and is equipped with
the restricted law of S. Additionally the notion of submonoids requires the presence of the
identity. A semigroup T divides a semigroup S if T is the image by a semigroup morphism
of a subsemigroup of S. Division of monoids is deﬁned in the same way by replacing any
occurrence of “semigroup” by “monoid”. The Cartesian (or direct) product of two semigroups
is simply the semigroup given by the Cartesian product of the two underlying sets equipped
with the Cartesian product of their laws.

A language L over Σ is recognized by a monoid M if there is a morphism h from Σ∗ to M
and a subset F of M such that L = h−1(F ). We also say that the morphism h recognizes L.

6

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

It is well known that a language is regular if and only if it is recognized by a ﬁnite monoid.
Actually, as ∼L is a congruence, the quotient Σ∗/∼L is a monoid, called the syntactic monoid
of L, that recognizes L via the syntactic morphism of L. The syntactic monoid of L is ﬁnite
if and only if L is regular. The quotient Σ+/∼L is analogously called the syntactic semigroup
of L.

A variety of ﬁnite monoids is a non-empty class of ﬁnite monoids closed under Cartesian
product and monoid division. A variety of ﬁnite semigroups is deﬁned similarly. When
dealing with varieties, we consider only varieties of ﬁnite monoids or semigroups, so we will
drop the adjective “ﬁnite” when talking about those.

An element s of a semigroup is idempotent if ss = s. For any ﬁnite semigroup S there
is a positive number (the minimum such number), the idempotent power of S, often denoted
ω, such that for any element s ∈ S, sω is idempotent.

A general result of Reiterman [Rei82] states that each variety of monoids (or semigroups)
can be deﬁned as the class of all ﬁnite monoids satisfying some set of identities, for an
appropriate notion of identity. In our case, we only use a restricted version of this notion of
an identity, that we understand as a formal equality of terms built on the basis of variables
by using products and ω-powers. A ﬁnite monoid is then said to satisfy such an identity
whenever the equality is veriﬁed for any setting of the variables to elements of the monoid,
interpreting the ω-power as the idempotent power of that monoid. For instance, the variety
of ﬁnite aperiodic monoids A, known as the variety of “group-free” ﬁnite monoids (i.e. those
verifying that they do not have any non-trivial group as a subsemigroup), is deﬁned by
the identity xω = xω+1. The variety of monoids DA is deﬁned by the identity (xy)ω =
(xy)ωx(xy)ω. The variety of monoids J is deﬁned by the identities (xy)ω = (xy)ωx = y(xy)ω.
One easily deduces that J ⊆ DA ⊆ A.

Varieties of languages. A variety of languages is a class of languages over arbitrary alphabets
closed under Boolean operations, quotients and inverses of morphisms (i.e. if L is a language
in the class over an alphabet Σ, if Γ is some other alphabet and ϕ : Γ∗ → Σ∗ is a morphism,
then ϕ−1(L) is also in the class).

Eilenberg showed [Eil76, Chapter VII, Section 3] that there is a bijective correspondence
between varieties of monoids and varieties of languages: to each variety of monoids V we
can bijectively associate L(V) the variety of languages whose syntactic monoids belong to
V and, conversely, to each variety of languages V we can bijectively associate M(V) the
variety of monoids generated by the syntactic monoids of the languages of V, and these
correspondences are mutually inverse.

When V is a variety of semigroups, we will denote by L(V) the class of languages
whose syntactic semigroup belongs to V. There is also an Eilenberg-type correspondence
for an appropriate notion of language varieties, that is ne-varieties (non-erasing-varieties) of
languages, but we won’t present it here. (The interested reader may have a look at [Str02]
as well as [PS05, Lemma 6.3].)

Quasi and locally V languages, modular counting and predecessor. If S is a semigroup we
denote by S1 the monoid S if S is already a monoid and S ∪ {1} otherwise.

The following deﬁnitions are taken from [PS05, CPS06b]. Let ϕ be a surjective morphism
from Σ∗, for Σ some alphabet, to a ﬁnite monoid M : such a morphism is called a stamp. For
all k consider the subset ϕ(Σk) of M . As M is ﬁnite there is a k such that ϕ(Σ2k) = ϕ(Σk).
This implies that ϕ(Σk) is a semigroup. The semigroup given by the smallest such k is called

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

7

the stable semigroup of ϕ and this k is called the stability index of ϕ. If 1 is the identity of
M , then ϕ(Σk) ∪ {1} is called the stable monoid of ϕ. If V is a variety of monoids, then
we shall denote by QV the class of stamps whose stable monoid is in V and by L(QV) the
class of languages whose syntactic morphism is in QV.

For V a variety of monoids, we say that a ﬁnite semigroup S is locally V if, for every
idempotent e of S, the monoid eSe belongs to V; we denote by LV the class of locally-V
ﬁnite semigroups, which happens to be a variety of semigroups.

We now deﬁne languages recognized by V ∗ Mod and V ∗ D. We do not use the
standard algebraic deﬁnition using the wreath product as we won’t need it, but instead give
a characterization of the languages recognized by such algebraic objects [CPS06a, Til87].

Let V be a variety of monoids. We say that a language over Σ is in L(V ∗ Mod) if
it is obtained by a ﬁnite combination of unions and intersections of languages over Σ for
which membership of each word over Σ only depends on its length modulo some integer
k ∈ N>0 and languages L over Σ for which there is a number k ∈ N>0 and a language L′
over Σ × {0, . . . , k − 1} whose syntactic monoid is in V, such that L is the set of words
w that belong to L′ after adding to each letter of w its position modulo k. Observe that
neither V ∗ Mod nor QV are varieties of monoids or semigroups, but classes of stamps that
happen to be varieties of stamps of a certain kind2, that we won’t introduce.

Similarly we say that a language over Σ is in L(V ∗ D) if it is obtained by a ﬁnite
combination of unions and intersections of languages over Σ for which membership of each
word over Σ only depends on its k ∈ N last letters and languages L over Σ for which there
is a number k ∈ N and a language L′ over Σ × Σ≤k (where Σ≤k denotes all words over Σ of
length at most k) whose syntactic monoid is in V, such that L is the set of words w that
belong to L′ after adding to each letter of w the word composed of the k (or less when near
the beginning of w) letters preceding that letter. The variety of semigroups V ∗ D can then
be deﬁned as the one generated by the syntactic semigroups of the languages in L(V ∗ D)
as deﬁned above.

A variety of monoids V is said to be local if L(V ∗ D) = L(LV). This is not the usual
deﬁnition of locality, deﬁned using categories, but it is equivalent to it [Til87, Theorem 17.3].
One of the consequences of locality that we will use is that L(V ∗ Mod) = L(QV) when V
is local [DP14, Corollary 18], while L(V ∗ Mod) ⊆ L(QV) in general (see [Dar14, Pap14]).

Programs over varieties of monoids. Programs over monoids form a non-uniform model of
computation, ﬁrst deﬁned by Barrington and Thérien [BT88], extending Barrington’s per-
mutation branching program model [Bar89]. Let M be a ﬁnite monoid and Σ an alphabet.
A program P over M is a ﬁnite sequence of instructions of the form (i, f ) where i is a positive
integer and f a function from Σ to M . The length of P is the number of its instructions.
A program has range n if all its instructions (i, f ) verify 1 ≤ i ≤ n. A program P of range
n deﬁnes a function from Σn, the words of length n, to M as follows. On input w ∈ Σn,
for w = w1 · · · wn, each instruction (i, f ) outputs the monoid element f (wi). A sequence of
instructions then yields a sequence of elements of M and their product is the output P (w)
of the program. The only program of range 0, the empty one, always outputs the identity
of M .

A language L over Σ is p-recognized by a sequence of programs (Pn)n∈N if for each n, Pn
has range n and length polynomial in n and recognizes L ∩ Σn, that is, there exists a subset

2To be precise, both are lm-varieties of stamps, as deﬁned in [Str02].

8

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

Fn of M such that L ∩ Σn is precisely the set of words w of length n such that Pn(w) ∈ Fn.
In that case, we also say that L is p-recognized by M .

We denote by P(M ) the class of languages p-recognized by a sequence of programs
(Pn)n∈N over M . If V is a variety of monoids we denote by P(V) the union of all P(M ) for
M ∈ V.

The following is a simple fact about P(V). Let Σ and Γ be two alphabets and µ : Σ∗ →
Γ∗ be a morphism. We say that µ is length multiplying, or that µ is an lm-morphism, if
there is a constant k such that for all a ∈ Σ, the length of µ(a) is k.

Lemma 2.1. [MPT91, Corollary 3.5] For V any variety of monoids, P(V) is closed under
Boolean operations, quotients and inverse images of lm-morphisms.

Given two range n programs P, P ′ over some monoid M using the same input alphabet
Σ, we shall say that P ′ is a subprogram, a preﬁx or a suﬃx of P whenever P ′ is, respectively,
a subword, a preﬁx or a suﬃx of P , looking at P and P ′ as words over [n] × M Σ.

3. General results about regular languages and programs

Let V be a variety of monoids. By deﬁnition any regular language recognized by a monoid
in V is p-recognized by a sequence of programs over a monoid in V. Actually, since in
a program over some monoid in V, the monoid element output for each instruction can
depend on the position of the letter read, hence in particular on its position modulo some
ﬁxed number, it is easy to see that any regular language in L(V ∗ Mod) is p-recognized by
a sequence of programs over some monoid in V. We will see in Section 3.2 that programs
over some monoid in V can also p-recognize the regular languages that are “essentially V”
i.e. that diﬀer from a language in L(V) only on the preﬁx and suﬃx of the words.

In this section we characterize those varieties V such that programs over monoids in V

do not recognize more regular languages than those mentioned above.

We ﬁrst recall the deﬁnitions and results around p-varieties developed by Péladeau,
Tesson, Straubing and Thérien and then present the deﬁnition of sp-varieties that was
inspired by their work and studied in the conference version of the present paper. In order
to deal with the limitation of sp-varieties we then deﬁne the notion of essentially-V that
will be the last ingredient for our deﬁnition of tameness. We then provide an upper bound
on the regular languages that can be p-recognized by a sequence of programs over a monoid
from a tame variety V.

3.1. p- and sp-varieties of monoids. We ﬁrst recall the deﬁnition of p-varieties. These
seem to have been originally deﬁned by Péladeau in his Ph.D. thesis [Pél90] and later used
by Tesson in his own Ph.D. thesis [Tes03]. The notion of a p-variety has also been deﬁned
for semigroups by Péladeau, Straubing and Thérien in [PST97].

Let µ be a morphism from Σ∗ to a ﬁnite monoid M . We denote by W(µ) the set of
languages L over Σ such that L = µ−1(F ) for some subset F of M . Given a semigroup S
there is a unique morphism ηS : S∗ → S1 extending the identity on S, called the evaluation
morphism of S. We write W(S) for W(ηS). We deﬁne W(M ) similarly for any monoid
M . It is easy to see that if M ∈ V then W(M ) ⊆ P(V). The condition to be a p-variety
requires a converse of this observation.

Deﬁnition 3.1. An p-variety of monoids is a variety V of monoids such that for any ﬁnite
monoid M , if W(M ) ⊆ P(V) then M ∈ V.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

9

The following result illustrates an important property of p-varieties, when the notion is

adapted to varieties of semigroups accordingly.

Proposition 3.2. [PST97] Let V ∗ D be a p-variety of semigroups, where V is a variety of
monoids.

Then P(V ∗ D) ∩ Reg = L(V ∗ D ∗ Mod) (where the latter class is deﬁned in the same

way as L(V ∗ Mod)).

It is known that J is a p-variety of monoids [Tes03] but as we have seen in the introduc-
tion, P(J) contains languages that are more complicated than those in L(J ∗ Mod) (see the
end of this subsection for a proof). In order to capture those varieties for which programs
are well behaved we need a restriction of p-varieties and this brings us to the following
deﬁnition.

Deﬁnition 3.3. An sp-variety of monoids is a variety V of monoids such that for any ﬁnite
semigroup S, if W(S) ⊆ P(V) then S1 ∈ V.

Hence any sp-variety of monoids is also a p-variety of monoids, but the converse is not

always true as we will see in Proposition 3.6 below that J is not an sp-variety.

An example of an sp-variety of monoids is the class of aperiodic monoids A. This is a
consequence of the result that for any number k > 1, checking if |w|a is a multiple of k for
w ∈ {a, b}∗ cannot be done in AC0 = P(A) [FSS84, Ajt83] (we shall denote the corresponding
language over the alphabet {0, 1} by MODk). Towards a contradiction, assume there would
exist a semigroup S such that S1 is not aperiodic but still W(S) ⊆ P(A). Then there is an x
in S such that xω 6= xω+1. Consider the morphism µ : {a, b}∗ → S1 sending a to xω+1 and b
to xω, and the language L = µ−1(xω). It is easy to see that L is the language of all words with
a number of a congruent to 0 modulo k, where k is the smallest number such that xω+k = xω.
As xω 6= xω+1, we have k > 1, so that L /∈ P(A) by [FSS84, Ajt83]. Let ηS : S∗ → S1 be
the evaluation morphism of S. The morphism ϕ : Σ∗ → S∗ sending each letter a ∈ Σ to
µ(a) veriﬁes that µ = ηS ◦ ϕ, so that L = µ−1(xω) = (ηS ◦ ϕ)−1(xω) = ϕ−1(η−1
S (xω)). From
W(S) ⊆ P(A) it follows that η−1
S (xω) ∈ P(A), hence since ϕ sends each letter of Σ to a
letter of S, it is an lm-morphism and as P(A) is closed under inverses of lm-morphisms by
Lemma 2.1, we have L = ϕ−1(η−1

S (xω)) ∈ P(A), a contradiction.

The following is the desired consequence of being an sp-variety of monoids.

Proposition 3.4. Let V be an sp-variety of monoids. Then P(V) ∩ Reg ⊆ L(QV).

Proof. Let L be a regular language in P(M ) for some M ∈ V. Let ML be the syntactic
monoid of L and ηL its syntactic morphism. Let S be the stable semigroup of ηL, in
particular S = ηL(Σk) for some k. We wish to show that S1 is in V.

We show that W(S) ⊆ P(V) and conclude from the fact that V is an sp-variety that
S1 ∈ V as desired. Let ηS : S∗ → S1 be the evaluation morphism of S. Consider m ∈ S and
consider L′ = η−1
S (m). We wish to show that L′ ∈ P(V). This implies that W(S) ⊆ P(V)
by closure under union, Lemma 2.1.

Let L′′ = η−1

L (m). Since m belongs to the syntactic monoid of L and ηL is the syntactic
morphism of L, a classical algebraic argument [Pin86, Chapter 2, proof of Lemma 2.6]
shows that L′′ is a Boolean combination of quotients of L. By Lemma 2.1, we conclude that
L′′ ∈ P(V).

By deﬁnition of S, for any element s of S there is a word us of length k such that

ηL(us) = s. Notice that this is precisely where we need to work with S and not S1.

10

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

Let f : S∗ → Σ∗ be the lm-morphism sending s to us and notice that L′ = f −1(L′′). The

result follows by closure of P(V) under inverse images of lm-morphisms, Lemma 2.1.

We don’t know whether it is always true that for sp-varieties of monoids V, L(QV) is

included in P(V). But we can prove it for local varieties.

Proposition 3.5. Let V be a local sp-variety of monoids. Then P(V) ∩ Reg = L(QV).

Proof. This follows from the fact that for local varieties L(QV) = L(V ∗ Mod) (see [DP14]).
The result can then be derived using Proposition 3.4, as we always have L(V ∗ Mod) ⊆
P(V).

As A is local [Til87, Example 15.5] and an sp-variety, it follows from Proposition 3.5
that the regular languages in P(A), hence in AC0, are precisely those in L(QA), which
is the characterization of the regular languages in AC0 obtained by Barrington, Compton,
Straubing and Thérien [BCST92].

We will see in the next section that DA is an sp-variety. As it is also local [Alm96],
we get from Proposition 3.5 that the regular languages of P(DA) are precisely those in
L(QDA).

As explained in the introduction, the language (a + b)∗ac+ can be p-recognized by a
program over J. A simple algebraic argument shows that it is not in L(QJ): just compute
the stable monoid of the syntactic morphism of the language, which is equal to the syntactic
monoid of the language, that is not in J. Hence, by Proposition 3.4, we have the following
result:

Proposition 3.6. J is not an sp-variety of monoids.

Despite Proposition 3.6 providing some explanation for the unexpected relative strength
of programs over monoids in J, the notion of an sp-variety of monoids isn’t entirely satisfac-
tory.

We say that a monoid is trivial when its underlying set contains a sole element. The
class of all trivial monoids, that we will denote by I, forms a variety: it is the sole variety
containing only trivial monoids, so we may call it the trivial variety of monoids.

One observation to be made is that any non-trivial monoid M p-recognizes the language
of words over {a, b} starting with an a: for the ﬁrst position in any word, just send a to any
element that is not the identity and b to the identity. This means that for any non-trivial
variety of monoids V, we have that a(a + b)∗ ∈ P(V). But since the stable monoid of
the syntactic morphism of a(a + b)∗ is equal to the syntactic monoid of this language, it
follows that for any non-trivial variety of monoids V not containing the syntactic monoid
of a(a + b)∗, we have P(V) ∩ Reg * L(QV), hence that V is not an sp-variety of monoids.
Therefore, many varieties of monoids actually aren’t sp-varieties of monoids simply
because of the built-in capacity of programs over any non-trivial monoid to test the ﬁrst
letter of input words. This is for example true for any non-trivial variety containing only
groups and for any non-trivial variety containing only commutative monoids. This built-in
capacity, additional to programs’ ability to do positional modulo counting that underlies the
deﬁnition of sp-varieties, should be taken into account in the notion we are looking for to
capture “good behavior”. In order to deﬁne our notion of tameness we ﬁrst study this extra
capacity that is built-in for programs over V and that we call “essentially-V”.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

11

3.2. Essentially-V stamps. It is easy to extend our reasoning above to show that given
any non-trivial monoid M and given some k ∈ N>0, the language of words over {a, b} having
an a in position k, that is (a + b)k−1a(a + b)∗, is p-recognized by M , and the same goes for
(a+b)∗a(a+b)k−1. By generalizing, we can quickly conclude that given any non-trivial variety
of monoids V, for any alphabet Σ and any x, y ∈ Σ∗, we have that xΣ∗y ∈ P(V) by closure
of P(V) under Boolean operations, Lemma 2.1. Put informally, p-recognition by monoids
taken from any ﬁxed non-trivial variety of monoids allows one to check some constant-length
beginning or ending of the input words. Moreover, p-recognition by monoids taken from any
ﬁxed non-trivial variety of monoids V also easily allows to test for membership of words in
L(V) after stripping out some constant-length beginning or ending: that is, languages of
the form Σk1LΣk2 for k1, k2 ∈ N and L ∈ L(V).

This motivates the deﬁnition of essentially-V stamps.

Deﬁnition 3.7. Let V be a variety of monoids. Let ϕ : Σ∗ → M be a stamp and let s be
its stability index.

We say that ϕ is essentially-V whenever there exists a stamp µ : Σ∗ → N with N ∈ V

such that for all u, v ∈ Σ∗, we have

µ(u) = µ(v) ⇒

ϕ(xuy) = ϕ(xvy) ∀x, y ∈ Σs

.

We will denote by EV the class of all essentially-V stamps3 and by L(EV) the class of
languages recognized by morphisms in EV.

(cid:0)

(cid:1)

Informally stated, a stamp ϕ : Σ∗ → M is essentially-V when it behaves like a stamp
into a monoid of V as soon as a suﬃciently long beginning and ending of any input word
has been ﬁxed. The value for “suﬃciently long” depends on ϕ and is adequately given by
the stability index s of ϕ, as by deﬁnition of s, any word w of length at least 2s can always
be made of length between s and 2s − 1 without changing the image by ϕ.

Let us start by giving some examples.
Consider ﬁrst the language a(a+b)∗ over the alphabet {a, b}. Let’s take ϕ : {a, b}∗ → M
to be its syntactic morphism:
its stability index is equal to 1 and it has the property
that for any w ∈ {a, b}∗, we have ϕ(aw) = ϕ(a) and ϕ(bw) = ϕ(b). Hence, if we deﬁne
µ : {a, b}∗ → {1} to be the obvious stamp into the trivial monoid {1}, we indeed have that
for all u, v ∈ {a, b}∗, it holds that

µ(u) = µ(v) ⇒

ϕ(xuy) = ϕ(xvy) ∀x, y ∈ {a, b}1

.

In conclusion, the stamp ϕ is essentially-V for any variety of monoids, in particular a(a +
b)∗ ∈ L(EI).

(cid:0)

(cid:1)

Let us now consider the language a(a + b)∗b(a + b)∗a over the alphabet {a, b} of words
starting and ending with an a and containing some b in between. Let ϕ′ : {a, b}∗ → M ′ be
its syntactic morphism: its stability index is equal to 3 and it has the property that for all
x, y ∈ {a, b}+, given any u, v ∈ {a, b}∗ verifying that the letter b appears in u if and only
if it appears in v, it holds that ϕ′(xuy) = ϕ′(xvy). Hence, if we deﬁne µ′ : {a, b}∗ → N ′ to
be the syntactic morphism of the language (a + b)∗b(a + b)∗, it is direct to see that for all
u, v ∈ {a, b}∗, it holds that

µ′(u) = µ′(v) ⇒

ϕ′(xuy) = ϕ′(xvy) ∀x, y ∈ {a, b}3

.

3This class actually is an ne-variety of stamps, as deﬁned in [Str02].

(cid:0)

(cid:1)

12

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

So we can conclude that the stamp ϕ′ is essentially-V for any variety of monoids containing
the syntactic monoid of (a+ b)∗b(a+ b)∗, in particular a(a+ b)∗b(a+ b)∗a ∈ L(EJ). However,
note that ϕ′ /∈ EI because we have ϕ′
(aaa)a(aaa)

(aaa)b(aaa)

6= ϕ′

.

It is now easy to prove that as long as V is non-trivial, polynomial-length programs
over monoids from V do have the built-in capacity to recognize any language recognized by
an essentially-V stamp.

(cid:1)

(cid:0)

(cid:1)

(cid:0)

Proposition 3.8. For any non-trivial variety of monoids V, we have L(EV) ⊆ P(V).

Proof. Let ϕ : Σ∗ → M be a stamp in EV. By deﬁnition, given the stability index s of ϕ,
there exists a stamp µ : Σ∗ → N with N ∈ V such that for all u, v ∈ Σ∗, we have

µ(u) = µ(v) ⇒

ϕ(xuy) = ϕ(xvy) ∀x, y ∈ Σs

.

Let F ⊆ M . By deﬁnition of µ, given m ∈ N and x, y ∈ Σs, we either have that
xµ−1(m)y ⊆ ϕ−1(F ) or that xµ−1(m)y ∩ ϕ−1(F ) = ∅. This entails that there exist B ⊆
Σ≤2s−1 and I ⊆ Σs × N × Σs such that

(cid:0)

(cid:1)

ϕ−1(F ) = B ∪

xµ−1(m)y .

[(x,m,y)∈I
We claim that {w} ∈ P(V) for any w ∈ Σ≤2s−1 and also that xµ−1(m)y ∈ P(V) for any
x, y ∈ Σs and m ∈ N . So, by closure of P(V) under Boolean operations, Lemma 2.1, it
follows that ϕ−1(F ) ∈ P(V). Since this is true for any F , we have that W(ϕ) ⊆ P(V) and
as this is itself true for all ϕ, we can conclude that L(EV) ⊆ P(V).

The claim remains to be proven.
Let k ∈ N>0 and a ∈ Σ. Since V is non-trivial, there exists a non-trivial N ′ ∈ V: we
shall denote its identity by 1 and by z one of its elements distinct from the identity, chosen
arbitrarily. It is easy to see that the language Σk−1aΣ∗ is p-recognized by the sequence of
programs (Pn)n∈N over N ′ such that for all n ∈ N, we have

Pn =

(k, f )
ε
(

if n ≥ k
otherwise

where f : Σ → N ′ is deﬁned by f (b) =

Σ∗aΣk−1 symmetrically.

z
1
(

if b = a
otherwise

for all b ∈ Σ. We prove the same for

It then follows by closure of P(V) under Boolean operations, Lemma 2.1, that {w} ∈

P(V) for any w ∈ Σ≤2s−1 and that xΣ∗y ∈ P(V) for any x, y ∈ Σs.

Finally, let m ∈ N . It is direct to show that there exists Lm ⊆ Σ∗ in P(V) verifying
that Lm ∩ ΣsΣ∗Σs = Σsµ−1(m)Σs: just build the sequence of programs (Qn)n∈N over N
such that for all n ∈ N, we have

Qn =

(

(s + 1, g)(s + 2, g) · · · (n − s, g)
ε

if n ≥ 2s + 1
otherwise

where g : Σ → N is deﬁned by g(b) = µ(b) for all b ∈ Σ. We can then conclude that
xµ−1(m)y ∈ P(V) for any x, y ∈ Σs by closure of P(V) under Boolean operations, Lemma 2.1,
and this holds for any m.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

13

3.3. Tameness. We are now ready to deﬁne tameness.

We will say that a stamp ϕ : Σ∗ → M is stable whenever ϕ(Σ2) = ϕ(Σ), i.e. the stability

index of ϕ is 1.

Deﬁnition 3.9. A variety of monoids V is said to be tame whenever for any stable stamp
ϕ : Σ∗ → M , if W(ϕ) ⊆ P(V) then ϕ ∈ EV.

Let us ﬁrst mention that tameness is a generalization of sp-varieties of monoids.

Proposition 3.10. Any sp-variety of monoids is tame.

Proof. Let V be an sp-variety of monoids.

Let ϕ : Σ∗ → M be a stable stamp such that W(ϕ) ⊆ P(V).
Let S = ϕ(Σ+): as ϕ is stable, we have S = ϕ(Σ). Let ρ : S → Σ be an arbitrary
mapping from S to Σ such that ϕ(ρ(s)) = s. Consider ηS : S∗ → S1 the evaluation morphism
of S: the unique morphism f : S∗ → Σ∗ sending each letter s ∈ S to ρ(s) veriﬁes that ηS =
ϕ ◦ f . Now, given any F ⊆ S1, we have η−1
S (F ) = f −1(ϕ−1(F )), but since ϕ−1(F ) ∈ P(V)
and as f is an lm-morphism because it sends each letter of S to a letter of Σ, it follows that
η−1
S (F ) ∈ P(V) by closure of P(V) under inverses of lm-morphisms, Lemma 2.1. Therefore,
W(S) ⊆ P(V).

Since V is an sp-variety of monoids, this entails that M = S1 belongs to V, and therefore
ϕ ∈ EV. As this is true for any stable stamp ϕ such that W(ϕ) ⊆ P(V), we can conclude
that V is tame.

The notion of essentially-V stamps can be adapted to varieties of semigroups in a
straightforward way. We can then deﬁne a notion of tameness for varieties of semigroups
accordingly. The exact same proof as the one above then goes through to allow us to show
that p-varieties of the form V ∗ D are tame.

However there exist varieties of monoids that are tame but not sp-varieties. We give an

example of such a variety in Subsection 3.4.

Programs over monoids taken from tame varieties of monoids have the expected behavior

as we show next.

Let ϕ : Σ∗ → M be a stamp of stability index s. The stable stamp of ϕ is the unique
stamp ϕ′ : (Σs)∗ → M ′ such that ϕ′(u) = ϕ(u) for all u ∈ Σs and M ′ is the stable monoid of
ϕ. For any variety of monoids V we let QEV be the class of stamps whose stable stamp is
essentially-V and, accordingly, we deﬁne L(QEV) as the class of languages whose syntactic
morphism is in QEV.

Proposition 3.11. A variety of monoids V is tame if and only if P(V) ∩ Reg ⊆ L(QEV).

Proof. Let V be a variety of monoids.

Left-to-right implication. Assume ﬁrst that V is tame. For this direction, the proof
follows the same lines as those of Proposition 3.4.

Let L ∈ P(V)∩Reg over some alphabet Σ and let η : Σ∗ → M be the syntactic morphism
of L. For any m ∈ M , a classical algebraic argument [Pin86, Chapter 2, proof of Lemma
2.6] shows that η−1(m) is a Boolean combination of quotients of L, so η−1(m) ∈ P(V) by
Lemma 2.1.

Now let s be the stability index of η, let M ′ be its stable monoid and take η′ : (Σs)∗ → M ′
to be the stable stamp of η. The unique morphism f : (Σs)∗ → Σ∗ such that f (u) = u for all
u ∈ Σs is an lm-morphism and veriﬁes that η′ = η ◦ f . Hence, for all m′ ∈ M ′, we have that

14

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

η′−1(m′) = f −1(η−1(m′)), so that η′−1(m′) ∈ P(V) by closure of P(V) under inverses of
lm-morphisms, Lemma 2.1. Thus, since inverses of monoid morphisms commute with union
and P(V) is closed under unions (Lemma 2.1), we can conclude that η′−1(F ) ∈ P(V) for
all F ⊆ M ′, i.e. W(η′) ⊆ P(V).

But as η′ is stable, by tameness of V, this entails that η′ ∈ EV, so that L ∈ L(QEV).

Right-to-left implication. Assume now that P(V) ∩ Reg ⊆ L(QEV). Let ϕ : Σ∗ → M
be a stable stamp verifying W(ϕ) ⊆ P(V).

For any m ∈ M , we therefore have ϕ−1(m) ∈ L(QEV). Let ηm : Σ∗ → Mm be the
syntactic morphism of the language ϕ−1(m), we thus have ηm ∈ QEV. We ﬁrst claim
that ηm is a stable stamp. To see this notice ﬁrst that for all u, v ∈ Σ∗ we have ϕ(u) =
Indeed assume that ϕ(u) = ϕ(v), then for all x, y ∈ Σ∗ we
ϕ(v) ⇒ ηm(u) = ηm(v).
have ϕ(xuy) = ϕ(xvy) hence we have xuy ∈ ϕ−1(m) iﬀ xvy ∈ ϕ−1(m) which entails
ηm(u) = ηm(v) by deﬁnition of the syntactic morphism. It follows that ηm(Σ2) = ηm(Σ) as
ϕ(Σ2) = ϕ(Σ).

Since ηm is equal to its stable stamp and ηm ∈ QEV, it follows that ηm ∈ EV. Therefore

there exists a stamp µm : Σ∗ → Nm with Nm ∈ V such that for all u, v ∈ Σ∗, we have

µm(u) = µm(v) ⇒

ηm(xuy) = ηm(xvy) ∀x, y ∈ Σ
Now, we deﬁne the unique stamp µ : Σ∗ → N such that µ(a) =
(cid:0)
m∈M Nm generated by the set {

m∈M µm(a) for all
(cid:1)
m∈M µm(a) | a ∈ Σ}.
a ∈ Σ and N is the submonoid of
Q
As V is a variety, N ∈ V. Take u, v ∈ Σ∗ and assume µ(u) = µ(v): this means that µm(u) =
µm(v) for all m ∈ M . Let x, y ∈ Σ. We then have in particular µϕ(xuy)(u) = µϕ(xuy)(v).
This implies by deﬁnition of µϕ(xuy) that ηϕ(xuy)(xuy) = ηϕ(xuy)(xvy). As ηϕ(xuy) is the
syntactic morphism of ϕ−1(ϕ(xuy)), it follows that ϕ(xvy) = ϕ(xuy). And this is true for
any x, y ∈ Σ.

Q

Q

.

In conclusion, µ witnesses the fact that ϕ is essentially-V.

As for the case of sp-varieties of monoids, we don’t know whether it is always true that
for a tame non-trivial variety of monoids V, L(QEV) is included in P(V). If this were the
case then for tame non-trivial varieties of monoids V we would have P(V)∩Reg = L(QEV).
We conjecture this to be at least true for varieties of monoids that are local.

Conjecture 3.12. Let V be a local tame variety of monoids. Then P(V)∩Reg = L(QEV).

We conclude this subsection by showing that J, which is not an sp-variety of monoids

(Proposition 3.6), isn’t tame either.

Proposition 3.13. J is not tame.

Proof. To show this, we show that (a + b)∗ac+, which belongs to P(J) by the construction
of the introduction, does not belong to L(QEJ).

We ﬁrst claim that any essentially-J stamp ϕ : Σ∗ → M of stability index s veriﬁes
that there exists some k ∈ N>0 such that ϕ(x(uv)ky) = ϕ(x(uv)kuy) for all u, v ∈ Σ∗ and
x, y ∈ Σs. Indeed, by deﬁnition there exists a stamp µ : Σ∗ → N with N ∈ J such that for
all u, v ∈ Σ∗, we have

µ(u) = µ(v) ⇒

ϕ(xuy) = ϕ(xvy) ∀x, y ∈ Σs

.

If we set ω to be the idempotent power of N , we have that for all u, v ∈ Σ∗,
(cid:0)
µ(u)µ(v)

(cid:1)
(uv)ωu

µ(u) = µ

µ(u)µ(v)

(uv)ω

=

=

µ

ω

ω

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

15

by the identities for J. Hence, we have that ϕ(x(uv)ωy) = ϕ(x(uv)ω uy) for all u, v ∈ Σ∗
and x, y ∈ Σs.

Let us now consider the syntactic morphism η : {a, b, c}∗ → M of the language (a +
b)∗ac+. As already mentioned for Proposition 3.6, the stable monoid of η is equal to
the syntactic monoid M . Moreover, the stability index of η is 2. Therefore, the sta-
ble stamp of η is the unique stamp η′ : ({a, b, c}2)∗ → M such that η′(u) = η(u) for all
u ∈ {a, b, c}2. By what we have shown just above, since the stability index of η′ is 1, if η′
were essentially-J, there should exist some k ∈ N>0 such that η′(x(uv)ky) = η′(x(uv)kuy)
for all u, v ∈ ({a, b, c}2)∗ and x, y ∈ {a, b, c}2. However, for all k ∈ N>0, we do have that
(bb)(cc) /∈ (a + b)∗ac+, which implies
(aa)
that
(cid:0)

(cid:0)
6= η′
for all k ∈ N>0. Therefore, it follows that the stable stamp η′ of η is not essentially-J, so
(cid:0)
we can conclude that (a + b)∗ac+ /∈ L(QEJ).

(cc) ∈ (a + b)∗ac+ while (aa)

(cid:1)
(bb)(aa)

(bb)(aa)

(bb)(aa)

(bb)(aa)

(bb)(cc)

(aa)

(aa)

(cc)

η′

(cid:1)

(cid:0)

(cid:0)

(cid:1)

(cid:0)

(cid:1)

(cid:1)

(cid:1)

k

k

k

k

3.4. The example of ﬁnite commutative monoids. The variety Com of ﬁnite commu-
tative monoids is deﬁned by the identity xy = yx and L(Com) is the class of languages
that are Boolean combinations of languages of the form {w ∈ Σ∗ | |w|a ≡ k mod p} for
k ∈ [[0, p − 1]] and p prime or {w ∈ Σ∗ | |w|a = k} for k ∈ N with Σ any alphabet and a ∈ Σ
(see [Eil76, Chapter VIII, Example 3.5]).

Since the syntactic monoid of the language a(a + b)∗ is not commutative, by the discus-
sion at the end of Subsection 3.1, we know that Com is not an sp-variety of monoids. It is,
however, tame, as we are going to prove now.

We ﬁrst give a suﬃcient equational characterization for any stable stamp ϕ to be

essentially-Com.

Lemma 3.14. Let ϕ : Σ∗ → M be a stable stamp verifying that for any x, y, e, f ∈ Σ such
that ϕ(e) and ϕ(f ) are idempotents, we have

Then, ϕ ∈ ECom.

ϕ(exyf ) = ϕ(eyxf ) .

Proof. Let us deﬁne the equivalence relation ∼ on Σ∗ by u ∼ v for u, v ∈ Σ∗ whenever
ϕ(xuy) = ϕ(xvy) for all x, y ∈ Σ. This equivalence relation is actually a congruence,
because given u, v ∈ Σ∗ verifying u ∼ v, for all s, t ∈ Σ∗ we have sut ∼ svt since for any
x, y ∈ Σ, it holds that

ϕ(xsuty) = ϕ(x′uy′) = ϕ(x′vy′) = ϕ(xsvty)

where x′, y′ ∈ Σ verify ϕ(xs) = ϕ(x′) and ϕ(ty) = ϕ(y′).

We observe that, since the stability index of ϕ is equal to 1, ϕ veriﬁes that ϕ(euvf ) =
ϕ(evuf ) for all u, v ∈ Σ∗ and e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents. Now take
u, v ∈ Σ∗ and x, y ∈ Σ. Since ϕ(Σ) is a ﬁnite semigroup and veriﬁes that ϕ(Σ) = ϕ(Σ)2, by a
classical result in ﬁnite semigroup theory (see e.g. [Pin86, Chapter 1, Proposition 1.12]), we
have that there exist x1, e, x2, y1, f, y2 ∈ Σ such that ϕ(x1ex2) = ϕ(x) and ϕ(y1f y2) = ϕ(y)

16

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

with ϕ(e) and ϕ(f ) idempotents. Therefore, it follows that

ϕ(xuvy) = ϕ(x1ex2uvy1f y2)
= ϕ(x1euvy1x2f y2)
= ϕ(x1euvy1x2f f y2)
= ϕ(x1ey1x2f uvf y2)
= ϕ(x1ey1x2f vuf y2)
= ϕ(x1evuy1x2f f y2)
= ϕ(x1evuy1x2f y2)
= ϕ(x1ex2vuy1f y2)
= ϕ(xvuy) .

Thus, we have that uv ∼ vu for all u, v ∈ Σ∗, implying that Σ∗/∼∈ Com. We can eventually
conclude that the stamp µ : Σ∗ → Σ∗/∼ deﬁned by µ(w) = [w]∼ for all w ∈ Σ∗ witnesses,
by construction, the fact that ϕ is essentially-Com.

The following lemma then asserts that any stable stamp ϕ such that W(ϕ) ⊆ P(Com)
actually veriﬁes the equation of the previous lemma, which allows us to conclude that Com
is tame by combining those two lemmas.

Lemma 3.15. Let ϕ : Σ∗ → M be a stable stamp such that W(ϕ) ⊆ P(Com). Then, for
any x, y, e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents, we have

ϕ(exyf ) = ϕ(eyxf ) .

Proof. Let us ﬁrst observe that for any program P over some ﬁnite commutative monoid N
using the input alphabet Σ and of range n ∈ N, there exist a program P ′ over N using the
n
i=1(i, hi) verifying P (w) = P ′(w)
same input alphabet and of same range such that P ′ =
for all w ∈ Σn [Tes03, Example 3.4]. We call P ′ a single-scan program.

The assumption that W(ϕ) ⊆ P(Com) thus means that for all F ⊆ M , there exists a
sequence (PF,n)n∈N of single-scan programs over some NF ∈ Com that recognizes ϕ−1(F ).
For all x, y, e, f, g ∈ Σ such that ϕ(e), ϕ(f ) and ϕ(g) are idempotents, we claim that

Q

ϕ(exf yg) = ϕ(eyf xg)

ϕ(ef ef ) = ϕ(ef )

ϕ(exyf ) = ϕ(eyef xf ).

(3.1)

(3.2)

(3.3)

Assuming the claim, take x, y, e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents. Equa-
tion (3.2) implies that ϕ(ef ) is an idempotent. As ϕ(Σ2) = ϕ(Σ), we have that there exists
g ∈ Σ such that ϕ(ef ) = ϕ(g), hence

ϕ(exyf ) = ϕ(eyef xf ) = ϕ(eygxf ) = ϕ(exgyf ) = ϕ(exef yf ) = ϕ(eyxf ) ,

the ﬁrst and last equalities being from (3.3) and the middle one from (3.1).

Thus, the lemma will be proven once we will have proven that (3.1), (3.2) and (3.3) hold

for all x, y, e, f, g ∈ Σ such that ϕ(e), ϕ(f ) and ϕ(g) are idempotents.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

17

(3.1) holds. Let x, y, e, f, g ∈ Σ such that ϕ(e), ϕ(f ) and ϕ(g) are idempotents. Set F =
n
{ϕ(exf yg)} and n = 2(|NF |2 + 1) + 1 and assume PF,n =
i=1(i, hi). Then, since the
function

∆ : [[1, |NF |2 + 1]] → NF

2

Q

cannot be injective, there must exist j1, j2 ∈ [[1, |NF |2+1]], j1 < j2 such that h2j1(x) = h2j2(x)
and h2j1(y) = h2j2(y). So

PF,n(e2j1−1xf 2j2−1−2j1ygn−2j2) = PF,n(e2j1−1yf 2j2−1−2j1xgn−2j2) ,

j 7→ (h2j (x), h2j (y))

hence as e2j1−1xf 2j2−1−2j1ygn−2j2 ∈ ϕ−1(F ) because

ϕ(e2j1−1xf 2j2−1−2j1ygn−2j2) = ϕ(exf yg) ,
we must have e2j1−1yf 2j2−1−2j1xgn−2j2 ∈ ϕ−1(F ). Thus, we have

ϕ(e2j1−1yf 2j2−1−2j1xgn−2j2) = ϕ(eyf xg) = ϕ(exf yg) .

So for all x, y, e, f, g ∈ Σ such that ϕ(e), ϕ(f ) and ϕ(g) are idempotents, we have

that (3.1) holds.

(3.2) holds. Let e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents. We have that

ϕ(ef ef ) = ϕ(ef f ef ) = ϕ(eef f f ) = ϕ(ef ) ,

the middle equality being from (3.1).

So for all e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents, we have that (3.2) holds.

(3.3) holds. Let x, y, e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents. Set F = {ϕ(exyf )}
n
and n = 4(2 |NF |4 + 1) and assume PF,n =
i=1(i, hi). Then, we have that the function
4

∆ : [[1, 2 |NF |4 + 1]] → NF

Q

veriﬁes that there exists (m1, m2, m3, m4) ∈ NF

j 7→ (h4j−2(x), h4j−2(f ), h4j−1(y), h4j−1(e))
4 such that

∆−1((m1, m2, m3, m4))

≥ 3 .

Therefore, there exist j1, j2, j3 ∈ [[1, 2 |NF |4 + 1]], j1 < j2 < j3 such that h4j3−2(x) =
h4j2−2(x), h4j3−2(f ) = h4j2−2(f ), h4j2−1(y) = h4j1−1(y) and h4j2−1(e) = h4j1−1(e). So

(cid:12)
(cid:12)

(cid:12)
(cid:12)

PF,n(e4j2−3xyf n−4j2+1) = PF,n(e4j1−2ye4(j2−j1)−2f ef 4(j3−j2)−2xf n−4j3+2) ,

hence as e4j2−3xyf n−4j2+1 ∈ ϕ−1(F ) because

ϕ(e4j2−3xyf n−4j2+1) = ϕ(exyf ) ,

we must have e4j1−2ye4(j2−j1)−2f ef 4(j3−j2)−2xf n−4j3+2 ∈ ϕ−1(F ). Thus, we have

ϕ(exyf ) = ϕ(e4j1−2ye4(j2−j1)−2f ef 4(j3−j2)−2xf n−4j3+2)

= ϕ(eyef ef xf )

= ϕ(eyef xf )

where the last equality uses (3.2).

So for all x, y, e, f ∈ Σ such that ϕ(e) and ϕ(f ) are idempotents, we have that (3.3)

holds.

18

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

4. The case of DA

In this section, we prove that DA is an sp-variety of monoids, which implies that it is
tame. Combined with the fact that DA is local [Alm96], we obtain the following result by
Proposition 3.5.

Theorem 4.1. P(DA) ∩ Reg = L(QDA).

The result follows from the following main technical contribution:

Proposition 4.2. (c + ab)∗, (b + ab)∗ and b∗((ab∗)k)∗ for any integer k ≥ 2 are regular
languages not in P(DA).

Observe that for any k ∈ N, k ≥ 2, the fact that b∗((ab∗)k)∗ /∈ P(DA) is an immediate
corollary of the classical result that MODk /∈ AC0 = P(A) [FSS84, Ajt83]. However, we
propose a direct semigroup-theoretic proof of the ﬁrst result without resorting to the involved
proof techniques of the latter result.

Before proving the proposition we ﬁrst show that it implies that DA is an sp-variety
of monoids. This implication is a consequence of the following lemma, which is a result
inspired by an observation in [TT02b] stating that non-membership of a given ﬁnite monoid
M in DA implies non-aperiodicity of M or division of it by (at least) one of two speciﬁc
ﬁnite monoids.
Lemma 4.3. Let S be a ﬁnite semigroup such that S1 /∈ DA. Then, one of (c + ab)∗,
(b + ab)∗ or b∗((ab∗)k)∗ for some k ∈ N, k ≥ 2 is recognized by a morphism µ : Σ∗ → S1, for
Σ the appropriate alphabet, such that µ(Σ+) ⊆ S.

Proof. We distinguish two cases: the aperiodic and the non-aperiodic one.

Aperiodic case. Assume ﬁrst that S1 is aperiodic. Then, since S1 /∈ DA, by Lemma 3.2.4
in [Tes98], we have that S1 is divided by the syntactic monoid of (c∗ac∗bc∗)∗, denoted by
∗, denoted by U . We treat
B2, or by the syntactic monoid of
those two not necessarily distinct subcases separately.

(b + c)∗a(b + c)∗b(b + c)∗

(cid:0)

(cid:1)

Subcase B2 divides S1. It is easily proven that (c + ab)∗ is recognized by B2 (actually, its
syntactic monoid is isomorphic to B2): just consider the syntactic morphism η : {a, b, c}∗ →
B2 of (c∗ac∗bc∗)∗ and build the morphism ϕ : {a, b, c}∗ → B2 sending a to η(a), b to η(b)
and c to η(ab).

By a classical result in algebraic automata theory [Pin86, Chapter 1, Proposition 2.7],
this implies that S1 recognizes (c + ab)∗. Thus there exists a morphism µ : {a, b, c}∗ → S1
recognizing (c + ab)∗, that has the property that µ({a, b, c}+) ⊆ S, otherwise there would
exist w ∈ {a, b, c}+ such that either w /∈ (c + ab)∗ while µ(ε) = µ(w) or w ∈ (c + ab)+ while
µ(ab) = µ(awb).

Subcase U divides S1. The proof goes the same way as for the ﬁrst subcase.

It is again easily proven that (b + ab)∗ is recognized by U : here we consider the syntactic
∗ and build the morphism ϕ : {a, b}∗ →

(b+c)∗a(b+c)∗b(b+c)∗

morphism η : {a, b}∗ → U of
U sending a to η(a) and b to η(b).

Thus there exists a morphism µ : {a, b}∗ → S1 recognizing (b + ab)∗, that also veriﬁes
µ({a, b}+) ⊆ S, otherwise there would exist w ∈ {a, b}+ such that w /∈ (b + ab)∗ while
µ(ε) = µ(w) or w ∈ b(b + ab)∗ while µ(a) = µ(aw) or w ∈ ab(b + ab)∗ while µ(ab) = µ(awb).

(cid:0)

(cid:1)

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

19

Non-aperiodic case. Assume now that S1 is not aperiodic. Then there is an x in S
such that xω 6= xω+1 for ω ∈ N>0 the idempotent power of S1. Consider the morphism
µ : {a, b}∗ → S1 sending a to xω+1 and b to xω, and the language L = µ−1(xω). Let
k ∈ N, k ≥ 2 be the smallest positive integer such that xω+k = xω, that cannot be 1 because
xω 6= xω+1. Using this, for all w ∈ {a, b}∗, we have

µ(w) = x|w|·ω+|w|a = xω+(|w|a mod k) ,

where |w| indicates the length of w and |w|a the number of a’s it contains, so that w belongs
to L if and only if |w|a = 0 mod k. Hence, L is the language of all words with a number
of a’s divisible by k, b∗((ab∗)k)∗.
In conclusion, b∗((ab∗)k)∗ is recognized by µ verifying
µ({a, b}+) ⊆ S.

Let now S be any ﬁnite semigroup such that W(S) ⊆ P(DA). Let ηS : S∗ → S1 be the
evaluation morphism of S. To show that S1 is in DA, we assume for the sake of contradiction
that it is not the case. Then Lemma 4.3 tells us that one of (c + ab)∗, (b + ab)∗ or b∗((ab∗)k)∗
for some k ∈ N, k ≥ 2 is recognized by a morphism µ : Σ∗ → S1, for Σ the appropriate
alphabet, such that µ(Σ+) ⊆ S.

In all cases, we thus have a language L ⊆ Σ∗ equal to µ−1(Q) for some subset Q of S1
with the morphism µ sending letters of Σ to elements of S. Consider then the morphism
ϕ : Σ∗ → S∗ sending each letter a ∈ Σ to µ(a), a letter of S: we have µ = ηS ◦ ϕ, so that
L = ϕ−1(η−1
S (Q) ∈ P(DA), hence since ϕ is
an lm-morphism and P(DA) is closed under inverses of lm-morphisms by Lemma 2.1, we
have L = ϕ−1(η−1

S (Q)). As W(S) ⊆ P(DA), we have that η−1

S (Q)) ∈ P(DA): a contradiction to Proposition 4.2.

In the remaining part of this section we prove Proposition 4.2.

Proof of Proposition 4.2. The idea of the proof is the following. We work by contradiction
and assume that we have a sequence of programs over some monoid M of DA deciding
one of the targeted language L. Let n be much larger than the size of M , and let Pn be
the program running on words of length n. Consider a set ∆ of words such that L ⊆ ∆∗
(for instance take ∆ = {c, ab} for L = (c + ab)∗). We will show that we can ﬁx a constant
(depending on M and ∆ but not on n) number of entries to Pn such that Pn always outputs
the same value and there are completions of the entries in ∆∗. Hence, if ∆ was chosen
so that there is actually a completion of the ﬁxed entries in L and one outside of L, Pn
cannot recognize the restriction of L to words of length n. We cannot prove this for all ∆, in
particular it will not work for ∆ = {ab} and indeed (ab)∗ is in P(DA). The key property of
our ∆ is that after ﬁxing any letter at any position, except maybe for a constant number of
positions, one can still complete the word into one within ∆∗. This is not true for ∆ = {ab}
because after ﬁxing a b in an odd position all completions fall outside of (ab)∗.

We now spell out the technical details.
Let ∆ be a ﬁnite non-empty set of non-empty words over an alphabet Σ. Let ⊥ be a
letter not in Σ. A mask is a word over Σ ∪ {⊥}. The positions of a mask carrying a ⊥ are
called free while the positions carrying a letter in Σ are called ﬁxed. A mask λ′ is a submask
of a mask λ if it is formed from λ by replacing some occurrences (possibly zero) of ⊥ by a
letter in Σ.

A completion of a mask λ is a word w over Σ that is built from λ by replacing all
occurrences of ⊥ by a letter in Σ. Notice that all completions of a mask have the same
length as the mask itself. A mask λ is ∆-compatible if it has a completion in ∆∗.

20

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

The dangerous positions of a mask λ are the positions within distance 2l − 2 of the ﬁxed
positions or within distance l − 1 of the beginning or the end of the mask, where l is the
maximal length of a word in ∆. A position that is not dangerous is said to be safe and is
necessarily free.

We say that ∆ is safe if the following holds. Let λ be a ∆-compatible mask. Let i be
any free position of λ that is not dangerous. Let a be any letter in Σ. Then the submask of
λ constructed by ﬁxing a at position i is ∆-compatible. We have already seen that ∆ = {ab}
is not safe. However our targeted ∆, ∆ = {c, ab}, ∆ = {b, ab}, ∆ = {a, b}, are safe. We
always consider ∆ to be safe in the following.

Note that it is important in the deﬁnition of safe for ∆ that we ﬁx only safe positions, i.e.
positions far apart and far from the beginning and the end of the mask. Indeed, depending
on the chosen ∆, there might be words that never appear as factors in any word of ∆∗, such
as bb when ∆ = {c, ab} or aa when ∆ = {b, ab}, so that ﬁxing a position near an already
ﬁxed position to an arbitrary letter in a ∆-compatible mask may result in a mask that has
no completion in ∆∗. This is why we make sure that safe positions are far from those already
ﬁxed and from the beginning and the end of the mask, where far depends on the length of
the words of ∆.

Finally, we say that a completion w of a mask λ is safe if w is a completion of λ
belonging to ∆∗ or is constructed from a completion of λ in ∆∗ by modifying only letters at
safe positions of λ, the dangerous positions remaining unchanged.

Let M be a monoid in DA whose identity we will denote by 1.
We deﬁne a version of Green’s relations for decomposing monoids that will be used, as
often in this setting, to prove the main technical lemma in the current proof. Given two
elements u, u′ of M we say that u ≤J u′ if there are elements v, v′ of M such that u′ = vuv′.
We write u ∼J u′ if u ≤J u′ and u′ ≤J u. We write u <J u′ if u ≤J u′ and u′ 6∼J u. Given
two elements u, u′ of M we say that u ≤R u′ if there is an element v of M such that u′ = uv.
We write u ∼R u′ if u ≤R u′ and u′ ≤R u. We write u <R u′ if u ≤R u′ and u′ 6∼R u. Given
two elements u, u′ of M we say that u ≤L u′ if there is an element v of M such that u′ = vu.
We write u ∼L u′ if u ≤L u′ and u′ ≤L u. We write u <L u′ if u ≤L u′ and u′ 6∼L u. Finally,
given two elements u, u′ of M , we write u ∼H u′ if u ∼R u′ and u ∼L u′.

We shall use the following well-known fact about these preorders and equivalence rela-

tions (see [Pin86, Chapter 3, Proposition 1.4]).

Lemma 4.4. For all elements u and v of M , if u ≤R v and u ∼J v, then u ∼R v. Similarly,
if u ≤L v and u ∼J v, then u ∼L v.

From the deﬁnition it follows that for all elements u, v, r of M , we have u ≤R ur and
v ≤L rv. When the inequality is strict in the ﬁrst case, i.e. u <R ur, we say that r is R-bad
for u. Similarly r is L-bad for v if v <L rv. It follows from M ∈ DA that being R-bad or
L-bad only depends on the ∼R or ∼L class, respectively. This is formalized in the following
lemma, that is folklore and used at least implicitly in many proofs involving DA (see for
instance [TT02b, proof of Theorem 3]). Since we didn’t manage to ﬁnd the lemma stated
and proven in the form below, we include a proof for completeness.

Lemma 4.5. If M is in DA, then u ∼R u′ and ur ∼R u implies u′r ∼R u. Similarly
u ∼L u′ and ru ∼L u implies ru′ ∼L u.
Proof. Let u, u′, r ∈ M such that u ∼R u′ and ur ∼R u. This means that there exist
v, v′, s ∈ M such that u = u′v′, u′ = uv and urs = u.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

21

This implies that

u′ = uv = ursv = u′v′rsv = u′(v′rsv)2 = · · · = u′(v′rsv)ω

where ω is the idempotent power of M . Hence, we have that

u′r(v′rsv)ωv′ = u′(v′rsv)ωr(v′rsv)ωv′ .
But, by [TT02b, Theorem 2], since M ∈ DA, we have that (xyz)ωy(xyz)ω = (xyz)ω for all
x, y, z ∈ M , so that

u′r(v′rsv)ωv′ = u′(v′rsv)ωv′ = u′v′ = u .
Therefore, we have u′r ≤R u and since uvr = u′r, we also have u ≤R u′r, so that u′r ∼R u
as claimed.

The proof goes through symmetrically for ∼L.

Let ∆ be a ﬁnite set of words and Σ be the corresponding alphabet, ∆ being safe, and
let n ∈ N. We are now going to prove the main technical lemma that allows us to assert that
after ﬁxing a constant number of positions in the input of a program over M , it can still
be completed into a word of ∆∗, but the program cannot make the diﬀerence between any
two possible completions anymore. To prove the lemma, we deﬁne a relation ≺ on the set
of quadruplets (λ, P, u, v) where λ is a mask of length n, P is a program over M for words
of length n and u and v are two elements of M . We will say that an element (λ1, P1, u1, v1)
is strictly smaller than (λ2, P2, u2, v2), written (λ1, P1, u1, v1) ≺ (λ2, P2, u2, v2), if and only
if λ1 is a submask of λ2, P1 is a subprogram of P2 and one of the following cases occurs:
(1) u2 <R u1 and v1 = v2 and P1 is a suﬃx of P2 and u1P1(w)v1 = u2P2(w)v2 for all safe

completions w of λ1;

(2) v2 <L v1 and u1 = u2 and P1 is a preﬁx of P2 and u1P1(w)v1 = u2P2(w)v2 for all safe

completions w of λ1;

(3) u2 = u1 and v1 = 1 and P1 is a preﬁx of P2 and u1P1(w)v1 <J u2P2(w)v2 for all safe

completions w of λ1;

(4) v2 = v1 and u1 = 1 and P1 is a suﬃx of P2 and u1P1(w)v1 <J u2P2(w)v2 for all safe

completions w of λ1.

Note that, since M is ﬁnite, this relation is well-founded (that is, it has no inﬁnite decreasing
chain, an inﬁnite sequence of quadruplets µ0, µ1, µ2, . . . such that µi+1 ≺ µi for all i ∈ N)
and the maximal length of any decreasing chain can be upper bounded by 2 · |M |2, that
does only depend on M . For a given quadruplet µ, we shall also call its height the biggest
i ∈ N such that there exists a decreasing chain µi ≺ µi−1 ≺ · · · ≺ µ0 = µ.

The following lemma is the key to the proof. It shows that modulo ﬁxing a few entries,
one can ﬁx the output: to count the number of ﬁxed positions for a given mask λ, we denote
by |λ|Σ the number of letters in λ belonging to Σ, that is to say, the number of ﬁxed positions
in λ.

Lemma 4.6. Let λ be a ∆-compatible mask of length n, let P be a program over M of range
n, let u and v be elements of M such that (λ, P, u, v) is of height h. Then there is an element
t of M and a ∆-compatible submask λ′ of λ verifying |λ′|Σ ≤ (2h6l)2h
· max{|λ|Σ , 1} such
that any safe completion w of λ′ veriﬁes uP (w)v = t.

Proof. The proof goes by induction on the height h.

Let λ be a ∆-compatible mask of length n, let P be a program over M for words of
length n, let u and v be elements of M such that (λ, P, u, v) is of height h, and assume

22

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

that for any quadruplet (λ′, P ′, u′, v′) strictly smaller than (λ, P, u, v), the lemma is veriﬁed.
Consider the following conditions concerning the quadruplet (λ, P, u, v):

(a) there does not exist any instruction (x, f ) of P such that for some letter a the submask
λ′ of λ formed by setting position x to a is ∆-compatible and f (a) is R-bad for u;

(b) v is not R-bad for u;
(c) there does not exist any instruction (x, f ) of P such that for some letter a the submask
λ′ of λ formed by setting position x to a is ∆-compatible and f (a) is L-bad for v;

(d) u is not L-bad for v.

We will now do a case analysis based on which of these conditions are violated or not.

Case 1: condition (a) is violated. So there exists some instruction (x, f ) of P such that for some
letter a the submask λ′ of λ formed by setting position x to a (if it wasn’t already the
case) is ∆-compatible and f (a) is R-bad for u. Let i be the smallest number of such an
instruction.

Let P ′ be the subprogram of P until, and including, instruction i − 1. Let w be a safe
completion of λ. For any instruction (y, g) of P ′, as y < i, g(wy) cannot be R-bad for u,
so u ∼R ug(wy). Hence, by Lemma 4.5, u ∼R uP ′(w) for all safe completions w of λ.

So, because f (a) is R-bad for u, any safe completion w of λ′, which is also a safe
completion of λ, is such that u ∼R uP ′(w) <R uP ′(w)f (a) ≤R uP (w)v by Lemma 4.5,
hence uP ′(w) <J uP (w)v by Lemma 4.4. So (λ′, P ′, u, 1) ≺ (λ, P, u, v), therefore, by
induction we get a ∆-compatible submask λ1 of λ′ and a monoid element t1 such that
uP ′(w) = t1 for all safe completions w of λ1.

Let P ′′ be the subprogram of P starting from instruction i+1. Notice that, since u ∼R t1
(by what we have proven just above), u <R t1f (a) (by Lemma 4.5) and t1f (a)P ′′(w)v =
uP ′(w)f (a)P ′′(w)v = uP (w)v for all safe completions w of λ1. Hence, (λ1, P ′′, t1f (a), v)
is strictly smaller than (λ, P, u, v) and by induction we get a ∆-compatible submask λ2 of
λ1 and a monoid element t such that t1f (a)P ′′(w)v = t for all safe completions w of λ2.

Thus, any safe completion w of λ2 is such that

uP (w)v = uP ′(w)f (a)P ′′(w)v = t1f (a)P ′′(w)v = t .

Therefore λ2 and t form the desired couple of a ∆-compatible submask of λ and an element
of M . We still have to show that |λ2|Σ satisﬁes the desired upper bound.

By induction, since (λ′, P ′, u, 1) is of height h′ ≤ h − 1, we have

Consequently, by induction again, as (λ1, P ′′, t1f (a), v) is of height h′′ ≤ h − 1, we have

(cid:12)
(cid:12)

(cid:12)
(cid:12)

|λ1|Σ ≤ (2h′

′

6l)2h

·

λ′

Σ ≤ (2h−16l)2h−1

·

λ′

Σ .
(cid:12)
(cid:12)

(cid:12)
(cid:12)

|λ2|Σ ≤ (2h′′

′′

6l)2h

· |λ1|Σ

≤ (2h−16l)2h−1
≤ (2h−16l)2h−1
= (2h−16l)2h

·

(cid:12)
(cid:12)

· |λ1|Σ
· (2h−16l)2h−1
λ′

Σ .
(cid:12)
(cid:12)

·

λ′

Σ

(cid:12)
(cid:12)

(cid:12)
(cid:12)

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

23

Moreover, it holds that |λ′|Σ ≤ |λ|Σ + 1, so that

|λ2|Σ ≤ (2h−16l)2h
≤ (2h−16l)2h
= (2h6l)2h

· (|λ|Σ + 1)
· 22h

· max{|λ|Σ , 1}

· max{|λ|Σ , 1} .

Case 2: condition (a) is veriﬁed but condition (b) is violated, so v is R-bad for u and Case 1 does

not apply.

Let w be a safe completion of λ: for any instruction (x, f ) of P , as the submask λ′ of
λ formed by setting position x to wx is ∆-compatible (by the fact that ∆ is safe and w is
a safe completion of λ), f (wx) cannot be R-bad for u, otherwise condition (a) would be
violated, so u ∼R uf (wx). Hence, by Lemma 4.5, u ∼R uP (w) for all safe completions w of
λ. Notice then that u ∼R uP (w) <R uP (w)v (by Lemma 4.5), hence uP (w) <J uP (w)v
(by Lemma 4.4) for all safe completions w of λ. So (λ, P, u, 1) ≺ (λ, P, u, v), therefore we
obtain by induction a monoid element t1 and a ∆-compatible submask λ′ of λ such that
uP (w) = t1 for all completions w of λ′. If we set t = t1v, we get that any safe completion
w of λ′ is such that uP (w)v = t1v = t. Therefore λ′ and t form the desired couple of a
∆-compatible submask of λ and an element of M .

Moreover, by induction, since (λ, P, u, 1) is of height h′ ≤ h − 1, we have

λ′

Σ ≤ (2h′
(cid:12)
(cid:12)

(cid:12)
(cid:12)

the desired upper bound.

′

6l)2h

· max{|λ|Σ , 1} ≤ (2h6l)2h

· max{|λ|Σ , 1} ,

Case 3: condition (c) is violated. So there exists some instruction (x, f ) of P such that for some
letter a the submask λ′ of λ formed by setting position x to a (if it wasn’t already the
case) is ∆-compatible and f (a) is L-bad for v.
We proceed as for Case 1 by symmetry.

Case 4: condition (c) is veriﬁed but condition (d) is violated, so u is L-bad for v and Case 3 does

not apply.

We proceed as for Case 2 by symmetry.
Case 5: conditions (a), (b), (c) and (d) are veriﬁed.

As it was in Case 2 and Case 4, using Lemma 4.5, the fact that condition (a) and
condition (c) are veriﬁed implies that u ∼R uP ′(w) and v ∼L P ′′(w)v for any preﬁx P ′ of
P , any suﬃx P ′′ of P and all safe completions w of λ. Moreover, since condition (b) and
condition (d) are veriﬁed, by Lemma 4.5, we get that uP (w)v ∼R u and uP (w)v ∼L v for
all safe completions w of λ. This implies that (λ, P, u, v) is minimal for ≺ and that h = 0.
Let w0 be a completion of λ that is in ∆∗. Let λ′ be the submask of λ ﬁxing all free
dangerous positions of λ using w0 and let t = uP (w0)v. Then, for any completion w of
λ′, which is a safe completion of λ by construction, we have that uP (w)v ∼R u ∼R t
and uP (w)v ∼L v ∼L t. Thus, uP (w)v ∼H t for any completion w of λ′. As M is
aperiodic, this implies that uP (w)v = t for all completions w of λ′ (see [Pin86, Chapter 3,
Proposition 4.2]). Therefore λ′ and t form the desired couple of a ∆-compatible submask
of λ and an element of M .

Now, since the number of free positions of λ ﬁxed in λ′, i.e. |λ′|Σ − |λ|Σ, is exactly the
number of free dangerous positions in λ, and as a position in λ is dangerous if it is within
distance 2l − 2 of a ﬁxed position or within distance l − 1 of the beginning or the end of

24

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

λ, we have
λ′

Σ ≤ 2 · |λ|Σ · (2l − 2) + 2 · (l − 1) + |λ|Σ = |λ|Σ · (4l − 3) + 2l − 2

(cid:12)
(cid:12)
the desired upper bound.

(cid:12)
(cid:12)

This concludes the proof of the lemma.

≤ (206l)20

· max{|λ|Σ , 1} ,

Setting ∆ = {c, ab} or ∆ = {b, ab} with Σ the associated alphabet, when applying
Lemma 4.6 with the trivial ∆-compatible mask λ of length n containing only free positions,
with P some program over M of range n and with u and v equal to 1, the resulting mask λ′
has the property that we have an element t of M such that P (w) = t for any safe completion
w of λ′. Since the mask λ′ is ∆-compatible and has a number of ﬁxed positions upper-
bounded by (2h6l)2h
where h is the height of (λ, P, u, v), itself upper-bounded by 2 · |M |2, as
long as n is big enough, we have a safe completion w0 ∈ ∆∗ and a safe completion w1 /∈ ∆∗.
Hence, P cannot be part of any sequence of programs p-recognizing ∆∗. This implies that
(c + ab)∗ /∈ P(M ) and (b + ab)∗ /∈ P(M ). Finally, for any k ∈ N, k ≥ 2, we can prove that
b∗((ab∗)k)∗ /∈ P(M ) by setting ∆ = {a, b} and completing the mask given by the lemma by
setting the letters in such a way that we have the right number of a modulo k in one case
and not in the other case.

This concludes the proof of Proposition 4.2 because the argument above holds for any

monoid in DA.

5. A fine hierarchy in P(DA)

The deﬁnition of p-recognition by a sequence of programs over a monoid given in Section 2
requires that for each n, the program reading the entries of length n has a length polynomial
in n. In the case of P(DA), the polynomial-length restriction is superﬂuous: any program
over a monoid in DA is equivalent to one of polynomial length over the same monoid [TT02a]
(in the sense that they recognize the same languages). In this section, we show that this
does not collapse further: in the case of DA, programs of length O(nk+1) express strictly
more than those of length O(nk).

Following [GT03], we use an alternative deﬁnition of the languages recognized by a
monoid in DA. We deﬁne by induction a hierarchy of classes of languages SUMk, where
SUM stands for strongly unambiguous monomial. A language L is in SUM0 if it is of the
form A∗ for some alphabet A. A language L is in SUMk for k ∈ N>0 if it is in SUMk−1
or L = L1aL2 for some languages L1 ∈ SUMi and L2 ∈ SUMj and some letter a with
i + j = k − 1 such that no word of L1 contains the letter a or no word of L2 contains the
letter a.

Gavaldà and Thérien stated without proof that a language L is recognized by a monoid in
DA iﬀ there is a k ∈ N such that L is a Boolean combination of languages in SUMk [GT03]
(see [Gro18, Theorem 4.1.9] for a proof). For each k ∈ N, we denote by DAk the variety
of monoids generated by the syntactic monoids of the Boolean combinations of languages
in SUMk. It can be checked that, for each k, DAk forms a variety of monoids recognizing
precisely Boolean combinations of languages in SUMk: this is what we do in the ﬁrst
subsection.

In the two following subsections, we then give a ﬁne program-length-based hierarchy

within P(DA) for this parametrization of DA.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

25

5.1. A parametrization of DA. For each k ∈ N, we denote by SU Lk the class of regular
languages that are Boolean combinations of languages in SUMk; it is a variety of languages
as shown just below. But as DAk is the variety of monoids generated by the syntactic
monoids of the languages in SU Lk, by Eilenberg’s theorem, we know that, conversely, all
the regular languages whose syntactic monoids lie in DAk are in SU Lk.

Back to the fact that SU Lk is a variety of languages for any k ∈ N. Closure under
Boolean operations is obvious by construction. Closure under quotients and inverses of
morphisms is respectively given by the following two lemmas and by the fact that both
quotients and inverses of morphisms commute with Boolean operations.

Given a word u over a given alphabet Σ, we will denote by alph(u) the set of letters of

Σ that appear in u.

Lemma 5.1. For all k ∈ N, for all L ∈ SUMk over an alphabet Σ and u ∈ Σ∗, u−1L and
Lu−1 both are unions of languages in SUMk over Σ.

Proof. We prove it by induction on k.

Base case: k = 0. Let L ∈ SUM0 over an alphabet Σ and u ∈ Σ∗. This means that L = A∗
for some A ⊆ Σ. We have two cases: either alph(u) * A and then u−1L = Lu−1 = ∅; or
alph(u) ⊆ A and then u−1L = Lu−1 = A∗ = L. So u−1L and Lu−1 both are unions of
languages in SUM0 over Σ. The base case is hence proved.

Inductive step. Let k ∈ N>0 and assume that the lemma is true for all k′ ∈ N, k′ < k.

Let L ∈ SUMk over an alphabet Σ and u ∈ Σ∗. This means that either L is in
SUMk−1 and the lemma is proved by applying the inductive hypothesis directly for L and
u, or L = L1aL2 for some languages L1 ∈ SUMi and L2 ∈ SUMj and some letter a ∈ Σ
with i + j = k − 1 and, either no word of L1 contains the letter a or no word of L2 contains
the letter a. We shall only treat the case in which a does not appear in any of the words of
L1; the other case is treated symmetrically.

There are again two cases to consider, depending on whether a does appear in u or not.
If a /∈ alph(u), then it is straightforward to check that u−1L = (u−1L1)aL2 and Lu−1 =
L1a(L2u−1). By the inductive hypothesis, we get that u−1L1 is a union of languages in
SUMi over Σ and that L2u−1 is a union of languages in SUMj over Σ. Moreover, it is
direct to see that no word of u−1L1 contains the letter a. By distributivity of concatenation
over union, we ﬁnally get that u−1L and Lu−1 both are unions of languages in SUMk over
Σ.

If a ∈ alph(u), then let u = u1au2 with u1, u2 ∈ Σ∗ and a /∈ alph(u1).

It is again

straightforward to see that

u−1L =

−1L2

u2
∅
(

if u1 ∈ L1
otherwise

and

Lu−1 = L1a(L2u−1) ∪

if u2 ∈ L2
otherwise
−1 is a union of languages in SUMi
As before, by the inductive hypothesis, we get that L1u1
−1L2 and L2u−1 are unions of languages in SUMj over Σ. And,
over Σ and that both u2
again, by distributivity of concatenation over union, we get that u−1L and Lu−1 both are a
union of languages in SUMk over Σ.

L1u1
∅
(

.

−1

26

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

This concludes the inductive step and therefore the proof of the lemma.

Lemma 5.2. For all k ∈ N, for all L ∈ SUMk over an alphabet Σ and ϕ : Γ∗ → Σ∗ a
morphism where Γ is another alphabet, ϕ−1(L) is a union of languages in SUMk over Γ.

Proof. We prove it by induction on k.

Base case: k = 0. Let L ∈ SUM0 over an alphabet Σ and ϕ : Γ∗ → Σ∗ a morphism where
Γ is another alphabet. This means that L = A∗ for some A ⊆ Σ. It is straightforward
to check that ϕ−1(L) = B∗ where B = {b ∈ Γ | ϕ(b) ∈ A∗}. B∗ is certainly a union of
languages in SUM0 over Σ. The base case is hence proved.

Inductive step. Let k ∈ N>0 and assume that the lemma is true for all k′ ∈ N, k′ < k.

Let L ∈ SUMk over an alphabet Σ and ϕ : Γ∗ → Σ∗ a morphism where Γ is another
alphabet. This means that either L is in SUMk−1 and the lemma is proved by applying the
inductive hypothesis directly for L and ϕ, or L = L1aL2 for some languages L1 ∈ SUMi
and L2 ∈ SUMj and some letter a ∈ Σ with i + j = k − 1 and, either no word of L1 contains
the letter a or no word of L2 contains the letter a. We shall only treat the case in which a
does not appear in any of the words of L1; the other case is treated symmetrically.

Let us deﬁne B = {b ∈ Γ | a ∈ alph(ϕ(b))} as the set of letters of Γ whose image
word by ϕ contains the letter a. For each b ∈ B, we shall also let ϕ(b) = ub,1aub,2 with
ub,1, ub,2 ∈ Σ∗ and a /∈ alph(ub,1). It is not too diﬃcult to see that we then have

ϕ−1(L) =

ϕ−1(L1ub,1

−1)bϕ−1(ub,2

−1L2) .

[b∈B

By the inductive hypothesis, by Lemma 5.1 and by the fact that inverses of morphisms
commute with unions, we get that ϕ−1(L1ub,1
−1) is a union of languages in SUMi over Γ
−1L2) is a union of languages in SUMj over Γ. Moreover, it is direct to
and that ϕ−1(ub,2
−1) contains the letter b for all b ∈ B. By distributivity of
see that no word of ϕ−1(L1ub,1
concatenation over union, we ﬁnally get that ϕ−1(L) is a union of languages in SUMk over
Γ.

This concludes the inductive step and therefore the proof of the lemma.

5.2. Strict hierarchy. For each k we show there exists a language Lk ⊆ {0, 1}∗ that can
be recognized by a sequence of programs of length O(nk) over a monoid Mk in DAk but
cannot be recognized by any sequence of programs of length O(nk−1) over any monoid in
DA.

For a given k ∈ N>0, the language Lk expresses a property of the ﬁrst k occurrences
of 1 in the input word. To deﬁne Lk we say that S is a k-set over n for some n ∈ N if
S is a set where each element is an ordered tuple of k distinct elements of [n]. For any
sequence ∆ = (Sn)n∈N of k-sets over n, we set L∆ =
n∈N Kn,Sn, where for each n ∈ N,
Kn,Sn is the set of words over {0, 1} of length n such that for each of them, it contains at
least k occurrences of 1 and the ordered k-tuple of the positions of the ﬁrst k occurrences
of 1 belongs to Sn.

S

On the one hand, we show that for all k there is a monoid Mk in DAk such that for all
∆ the language L∆ is recognized by a sequence of programs over Mk of length O(nk). The
proof is done by an inductive argument on k.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

27

On the other hand, we show that for all k there is a ∆ such that for any ﬁnite monoid M
and any sequence of programs (Pn)n∈N over M of length O(nk−1), L∆ is not recognized by
(Pn)n∈N. This is done using a counting argument: for some monoid size i, for n big enough,
the number of languages in {0, 1}n recognized by a program over some monoid of size i of
length at most α · nk−1 for α some constant is upper-bounded by a number that turns out
to be asymptotically smaller than the number of diﬀerent possible Kn,Sn.

Upper bound. We start with the upper bound. Notice that for some k ∈ N>0 and ∆ =
(Sn)n∈N, the language of words of length n of L∆ is exactly Kn,Sn. Hence the fact that L∆
can be recognized by a sequence of programs over a monoid in DAk of length O(nk) is a
consequence of the following proposition.

Proposition 5.3. For all k ∈ N>0 there is a monoid Mk ∈ DAk such that for all n ∈ N
and all k-sets Sn over n, the language Kn,Sn is recognized by a program over Mk of length
at most 4nk.

Proof. We ﬁrst deﬁne by induction on k a family of languages Zk over the alphabet Yk =
{⊥l, ⊤l | 1 ≤ l ≤ k}. For k = 0, Z0 is {ε}. For k > 0, Zk is the set of words containing ⊤k
and such that the ﬁrst occurrence of ⊤k has no ⊥k to its left, and the sequence between the
ﬁrst occurrence of ⊤k and the ﬁrst occurrence of ⊥k or ⊤k to its right, or the end of the
word if there is no such letter, belongs to Zk−1. A simple induction on k shows that Zk is
deﬁned by the following expression

k−1⊤kY ∗
Y ∗
and therefore it is in SUMk and its syntactic monoid Mk is in DAk.

k−2⊤k−1 · · · Y ∗

1 ⊤2⊤1Y ∗
k

Fix n. If n = 0, the proposition follows trivially, otherwise, we deﬁne by induction on k
a program Pk(i, S) for every k-set S over n and every 1 ≤ i ≤ n + 1 that will for the moment
output elements of Yk ∪ {ε} instead of outputting elements of Mk.

For any k > 0, 1 ≤ j ≤ n and S a k-set over n, let fj,S be the function with fj,S(0) = ε
and fj,S(1) = ⊤k if j is the ﬁrst element of some ordered k-tuple of S, fj,S(1) = ⊥k otherwise.
We also let gk be the function with gk(0) = ε and gk(1) = ⊥k. If S is a k-set over n and
1 ≤ j ≤ n then S|j denotes the (k − 1)-set over n containing the ordered (k − 1)-tuples ¯t
such that (j, ¯t) ∈ S.

For k > 0, 1 ≤ i ≤ n + 1 and S a k-set over n, the program Pk(i, S) is the following

sequence of instructions:

(i, fi,S)Pk−1(i + 1, S|i)(i, gk ) · · · (n, fn,S)Pk−1(n + 1, S|n)(n, gk).

In other words, the program guesses the ﬁrst occurrence j ≥ i of 1, returns ⊥k or ⊤k
depending on whether it is the ﬁrst element of an ordered k-tuple in S, and then proceeds
for the next occurrences of 1 by induction.

For k = 0, 1 ≤ i ≤ n + 1 and S a 0-set over n (that is empty or contains ε, the only

ordered 0-tuple of elements of [n]), the program P0(i, S) is the empty program ε.

A simple computation shows that for any k ∈ N>0, 1 ≤ i ≤ n + 1 and S a k-set over n,

the number of instructions in Pk(i, S) is at most 4nk.

A simple induction on k shows that when running on a word w ∈ {0, 1}n, for any
k ∈ N>0, 1 ≤ i ≤ n + 1 and S a k-set over n, Pk(i, S) returns a word in Zk iﬀ the ordered
k-tuple of the positions of the ﬁrst k occurrences of 1 starting at position i in w exists and
is an element of S.

28

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

For any k > 0 and Sn a k-set over n, it remains to apply the syntactic morphism of Zk
to the output of the functions in the instructions of Pk(1, Sn) to get a program over Mk of
length at most 4nk recognizing Kn,Sn.

Lower bound. The following claim is a simple counting argument.

Claim 5.4. For all i ∈ N>0 and n ∈ N, the number of languages in {0, 1}n recognized by
programs over a monoid of size i, reading inputs of length n over the alphabet {0, 1}, with
at most l ∈ N instructions, is bounded by ii2

2i · (n · i2)l.

Proof. Fix a monoid M of size i. Since a program over M of range n with less than l instruc-
tions can always be completed into such a program with exactly l instructions recognizing
the same languages in {0, 1}n (using the identity of M ), we only consider programs with
exactly l instructions. As Σ = {0, 1}, there are n · i2 choices for each of the l instructions of
a range n program over M reading inputs in {0, 1}∗. Such a program can recognize at most
2i diﬀerent languages in {0, 1}n. Hence, the number of languages in {0, 1}n recognized by
programs over M of length at most l is at most 2i · (n · i2)l. The result follows from the facts
that there are at most ii2
isomorphism classes of monoids of size i and that two isomorphic
monoids allow to recognize the same languages in {0, 1}n through programs.

If for some k ∈ N>0 and 1 ≤ i ≤ α, α ∈ N>0, we apply Claim 5.4 for all n ∈ N,
l = α · nk−1, we get a number µi(n) of languages upper-bounded by nO(nk−1), which is
asymptotically strictly smaller than the number of distinct Kn,Sn, which is 2(n
k), i.e. µi(n)
is in o

2(n
k)

.

(cid:0)

(cid:1)

Hence, for all j ∈ N>0, there exist an nj ∈ N and Tj a k-set over nj such that no program
over a monoid of size 1 ≤ i ≤ j, of range nj and of length at most j · nk−1 recognizes Knj,Tj .
Moreover, we can assume without loss of generality that the sequence (nj)j∈N>0 is increasing.
Let ∆ = (Sn)n∈N be such that Snj = Tj for all j ∈ N>0 and Sn = ∅ for any n ∈ N verifying
that it is not equal to any nj for j ∈ N>0. We show that no sequence of programs over a
ﬁnite monoid of length O(nk−1) can recognize L∆. If this were the case, then let i be the
size of the monoid. Let j ≥ i be such that for any n ∈ N, the n-th program has length at
most j · nk−1. But, by construction, we know that there does not exist any such program of
range nj recognizing Knj ,Tj , a contradiction.

This implies the following hierarchy, where P(V, s(n)) for some variety of monoids V
and a function s : N → N denotes the class of languages recognizable by a sequence of
programs of length O(s(n)):

Proposition 5.5. For all k ∈ N, P
and d ∈ N, d ≤ max{k − 1, 0}, P

DA, nk

( P

DAk, nd

(cid:0)

( P
(cid:1)

DA, nk+1
DAk, nd+1
(cid:0)

. More precisely, for all k ∈ N
.
(cid:1)
(cid:1)

(cid:0)
To prove this proposition, we use two facts. First, that for all k ∈ N and all d ∈
N, d ≤ max{k − 1, 0}, any monoid from DAd is also a monoid from DAk. And second, that
a∗ ∈ P(DA0, n) \ P(DA0, 1) simply because any program over some ﬁnite monoid of range
n for n ∈ N recognizing an must have at least n instructions, one for each input letter.

(cid:1)

(cid:0)

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

29

5.3. Collapse. Tesson and Thérien showed that any program over a monoid M in DA is
equivalent to one of polynomial length [TT02a]. We now show that if we further assume
that M is in DAk then the length can be assumed to be O(nmax{k,1}).

Proposition 5.6. Let k ≥ 0. Let M ∈ DAk. Then any program over M is equivalent to a
program over M of length O(nmax{k,1}) which is a subprogram of the initial one.

For each possible acceptance set, an input word to the program is accepted if and only
if the word over the alphabet M produced by the program belongs to some ﬁxed Boolean
combination of languages in SUMk. The idea is then just to keep enough instructions so
that membership of the produced word over M in each of these languages does not change.
Recall that if P is a program over some monoid M of range n, then P (w) denotes the
element of M resulting from the execution of the program P on w. It will be convenient
here to also work with the word over M resulting from the sequence of executions of each
instruction of P on w. We denote this word by EP (w).

The result is a consequence of the following lemma and the fact that for any acceptance
set F ⊆ M , a word w ∈ Σn (where Σ is the input alphabet) is accepted iﬀ EP (w) ∈ L where
L is a language in SU Lk, a Boolean combination of languages in SUMk.

Lemma 5.7. Let Σ be an alphabet, M a ﬁnite monoid, and n, k natural numbers.

For any program P over M of range n and any language K over M in SUMk, there
exists a subprogram Q of P of length O(nmax{k,1}) such that for any subprogram Q′ of P that
has Q as a subprogram, we have for all words w over Σ of length n:

EP (w) ∈ K ⇔ EQ′(w) ∈ K .

Proof. A program P over M of range n is a ﬁnite sequence (pi, fi) of instructions where each
pi is a positive natural number which is at most n and each fi is a function from Σ to M .
We denote by l the number of instructions of P . For each set I ⊆ [l] we denote by P [I] the
subprogram of P consisting of the subsequence of instructions of P obtained after removing
all instructions whose index is not in I. In particular, P [1, m] denotes the initial sequence
of instructions of P , until instruction number m.
We prove the lemma by induction on k.
The intuition behind the proof for a program P on inputs of length n and some K1γK2 ∈
SUMk when k ≥ 2 is as follows. We assume that K1 does not contain any word with the
letter γ, the other case is done symmetrically. Consider the subset of all indices Iγ ⊆ [l] that
correspond, for a ﬁxed letter a and a ﬁxed position p in the input, to the ﬁrst instruction
of P that would output the element γ when reading a at position p. We then have that,
given some w as input, EP (w) ∈ K1γK2 if and only if there exists i ∈ Iγ verifying that the
element at position i of EP (w) is γ, EP [1, i − 1](w) ∈ K1 and EP [i + 1, l](w) ∈ K2. The
idea is then that if we set I to contain Iγ as well as all indices obtained by induction for
P [1, i − 1] and K1 and for P [i + 1, l] and K2, we would have that for all w, EP (w) ∈ K1γK2
if and only if EP [I](w) ∈ K1γK2, that is EP (w) where only the elements at indices in I
have been kept.

The intuition behind the proof when k < 2 is essentially the same, but without induction.
We now spell out the details of the proof, starting with the inductive step.

Inductive step. Let k ≥ 2 and assume the lemma proved for all k′ < k. Let n be a
natural number, P a program over M of range n and length l and any language K over
M in SUMk. If K ∈ SUMk−1, by the inductive hypothesis, we are done. Otherwise, by

30

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

deﬁnition, K = K1γK2 for γ ∈ M and some languages K1 ∈ SUMk1 and K2 ∈ SUMk2
over M with k1 + k2 = k − 1. Moreover either γ does not occur in any of the words of K1
or it does not occur in any of the words of K2. We only treat the case where γ does not
appear in any of the words in K1. The other case is treated similarly by symmetry.

Observe that when n = 0, we necessarily have P = ε, so that the lemma is trivially

proven in that case. So we now assume n > 0.

For each 1 ≤ p ≤ n and each a ∈ Σ consider within the sequence of instructions of P
the ﬁrst instruction of the form (p, f ) with f (a) = γ, if it exists. We let Iγ be the set of
indices of these instructions for all a and p. Notice that the size of Iγ is in O(n).

For all i ∈ Iγ, we let Ji,1 be the set of indices of the instructions within P [1, i − 1]
appearing in its subprogram obtained by induction for P [1, i − 1] and K1, and Ji,2 be the
same for P [i + 1, l] and K2.

We now let I be the union of Iγ and Ji,1 and J ′

i,2 = {j + i | j ∈ Ji,2} for all i ∈ Iγ. We

claim that Q = P [I] has the desired properties.

First notice that by induction the sizes of Ji,1 and J ′

i,2 for all i ∈ Iγ are in O(nmax{k−1,1})
= O(nk−1) and because the size of Iγ is linear in n, the size of I is in O(nk) = O(nmax{k,1})
as required.

Let Q′ be a subprogram of P that has Q as a subprogram: it means that there exists

some set I ′ ⊆ [l] containing I such that Q′ = P [I ′].

Now take w ∈ Σn.
Assume now that EP (w) ∈ K. Let i be the position in EP (w) of label γ witnessing
the membership in K. Let (pi, fi) be the corresponding instruction of P .
In particular
we have that fi(wpi) = γ. Because γ does not occur in any word of K1, for all j < i
such that pj = pi we cannot have fj(wpj ) = γ. Hence i ∈ Iγ. By induction we have that
EP [1, i − 1][J](w) ∈ K1 for any set J ⊆ [i − 1] containing Ji,1 and EP [i + 1, l][J](w) ∈ K2
for any set J ⊆ [l − i] containing Ji,2. Hence, if we set I ′
1 = {j ∈ I ′ | j < i} as the subset of
2 = {j − i ∈ I ′ | j > i} as the subset of I ′ of elements greater
I ′ of elements less than i and I ′
than i translated by −i, we have

EP [I ′](w) = EP [1, i − 1][I ′

1](w)γEP [i + 1, l][I ′

2](w) ∈ K1γK2 = K

as desired.

Assume ﬁnally that EP [I ′](w) ∈ K. Let i be the index in I ′ whose instruction pro-
vides the letter γ witnessing the fact that EP [I ′](w) ∈ K. This means that if we set
2 = {j − i ∈ I ′ | j > i}
1 = {j ∈ I ′ | j < i} as the subset of I ′ of elements less than i and I ′
I ′
as the subset of I ′ of elements greater than i translated by −i, we have EP [I ′](w) =
2](w) with EP [1, i − 1][I ′
EP [1, i − 1][I ′
2](w) ∈
K2. If i ∈ Iγ, then it means that I ′
2 ⊆ [l − i] contains Ji,2
by construction, so that, by induction,

1 ⊆ [i − 1] contains Ji,1 and that I ′

1](w) ∈ K1 and EP [i + 1, l][I ′

1](w)γEP [i + 1, l][I ′

EP (w) = EP [1, i − 1](w)γEP [i + 1, l](w) ∈ K1γK2 = K .

If not this shows that there is an instruction (pj, fj) with j < i, j ∈ I ′, pj = pi and
fj(wpj ) = γ. But that would contradict the fact that γ cannot occur in K1. So we have
EP (w) ∈ K as desired.

Base case. There are two subcases to consider.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

31

Subcase k = 1. Let n be a natural number, P a program over M of range n and length l
and any language K over M in SUM1.

If K ∈ SUM0, we can conclude by referring to the subcase k = 0.
Otherwise K = A∗

2 for γ ∈ M and some alphabets A1 ⊆ M and A2 ⊆ M . Moreover
either γ /∈ A1 or γ /∈ A2. We only treat the case where γ does not belong to A1, the other
case is treated similarly by symmetry.

1γA∗

We use the same idea as in the inductive step.
Observe that when n = 0, we necessarily have P = ε, so that the lemma is trivially

proven in that case. So we now assume n > 0.

For each 1 ≤ p ≤ n, each α ∈ M and a ∈ Σ consider within the sequence of instructions
of P the ﬁrst and last instruction of the form (p, f ) with f (a) = α, if they exist. We let I
be the set of indices of these instructions for all a, α and p. Notice that the size of I is in
O(n) = O(nmax{k,1}).

We claim that Q = P [I] has the desired properties. We just showed that it has the

required length.

Let Q′ be a subprogram of P that has Q as a subprogram: it means that there exists

some set I ′ ⊆ [l] containing I such that Q′ = P [I ′].

Take w ∈ Σn.
Assume now that EP (w) ∈ K. Let i be the position in EP (w) of label γ witnessing
the membership in K. Let (pi, fi) be the corresponding instruction of P .
In particular
we have that fi(wpi) = γ and this is the γ witnessing the membership in K. Because
γ /∈ A1, for all j < i such that pj = pi we cannot have fj(wpj ) = γ. Hence i ∈ I ⊆ I ′. From
EP [1, i − 1](w) ∈ A∗
1 and
EP [I ′ ∩ [[i + 1, l]]](w) ∈ A∗
K as desired.

2 it follows that EP [I ′ ∩ [[1, i − 1]]](w) ∈ A∗

1 and EP [i + 1, l](w) ∈ A∗

2, showing that EP [I ′](w) = EP [I ′ ∩ [[1, i − 1]]](w)γEP [I ′ ∩ [[i + 1, l]]](w) ∈

1 and EP [I ′ ∩ [[i + 1, l]]](w) ∈ A∗
2.

Assume ﬁnally that EP [I ′](w) ∈ K. Let i be the index in I ′ whose instruction provides
the letter γ witnessing the fact that EP [I ′](w) ∈ K. This means that EP [I ′ ∩ [[1, i − 1]]](w) ∈
A∗
If there is an instruction (pj, fj), with j < i and
fj(wpj ) /∈ A1 then either j ∈ I ′ and we get a direct contradiction with the fact that
1, or j /∈ I ′ and we get a smaller j′ ∈ I ⊆ I ′ with the same
EP [I ′ ∩ [[1, i − 1]]](w) ∈ A∗
property, contradicting again the fact that EP [I ′ ∩ [[1, i − 1]]](w) ∈ A∗
1. Hence for all j < i,
fj(wpj ) ∈ A1. By symmetry we have that for all j > i, fj(wpj ) ∈ A2, showing that
EP (w) ∈ A∗

2 = K as desired.

1γA∗

Subcase k = 0. Let n be a natural number, P a program over M of range n and length l
and any language K over M in SUM0.

Then K = A∗ for some alphabet A ⊆ M .
We again use the same idea as before.
Observe that when n = 0, we necessarily have P = ε, so that the lemma is trivially

proven in that case. So we now assume n > 0.

For each 1 ≤ p ≤ n, each α ∈ M and a ∈ Σ consider within the sequence of instructions
of P the ﬁrst instruction of the form (p, f ) with f (a) = α, if it exists. We let I be the set
of indices of these instructions for all a, α and p. Notice that the size of I is in O(n) =
O(nmax{k,1}).

We claim that Q = P [I] has the desired properties. We just showed that it has the

required length.

32

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

Let Q′ be a subprogram of P that has Q as a subprogram: it means that there exists

some set I ′ ⊆ [l] containing I such that Q′ = P [I ′].

Take w ∈ Σn.
Assume now that EP (w) ∈ K. As EP [I ′](w) is a subword of EP (w), it follows directly

that EP [I ′](w) ∈ A∗ = K as desired.

Assume ﬁnally that EP [I ′](w) ∈ K.

If there is an instruction (pj, fj), with j ∈ [l]
and fj(wpj ) /∈ A then either j ∈ I ′ and we get a direct contradiction with the fact that
EP [I](w) ∈ A∗ = K, or j /∈ I ′ and we get a smaller j′ ∈ I ⊆ I ′ with the same property,
contradicting again the fact that EP [I ′](w) ∈ A∗ = K. Hence for all j ∈ [l], fj(wpj ) ∈ A,
showing that EP (w) ∈ A∗ = K as desired.

6. Conclusion

We introduced a notion of tameness, particularly relevant to the analysis of programs over
monoids from “small” varieties. The main source of interest in tameness is Proposition 3.11,
stating that a variety of monoids V is tame if and only if the class of regular languages
p-recognized by programs over monoids from V is included in the class L(QEV). A ﬁrst
question that arises is for which V those two classes of regular languages are equal. We
could not rule out the possibility that for some tame non-trivial V, L(QEV) \ P(V) 6= ∅.
We conjecture that if V is local, abusing notation, QEV = EV ∗Mod, by analogy with QV
equating V∗Mod in that case; as L(EV ∗ Mod) ⊆ P(V) holds unconditionally (because V
cannot be trivial if it is local [Til87, p. 134]), under our conjecture P(V) ∩ Reg = L(QEV)
would hold for local tame varieties V (this is Conjecture 3.12).

Concretely, we have obtained the technical result that DA is a tame variety using
semigroup-theoretic arguments. We have given A and Com as further examples of tame
varieties. Our proof that A is tame needed the fact that MODm /∈ AC0 for all m ≥ 2,
so it would be interesting to prove A tame “purely algebraically”, independently from the
known combinatorial arguments [Ajt83, FSS84, Hås86] and those based on approximating
circuits by polynomials over some ﬁnite ﬁeld [Raz87, Smo87]. But tameness of A is actually
equivalent to MODm /∈ AC0 for all m ≥ 2 by Proposition 3.11, thus confronting us with the
challenging task to reprove signiﬁcant circuit complexity results by relying mainly on new
semigroup-theoretic arguments. Such a breakthrough is still to be made.

By contrast, we have shown that J is not tame. So programs over monoids from J p-
recognize “more regular languages than expected”. A natural question to ask is what these
regular languages in P(J) are. Partial results in that direction were obtained in [Gro20].

To conclude we should add, in fairness, that the progress reported here does not in
any obvious way bring us closer to major NC1 complexity subclasses separations. Our
concrete contributions here largely concern P(DA) and P(J), classes that are well within
AC0. But this work does uncover new ways in which a program can or cannot circumvent
the limitations imposed by the underlying monoid algebraic structure available to it.

Acknowledgments

The authors would like to thank the anonymous referees for their detailed reports as well as
for their constructive criticism and the many suggestions and comments they made. This
helped us to really improve our paper.

TAMENESS AND THE POWER OF PROGRAMS OVER MONOIDS IN DA

33

[Ajt83] Miklós Ajtai. Σ1

1-formulae on ﬁnite structures. Ann. Pure Appl. Log., 24(1):1–48, 1983.

References

[Alm96]

[Bar89]

doi:10.1016/0168-0072(83)90038-6.
Jorge Almeida. A syntactical proof of locality of DA. Int. J. Algebra Comput., 6(2):165–178, 1996.
doi:10.1142/S021819679600009X.
David A. Mix Barrington. Bounded-width polynomial-size branching programs
nize
38(1):150–164,
doi:10.1016/0022-0000(89)90037-8.

in NC1. J. Comput. Syst. Sci.,

exactly those

recog-
1989.

languages

[BCST92] David A. Mix Barrington, Kevin J. Compton, Howard Straubing, and Denis Thérien. Regular lan-
guages in NC1. J. Comput. Syst. Sci., 44(3):478–499, 1992. doi:10.1016/0022-0000(92)90014-A.
David A. Mix Barrington and Denis Thérien. Finite monoids and the ﬁne structure of NC1. J.
ACM, 35(4):941–952, 1988. doi:10.1145/48014.63138.

[BT88]

[CPS06a] Laura Chaubard,

Jean-Éric Pin,

of C-varieties and concatenation product. Theor. Comput. Sci.,
doi:10.1016/j.tcs.2006.01.039.

and Howard Straubing. Actions, wreath products
2006.

356(1-2):73–89,

[DP13]

[Dar14]

[CPS06b] Laura Chaubard, Jean-Eric Pin, and Howard Straubing. First order formulas with modular pred-
icates. In 21th IEEE Symposium on Logic in Computer Science (LICS 2006), 12-15 August 2006,
Seattle, WA, USA, Proceedings, pages 211–220, 2006. doi:10.1109/LICS.2006.24.
Luc Dartois. Méthodes algébriques pour la théorie des automates. PhD thesis, Université Paris
Diderot, Paris, 2014. URL: http://lacl.fr/~ldartois/these.pdf.
Luc Dartois and Charles Paperman. Two-variable ﬁrst order logic with modular predi-
cates over words. In 30th International Symposium on Theoretical Aspects of Computer Sci-
ence, STACS 2013, February 27 - March 2, 2013, Kiel, Germany, pages 329–340, 2013.
doi:10.4230/LIPIcs.STACS.2013.329.
Luc Dartois and Charles Paperman. Adding modular predicates. CoRR, abs/1401.6576, 2014.
URL: http://arxiv.org/abs/1401.6576.
Samuel
and
https://www.sciencedirect.com/bookseries/pure-and-applied-mathematics/vol/59/part/PA.
Samuel
and
https://www.sciencedirect.com/bookseries/pure-and-applied-mathematics/vol/59/part/PB.

and Machines.

and Machines.

mathematics.

mathematics.

Pure
URL:

Pure
URL:

Languages,

Languages,

Automata,

Automata,

Eilenberg.

Eilenberg.

Academic

Academic

Volume

Volume

applied

applied

[DP14]

[Eil76]

[Eil74]

Press,

Press,

York,

York,

1976.

1974.

New

New

A.

B.

[FSS84] Merrick L. Furst, James B. Saxe, and Michael Sipser. Parity, circuits, and the polynomial-time

hierarchy. Math. Syst. Theory, 17(1):13–27, 1984. doi:10.1007/BF01744431.

[Gro18]

[Gro20]

[GMS17] Nathan Grosshans, Pierre McKenzie, and Luc Segouﬁn. The power of programs over
monoids in DA. In 42nd International Symposium on Mathematical Foundations of Com-
puter Science, MFCS 2017, August 21-25, 2017 - Aalborg, Denmark, pages 2:1–2:20, 2017.
doi:10.4230/LIPIcs.MFCS.2017.2.
Nathan Grosshans. The limits of Nečiporuk’s method and the power of programs over monoids
taken from small varieties of ﬁnite monoids. PhD thesis, University of Paris-Saclay, France, 2018.
URL: https://tel.archives-ouvertes.fr/tel-01935719.
Nathan Grosshans. The power of programs over monoids in J. In Language and Automata Theory
and Applications - 14th International Conference, LATA 2020, Milan, Italy, March 4-6, 2020,
Proceedings, pages 315–327, 2020. URL: https://hal.archives-ouvertes.fr/hal-02414771,
doi:10.1007/978-3-030-40608-0_22.
Ricard Gavaldà and Denis Thérien. Algebraic characterizations of small classes of Boolean
functions. In STACS 2003, 20th Annual Symposium on Theoretical Aspects of Computer Sci-
ence, Berlin, Germany, February 27 - March 1, 2003, Proceedings, pages 331–342, 2003.
doi:10.1007/3-540-36494-3_30.
Johan Håstad. Almost optimal lower bounds for small depth circuits. In Proceedings of the 18th
Annual ACM Symposium on Theory of Computing, May 28-30, 1986, Berkeley, California, USA,
pages 6–20, 1986. doi:10.1145/12130.12132.

[Hås86]

[GT03]

[LTT06] Clemens Lautemann, Pascal Tesson, and Denis Thérien. An algebraic point of view on the Crane
Beach property. In Zoltán Ésik, editor, Computer Science Logic, 20th International Workshop,

34

N. GROSSHANS, P. MCKENZIE, AND L. SEGOUFIN

CSL 2006, 15th Annual Conference of the EACSL, Szeged, Hungary, September 25-29, 2006,
Proceedings, pages 426–440, 2006. doi:10.1007/11874683_28.

[MPT91] Pierre McKenzie, Pierre Péladeau, and Denis Thérien. NC1: The automata-theoretic viewpoint.

Comput. Complex., 1:330–359, 1991. doi:10.1007/BF01212963.

[MR65] Ward D. Maurer and John L. Rhodes. A property of ﬁnite simple non-abelian groups. Proc. Amer.

[Pap14]

[Pél90]

[Pin86]

[PS05]

Math. Soc., 16(3):552–554, 1965. doi:10.1090/s0002-9939-1965-0175971-0.
Charles Paperman. Circuits booléens, prédicats modulaires et langages réguliers. PhD thesis, Uni-
versité Paris Diderot, Paris, 2014. URL: https://paperman.name/data/these.pdf.
Pierre Péladeau. Classes de circuits booléens et variétés de monoïdes. PhD thesis, Université
Pierre-et-Marie-Curie (Paris-VI), Paris, France, 1990.
Jean-Éric Pin. Varieties of Formal Languages. North Oxford, London and Plenum, New-York,
1986. (Traduction de Variétés de langages formels).
Jean-Éric Pin and Howard Straubing. Some results on C-varieties. RAIRO Theor. Informatics
Appl., 39(1):239–262, 2005. doi:10.1051/ita:2005014.

[Str00]

[Str94]

[Rei82]

[Sim75]

[Raz87]

[PST97] Pierre Péladeau, Howard Straubing, and Denis Thérien. Finite semigroup varieties deﬁned by
programs. Theor. Comput. Sci., 180(1-2):325–339, 1997. doi:10.1016/S0304-3975(96)00297-6.
Alexander A. Razborov. Lower bounds on the size of bounded depth circuits over a complete basis
with logical addition. Mathematical Notes of the Academy of Sciences of the USSR, 41(4):333–338,
1987. doi:10.1007/bf01137685.
Jan Reiterman. The Birkhoﬀ theorem for ﬁnite algebras. Algebra Universalis, 14(1):1–10, 1982.
doi:10.1007/bf02483902.
Imre Simon. Piecewise testable events. In Automata Theory and Formal Languages, 2nd GI Con-
ference, Kaiserslautern, May 20-23, 1975, pages 214–222, 1975. doi:10.1007/3-540-07407-4_23.
[Smo87] Roman Smolensky. Algebraic methods in the theory of lower bounds for Boolean circuit complex-
ity. In Proceedings of the 19th Annual ACM Symposium on Theory of Computing, 1987, New
York, New York, USA, pages 77–82, 1987. doi:10.1145/28395.28404.
Howard Straubing. Finite Automata, Formal Logic, and Circuit Complexity. Birkhauser, Boston,
1994. doi:10.1007/978-1-4612-0289-9.
one
Straubing. When
Howard
mic Problems
doi:10.1007/978-1-4612-1388-8_15.
Howard Straubing. Languages deﬁned with modular counting quantiﬁers. Inf. Comput.,
166(2):112–132, 2001. doi:10.1006/inco.2000.2923.
Howard Straubing. On logical descriptions of regular languages. In LATIN 2002: Theoretical In-
formatics, 5th Latin American Symposium, Cancun, Mexico, April 3-6, 2002, Proceedings, pages
528–538, 2002. doi:10.1007/3-540-45995-2_46.
to
Pascal
An
Montreal,
McGill
ity. Master’s
https://escholarship.mcgill.ca/concern/theses/9g54xk72r.
Pascal Tesson. Computational Complexity Questions Related
and Semigroups. PhD thesis, McGill University, Montreal, Canada,
https://escholarship.mcgill.ca/concern/theses/j9602115z.
Bret Tilson. Categories as algebra: An essential ingredient in the theory of monoids. J. Pure Appl.
Algebra, 48(1-2):83–198, 1987. doi:10.1016/0022-4049(87)90108-3.

in Groups and Semigroups, pages 267–288. Birkhäuser Boston,

to Finite Monoids
2003. URL:

In Algorith-
2000.

complex-
URL:

communication

ﬁnite monoid

University,

approach

algebraic

simulate

another.

Canada,

Tesson.

[Tes98]

[Tes03]

[Str01]

[Str02]

[Til87]

thesis,

1998.

can

[TT02a] Pascal Tesson and Denis Thérien. The computing power of programs over ﬁnite monoids. J.

Autom. Lang. Comb., 7(2):247–258, 2002. doi:10.25596/jalc-2002-247.

[TT02b] Pascal Tesson and Denis Thérien. Diamonds are forever: the variety DA. In Semigroups, Algo-

rithms, Automata and Languages, pages 475–499, 2002. doi:10.1142/9789812776884_0021.

This work is licensed under the Creative Commons Attribution License. To view a copy of this
license, visit https://creativecommons.org/licenses/by/4.0/ or send a letter to Creative
Commons, 171 Second St, Suite 300, San Francisco, CA 94105, USA, or Eisenacher Strasse 2,
10777 Berlin, Germany

