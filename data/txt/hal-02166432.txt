Who started this rumor? Quantifying the natural
differential privacy guarantees of gossip protocols
Aurélien Bellet, Rachid Guerraoui, Hadrien Hendrikx

To cite this version:

Aurélien Bellet, Rachid Guerraoui, Hadrien Hendrikx. Who started this rumor? Quantifying the
natural differential privacy guarantees of gossip protocols. DISC 2020 - 34th International Symposium
on Distributed Computing, Oct 2020, Freiburg / Virtual, Germany. ￿hal-02166432v2￿

HAL Id: hal-02166432

https://inria.hal.science/hal-02166432v2

Submitted on 6 Jan 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Who started this rumor? Quantifying the natural
diﬀerential privacy of gossip protocols

Aurélien Bellet
INRIA
aurelien.bellet@inria.fr

Rachid Guerraoui
EPFL
rachid.guerraoui@epﬂ.ch

Hadrien Hendrikx
PSL, DIENS, INRIA
hadrien.hendrikx@inria.fr

Abstract

Gossip protocols (also called rumor spreading or epidemic protocols) are widely used to disseminate
information in massive peer-to-peer networks. These protocols are often claimed to guarantee privacy
because of the uncertainty they introduce on the node that started the dissemination. But is that
claim really true? Can the source of a gossip safely hide in the crowd? This paper examines, for the
ﬁrst time, gossip protocols through a rigorous mathematical framework based on diﬀerential privacy
to determine the extent to which the source of a gossip can be traceable. Considering the case of a
complete graph in which a subset of the nodes are curious, we study a family of gossip protocols
parameterized by a “muting” parameter s: nodes stop emitting after each communication with a
ﬁxed probability 1 − s. We ﬁrst prove that the standard push protocol, corresponding to the case
s = 1, does not satisfy diﬀerential privacy for large graphs. In contrast, the protocol with s = 0
(nodes forward only once) achieves optimal privacy guarantees but at the cost of a drastic increase
in the spreading time compared to standard push, revealing an interesting tension between privacy
and spreading time. Yet, surprisingly, we show that some choices of the muting parameter s lead to
protocols that achieve an optimal order of magnitude in both privacy and speed. Privacy guarantees
are obtained by showing that only a small fraction of the possible observations by curious nodes
have diﬀerent probabilities when two diﬀerent nodes start the gossip, since the source node rapidly
stops emitting when s is small. The speed is established by analyzing the mean dynamics of the
protocol, and leveraging concentration inequalities to bound the deviations from this mean behavior.
We also conﬁrm empirically that, with appropriate choices of s, we indeed obtain protocols that are
very robust against concrete source location attacks (such as maximum a posteriori estimates) while
spreading the information almost as fast as the standard (and non-private) push protocol.

2012 ACM Subject Classiﬁcation Security and privacy → Privacy-preserving protocols

Keywords and phrases Gossip Protocol, Rumor Spreading, Diﬀerential Privacy

Funding Aurélien Bellet: This research was supported by grants ANR-16-CE23-0016-01 and ANR-
18-CE23-0018-03, by the European Union’s Horizon 2020 Research and Innovation Program under
Grant Agreement No. 825081 COMPRISE (https://project.inria.fr/comprise/), by a grant
from CPER Nord-Pas de Calais/FEDER DATA Advanced data science and technologies 2015-2020.
Rachid Guerraoui: This research was supported by European ERC Grant 339539 - AOC.
Hadrien Hendrikx: This research was supported by the MSR-INRIA joint centre.

1

Introduction

Gossip protocols (also called rumor spreading or epidemic protocols), in which participants
randomly choose a neighbor to communicate with, are both simple and eﬃcient means
to exchange information in P2P networks [1, 2, 3, 4]. They are a basic building block to

0
2
0
2

g
u
A
4

]

C
D
.
s
c
[

6
v
8
3
1
7
0
.
2
0
9
1
:
v
i
X
r
a

 
 
 
 
 
 
2

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

propagate and aggregate information in distributed databases [5, 6] and social networks [7, 8],
to model the spread of infectious diseases [9], as well as to train machine learning models on
distributed datasets [10, 11, 12, 13].

Some of the information gossiped may be sensitive, and participants sharing it may not
want to be identiﬁed. This can for instance be the case of whistle-blowers or individuals that
would like to exercise their right to freedom of expression in totalitarian regimes. Conversely,
it may sometimes be important to locate the source of a (computer or biological) virus, or
fake news, in order to prevent it from spreading before too many participants get “infected”.

There is a folklore belief that gossip protocols inherently guarantee some form of source
anonymity because participants cannot know who issued the information in the ﬁrst place
[14]. Similarly, identifying “patient zero” for real-world epidemics is known to be a very hard
task. Intuitively indeed, random and local exchanges make identiﬁcation harder. But to what
extent? Although some work has been devoted to the design of source location strategies
in speciﬁc settings [15, 16, 17], the general anonymity claim has never been studied from
a pure privacy perspective, that is, independently of the very choice of a source location
technique. Depending on the use-case, it may be desirable to have strong privacy guarantees
(e.g., in anonymous information dissemination) or, on the contrary, we may hope for weak
guarantees, e.g., when trying to identify the source of an epidemic. In both cases, it is crucial
to precisely quantify the anonymity level of gossip protocols and study its theoretical limits
through a principled approach. This is the challenge we take up in this paper for the classic
case of gossip dissemination in a complete network graph.

Our ﬁrst contribution is an information-theoretic model of anonymity in gossip protocols
based on ((cid:15), δ)-diﬀerential privacy (DP) [18, 19]. Originally introduced in the database
community, DP is a precise mathematical framework recognized as the gold standard for
studying the privacy guarantees of information release protocols. In our proposed model,
the information to protect is the source of the gossip, and an adversary tries to locate the
source by monitoring the communications (and their relative order) received by a subset of f
curious nodes. In a computer network, these curious nodes may have been compromised by a
surveillance agency; in our biological example, they could correspond to health professionals
who are able to identify whether a given person is infected. Our notion of DP then requires
that the probability of any possible observation of the curious nodes is almost the same no
matter who is the source, thereby limiting the predictive power of the adversary regardless of
its actual source location strategy. A distinctive aspect of our model is that the mechanism
that seeks to ensure DP comes only from the natural randomness and partial observability of
gossip protocols, not from additional perturbation or noise which aﬀects the desired output as
generally needed to guarantee DP [20]. We believe our adaptation of DP to the gossip context
to be of independent interest. We also complement it with a notion of prediction uncertainty
which guarantees that even unlikely events do not fully reveal the identity of the source
under a uniform prior on the source. This property directly upper bounds the probability of
success of any source location attack, including the maximum likelihood estimate.

We use our proposed model to study the privacy guarantees of a generic family of gossip
protocols parameterized by a muting parameter s: nodes have a ﬁxed probability 1 − s
to stop emitting after each communication (until they receive the rumor again). In our
biological parallel, this corresponds to the fact that a person stops infecting other people
after some time. The muting parameter captures the ability of the protocol to forget initial
conditions, thereby helping to conceal the identity of the source. In the extreme case where
s = 1, we recover the standard “push” gossip protocol [2], and show that it is inherently not
diﬀerentially private for large graphs. In contrast, we also show that, at the other end of the

A. Bellet, R. Guerraoui and H. Hendrikx

3

Standard push
(minimal privacy, maximal speed)
Muting after infecting
(maximal privacy, minimal speed)
Generic parameterized gossip
(privacy vs. speed trade-oﬀ)

Muting param.

δ ensuring (0, δ)-DP Spreading time

s = 1

s = 0

1

f
n

O(log n)

O (n log n)

0 < s < 1

s + (1 − s) f
n

O (log(n)/s)

Table 1 Summary of results to illustrate the tension between privacy and speed. n is the total
number of nodes and f /n is the fraction of curious nodes in the graph. δ ∈ [0, 1] quantiﬁes diﬀerential
privacy guarantees (smaller is better). Spreading time is asymptotic in n.

spectrum, choosing s = 0 leads to optimal privacy guarantees among all gossip protocols.

More generally, we determine matching upper and lower bounds on the privacy guarantees
of gossip protocols. Essentially, our upper bounds on privacy are obtained by tightly lower
bounding the probability that the source node contacts a curious node before another node
does, and upper bounding the probability that this happens for a random node ﬁxed in
advance, in a way that holds for all gossip algorithms. Remarkably, despite the fact that the
source node always has a non-negligible probability of telling the rumor to a curious node
ﬁrst, our results highlight the fact that setting s = 0 leads to strong privacy guarantees in
several regimes, including the pure ((cid:15), 0)-DP as well as prediction uncertainty.

It turns out that, although achieving optimal privacy guarantees, choosing s = 0 leads
to a very slow spreading time (log-linear in the number of nodes n). This highlights an
interesting tension between privacy and spreading time: the two extreme values for the
muting parameter s recover the two extreme points of this trade-oﬀ. We then show that more
balanced trade-oﬀs can be achieved: appropriate choices of the muting parameter lead to
gossip protocols that are near-optimally private with a spreading time that is logarithmic in
the size of the graph. In particular, the trade-oﬀ between privacy and speed shows up in the
constants but, surprisingly, some choices of the parameter lead to protocols that achieve an
optimal order of magnitude for both aspects. Our results on this trade-oﬀ are summarized in
Table 1: for a proportion f /n of curious nodes, one can see that setting the muting parameter
s = f /n achieves almost optimal privacy (up to a factor 2) while being substantially faster
than s = 0 (optimal up to a factor f /n). Similarly, if one wants to achieve (0, δ0)-diﬀerential
privacy with δ0 > 2f /n, then it is possible to set s = δ0/2 and obtain a protocol that respects
the privacy constraint with spreading time O(log(n)/δ0). From a technical perspective,
these privacy results are obtained by showing that only a small fraction of the possible
observations by curious nodes have diﬀerent probabilities when two diﬀerent nodes start
with the gossip. This requires to precisely evaluate the probability of well-chosen worst-case
sequences, which is generally hard as randomness is involved both when nodes decide to stop
spreading the rumor (with probability 1 − s) and when they choose who to communicate
with. Our parameterized gossip protocol can be seen as a population protocol [21], and we
prove its speed by analyzing its mean dynamics and leveraging concentration inequalities to
bound the deviations from the mean dynamics.

We support our theoretical ﬁndings by an empirical study of our parameterized gossip
protocols. The results show that appropriate choices of s lead to protocols that are very
robust against classical source location attacks (such as maximum a posteriori estimates)
while spreading the information almost as fast as the standard (and non-private) push
protocol. Crucially, we observe that our diﬀerential privacy guarantees are very well aligned
with the ability to withstand attacks that leverage background information, e.g., targeting

4

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

known activists or people who have been to certain places.

The rest of the paper is organized as follows. We ﬁrst discuss related work and formally
introduce our concept of diﬀerential privacy for gossip. Then, we study two extreme cases
of our parameterized gossip protocol: the standard push protocol, which we show is not
private, and a privacy-optimal but slow protocol. This leads us to investigate how to better
control the trade-oﬀ between speed and privacy. Finally, we present our empirical study and
conclude by discussing open questions.

For pedagogical reasons, we keep our model relatively simple to avoid unnecessary
technicalities in the derivation and presentation of our results. For completeness, we discuss
the impact of possible extensions (e.g., information observed by the adversary, malicious
behavior, termination criterion) in Appendix A. For space limitations, some detailed proofs
are also deferred to the appendix.

2

Background and Related Work

2.1 Gossiping

The idea of disseminating information in a distributed system by having each node push
messages to a randomly chosen neighbor, initially coined the random phone-call model, dates
back to even before the democratization of the Internet [2]. Such protocols, later called
gossip, epidemic or rumor spreading, were for instance applied to ensure the consistency of
a replicated database system [5]. They have gained even more importance when argued to
model spreading of infectious diseases [9] and information dissemination in social networks
[7, 8]. Gossip protocols can also be used to compute aggregate queries on a database
distributed across the nodes of a network [22, 6], and have recently become popular in
federated machine learning [23] to optimize cost functions over data distributed across a large
set of peers [10, 11, 12, 13]. Gossip protocols diﬀer according to their interaction schemes,
i.e., pull or push, sometimes combining both [3, 24, 25].

In this work, we focus on the classical push form in the standard case of a complete graph
with n nodes (labeled from 0 to n − 1). We now deﬁne its key communication primitive.
Denoting by I the set of informed nodes, tell_gossip(i, I) allows an informed node i ∈ I
to tell the information to another node j ∈ {0, ..., n − 1} chosen uniformly at random.
tell_gossip(i, I) returns j (the node that received the message) and the updated I (the new
set of informed nodes that includes j). Equipped with this primitive, we can now formally
deﬁne the class of gossip protocols that we consider in this paper.

(cid:73) Deﬁnition 1 (Gossip protocols). A gossip protocol on a complete graph is one that (a)
terminates almost surely, (b) ensures that at the end of the execution the set of informed
nodes I is equal to {0, ..., n − 1}, and (c) can modify I only through calls to tell_gossip.

2.2 Locating the Source of the Gossip

Determining the source of a gossip is an active research topic, especially given the potential
applications to epidemics and social networks, see [15] for a recent survey. Existing approaches
have focused so far on building source location attacks that compute or approximate the
maximum likelihood estimate of the source given some observed information. Each approach
typically assumes a speciﬁc kind of graphs (e.g., trees, small world, etc.), dissemination
model and observed information. In rumor centrality [17], the gossip communication graph
is assumed to be fully observed and the goal is to determine the center of this graph to
deduce the node that started the gossip. Another line of work studies the setting in which

A. Bellet, R. Guerraoui and H. Hendrikx

5

some nodes are curious sensors that inform a central entity when they receive a message
[16]. Gossiping is assumed to happen at random times and the source node is estimated by
comparing the diﬀerent timings at which information reaches the sensors. The proposed
attack is natural in trees but does not generalize to highly connected graphs. The work
of [26] focuses on hiding the source instead of locating it. The observed information is a
snapshot of who has the rumor at a given time. A speciﬁc dissemination protocol is proposed
to hide the source but the privacy guarantees only hold for tree graphs.

We emphasize that the privacy guarantees (i.e., the probability not to be detected) that
can be derived from the above work only hold under the speciﬁc attacks considered therein.
Furthermore, all approaches rely on maximum likelihood and hence assume a uniform prior
on the probability of each node to be the source. The guarantees thus break if the adversary
knows that some of the nodes could not have started the rumor, or if he is aware that the
protocol is run twice from the same source.

We note that other problems at the intersection of gossip protocols and privacy have
been investigated in previous work, such as preventing unintended recipients from learning
the rumor [27], and hiding the initial position of agents in a distributed system [28].

2.3 Diﬀerential Privacy

While we borrow ideas from the approaches mentioned above (e.g., we assume that a subset
of nodes are curious sensors as in [16]), we aim at studying the fundamental limits of
any source location attack by measuring the amount of information leaked by a gossip
scheme about the identity of the source. For this purpose, a general and robust notion of
privacy is required. Diﬀerential privacy [18, 20] has emerged as a gold standard for it holds
independently of any assumption on the model, the computational power, or the background
knowledge that the adversary may have. Diﬀerentially private protocols have been proposed
for numerous problems in the ﬁelds of databases, data mining and machine learning: examples
include computing aggregate and linear counting queries [20], releasing and estimating graph
properties [29, 30], clustering [31], empirical risk minimization [32] and deep learning [33].
In this work, we consider the classic version of diﬀerential privacy which involves two
parameters (cid:15), δ ≥ 0 that quantify the privacy guarantee [19]. More precisely, given any two
databases D1 and D2 that diﬀer in at most one record, a randomized information release
protocol P is said to guarantee ((cid:15), δ)-diﬀerential privacy if for any possible output S:

p(P(D1) ∈ S) ≤ e(cid:15)p(P(D2) ∈ S) + δ,

(1)

where p(E) denotes the probability of event E. Parameter (cid:15) places a bound on the ratio of
the probability of any output when changing one record of the database, while parameter δ
is assumed to be small and allows the bound to be violated with small probability. When
(cid:15) = 0, δ gives a bound on the total variation distance between the output distributions, while
δ = 0 is sometimes called “pure” (cid:15)-diﬀerential privacy. DP guarantees hold regardless of the
adversary and its background knowledge about the records in the database. In our context,
the background information could be the knowledge that the source is among a subset of all
nodes. Robustness against such background knowledge is crucial in some applications, for
instance when sharing secret information that few people could possibly know or when the
source of an epidemic is known to be among people who visited a certain place. Another
key feature of diﬀerential privacy is composability: if ((cid:15), δ)-diﬀerential privacy holds for a
release protocol, then querying this protocol two times about the same dataset satisﬁes
(2(cid:15), 2δ)-diﬀerential privacy. This is important for rumor spreading as it enables to quantify
privacy when the source propagates multiple rumors that the adversary can link to the same

6

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

source (e.g., due to the content of the message). We will see in Section 6 that these properties
are essential in practice to achieve robustness to concrete source location attacks.

Existing diﬀerentially private protocols typically introduce additional perturbation (also
called noise) to hide critical information [20]. In contrast, an original aspect of our work
is that we will solely rely on the natural randomness and limited observability brought by
gossip protocols to guarantee diﬀerential privacy.

3

A Model of Diﬀerential Privacy for Gossip Protocols

Our ﬁrst contribution is a precise mathematical framework for studying the fundamental
privacy guarantees of gossip protocols. We formally deﬁne the inputs of the gossip protocols
introduced in Deﬁnition 1, the outputs observed by the adversary during their execution,
and the privacy notions we investigate. To ease the exposition, we adopt the terminology of
information dissemination, but we sometimes illustrate the ideas in the context of epidemics.

3.1

Inputs and Outputs

As described in Section 2.3, diﬀerential privacy is a probabilistic notion that measures the
privacy guarantees of a protocol based on the variations of its output distribution for a change
in its input. In this paper, we adapt it to our gossip context. We ﬁrst formalize the inputs
and outputs of gossip protocols, in the case of a single piece of information to disseminate
(multiple pieces can be addressed through composition, see Section 2.3). At the beginning
of the protocol, a single node, the source, has the information (the gossip, or rumor). This
node deﬁnes the input of the gossip protocol, and it is the actual “database” that we want to
protect. Therefore, in our context, input databases in Equation (1) have only 1 record, which
contains the identity of the source (an integer between 0 and n − 1). Therefore, all possible
input databases diﬀer in at most one record, and diﬀerential privacy aims at protecting the
content of the database, i.e., which node started the rumor.

We now turn to the outputs of a gossip protocol. The execution of a protocol generates an
ordered sequence Somni of pairs (i, j) of calls to tell_gossip where (Somni)t corresponds to
the t-th time the tell_gossip primitive has been called, i is the node on which tell_gossip
was used and j the node that was told the information. If several calls to tell_gossip
happen simultaneously, ties are broken arbitrarily. We assume that the messages are received
in the same order that they are sent. This protocol can thus be seen as an epidemic
population protocol model [21] in which nodes interact using tell_gossip. The sequence
Somni corresponds to the output that would be observed by an omniscient entity who could
eavesdrop on all communications. It is easy to see that, for any execution, the source can be
identiﬁed exactly from Somni simply by retrieving (Somni)0.

In this work, we focus on adversaries that monitor a set of curious nodes C of size f , i.e.
they observe all communications involving a curious node. This model, previously introduced
in [16], is particularly meaningful in large distributed networks: while it is unlikely that
an adversary can observe the full state of the network at any given time, compromising or
impersonating a subset of the nodes appears more realistic. The number of curious nodes
is directly linked with the release mechanism of DP: while the ﬁnal state of the system is
always the same (everyone knows the rumor), the information released depends on which
messages were received by the curious nodes during the execution. Formally, the output
disclosed to the adversary during the execution of the protocol, i.e., the information he can
use to try to identify the source, is a subsequence of Somni as deﬁned below.

A. Bellet, R. Guerraoui and H. Hendrikx

7

(cid:73) Assumption 2. The sequence S observed by the adversary through the (random) execution
of the protocol is a (random) subsequence S = ((Somni)t|(Somni)t = (i, j) with j ∈ C), that
contains all messages sent to curious nodes. The adversary has access to the relative order
of tuples in S, which is the same as in Somni, but not to the index t in Somni.

It is important to note that the adversary does not know which messages were exchanged
between non-curious nodes. In particular, he does not know how many messages were sent in
total at a given time. As we focus on complete graphs, knowing which curious node received
the rumor gives no information on the source node. For a given output sequence S, we write
St = i to denote that the t-th tell_gossip call in S originates from node i. Omitting the
dependence on S, we also denote ti(j) the time at which node j ﬁrst receives the message
(even for the source) and td(j) the time at which j ﬁrst communicates with a curious node.
The ratio f /n of curious nodes determines the probability of the adversary to gather
information (the more curious nodes, the more information leaks). For a ﬁxed f , the adversary
only becomes weaker as the network grows bigger. Since we would like to study adversaries
with ﬁxed power, unless otherwise noted we make the following assumption.

(cid:73) Assumption 3. The ratio of curious nodes f /n is constant.

Finally, we emphasize that we do not restrict the computational power of the adversary.

3.2 Privacy Deﬁnitions

We now formally introduce our privacy deﬁnitions. The ﬁrst one is a direct application of
diﬀerential privacy (Equation 1) for the inputs and outputs speciﬁed in the previous section.
To ease notations, we denote by I0 the source of the gossip (the set of informed nodes at time
0), and for any given i ∈ {0, ..., n − 1}, we denote by pi(E) = p(E|I0 = {i}) the probability
of event E if node i is the source of the gossip. The protocol is therefore abstracted in this
notation. Denoting by S the set of all possible outputs, we say that a gossip protocol is
((cid:15), δ)-diﬀerentially private if:

pi(S) ≤ e(cid:15)pj(S) + δ, ∀S ⊂ S, ∀i, j ∈ {0, ..., n − 1},

(2)

where p(S) is the probability that the output belongs to the set S. This formalizes a notion
of source indistinguishability in the sense that any set of output which is likely enough to
happen if node i starts the gossip (say, pi(S) ≥ δ) is almost as likely (up to a e(cid:15) multiplicative
factor) to be observed by the adversary regardless of the source. Note however that when
δ > 0, this deﬁnition can be satisﬁed for protocols that release the identity of the source
(this can happen with probability δ). To capture the behavior under unlikely events, we also
consider the complementary notion of c-prediction uncertainty for c > 0, which is satisﬁed if
for a uniform prior p(I0) on source nodes and any i ∈ {0, ..., n − 1}:

p(I0 6= {i}|S)/p(I0 = {i}|S) ≥ c,

(3)

for any S ⊂ S such that pi(S) > 0. Prediction uncertainty guarantees that no observable
output S (however unlikely) can identify a node as the source with large enough probability:
it ensures that the probability of success of any source location attack is upper bounded
by 1/(1 + c). This holds in particular for the maximum likelihood estimate. Prediction
uncertainty does not have the robustness of diﬀerential privacy against background knowledge,
as it assumes a uniform prior on the source. While it can be shown that ((cid:15), 0)-DP with (cid:15) > 0
implies prediction uncertainty, the converse is not true. Indeed, prediction uncertainty is

8

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

satisﬁed as soon as no output identiﬁes any node with enough probability, without necessarily
making all pairs of nodes indistinguishable as required by DP. We will see that prediction
uncertainty allows to rule out some naive protocols that have nonzero probability of generating
sequences which reveal the source with certainty.

Thanks to the symmetry of our problem, we consider without loss of generality that node
0 starts the rumor (I0 = {0}) and therefore we will only need to verify Equations (2) and (3)
for i = 0 and j = 1.

4

Extreme Privacy Cases

In this section, we study the fundamental limits of gossip in terms of privacy. To do so, we
parameterize gossip protocols by a muting parameter s ∈ [0, 1], as depicted in Algorithm 1.
We thereby capture, within a generic framework, a large family of protocols that ﬁt Deﬁnition 1
and work as follows. They maintain a set A of active nodes (initialized to the source node)
which spread the rumor asynchronously and in parallel: this is modeled by the fact that at
each step of the protocol, a randomly selected node i ∈ A invokes the tell_gossip primitive
to send the rumor to another node (which in turn becomes active), while i also stays active
with probability s. This is illustrated in Figure 1. The muting parameter s can be viewed
as a randomized version of fanout in [34].1 Algorithm 1 follows the population protocol
model [21], and is also related to the SIS epidemic model [9] but in which the rumor never
dies regardless of the value of s ∈ [0, 1] (there always remain some active nodes). Although
we present it from a centralized perspective, we emphasize that Algorithm 1 is asynchronous
and can be implemented by having active nodes wake up following a Poisson process.

In the rest of this section, we show that extreme privacy guarantees are obtained for

extreme values of the muting parameter s.

4.1 Standard Push has Minimal Privacy

The natural case to study ﬁrst in our framework is when the muting parameter is set to s = 1:
this corresponds to the standard push protocol [2] in which nodes always keep emitting after
they receive the rumor. Theorem 4 shows that, surprisingly, the privacy guarantees of this
protocol become arbitrarily bad as the size of the graph increases (keeping the fraction of
curious nodes constant).

(cid:73) Theorem 4 (Standard push is not diﬀerentially private). If Algorithm 1 with s = 1 guarantees
((cid:15), δ)-DP for all values of n and constant (cid:15) < ∞, then δ = 1.

This result may seem counter-intuitive at ﬁrst since one could expect that it would be
more and more diﬃcult to locate the source when the size of the graph increases. Yet, since
the ratio of curious nodes is kept constant, this result comes from the fact that the event
{td(0) ≤ ti(1)} (node 0 communicates with a curious node before node 1 gets the message)
becomes more and more likely as n grows, hence preventing any meaningful diﬀerential
privacy guarantee when n is large enough. The proof is in Appendix C.1. Theorem 4 clearly
highlights the fact that the standard gossip protocol (s = 1) is not diﬀerentially private in
general. We now turn to the other extreme case, where the muting parameter s = 0.

1 Unlike in the classic fanout, nodes start to gossip again each time they receive a message instead of

deactivating permanently.

A. Bellet, R. Guerraoui and H. Hendrikx

9

Algorithm 1 Parameterized Gossip

Require: n {Number of nodes}, k {Source
node}, s {Probability for a node to remain
active}

Ensure: I = {0, . . . , n − 1} {All nodes are

informed}

Sample i uniformly at random from A

1: I ← {k}, A ← {k}
2: while |I| < n do
3:
4: A ← A \ {i} with probability 1 − s
5:
6: end while

j, I ← tell_gossip(i, I), A ← A ∪ {j}

Figure 1 Left: Parameterized Gossip. Right: Illustration of the role of muting parameter s. S
indicates the source and C a curious node. Green nodes know the rumor, and red circled nodes are
active. When s = 0, there is only one active node at a time, which always stops emitting after telling
the gossip. In the case s = 1, nodes always remain active once they know the rumor (this is the
standard push gossip protocol [2]). When 0 < s < 1, each node remains active with probability s
after each communication.

4.2 Muting After Infecting has Maximal Privacy

We now study the privacy guarantees of generic Algorithm 1 when s = 0. In this protocol,
nodes forward the rumor to exactly one random neighbor when they receive it and then
stop emitting until they receive the rumor again. Intuitively, this is good for privacy: the
source changes and it is quickly impossible to recover which node started the gossip (as
initial conditions are quickly forgotten). In fact, once the source tells the rumor once, the
state of the system (the set of active nodes, which in this case is only one node) is completely
independent from the source. A similar idea was used in the protocol introduced in [26].

The following result precisely quantiﬁes the privacy guarantees of Algorithm 1 with
parameter s = 0 and shows that it is optimally private among all gossip protocols (in the
precise sense of Deﬁnition 1).

(cid:73) Theorem 5. Let (cid:15) ≥ 0. For muting parameter s = 0, Algorithm 1 satisﬁes ((cid:15), δ)-diﬀerential
privacy with δ = f
f +1 − 1. Furthermore,
n
these privacy guarantees are optimal among all gossip protocols.

and c-prediction uncertainty with c = n

1 − e(cid:15)−1

(cid:16)

(cid:17)

f

Proof of Theorem 5. We start by proving the fundamental limits on the privacy of any
gossip protocol, and then prove matching guarantees for Algorithm 1 with s = 0.

(Fundamental limits in privacy) Proving a lower bound on the diﬀerential privacy
parameters can be achieved by ﬁnding a set of possible outputs S (here, a set of ordered
Indeed, a direct application of the deﬁnition of
sequences) such that p0(S) ≥ p1(S).
Equation (2) yields that given any gossip protocol, S ⊂ S and w0, w1 ∈ R such that w0 ≤
p0(S) and p1(S) ≤ w1, if the protocol satisﬁes ((cid:15), δ) diﬀerential privacy then δ ≥ w0 − e(cid:15)w1.
The proofs need to consider all the messages sent and then distinguish between the ones that
are disclosed (sent to curious nodes) and the ones that are not.

Since I = {0} then tell_gossip is called for the ﬁrst time by node 0 and it is called
at least once otherwise the protocol terminates with I = {0}, violating the conditions of
Deﬁnition 1. We denote by S(0) the set of output sequences such that S0 = 0 (i.e., 0 is the

step 1step 2step 3step 1step 1step 2step 210

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

ﬁrst to communicate with a curious node). We also deﬁne the event T c
0 = {td(0) 6= 0} (the
source does not send its ﬁrst message to a curious node). For all i /∈ C ∪ {0}, we have that
p0(S0 = i|T c
0 ) since p0(A1 = {0}) = p0(i ∈ A1), where A1 is the set of
active nodes at time 1. From this inequality we get

0 ) ≤ p0(S0 = 0|T c

P

i /∈C p0(S0 = 0|T c

0 ) ≥ P

i /∈C p0(S0 = i|T c

0 ) = 1 ≥ P

i /∈C p0(S0 = 1|T c

0 ),

where the equality comes from the fact that S0 = i for some i /∈ C. The second inequality
0 ) = pj(S0 = k|T c
comes from the fact that pj(S0 = i|T c
0 ) for all i, k 6= j. Therefore, we
0 ) ≤ 1
0 ) ≥ 1
have p0(S0 = 0|T c
n−f . Combining the above expressions, we
derive the probability of S(0) when 0 started the gossip. We write p0(S(0)) = p0(S(0), td(0) =
(cid:0)S(0)|td(0) = 0(cid:1) = 1:
0) + p0(S(0), T c

n−f and p0(S0 = 1|T c

0 ) and then, since p0

(cid:0)S(0)(cid:1) = p0

(cid:0)td(0) = 0(cid:1)p0

(cid:0)S(0)|td(0) = 0(cid:1) + p0

p0

(cid:0)S(0)|T c

0

(cid:1)p0

(cid:0)T c

0

(cid:1) ≥

f
n

+

(cid:16)

1
n − f

1 −

(cid:17)

f
n

In the end, p0(S(0)) ≥ f
n + 1
obtain p1(S(0)|td(0) = 0) = 0 and so p1(S(0)) = p1(T c

n . If node 1 initially has the message, we do the same split and
0 )p1(S(0)|T c

0 ) ≤ 1

n .

The upper bound on prediction uncertainty is derived using the same quantities:

p(I0 6= 0|S(0))
p(I0 = 0|S(0))

=

X

i /∈C∪{0}

pi(S(0))
p0(S(0))

≤ (n − f − 1)

p1(S(0))
p0(S(0))

≤

n − f − 1
f + 1

=

n
f + 1

− 1.

Note that we have never assumed that curious nodes knew how many messages were sent
at a given point in time. We have only bounded the probability that the source is the ﬁrst
node that sends a message to curious nodes.

(Matching guarantees for Algorithm 1 with s = 0) For this protocol, the only

outputs S such that p0(S) 6= p1(S) are those in which td(0) = 0 or td(1) = 0. We write:

p0(S0 = 0) = p0(td(0) = 0)p0(S0 = 0|td(0) = 0) + p0(T c

0 )p0(S0 = 0|T c

0 ).

0 ) = 1

For any i /∈ C where C is the set of curious nodes, we have that p0(S0 = 0|T c
0 ) = p0(S0 =
i|T c
n−f . Indeed, given that td(0) 6= 0, the node that receives the ﬁrst message is selected
uniformly at random among non-curious nodes, and has the same probability to disclose the
gossip at future rounds. Plugging into the previous equation, we obtain:

p0(S0 = 0) =

f
n

(cid:16)

1 −

+

f
n

(cid:17) 1

n − f

=

f + 1
n

.

For any other node i /∈ C ∪ {0}, p0(S0 = i) = p0(T c
n because p0(S0 =
i|td(0) = 0) = 0. Combining these results we get p0(S(0)) ≤ e(cid:15)p1(S(0)) + δ for any (cid:15) > 0 and
δ = f

n (1 − e(cid:15)−1
To prove the prediction uncertainty result, we use the diﬀerential privacy result with

). By symmetry, we make a similar derivation for S(1).

0 )p0(S0 = i|T c

0 ) = 1

f

e(cid:15) = f + 1 (and thus δ = 0) and write that for any S ∈ S:

p(I0 6= 0|S)
p(I0 = 0|S)

=

X

i /∈C∪{0}

pi(S)
p0(S)

≥ (n − f − 1)e−(cid:15) =

n
f + 1

− 1.

(cid:74)

Theorem 5 establishes matching upper and lower bounds on the privacy guarantees of
gossip protocols. More speciﬁcally, it shows that setting the muting parameter to s = 0
provides strong privacy guarantees that are in fact optimal. Note that in the regime where
(cid:15) = 0 (where DP corresponds to the total variation distance), δ cannot be smaller than the

A. Bellet, R. Guerraoui and H. Hendrikx

11

proportion of curious nodes. This is rather intuitive since the source node has probability
at least f /n to send its ﬁrst message to a curious node. However, one can also achieve
diﬀerential privacy with δ much smaller than f /n by trading-oﬀ with (cid:15) > 0. In particular,
the pure version of diﬀerential privacy (δ = 0) is attained for (cid:15) ≈ log f , which provides good
privacy guarantees when the number of curious nodes is not too large. Furthermore, even
though the probability of disclosing some information is of order f /n, prediction uncertainty
guarantee shows that an adversary with uniform prior always has a high probability of
making a mistake when predicting the source. Crucially, these privacy guarantees are made
possible by the natural randomness and partial observability of gossip protocols.
(cid:73) Remark 6 (Special behavior of the source). A subtle but key property of Algorithm 1 is
that the source follows the same behavior as other nodes. To illustrate how violating this
property may give away the source, consider this natural protocol: the source node transmits
the rumor to one random node and stops emitting, then standard push (Algorithm 1 with
s = 1) starts from the node that received the information. While this delayed start gossip
protocol achieves optimal diﬀerential privacy in some regimes, it is fundamentally ﬂawed. In
particular, it does not guarantee prediction uncertainty in the sense that c → 0 as the graph
grows. Indeed, the adversary can identify the source with high probability by detecting
that it communicated only once and then stopped emitting for many rounds. We refer to
Appendix B for the formal proof.

5

Privacy vs. Speed Trade-oﬀs

While choosing s = 0 achieves optimal privacy guarantees, an obvious drawback is that it
leads to a very slow protocol since only one node can transmit the rumor at any given time.
It is easy to see that the number of gossip operations needed to inform all nodes can be
reduced to the time needed for the classical coupon collection problem: it takes O(n log n)
communications to inform all nodes with probability at least 1 − 1/n [35]. As this protocol
performs exactly one communication at any given time, it needs time O(n log n) to inform all
nodes with high probability. This is in stark contrast to the standard push gossip protocol
(s = 1) studied in Section 4.1 where all informed nodes can transmit the rumor in parallel,
requiring only time O(log n) [1].

These observations motivate the exploration of the privacy-speed trade-oﬀ (with parameter
0 < s < 1). We ﬁrst show below that nearly optimal privacy can be achieved for small values
of s. Then, we study the spreading time and show that the O(log n) time of the standard
gossip protocol also holds for s > 0, leading to a sweet spot in the privacy-speed trade-oﬀ.

5.1 Privacy Guarantees

Theorem 7 conveys a (0, δ)-diﬀerential privacy result, which means that apart from some
unlikely outputs that may disclose the identity of the source node, most of these outputs
actually have the same probability regardless of which node triggered the dissemination. We
emphasize that the guarantee we obtain holds for any graph size with ﬁxed proportion f /n
of curious nodes.

(cid:73) Theorem 7 (Privacy guarantees for s < 1). For 0 < s < 1 and any ﬁxed r ∈ N∗, Algorithm 1
with muting parameter s guarantees (0, δ)-diﬀerential privacy with:

δ = 1 − (1 − s)

(cid:19)k+1

∞
X

k=0

(cid:18)

sk

1 −

f
n

≤ 1 − (1 − sr)

(cid:18)

1 −

(cid:19)r

.

f
n

12

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

For example, choosing r = 1 leads to δ ≤ s + (1 − s) f
n , as reported in Table 1. Slightly tighter
bounds can be obtained, but this is enough already to recover optimal guarantees as s → 0.

Proof. We ﬁrst consider that S is such that td(0) ≥ td(1). Then, p0(S) ≤ p1(S) since node
0 needs to receive the rumor before being able to communicate it to curious nodes, and
Equation (2) is veriﬁed. Suppose now that S is such that td(0) ≤ td(1). In this case, we note
tm the ﬁrst time at which the source stops to emit (which happens with probability 1 − s
each time it sends a message). Then, we denote F = {td(0) ≤ tm} (and F c its complement).
In this case, p0(S|F c) ≤ p1(S|F c). Indeed, conditioned on F c, td(0) ≥ ti(0) if node 0 is not
the source and td(0) ≥ max(tm, ti(0)) if it is. Then, we can write:

p0(S) = p0(S, F c) + p0(S, F ) ≤ p1(S, F c) + p0(F ) ≤ p1(S) + p0(F ).

Denoting Tf the number of messages after which the source stops emitting, we write:

p0(F ) =

∞
X

k=1

p0(Tf = k)p0(F |Tf = k) =

∞
X

k=0

(1 − s)sk(cid:16)

1 − (cid:0)1 −

(cid:1)k+1(cid:17)

f
n

, for s > 0.

Note that we can also write for k ≥ 1 that p0(F ) = p0(F, Tf ≤ k) + p0(F, Tf > k), and so:

(cid:16)
p0(F ) ≤ (1 − sk)

1 − (cid:0)1 −

(cid:1)k(cid:17)

f
n

+ sk = 1 − (1 − sk)

(cid:16)

1 −

(cid:17)k

.

f
n

(cid:74)

The diﬀerential privacy guarantees given by Theorem 7 and the optimal guarantees of
Theorem 5 are of the same order of magnitude when s is of order f /n. Indeed, consider
(cid:15) = 0. Then, setting r = 1 in Theorem 7 leads to an additive gap of s(1 − f /n) between
the privacy of Algorithm 1 and the optimal guarantee, showing that one can be as close as
desired to the optimal privacy as long as s is chosen close enough to 0. In particular, the
ratio between the privacy of Algorithm 1 and the lower bound is less than 2 for all s ≤ f /n.
This indicates that the privacy guarantees are very tight in this regime. We also recover
exactly the optimal guarantee of Theorem 5 in the case s = 0 (without the ability to control
the trade-oﬀ between (cid:15) and δ). Importantly, we also show that Algorithm 1 with s < 1
satisﬁes prediction uncertainty, unlike the case where s = 1.

(cid:73) Theorem 8. Algorithm 1 guarantees prediction uncertainty with c = (1 − f +1

n )(1 − s).

This result is another evidence that picking s < 1 allows to derive meaningful privacy

guarantees. The proof can be found in Appendix C.1.

5.2 Spreading time

We have shown that parameter s has a signiﬁcant impact on privacy, from optimal (s = 0)
to very weak (s = 1) guarantees. Yet, s also impacts the spreading time: the larger s, the
more active nodes at each round. This is highlighted by the two extreme cases, for which the
spreading time is already known and exhibits a large gap: O(log n) for s = 1 and O(n log n)
for s = 0. To establish whether we can obtain a protocol that is both private and fast, we
need to characterize the spreading time for the cases where 0 < s < 1.

The key result of this section is to prove that the logarithmic speed of the standard push
gossip protocol holds more generally for all s > 0. This result is derived from the fact that
the ability to forget does not prevent an exponential growth phase. What changes is that
the population of active nodes takes approximately 1/s rounds to double instead of 1 for
standard gossip. For ease of presentation, we state below the result for the synchronous

A. Bellet, R. Guerraoui and H. Hendrikx

13

(a) Fraction of informed nodes

(b) Fraction of active nodes

Figure 2 Eﬀect of parameter s of Algorithm 1 on the spreading time for a network of n = 216
nodes. The curves represent median values and the shaded area represents the 10 and 90 percent
conﬁdence intervals over 100 runs. Each curve stops when all nodes are informed (and so the protocol
terminates), except for s = 0 since the protocol is very slow in this case.

version of Algorithm 1, in which the notion of round corresponds to iterating over the full
set A. A similar result (with an appropriate notion of rounds) can be obtained for the
asynchronous version given in Algorithm 1.

(cid:73) Theorem 9. For a given s > 0 and for all 1 > δ > 0 and C ≥ 1, there exists n large
enough such that the synchronous version of Algorithm 1 with parameter s sends at least
Cn log n messages in 6C log(n)/s rounds with probability at least 1 − δ.

Proof sketch. The key argument of the proof is that the gossip process very closely follows
its mean dynamics. After a transition phase of a logarithmic number of rounds, a constant
fraction of the nodes (depending on s) remains active despite the probability to stop emitting
after each communication. This “determinism of gossip process" has been introduced in [36],
but their analysis only deals with the case s = 1. Our proof takes into account the nontrivial
impact of nodes deactivation in the exponential and linear growth phase. Besides, we need
to introduce and analyze a last phase, showing that with high probability the population
never drops below a critical threshold of active nodes. The full proof is in Appendix C.2. (cid:74)

Theorem 9 shows that generic gossip with s > 0 still achieves a logarithmic spreading
time even though nodes can stop transmitting the message. The 1/s dependence is intuitive
since 1/s rounds are needed in expectation to double the population of active nodes (without
taking collisions into account). Therefore, the exponential growth phase which usually takes
time O(log n) now takes time O(log(n)/s) for s < 1. To summarize, we have shown that one
can achieve both fast spreading and near-optimal privacy, leading to the values presented in
Table 1 of the introduction.

6

Empirical Evaluation

In this section, we evaluate the practical impact of s on the spreading time as well as on the
robustness to source location attacks run by adversaries with background knowledge.

14

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

(a) Attack precision under prior information on
the source

(b) Attack precision when the source spreads
multiple rumors

Figure 3 Eﬀect of parameter s of Algorithm 1 on the precision of source location attacks for a
network of n = 216 node with 10% of curious nodes. Precision is estimated over 15,000 random runs.

6.1 Spreading Time

To complement Theorem 9, which proves logarithmic spreading time (asymptotic in n), we
run simulations on a network of size n = 216. The logarithmic spreading time for s > 0 is
clearly visible in Figure 2a, where we see that the gossip spreads almost as fast for s = 0.5
that it does for s = 1. We also observe that even when s is small, the gossip remains
much faster than for s = 0. The results in Figure 2b illustrate that the fraction of active
nodes grows exponentially fast for all values of s > 0 and then reaches a plateau when the
probability of creating a new active node is compensated by the probability of informing an
already active node. Empirically, this happens when the fraction of active nodes is of order s.
We note incidentally that gossip protocols are often praised for their robustness to lost
messages [37, 38]. While the protocol with s = 0 does not tolerate a single lost message,
setting s > 0 improve the resilience thanks to the linear proportion of active nodes. The
latter property makes it unlikely that the protocol stops because of lost messages as long as
s is larger than the probability of losing messages. Of course, the protocol remains somewhat
sensitive to messages lost during the ﬁrst few steps.

6.2 Robustness Against Source Location Attacks

Getting an intuitive understanding of the privacy guarantees provided by Theorem 7 is not
straightforward, as often the case with diﬀerential privacy. Therefore, we illustrate the eﬀect
of the muting parameter on the guarantees of our gossip protocol by simulating concrete
source location attacks. We consider two challenging scenarios where the adversary has some
background knowledge: either 1) prior knowledge that the source belongs to a subset of the
nodes, or 2) side information indicating that the same source disseminates multiple rumors.

Prior knowledge on the source. We ﬁrst consider the case where the adversary is able
to narrow down the set of suspected nodes. In this case we can design a provably optimal
attack, as shown by the following theorem (see Appendix C.3 for the proof).

(cid:73) Theorem 10. If the adversary has a uniform prior over a subset P of nodes, i.e., p(I0 =
i) = p(I0 = j) for all i, j ∈ P and p(I0 = i) = 0 for i /∈ P , and for some output sequence S,
tc is such that Stc ∈ P and St /∈ P if t < tc , then p(I0 = Stc|S) ≥ p(I0 = i|S) for all i.

A. Bellet, R. Guerraoui and H. Hendrikx

15

Theorem 10 means that under a uniform prior over nodes in P , the attack in which curious
nodes predict the source to be the ﬁrst node in P that communicates with them corresponds
to the Maximum A Posteriori (MAP) estimator. The set P represents the prior knowledge
of the adversary: he knows for sure that the source belongs to P .

Figure 3a shows the precision of this attack as a function of s for varying degrees of
prior knowledge. We see that, when s is small, the prior knowledge does not improve the
attack precision signiﬁcantly, and that the precision remains very close to the probability that
the source sends its ﬁrst message to a curious node. This robustness to prior knowledge is
consistent with the properties of diﬀerential privacy (see Section 2.3). On the contrary, when
s is high (i.e., diﬀerential privacy guarantees are weak), the impact of the prior knowledge
on the precision of the attack is much stronger.

Multiple dissemination. We investigate another scenario in which diﬀerential privacy
guarantees can also provide robustness, namely when the adversary knows that the same
source node disseminates multiple rumors. In this setting, analytically deriving an optimal
attack is very diﬃcult. Instead, we design an attack which leverages the fact that even
though the source is not always the ﬁrst node to communicate with curious nodes, with high
probability it will be among the ﬁrst to do so. More precisely, the curious nodes record the
10 ﬁrst nodes that communicate with them in each instance (results are not very sensitive to
this choice), and they predict the source to be the node that appears in the largest number
of instances. In case of a tie, the curious nodes choose the node that ﬁrst communicated
with them, with ties broken at random. Figure 3b shows that the precision of this attack
increases dramatically with the number of rumors when s is large, reaching almost sure
detection for 10 rumors. Remarkably, for small values of s, the attack precision increases
much more gracefully with the number of rumors, as expected from the composition property
of diﬀerential privacy discussed in Section 2.3. Meaningful privacy guarantees can still be
achieved as long as the source does not spread too many rumors.

7

Concluding Remarks

This paper initiates the formal study of privacy in gossip protocols to determine to which
extent the source of a gossip can be traceable. Essentially: (1) We propose a formal model
of anonymity in gossip protocols based on an adaptation of diﬀerential privacy; (2) We
establish tight bounds on the privacy of gossip protocols, highlighting their natural privacy
guarantees; (3) We precisely capture the trade-oﬀ between privacy and speed, showing in
particular that it is possible to design both fast and near-optimally private gossip protocols;
(4) We experimentally evaluate the speed of our protocols as well as their robustness to
source location attacks, validating the relevance of our formal diﬀerential privacy guarantees
in scenarios where the adversary has some background knowledge.

Our work opens several interesting perspectives. In particular, it paves the way to the
study of diﬀerential privacy for gossip protocols in general graphs, which is challenging and
requires relaxations of diﬀerential privacy in order to obtain nontrivial guarantees. We refer
to Appendix D for a discussion of these questions. Another avenue for future research is
motivated by very recent work showing that hiding the source of a message can amplify
diﬀerential privacy guarantees for the content of the message [39, 40, 41]. Unfortunately,
classic primitives to hide the source of messages such as mixnets can be diﬃcult and costly
to deploy. Showing that gossip protocols can naturally amplify diﬀerential privacy for the
message contents would make them very desirable for privacy-preserving distributed AI
applications, such as those based on federated [23] and decentralized machine learning [42].

16

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

References

1 A. M. Frieze and G. R. Grimmett, “The shortest-path problem for graphs with random

2

arc-lengths,” Discrete Applied Mathematics, vol. 10, no. 1, pp. 57–77, 1985.
B. Pittel, “On spreading a rumor,” SIAM Journal on Applied Mathematics, vol. 47, no. 1, pp.
213–223, 1987.

3 R. Karp, C. Schindelhauer, S. Shenker, and B. Vocking, “Randomized rumor spreading,” in

4

FOCS, 2000.
P. Berenbrink, J. Czyzowicz, R. Elsässer, and L. Gasieniec, “Eﬃcient information exchange in
the random phone-call model,” Automata, Languages and Programming, 2010.

5 A. Demers, D. Greene, C. Hauser, W. Irish, J. Larson, S. Shenker, H. Sturgis, D. Swinehart,

6

7

and D. Terry, “Epidemic algorithms for replicated database maintenance,” in PODC, 1987.
S. Boyd, A. Ghosh, B. Prabhakar, and D. Shah, “Randomized gossip algorithms,” IEEE
Transactions on Information Theory, vol. 52, no. 6, pp. 2508–2530, 2006.
B. Doerr, M. Fouz, and T. Friedrich, “Social networks spread rumors in sublogarithmic time,”
in STOC, 2011.

8 G. Giakkoupis, R. Guerraoui, A. Jégou, A.-M. Kermarrec, and N. Mittal, “Privacy-conscious
information diﬀusion in social networks,” in International Symposium on Distributed Computing.
Springer, 2015, pp. 480–496.

9 H. W. Hethcote, “The mathematics of infectious diseases,” SIAM Review, vol. 42, no. 4, pp.

10

11

12

599–653, 2000.
J. C. Duchi, A. Agarwal, and M. J. Wainwright, “Dual Averaging for Distributed Optimization:
Convergence Analysis and Network Scaling,” IEEE Transactions on Automatic Control, vol. 57,
no. 3, pp. 592–606, 2012.
I. Colin, A. Bellet, J. Salmon, and S. Clémençon, “Gossip dual averaging for decentralized
optimization of pairwise functions,” in ICML, 2016.
P. Vanhaesebrouck, A. Bellet, and M. Tommasi, “Decentralized collaborative learning of
personalized models over networks,” in AISTATS, 2017.

13 A. Koloskova, S. Stich, and M. Jaggi, “Decentralized Stochastic Optimization and Gossip

Algorithms with Compressed Communication,” in ICML, 2019.

14 M. Ghaﬀari and C. Newport, “How to discreetly spread a rumor in a crowd,” in DISC, 2016.
J. Jiang, S. Wen, S. Yu, Y. Xiang, and W. Zhou, “Identifying propagation sources in networks:
15
State-of-the-art and comparative studies,” IEEE Communications Surveys & Tutorials, vol. 19,
no. 1, pp. 465–481, 2017.
P. C. Pinto, P. Thiran, and M. Vetterli, “Locating the source of diﬀusion in large-scale
networks,” Physical Review Letters, 2012.

16

17 D. Shah and T. Zaman, “Rumors in a network: Who’s the culprit?” IEEE Transactions on

Information Theory, 2011.

18 C. Dwork, “Diﬀerential Privacy,” in ICALP, 2006.
19 C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and M. Naor, “Our data, ourselves:

Privacy via distributed noise generation,” in EUROCRYPT, 2006.

20 C. Dwork and A. Roth, “The algorithmic foundations of diﬀerential privacy,” Foundations

and Trends in Theoretical Computer Science, vol. 9, no. 3–4, pp. 211–407, 2014.

21 D. Angluin, J. Aspnes, and D. Eisenstat, “Fast computation by population protocols with a

leader,” Distributed Computing, vol. 21, no. 3, pp. 183–199, 2008.

22 D. Kempe, A. Dobra, and J. Gehrke, “Gossip-Based Computation of Aggregate Information,”

23

in FOCS, 2003.
P. Kairouz, H. B. McMahan, B. Avent, A. Bellet, M. Bennis, A. N. Bhagoji, K. Bonawitz,
Z. Charles, G. Cormode, R. Cummings, R. G. L. D’Oliveira, S. E. Rouayheb, D. Evans,
J. Gardner, Z. Garrett, A. Gascón, B. Ghazi, P. B. Gibbons, M. Gruteser, Z. Harchaoui, C. He,
L. He, Z. Huo, B. Hutchinson, J. Hsu, M. Jaggi, T. Javidi, G. Joshi, M. Khodak, J. Konečný,
A. Korolova, F. Koushanfar, S. Koyejo, T. Lepoint, Y. Liu, P. Mittal, M. Mohri, R. Nock,
A. Özgür, R. Pagh, M. Raykova, H. Qi, D. Ramage, R. Raskar, D. Song, W. Song, S. U. Stich,

A. Bellet, R. Guerraoui and H. Hendrikx

17

Z. Sun, A. T. Suresh, F. Tramèr, P. Vepakomma, J. Wang, L. Xiong, Z. Xu, Q. Yang, F. X. Yu,
H. Yu, and S. Zhao, “Advances and Open Problems in Federated Learning,” arXiv:1912.04977,
Tech. Rep., 2019.

24 D. R. Kowalski and C. T. Caro, “Estimating time complexity of rumor spreading in ad-hoc
networks,” in International Conference on Ad-Hoc Networks and Wireless. Springer, 2013,
pp. 245–256.

25 H. Acan, A. Collevecchio, A. Mehrabian, and N. Wormald, “On the push&pull protocol for
rumor spreading,” SIAM Journal on Discrete Mathematics, vol. 31, no. 2, pp. 647–668, 2017.
26 G. Fanti, P. Kairouz, S. Oh, K. Ramchandran, and P. Viswanath, “Hiding the rumor source,”

IEEE Transactions on Information Theory, 2017.

27 C. Georgiou, S. Gilbert, and D. R. Kowalski, “Conﬁdential gossip,” in ICDCS, 2011.
28 K. Gotfryd, M. Klonowski, and D. Pajak, “On location hiding in distributed systems,” in
International Colloquium on Structural Information and Communication Complexity. Springer,
2017, pp. 174–192.

29 W. Lu and G. Miklau, “Exponential random graph estimation under diﬀerential privacy,” in

KDD, 2014.

30 H. Sun, X. Xiao, I. Khalil, Y. Yang, Z. Qin, H. Wang, and T. Yu, “Analyzing subgraph

31

statistics from extended local views with decentralized diﬀerential privacy,” in CCS, 2019.
Z. Huang and J. Liu, “Optimal diﬀerentially private algorithms for k-means clustering,” in
PODS, 2018.

32 K. Chaudhuri, C. Monteleoni, and A. D. Sarwate, “Diﬀerentially Private Empirical Risk

Minimization,” Journal of Machine Learning Research, vol. 12, pp. 1069–1109, 2011.

33 M. Abadi, A. Chu, I. J. Goodfellow, H. B. McMahan, I. Mironov, K. Talwar, and L. Zhang,

34

35

36

“Deep learning with diﬀerential privacy,” in CCS, 2016.
P. T. Eugster, R. Guerraoui, A.-M. Kermarrec, and L. Massoulié, “Epidemic information
dissemination in distributed systems,” Computer, vol. 37, no. 5, pp. 60–67, 2004.
P. Erdős and A. Rényi, “On a classical problem of probability theory,” Publ. Math. Inst. Hung.
Acad. Sci., 1961.
S. Sanghavi, B. Hajek, and L. Massoulié, “Gossiping with multiple messages,” IEEE Transac-
tions on Information Theory, vol. 53, no. 12, pp. 4640–4654, 2007.

37 D. Alistarh, S. Gilbert, R. Guerraoui, and M. Zadimoghaddam, “How eﬃcient can gossip

be?(on the cost of resilient information exchange),” in ICALP, 2010.

38 C. Georgiou, S. Gilbert, R. Guerraoui, and D. R. Kowalski, “Asynchronous gossip,” Journal

of the ACM, vol. 60, no. 2, p. 11, 2013.

39 U. Erlingsson, V. Feldman, I. Mironov, and A. R. abd Kunal Talwar, “Ampliﬁcation by
Shuﬄing: From Local to Central Diﬀerential Privacy via Anonymity,” arXiv:1811.12469, Tech.
Rep., 2018.

40 A. Cheu, A. D. Smith, J. Ullman, D. Zeber, and M. Zhilyaev, “Distributed Diﬀerential Privacy

via Shuﬄing,” arXiv:1808.01394, Tech. Rep., 2018.

41 B. Balle, J. Bell, A. Gascon, and K. Nissim, “The Privacy Blanket of the Shuﬄe Model,”

arXiv:1903.02837, Tech. Rep., 2019.

42 A. Bellet, R. Guerraoui, M. Taziki, and M. Tommasi, “Personalized and Private Peer-to-Peer

Machine Learning,” in AISTATS, 2018.

43 G. Giakkoupis, Y. Nazari, and P. Woelfel, “How asynchrony aﬀects rumor spreading time,” in

PODC, 2016.

44 R. Arratia and L. Gordon, “Tutorial on large deviations for the binomial distribution,” Bulletin

of mathematical biology, vol. 51, no. 1, pp. 125–131, 1989.

45 M. Mitzenmacher and E. Upfal, Probability and computing: Randomized algorithms and

probabilistic analysis. Cambridge University Press, 2005.

46 D. Kifer and A. Machanavajjhala, “Puﬀerﬁsh: A framework for mathematical privacy deﬁni-

tions,” ACM Transactions on Database Systems, vol. 39, no. 1, p. 3, 2014.

18

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

47 M. E. Andrés, N. E. Bordenabe, K. Chatzikokolakis, and C. Palamidessi, “Geo-

indistinguishability: diﬀerential privacy for location-based systems,” in CCS, 2013.

48 K. Chatzikokolakis, M. E. Andrés, N. E. Bordenabe, and C. Palamidessi, “Broadening the

Scope of Diﬀerential Privacy Using Metrics,” in PETS, 2013.

A. Bellet, R. Guerraoui and H. Hendrikx

19

A Model Extensions

We kept our model relatively simple in the main paper to avoid unnecessary complexity in
the notations and additional technicalities in the derivation and presentation of our results.
In this appendix, we brieﬂy discuss various possible extensions. Basically, we make here the
point that, although these generally lead to technical complications, they do not signiﬁcantly
impact privacy guarantees.

A.1 Pull and Push-Pull Protocols

Our study focus on the classic push form of gossip protocols. This can be justiﬁed by the fact
that, for regular graphs, synchronous push has asymptotic spreading time guarantees that
are comparable with the push-pull variant [43]. Besides, the diﬀerential privacy guarantees
of any gossip protocol are limited by the probability that the ﬁrst node informed by the
source is a curious node, and we show this bound can be matched with push protocols.
Nevertheless, extensions of our results to pull and push-pull variants of gossip protocols [3]
are possible. Forgetting mechanisms similar to the ones in Algorithm 1 can be introduced for
these protocols, i.e. nodes would have a probability 1 − s to stop disclosing information after
each time they are pulled (if they do not pull someone with the information in between).
Although slightly diﬀerent, the optimal privacy guarantees would remain of the same order
of magnitude. Yet, we expect pull guarantees to be even worse in the case s = 1 because
curious nodes could stop suspecting all nodes that they have pulled and that did not have the
rumor. Besides, the pull protocol for s = 0 would be even slower than its push counterpart.

A.2 Eavesdropping Adversary

Since we consider a complete graph, our formalization of the adversary as a fraction f /n
of curious nodes is closely related to an eavesdropping adversary who would observe each
communication with probability f /n. Indeed, both models consider that each communication
has a probability f /n of being disclosed to the adversary. Most of our results are thus easily
transferable to this alternative setting. The only diﬀerence would be that all nodes can be
suspected in the eavesdropping model, thus introducing a (1 − f /n)−1 factor each time we
consider the population of non-curious nodes.

A.3 Information Observed by the Adversary

We discuss three possible variants of the output observed by the adversary.

A.3.1 Messages Sent by Curious Nodes

For simplicity of exposition, we considered that curious nodes only observe messages that
are sent to them and not the messages that they send. However, including the messages sent
by curious nodes in their observed output would not impact the bounds on privacy (i.e., the
guarantees for the algorithms). For the optimal algorithm, we only consider what happens
during the ﬁrst round, so including the messages sent by curious nodes does not change the
result. This in particular implies that the fundamental limits of Theorem 5 remain the same
(since the adversary observes strictly more information). Similarly, for the parameterized
algorithm, Theorem 7 is obtained by bounding the probability of a set ˆS. Then, we have
p( ˆS, Sout) ≤ p( ˆS) where Sout is the sequence of messages sent by the curious nodes. In

20

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

general, adding the messages sent by curious nodes to the output sequences has little or no
impact on our results.

A.3.2 Message Ordering

We assumed that the relative order of messages is preserved in the output sequence observed
by curious nodes. This could be relaxed, as in real-world networks a message sent before
another may well be received after it. One could for instance introduce a random swapping
model to take this into account and investigate whether this weaker output leads to an
improvement in the privacy guarantees. However, we argue that this improvement would be
quite limited. First of all, it would not aﬀect the privacy guarantees of the optimal protocol:
since there is a single active node able to send a message at any given time, swapping is not
possible. Therefore, the lower bound and the matching algorithm would not be aﬀected by
this change. Since parameterized gossip is almost privacy-optimal for small values of s and
swapping would only increase privacy, then we argue that the guarantees of parameterized
gossip would be very similar in this case. Furthermore, even when several nodes are active
at the same time (e.g., in Algorithm 1 large s), the proofs can be adapted to work with
counting the messages received instead of the messages sent. In this case, swapping is as
likely to expose the source (making its messages arrive earlier) than to hide it (delaying the
messages it sends).

A.3.3 Global Timing

In our model, we assume that curious nodes only have access to the relative ordering in
which they received the messages but they have no information on the global time at which
it was sent. This is justiﬁed in practice by the asynchrony and locality of the exchanges.
We brieﬂy discuss here how the privacy guarantees are aﬀected if one considers a stronger
adversary that has access to the number of times the tell_gossip procedure has been called.
Formally, this adversary observes the set S = {(t, i, j)|(i, j) = (Somni)t, j ∈ C}. This set can
be turned into a sequence by ordering it by increasing values of t. Note that this is not a
realistic adversary as gossip protocols naturally enforce partial observability of the events.
The following result quantiﬁes the limits of privacy for this stronger adversary, which can
be compared to the results of Theorem 5 in the main text. We can see that in the regime
(cid:15) = 0 (total variation distance), the limits remain the same. However, achieving δ < f /n
and prediction uncertainty is not possible against this stronger adversary. Note also that
Algorithm 1 with s = 0 remains optimal.

(cid:73) Theorem 11. If a gossip protocol satisﬁes ((cid:15), δ)-diﬀerential privacy and c-prediction
uncertainty then we have δ ≥ f
n and c = 0 in the strong adversary setting. Furthermore,
these bounds are tight and matched by Algorithm 1 when its parameter is set to s = 0.

Proof. The fact that tell_gossip is called at least once and is ﬁrst called on node 0 still
holds. Sequence S(0) now denotes the fact that node 0 communicates with a curious node at
time 0. Since the protocol is run on the complete graph, the node selected by tell_gossip
is chosen uniformly within {0, ..., n − 1}, so a curious node is selected with probability f
n .
We thus have p0(S(0)) = f
n . Besides, node 0 cannot communicate with a curious node at
time 0 if node 1 starts the rumor so p1(S(0)) = 0. For prediction uncertainty, using the same
sequence S(0) yields pi(S(0))

p0(S(0)) = 0 for all i 6= 0 and therefore c = 0.

It remains to show that these bounds are matched by Algorithm 1 with s = 0. The fact that
the only outputs that have a diﬀerent probability if node 0 starts (compared to the case when 1

A. Bellet, R. Guerraoui and H. Hendrikx

21

starts) are those in which 0 (or 1) communicates with a curious node for its ﬁrst communication
is still true with the stronger adversary. Then, we write p0(S0 = 0) = p1(S0 = 1) = f
n and
p0(S0 = 1) = p1(S0 = 0) = 0. This ensures that p0(S(0)) ≤ p1(S(0)) + f
n (similarly for S(1)),
(cid:74)
and the result follows.

A.4 Malicious Behavior

We also assumed for simplicity that nodes are curious but not malicious, i.e., they follow
the protocol. This is motivated by a practical scenario where a subset of nodes are simply
being monitored by a curious entity. If curious nodes can also act maliciously, they have
three possible ways to aﬀect the protocol (abstracting away the content of the information):
emitting more, emitting less, or not choosing neighbors uniformly at random. If they emit
more, they will inform more nodes, which makes it more diﬃcult for them to locate the
source. If they emit less (potentially not at all), then in the case s < 1, the protocol could
stop before all nodes are informed. Yet, the privacy bounds are derived from the fact that
the source forgets the information before communicating to a curious node. Choosing the
neighbors they send the messages to reduces to the case in which they emit less (for they do
not send messages to uninformed nodes) but without aﬀecting protocol speed or termination
(this does not reduce the number of active nodes). Thus, the impact on the observed output
and therefore on the privacy would be minimal. In the case s = 1, malicious nodes have
slightly more impact but remain quite small: this case only makes the set of informed nodes
grow slightly slower.

A.5 Termination Criterion

For simplicity, in all our gossip protocols we used a global termination criterion (the protocol
terminates when all nodes are informed). Termination without using global coordination is a
problem in its own right that has been extensively studied (see for instance [3]). Although
some termination criteria could have a great impact on privacy, we argue that termination
can be handled late in the execution so as to reveal very little about the beginning, hence
avoiding any signiﬁcant impact on privacy. For instance, it is possible to design a variant of
Algorithm 1 in which nodes only ﬂip a coin with probability s for a ﬁxed number of times,
and then stop emitting completely. This ﬁxed number would have to depend on s, but then
if it is large enough, it would guarantee both termination and privacy. Indeed, nodes would
not communicate with curious nodes each time they are activated with high probability so
this counter would actually provide very little information to the curious nodes. Determining
how large this number of iterations should be, and the exact impact on privacy (which we
argue is very small), is beyond the scope of this paper.

B Delayed Start Gossip

Consider the protocol described in Remark 6, which we call delayed start gossip:
1. The source calls tell_gossip once to forward to an arbitrary node, say node j.
2. Node j then starts a standard push protocol (Algorithm 1 with s = 1).

This simple protocol is clearly optimal from the point of view of diﬀerential privacy in
the regime (cid:15) = 0 (total variation distance). Indeed, if the ﬁrst communication does not hit a
curious node then the probability of a given output when two diﬀerent nodes start the gossip
is the same. It is also fast since it runs the standard gossip after the ﬁrst round.

22

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

Yet, this naive protocol has a major ﬂaw. Indeed, when the ﬁrst communication hits
a curious node, the adversary can monitor whether the sender communicates with curious
nodes again in the next rounds. If it does not, they can guess that the node is the source,
and they will in fact make a correct guess with probability arbitrarily close to 1 for large
enough graphs. On the other hand, when the sender communicates again with a curious
node shortly after, they can be very conﬁdent that this node is not the source. Hence, it is
possible to design a very simple attack with a very high precision (almost always right) and
almost optimal recall (identifying the source with certainty every time the information is
actually released, i.e. with probability f

n ).

Making sure that the adversary is uncertain about its prediction is therefore a desirable
property. This is captured by our notion of prediction uncertainty. The following proposition
formalizes the above claims.

(cid:73) Proposition 12. We call cds the prediction uncertainty constant of the delayed start protocol
and we assume the ratio of curious nodes f /n to be constant. Then cds → 0 when n → ∞.

More generally, it is in principle possible to prove similar results for any protocol in which
the source node does not behave like other nodes. Indeed, if the special behaviour can be
detected, then the adversary can know for sure the source of the rumor. This motivates the
need for more involved protocols such as those covered by Algorithm 1.

r

Proof of Proposition 12. The proof reuses some elements of the proof of Theorem 4. We
consider the sequence S(0)
such that node 0 is the ﬁrst node to communicate with a curious
node (S0 = 0) and then r other nodes communicate with curious nodes before 0 does (Si 6= 0
for i ∈ {1, ..., r}). We denote by t0 the time at which node 0 gets the message and becomes
active again (we refer here to the global order, although of course the curious nodes do not
have access to it). Then, with the usual notations we have:

(cid:17)

(cid:16)

S(0)
r

p0

= p0(S0 = 0)p0

(cid:16)

S(0)
r

(cid:17)

|S0 = 0

≥

≥

≥

f
n
f
n
f
n

p0 (∩r

i=1Si 6= 0|S0 = 0)

p0(t0 ≥ r)

p0(nc(r) ≤ k∗)p0(t0 ≥ r|nc(r) ≤ k∗).

Then, we recall from the proof of Theorem 4 that

p0(nc(r) ≤ k) = p

(cid:18)

(cid:18)

Binom(k,

(cid:19)

) ≥ r

f
n

= p

Binom(k, 1 −

(cid:19)

) < k − r

f
n

(cid:18)

= 1 − p

Binom(k, 1 −

(cid:19)

) ≥ k − r

,

f
n

so if we set k = 2n
there exists a constant H (only depending on f /n) such that p0(nc(r) ≤ r 2n
Therefore, we have:

f r and use tail bounds on the binomial law (Theorem 1 of [44]) then
f ) ≥ 1 − e−rH .

(cid:17)

(cid:16)

S(0)
r

p0

≥

f
n

(cid:0)1 − e−rH (cid:1)

(cid:19)r 2f

n

(cid:18)

1 −

1
n

≥ C1(r, n).

(4)

A. Bellet, R. Guerraoui and H. Hendrikx

23

The last line comes from calculations done in the proof of Theorem 4. We now study p1(S(0)
r ).
Since node 1 started the protocol then it means that no other node (and in particular 0) will
stop emitting the message. Therefore, if node 0 is the ﬁrst to communicate with a curious
node then it will remain active for the whole duration of the protocol. Consider that the
ﬁrst disclosure happens after Tf communications. We can write:

(cid:17)

(cid:16)

S(0)
r

p1

≤ p1(S0 = 0)p1 (∩r

i=1Si 6= 0|S0 = 0, Tf ≤ tf ) + p1(Tf > tf ).

Since the fraction of curious nodes is constant, we can choose tf independently of n or r
in order to control the second

n tf ≤ (cid:15)

(cid:17)

4(n−f ) if tf = n

f log

(cid:16) 4(n−f )
(cid:15)

such that p(Tf > tf ) ≤ e− f
term. Then,

p1 (∩r

i=1Si 6= 0|S0 = 0, Tf ≤ tf ) ≤

tf +r
Y

t=tf

(cid:18)

1 −

(cid:19)

f
n

1
t

− f
n

Ptf +r
t=tf

1

t .

≤ e

A series-integral comparison yields that if r = log2(n) then exp

large enough. Finally, we use the fact that p1(S0 = 0) ≤ 1

Finally, we observe that C1(log2 n, n) → f

In particular, C1(log2 n, n) ≥ f

p(I0 6= 0|S(0)
r )
p(I0 = 0|S(0)
r )

=

X

i /∈C∪{0}

2n for n large enough, so we have
pi(S(0)
r )
p0(S(0)
r )

n
f

≤

(cid:15).

(cid:16)

(cid:17)

4 for n
2(n−f ) .
n when n → ∞ where C1 is deﬁned in Equation 4.

n−f to write that p1

Ptf +r
1
t=tf
t
(cid:16)
S(0)
r

≤ (cid:15)

− f
n

≤ (cid:15)

(cid:17)

(5)

Since (cid:15) can be picked arbitrarily small and n

f is assumed to be constant then the previous
(cid:74)

ratio can be made arbitrary small.

C Detailed Proofs

C.1 Privacy Guarantees

Proof of Theorem 4. Intuitively, the proof relies on the fact that the event {td(0) ≤ ti(1)}
(node 0 communicates with a curious node before node 1 gets the message) becomes more
and more likely as n grows, hence preventing any meaningful diﬀerential privacy guarantee
when n is large enough. To formalize this, we study S(0)
r = {S, St = 0 for some t ≤ r}, the
set of output sequences such that the rank of node 0 in the sequence is less than r. For a
speciﬁc sequence to not be in S(0)
, there must have been at least r communications (because
r nodes must have communicated with curious nodes), and none of them involved 0 and
a curious node. Therefore, if we note nc(r) the number of communications that actually
happened before the output sequence reached size r, we have nc(r) ≥ r. Then, denoting by
C(t) the node that communicated with a curious node at time t (with C(t) = −1 when the
communication did not involve a curious node):

r

p0(S(0)

r ) = 1 − p

(cid:16)

∩nc(r)

(cid:17)
t=0 C(t) 6= 0

= 1 − Qnc(r)

t=0 p (C(t) 6= 0) ≥ 1 − Qr

t=0

(cid:16)
1 − f
n

1
t+1

(cid:17)

,

1

|It| ≥ 1

where the last step comes from the fact that the probability of node 0 to be selected at time t
is
t because at most one node is informed at each step and the active node is selected
uniformly among informed nodes. We use the fact that log(1 + x) ≤ x for any x > −1 on
x = − f
n

(cid:17)

= exp

(cid:16) Pr

t=0 log

(cid:16)

1 − f
n

1
t+1

(cid:17)(cid:17)

≤ exp

(cid:16)

− f
n

Pr

t=0

(cid:17)

.

1
t+1

(6)

1
t+1 to get:
(cid:16)

1 − f
n

1
t+1

Qr

t=0

24

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

Therefore, p0(S(0)
any network size for this result to hold since the ratio f /n is assumed to be constant.

r ) goes to 1 as r goes to inﬁnity. We emphasize that we do not need to ﬁx

n ) is the binomial law of parameters k and f

Then, for a given r and for any k > 0, p(nc(r) ≤ k) is equal to p(Binom(k, f

n ) ≥ r) where
Binom(k, f
n . This is because it is the probability
of having exactly r successes with the sum of less than k Bernoullis of parameter f
n , which
is equal to the probability of having more than r successes with the sum of k Bernoullis of
the same parameters. Therefore, p(nc(r) ≤ k) is independent of n and we can choose k∗
independently of n such that p(nc(r) > k∗) ≤ 1

n . Then, we write that

p1(S(0)

r ) = p1(S(0)

r

, nc(r) ≤ k∗) + p1(S(0)

r

, nc(r) > k∗) ≤ p1(S(0)

r

|nc(r) ≤ k∗) + 1/n.

This implies p1(S(0)
|nc(r) ≤ k∗) ≤ p1(0 ∈ Ir|nc(r) ≤ k∗) ≤ 1 − p1(0 /∈ Ir|nc(r) ≤ k∗). We
know that only r communications have reached curious nodes but the others have reached a
random node in the graph, and there is at most k∗ of them, so ﬁnally:

r

p1(S(0)

r ) ≤ 1 −

(cid:17)k∗

(cid:16)

1 −

1
n

+

1
n

.

We immediately see that p1(S(0)
and we have shown above that p0(S(0)
p0(S(0)

r ) goes to 0 as n grows because k∗ is independent of n,
r ) goes to 1 as n grows. Since we must have that
r ) + δ, we must have δ = 1 if we want δ and (cid:15) to be independent of n. (cid:74)

r ) ≤ e(cid:15)p1(S(0)

Proof of Theorem 8. For any set of sequences S ⊂ S such that p0(S) > 0:

p(I0 6= 0|S)
p(I0 = 0|S)

=

X

i /∈C∪{0}

pi(S)
p0(S)

≥

X

i /∈C∪{0}

pi(A1 = {0})pi(S|A1 = {0})
p0(S)

,

where A1 is the set of active nodes at round 1. Because the state of the system (active nodes)
is the same in both cases we can write that pi(S|A1 = {0}) = p0(S). Besides, pi(A1 = {0})
corresponds to the probability that node i sends a message to node 0 and then stops emitting.
Therefore: p(I06=0|S)
(cid:74)

(1 − s) > 0.

(cid:17)

(cid:16)

p(I0=0|S) ≥

1 − f +1
n

C.2 Spreading time

Proof of Theorem 9. The idea of this proof is to rely on the “determinism” of gossip process,
similarly to [36]. This means that the gossip process very closely follows its mean dynamics.
In our case, there is an added diﬃculty in the fact that extra randomness is introduced by
the deactivation of the nodes. Yet, we precisely quantify the impact of this phenomenon on
the results. We start by showing that if more than k(s) nodes are informed at a given time,
then with very high probability the number of informed nodes never drops below this fraction
once it is reached. Therefore, a number of messages proportional to the size of the graph is
sent at each round. The condition on s for this to happen is written in Equation (11). More
formally, we ﬁx s ∈ (0, 1] and denote by At the number of nodes that are active at round t,
which is such that At = αtn. Then, we note

f : α → 1 − pu(α)(1 − αs),

(7)

n )αn. Note that f (α) = 1

E[At+1|At = αn]. To see this, we count the
where pu(α) = (1 − 1
n
number of active nodes at time t + 1. In total, At = αn messages are sent at the beginning
of the round. Therefore, for each node, the probability of having received a message at the
end of the round is exactly 1 − pu(α) since each message has a 1/n probability to be sent to

A. Bellet, R. Guerraoui and H. Hendrikx

25

this speciﬁc node. In the end, n (1 − pu(α)) nodes get the message in expectation. The rest
of the active nodes at time t + 1 is made of the nodes that were active, did not receive the
message and did not deactivate, which represents a portion nαpu(α)s of the nodes. Then,
one can see that the function f is simply the sum of these 2 terms. We show by using that
(1 − x)y ≤ e−xy ≤ 1 − xy + x2y2
2

that for α ≤ αs = s

1+2s , we have:

f (α) ≥

(cid:16)

1 +

(cid:17)

s
2

α.

(8)

Then, we follow the same steps as in Lemma 15 in [36]. We call At the number of active
nodes at round t, and At,m the number of active nodes at round t after m messages have
been sent (so during the round). Then, we can deﬁne Xi = At,i+1 − At,i. At,i+1 only depends
on At,i and so does Xi:

Xi =

(cid:26) 1

with proba
−1 with proba
0

otherwise

s(1 − |At,i|
n )
(1 − s) |At,i|−1

n

Then, we deﬁne the martingale Zi = E[PAt
At+1 − nf (α) = Z0 − ZAt. If we call Sk,t = PAt

i=1 Xi|X1, · · · , Xi, At]. This allows us to write

i=k Xi then for any d ∈ {−1, 0, 1}:

E[S1,t|X1, , Xi, Xi+1 = 1, At]

≥ E[S1,t|X1, · · · , Xi, Xi+1 = d, At]
≥ E[S1,t|X1, · · · , Xi, Xi+1 = −1, At],

because the distribution of Xi only depends on At,i. Therefore, |Zi+1−Zi| ≤ (1+E[Si+1,t|At+
1]) − (E[Si+1,t|At − 1] − 1)] ≤ 2. Azuma’s inequality [45] then gives:

(cid:18)

p

At+1 − nf (

At
n

) ≤ −λAt|At = k

(cid:19)

≤ e− (λk)2
8k .

(9)

We also have that p(At+1 < k|At ≥ k) ≤ p(At+1 ≤ k|At = k). Then, for any α ≤ αs,
Equation 8 yields that for all λ:

(cid:16)

p

At+1 ≤ At

(cid:16)

1 +

s
2

(cid:17)

(cid:17)

|At

− λ

≤ e− λ2

8 At.

(10)

We can then bound this expression by using Equation 9 with λ = s

2 , leading to

p(At+1 < k|At ≥ k) ≤ e− s2

32 k if α ≤ αs.

Denoting by Nk,j the number of messages sent between rounds k and j, we can decompose
over Cα−1 log n rounds so that if m is such that there are at least α active nodes at round
m then:

p(Nm,m+Cα−1 log n ≥ Cn log n) ≥ (1 − e− s2αn

32 )Cα−1 log n,

because it is equal to the probability that the fraction of active nodes never goes below α for
Cα−1 log n rounds. Therefore, if

s2 ≥

32
αn

log

C log n
α log(1 − δ)

, then p(Nm,m+Cα−1 log n ≥ Cn log n) ≥ 1 − δ.

(11)

Equation 11 gives a lower bound on the value of α. Note that for a ﬁxed α, this lower
bound goes to 0 as n grows so in particular, Equation 11 is satisﬁed for α = αs if n is large

26

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

enough. It now remains to show that such a fraction α of active nodes can be reached in
logarithmic time. Usual gossip analysis takes advantage of the exponential growth of the
informed nodes during early rounds for which no collision occur. We have to adapt the
analysis to the fact that nodes may stop communicating with some probability and split the
analysis into two phases.

In the rest of the proof, we prove that a constant fraction of the nodes (independent of n)
can be reached with a logarithmic number of rounds. We ﬁrst analyze how long it takes to
go from O(log n) to O(n) active nodes and then from 1 to O(log n). Equation 8 along with
Equation 9 with λ = s

4 give that as long as At0(1 + s

(cid:16)

p

At+t0+1 ≥ At0 (1 +

s
4

)t+1|At = At0 (1 +

)t(cid:17)

s
4

4 )t ≤ αsn then
≥ 1 − e− αns2

128

for any t ≥ t0 such that At0
rounds (so for a logarithmic number of rounds) then p (cid:0)Atαs +t0 ≥ nα|At0
because in this case, At ≥ At0 for t ≥ t0. Therefore, if

≤ nαs . Therefore, if we do this for all t ≤ tαs = log(αsn)
log(1+ s
4 )
s2
At0
128 (cid:1)tαs

(cid:1) ≥ (cid:0)1−e−

2

(cid:0)1 + c

(cid:1)t

At0 ≥ −

(cid:16)

128
s2 log

1 − (1 − δ)

(cid:17)

1
tαs

, then p(Atαs +t0 ≥ nαs|At0 ) ≥ 1 − δ.

(12)

along with the fact that δ < 1 ≤ tαs to

Using the fact that (1 − x)y ≤ e−xy ≤ 1 − xy + x2y2
2
simplify Equation 12, we show that if At0 satisﬁes:
(cid:19)

At0 ≥

128
s2 log

(cid:18) 2tαs
δ

,

(13)

then it also satisﬁes Equation 12.

It only remains to prove that such an At0 can be reached with t0 logarithmic in n. For this,
use again Azuma inequality but on κ consecutive rounds this time. Therefore, Equation 10
becomes, assuming that at least At messages are sent at each round:
(cid:17)

(cid:16)

(cid:16)

(cid:17)

p

At+κ ≤ At

1 +

− λ

|At

≤ e− λ2

8κ At.

(14)

κs
2

We apply this inequality for κ = 2C log(n)/s and λ = C log(n)/2 (which is valid because at
least A0 = 1 node is active at each round), which yields:
(cid:19)

(cid:18)

p

Aκ ≤ 1 +

C log(n)
2

|At

≤ e− s log(n)

64 C.

(15)

In particular, for a ﬁxed values of C, s, and δ, then p
≤ 1 − δ for n large
enough. Finally, tαs is logarithmic in n so similarly, Equation (13) is satisﬁed for t0 = κ if n
is large enough.

|At

2

Aκ ≥ C log(n)

(cid:16)

(cid:17)

We conclude the proof by noting that
p (cid:0)N0,t0+tαs +Cα−1 log n ≥ Cn log n(cid:1)
(cid:18)
128
s2 log

(cid:18) 2tαs
δ

At0 ≥

≥ p

(cid:19)(cid:19)

(cid:18)

p

Atαs +t0 ≥ nαs|At0 ≥

128
s2 log

(cid:18) 2tαs
δ

(cid:19)(cid:19)

× p (cid:0)Ntαs +t0,tαs +t0+Cα−1 log n ≥ Cn log n|At0+tαs

≥ nαs

(cid:1)

≥ (1 − δ)3 ≥ 1 − 3δ.

Finally, we have that t0 ≤ 2C log(n)/s, tαs ≤ log(n)/s and 1/αs ≤ 3/s so in the end,
t0 + tαs + Cα−1 log n ≤ 6C log(n)/s. Without loss of generality, δ can also be replaced by
(cid:74)
δ/3.

A. Bellet, R. Guerraoui and H. Hendrikx

27

(cid:73) Remark 13 (Extension to the Asynchronous Version). The ﬁrst part of the proof directly
extends to the asynchronous algorithm by simply considering slices of time during which a
set of αn nodes send αn messages, which essentially means constant time. Then, we consider
a logarithmic number of slices. The phase from 1 to O(log n) active nodes requires sending a
logarithmic number of messages and can thus be done in logarithmic time. Finally, phase 2
(going from O(log n) to O(n) active nodes) consists in evaluating a logarithmic number of
rounds during which a logarithmic number of nodes are active. Again, the only important
thing is the number of messages sent (and not which node sent them) so using constant
time intervals ensures that enough messages are sent between each pseudo-rounds with
high probability. To summarize, it is possible to prove a statement very similar to that of
Theorem 9 in the asynchronous setting, where the notion of rounds is replaced by constant
time intervals. We omit the exact details of this alternative formulation.

C.3 Maximum Likelihood Estimation

Proof of Theorem 10. We recall that S is the output sequence observed by curious nodes,
so that S0, is the ﬁrst node that communicates with a curious node. The source is noted I0,
as it is the ﬁrst node informed of the rumor. The set P is such that p(I0 = i) = 0 if i /∈ P .
Recall that tc is such that Stc ∈ P and St /∈ P for 0 ≤ t < tc. By a slight abuse of notation,
note At the set of active nodes at the time where St is disclosed (time of t-th communication
with a curious node), so St ∈ At for all t.

We know that for all i ∈ P then p((St)t<tc |Atc, I0 = i) = p((St)t<tc|Atc ) since St /∈ P
for t < tc. Similarly, p((St)t≥tc|Atc, I0 = i, (St)t<tc) = p((St)t≥tc|Atc ) since the output after
some time only depends on the active nodes at that time. Therefore, p(S|Atc , I0 = i) =
p(S|Atc) for all i ∈ P , which critically relies on the fact that tc is the time of ﬁrst disclosure
of a node in P (the ﬁrst inequality would not hold otherwise). We note [n] = {1, ..., n}. We
then write for i ∈ P :

p(I0 = i|S) =

=

=

X

A⊂[n]
X

A⊂[n]

p(Atc = A|S)p(I0 = i|Atc = A, S)

p(Atc = A|S)p(I0 = i|Atc = A)

X

p(Atc = A|S)

A⊂[n]:Stc ∈A

p(I0 = i)
p(Atc = A)

p(Atc = A|I0 = i).

Let j ∈ P ∩ Atc. If i ∈ Atc then p(Atc = A|I0 = i) = p(Atc = A|I0 = j). Otherwise,
let us denote Eij(A) = ∩k∈A\{j}{k active at time tc} ∩k /∈A∪{i} {k inactive at time tc}. This
event represents the realization of Atc for all nodes diﬀerent from i and j. We then write:

p(Atc = A|I0 = i) = p(∩k∈A{k ∈ Atc } ∩k /∈A {k /∈ Atc}|I0 = i)

= p(Eij(A)|I0 = i)p(j ∈ Atc, i /∈ Atc|I0 = i, Eij(A))
= p(Eij(A)|I0 = j)p(j ∈ Atc , i /∈ Atc|I0 = i, Eij(A))
≤ p(Eij(A)|I0 = j)p(j ∈ Atc , i /∈ Atc|I0 = j, Eij(A)))
= p(Atc = A|I0 = j).

The inequality comes from the fact that it is more likely that j is active and i is
inactive if j is the source than if i is (i.e., if it is already the case at the beginning).
This means that p(Atc = A|I0 = i) ≤ p(Atc = A|I0 = j) for all i ∈ [n] and j ∈ Atc.

28

Quantifying the Natural Diﬀerential Privacy Guarantees of Gossip Protocols

Since the summation is over all A such that S0 ∈ A (by deﬁnition of Stc and Atc), and
p(Atc = A|I0 = i) ≤ p(Atc = A|I0 = Stc ), we have for all considered A:

p(I0 = i|S) =

X

p(Atc = A|S)

A⊂[n]:Stc ∈A
X

≤

p(Atc = A|S)

A⊂[n]:Stc ∈A
= p(I0 = Stc |S).

p(I0 = i)
p(Atc = A)

p(I0 = Stc)
p(Atc = A)

p(Atc = A|I0 = i)

p(Atc = A|I0 = Stc )

This means that Stc is more likely to be the source than any other suspected node when
the adversary observes output S. Note that this requires uniform prior over nodes that can
be suspected since we used the fact that p(I0 = i) = p(I0 = Stc ) for all i ∈ P . For i /∈ P ,
(cid:74)
p(I0 = i|S) = 0 ≤ p(I0 = Stc|S).

D Challenges of Private Gossip for General Graphs

A natural extension of this work is to consider general graphs. We discuss in this section
several aspects related to the natural privacy of gossip protocols in arbitrary graphs. In
particular, we highlight the fact that problem-speciﬁc modeling choices are needed to go
beyond the complete graph, and that even deﬁning a notion of privacy that is suitable for all
graphs is very challenging.

D.1 Average-Case versus Worst-Case Privacy

Unlike the case of complete graphs, the location of curious nodes critically impacts the
privacy guarantees in arbitrary graphs. A naive way to deal with this issue is to randomize
the location of curious nodes a posteriori. Let us denote by Lf
i,j the set containing all subsets
of nodes of size f of the graph that do not contain i and j. For ﬁxed nodes i and j, the
set of curious nodes C is drawn from U (Lf
i,j. For some
parameters (cid:15), δ ≥ 0, privacy can be deﬁned as follows: ∀i, j ∈ {0, ..., n − 1}, ∀S ∈ S

i,j), the uniform distribution over Lf

E

C∼U (Lf

i,j )[pi(S, C) − e(cid:15)pj(S, C)] ≤ δ.

Note that pi(S, C) = 0 if the output sequence S is not compatible with the set of curious
nodes C, i.e. if (k, l) ∈ S and k, l /∈ C. To pick the curious nodes, it is possible to either pick
a set of f curious nodes at once or to pick each node (except for i and j) with probability
f /n. This randomized deﬁnition allows to prove a bound similar to that of Theorem 5 for
arbitrary graphs. Indeed, the ﬁrst node that receives the rumor has probability f
n of being
a curious node. However, such average-case notions of privacy are highly undesirable: in
this case, no protection is provided against a (much more realistic) adversary that controls a
fraction of nodes ﬁxed in advance.

The worst-case approach consists in bounding the maximum diﬀerence instead of the
expectation. This is the approach taken in our work for the complete graph (the max
operator is implicit because the location of curious nodes does not matter in a complete
graph). In the case of general graphs, the corresponding privacy deﬁnition is given by:
∀i, j ∈ {0, ..., n − 1}, ∀S ∈ S,

[pi(S, C) − e(cid:15)pj(S, C)] ≤ δ.

max
C∈Lf

i,j

A. Bellet, R. Guerraoui and H. Hendrikx

29

We immediately observe that with this deﬁnition, it is impossible to have δ < 1 as soon
as there is a node in the graph with less than f neighbors. This modeling choice is quite
unrealistic as well because having a node surrounded by curious nodes means that the
adversary actually believes this speciﬁc node has a strong probability of being the source and
therefore put more sensors around it. A possible alternative would be to place curious nodes
so as to bound the maximum privacy for any pair of nodes, and then evaluate the minimum
privacy in this setting. This deﬁnition would mean that the adversary wants to be able to
distinguish any pair of nodes as best as possible.

We see that choosing the locations of the curious nodes in an arbitrary graph is a complex
problem that is heavily dependent on the topology of the graph and on the prior of the
adversary on the locations of the curious nodes. Indeed, the adversary may simply want to
isolate a suﬃciently small group of nodes that have a high probability of being the source.

D.2 Relaxing the Diﬀerential Privacy Deﬁnition

Diﬀerential privacy is a very strong notion that enforces indistinguishability between all pairs
of nodes, in order to be robust to any prior information about who might be the source. In
particular, an adversary should not be able to precisely identify the source even if it knows
that only two nodes in the graph can be the source. Although it was possible to obtain
meaningful privacy guarantees of this kind for the complete graph, this appears to be too
strong of a requirement for some graph topology and location of curious nodes. Consider
for instance the extreme case of a line graph. It is clear that any non-trivial adversary can
always distinguish between two segments of the line. This intuition directly extends to any
graph which admits a cut with only curious nodes in it.

A natural idea is to restrict the pairs of nodes that are required to be indistinguishable.
Several ways of doing this may be considered. For instance, one could require that each
node is indistinguishable from k other nodes in the graph. Such relaxed deﬁnition could be
obtained using the Puﬀerﬁsh framework [46], which explicitly provides a notion of secret to
protect. But how to choose such k nodes based on the topology and how to characterize the
optimal locations of curious nodes is very challenging. Another direction could be to adapt
the notions of metric-based diﬀerential privacy [47, 48] to design a notion of privacy where
the required indistinguishability for a given node is a function of its distance to curious nodes
in the graph, or to require that pairs of nodes become less indistinguishable with distance in
the graph. Yet, it is not clear how to characterize the inﬂuence of the graph topology.

D.3 Optimality of Algorithm 1 with s=0

We have seen in this section that the privacy guarantees for arbitrary graphs heavily rely on
the particular privacy notion and that some recent privacy frameworks may provide tools
to relax the classic diﬀerential privacy deﬁnition which is generally too strong for arbitrary
graphs. We conjecture that for some of these relaxed deﬁnitions, the optimal algorithm for
general graphs will be the same as in our case of the complete graph. Indeed, the strength of
Algorithm 1 with s = 0 is to forget initial conditions quickly. In the complete graph, it does
so in one step. In an arbitrary graph, the information about the part of the graph the source
belongs to is still present after some steps, but the source should quickly be completely
indistinguishable from its direct neighbors. In particular, attacks based on centrality [17]
are rather meaningless against this algorithm because spreading only occurs along a random
walk in the graph. As in the case of the complete graph, Algorithm 1 with s > 0 is then
likely to enjoy near-optimal privacy guarantees.

