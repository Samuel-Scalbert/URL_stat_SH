Discovery of link keys in resource description framework
datasets based on pattern structures
Nacira Abbas, Alexandre Bazin, Jérôme David, Amedeo Napoli

To cite this version:

Nacira Abbas, Alexandre Bazin, Jérôme David, Amedeo Napoli. Discovery of link keys in resource
description framework datasets based on pattern structures. International Journal of Approximate
Reasoning, 2023, 161, pp.108978. ￿10.1016/j.ijar.2023.108978￿. ￿hal-04368386￿

HAL Id: hal-04368386

https://hal.science/hal-04368386

Submitted on 31 Dec 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Discovery of Link Keys in Resource Description
Framework Datasets Based on Pattern Structures

Nacira Abbasa, Alexandre Bazinb, Jérôme Davidc, Amedeo Napolia

aUniversité de Lorraine, CNRS, Inria, LORIA, Nancy, 54000, France
bUniversité de Montpellier, CNRS, LIRMM, Montpellier, 34095, France
cUniv. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, Grenoble, 38000, France

Abstract

In this paper, we present a detailed and complete study on data interlinking
and the discovery of identity links between two RDF –Resource Description
Framework– datasets over the web of data. Data interlinking is the task of
discovering identity links between individuals across datasets. Link keys are
constructions based on pairs of properties and classes that can be considered as
rules allowing to infer identity links between subjects in two RDF datasets. Here
we investigate how FCA –Formal Concept Analysis– and its extensions are well
adapted to investigate and to support the discovery of link keys. Indeed plain
FCA allows to discover the so-called link key candidates, while a specific pattern
structure allows to associate a pair of classes with every candidate. Different link
key candidates can generate sets of identity links between individuals that can be
considered as equal when they are regarded as partitions of the identity relation
and thus involving a kind of redundancy. In this paper, such a redundancy is
deeply studied thanks to partition pattern structures. In particular, experiments
are proposed where it is shown that redundancy of link key candidates while
not significant when based on identity of partitions appears to be much more
significant when based on similarity.

Keywords: Data Interlinking, Link Key Discovery, Link Key Candidate,
Formal Concept Analysis, Pattern Structures, Redundancy of Link Sets.

1. Introduction

In this paper, we are interested in data interlinking through the discovery
of identity links between two RDF (Resource Description Framework) datasets
over the web of data [1]. RDF triples such as (subject,property,object) are the
basic bricks of the web of data [2]. Elements in such triples may be described
thanks to an RDF Schema and/or OWL –Web Ontology Language– ontologies.
Moreover, a given subject can be represented in two different datasets by differ-
ent individuals. Then data interlinking is the task of discovering identity links
between individuals across different datasets. In particular, data interlinking is
meaningful in data preparation, data cleaning, and noise reduction.

Preprint submitted to International Journal of Approximate Reasoning December 31, 2023

There are several approaches for discovering identity links between two RDF
datasets. Some approaches, as in the systems LIMES [3] and SILK [4], are based
on link specifications which are rules declaring whether two elements should be
linked. In addition, link specifications may also be specified by users or learned
from data [5, 6, 7]. Other approaches are based on the discovery of sufficient
conditions for declaring that two subjects are identical [8, 9, 10]. Following this
way, link keys extend the notion of keys in databases and can be viewed as rules
allowing to infer identity links between subjects in two RDF datasets [11]. A
link key is based on two sets of property pairs associated with a pair of classes.
The property pairs correspond to sufficient conditions for declaring that two
subjects are identical w.r.t. the associated pair of classes.

For example, the link key ({(designation,title)},{(creator,author)},(Book,Novel))
states that whenever an instance a of the class Book has the same values for the
property designation as an instance b of the class Novel for the property title, and
that a and b share at least one value for the properties creator and author, then
a and b denote the same entity.

More formally, the link keys which are under investigation in this paper are
composed of two sets of property pairs ({(pi, qi)}i∈I , {(p′
j)}j∈J ) associated
with a pair of classes (c1, c2). Then, whenever an instance a of class c1 has the
same non empty set of values as an instance b of class c2, i.e. pi(a) = qi(b) for
all property pairs in {(pi, qi)}i∈I , and shares at least one value for all property
pairs in {(p′
j(b) ̸= ∅, then a and b denote the same entity.
The first property set {(pi, qi)}i∈I corresponds to a “universal quantification”
while the second property set {(p′
j)}j∈J corresponds to an “existential quan-
tification”. An identity link is then materialized by the a owl:sameAs b link, where
the OWL construction owl:sameAs represents an equivalence relation.

j)}j∈J , i.e. p′

j(a) ∩ q′

j, q′

j, q′

j, q′

Link keys are not provided with RDF datasets and some algorithms were
designed for automatically discovering such link keys [11, 12, 13]. These algo-
rithms try to reduce the search space instead of checking every combination of
property pairs and class pairs. They focus on the discovery of “link key candi-
dates” which are made precise below and which involve maximality and closure.
Accordingly, straightforward connections were established in [14, 12] between
link key discovery and Formal Concept Analysis (FCA [15]). Following the lines
proposed in [14], FCA is applied in [12] to a binary table where rows correspond
to individual pairs and columns to property pairs. The intent of a resulting
concept corresponds to a link key candidate while the extent includes potential
identity links between individuals.

Afterwards, these identity links should be validated thanks to appropriate
quality measures such as “coverage” and “discriminability” [11]. Coverage de-
pends on linkage between entities, i.e., the more subjects are linked by a candi-
date the better is the coverage of the candidate. By contrast, discriminability
assumes that subjects have to be distinct in each dataset and then measures the
capability of a link key candidate to discriminate between subjects.

A generalization of the FCA-based approach was proposed in [13], which
relies on pattern structures [16, 17] and which takes into account different pairs
of classes at the same time in the discovery of link keys. Link key candidates

2

are searched in one pass and the class pairs associated with each discovered link
key candidate are specified. There is no need to iterate over every pair of classes
and the discovery process does not require any prior alignment. Moreover pairs
of class expressions such as conjunctions or disjunctions of named classes may
be returned with link key candidates rather than pairs of named classes.

Actually, link key candidates allow to generate different and maximal link
sets, i.e., the mapping between individuals is close to a “bijection”. However,
some candidates are generating the same link set when the latter is considered
as a partition w.r.t. the equivalence relation owl:sameAs. This leads to a form of
“redundancy” as two different candidates that are inducing the same partition
can be considered as equivalent w.r.t. the generated link sets. This redundancy
can be detected thanks to the equivalence classes generated by the owl:sameAs
relation. Then two candidates relying on the same partition can be considered
as redundant and “merged”. It should be noticed that no link key is removed in
this case, and that merging records redundancy. In this way, the objective of
the research work presented in [18] was to check the existence and to evaluate
the significance of such redundancy.

Based on “partition pattern structures” (pps) introduced in [19] for discov-
ering functional dependencies in datasets, we were able to formalize link key
discovery in taking into account sets of equivalent individuals w.r.t. owl:sameAs
partitions. Then, a pattern concept represents a link key candidate and the
related partition induced by the candidate. Experiments provided three main
results: (i) the redundancy of link keys in real-world datasets is not so sig-
nificant, (ii) the discovery of link key candidates based on pps is efficient and
returns whenever possible a reduced number of non redundant candidates, (iii)
the quality of the returned link keys is quite high when compared to competitors.
This paper is based on two previous publications at the “International Con-
ference on Concept Lattices and Applications” (CLA 2020 and 2022) [13, 18].
It proposes a complete and revised synthesis of both papers including an alter-
native formalization, additional explanations, and extended experiments. The
application of partition pattern structure for detecting redundancy in link key
discovery and an alternative way of dealing with redundancy are made pre-
cise. For completing and generalizing the research work initiated in [18], we
have carried out experiments where the equality operation corresponding to the
owl:sameAs relation is weakened and replaced with a similarity operation. These
experiments tell us that redundancy based on equality is in general small and
not so important. By contrast, redundancy based on similarity appears to be
much more significant with a similarity above rather high thresholds. In partic-
ular, this shows that this research line brings some benefits and contributes in
a substantial way to general research about link keys.

The summary of the paper is as follows. Section 2 introduces RDF datasets
and the basics about link key expressions/candidates, and link key discovery.
Then in Section 3 the formalism of pattern structures, which extends plain
Formal Concept Analysis, is made precise and supports the discovery of link
key candidates with pairs of classes. Examples of a pattern structure, a pattern
In
concept lattice, and a set of link key candidates are given in Section 3.

3

Section 5 redundancy of link key candidates is discussed, and as well the way
how partition pattern structures allow to detect such redundancy. Section 6
provides details about experiments, describes the datasets which are reused, and
shows how the use of a similarity brings another point of view on redundancy
of link key candidates. Finally, before Conclusion, Section 7 presents the state
of the art and especially the approaches which are close to the present research
work.

2. Basics About Link Keys

The process of discovering link keys takes as input two RDF datasets, com-
putes a set of potential link keys, called link key candidates, and evaluates them
thanks to quality measures. This section introduces different definitions about
RDF datasets that are used in the following.

2.1. RDF Dataset

An RDF dataset represents data as a collection of graphs associating entities
to values or to other entities through properties. For the sake of simplicity and
without loss of generality, we do not make the distinction between “RDF graph”
and an “RDF dataset” in this paper.

Definition 1 (RDF Dataset). Let U denote a set of IRIs, i.e., “Internationalized
Resource Identifiers”, B a set of blank nodes, i.e., “anonymous resources” or
“variables”, and L a set of literals, i.e., “string values”.

An RDF dataset is a set of triples (s, p, o) ∈ (U ∪ B) × U × (U ∪ B ∪ L).

Here after, D denotes an RDF dataset, and (s, p, o) a triple with a subject
s ∈ (U ∪ B), a predicate p ∈ U , and an object o ∈ (U ∪ B ∪ L). Then
S(D) = {s | ∃ p, o (s, p, o) ∈ D} denotes the set of subject identifiers, while
P (D) = {p | ∃ s, o (s, p, o) ∈ D} and the set of property identifiers. In addition,
p(s) = {o | (s, p, o) ∈ D} denotes the set of objects –or values– associated with
s through property p.

Furthermore, N C(D) = {c ∈ U | ∃ s (s, rdf:type, c) ∈ D} denotes the set
of named classes, where rdf:type stands for the instantiation link in RDF, and
IN C(c) = {s | ∃ s (s, rdf:type, c) ∈ D} denotes the set of instances of a named
classes c ∈ N C(D).

Finally, an identity link is an RDF triple such as (a, owl:sameAs, b), stating
that the IRIs a and b are referring to the same entity, or a and b are denoting
the same individual.

Example 1. In Figure 1, P(D1) and P(D2) are sets of property identifiers:

P(D1) = {cAge, cFN, cLN, given, famN, date, desig, creat},
P(D2) = {pAge, pLN, pFN, first, name, year, title, auth}.

NC(D1) and NC(D2) are sets of named classes over D1 and D2:

NC(D1) = {Character, Woman, Scientist, Book},
NC(D2) = {Persona, FemScientist, Dictionary, Novel}.

4

Character

a1

a2

Woman

a3

a4

a5

a6

a7

a8

a9

a10

a11

a12

Scientist

Book

a13

a14

a15

a16

a17

e

c

g
A
c F N
c L N
cLN

c F N
c L N
cFN
cAge

f a m N

f a m N
g i v e n
e n
g i v
f a m N

g i v e n
f a m N

g i v e n
famN

given
famN

given
famN

given
famN
famN
given

given
famN

30

Zia

Dupont

Durant

Maria

Thomas

Celeste

22

Winfrey

Kelly

Grace

Hopper

Anita

Borg

Ada

Lovelace

Katie

Bouman

Rosalind

Franklin

Marie

Curie

Pierre

Alan

Turing

2016

desig

d e s i g

d a t e

date

d e s i g
creat
c r e a t

desig

desig
creat

D1

The Merriam-Webster Dictionary

2009

Les Misérables

Victor Hugo

Notre-Dame de Paris

The Talisman

Stephen King

Peter Straub

pAge
pFN
pLN

pFN

pLN

pLN
pFN
pAge

first
name

first
name

first
name

first
name

first
name

first
n a m e

year

title

title

year

title
auth

auth

title

title
auth
a u t h

Persona

b1

b2

FemScientist

b5

b6

b7

b8

b9

b10

Dictionary

b13

b14

b15

b16

b17

N ovel

D2

Figure 1: An example of two RDF datasets, with D1 on the left-hand side and D2 on the
right-hand.

5

There are also different sets of instances namely:

INC(Character) = {a1, a2}, INC(Woman) = {a3, . . . , a10}, INC(Book) = {a13, . . . , a17},
INC(Scientist) = {a5, . . . , a12}, INC(Persona) = {b1, b2}, INC(Dictionary) = {b13, b14},
INC(FemScientist) = {b5, . . . , b10}, and INC(Novel) = {b15, b16, b17}.

Furthermore, the “value” of b17 for property auth is auth(b17) = {Stephen King,
Peter Straub}.

It is possible to lift the above restriction to named classes and to consider
conjunctions of named classes such as c1⊓classc2, or disjunctions of named classes
such as c1 ⊔class c2. The intuition justifying such an extension relies on the fact
that ontologies related to RDF datasets are usually based on different levels of
abstraction. For example, the set of female scientists may be represented by the
conjunction of the classes “Woman” and “Scientist” in one dataset, and by the
named class “FemScientist” in another dataset. In such a case, it is interesting to
be able to take into account conjunctions and also disjunctions of classes. Then
in agreement with the corresponding constructions in Description Logics [20],
the set of class expressions over the RDF dataset D denoted by C(D), including
named classes, plus conjunctions (c1⊓classc2 ∈ C(D)) and disjunctions of named
classes (c1 ⊔class c2 ∈ C(D)), can be recursively defined as follows:

– If c ∈ N C(D) then c ∈ C(D),

– if c1, c2 ∈ C(D) then c1 ⊓class c2 ∈ C(D),

– if c1, c2 ∈ C(D) then c1 ⊔class c2 ∈ C(D).

Accordingly, the set of instances of a class c ∈ C(D), denoted by I(c), is

recursively defined as follows:

– If c ∈ N C(D) then I(c) = IN C(c),

– if c1, c2, c3 ∈ C(D) such as c1 = c2 ⊓class c3, then I(c1) = I(c2) ∩ I(c3),

– if c1, c2, c3 ∈ C(D) such as c1 = c2 ⊔class c3, then I(c1) = I(c2) ∪ I(c3).

2.2. Link key expressions, generated links and candidate link keys

Link keys are based on a syntax and a semantics, and they are used to
generate identity links between individuals. The discovery of link keys relies on
the definitions of “link key expression”, “identity link”, and “link key candidate”,
as made precise here below.

Definition 2 (Link key expression and generated identity link set). A link key
expression over two RDF datasets D1 and D2 is a tuple k = (Eq, In, (c1, c2))
such that In ⊆ P (D1) × P (D2), Eq ⊆ In, c1 ∈ C(D1), and c2 ∈ C(D2).

The set of identity links generated by k is denoted by L(k) and includes the

set of pairs of instances (a, b) ∈ I(c1) × I(c2) satisfying:

(i) for all (p, q) ∈ Eq, p(a) = q(b) and p(a) ̸= ∅,

6

(ii) for all (p, q) ∈ In \ Eq, p(a) ∩ q(b) ̸= ∅.

Intuitively, a link key expression k = (Eq, In, (c1, c2)) generates the identity
link (a, b) between individuals a instance of class c1 and b instance of class c2,
when (i) for all (p, q) ∈ Eq, a has the same values for p as b has for q, and (ii)
for all (p′, q′) ∈ In, a and b share at least one value for p′ and q′.

The number of link key expressions may be exponential w.r.t. the number of
properties. In addition, it is possible that several link key expressions generate
the same set of identity links. Then, to reduce the number of potential link keys,
link key discovery algorithms only consider the so-called link key candidates. The
latter correspond to link key expressions that generate at least one link and that
are “maximal” among all link key expressions generating the same links.

Definition 3 (Link key candidate). A link key candidate is a link key expression
k1 = (Eq1, In1, (c1, c2)) such that:

(i) L(k1) ̸= ∅,
(ii) there does not exist another link key expression k2 = (Eq2, In2, (c1, c2))

over D1 and D2 such that Eq1 ⊂ Eq2, In1 ⊂ In2, and L(k1) = L(k2).

For example, consider the expressions k1 and k2:

k1 = ({(date, year),(desig, title)},{(date, year),(desig, title)}, (Book, Dictionary)),
k2 = ({(date, year)},{(date, year)},(Book, Dictionary)).

The link key expressions k1 and k2 both generate the same set of links, namely
L(k1) = L(k2) = {(a13,b13), (a14,b14)}. As k1 is larger than k2, i.e. {(date,year)} ⊂
{(date,year),(desig,title)}, and as there is no other link key expression generating
the same set of links as k1, then k1 is considered as a link key candidate.

2.3. Quality measures

A link key candidate can be promoted as a “valid link key” as soon as it
generates only valid identity links. As it is not feasible to check one by one
every identity link, adapted measures have been introduced for evaluating the
quality of a link key candidate. In this way, “discriminability” and “coverage” are
two quality measures that work in an unsupervised scenario, i.e., when reference
links are not available, as this is the case most of the time [11].

Intuitively, coverage (resp. discriminability) evaluates how close is a set
of links to a surjective (resp.
injective) map. Hence, coverage is maximum
when all instances of the considered classes are linked to “at least” another
instance. Discriminability is maximum when instances are linked to “at most”
one instance.

Definition 4. Let L ⊆ I(c1) × I(c2) be a set of links between classes c1 and c2.
Let us denote π1(L) = {a|(a, b) ∈ L} and π2(L) = {b|(a, b) ∈ L}.

The coverage of L over c1 and c2 is defined as:

co(L, c1, c2) =

|π1(L) ∪ π2(L)|
|I(c1) ∪ I(c2)|

7

The discriminability of L is defined as:

di(L) =

min(|π1(L)|, |π2(L)|)
|L|

Similarly to the F-measure, discriminability and coverage can be combined

into a harmonic mean denoted by hm (hmean).

2.4. A Semantics for Link Keys

Link keys are not only syntactic constructions and a semantics may be de-
fined for such expressions. Usually, the semantics of link keys reuses the De-
scription Logics (DL) for interpretation I = (∆I, ·I) [20]. The set ∆I is called
the interpretation domain and is composed of individuals, while the interpreta-
tion function ·I maps conceptual expressions into subsets of the interpretation
domain, i.e., subsets of individuals. Such a semantics allows to check the con-
sistency of knowledge bases related by link keys, to infer subsumption relations
between link keys, and to define the validity of a link key w.r.t. an interpreta-
tion.

Definition 5 (Link key). A link key is an expression of the form (Eq, In, (c1, c2))
where Eq and In are sets of pairs of properties with Eq ⊆ In, and c1 and c2
are classes.

An interpretation I satisfies a link key (Eq, In, (c1, c2)) if, for any α ∈ cI
1

and β ∈ cI
(1) pI
(2) pI

2 verifying (1) and (2) below it can be inferred that α = β.
i (α) = qI
j (α) ∩ qI

i (β) with pI
j (β) ̸= ∅ for all (pj, qj) ∈ In,

i (α) ̸= ∅ for all (pi, qi) ∈ Eq,

The link keys which are considered here are a merge of “weak eq-link keys”
and “weak in-link keys” as this is introduced and made precise in [21]. However,
the present work is not directly related to semantics of link keys and we will no
more elaborate in this direction.

3. Basics About Pattern Structures

Pattern structures [16, 17] are an extension of Formal Concept Analysis [15]
aimed at adapting the FCA formalism to objects whose descriptions is too com-
plex to be expressed as a set of binary attributes. This is the case when ob-
jects have attributes whose values can be numbers, intervals, sequences, trees,
graphs. . . It should be noticed that “object” here denotes an element or an indi-
vidual which has a description and not as a component of an RDF triple.

Definition 6 (Pattern structure). A pattern structure is a triple (G, (D, ⊓), δ),
where G is a set of objects, D is a set of descriptions, and δ : G (cid:55)→ D maps an
object to its description.

Moreover, the operator ⊓ is a similarity operator that defines the similarity
between two descriptions. In addition, given two descriptions d1 and d2, ⊓ is
associated with a partial ordering denoted by ⊑ as follows: d1 ⊓ d2 = d1 iff
d1 ⊑ d2.

8

In particular, the set of potential descriptions (D, ⊑) forms a meet-semilattice.
The semi-lattice (D, ⊑) can be interpreted as the set of descriptions ordered by
the ⊑ relation (subsumption). Actually ⊓ maps pairs of descriptions to their
least common subsumer as explained in [16]. For example, Figure 2 depicts a
simple pattern structure in which objects are described by intervals. Details
and examples about “interval pattern structures” can be found in [17].

Objects Descriptions

g1
g2
g3

[1, 2]
[2, 3]
[3, 4]

Figure 2: A pattern structure with three objects g1, g2 and g3 whose description is an interval.
[a, b] ⊓ [c, d] =
The similarity ⊓ between two intervals is defined by their convex hull, i.e.
[min(a, c), max(b, d)]. Then δ(g1) ⊓ δ(g2) = [1, 2] ⊓ [2, 3] = [1, 3].

As in plain FCA, given a pattern structure (G, (D, ⊓), δ), two derivation

operators denoted by ·⋄ can be defined as follows:

·⋄ : 2G (cid:55)→ D, G⋄ = (cid:108)
g∈G

δ(g)

·⋄ : D (cid:55)→ 2G, d⋄ = {g ∈ G | d ⊓ δ(g) = d}

It should be noticed that, alternatively, d ⊓ δ(g) = d can be rewritten as
d ⊑ δ(g). Given a set of objects G, G⋄ returns the most specific description
common to all the objects in G. Dually, given a description d, d⋄ returns all the
objects whose description is more specific than d. Based on these two derivation
operators we can define a pattern concept as:

Definition 7 (Pattern concept). A pattern concept in (G, (D, ⊓), δ) is a pair
(A, d) with A ⊆ G and d ∈ D such that A = d⋄ and d = A⋄.

For example, in Figure 3, ({g1, g2}, [1, 3]) is a concept as {g1, g2}⋄ = δ(g1) ⊓
δ(g2) = [1, 3] and dually [1, 3]⋄ = {g1, g2}. Then, as this is the case in plain
FCA, the set of all concepts of a pattern structure can be partially ordered
by inclusion of extents to form a complete lattice called the “pattern concept
lattice” of the pattern structure.

In the pattern concept lattice, it can be checked that every object is attached
to a unique concept, i.e., the corresponding “object pattern concept” (the “object
concept” in plain FCA) [15]. Dually, for every description there is an “descrip-
tion pattern concept”, also called an “attribute pattern concept” (the “attribute
concept” in plain FCA). Intuitively, considering the order from top to bottom
in the lattice, as soon as a description is attached to a given pattern concept, it
is attached to all the pattern concepts which are below. For example, the de-
scription pattern concept of interval [2, 4] is the pattern concept ({g2, g3}, [2, 4])
and interval [2, 4] is subsumed by the intents [2, 3] and [3, 4] lying in the pattern
concepts below. Recall that for descriptions d1 and d2, d1 ⊓ d2 = d1 iff d1 ⊑ d2.

9

({g1, g2, g3}, [1, 4])

({g1, g2}, [1, 3])

({g2, g3}, [2, 4])

({g1}, [1, 2])

({g2}, [2, 3])

({g3}, [3, 4])

(∅, ⊤)

Figure 3: The pattern concept lattice related to the pattern structure given in Figure 2. The
⊤ symbol is arbitrarily added to the meet-semilattice of intervals in order to make it a lattice.

This can be read for intervals as follows:
[2, 3] ⊓ [2, 4] = [2, 4] iff [2, 4] ⊆ [2, 3]
[17]. Dually, considering the order from bottom to top in the lattice, as soon
as an object is attached to a given pattern concept, it is attached to all the
pattern concepts which are above. For example, the object pattern concept of
{g1} is the pattern concept ({g1}, [1, 2]), and {g1} is lying in all extents above
this pattern concept.

More formally, the object pattern concept is defined as γ(g) = (g⋄⋄, g⋄), while
the description pattern concept is defined as µ(d) = (d⋄, d⋄⋄). Moreover, the
set of object pattern concepts ordered by the inclusion relation on the extents
is called the OC-poset of the pattern structure [22]. Actually, this is a partially
ordered set and not necessarily a lattice. More details and an example involving
the OC-poset is proposed in Section 5.

4. Discovering Link Keys Within Pattern Structures

In this section, we present the use of pattern structures to discover link key
candidates in RDF datasets. The pairs of classes considered in the link key
expressions are restricted to class expressions composed of named classes, or
conjunctions of named classes such as c1 ⊓class c2, or disjunctions of named
classes such as c1 ⊔class c2. Recall that conjunctions and disjunctions of named
classes correspond to respectively conjunction and disjunction of concepts in
Description Logics [20].

Definition 8 (LK-pattern structure). Let D1 and D2 be two RDF datasets.
The LK-pattern structure supporting link key candidate discovery over D1 and
D2 is defined as the triple (S(D1) × S(D2), (E, ⊓), δ) where:
( i) Objects: S(D1) × S(D2) denotes the set of subjects pairs over D1 and D2.
( ii) Descriptions and similarity operator (⊓): E denotes the set of link key
expressions k = (Eq, In, (c1, c2)) over D1 and D2, where c1 ∈ C(D1) and c2 ∈
C(D2).
The similarity operator (⊓) is such that:

10

Objects
S(D1) × S(D2)
(a1,b1)
(a1,b2)
(a2,b1)
(a2,b2)
(a4,b5)
(a5,b5)

(a6,b6)

(a7,b7)

(a8,b8)

(a9,b9)

(a10,b10)
(a11,b10)
(a13,b13)
(a13,b14)
(a14,b13)
(a14,b14)

(a15,b15)
(a15,b16)
(a16,b15)
(a16,b16)

(a17,b17)

Eq

{(cAge,pAge)}

{}
{}

{(cAge,pAge)}

{(given,first)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(famN,name)}
{(date,year),
(desig,title)}
{(desig,title)}
{(desig,title)}
{(date,year),
(desig,title)}
{(creat,auth),
(desig,title)}
{(creat,auth)}
{(creat,auth)}
{(creat,auth),
(desig,title)}

{(desig,title)}

Descriptions

In

{(cFN,pFN),
(cLN,pLN)}
{(cLN,pLN)}
{(cFN,pFN)}
{(cFN,pFN),
(cLN,pLN)}
{(given,first)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(given,first),
(famN,name)}
{(famN,name)}
{(date,year),
(desig,title)}
{(desig,title)}
{(desig,title)}
{(date,year),
(desig,title)}
{(creat,auth),
(desig,title)}
{(creat,auth)}
{(creat,auth)}
{(creat,auth),
(desig,title)}
{(creat,auth),
(desig,title)}

C(D1)× C(D2)

(Character, Persona)

(Character, Persona)
(Character, Persona)

(Character, Persona)

(Woman, FemScientist)
(Woman⊓classScientist,
FemScientist)
(Woman⊓classScientist,
FemScientist)
(Woman⊓classScientist,
FemScientist)
(Woman⊓classScientist,
FemScientist)
(Woman⊓classScientist,
FemScientist)
(Woman⊓classScientist,
FemScientist)
(Scientist, FemScientist)

(Book,Dictionary)

(Book,Dictionary)
(Book,Dictionary)

(Book,Dictionary)

(Book,Novel)

(Book,Novel)
(Book,Novel)

(Book,Novel)

(Book,Novel)

Table 1: The LK-pattern structure corresponding to the datasets D1 and D2 given in Figure 1.

11

(Eq1, In1, (cD1
(Eq1 ∩ Eq2, In1 ∩ In2, (cD1

1 )) ⊓ (Eq2, In2, (cD1
1 ⊔class cD1

1 , cD2

2 , cD2
2 , cD2

2 )) =
1 ⊔class cD2

2 )).

( iii) Mapping δ:

δ : S(D1) × S(D2) −→ E associates a pair (s1, s2) ∈ S(D1) × S(D2) to its

description δ((s1, s2)) = (Eq, In, (c1, c2)) where:

Eq = {(p1, p2) | p1(s1) = p2(s2) ̸= ∅},
In = {(p1, p2) | p1(s1) ∩ p2(s2) ̸= ∅},
c1 is the conjunction of the named classes to which s1 belongs,
i.e., c1 = (cid:100)i∈[1,ℓ1] cli where cli verifies (s1,rdf:type,cli) for i ∈ [1, ℓ1],
similarly, c2 is the conjunction of the named classes to which s2 belongs,
i.e., c2 = (cid:100)j∈[1,ℓ2] clj where (s2,rdf:type,clj) for j ∈ [1, ℓ2].

For example, the LK-pattern structure corresponding to the datasets given
in Figure 1 is detailed in Table 1. The pattern concept lattice corresponding to
this LK-pattern structure is displayed in Figure 4.

In the pattern concept lattice, every pattern concept is based on a pair of
closed sets, namely an intent representing a link key candidate and an extent
representing the related link set, plus a pair of classes related to the type of
the subjects under study. For example, the link key candidate k9 is associated
with the pair of classes (Woman ⊓class Scientist, FemScientist), i.e., k9 relates an
instance of the class conjunction Woman ⊓class Scientist with an instance of the
class FemScientist. Moreover, different link key candidates may have the same
sets of pairs of properties Eq and In, but they are associated with different pairs
of class expressions, as this is the case for k1a and k1b. Indeed, k1a and k1b have
the same sets of properties pairs, namely {(desig,title)}, {(desig,title)}, while they
are associated respectively with (Book,Dictionary ⊔class Novel) and (Book,Novel).

The properties appearing in such link key candidates describe subjects be-
longing to different classes. For example, the property title in k1a and k1b de-
scribes instances of the classes Dictionary or Novel. Furthermore, it should be
noticed that one pair of classes can be associated with more than one link key
candidate. For example, the pair of classes (Book,Novel) (in orange in Figure 4)
is associated with the four link key candidates k3, k4, k5, and k6. In particular,
this means that there are four possible choices to select a link key candidate for
the pair of classes (Book,Novel).

Now let us have a more precise look at the link sets generated by link key
candidates. For example, the link set L(k11) = {(a1,b1),(a2,b2),(a2,b1)} is gener-
ated by k11 and L(k12) = {(a1,b1),(a2,b2),(a1,b2)} is generated by k12. An identity
link states that two subjects represent the same entity and materialized by the
owl:sameAs relation. The latter is an equivalence relation, i.e., reflexive, symmet-
ric, and transitive. Relying on the transitivity of owl:sameAs and considering link
sets as partitions, it comes that k11 and k12 are generating the same equivalence
class of links [18]. Then it can be concluded that the four subjects a1, a2, b1,
and b2, represent the same entity.

Therefore, when link sets are considered as partitions induced by owl:sameAs,
the two link key candidates k11 and k12 are carrying the same information about
identity links. In other words, this involves a kind of “redundancy”, i.e., it is

12

k0
S(D1) × S(D2)
∗

k8
co=.92, di=.85, hm=.89

k7
co=.92, di=.85, hm=.89

{(a4, b5)}

{(given,first)},
{(given,first)}

{(a11, b10)}

{(famN,name)}},
{(famN,name)}}

(Woman,FemScientist)

(Scientist,FemScientist)

k9
co=1, di=1, hm=1

{(a5, b5), (a6, b6), (a7, b7),
(a8, b8), (a9, b9), (a10, b10)}

{(famN,name), (given,first)},
{(famN,name), (given,first)}

(Woman⊓classScientist,FemScientist)

k1a
co=1, di=.71, hm=.83

k3
co=.75, di=.60, hm=.66

{(desig,title)},
{(desig,title)}

(Book,(Dictionary⊔classNovel))

{}, {(creat,auth)}

(Book,Novel)

k11
co=1, di=.66, hm=.80

k12
co=1, di=.66, hm=.80

{(a2, b1)}

{(a1, b2)}

{}, {(cFN,pFN)}

{}, {(cLN,pLN)}

(Character,Persona)

(Character,Persona)

k13
co=1, di=1, hm=1

{(a1, b1), (a2, b2)}

{(cAge, pAge)},
{((cAge, pAge), (cLN,pLN), (cFN,pFN)}

(Character,Persona)

k1b
co=.57, di=.50, hm=.53

k4
co=.75, di=1, hm=.85

k5
co=.50, di=.0.50, hm=.50

{(a13, b14), (a14, b13)}

{(a17, b17)}

{(a15, b16), (a16, b15)}

{(desig,title)},
{(desig,title)}

{(desig,title)}
{(desig,title), (creat,auth)}

(Book,Dictionary)

(Book,Novel)

{(creat,auth)},
{(creat,auth)}

(Book,Novel)

k2
co=.57, di=1, hm=.72

{(a13, b13), (a14, b14)}

{(date,year), (desig,title)}
{(date,year), (desig,title)}

k6
co=.50, di=1, hm=.66

{(a15, b15), (a16, b16)}

{(creat,auth), (desig,title)}
{(creat,auth), (desig,title)}

(Book,Dictionary)

(Book,Novel)

k10

P (D1) × P (D2)

Figure 4: The pattern concept lattice induced from the LK-pattern structure in Table 1.

no longer true that every link key candidate provides information that cannot
be retrieved from the rest of the link key candidates. Accordingly, the topic of
the next Section is to present how to define, to detect, and to deal with such
redundancy.

5. Detecting Redundant Link Keys with Partition Pattern Structures

5.1. Detecting the Redundancy of Link Keys based on Partition Pattern Struc-

tures

In [19], authors are using “partition pattern structures” for discovering func-
tional dependencies (FDs), which correspond to attribute implications or to
pairs of attributes having the same behavior w.r.t. an object partition. Here
we are facing the same kind of problem and thus we reuse the same approach,
replacing “implication” by “link key candidate”, knowing that an implication
within a concept lattice is related with a closed set as link key candidates are.

13

Below, we show how the detection of redundancy among link key candidates
is based on the use of partition pattern structures, where partitions of subjects
are composed of equivalent subsets of subjects in generated link sets. Firstly, we
present a motivating example explaining the process of redundancy detection.
In Figure 4, the link key candidate k1b generates the following link set:

L(k1b) = {(a13,b13),(a14,b14),(a13,b14),(a14,b13)}.

Based on the symmetry and transitivity of the owl:sameAs relation, it is pos-
sible to compute the equivalence class of subjects lying in the L(k1b) link set.
Then, the link (a13,a14) can be inferred from the pairs (a13,b13) and (b13,a14)
(using symmetry for the latter). In particular, these two pairs can be rewrit-
ten as the RDF triples (a13,owl:sameAs,b13) and (b13,owl:sameAs,a14). Computing
the transitive closure of the owl:sameAs relation in L(k1b) yields the partition
{a13,a14,b13,b14}. This partition can be regarded as an equivalence class or as a
“complete graph” –all vertices are connected to each others. Based on that, we
have the following definition:

Definition 9 (Partition of subjects induced by a link key). Let D1 and D2 be
two RDF datasets and k a link key candidate. The partition of subjects induced
by k is defined as the quotient set: P art(k) = L(k)/owl:sameAs.

Before making precise the “partition pattern structure” supporting the dis-
covery of such quotient sets, we recall that the meet of two partitions ⊓part
is defined as the coarsest common refinement of the two partitions [19]. For
example:

{{a15,a16,b15,b16}} ⊓part {{a15,b15},{a16,b16},{a17,b17}} = {{a15,b15},{a16,b16}}.
Given two RDF datasets D1 and D1, the set of instances I(D1) ∪ I(D1),
the related set of partitions equipped with the similarity operator ⊓part, we can
build the following “partition pattern structure”:

Definition 10 (LK-partition pattern structure). Let D1 and D2 be two RDF
datasets. The LK-partition pattern structure over D1 and D2 is defined as the
triple (LKC, (P art(S(D1) ∪ S(D2)), ⊓part), δ) such that:

– LKC is the set of link key candidates over D1 and D2 computed thanks

to the LK-pattern structure introduced in Section 4,

– P art(S(D1) ∪ S(D2)) is the set of partitions of the set of all subjects in

D1 and D2, while ⊓part is the “meet” of two partitions,

– δ maps a link key candidate k to the partition P art(k) = L(k)/owl:sameAs,

where L(k) is the link set generated by k.

For example, the LK-partition pattern structure corresponding to the RDF
datasets displayed in Figure 1 is given in Table 2. The objects are the link key
candidates k1a, k1b, k2, . . . , k9, k11, k12, k13, which are taken from the LK-pattern
structure given in Table 1, while the descriptions are the related partitions of
subjects.

14

PPS objects (ki)
k1a
k1b
k2
k3
k4
k5
k6
k7
k8
k9
k11
k12
k13

Descriptions (δ(ki) = P art(ki))

{{a13, a14, b13, b14}, {a15, b15}, {a16, b16}, {a17, b17}}
{{a13, a14, b13, b14}}
{{a13, b13}, {a14, b14}}
{{a15, a16, b15, b16}, {a17, b17}}
{{a15, b15}, {a16, b16}, {a17, b17}}
{{a15, a16, b15, b16}}
{{a15, b15}, {a16, b16}}
{{a5, b5}, {a6, b6}, {a7, b7}, {a8, b8}, {a9, b9}, {a10, a11, b10}}
{{a4, a5, b5}, {a6, b6}, {a7, b7}, {a8, b8}, {a9, b9}, {a10, b10}}
{{a5, b5}, {a6, b6}, {a7, b7}, {a8, b8}, {a9, b9}, {a10, b10}}
{{a1, a2, b1, b2}}
{{a1, a2, b1, b2}}
{{a1, b1}, {a2, b2}}

Table 2: The “partition pattern structure” corresponding to the pattern structure given in Ta-
ble 1.

Pattern concepts from this LK-partition pattern structure are composed
of a set of link keys (the extent) and a partition of the set of instances (the
intent) that is the coarsest refinement of the partitions induced by the link keys
In order to detect redundant link keys, we want to find sets
in the extent.
of link keys that induce the same partition of instances, i.e.
link keys ki, kj
such that P art(ki) = P art(kj). As such, we do not need all the concepts of
this LK-partition pattern structure but only the concepts in which the intent
is a partition of subjects induced by a single link key, i.e. concepts of the form
(k⋄⋄
i ). Those concepts are, by definition, the object concepts introducers
i
(about the OC-poset, see Section 3 and [22]). If the extent of these concepts
contains more than one element, it contains redundant link keys.

, k⋄

Figure 5 shows the OC-poset of the running example completed into a lattice
(for the sake of readability). We can observe that the link key candidates k11
and k12 are merged into the same concept, at the bottom left. This concept can
be interpreted in the following way: k11 and k12 are inducing the same partition
and they should be considered as equivalent. By contrast, the extents of the
other concepts contain only a single element as these link key candidates are
not redundant.

5.2. From Partition Equality to Partition Similarity

Partitions of subjects induced by link keys can be different but still close.
Then, instead of comparing partitions thanks to equality, one can use an adapted
similarity measure. Given two partitions, such a similarity measure can be
defined as the ratio of the common equivalence classes among all equivalence
classes composing both partitions.

Definition 11 (Similarity between partitions). Given two partitions P1 and
P2, the similarity measure between P1 and P2 can be defined as:

σ(P1, P2) =

|P1 ∩ P2|
|P1 ∪ P2|

15

{k1a, k1b, k2, k3, k4, k5, k6, k7, k8, k9, k11, k12, k13}

∅

{k13}

{{a1, b1}, {a2, b2}}

{k2}

{k6}

{{a13, b13}, {a14, b14}}

{{a15, b15}, {a16, b16}}

{k9}

{{a5, b5}, {a6, b6}, {a7, b7},
{a8, b8}, {a9, b9}, {a10, b10}}

{k1b}

{k4}

{k5}

{{a13, a14, b13, b14}}

{{a15, b15}, {a16, b16}, {a17, b17}}

{{a15, a16, b15, b16}}

{k11, k12}

{{a1, a2, b1, b2}}

{k8}

{k7}

{k1a}

{k3}

{{a4, a5, b5}, {a6, b6}, {a7, b7},
{a8, b8}, {a9, b9}, {a10, b10}}

{{a5, b5}, {a6, b6}, {a7, b7}, {a8, b8},
{a9, b9}, {a10, a11, b10}}

{{a13, a14, b13, b14},
{a15, b15}, {a16, b16}, {a17, b17}}

{{a15, a16, b15, b16},
{a17, b17}}

∅

P (D1) × P (D2)

Figure 5: The OC-poset of the LK-partition pattern structure given in Table 2.

For example, in Table 2, the similarity between Part(k3) and Part(k4) is 1/4
because Part(k3) and Part(k4) only share one equivalence class, namely {a17,b17}.
By contrast, the similarity between partitions Part(k5) and Part(k6) is 0 because
no equivalence class is shared, even if there exists a subsumption relation be-
tween k5 and k6 (see Figure 5).

In data clustering, the Rand index is usually used for comparing partitions
[23]. Since this index is defined over pairs of elements, it may return a more
precise estimation of similarity. However, it requires that the two compared
partitions are defined over the same set of objects, which is not the case here.
Here after, in Section 6, we present experiments about the redundancy of
link keys in real-world datasets. Moreover, we also discuss the contrast existing
between the use of equality and the use of similarity for comparing partitions.
Actually, redundancy which is not really significant when based on equality
becomes much more significant when based on similarity.

6. Experiments

There are two main objectives in these experiments. The first one is to show
how the discovery of link keys based on pattern structure extends the related
process based on FCA as proposed in [12]. The second one is to investigate
in real-world datasets how significant is redundancy among link keys, when
partition pattern structures are used to detect such redundancy.

16

Task

Dataset

Restaurants

Person1

Pr

Actor

Restaurant1

Restaurant2

Person11

Person12

Pr1

Pr2

DB Actor
Yago Actor

classes
r1:Restaurant, r1:Address,
r1:City
r2:Restaurant, r2:Address,
r2:Category
p11:Person, p11:Address,
p11:Suburb, p11:State
p12:Person, p12:Address
Classes of Restaurant1
and Person11
Classes of Restaurant2
and Person12
db:Actor
yago:Actor

#inst.

#prop. #triples

|LK-PS|

339

2256

2000

1000

2339

3256

5807
108415

6

6

13

12

19

18

16
16

1130

7520

9000

7000

10130

14520

94606
1029580

36

2212

2260

2005

Table 3: The description of the datasets used in the experiments. The columns #inst., #prop.,
and #triples, respectively denote the number of instances, of properties, and of triples in each
dataset. The number of link key candidates generated in the pattern structure is given in the
column |LK-PS|.

6.1. The Datasets and Their Contents

In these experiments, the so-called “tasks” described in Table 3 are taken
from OAEI1 2010. A task consists in discovering links between instances of the
two corresponding datasets given in the column “Dataset”. For every task, a set
of reference owl:sameAs links is provided (gold standard). Accordingly, reference
links between classes r1:Restaurant and r2:Restaurant are provided in the task
Restaurants, and between classes p11:Person and p12:Person as well. By contrast,
as they were not provided, we built the reference links between r1:Address and
r2:Address, and between classes p11:Address and p12:Address The task Pr, built on
purpose, is based on a combination of Restaurant1 and Person11 from one side,
and a combination of Restaurant2 and Person12 from the other side. Moreover,
we considered the task Actor introduced in [24] which consists in linking the class
db:Actor from DBpedia and the class yago:Actor from Yago. A set of reference
links between these two classes is provided.

Regarding the provenance of these datasets, Restaurant1 and Person1 are taken
from the well-known “Ontology Alignment Evaluation Initiative (OAEI)” which
includes a collection of benchmarks designed to assess and to compare the per-
formance of ontology alignment systems, including data interlinking systems.
Experiments were conducted on additional datasets taken from OAEI, namely
Doremus (OAEI 2016) and SPIMBench (OAEI 2018), and similar results were
observed.

Finally, experiments were also conducted on the Actor dataset, which was
extracted from DBpedia and Yago. This dataset was selected because of its
particular use in experiments about data interlinking based on keys and condi-
tional keys [24]. Additional results about these last experiments can be found
in [18].

1http://oaei.ontologymatching.org/2010/im/index.html

17

6.2. A Pattern Structure for Link Key Discovery

As pointed out above, one objective in these experiments is to understand
to which extent link key discovery based on pattern structure extends the FCA-
based approach proposed in [12]. Thus link key candidates were generated
using both methods and then ranked thanks to hm, i.e., the harmonic mean of
coverage and discriminability. The results returned by the FCA-based process
can be interpreted as follows:

– The top link key candidate for task Restaurants, say k1st
, generates links
R
between classes r1:Restaurant and r2:Restaurant, while k1st
R does not generate
any link between classes r1:Address and r2:Address. The link key generating
links between r1:Address and r2:Address is ranked second.

– The top link key candidate for task Person1, say k1st
P1 , generates links be-
tween classes p11:Person and p12:Person, while k1st
P1 does not generate any
link between classes p11:Address and p12:Address. Moreover, the link key
candidates ranked from 1 to 8 do not generate any link between classes
p11:Address and p12:Address.

– The top link key candidate for task Pr, k1st

Pr , generates links between classes
p11:Person and p12:Person only. The first link key candidate generating links
between classes p11:Address and p12:Address is ranked 8th.

The first link key candidate generating links between classes r1:Restaurant
and r2:Restaurant is ranked at position 1976. Moreover, the first link
key candidate generating links between classes r1:Address and r2:Address
is ranked at position 2049.

– Finally, the top link key candidate for task Actor generates links between
db:Actor and yago:Actor, which are the most general classes in this task.
Then the interest of such link key candidates is rather low.

The FCA-based method for discovering link key candidates returns candi-
dates without specifying the pairs of classes, such as ({}, {(r1:name,r2:name)},
()), which is the top link key candidate in the task Restaurants. This link key
if an instance of Restaurant1 and an
candidate can be interpreted as follows:
instance of Restaurant2 share at least a value for the property name, then these
two instances denote the same entity. Even a non expert person may conclude
that the validity of such a link key is not very high, since holding the same name
does not mean at all lying at the same place.

By contrast, the use of an adapted pattern structure as discussed in this
paper allows one to discover link key candidates with related pairs of classes.
Then it is straightforward to select link key candidates w.r.t. a target pair of
classes. For example, in the task Restaurants, it is possible to select if required
the top link key candidate defined over classes r1:Restaurant and r2:Restaurant,
namely ({},{(r1:name,r2:name)},(r1:Restaurant,r2:Restaurant)). Then, the first link
key candidate defined over classes r1:Address and r2:Address can be selected in

18

Restaurant

2
0
1

5
6

5
4

7
3

9
2

3
1

4

2

0 0

2

1.5

1

0.5

0

s
n
o
i
t
i
t
r
a
p

f
o

s
r
i
a
p

r
a
l
i

m

i
s

#

·106

6
0
1
·
4
8
.
1

Person1

6
0
1
·
9
3
.
1

5
0
1
·
5
4
.
8

5
0
1
·
2
.
4

5
0
1
·
7
7
.
1

8
9
3
,
4
6

6
3
6
,
0
2

0
8
4
,
5

8
5
5

0

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
similarity threshold

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
similarity threshold

·106

6
0
1
·
4
8
.
1

Pr

·105

5
0
1
·
5
3
.
3

Actor

6
0
1
·
9
3
.
1

5
0
1
·
6
4
.
8

5
0
1
·
2
.
4

5
0
1
·
7
7
.
1

1
1
4
,
4
6

0
4
6
,
0
2

2
8
4
,
5

8
5
5

0

s
n
o
i
t
i
t
r
a
p

f
o

s
r
i
a
p

r
a
l
i

m

i
s

#

3

2

1

0

5
0
1
·
5
8
.
1

5
0
1
·
1
1
.
1

5
4
8
,
3
6

9
4
0
,
5
3

2
0
8
,
5
1

5
5
2
,
7

2
8
4
,
3

7
6
0
,
1

9
2

s
n
o
i
t
i
t
r
a
p

f
o

s
r
i
a
p

r
a
l
i

m

i
s

#

100

80

60

40

20

0

2

1.5

1

0.5

0

s
n
o
i
t
i
t
r
a
p

f
o

s
r
i
a
p

r
a
l
i

m

i
s

#

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
similarity threshold

0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
similarity threshold

Figure 6: Variation of the number of similar pairs of partitions w.r.t. the similarity threshold.
In this experiment, we do not count pairs of the same partition (P, P ) (reflexivity) and we
count pairs (P1, P2) and (P2, P1) as only one pair (symmetry).

continuation, namely ({},{(r1:street,r2:street)},(r1:Address,r2:Address)). This pro-
cess ensures a progressive selection process of link key candidates, where any
class pair can be considered, excluding inconsistent or not relevant pairs.

Let us consider now the link key candidate ({},{(r1:name,p12:given_name)},
(r1:Restaurant,p12:Person)) that is returned in task Pr. Actually, this link key
candidate instantiates an inconsistent pair of classes, since a restaurant and a
person cannot materialize the same entity. As such this candidate should be
excluded by a domain expert. Accordingly, the paper [25] follows this idea and
proposes the LKSA algorithm aimed at the selection of link key candidate guided
by the associated pairs of classes. This enforces the fact that link key candidates
with associated pairs of classes are significant and bring an added value in link
key management.

6.3. The Redundancy of Link key candidates

The next experiments are aimed at determining how important is redun-
dancy of link key candidates in real-world datasets. Firstly, the set of link key

19

candidates, named “LK-PS”, is generated thanks to the LK-pattern structure.
Then the redundancy of candidates is based on the equality of partitions in
the LK-partition pattern structure, i.e., two link key candidates are declared as
redundant when they induce the same link partition. Then, the set of link key
candidates lying in the OC-poset, related to the LK-partition pattern structure
and named “LK-PPS”, can be generated. The results can be read as follows. In
the tasks Restaurants, Person1, and Pr, it comes that |LK-PS| = |LK-PPS|. Thus
no redundancy among link keys can be observed in these real-world datasets.
Besides that, in task Actor, there are 29 pairs of partitions which are equal,
showing that some redundant candidates are existing in these datasets. More
precisely, |LK-PPS| is lower than |K-PS| by 1%.

Hence, it can be concluded that redundancy of link key candidates based on
equality is not really significant in the real-world datasets considered in these
experiments. This also shows that equality of partitions is probably a too strong
constraint and should be relaxed. Following this line, the next experiments are
no longer based on equality of partitions but instead on similarity of partitions
as introduced in Definition 11. The similarity measure is evaluated for all pairs
of candidates contained in LK-PS. Figure 6 shows the cumulative distributions
for each task.

The results can be read as follows. The link key candidates generate similar
partitions when the similarity threshold is equal or below 0.8 in task Restaurants,
and when the similarity threshold is equal or below 0.9 in tasks Person 1 and Pr.
In the task Actor, it can be observed that 29 pairs of link key candidates
are generating the same partitions when the similarity threshold is 1, 0. By
contrast, this number exponentially increases when the threshold is set to 0.9, as
the number of similar pairs of partitions jumps from 29 to 1067! More generally,
such a break can be verified in all the datasets with threshold values varying
from 0.5 to 0.9, except in Restaurants where the number of pairs is smaller than
in the other datasets.

Contrasting the results of the experiments based on equality of partitions,
the experiments based on similarity show that a “redundancy” effectively exists
in real-world datasets, even if it is rather weak. Then redundancy based on
similarity of partitions can be considered as a valuable criterion for merging
link key candidates, especially in large datasets. Indeed, the number of link key
candidates can increase very quickly, and then the resulting pattern concept
lattices become much harder to visualize, to handle, and to interpret. Merging
redundant link keys based on similarity of partitions is a way to minimize the
total number of link keys and to build kinds of “classes” of link keys. Then
such classes of link keys can be proposed to domain experts for evaluation and
interpretation. More should be done in this way and this opens new lines of
research for future work.

7. Related Work

Data interlinking is a difficult task is studied since a long time. Systems
such as “SILK” [4] and “LIMES” [3] rely on link specifications to discover links,

20

and in particular identity links, between two RDF datasets. Link specifications
define conditions that subjects should meet in order to be linked. These speci-
fications are complex, as they are composed of many elements, (i) properties to
be compared, (ii) transformations to be applied, (iii) similarity measures to be
used for comparing pairs, (iv) aggregation functions for combining several sim-
ilarity values, and finally (v) similarity thresholds. To optimize link generation
in terms of runtime efficiency and scaling, SILK relies on blocking strategies. By
contrast, LIMES takes advantage of the triangular inequality in the Euclidean
space for reducing the number of comparisons.

Moreover, in SILK and LIMES, while users may manually define link spec-
ifications, algorithms such as “RAVEN” [26], “EAGLE” [6], and “LIGON” [27],
are used to automatically discover links between datasets. One main common
characteristic shared by these algorithms is that they are based on machine
learning techniques, and thus they require a set of reference links. Furthermore,
they do not take into account the semantics of ontologies possibly attached to
the considered datasets, which describe elements in the RDF triples and provide
classes.

As underlined above, link specifications require the definition of properties
and classes to be compared, as well as determining the adapted similarity mea-
sures and associated thresholds. To a certain extent, link keys can be considered
as a particular kind of link specifications. In this way, link key discovery tech-
niques can be valuable assets and complements for supporting approaches based
on link specifications, as they automatically provide properties and classes to be
compared without requiring reference links. Such properties and classes provide
a support for link specification along with similarity measures and thresholds.
There are some other approaches in link discovery relying on logical axioms
from which are deriving the researched links. As they are based on a logical
interpretation, logical reasoners or rule interpreters can take advantage of logical
axioms to infer such new facts. These approaches are more efficient when the
In particular, key-
descriptions of the same entity are likely to be identical.
based approaches are falling in this category. A key is a set of properties whose
values unequivocally define instances of the associated class within a dataset.
Although keys are not directly intended to be used in data interlinking, they
can easily be used for solving this task, as shown in the following example.
Let us consider two datasets, say D1 and D2, and the following key related to
D1 and D2, namely “{firstName,lastName}, (Person)”. Here firstName and lastName
are properties, and Person is a class of individuals related to D1 and D2. The
key can be interpreted as follows: when an instance say p1 of Person in D1 and
an instance say p2 of the same class Person in D2 have the same firstName and
the same lastName, then p1 and p2 represent the same entity, and an identity
link can be created for relating p1 and p2. As one can see, based on the above
description, keys are very close to link keys.

Keys, as this is also the case for link keys, are not necessarily provided in
datasets, and various approaches have been proposed to automatically discover-
ing such keys. For example, the “KD2R” algorithm [28] discovers keys that are
valid in multiple RDF datasets. However, when the datasets contain duplicates

21

or erroneous data, no keys can be discovered using this approach. Furthermore,
the KD2R algorithm is hardly scalable when dealing with large datasets. Thus
a new algorithm called “SAKey” was introduced in [29] to improve applicabil-
ity and scalability of the precedent key-based approach. SAKey discovers keys
with exceptions called n-almost keys. A set of properties is an n-almost key if
at most n instances share the same values for this set of properties. A later
improvement was brought in the “VICKEY” algorithm [24] for dealing with the
absence of keys in some datasets. VICKEY is able to discover the so-called
“conditional keys” that are valid only in a part of the whole dataset where spe-
cific conditions made precise within the conditional key are met. When they
are running, KD2R, SAKey, and VICKEY, are following the same main steps.
Firstly, they compute a set of maximal non-keys, which are based on combina-
tions of properties sharing the same values for at least two instances. Then the
keys are computed from the set of non-keys. Moreover, these algorithms make
use of various efficient techniques to reduce the search space of potential keys.
A closer look on the way keys are used in data interlinking shows that the
two datasets considered for interlinking should rely on the same ontology or an
ontology alignment has to be provided. This can be seen as a limitation that
can be overcome by using link keys. Then, as this is the case for keys, link keys
can be declared as logical axioms. By contrast, unlike keys, link keys can be
used in data interlinking in scenarios when different ontologies are involved or
when no ontology alignment is provided. Finally, an experimental comparison
between the present approach based on link keys, and approaches based on keys
and conditional keys, in terms of recall, precision, and F-measure, is detailed
in [18].

In the FCA community, a recent work dealing with data interlinking was pro-
posed in [30]. More precisely, the Graph-FCA system [31] is aimed at extending
the FCA setting to deal with multi-relational or graph data. Graph-FCA can be
used to discover identity links between instances as well as alignments between
properties and classes. Graph-FCA and the approach presented in this paper
share some commonalities, such as discovering identity links between instances
in different datasets. However, the objectives of the two systems are quite differ-
ent, dealing with graph data for the former and dealing with link key discovery
for the latter. Nevertheless, a careful comparison of both approaches remains
to be carried out.

8. Conclusion

In this paper, we have made precise an original research work about data
interlinking based on FCA and Pattern Structures. The main objective is to dis-
cover the so-called link key candidates and the related identity link sets across
two RDF datasets in the web of data. Actually, link keys are syntactic con-
structions based on pairs of properties and of classes that can be considered
as rules allowing to infer identity links between two subjects in RDF datasets.
FCA and pattern structures are well adapted to support this discovery pro-
cess. FCA is used to discover link key candidates while pattern structures allow

22

one to associate pair of classes with a link key candidate. Moreover, when the
owl:sameAs relation is regarded as an equivalence relation, two link key candi-
dates can be considered as redundant when they generate the same link sets.
Then partition pattern structures allow one to study the potential redundancy
of link key candidates. It appears that FCA and pattern structures are really
valuable formalisms in link key discovery, and this paper demonstrates it.

Future work can be carried out in several directions. Firstly, there is a
need for improving the formalization of link key discovery within the FCA and
the pattern structure formalisms. In particular, more complete investigations
about the relations between equality-based and similarity-based partitions, and
as well the significance of redundancy remain to be done.
In parallel, more
experiments should be performed to support and demonstrate these theoretical
aspects. Finally, another direction is to study the relations existing with link
discovery in Knowledge Graphs and more generally in the web of data [32, 33],
especially link prediction [34] and entity summarization [35].

Acknowledgments

This work has been partially supported by the ANR project Elker (ANR-

17-CE23-0007-01).

References

[1] M. Nentwig, M. Hartung, A.-C. Ngonga Ngomo, E. Rahm, A survey of
current Link Discovery frameworks, Semantic Web Journal 8 (3) (2017)
419–436.

[2] A. Hogan, The Web of Data, Springer, 2020.

[3] A. N. Ngomo, S. Auer, LIMES – A Time-Efficient Approach for Large-Scale
Link Discovery on the Web of Data, in: T. Walsh (Ed.), Proceedings of
the 22nd International Joint Conference on Artificial Intelligence (IJCAI),
IJCAI/AAAI, 2011, pp. 2312–2317.

[4] J. Volz, C. Bizer, M. Gaedke, G. Kobilarov, Silk – A Link Discovery Frame-
work for the Web of Data, in: C. Bizer, T. Heath, T. Berners-Lee, K. Idehen
(Eds.), Proceedings of the WWW2009 Workshop on Linked Data on the
Web (LDOW), CEUR Workshop Proceedings 538, 2009.

[5] R. Isele, C. Bizer, Active learning of expressive linkage rules using genetic

programming, Journal of web semantics 23 (2013) 2–15.

[6] A. N. Ngomo, K. Lyko, EAGLE: Efficient Active Learning of Link Specifica-
tions Using Genetic Programming, in: E. Simperl, P. Cimiano, A. Polleres,
Ó. Corcho, V. Presutti (Eds.), Proceedings of the 9th Extended Seman-
tic Web Conference (ESWC), Lecture Notes in Computer Science 7295,
Springer, 2012, pp. 149–163.

23

[7] A. N. Ngomo, K. Lyko, Unsupervised learning of link specifications: de-
terministic vs. non-deterministic, in: P. Shvaiko, J. Euzenat, K. Srinivas,
M. Mao, E. Jiménez-Ruiz (Eds.), Proceedings of the 8th International
Workshop on Ontology Matching at ISWC, CEUR Workshop Proceedings
1111, 2013, pp. 25–36.

[8] F. Saïs, N. Pernelle, M.-C. Rousset, L2R: A Logical Method for Reference
Reconciliation, in: Proc. 22nd National Conference on Artificial Intelligence
(AAAI), Vancouver (CA), AAAI Press, 2007, pp. 329–334.

[9] M. Al-Bakri, M. Atencia, S. Lalande, M.-C. Rousset, Inferring same-as facts
from Linked Data: an iterative import-by-query approach, in: Proceedings
of the 29th AAAI Conference on Artificial Intelligence, Austin (TX US),
AAAI Press, 2015, pp. 9–15.

[10] M. Al-Bakri, M. Atencia, J. David, S. Lalande, M.-C. Rousset, Uncertainty-
sensitive reasoning for inferring sameAs facts in linked data, in: Proceedings
of the 22nd European Conference on Artificial intelligence (ECAI), Den
Haague (NL), 2016, pp. 698–706.

[11] M. Atencia, J. David, J. Euzenat, Data interlinking through robust linkkey

extraction, in: Proceedings of ECAI, 2014, pp. 15–20.

[12] M. Atencia, J. David, J. Euzenat, A. Napoli, J. Vizzini, Link key candidate
extraction with relational concept analysis, Discrete Applied Mathematics
273 (2020) 2–20.

[13] N. Abbas, J. David, A. Napoli, Discovery of Link Keys in RDF Data Based
on Pattern Structures: Preliminary Steps, in: F. J. Valverde-Albacete,
M. Trnecka (Eds.), Proceedings of the International Conference on Con-
cept Lattices and Their Applications (CLA), CEUR Workshop Proceedings
2668, 2020, pp. 235–246.

[14] M. Atencia, J. David, J. Euzenat, What can FCA do for database linkkey
extraction?, in: S. O. Kuznetsov, A. Napoli, S. Rudolph (Eds.), Proceedings
of FCA4AI Workshop, CEUR Proceedings Vol-1257, 2014, pp. 85–92.

[15] B. Ganter, R. Wille, Formal Concept Analysis: Mathematical Foundations,

Springer, 1999.

[16] B. Ganter, S. O. Kuznetsov, Pattern Structures and Their Projections,
in: H. S. Delugach, G. Stumme (Eds.), Proceedings of the International
Conference on Conceptual Structures (ICCS), Lecture Notes in Computer
Science 2120, Springer, 2001, pp. 129–142.

[17] M. Kaytoue, S. O. Kuznetsov, A. Napoli, S. Duplessis, Mining Gene Expres-
sion Data with Pattern Structures in Formal Concept Analysis, Information
Sciences 181 (10) (2011) 1989–2001.

24

[18] N. Abbas, A. Bazin, J. David, A. Napoli, A Study of the Discovery and
Redundancy of Link Keys Between Two RDF Datasets Based on Partition
Pattern Structures, in: P. C. Ortega, O. Krídlo (Eds.), Proceedings of
the International Conference on Concept Lattices and Their Applications
(CLA), CEUR Workshop Proceedings 3308, 2022, pp. 175–189.

[19] J. Baixeries, M. Kaytoue, A. Napoli, Characterizing functional dependen-
cies in formal concept analysis with pattern structures, Annals of Mathe-
matics and Artificial Intelligence 72 (2014) 129–149.

[20] F. Baader, D. Calvanese, D. McGuinness, P. Patel-Schneider, D. Nardi,
et al., The Description Logic Handbook: Theory, Implementation and Ap-
plications, Cambridge University Press, 2003.

[21] M. Atencia, J. David, J. Euzenat, On the relation between keys and link

keys for data interlinking, Semantic Web Journal 12 (4) (2021) 547–567.

[22] A. Berry, A. Gutierrez, M. Huchard, A. Napoli, A. Sigayret, Hermes: a sim-
ple and efficient algorithm for building the AOC-poset of a binary relation,
Annals of Mathematics and Artificial Intelligence 72 (2014) 45–71.

[23] W. M. Rand, Objective criteria for the evaluation of clustering methods,

Journal of the American Statistical Association 66 (336) (1971) 846–850.

[24] D. Symeonidou, L. Galárraga, N. Pernelle, F. Saïs, F. M. Suchanek,
VICKEY: Mining Conditional Keys on Knowledge Bases, in: Proceed-
ings of 16th International Semantic Web Conference (ISWC), LNCS 10587,
Springer, 2017, pp. 661–677.

[25] N. Abbas, J. David, A. Napoli, LKSA : un algorithme de sélection de clés
de liage dans des données RDF guidée par des paires de classes, in: J. Azé,
V. Lemaire (Eds.), Extraction et Gestion des Connaissances (EGC), Vol.
E-37 of RNTI, Éditions RNTI, 2021, pp. 205–216.

[26] A. N. Ngomo, J. Lehmann, S. Auer, K. Höffner, RAVEN – Active Learning
of Link Specifications, in: P. Shvaiko, J. Euzenat, T. Heath, C. Quix,
M. Mao, I. F. Cruz (Eds.), Proceedings of the 6th International Workshop
on Ontology Matching, CEUR Workshop Proceedings 814, 2011.

[27] M. A. Sherif, K. Dreßler, A. N. Ngomo, LIGON – link discovery with
noisy oracles, in: P. Shvaiko, J. Euzenat, E. Jiménez-Ruiz, O. Hassanzadeh,
C. Trojahn (Eds.), Proceedings of the 15th International Workshop on
Ontology Matching (co-located with ISWC), CEUR Workshop Proceedings
2788, 2020, pp. 48–59.

[28] N. Pernelle, F. Saïs, D. Symeonidou, An automatic key discovery approach

for data linking, Journal of Web Semantics 23 (2013) 16–30.

25

[29] D. Symeonidou, V. Armant, N. Pernelle, F. Saïs, SAKey: Scalable Al-
most Key Discovery in RDF Data, in: Proceedings of 13th International
Semantic Web Conference (ISWC), LNCS 8796, Springer, 2014, pp. 33–49.

[30] S. Ferré, Exploring the Application of Graph-FCA to the Problem of
Knowledge Graph Alignment, in: P. Cordero, O. Krídlo (Eds.), Proceed-
ings of the Sixteenth International Conference on Concept Lattices and
Their Applications (CLA), CEUR Workshop Proceedings 3308, 2022, pp.
79–92.

[31] S. Ferré, P. Cellier, Graph-FCA: An extension of Formal Concept Analysis
to knowledge graphs, Discrete applied mathematics 273 (2020) 81–102.

[32] A. Haller, J. D. Fernández, M. R. Kamdar, A. Polleres, What Are Links in
Linked Open Data? A Characterization and Evaluation of Links between
Knowledge Graphs on the Web, ACM Journal of Data and Information
Quality 12 (2) (2020) 9:1–9:34.

[33] A. Haller, A. Polleres, D. Dobriy, N. Ferranti, S. J. R. Méndez, An Analysis
of Links in Wikidata, in: P. Groth, M. Vidal, F. M. Suchanek, P. A. Szekely,
P. Kapanipathi, C. Pesquita, H. Skaf-Molli, M. Tamper (Eds.), Proceedings
of the 19th International Conference on Semantic Web (ESWC), Lecture
Notes in Computer Science 13261, Springer, 2022, pp. 21–38.

[34] J. Portisch, N. Heist, H. Paulheim, Knowledge graph embedding for data
mining vs. knowledge graph embedding for link prediction – two sides of
the same coin?, Semantic Web 13 (3) (2022) 399–422.

[35] E. Yang, F. Hao, Y. Yang, C. D. Maio, A. Nasridinov, G. Min, L. T. Yang,
Incremental Entity Summarization With Formal Concept Analysis, IEEE
Transactions on Services Computing 15 (6) (2022) 3289–3303.

26

