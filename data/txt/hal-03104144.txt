Grammars for Document Spanners
Liat Peterfreund

To cite this version:

Liat Peterfreund. Grammars for Document Spanners. ICDT 2021 - 24th International Conference on
Extending Database Technology, Mar 2021, Nicosia / Virtual, Cyprus. ￿hal-03104144￿

HAL Id: hal-03104144

https://inria.hal.science/hal-03104144

Submitted on 8 Jan 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Grammars for Document Spanners

Liat Peterfreund
IRIF - CNRS & Université de Paris, Paris, France
University of Edinburgh, Edinburgh, UK
liatpf.cs@gmail.com

Abstract

We propose a new grammar-based language for deﬁning information-extractors from documents
(text) that is built upon the well-studied framework of document spanners for extracting structured
data from text. While previously studied formalisms for document spanners are mainly based on
regular expressions, we use an extension of context-free grammars, called extraction grammars, to
deﬁne the new class of context-free spanners. Extraction grammars are simply context-free grammars
extended with variables that capture interval positions of the document, namely spans. While
regular expressions are eﬃcient for tokenizing and tagging, context-free grammars are also eﬃcient
for capturing structural properties. Indeed, we show that context-free spanners are strictly more
expressive than their regular counterparts. We reason about the expressive power of our new class
and present a pushdown-automata model that captures it. We show that extraction grammars can be
evaluated with polynomial data complexity. Nevertheless, as the degree of the polynomial depends
on the query, we present an enumeration algorithm for unambiguous extraction grammars that, after
quintic preprocessing, outputs the results sequentially, without repetitions, with a constant delay
between every two consecutive ones.

2012 ACM Subject Classiﬁcation Information systems → Relational database model; Information
systems → Data model extensions

Keywords and phrases Information Extraction, Document Spanners, Context-free Grammars, Reg-
ular Expressions, Pushdown Automata.

Digital Object Identiﬁer 10.4230/LIPIcs...

1

Introduction

The abundance and availability of valuable textual resources in the last decades position text
analytics as a standard component in data-driven workﬂows. One of the core operations that
aims to facilitate the analysis and integration of textual content is Information Extraction (IE),
the extraction of structured data from text. IE arises in a large variety of domains, including
social media analysis [4], health-care analysis [44], customer relationship management [1],
information retrieval [46], and more.

Rules have always been a key component in various paradigms for IE, and their roles
have varied and evolved over the time. Systems such as Xlog [39] and IBM’s SystemT [28, 6]
use rules to extract relations from text (e.g., tokenizer, dictionary lookup, and part-of-speech
tagger) that are further manipulated with relational query languages. Other systems use
rules to generate features for machine-learning classiﬁers [27, 36].

Document Spanners. The framework of document spanners that was presented by Fagin
et al. provides a theoretical basis for investigating the principles of relational rule systems
for IE [12]. The research on document spanners has focused on their expressive power [12,
15, 35, 18, 33, 20] their computational complexity [2, 14, 19, 34], incompleteness [30, 34],
and other system aspects such as cleaning [13], dynamic complexity [21], distributed query
planning [8] and an annotated variant [9].

In the documents spanners framework, a document d is a string over a ﬁxed ﬁnite
alphabet, and a spanner is a function that extracts from a document a relation over the
spans of d. A span x is a half-open interval of positions of d and it represents a substring

© Liat Peterfreund;
licensed under Creative Commons License CC-BY

Leibniz International Proceedings in Informatics
Schloss Dagstuhl – Leibniz-Zentrum für Informatik, Dagstuhl Publishing, Germany

XX:2

Grammars for Document Spanners

x

y

[1, 2i
[3, 4i
[3, 4i

[2, 3i
[4, 5i
[4, 6i

S → B ‘x aAb ay B
A → aAb ax‘y
B → aB bB (cid:15)

‘x aa ax‘y bb ay b
aa ‘x aa ax‘y bb ay b
aa ‘x a ax‘y b ay b

Figure 1 Extracted relation

Figure 2 Production rules

Figure 3 Ref-words

dx of d that is identiﬁed by these positions. A natural way to specify a spanner is by
a regex formula: a regular expression with embedded capture variables that are viewed
as relational attributes. For instance, the spanner that is given by the regex formula
(a ∨ b)∗ ‘x aa∗ ax‘y bb∗ ay (a ∨ b)∗ extracts from documents spans x and y that correspond,
respectively, with a non-empty substring of a’s followed by a non-empty substring of b’s. In
particular, it extracts from the document ababb the relation depicted in Figure 1.

The class of regular spanners is the class of spanners deﬁnable as the closure of regex
formulas under positive relational algebra operations: projection, natural join and union. The
class of regular spanners can be represented alternatively by ﬁnite state machines, namely
variable-set automata (vset-automata), which are nondeterministic ﬁnite-state automata that
can open and close variables (that, as in the case of regex formulas, play the role of the
attributes of the extracted relation). Core spanners [12] are obtained by extending the class
of regular spanners with string-equality selection on span variables. Although core spanners
can express strictly more than regular spanners, they are still quite limited as, e.g., there is
no core spanner that extracts all pairs x and y of spans having the same length [12].

To date, most research on spanners has been focused on the regular representation, that
is, regular expressions and ﬁnite state automata. While regular expressions are useful for
segmentation and tokenization, they are not useful in describing complex nested structures
(e.g., syntactic structure of a natural language sentence) and relations between diﬀerent
parts of the text. Regular languages also fall short in dealing with tasks such as syntax
highlighting [31] and ﬁnding patterns in source code [40]. For all of the above mentioned
tasks we have context-free grammars. It is well known that context-free languages are strictly
more expressive than regular languages. While Büchi [5] has showed that regular languages
are equivalent to monadic second order logic (over strings), Lautemann et al. [26] have
showed that adding an existential quantiﬁcation over a binary relation that is interpreted as
a matching is enough to express all context-free languages. This quantiﬁcation, intuitively, is
what makes it possible to also express structural properties.

Contribution. In this work we propose a new grammar-based approach for deﬁning the class
of context-free spanners. Context-free spanners are deﬁned with extraction grammars which,
like regex formulas, incorporate capture variables that are viewed as relational attributes.
Extraction grammars produce ref-words which are words over an extended alphabet that
consists of standard terminal symbols along with variable operations that denote opening
and closing of variables. The result of evaluating an extraction grammar on a document d is
deﬁned via the ref-words that are produced by the grammar and equal to d after erasing the
variable operations. For example, the extraction grammar whose production rules appear
in Figure 2 produces the ref-words ‘x a ax‘y b ay abb and ab ‘x a ax‘y b ay b, and more.
Hence, it extracts from d := ababb the two ﬁrst tuples from the relation in Figure 1. In
Figure 3 there are additional examples of ref-words produced by this grammar. In general,
the given grammar extracts from documents the spans x and y that correspond, respectively,
with a non-empty substring of a’s followed by an equal-length substring of b’s. With a slight

L. Peterfreund

XX:3

adaptation of Fagin et al. inexpressibility proof [12, Theorem 4.21], it can show that this
spanner is inexpressible by core spanners.

Indeed, we show that context-free spanners are strictly more expressive than regular
spanners and that the restricted class of regular extraction grammars captures the regular
spanners. We compare the expressiveness of context-free spanners against core and generalized
core spanners and show that context-free spanners are incomparable to any of these classes.
In addition to extraction grammars, we present a pushdown automata model that captures
the context-free spanners.

In term of evaluation of context-free spanners we can evaluate extraction grammars in
polynomial time in data complexity, where the spanner is regarded as ﬁxed and the document
as input. However, as the degree of this polynomial depends on the query (in particular, in
the number of variables in the relation it extracts), we propose an enumeration algorithm for
unambiguous extraction grammars. Our algorithm outputs the results consecutively, after
quintic preprocessing, with constant delay between every two answers. In the ﬁrst step of
the preprocessing stage we manipulate the extraction grammar so that it will be adjusted to
a speciﬁc document. In the second step of the preprocessing we change it in a way that its
non-terminals include extra information on the variable operations. This extra information
enables us to skip sequences of productions that do not aﬀect the output, hence obtaining
a delay that is independent of the input document and linear in the number of variables
associated with our spanner.

Related Work. Grammar-based parsers are widely used in IE systems [45, 38]. There are,
as well, several theoretical frameworks that use grammars for IE, one of which is Knuth’s
framework of attribute grammars [24, 25]. In this framework, the non-terminals of a grammar
are attached with attributes1 that pass semantic information up and down a parse tree.
While both extraction grammars and attribute grammars extract information via grammars,
it seems as if the expressiveness of these formalisms is incomparable to extraction grammars.

The problem of enumerating words of context-free grammars arises in diﬀerent contexts [42,
32]. Providing complexity guarantees on the enumeration is usually tricky and requires
assumptions either on the grammar or on the output. Mäkinen [29] has presented an
enumeration algorithm for regular grammars and for unambiguous context-free grammars
with additional restrictions (strongly preﬁx-free and length complete). Later, Dömösi [10] has
presented an enumeration algorithm for unambiguous context-free grammars that outputs,
with quadratic delay, only the words of a ﬁxed length.

Organization. In Section 2, we present extraction grammars, their semantics and extraction
pushdown automata. In Section 3, we shortly discuss the expressive power of context-free
spanners and their evaluation. In Sections 4 and 5, we present our enumeration algorithm,
and in Section 6 we conclude.

2

Context-Free Spanners

In this section we present the class of context-free spanners by presenting two representation
systems: extraction grammars and extraction pushdown automata.

1 The term “attributes” was previously used in the relational context; Here the meaning is diﬀerent.

XX:4

Grammars for Document Spanners

2.1 Preliminaries

We start by presenting the formal setup based on notations and deﬁnitions used in previous
works on document spanners (e.g., [12, 19]).

Strings and Spans. We set an inﬁnite set Vars of variables and ﬁx a ﬁnite alphabet Σ
that is disjoint of Vars. In what follows we assume that our alphabet Σ consists of at least
two letters. A document d is a ﬁnite sequence over Σ whose length is denoted by |d|. A
span identiﬁes a substring of d by specifying its bounding indices. Formally, if d = σ1 · · · σn
where σi ∈ Σ then a span of d has the form [i, ji where 1 ≤ i ≤ j ≤ n + 1 and d[i,ji denotes
the substring σi · · · σj−1. When i = j it holds that d[i,ji equals the empty string, which we
denote by (cid:15). We denote by Spans(d) the set of all possible spans of a document d.

Document Spanners. Let X ⊆ Vars be a ﬁnite set of variables and let d be a document.
An (X, d)-mapping assigns spans of d to variables in X. An (X, d)-relation is a ﬁnite set of
(X, d)-mappings. A document spanner (or spanner, for short) is a function associated with a
ﬁnite set X of variables that maps documents d into (X, d)-relations.

2.2 Extraction Grammars

The variable operations of a variable x ∈ Vars are ‘x and ax where, intuitively, ‘x denotes
the opening of x, and ax its closing. For a ﬁnite subset X ⊆ Vars, we deﬁne the set
ΓX := {‘x, ax x ∈ X}. That is, ΓX is the set that consists of all the variable operations of
all variables in X. We assume that Σ and ΓX are disjoint. We extend the classical deﬁnition
of context-free grammars [23] by treating the variable operations as special terminal symbols.
Formally, a context-free extraction grammar, or extraction grammar for short, is a tuple
G := (X, V, Σ, P, S) where

X ⊆ Vars is a ﬁnite set of variables,
V is a ﬁnite set of non-terminal symbols2,
Σ is a ﬁnite set of terminal symbols;
P is a ﬁnite set of production rules of the form A → α where A is a non-terminal and
α ∈ (V ∪ Σ ∪ ΓX )∗, and
S is a designated non-terminal symbol referred to as the start symbol.

We say that the extraction grammar G is associated with X.

(cid:73) Example 1.
In this and in the following examples we often denote the elements in V by
upper case alphabet letters from the beginning of the English alphabet (A, B, C, . . .). Let
Σ = {a, b}, and let us consider the grammar disjEqLen associated with the variables {x, y}
that is given by the following production rules:

S → B ‘x A ay B B ‘y A ax B
A → aAa aAb bAb bAa
A → ax B ‘y ay B ‘x
B → (cid:15) aB bB

Here and in what follows, we use the compact notation for production rules by writing
· · · αn instead of the productions A → α1, · · · , A → αn. As we shall later see,
A → α1
(cid:74)
this grammar extracts pairs of disjoint spans with the same length.

2 Note that these are often referred to as variables, however, here we use the term ‘non-terminals’ to

distinguish between these symbols and elements in Vars.

L. Peterfreund

XX:5

While classical context-free grammars generate strings, extraction grammars generate
words over the extended alphabet Σ ∪ ΓX . These words are referred to as ref-words [37].
Similarly to (classical) context-free grammars, the process of deriving ref-words is deﬁned via
the notations ⇒, ⇒n, ⇒∗ that stand for one, n, and several (possibly zero) derivation steps,
respectively. To emphasize the grammar being discussed, we sometime use the grammar as
a subscript (e.g., ⇒∗
G). For the full deﬁnitions we refer the reader to Hopcroft et al. [23].
A non-terminal A is called useful if there is some derivation of the form S ⇒∗ αAβ ⇒∗ w
where w ∈ (Σ ∪ ΓX )∗. If A is not useful then it is called useless. For complexity analysis, we
deﬁne the size |G| of an extraction grammar G as the sum of the number of symbols at the
right-hand sides (after the →) of its rules.

2.3 Semantics of Extraction Grammars

Following Freydenberger [16] we deﬁne the semantics of extraction grammars using ref-words.
A ref-word r ∈ (Σ ∪ ΓX )∗ is valid (for X) if each variable of X is opened and then closed
exactly once, or more formally, for each x ∈ X the string r has precisely one occurrence of
‘x, precisely one occurrence of ax, and the former is before (i.e., to the left of) the latter.

(cid:73) Example 2. The ref-word r1 := ‘x aa ay‘x ab ay is not valid for {x, y} whereas the
(cid:74)
ref-words r2 := ‘x aa ax‘y ab ay and r3 := ‘y a ay‘x a ax ab are valid for {x, y}.

To connect ref-words to terminal strings and later to spanners, we deﬁne a morphism
clr : (Σ ∪ ΓX )∗ → Σ∗ by clr(σ) := σ for σ ∈ Σ, and clr(τ ) := (cid:15) for τ ∈ ΓX . For d ∈ Σ∗,
let Ref(d) be the set of all valid ref-words r ∈ (Σ ∪ ΓX )∗ with clr(r) = d. By deﬁnition,
every r ∈ Ref(d) has a unique factorization r = r0
x for each x ∈ X. With
these factorizations, we interpret r as a (X, d)-mapping µr by deﬁning µr(x) := [i, ji, where
x)| + 1 and j := i + |clr(rx)|. An alternative way of understanding µr = [i, ji is
i := |clr(r0
that i is chosen such that ‘x occurs between the positions in r that are mapped to σi−1
and σi, and ax occurs between the positions that are mapped to σj−1 and σj (assuming
that d = σ1 · · · σ|d|, and slightly abusing the notation to avoid a special distinction for the
non-existing positions σ0 and σ|d|+1).

x · ‘x · rx · ax · r00

(cid:73) Example 3. Let d = aaab. The ref-word r2 from Example 2 is interpreted as the
(cid:74)
({x, y}, d)-mapping µr2 with µr2 (x) = [1, 3i and µr2(y) = [3, 5i.

Extraction grammars deﬁne ref-languages which are sets of ref-words. The ref-language
R(G) of an extraction grammar G := (X, V, Σ, P, S) is deﬁned by R(G) := {r ∈ (Σ ∪
ΓX )∗ S ⇒∗ r} . Note that we use R(G) instead of L(G) being used for standard grammars,
to emphasize that the produced language is a ref-language. (We also use L(G) when G is a
standard grammar.) To illustrate the deﬁnition let us consider the following example.

(cid:73) Example 4. Both ref-words r1 and r2 from Example 2 are in R(disjEqLen) where
disjEqLen is the grammar described in Example 1. Producing both r1 and r2 starts
similarly with the sequence: S ⇒ B ‘x A ay B ⇒2 ‘x A ay ⇒ ‘x aAb ay ⇒ ‘x aaAab ay.
The derivation of r1 continues with ⇒ ‘x aa ay B ‘x ab ay ⇒ ‘x aa ay‘x ab ay whereas
(cid:74)
that of r2 continues with ⇒ ‘x aa ax B ‘y ab ay ⇒ ‘x aa ax‘y ab ay.

We denote by Ref(G) the set of all ref-words in R(G) that are valid for X. Finally, we deﬁne the
set Ref(G, d) of ref-words in Ref(G) that clr maps to d. That is, Ref(G, d) := Ref(G)∩Ref(d) .
The result of evaluating the spanner

on a document d is then deﬁned as

G
(cid:75)

(cid:74)

(d) := {µr r ∈ Ref(G, d)} .

G
(cid:75)
(cid:74)

XX:6

Grammars for Document Spanners

(cid:73) Example 5. Let us consider the document d := aaba. The grammar disjEqLen maps d
into a set of ({x, y}, d)-mappings, amongst are µr2 that is deﬁned by µr2 (x) := [1, 3i and
µr2 (y) := [3, 5i and µr3 that is deﬁned by µr3 (x) := [2, 3i and µr3 (y) := [1, 2i. It can be
shown that the grammar disjEqLen maps every document d into all possible ({x, y}, d)-
mappings µ such that µ(x) and µ(y) are disjoint (i.e., do not overlap) and have the same
(cid:74)
length (i.e., |dµ(x)| = |dµ(y)|).

A spanner S is said to be deﬁnable by an extraction grammar G if S(d) =
document d.

G
(cid:75)

(cid:74)

(d) for every

(cid:73) Deﬁnition 6. A context-free spanner is a spanner deﬁnable by an extraction grammar.

2.4 Extraction Pushdown Automata

An extraction pushdown automaton, or extraction PDA, is associated with a ﬁnite set X ⊆ Vars
of variables and can be viewed as a standard pushdown automata over the extended alphabet
Σ ∪ ΓX . Formally, an extraction PDA is a tuple A := (X, Q, Σ, ∆, δ, q0, Z, F ) where X is a
ﬁnite set of variables; Q is a ﬁnite set of states; Σ is the input alphabet; ∆ is a ﬁnite set
which is called the stack alphabet; δ is a mapping Q × (cid:0)Σ ∪ {(cid:15)} ∪ ΓX
which is
called the transition function; q0 ∈ Q is the initial state; Z ∈ ∆ is the initial stack symbol;
and F ⊆ Q is the set of accepting states. Indeed, extraction PDAs run on ref-words (i.e.,
ﬁnite sequences over Σ ∪ ΓX ), as opposed to classical PDAs whose input are words (i.e., ﬁnite
sequences over Σ). Similarly to classical PDAs, the computation of extraction PDAs can be
described using sequences of conﬁgurations: a conﬁguration of A is a triple (q, w, γ) where q
is the state, w is the remaining input, and γ is the stack content such that the top of the
stack is the left end of γ and its bottom is the right end. We use the notation ‘∗ similarly to
how it is used in the context of PDAs [22] and deﬁne the ref-language R(A):

(cid:1) × ∆ → 2Q×∆∗

R(A) := {r ∈ (Σ ∪ ΓX )∗ ∃α ∈ ∆∗, qf ∈ F : (q0, r, Z) ‘∗ (qf , (cid:15), α)} .

We denote the language of A by R(A) to emphasize that it is a ref-language, and denote by
Ref(A) the set of all ref-words in R(A) that are valid for X. The result of evaluating the
spanner

on a document d is then deﬁned as

A
(cid:74)

(cid:75)

A
(cid:74)

(cid:75)

(d) := {µr r ∈ Ref(A) ∩ Ref(d)} .

(cid:73) Example 7. We deﬁne the extraction PDA that maps a document d into the set of
({x, y}, d)-mappings µ where µ(x) ends before µ(y) starts and their lengths are the same.
The stack alphabet consists of the bottom symbol ⊥ and C, and the transition function δ is
described in Figure 4 where a transition from state q to state q0 that is labeled with τ, A/ γ
denotes that the automaton moves from state q to state q0 upon reading τ with A at the top
of the stack, while replacing A with γ. We can extend the automaton in a symmetric way
such that it will represent the same spanner as that represented by the grammar disjEqLen
(cid:74)
from Example 1.

We say that a spanner S is deﬁnable by an extraction PDA A if for every document d
it holds that
(d) = S(d). Treating the variable operations as terminal symbols enables
(cid:75)
us to use the equivalence of PDAs and context-free grammars and conclude the following
straightforward observation.

A

(cid:74)

(cid:73) Proposition 8. The class of spanners deﬁnable by extraction grammars is equal to the
class of spanners deﬁnable by extraction PDAs.

Thus, we have also an automata formalism for deﬁning the context-free spanners.

L. Peterfreund

XX:7

Σ,⊥/ ⊥

Σ,C/ CC

Σ,C/ C

Σ,C/ (cid:15)

Σ,⊥/ ⊥

q0

‘x,C/ C

qx

ax,C/ C

qxy

‘y,C/ C

qy

ay,⊥/ ⊥

qf

S → B ‘x A1 ay B B ‘y A2 ax B
Ai → aAia aAib
A1 → ax B ‘y , A2 → ay B ‘x
B → (cid:15)

aB bB

bAib

bAia, i = 1, 2

Figure 4 Transition function of Example 7

Figure 5 Productions of Example 9

2.5 Functional Extraction Grammars

Freydenberger and Holldack [17] have presented the notion of
functionality in the context of
regular spanners. We now extend it to extraction grammars. The intuition is that interpreting
an extraction grammar as a spanner disregards ref-words that are not valid. We call an
extraction grammar G functional if every ref-word in R(G) is valid.

(cid:73) Example 9. The grammar disjEqLen in our running example is not functional. Indeed,
we saw in Example 4 that the ref-word r1, although it is not valid, is in R(disjEqLen). We
can, however, simply modify the grammar to obtain an equivalent functional one. Notice that
the problem arises due to the production rules S → B ‘x A ay B and S → B ‘y A ax B.
For variable A we have A ⇒∗ r1 where r1 contains both ax and ‘y, and we also have A ⇒∗ r2
where r2 contains both ay and ‘x. To ﬁx that, we can replace the non-terminal A with
two non-terminals, namely A1 and A2, and change the production rules so that for every
ref-word r if A1 ⇒∗ r then r contains both ax and ‘y, and if A2 ⇒∗ r then r contains both
ay and ‘x. It can be shown that the grammar G whose production rules appear in Figure 5
(cid:74)
is functional and that

=

(cid:74)
(cid:73) Proposition 10.
Every extraction grammar G can be converted into an equivalent
functional extraction grammar G0 in O(|G|2 + 32k|G|) time where k is the number of variables
G is associated with.

(cid:74)

disjEqLen
(cid:75)

G
(cid:75)

.

Inspired by Chomsky’s hierarchy, we say that an extraction grammar is in Chomsky Normal
Form (CNF) if it is in CNF when viewed as a grammar over the extended alphabet Σ ∪ ΓX .
We remark that, in Proposition 10, G0 is in CNF.

2.6 Unambiguous Extraction Grammars

A grammar G is said to be unambiguous if every word it produces has a unique parse-tree.
We extend this deﬁnition to extraction grammars. An extraction grammar G is said to be
unambiguous if for every document d and every (X, d)-mapping µ ∈
(d) it holds that
there is a unique ref-word r for which µr = µ and this ref-word has a unique parse tree.
Unambiguous extraction grammars are less expressive than their ambiguous counterparts as
the Boolean case shows (i.e., unambiguous context-free grammars are less expressive than
ambiguous context-free grammars [23]).

G
(cid:75)

(cid:74)

(cid:73) Example 11. The extraction grammar given in Example 9 is not unambiguous since it
produces the ref-words ‘xax‘yay and ‘yay‘xax that correspond with the same mapping. It
can be shown that replacing the derivation B → (cid:15) with B → a b results in an unambiguous
extraction grammar which is equivalent to disjEqLen on any document diﬀerent than (cid:15).
(Note however that this does not imply that the ref-languages they produce are equal.) (cid:74)

Our main enumeration algorithm for extraction grammars relies on unambiguity and the
following observation.

(cid:73) Proposition 12. In Proposition 10, if G is unambiguous then so is G0.

XX:8

Grammars for Document Spanners

3

Expressive Power and Evaluation

In this section we compare the expressiveness of context-free spanners compared to other
studied classes of spanners and discuss its evaluation shortly.

3.1 Regular Spanners

A variable-set automaton A (or vset-automaton, for short) is a tuple A := (X, Q, q0, qf , δ)
where X ⊆ Vars is a ﬁnite set of variables also referred to as Vars(A), Q is the set of states,
q0, qf ∈ Q are the initial and the ﬁnal states, respectively, and δ : Q × (Σ ∪ {(cid:15)} ∪ ΓX ) → 2Q is
the transition function. To deﬁne the semantics of A, we interpret A as a non-deterministic
ﬁnite state automaton over the alphabet Σ ∪ ΓX , and deﬁne R(A) as the set of all ref-words
r ∈ (Σ ∪ ΓX )∗ such that some path from q0 to qf is labeled with r. Like for regex formulas,
we deﬁne Ref(A, d) = R(A) ∩ Ref(d) and ﬁnally we deﬁne for every document d ∈ Σ∗:
(d) := {µr r ∈ Ref(A, d)}. The class of regular spanners equals the class of spanners
A
(cid:74)
that are expressible as a vset-automaton [12].

(cid:75)

Inspired by Chomsky’s hierarchy, we say that an extraction grammar G is regular if
its productions are of the form A → σB and A → σ where A, B are non-terminals and
σ ∈ (Σ∪ΓX ). We then have the following equivalence that is strongly based on the equivalence
of regular grammars and ﬁnite state automata.

(cid:73) Proposition 13. The class of spanners deﬁnable by regular extraction grammars is equal
to the class of regular spanners.

3.2

(Generalized) Core Spanners

An alternative way to deﬁne regular spanners is based on the notion of regex formulas:
Formally, a regex formula is deﬁned recursively by α := ∅ | (cid:15) | σ | α ∨ α | α · α | α∗ | ‘x α ax
where σ ∈ Σ and x ∈ Vars. We denote the set of variables whose variable operations occur
in α by Vars(α) and interpret each regex formula α as a generator of a ref-word language
R(α) over the extended alphabet Σ ∪ ΓVars(α). For every document d ∈ Σ∗, we deﬁne
(d) := {µr r ∈ Ref(α, d)}. The class
Ref(α, d) = R(α) ∩ Ref(d), and the spanner
α
(cid:74)
of regular spanners is then deﬁned as the closure of regex formulas under the relational
algebra operators: union, projection and natural join.

by

α

(cid:74)

(cid:75)

(cid:75)

In their eﬀorts to capture the core of AQL which is IBM’s SystemT query language,
Fagin et al. [12] have presented the class of core spanners which is the closure of regex
formulas under the positive operators, i.e., union, natural join and projection, along with the
string equality selection that is deﬁned as follows Let S be a spanner and let x, y ∈ Vars(S),
x,yS) = Vars(S) and, for all d ∈ Σ∗,
the string equality selection ζ =
ζ =
x,yS(d) is the set of all µ ∈ S(d) where dµ(x) = dµ(y). Note that unlike the join operator
that joins mappings that have identical spans in their shared variables, the selection operator
compares the substrings of d that are described by the spans and does not distinguish
between diﬀerent spans that span the same substrings.

x,yS is deﬁned by Vars(ζ =

The class of generalized core spanners is obtained by adding the diﬀerence operator. That
is, it is deﬁned as the closure of regex formulas under union, natural join, projection, string
equality, and diﬀerence. We say that two classes S, S 0 of spanners are incomparable if both
S \ S 0 and S 0 \ S are not empty.

(cid:73) Proposition 14. The classes of core spanners and generalized core spanners are each
incomparable with the class of context-free spanners.

L. Peterfreund

XX:9

We conclude the discussion by a straightforward result on closure properties.

(cid:73) Proposition 15. The class of context-free spanners is closed under union and projection,
and not closed under natural join and diﬀerence.

3.3 Evaluating Context-Free Spanners

The evaluation problem of extraction grammars is that of computing
document and G is an extraction grammar. Our ﬁrst observation is the following.

G
(cid:75)

(cid:74)

(d) where d is a

(cid:73) Proposition 16. For every extraction grammar G and every document d it holds that
(d) can be computed in O(|G|2+|d|2k+3 k3 |G|) time where G is associated with k variables.
G
(cid:75)
(cid:74)
The proof of this proposition is obtained by iterating through all valid ref-words and
using the Cocke-Younger-Kasami (CYK) parsing algorithm [23] to check whether the current
valid ref-word is produced by G. We can, alternatively, use Valiant’s parser [41] and obtain
O(|G|2 + |d|2k+ω kω |G|) where ω < 2.373 is the matrix multiplication exponent [43].

While the evaluation can be done in polynomial time in data complexity (where G is
regarded as ﬁxed and d as input), the output size might be quite big. To be more precise,
for an extraction grammar G associated with k variables the output might consist of up
to |d|2k mappings. Instead of outputting these mappings altogether, we can output them
sequentially (without repetitions) after some preprocessing.

Our main enumeration result is the following.

(cid:73) Theorem 17. For every unambiguous extraction grammar G and every document d there
(d) with delay O(k) after O(|d|5|G|234k)
is an algorithm that outputs the mappings in
preprocessing where k is the number of variables G is associated with.

G
(cid:75)

(cid:74)

Our algorithm consists of two main stages: preprocessing and enumeration. In the prepro-
cessing stage, we manipulate the extraction grammar and do some precomputations which
are later exploited in the enumeration stage in which we output the results sequentially. We
remark that unambiguity is crucial for the enumeration stage as it allows to output the
mappings without repetition.

Through the lens of data complexity, our enumeration algorithm outputs the results
with constant delay after quintic preprocessing. That should be contrasted with regular
spanners for which there exists a constant delay enumeration algorithm whose preprocessing
is linear [2, 14]. In the following sections, we present the enumeration algorithm and discuss
its correctness but before we deal with the special case d := (cid:15). In this case,
(d) is either
G
(cid:75)
empty or contains exactly one mapping (since, by deﬁnition, the document (cid:15) has exactly
one span, namely [1, 1i). Notice that
(d) is empty if and only if G does not produce a
(cid:75)
ref-word that consists only of variable operations. To check this, it suﬃces to change the
production rules of G by replacing every occurrence of τ ∈ ΓX with (cid:15) and check whether the
new grammar produces (cid:15). This can be done in linear time [22] which completes the proof of
this case.

G
(cid:74)

(cid:74)

4

Preprocessing of the Enumeration Algorithm

Due to Propositions 10 and 12, we can assume that our unambiguous extraction grammar is
functional and in CNF. As this conversion requires O(32k|G|2), it can be counted as part of
our preprocessing.

XX:10 Grammars for Document Spanners

The preprocessing stage consists of two steps:

in the ﬁrst we adjust the extraction
grammar to a given document and add subscripts to non-terminals to track this connection,
and in the second we use superscripts to capture extra information regarding the variable
operations.

4.1 Adjusting the Extraction Grammar to d

Let G := (X, V, Σ, P, S) be an extraction grammar in CNF and let d := σ1 · · · , σn, n ≥ 1 be
a document. The goal of this step is to restrict G so that it will produce only the ref-words
which clr maps to d. To this end, we deﬁne the grammar Gd that is associated with the
same set X of variables as G, and is deﬁned as follows:

The non-terminals are {Ai,j A ∈ V, 1 ≤ i ≤ j ≤ n} ∪ {A(cid:15) A ∈ V },
the terminals are Σ,
the initial non-terminal is S1,n, and
the production rules are deﬁned as follows:

Ai,i → σi for any A → σi ∈ P ,
A(cid:15) → σ for any A → σ ∈ P with σ ∈ ΓX ,
A(cid:15) → B(cid:15)C(cid:15) for any A → BC ∈ P ,
Ai,j → Bi,jC(cid:15) for any 1 ≤ i ≤ j ≤ n and any A → BC ∈ P ,
Ai,j → B(cid:15)Ci,j for any 1 ≤ i ≤ j ≤ n and any A → BC ∈ P ,
Ai,j → Bi,i0Ci0+1,j for any 1 ≤ i ≤ i0 < j ≤ n and A → BC ∈ P .

We eliminate useless non-terminals from Gd and by a slight abuse of notation refer to the
result as Gd from now on. The intuition behind this construction is that if the subscript of a
non-terminal is i, j then this non-terminal produces a ref-word that clr maps to σi · · · σj, and
if it is (cid:15) then it produces a ref-word that consists only of variable operations.

(cid:73) Example 18. Figure 6 presents a possible parse-tree of a grammar Gd.

(cid:74)

We establish the following connection between G and Gd.

(cid:73) Lemma 19. For every extraction grammar G in CNF, every document d := σ1 · · · σn,
every non-terminal A of G, and any ref-word r ∈ (Σ ∪ ΓX )∗ with clr(r) = σi · · · σj the
following holds: A ⇒∗

G r if and only if Ai,j ⇒∗
Gd

r

This allows us to conclude the following straightforward corollary.

(cid:73) Corollary 20. For every extraction grammar G in CNF and for every document d, it holds
that Ref(G, d) = L(Gd).

We note that adjusting our extraction grammar to d is somewhat similar to the CYK
algorithm [23] and therefore it is valid on extraction grammars G in CNF. For a similar
reason, we obtain the following complexity which is cubic in |d|.

(cid:73) Proposition 21. For every extraction grammar G in CNF and for every document d, it
holds that Gd can be constructed in O(|d|3|G|).

Can the complexity of the adjustment be improved? We leave this as an open question. We
note, however, that it might be possible to use similar ideas used by Earley’s algorithm [11]
to decrease the complexity of this step.

L. Peterfreund

XX:11

4.2 Constructing the Decorated Grammar

The goal of this step of the preprocessing is to encode the information on the produced
variable operations within the terminals and non-terminals. We obtain from Gd, constructed
in the previous step, a new grammar, namely decorGrmr(Gd), that produces decorated
words over the alphabet {(x, i, y) x, y ⊆ ΓX , 1 ≤ i ≤ n}. A terminal (x, i, y) indicates
that x and y are variable operations that occur right before and right after σi, respectively.
(Notice that x, y does not necessarily contain all of these variable operations as some of the
variable operations that appear, e.g., after i, can be contained in x0 in case (x0, i + 1, y0)
is the terminal that appears right after (x, i, y).) This information is propagated also to
the non-terminals such that a non-terminal with a superscript x, y indicates that x and y
are variable operations at the beginning and end, respectively, of the sub decorated word
produced by this non-terminal. Non-terminals with subscript (cid:15) are those that produce
sequences of variable operations.

To deﬁne decorGrmr(Gd), we need G to be functional. The following key observation
is used in the formal deﬁnition of decorGrmr(Gd) and is based on the functionality of G.

(cid:73) Proposition 22. For every functional extraction grammar G and every non-terminal A of
G there is a set xA ⊆ ΓX of variable operations such that for every ref-word r where A ⇒∗ r
the variable operations that appear in r are exactly those in xA. Computing all sets xA can
be done in O(|G|).

In other words, for functional extraction grammars, the information on the variable operations
is stored implicitly in the non-terminals. The grammar decorGrmr(Gd) is deﬁned in three
steps.

Step 1. We set the following production rules for all subsets x, y, z, w ⊆ ΓX that are
pairwise disjoint:

i,i → σi for any rule Ai,i → σi in Gd,

A∅,∅
A(cid:15) → (cid:15) for any rule A(cid:15) → τ in Gd (with τ ∈ ΓX ),
A(cid:15) → B(cid:15)C(cid:15) for any rule A(cid:15) → B(cid:15)C(cid:15) in Gd,
Ax,y∪xC
i,j
Ax∪xB ,y
i,j
Ax,w

i,j → Bx,y

i,j C(cid:15) for any rule Ai,j → Bi,jC(cid:15) in Gd and x ∩ xC = y ∩ xC = ∅,
for any rule Ai,j → B(cid:15)Ci,j in Gd and x ∩ xB = y ∩ xB = ∅,

→ Bx,y
→ B(cid:15)C x,y
i,j
i,i0 C z,w
i0+1,j for any rule Ai,j → Bi,i0Ci0+1,j in Gd and pairwise disjoint x, y, z, w,

with xB and xC deﬁned as in Proposition 22.

Step 2. We process the resulting grammar by three standard operations [23] in the following
order: (i) we eliminate useless non-terminals (i.e., those that do not produce a terminal string
or are not reachable from the initial non-terminal), (ii) we eliminate epsilon-productions, and
(iii) we eliminate unit productions. We elaborate on (iii) as it is important for the sequel.
To eliminate unit productions we compute for each non-terminal the set of non-terminals
that are reachable from it by unit productions only. That is, we say that a non-terminal
B is reachable form non-terminal A if there is a sequence of unit productions of the form
A1 → A2, · · · An−1 → An with A1 = A and An = B. We then replace every production
B → α which is not a unit production with A → α, and after that discard all unit productions.

Step 3. The last step of the construction is adding a fresh start symbol S and adding
the production rules S → Sx,y
1,n . We also replace
each production of the form Ax,y
i,i → (x, i, y). This can be viewed as a
‘syntactic sugar’ since it is only intended to help us formulate easily the connection between
the grammar G and decorGrmr(Gd).

1,n for any non-terminal of the form Sx,y

i,i → σi with Ax,y

XX:12 Grammars for Document Spanners

A1,2

A‘x ,∅
1,2

A‘x ,∅
1,2

S∅,∅
1,n

B1,1

C2,2

B

‘x ,ax ‘y
1,1

C

ay ,∅
2,2

A∅,∅
1,1

B∅,∅
2,n

D1,1

E(cid:15)

F(cid:15)

G2,2

D‘x,∅
1,1

G∅,∅
2,2

B

‘x,ax ‘y
1,1

C

ay ,∅
2,2

C∅,∅
2,2

···

H(cid:15)

I1,1

J(cid:15)

K(cid:15)

ay

σ2

‘x

σ1

ax

‘y

σ2

I ∅,∅
1,1

σ1

(‘x,1,ax‘y)

(ay,2,∅)

E∅,∅

n−2,n−2 F ∅,∅

n−1,n

G∅,‘xax

n−1,n−1 G∅,∅

n,n

Figure 6 After the adjust-

Figure 7 Before

Figure 8 After

Figure 9 Non-stable non-

ment to d

step 2 (iii)

step 3

terminals

(cid:73) Example 23. Figures 7 and 8 illustrate the diﬀerent steps in the construction of the
decorated grammar decorGrmr(Gd). For simplicity, we present the superscripts as pairs
(cid:74)
of sequences (each represent elements in the set) separated by commas ‘,’.

Note that by a simple induction it can be shown that the resulting grammar does no longer
contain non-terminals of the form A(cid:15). We denote the resulting grammar and its set of
non-terminals by decorGrmr(Gd) and V dec, respectively.

The (X, d)-mapping µw that corresponds with w := (x1, 1, y1) · · · (xn, n, yn) (which
is a decorated word produced by decorGrmr(Gd)) is deﬁned by µw(x) = [i, ji where
‘x∈ xi ∪ yi−1 and ax∈ xj ∪ yj−1 where y0 = xn+1 = ∅. We say that a decorated word w is
valid if µw(x) is well-deﬁned for every x ∈ X.

(cid:73) Proposition 24. For every functional extraction grammar G in CNF and for every
document d, if G is unambiguous then decorGrmr(Gd) is unambiguous.

This allows us to establish the following connection between decorGrmr(Gd) and

(d).

G
(cid:75)

(cid:74)

(cid:73) Lemma 25. For every functional unambiguous extraction grammar G in CNF and for
every document d, every decorated word produced by decorGrmr(Gd) is valid and

(d) = {µw S ⇒∗

decorGrmr(Gd) w}.

G
(cid:75)
(cid:74)

Finally, combining Proposition 24 and Lemma 25 leads to the following direct corollary.

(cid:73) Corollary 26. For every functional unambiguous extraction grammar G in CNF and for
every document d, enumerating mappings in
(d) can be done by enumerating parse-trees
G
(cid:75)
of decorated words in {w S ⇒∗
decorGrmr(Gd) w}.

(cid:74)

To summarize the complexity of constructing decorGrmr(Gd) we have:

(cid:73) Proposition 27. For every functional unambiguous extraction grammar G in CNF and
for every document d, decorGrmr(Gd) can be constructed in O(|Gd| 52k) = O(|d|3|G| 52k)
where k is the number of variables associated with G.

5

Enumeration Algorithm

Our enumerating algorithm builds recursively the parse-trees of the decorated grammar
decorGrmr(Gd). Before presenting it, we discuss some of the main ideas that allow us to
obtain a constant delay between every two consecutive outputs.

L. Peterfreund

XX:13

5.1 Stable non-terminals

The non-terminals of decorGrmr(Gd) are decorated with superscripts and subscripts that
give extra information that can be exploited in the process of the derivation.

(cid:73) Example 28. Figure 10 presents a partial parse-tree (without the leaves and the ﬁrst
production) for a decorated word in decorGrmr(Gd). Notice that the variable operations
that appear in the subtrees rooted in the non-terminal C ‘x‘y,ay
are only those indicated in
its superscript. That is, there are no variable operations that occur between positions 1, 2
(cid:74)
and 2, 3.

1,3

Motivated by this, we say that a non-terminal Ax,y

i,j of decorGrmr(Gd) is stable if xA = x∪y.
(cid:73) Lemma 29. For every functional extraction grammar G in CNF and for every document
d, the set of stable non-terminals of decorGrmr(Gd) is computable in O(|Gd|52k) where k
is the number of variables G is associated with.

Therefore, while constructing the parse-trees of decorGrmr(Gd) whenever we reach a

stable non-terminal we can stop since its subtree does not aﬀect the mapping.

5.2 The Jump Function

If G is associated with k variables, there are exactly 2k variable operations in each ref-word
produced by G. Hence, we can bound the number of non-stable non-terminals in a parse-tree
of decorGrmr(Gd). Nevertheless, the depth of a non-stable non-terminal can be linear in
|d| as the following example suggests.

(cid:73) Example 30. Consider the non-stable non-terminal F ∅,∅
n−1,n in the partial parse tree in
Figure 9 of the decorated word (∅, 1, ∅) · · · (∅, n − 1, ‘xax)(∅, n, ∅). Observe that the depth
(cid:74)
of this non-terminal is linear in n.

Since we want the delay of our algorithm to be independent of |d|, we skip parts of the
parse tree in which no variable operation occurs. This idea somewhat resembles an idea that
was implemented by Amarilli et al. [2] in their constant delay enumeration algorithm for
regular spanners represented as vset-automata. There, they deﬁned a function that ‘jumps’
from one state to the other if the path from the former to the latter does not contain any
variable operation. We extend this idea to extraction grammars by deﬁning the notion of
skippable productions. Intuitively, when we focus on a non-terminal in a parse tree, the
corresponding mapping is aﬀected by either the left subtree of this non-terminal, or by its
right subtree, or by the production applied on the non-terminal itself (or by any combination
of the above). If the mapping is aﬀected exclusively by the left (right, respectively) subtree
then we can skip the production and move to check the left (right, respectively) subtree, and
do so recursively until we reach a production for which this is no longer the case.

i,i0 C z0,y

i,j → Bx,z

Formally, a skippable production rule is of the form Ax,y

i0+1,j where (a) Ax,y
i,j
is non-stable, (b) z = z0 = ∅, and (c) exactly one of Bx,z
i0+1,j is stable. Intuitively, (a)
assures that the parse tree rooted in Ax,y
i,j aﬀects the mapping, (b) assures that the production
applied on Ax,y
i,j does not aﬀect the mapping and (c) assures that exactly one subtree of
Ax,y
i0+1,j if Bx,z
i,i0
is stable) aﬀects the mapping. We then say that a skippable production rule ρ follows a
skippable production rule ρ0 if the non-stable non-terminal in the right-hand side of ρ0 is
the non-terminal in the left-hand side of ρ. The function jump : V dec → 2V dec
is deﬁned by
B ∈ jump(Ax,y
i,j ) if there is a sequence of skippable production rules ρ1, · · · , ρm such that:

i0+1,j is stable, or the one rooted at C z0,y

i,j (either the one rooted at Bx,z

i,i0 if C z0,y

i,i0 , C z0,y

XX:14 Grammars for Document Spanners

S

‘x ‘y ,az
1,6

A

‘x ‘y ,‘z
1,4

B∅,az
5,6

C

‘x ‘y ,ay
1,3

D∅,‘z
4,4

E∅,∅
5,5

F ax,az
6,6

G

‘x‘y ,∅
1,2

H

∅,ay
3,3

I

‘x ‘y ,∅
1,1

J ∅,∅
2,2

procedure enumerate(α, map)
if α = (cid:15) then

output map
denote α by A · α0;
foreach B ∈ jump(A) do

foreach (β, map0) ∈ applyProd(B)
do

enumerate(β · α0, map ∪ map0);

Figure 10 decorGrmr(Gd) Parse tree

Figure 11 Main enumeration algorithm

ρι follows ρι−1 for every ι,
the left-hand side of ρ1 is Ax,y
i,j ,
the non-stable non-terminal in the right-hand side of ρm is B,
there is a production rule that is not skippable whose left-hand side is B.

(cid:73) Example 31. In the decorated grammar whose (one of its) parse tree appears in Figure 9
it holds that F ∅,∅
(cid:74)

n−1,n ∈ jump(S∅,∅

1,n).

The acyclic nature of the decorated grammar (that is, the fact that a non-terminal cannot
be produced from itself) enables us to obtain the following upper bound for the computation
of the jump function.

(cid:73) Lemma 32. For every functional unambiguous extraction grammar G in CNF and for
every document d, the jump function is computable in O(|d|534k|G|2) where k is the number
of variables G is associated with.

The proof of this lemma relies on the acyclic nature of decorGrmr(Gd). Lemmas 29 and 32
imply that we can ﬁnd the non-stable non-terminals as well as compute the jump function as
part of the quintic preprocessing. It is important to note that if we can reduce the complexity
of computing the jump function then we can reduce the preprocessing time.

5.3 The Algorithm

Our main enumeration algorithm is presented in Figure 11 and outputs (X, d)-mappings µ
represented as sets of pairs (‘x, i), (ax, j) whenever µ(x) = [i, ji. The procedure applyProd
is called with a non-terminal Ax,y
i,j that is (a) non-stable and (b) appears at the left-hand
side of at least one rule that is not skippable. The procedure applyProd is an iterator that
outputs with constant delay all those pairs (β, map) for which there exists a not skippable
rule of the form Ax,y

i0+1,j such that the following hold:

i,j → Bx,z

i,i0 C z0,y

map = {(τ, i0 + 1) τ ∈ z ∪ z0}, and
β is the concatenation of the non-stable terminals amongst Bx,z
is non-stable and since Ax,y

Notice that since Ax,y
i0+1,j is not skippable, it holds
i,j
that either z 6= ∅ or z0 6= ∅ (or both). Thus, the returned map is not empty which implies
that every call to this procedure adds information on the mapping, and thus the number of
calls is bounded. Notice also that β is the concatenation of the non-terminals among Bx,z
i,i0
and C z0,y

i0+1,j that aﬀect the mapping.

i,j → Bx,z

i,i0 C z0,y

i,i0 and C z0,y

i0+1,j.

L. Peterfreund

XX:15

(cid:73) Example 33. The procedure applyProd applied on S‘x‘y,az
pair (‘z, 5) to map; When applied on A‘x‘y,‘z
1,4
on B∅,az
5,6 , it adds the pair (ax, 6) to map.

from Figure 10 adds the
, it adds the pair (ay, 4) to map; When applied
(cid:74)

1,6

1,n , map) where Sx,y

The recursive procedure enumerate outputs mappings as a set of pairs of the form (γ, i)
with γ ∈ ΓX a variable operation and 1 ≤ i ≤ n. The main enumeration algorithm calls
the recursive procedure enumerate with pairs (Sx,y
1,n is a non-terminal in
decorGrmr(Gd), and map is the set containing pairs (τ, 1) for any τ ∈ x, and (τ, n + 1)
for any τ ∈ y. The recursive procedure enumerate gets a pair (α, map) as input where α
is a (possibly empty) sequence of non-stable non-terminals and map is a set of pairs of the
above form. It recursively constructs an output mapping by applying derivations on the
non-stable non-terminals (by calling applyProd) while skipping the skippable productions
(by using jump). We assume that enumerate has O(1) access to everything computed in
the preprocessing stage, that is, the grammar decorGrmr(Gd), the jump function, and
the sets of stable and non-stable non-terminals.

(cid:73) Theorem 34. For every functional unambiguous extraction grammar G in CNF and for
every document d, the main enumerating algorithm described above enumerates the mappings
(d) (without repetitions) with delay of O(k) between each two consecutive mappings
in
where k is the number of variables G is associated with.

G
(cid:75)

(cid:74)

Had G been ambiguous, the complexity guarantees on the delay would not have held.

Finally, we remark that the proof of Theorem 17 follows from Corollary 25, Proposition 27,

Lemma 29, Lemma 32, and Theorem 34.

6

Conclusion

In this paper we propose a new grammar-based language for document spanners, namely
extraction grammars. We compare the expressiveness of context-free spanners with previously
studied classes of spanners and present a pushdown model for these spanners. We present
an enumeration algorithm for unambiguous grammars that outputs results with a constant
delay after quintic preprocessing in data complexity. We conclude by suggesting several
future research directions.

To reach a full understanding of the expressiveness of context-free spanners, one should
characterize the string relations that can be expressed with context-free spanners. This
can be done by understanding the expressiveness of context-free grammars enriched with
string equality selection. We note that there are some similarities between recursive Datalog
over regex formulas [35] and extraction grammars. Yet, with the former we reach the full
expressiveness of polynomial time spanners (data complexity) whereas with the latter we
cannot express string equality. Understanding the connection between these two formalisms
better can be a step in understanding the expressive power of extraction grammars.

Regarding our enumeration complexity, it might be possible to decrease the preprocessing
complexity by using other techniques to compute the jump function. Another direction is to
ﬁnd restricted classes of extraction grammars that are more expressive than regular spanners
yet allow linear time preprocessing (similarly to [2]).

It can be interesting to examine more carefully whether the techniques used here for
enumerating the derivations can be applied also for enumerating queries on trees, or enu-
merating queries beyond MSO on strings. This connects to a recent line of work on eﬃcient
enumeration algorithms for monadic-second-order queries on trees [3]. Can our techniques
be used to obtain eﬃcient evaluation for more expressive queries?

XX:16 Grammars for Document Spanners

Acknowledgments

The author is grateful to Arnaud Durand, Michael Kaminski, Benny Kimelfeld, and Leonid
Libkin for the discussions and their useful comments, and to Dominik D. Freydenberger for
the helpful references.

References

1

Jitendra Ajmera, Hyung-Il Ahn, Meena Nagarajan, Ashish Verma, Danish Contractor, Stephen
Dill, and Matthew Denesuk. A CRM system for social media: challenges and experiences. In
WWW, pages 49–58. ACM, 2013.

4

2 Antoine Amarilli, Pierre Bourhis, Stefan Mengel, and Matthias Niewerth. Constant-delay
enumeration for nondeterministic document spanners. In ICDT, pages 22:1–22:19, 2019.
3 Antoine Amarilli, Pierre Bourhis, Stefan Mengel, and Matthias Niewerth. Enumeration on
trees with tractable combined complexity and eﬃcient updates. In PODS, pages 89–103, 2019.
Edward Benson, Aria Haghighi, and Regina Barzilay. Event discovery in social media feeds.
In ACL, pages 389–398. The Association for Computer Linguistics, 2011.
J. Richard Büchi and Lawrence H. Landweber. Deﬁnability in the monadic second-order
theory of successor. J. Symb. Log., 34(2):166–170, 1969.
Laura Chiticariu, Rajasekar Krishnamurthy, Yunyao Li, Sriram Raghavan, Frederick Reiss,
and Shivakumar Vaithyanathan. SystemT: An algebraic approach to declarative information
extraction. In ACL, pages 128–137, 2010.

5

6

7 Noam Chomsky. On certain formal properties of grammars. Information and Control, 2(2):137–

8

9

10

11

167, 1959.
Johannes Doleschal, Benny Kimelfeld, Wim Martens, Yoav Nahshon, and Frank Neven.
Split-correctness in information extraction. In PODS, pages 149–163, 2019.
Johannes Doleschal, Benny Kimelfeld, Wim Martens, and Liat Peterfreund. Weight annotation
in information extraction. In ICDT, volume 155 of LIPIcs, pages 8:1–8:18. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2020.
Pál Dömösi. Unusual algorithms for lexicographical enumeration. Acta Cybernetica, 14(3):461–
468, 2000.
Jay Earley. An eﬃcient context-free parsing algorithm. Communications of the ACM, 13(2):94–
102, 1970.

12 Ronald Fagin, Benny Kimelfeld, Frederick Reiss, and Stijn Vansummeren. Document spanners:

A formal approach to information extraction. J. ACM, 62(2):12, 2015.

13 Ronald Fagin, Benny Kimelfeld, Frederick Reiss, and Stijn Vansummeren. Declarative cleaning
of inconsistencies in information extraction. ACM Trans. Database Syst., 41(1):6:1–6:44, 2016.
Fernando Florenzano, Cristian Riveros, Martín Ugarte, Stijn Vansummeren, and Domagoj
Vrgoc. Constant delay algorithms for regular document spanners. In PODS, pages 165–177.
ACM, 2018.

14

15 Dominik D. Freydenberger. A logic for document spanners. In ICDT, volume 68 of LIPIcs,

pages 13:1–13:18. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2017.

16 Dominik D. Freydenberger. A logic for document spanners. Theory Comput. Syst., 63(7):1679–

1754, 2019.

17 Dominik D. Freydenberger and Mario Holldack. Document spanners: From expressive power
to decision problems. In ICDT, volume 48 of LIPIcs, pages 17:1–17:17. Schloss Dagstuhl -
Leibniz-Zentrum für Informatik, 2016.

18 Dominik D. Freydenberger and Mario Holldack. Document spanners: From expressive power

to decision problems. Theory Comput. Syst., 62(4):854–898, 2018.

19 Dominik D. Freydenberger, Benny Kimelfeld, and Liat Peterfreund. Joining extractions of

regular expressions. In PODS, pages 137–149, 2018.

20 Dominik D. Freydenberger and Liat Peterfreund. Finite models and the theory of concatenation.

CoRR, abs/1912.06110, 2019. URL: http://arxiv.org/abs/1912.06110.

L. Peterfreund

XX:17

21 Dominik D. Freydenberger and Sam M. Thompson. Dynamic complexity of document spanners.

22

In ICDT, volume 155, pages 11:1–11:21, 2020.
John E. Hopcroft, Rajeev Motwani, and Jeﬀrey D. Ullman. Introduction to automata theory,
languages, and computation - international edition (2. ed). Addison-Wesley, 2003.
John E. Hopcroft, Rajeev Motwani, and Jeﬀrey D. Ullman. Introduction to automata theory,
languages, and computation, 3rd Edition. Pearson international edition. Addison-Wesley, 2007.
24 Donald E. Knuth. Semantics of context-free languages. Mathematical Systems Theory,

23

2(2):127–145, 1968.

25 Donald E. Knuth. Correction: Semantics of context-free languages. Mathematical Systems

26

Theory, 5(1):95–96, 1971.
Clemens Lautemann, Thomas Schwentick, and Denis Thérien. Logics for context-free languages.
In CSL, volume 933 of Lecture Notes in Computer Science, pages 205–216. Springer, 1994.

27 Yaoyong Li, Kalina Bontcheva, and Hamish Cunningham. SVM based learning system for
information extraction. In Deterministic and Statistical Methods in Machine Learning, First
International Workshop, Sheﬃeld, UK, September 7-10, 2004, Revised Lectures, pages 319–339,
2004.

28 Yunyao Li, Frederick Reiss, and Laura Chiticariu. SystemT: A declarative information

30

29

extraction system. In ACL, pages 109–114. ACL, 2011.
Erkki Mäkinen. On lexicographic enumeration of regular and context-free languages. Acta
Cybernetica, 13(1):55–61, 1997.
Francisco Maturana, Cristian Riveros, and Domagoj Vrgoč. Document spanners for extracting
incomplete information: Expressiveness and complexity. In PODS, pages 125–136, 2018.
31 Andrea Moro, Marco Tettamanti, Daniela Perani, Caterina Donati, Stefano F Cappa, and Fer-
ruccio Fazio. Syntax and the brain: disentangling grammar by selective anomalies. Neuroimage,
13(1):110–118, 2001.

32 Takashi Nagashima. A formal deductive system for CFG. Hitotsubashi journal of arts and

sciences, 28(1):39–43, 1987.

33 Yoav Nahshon, Liat Peterfreund, and Stijn Vansummeren. Incorporating information extraction

34

35

36

in the relational database model. In WebDB, page 6. ACM, 2016.
Liat Peterfreund, Dominik D. Freydenberger, Benny Kimelfeld, and Markus Kröll. Complexity
bounds for relational algebra over document spanners. In PODS, pages 320–334. ACM, 2019.
Liat Peterfreund, Balder ten Cate, Ronald Fagin, and Benny Kimelfeld. Recursive programs
for document spanners. In ICDT, volume 127 of LIPIcs, pages 13:1–13:18. Schloss Dagstuhl -
Leibniz-Zentrum fuer Informatik, 2019.
Christopher De Sa, Alexander Ratner, Christopher Ré, Jaeho Shin, Feiran Wang, Sen Wu, and
Ce Zhang. Deepdive: Declarative knowledge base construction. SIGMOD Record, 45(1):60–67,
2016.

37 Markus L. Schmid. Characterising REGEX languages by regular languages equipped with

factor-referencing. Inf. Comput., 249:1–17, 2016.

38 Rania A Abul Seoud, Abou-Bakr M Youssef, and Yasser M Kadah. Extraction of protein inter-
action information from unstructured text using a link grammar parser. In 2007 International
Conference on Computer Engineering & Systems, pages 70–75. IEEE, 2007.

40

39 Warren Shen, AnHai Doan, Jeﬀrey F. Naughton, and Raghu Ramakrishnan. Declarative
information extraction using Datalog with embedded extraction predicates. In VLDB, pages
1033–1044, 2007.
Jason M Smith and David Stotts. SPQR: Flexible automated design pattern extraction from
source code. In 18th IEEE International Conference on Automated Software Engineering,
pages 215–224. IEEE, 2003.
Leslie G. Valiant. General context-free recognition in less than cubic time. J. Comput. Syst.
Sci., 10(2):308–315, 1975. doi:10.1016/S0022-0000(75)80046-8.

41

42 Huang Wen-Ji. Enumerating sentences of context free language based on ﬁrst one in order.

Journal of Computer Research and Development, 41(1):9–14, 2004.

XX:18 Grammars for Document Spanners

43 Virginia Vassilevska Williams. Multiplying matrices faster than coppersmith-winograd. In

STOC, pages 887–898. ACM, 2012.

44 Hua Xu, Shane P. Stenner, Son Doan, Kevin B. Johnson, Lemuel R. Waitman, and Joshua C.
Denny. MedEx: a medication information extraction system for clinical narratives. JAMIA,
17(1):19–24, 2010.

45 Akane Yakushiji, Yuka Tateisi, Yusuke Miyao, and Jun-ichi Tsujii. Event extraction from
biomedical papers using a full parser. In Biocomputing 2001, pages 408–419. World Scientiﬁc,
2000.

46 Huaiyu Zhu, Sriram Raghavan, Shivakumar Vaithyanathan, and Alexander Löser. Navigating

the intranet with high precision. In WWW, pages 491–500. ACM, 2007.

L. Peterfreund

XX:19

A

Appendix for Section 2

(cid:73) Proposition 10. Every extraction grammar G can be converted into an equivalent functional
extraction grammar G0 in O(|G|2 + 32k|G|) time where k is the number of variables G is
associated with.

Proof. Let G := (X, V, Σ, P, S) be an extraction grammar. We assume that G is in CNF
since if it is not then we can convert it into one in O(|G|2) with the standard algorithm
presented, e.g., in [23]. Note that the resulting grammar is O(|G|). We deﬁne an extraction
grammar G0 that is associated with X as well as follows. Its non-terminals are X × 2ΓX , its
terminals are Σ, the start variable is (S, ΓX ), and its production rules are as follows.

(A, X1) → (B, X2)(C, X3) whenever A → BC ∈ P , and X1 = X2 ∪ X3, and X2 ∩ X3 = ∅,
and for any x ∈ X if ax∈ X2 then ‘x6∈ X3;
(A, ∅) → σ whenever A → σ ∈ P with σ ∈ Σ; and
(A, {τ }) → τ whenever A → τ ∈ P with τ ∈ ΓX .

A straightforward induction shows that G0 is functional and that it is equivalent to G. The
number of ways to choose two disjoint subsets of ΓX is 32k and therefore complexity of the
construction is O(|G|2 + 32k|G|) where k is the number of variables associated with G. Notice
that G0 is in CNF since G is in CNF. Notice also that if G is in CNF to begin with, the
(cid:74)
complexity reduces to O(32k|G|).

(cid:73) Proposition 12. In Proposition 10, if G is unambiguous then so is G0.

Proof. Assume that G is unambiguous. It suﬃces to show that converting it to CNF G00
results in an unambiguous extraction grammar and that the conversion to G0 preserve
unambiguity (that is, if G00 is unambiguous then so is G0). This is straightforward since if we
assume that G0 is not unambiguous than we can easily show that so is G00 (by translating G0’s
derivations to G00 by omitting the second coordinate). So it is left to show that the conversion
to CNF preserves unambiguity. For that, we repeat here the details of the algorithm presented
in [22, Section 7.1.5] for converting a grammar G to CNF. The algortihm consists of three
steps:
1. We omit (cid:15)-productions, unit productions and useless symbols.
2. We arrange that all bodies of length 2 or more consists only of variables;
3. We break bodies of length 3 or more into a cascade of productions, each with a body

consisting of two variables.

In step 1 we do not add ambiguity as we reduce productions. In step 2 we add productions of
the form A → σ but these do not aﬀect unambiguity as these As are fresh non-terminals and
for each σ we have a unique A. In step 3 we replace rules of the form A → A1 · · · An into the
cascade A → A1B1, B1 → A2B2, · · · Bn−2 → An−1An where all Bis are fresh non-terminals.
(cid:74)
Thus, this step do not aﬀect unambiguity.

B

Appendix for Section 3

(cid:73) Proposition 13. The class of spanners deﬁnable by regular extraction grammars is equal
to the class of regular spanners.

Proof. Let us consider the regular spanner represented as the vset-automaton A. Since every
regular language is also a context-free language we can construct a pushdown automaton A0

XX:20 Grammars for Document Spanners

such that R(A0) = R(A). Thus,

A

=

A0

(cid:74)

(cid:75)

(cid:74)

(cid:75)

For the second direction we have to show that every spanner described by a right-regular
extraction grammar is a regular spanner. Let G = (V, Σ, P, S) be a right-regular extraction
grammar. We use a similar construction used for converting a right regular grammar into a
non-deterministic automaton while treating the variable operations as terminal symbols. The
states of the automaton are a new ﬁnal state qf along with a state qA for every non-terminal
A ∈ V with the state qS as the initial state. The transition function δ is the following: for
every A → σB we set δ(qA, σ) = qB and for A → σ we set δ(qA, σ) = qf . It holds that
(cid:74)
R(G) = L(A) and in particular, for every d we have that

(d) =

A

G
(cid:75)
(cid:74)

(d).
(cid:75)

(cid:74)

(cid:0) ‘x Σ∗ ax‘y Σ∗ ay

(cid:73) Example 35. Let us consider the following Boolean core spanner given as the expression
(cid:1). It can be shown that the spanner
π∅ ζ =
is
x,y
evaluated to a non-empty ({x, y}, d)-relation on d if and only if d is of the form ww for some
w ∈ Σ∗ (and in this case it contains a single ({x, y}, d)-mapping). For instance, on d1 := abab
(d1) contains exactly one ({x, y}, d1)-mapping µ1
we have that
that is deﬁned such that µ1(x) = [1, 3i and µ1(y) = [3, 5i. On the other hand, on d2 := aba
(cid:0) ‘x Σ∗ ax‘y Σ∗ ay
(cid:74)
and on d3 := abaa it holds that

(cid:0) ‘x Σ∗ ax‘y Σ∗ ay

(cid:0) ‘x Σ∗ ax‘y Σ∗ ay

(di) for i = 2, 3 is empty.

ζ =
x,y

ζ =
x,y

(cid:1)

(cid:1)

(cid:1)

(cid:74)

(cid:75)

(cid:75)

(cid:74)

ζ =
x,y

(cid:74)

(cid:75)

(cid:73) Proposition 14. The classes of core spanners and generalized core spanners are each
incomparable with the class of context-free spanners.

Proof. The proof of this proposition is based partly on the following observation which, in
turn, is based on the deﬁnition: A language L is deﬁnable by a Boolean spanner S if for
every word w ∈ Σ∗ it holds that S(w) 6= ∅ if only if w ∈ L.

(cid:66) Observation 36.

Boolean extraction grammars capture the context-free languages.

This observation is straightforward as every extraction grammar that is associated with an
empty set of variables can be interpreted as a context-free grammar. We now prove the
proposition: To show that each of the class of core spanners and generalized spanners is not
contained in the class of context-free spanners it suﬃces to show that there is a that is not
context-free. Indeed, the language {ww | w ∈ Σ∗} which, as shown in Example 35, is deﬁnable
by a Boolean core spanner is not a context-free language [23] and hence by Observation 36 is
not deﬁnable by any extraction spanner. For the other direction, the language {anbn|n ≥ 1} is
context free and hence by Observation 36 is deﬁnable by an extraction grammar, nevertheless,
this language is not accepted by any Boolean core spanner [12] and not by any generalized
(cid:74)
core spanner [20].

(cid:73) Theorem 15. The class of context-free spanners is closed under union and projection,
and not closed under natural join and diﬀerence.

Proof. We show each of the claims separately:

Closure under projection and union. Let GX := (V, Σ, P, S) be an extraction grammar
and let X 0 ⊆ X. We deﬁne a morphism clrX : (Σ ∪ V ∪ ΓX )∗ → (Σ ∪ V ∪ ΓY )∗ where
Y := X \ X 0 by clrX (σ) = σ for σ ∈ Σ, and clrX (γ) = γ for γ ∈ ΓY and clrX (γ) = (cid:15) for
γ ∈ ΓX 0. We deﬁne the grammar G0 = (V 0, Σ0, P 0, S0) where V 0 := V, Σ0 := Σ, S0 := S and P 0
is deﬁned as follows: for every A → α ∈ P we have A → clrX (α) ∈ P 0. It is straightforward
that
. Closure under union can be obtained by the same technique used for
unifying grammars. Let G1, G2 be two extraction grammars with Vars(G1) = Vars(G2). We

πX 0GX

G0

=

(cid:74)

(cid:75)

(cid:74)

(cid:75)

L. Peterfreund

XX:21

can construct a grammar G with R(G) = R(G1) ∪ R(G2). Therefore, for every d it holds
that Ref(G, d) = (R(G1) ∪ R(G2)) ∩ Ref(d) and thus

G2

G1

=

∪

G
(cid:75)

(cid:74)

(cid:74)

(cid:75)

(cid:74)

.
(cid:75)

Non-closure under natural join and diﬀerence. Non-closure properties are immediate
consequence of the case for context-free languages since non-deterministic automata and push-
down automata can be viewed as Boolean vset-automata and Boolean pushdown automata,
respectively. This is due to the fact that the deﬁnitions of Boolean pushdown automaton
and non-deterministic automaton coincide, as well as those of Boolean vset-automaton and
(cid:74)
non-deterministic automaton.

(cid:73) Proposition 16. For every extraction grammar G and every document d it holds that
(d) can be computed in O(|G|2+|d|2k+3 k3 |G|) time where G is associated with k variables.
G
(cid:74)
(cid:75)
Proof. This proposition relies on the celebrated Cocke-Younger-Kasami (CYK) parsing
algorithm for context-free grammars [23]. Given a context-free grammar G in Chomsky
Normal Form [7], as will be deﬁned shortly, and a string w, the CYK algorithm determines
whether G produces w (i.e., w is a word in the language deﬁned by G.) A context-free
grammar G is in Chomsky Normal Form (CNF) if all of its production rules are of the form
A → BC where A, B, C are non-terminals or of the form A → σ where A is a non-terminal
and σ is a terminal. The algorithm that computes
(d) operates as follows: it iterates
G
(cid:75)
over all of the ref-words r that are (1) valid for the variables Vars(G) whose operations
appear in G and (2) mapped by clr into d. For each such ref-word, it uses CYK algorithm to
determine whether it is produced by G by treating G as a standard CFG over the extended
alphabet Σ ∪ ΓX , and after converting G into CNF. We convert G into CN F in O(|G|2).
Note that there are O(|d|2k) valid ref-words, and each is represented by a ref-word of length
O(|d| + 2k). For every such ref-word we use CYK to check whether it belongs to G in
O((|d| + 2k)3|G|). Since we repeat the process for every ref-word the total complexity is
(cid:74)
O(|G|2 + |d|2k(|d| + 2k)3|G|).

(cid:74)

C

Appendix for Section 4

(cid:73) Lemma 19. For every extraction grammar G in CNF, every document d := σ1 · · · σn,
every non-terminal A of G, and any ref-word r ∈ (Σ ∪ ΓX )∗ with clr(r) = σi · · · σj the
following holds: A ⇒∗

G r if and only if Ai,j ⇒∗
Gd

r

G σi if and only if Ai,i ⇒∗
Gd

In the base case we have j = i and then
Proof. The proof is by induction on j − i.
r = σi. By deﬁnition we have A ⇒∗
σi. For the induction
step: If A ⇒∗
G BC ⇒∗
G r with r = σi · · · σj then since G is in CNF we have A ⇒∗
G r1r2
where clr(r1) = σi · · · σi+‘ and clr(r2) = σi+‘+1 · · · σj. We can use the induction hypothesis
to obtain that Bi,i+‘ ⇒∗
r2. By deﬁnition of Gd we have
that Ai,j ⇒∗
r. For the other
direction, let us assume that Ai,j ⇒∗
r. By deﬁnition Gd is in CNF as well and also
by deﬁnition we have that Ai,j ⇒∗
G BC. Thus, we obtain
Ai,j ⇒∗
G r1 and
(cid:74)
C ⇒∗

Bi,i+‘Ci+‘+1,j and thus we can conclude that Ai,j ⇒∗

r1r2 = r. By induction hypothesis we have B ⇒∗

Gd
Bi,i+‘Ci+‘+1,j where A ⇒∗

G r2. Combining the above we get A ⇒∗

r1 and that Ci+‘+1,j ⇒∗

Bi,i+‘Ci+‘+1,j ⇒∗

G r1r2 = r.

G BC ⇒∗

Gd

Gd

Gd

Gd

Gd

Gd

Gd

(cid:73) Proposition 21. For every extraction grammar G in CNF and for every document d, it
holds that Gd can be constructed in O(|d|3|G|).

XX:22 Grammars for Document Spanners

Proof. Each production rule in G has at most |d|3 variations in Gd. Thus, the total time
(cid:74)
required to produce Gd is O(|d|3|G|).

(cid:73) Proposition 22. For every functional extraction grammar G and every non-terminal
A of G there is a set xA ⊆ ΓX of variable operations such that for every ref-word r where
A ⇒∗ r the variable operations that appear in r are exactly those in xA. Computing all sets
xA can be done in O(|G|).

Proof. Assume by contradiction that this is not the case. That is, there are r, s such that
A ⇒∗ r and A ⇒∗ s. Since G does not contain any unreachable non-terminal and since every
non-terminal of G is reachable from the initial non-terminal there are the following leftmost
derivations:

S ⇒∗ r0Aγ ⇒∗ r0rr00

and

S ⇒∗ s0Aδ ⇒∗ s0ss00

where r0, s0, r00, s00 ∈ (Σ ∪ ΓX )∗ and γ, δ ∈ (V ∪ Σ ∪ ΓX )∗. Recall that both r0rr00 and s0ss00
are valid and thus if the variable operations that occur in r and s are diﬀerent then so do
the variable operations that appear in r0r00 and in s0s00. Thus, we can replace r with s and
obtain a ref-word that is not valid. This contradicts the fact that G is functional.

To compute the sets xA, we view the non-terminals as nodes and the transitions as edges
such that A → BC implies that there is an edge from A to B, and an edge from A to C. We
then run a BFS on this graph and view the output sequence of non-terminals as a topological
order. We then iterate over the non-terminals in an inverse order and accumulate for each
the set of variable operations that consists of its descendants. This whole process can be
(cid:74)
done in O(|G|).

(cid:73) Proposition 24. For every functional extraction grammar G in CNF and for every
document d, if G is unambiguous then decorGrmr(Gd) is unambiguous.

Proof. It is straightforward that if G is unambiguous then so is Gd for any document d.
Assume by contradiction that decorGrmr(Gd) is not unambiguous. That is, there is a
decorated word that has two parse-trees. By the deﬁnition of decorGrmr(Gd) it follows
that if it is the case then Gd has two diﬀerent parse-trees to the same ref-words which leads
(cid:74)
to the desired contradiction.

(cid:73) Lemma 25. For every functional unambiguous extraction grammar G in CNF and for
every document d, every decorated word produced by decorGrmr(Gd) is valid and

(d) = {µw S ⇒∗

decorGrmr(Gd) w}.

G
(cid:75)
(cid:74)

Proof. Let w be a decorated word such that S ⇒∗
G (x1, 1, y1) · · · (xn, n, yn). Assume by
contradiction that there is a variable x such that µw(x) is not well-deﬁned. It follows from
the construction of decorGrmr(Gd) that either the variable operation ‘x or ax appears
more than once in a ref-word produced by G or that the variable operation ‘x occurs after
ax in a ref-word produced by G. That is a contradiction to the fact that G is functional.

L. Peterfreund

XX:23

Before moving on to the second part of the theorem, we present some deﬁnitions.
We deﬁne a function f from the possible parse-trees of Gd to the possible parse-trees
of decorGrmr(Gd) with d := σ1 · · · σn. We ﬁrst deﬁne for every σi the non-terminal asso-
ciated with it as the non-terminal that is the root of the maximal subtree with leaf σi and no
other leaf from Σ. The function f replaces for every i the subtree rooted in the non-terminal
Ai,i associated with σi with the subtree Ax,y
x1 · · · x‘σiy1 · · · y‘0
and x = {x1, · · · , x‘} and y = {y1, · · · , y‘0}. By a slight abuse of notation and since we are
dealing with unambiguous grammars we refer to parse-trees as the word they produce and
vice-versa. Note that

i,i → (x, i, y) where Ai,i ⇒∗
Gd

Claim 1. if r ∈ R(Gd) then S ⇒∗

decorGrmr(Gd) f (r).

This claim can be showed by a simple induction using the deﬁnition of decorGrmr(Gd).

Claim 2.
r ∈ R(Gd) and the image under f of the parse-tree of r is w.

decorGrmr(Gd) (x1, 1, y1) · · · (xn, n, yn) with then there is a r such that

if S ⇒∗

This claim can be proved by a simple induction using the deﬁnition of decorGrmr(Gd).

Claim 3. For every r it holds that µr = µr0
of r.

where r0 is the image under f of the parse tree

This claim is a direct consequence of the deﬁnitions.

Moving back to the proof of the theorem, which is showing that

(d) = {µw S ⇒∗

decorGrmr(Gd) w}.

G
(cid:75)
(cid:74)

(d) then there is a ref-word r in R(G) such that µ = µr. By claim 1,
decorGrmr(Gd) f (r). Note also that clrdec(f (r)) = d. Finally, by Claim 3 we can

(cid:74)

G
(cid:75)

If µ ∈
S ⇒∗
conclude the claim.

If µ ∈ {µw S ⇒∗

decorGrmr(Gd) w} then there is a decorated word w such that µ = µw.
Claim 2 implies that there exists a r ∈ R(G) such that f (r) = w. Then, by claim 3 we
(cid:74)
conclude that µr = µw which completes the proof.

(cid:73) Proposition 27. For every functional unambiguous extraction grammar G in CNF and
for every document d, decorGrmr(Gd) can be constructed in O(|Gd| 52k) = O(|d|3|G| 52k)
where k is the number of variables associated with G.

Proof. In Step 1 of the construction we create several copies of each production of Gd.
Notice that there are 52k four pairwise disjoint subsets of ΓX (which is equivalent to the
number of mappings from ΓX to a domain of size 5 which indicates to which subset an
elements belong). The size of the grammar after step 1 is O(|Gd|52k) and that is also the
time complexity required for constructing it. Step 2 consists of several linear scans of the
resulting grammar and hence can be done in O(|Gd|52k) time. Finally, in step 3 we remove
the unit productions. For this purpose we have to compute for each non-terminal the set of
its reachable non-terminal using only unit productions. The naive solution would require a
quadratic computation but here we have the subscripts that give us extra information and it
suﬃces to check for a non-terminal Ai,j only those non-terminals that have similar subscript.
Since for each i, j there are at most O(|G|32k) unit productions, we can do the computation in
O(|d|2|G|32k). Thus, we obtain the following complexity O(|Gd| 52k) = O(|d|3|G| 52k). (cid:74)

XX:24 Grammars for Document Spanners

D Appendix for Section 5

(cid:73) Lemma 29. For every functional extraction grammar G in CNF and for every document
d, the set of stable non-terminals of decorGrmr(Gd) is computable in O(|Gd|52k) where k
is the number of variables G is associated with.

Proof. Recall that in Proposition 22 we showed that we can compute the sets xA for
It is straightforward that the stable
every non-terminal A in G in linear time in |G|.
non-terminals of decorGrmr(Gd) are exactly those of the form Ax,y
i,j . We can scan the non-
terminals of decorGrmr(Gd) and for each such non-terminal Ax,y
i,j check in O(1) whether
xa = x ∪ y. Therefore, the complexity of this step is O(|G|) + O(|decorGrmr(Gd)|) =
(cid:74)
O(|d|3|G| 52k).

(cid:73) Lemma 32. For every functional unambiguous extraction grammar G in CNF and for
every document d, the jump function is computable in O(|d|534k|G|2) where k is the number
of variables G is associated with.

Proof. We claim that Algorithm 1 computes the jump function. The algorithm has access
to the grammar decorGrmr(Gd) as well as to its skippable productions (i.e., it can check
in O(1) whether a production is skippable or not). The algorithm returns a 5 dimensional
array such that at the end of the run jmp[A, i, j, x, y] will contain all of the non-terminals
that are in the result of applying the jump on Ax,y
i,j . The algorithm uses an auxiliary array

Algorithm 1: Compute The Jump
procedure computeJump()
foreach non terminal Ax,y
i,j

reachable[A, i, j, x, y] := {Ax,y
i,j }

in decorGrmr(Gd) do

foreach non terminal A in decorGrmr(Gd) do

insert A to remove

foreach production rule ρ in decorGrmr(Gd) do
if ρ is non-skipabble with lefthand side Ax,y

i,j then

remove := remove \ {Ax,y
i,j }

foreach non-terminal Ax,y
i,j
jmp[A, i, j, x, y] := {Ax,y
i,j } \ remove

in decorGrmr(Gd) do

initialize perform a topological sort on non-terminals;
foreach skippable ρ := Ax,y
topological sort do

i,j → Bx,∅

i,‘ C ∅,y

‘+1,j in decorGrmr(Gd) in reverse order to

if Bx,∅
i,‘

is non-stable then

reachable[A, i, j, x, y] := reachable[A, i, j, x, y] ∪ reachable[B, i, ‘, x, ∅];
jmp[A, i, j, x, y] := reachable[A, i, j, x, y] \ remove;

if C ∅,y

‘+1,j is non-stable then
reachable[A, i, j, x, y] := reachable[A, i, j, x, y] ∪ reachable[C, ‘ + 1, j, ∅, y]

jmp[A, i, j, x, y] := reachable[A, i, j, x, y] \ remove;

output jmp

reachable and an auxiliary set remove. The correctness of the algorithm is based on the

XX:25

L. Peterfreund

following claims:

Claim 1: The array reachable stores in cell reachable[A, i, j, x, y] all of the non-terminals

B such that there is a sequence of skippable productions ρ1, · · · , ρm such that:

ρι follows ρι−1 for every ι,
the left-hand side of ρ1 is Ax,y
i,j ,
the non-stable non-terminal in the right-hand side of ρm is B

Claim 2: The set remove contains all of the non-terminals B for which there is no
non-skippable production with B in the left-hand side. That is, all of the productions that
have B in their left-hand side are skippable.

This two claims allows us to conclude the following. Since both B ∈ reachable[A, i, j, x, y]

and B 6∈ remove, there is a sequence of skippable productions ρ1, · · · , ρm such that:

ρι follows ρι−1 for every ι,
the left-hand side of ρ1 is Ax,y
i,j ,
the non-stable non-terminal in the right-hand side of ρm is B,
there is no production rule that is not skippable whose left-hand side is B.

This, in turn, completes the proof of correctness of the algorithm.

We shall now explain why both claims hold. While Claim 2 is derived directly from
the way we initialize remove, the proof of Claim 1 is more involved as we now explain.
Since decorGrmr(Gd) produces only terminal decorated words of ﬁxed length |d| (see
Lemma 25) and since it is in CNF, we can conclude that the longest derivation sequence of
decorGrmr(Gd) is of length O(|d|). Therefore, the correctness of the claim is obtained
from the fact that we iterate over the skippable derivation in a reverse order to the topological
order.

Complexity. We assume that we can check in O(1) whether a non-terminal is stable. To
do so, we can run the algorithm described in the proof of Lemma 29 and store the data in a
lookup table with the non-terminals as keys and the value is either ‘stable’ or ‘non-stable’.
The runtime of this procedure is O(|Gd|52k).

We also assume that we can check in O(1) whether a rule in decorGrmr(Gd) is skippable.
To do so, we can use the above look-up table and for each rule check whether all of the
conditions in the deﬁnition hold in O(1). We can store this information in a lookup table
with the rules as keys and the value is either ‘skippable’ or ‘non-skippable’. The runtime of
this procedure is also O(|Gd|52k).

The four ﬁrst for each loops are used for initializations and require O(|Gd|52k) =
O(|d|3|G|52k) as the iterate through all production rules of decorGrmr(Gd). We then
preform a topological sort on the production rules in O(|d|3|G|52k).

The last for each loop iterates through all of the skippable rules of decorGrmr(Gd)
ordered by their head in a reverse order to that we have obtained in the topological sort
we performed. There are at most O(|d|3|G|32k) such rules (since we their form is Ax,y
i,j →
Bx,∅
‘+1,j). In each such iteration, we compute set unions and set diﬀerence. The size of
the set is bounded by O(|d|232k|G|). Thus, the total time complexity of the second for loop
(cid:74)
is O(|d|534k|G|2). And ﬁnally, the total complexity of the jump is O(|d|534k|G|2).

i,‘ C ∅,y

D.1 Proof of Theorem 34

(cid:73) Theorem 34. For every functional unambiguous extraction grammar G in CNF and for
every document d, the main enumerating algorithm described above enumerates the mappings

XX:26 Grammars for Document Spanners

(d) (without repetitions) with delay of O(k) between each two consecutive mappings

in
where k is the number of variables G is associated with.

G
(cid:75)

(cid:74)

In what follows, we present each (X, d)-mapping µ as the set {(‘x, i), (ax, j) µ(x) := [i, ji}

of pairs. Before proving the theorem itself we prove some lemmas.

We say that a mapping A is compatible with a set B of pairs of the form (τ, i) with

τ ∈ ΓX and 1 ≤ i ≤ n if B ⊆ A.

(cid:73) Lemma 37. The procedure enumerate(Sx,y
1,n , map) where map = {(x, 1) x ∈ x} ∪ {(y, n +
1) y ∈ y} outputs every mapping µw that corresponds with a decorated word w produced by
decorGrmr(G, d) and that is compatible with map.

Proof. Let w be a decorated word such that γ1 ⇒ · · · ⇒ γm ⇒ w in a leftmost derivation
where every γi 6= γj and γ1 = Sx,y
1,n . We recursively deﬁne µw,j as follows: µw,m is map. We
denote the production rule applied in γ‘ ⇒ γ‘+1 by Ax,y
i0+1,j and µw,‘ is the union
of µw,‘+1 with {(τ, i0 + 1)|τ ∈ z ∪ w}. We say that Ax,y
i0+1,j is productive if µw,‘
strictly contains µw,‘+1. We deﬁne the morphism nonStable that maps stable non-terminal
and non-terminals into (cid:15) and acts as the identity on the non-stable non-terminals.

i,j → Bx,z
i,j → Bx,z

i,i0 C w,y
i,i0 C w,y

We prove that if γ‘ ⇒∗ w where γ‘ is a sequence over the non-terminals and terminals
then enumerate(nonStable(γ‘), ∅) returns the mapping µw,‘. The proof is done by a
nested induction: on ‘ − i for i = 0, · · · ‘ − 1 and an inner induction on the number of
productive productions applied throughout γ‘ ⇒∗ w. If there were no productive productions
applied then µw,‘ = ∅ and, in addition, this implies that nonStable(γ‘) = (cid:15).
Indeed
enumerate((cid:15), ∅) returns ∅ which completes the induction basis. For the induction step: Let
us assume that there is one or more productive production applied in γ‘ ⇒∗ w. This implies
that there is at least one non-stable non-terminal in γ‘. Let us ﬁnd the left most non-stable
non-terminal Ax,y
i,j

in γ‘ and denote γ‘ = αAβ. We can write

αAβ ⇒∗ α0Ax,y

i,j β0 ⇒ α0Bx,z

i,i0 C w,y

i0+1,jβ0 ⇒∗ w

i,j → Bx,z

i,i0 C w,y
i0+1,j
i,j β0, and γ‘0+1 =

where no productive production was applied here αAβ ⇒∗ α0Ax,y
is a productive production. We then denote γ‘ = αAβ, γ‘0 = α0Ax,y
α0Bx,z

i,j β0 and Ax,y

i0+1,jβ0. We distinguish between two cases:

i,i0 C w,y
If A is a non-stable non-terminal then it holds that Ax,y
i,j ∈ jump(A) and then we
consider the run enumerate(nonStable(αAβ), ∅) in which we enter the outer for
loop with Ax,y
i,j and choose from the output of applyProd the pair (β0, map0) that
corresponds with the iteration in applyProd that matches Ax,y
i0+1,j. Note
that in this case map0 is the union {(τ, i0 + 1)|x ∈ z ∪ w}. We then continue with calling
enumerate(nonStable(γ‘0 + 1), map0). By induction hypothesis and by the deﬁnition
of enumerate (and in particular the fact that it accumulates the output mapping
throughout the run), it holds that enumerate(nonStable(αAβ), ∅) returns µw,‘.
If A is a stable non-terminal then it holds that Ax,y
non-stable non-terminal to the right of A. In this case, the proof continues similarly.

i,j ∈ jump(A0) where A0 is the ﬁrst

i,j → Bx,z

i,i0 C w,y

We can ﬁnally conclude the desired claim.

(cid:74)

(cid:73) Lemma 38. The procedure enumerate(Sx,y
with a decorated word w produced by decorGrmr(G, d) exactly once.

1,n ) outputs every mapping µw that corresponds

Proof. Assume to the contrary that there is a mapping µ that is outputted twice. Let
us consider the two diﬀerent call stacks of the procedure enumerate and let us examine
the ﬁrst point where they diﬀer. That is, in one stack enumerate(α, map) has called

L. Peterfreund

XX:27

enumerate(α0, map0) and in the other stack enumerate(α, map) has called the procedure
enumerate(α00, map00). This, in turn, implies that the applyProd returned two pairs
(β, map) and (β0, map0) that are diﬀerent. Note that for any two pairs (β, map) and (β0, map0)
in the output of applyProd it holds that both map 6= ∅ and map0 6= ∅, and map 6= map0
since decorGrmr(Gd) is unambiguous. This, combined with the fact that enumerate
accumulates its output mapping throughout the run, we conclude that the mappings in both
(cid:74)
runs would be diﬀerent. That is a contradiction.

(cid:73) Proposition 39. The procedure applyProd is always called by enumerate with a non-
terminal A that is non-stable and appears in the lefthand side of some non-skippable produc-
tion.

Proof. This is straightforward from the deﬁnition of jump and the fact that applyProd is
called on a non-terminal in the image of jump. Note that jump never maps a non-terminal
(cid:74)
into the empty set.

(cid:73) Proposition 40. The following hold:

The procedure applyProd always returns at least one pair (β, map) with map 6= ∅.
For every pair (β, map) that is in the output of applyProd it holds that map 6= ∅.

Proof.

Straightforward from Proposition 39.

If applyProd is called with Ax,y
of a non-skippable rule Ax,y
z ∪ w 6= ∅ which concludes the desired claim.
This concludes the proof.

i,j → Bx,z

i,j then by Proposition 39, it appears in the lefthand side
‘+1,j. Since the rule is not skippable it holds that

i,‘ C w,y

(cid:74)

(cid:73) Lemma 41. The procedure enumerate(Sx,y
secutive mappings.

1,n ) outputs with O(k) delay between two con-

Proof. The size of each mapping that is outputted by enumerate is O(k). Due to Proposi-
tion 40, before each recursive call to enumerate the mapping grows in at least one pair.
Therefore the stack call of enumerate is at most k + 1. Note that when the stack call of
enum is of depth i then in the last call to enumerate (the top of the stack) the ﬁrst element
passed to it contains at most k − i non-stable non-terminals (since the mappings are always
(cid:74)
of ﬁxed size k).

XX:28 Grammars for Document Spanners

Algorithm 2: Apply Production Algorithm

procedure applyProd(Ax,y
i,j )
initialize map = ∅;
foreach non-skippable production of the form Ax,y

i,j → Bx,z

i,‘ C w,y

‘+1,j do

map = ∅;
foreach x ∈ z ∪ w do

if Bx,z

map = map ∪ {(x, ‘ + 1)}
i,‘ and C w,y
i,‘ C w,y
β = Bx,z
is non-stable and C w,y

‘+1,j are non-stable then
‘+1,j

if Bx,z
i,‘

‘+1,j is stable then

β = Bx,z
i,‘
is stable and C w,y

if Bx,z
i,‘

‘+1,j is non-stable then

β = C w,y
‘+1,j
if Bx,z
i,‘ and C w,y
β = (cid:15)

output (β, map)

‘+1,j are stable then

