How Do Deep Convolutional SDM Trained on Satellite
Images Unravel Vegetation Ecology ?
Benjamin Deneu, Alexis Joly, Pierre Bonnet, Maximilien Servajean, François

Munoz

To cite this version:

Benjamin Deneu, Alexis Joly, Pierre Bonnet, Maximilien Servajean, François Munoz. How Do Deep
ICPR 2020 - 25th
Convolutional SDM Trained on Satellite Images Unravel Vegetation Ecology ?.
International Conference on Pattern Recognition, Alberto Del Bimbo; Rita Cucchiara; Stan Sclaroff;
Giovanni Maria Farinella; Tao Mei; Marco Bertini; Hugo Jair Escalante; Roberto Vezzani, Jan 2021,
Milan / Virtual, Italy. pp.148-158, ￿10.1007/978-3-030-68780-9_15￿. ￿hal-03167637￿

HAL Id: hal-03167637

https://hal.inrae.fr/hal-03167637

Submitted on 12 Mar 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

How do Deep Convolutional SDM trained on satellite
images unravel vegetation ecology?

Benjamin Deneu1,2[0000−0003−0640−5706], Alexis Joly1[0000−0002−2161−9940], Pierre
Bonnet2,3[0000−0002−2828−4389], Maximilien Servajean4[0000−0002−9426−2583], and
François Munoz5[0000−0001−8776−4705]

1 INRIA, UMR LIRMM, Univ Montpellier, France
2 AMAP, Univ Montpellier, CIRAD, CNRS, INRAE, IRD, Montpellier, France
3 CIRAD, UMR AMAP, F-34398 Montpellier, France
4 LIRMM, Université Paul Valéry, University of Montpellier, CNRS, Montpellier, France
5 CNRS, LECA, France

Abstract. Species distribution models (SDM) assess and predict how species
spatial distributions depend on the environment, due to species ecological
preferences. These models are used in many different scenarios such as con-
servation plans or monitoring of invasive species. The choice of a model and
of environmental data have strong impact on the model’s ability to capture im-
portant ecological information. Speciﬁcally, state-of-the-art models generally
rely on local, punctual environmental information, and do not take into ac-
count environmental variation in surrounding landscape. Here we use a con-
volutional neural network model to analyze and predict species distributions
depending on high resolution data including remote sensing images, land cover
and altitude. We show that the model unravel the functional response of veg-
etation to both local and large-scale environmental variation. To demonstrate
the ecological signiﬁcance of the results, we propose an original statistical anal-
ysis of t-SNE nonlinear dimension reduction. We illustrate and test the traits-
species-environment relationships learned by the model and expressed in t-
SNE dimensions.

Keywords: Species Distribution Model · Convolutional Neural Network · Eco-
logical Interpretation · Plant functional traits · Trait–environment relationships
· t-SNE

1 Introduction

Understanding and predicting the geographic distribution of species is a key objec-
tive in ecology and conservation. Species Distribution Models (SDM) aim at char-
acterizing the relationship between the environment and species occurrences, de-
pending on species ecological niches [14]. The ecological niche is multidimensional,
and involves factors playing in a complex fashion (i.e. non linear system) and at
multiple spatial scales. Most SDMs are correlative methods relating known species
occurrence data to potential environmental predictors [17,1,25].Popular examples
of such methods include MAXENT [26,27], random forest [9] and boosted regres-
sion trees [10,15]. Earlier works devised SDMs based on single-layer neural networks

2

B. Deneu et al.

[22,2], and recently deep neural networks have proved relevant to better address the
complexity of ecological niches, allowing to recognized a larger complexity in the
way environment shapes ecological niches [6,4]. Key advantages of deep learning
are that (i) it allows characterizing complex structuring of ecological niche depend-
ing on multiple environmental factors, (ii) it can learn ecological features common
to a large number of species, and thus grasp the signatures of common ecological
processes and improve SDM predictions across species [5,7].

A speciﬁc class of neural networks initially proposed in [21], named Convolu-
tional Neural Networks (CNN), has very recently been proposed for SDM [5,13]. A
property of CNN is that they rely on spatial environmental tensors rather than on
local values of environmental factors. These tensors represent the spatial realization
of environmental factors around each point. Unlike other SDM approaches, CNN-
based SDMs (CNN-SDMs) can use this very large input data and therefore potentially
capture richer information than in punctual vectors. CNNs were originally designed
for image classiﬁcation [21] and proved to outperform any other statistical or ma-
chine learning methods in the task of learning complex visual patterns. This largely
explains why CNN-based architectures are the most popular deep learning imple-
mentations in ecological studies since few years [7].

In this paper, we use a deep species distribution model based on a convolutional
neural network applied to high resolution remote sensing images as one of the in-
put covariables. This model has already been evaluated and compared to other more
classical methods revealing superior performance to state of the art models. In this
paper we are interested in the interpretation of these performances. The major con-
tribution of the paper is to provide an ecological interpretation of the model. There-
fore, we propose to rely on t-SNE [23], a nonlinear dimension reduction technique
widely used in data science to visualize high-dimensional feature spaces. More pre-
cisely, we use it to build a low-dimensional embedding of the 2028-dimensional rep-
resentation space learned by the convolutional neural network (i.e. the 2028 neu-
rons used as input of the species prediction layer of the model). The resulting low-
dimensional embedding is then used in two ways: (i) to visualize the relationships
between the learned features, the species traits and the environment, and (ii) to
quantify these relationships using statistical tests. The main outcome of our study
is that the statistical tests clearly demonstrate that the model was able to capture
meaningful relationships between the species traits and the environment. This is
particularly remarkable in the sense that none of these information were used as
input covariables during the training of the model. The model was actually capable
of inferring them directly from the high-resolution spatialized images used as input
and the species occurrences.

2 Material and Methods

2.1 CNN-SDM Model Training and Validation

Training Dataset A detailed description of the dataset (named GeoLifeCLEF 2020)
is provided in [8]. It consists of 1,921,123 observations from the US (1,097,640) and
France (823,483) covering 31, 435 plant and animal species (Table 1). Each species

Title Suppressed Due to Excessive Length

3

observation is paired with high-resolution covariates (RGB-IR imagery, land cover
and altitude), see Fig.1. We used RGB-IR imagery from the 2009-2011 cycle of the Na-
tional Agriculture Imagery Program (NAIP) in the U.S.6, and from the BD-ORTHO®
2.0 and ORTHO-HR® 1.0 databases from IGN in France7. Land cover data originates
from the National Land Cover Database (NLCD) [20] for the U.S. and from CESBIO8
for France. All elevation data comes from the NASA Shuttle Radar Topography Mis-
sion (SRTM)9. All of these high-resolution covariates were homogenized at a spatial
resolution of 1 meter per pixel and provided as 256 × 256 images covering a 256m
× 256m square centered on each observation (some were oversampled and some
where downsampled).

(b) Example of high-resolution covariates
patch (respectively: RGB imagery, IR im-
agery, altitude, land cover).

(a) Occurrences

Fig. 1: Occurrences distribution (training data in blue, test data in red) in France (a),
and an example high-resolution tensor (b). RGB patch is displayed with native colors,
IR imagery, altitude and land cover are in artiﬁcial colors from purple (lowest values)
to yellow (highest values).

Table 1: Number of occurrences, of species and of occurrences per species grouped
for plants and animals, and per region (for the training set).

Kingdom
Plants
Animals
All

Nb. of occurrences
France
741,010
61,865
802,875

US
524,280
551,563
1,622,120

Nb. of species
US
11,369
13,882
25,251

France
3,114
4,899
8,013

Nb. of occ. per sp.
US
46.1
39.7
42.6

France
238.0
12.6
100.2

6 National Agriculture Image Program, https://www.fsa.usda.gov
7 https://geoservices.ign.fr
8 http://osr-cesbio.ups-tlse.fr/~oso/posts/2017-03-30-carte-s2-2016/
9 https://lpdaac.usgs.gov/products/srtmgl1v003/

4

B. Deneu et al.

Deep Convolutional SDM Architecture Our deep convolutional neural network is
the composition of non linear transformations of the input space z = φ(x) with a lin-
ear classiﬁer ψ(z). The vector z is called the representation vector, or feature vector
of the input tensor x. The architecture used is based on the Inception V3 [28] model
adapted in the same way introduced in [11]. The representation layer has size 2048
and the loss is the cross-entropy. The output of the model can be interpreted as the
probability for each species.

Predictive Performance We evaluated the model and compared it to other more
classical approaches, such as a random forest learned on environmental data (RF),
using a spatial block holdout procedure10. On a top-30 score, the CNN obtained
23.5% success compared to the 20.4% success of the random forest environmental
model. This evaluation allowed us to validate the performance of the model (CNN-
SDM) that we will study later in this report.

2.2 Ecological Interpretation of the Learned Features

We considered environmental and species trait data not used during model training.
We assess the extent to which the model could capture ecological information such
as the functional response of plant species to environmental constraints (specif-
ically, climatic and pedological factors). In the following subsections, we ﬁrst de-
scribe the environmental and species traits data used (2.3). In subsection 2.4, we
then describe the non linear dimension reduction technique that we used to embed
the 2048-dimensional feature vectors z into a low-dimensional space of 2 or 3 di-
mensions aimed at conserving only the most structuring information. In subsection
2.5, we describe the statistical tests that were performed on top of the resulting low-
dimensional embedding for the ecological interpretation. Finally, in subsection 2.6,
we describe some additional methodological details that were used for visualization
purposes.

2.3 Environmental and Trait Data

We used 19 bio-climatic rasters (30arcsec2/pixel (above 1km2/pixel) from WorldClim
[19]) and 8 pedologic rasters (250m2/pixel, from SoilGrids [18]), the detailed list and
resolutions are presented in Table 2.

We used ecological information available for more than 1,400 plant species, in
terms of Ellenberg’s indicator values (EIVs) [16] (see Table 3). These variables repre-
sent an ordinal classiﬁcation of ecological strategies for major environmental con-
straints and the use of essential resources [3].

10 Test occurrences are contained in 5×5km quadrats with no train occurrences and represent

2.5% of the overall set.

Title Suppressed Due to Excessive Length

5

Table 2: Summary of environmental variable rasters provided.

Res.
Name Description
bio_1 Annual Mean Temperature
30 arcsec
bio_2 Mean Diurnal Range (Mean of monthly (max temp - min temp)) 30 arcsec
30 arcsec
bio_3 Isothermality (bio_2/bio_7) (* 100)
30 arcsec
bio_4 Temperature Seasonality (standard deviation *100)
30 arcsec
bio_5 Max Temperature of Warmest Month
30 arcsec
bio_6 Min Temperature of Coldest Month
30 arcsec
bio_7 Temperature Annual Range (bio_5-bio_6)
30 arcsec
bio_8 Mean Temperature of Wettest Quarter
30 arcsec
bio_9 Mean Temperature of Driest Quarter
30 arcsec
bio_10 Mean Temperature of Warmest Quarter
30 arcsec
bio_11 Mean Temperature of Coldest Quarter
30 arcsec
bio_12 Annual Precipitation
30 arcsec
bio_13 Precipitation of Wettest Month
30 arcsec
bio_14 Precipitation of Driest Month
30 arcsec
bio_15 Precipitation Seasonality (Coefﬁcient of Variation)
30 arcsec
bio_16 Precipitation of Wettest Quarter
30 arcsec
bio_17 Precipitation of Driest Quarter
30 arcsec
bio_18 Precipitation of Warmest Quarter
30 arcsec
bio_19 Precipitation of Coldest Quarter
250 m
orcdrc Soil organic carbon content (g/kg at 15cm depth)
250 m
phihox Ph x 10 in H20 (at 15cm depth)
250 m
cecsol Cation exchange capacity of soil in cmolc/kg 15cm depth
250 m
bdticm Absolute depth to bedrock in cm
250 m
clyppt Clay (0-2 micro meter) mass fraction at 15cm depth
250 m
sltppt Silt mass fraction at 15cm depth
250 m
sndppt Sand mass fraction at 15cm depth
250 m

bldﬁe Bulk density in kg/m3 at 15cm depth

Table 3: Summary of the used plant species traits.

Ranges of values (Nb species)
2 - 9 (1,423)
1 - 9 (1,413)
1 - 8 (1,411))
1 - 9 (1,405)
1 - 12 (1,405)

Description
Light availability
Temperature
Climatic continentality

Name
EIV L
EIV T
EIV K
EIV AirH Air humidity
Soil humidity
EIV F
Reaction (soil acidity / pH) 1 - 9 (1,410)
EIV R
1 - 9 (1,412)
EIV TroL Trophic level
0 - 9 (1,416)
EIV S
1 - 9 (1,416)
EIV SoiT Soil texture
1 - 9 (1,422)
EIV N

Nitrogen (soil fertility)

Salt (soil salinity)

6

B. Deneu et al.

2.4 Dimension Reduction

CNNs train a representation space in which species occurrences projections z = φ(x)
tend to be linearly separable (thanks to the multinomial logistic regression ψ trained
on top of z). We analyzed how the structure of the learned space could grasp ma-
jor ecological and environmental information unused during learning. We identi-
ﬁed major dimensions of the learned space by projecting the feature vectors z into
a very low-dimensional space of 2 or 3 dimensions. For this purpose, we used the
t-SNE dimension reduction method [23]. First, t-SNE constructs a probability distri-
bution over pairs of high-dimensional objects such as similar objects are assigned a
higher probability while dissimilar points are assigned a lower probability. Second, t-
SNE deﬁnes a similar probability distribution over the points in the low-dimensional
map, and it minimizes the Kullback–Leibler divergence (KL divergence) between the
two distributions with respect to the locations of the points in the map. The main
advantage of t-SNE is that it is able to preserve the main regularities of the original
space even if some of them are not linear. We also computed PCA as a preliminary
dimension reduction step.
In more details, to process the dimension reduction we randomly selected 32, 000
training occurrences x j and computed their representations z j = φ(x j ). Then, we
ﬁrst reduced the dimension from 2048 to 50 by PCA using the PCA method of the
scikitlearn package. The resulting 50-dimensional feature vectors were then further
reduced by t-SNE using the t-SNE method of the scikitlean package. For most ex-
periments, the used dimension for t-SNE was set to 2 (apart from the geographi-
cal map of Figure Figure 3b where it was set to 3 and base on other occurrences,
see section subsection 2.6). In the following, we denote as ˜z = g (z) the resulting 2-
dimensional feature vectors where the function g denotes the complete dimension
reduction function (PCA+t-SNE).

2.5 Ecological Interpretation of t-SNE Dimensions

Relationship of t-SNE Dimensions to Ecological Traits and Environmental Factors
For each of the two variables ˜z1 and ˜z2, corresponding in the two axis of the t-SNE,
we ﬁtted a linear model using either the environmental variables or the species trait
variables as input covariates (lm function in R environment).
The link between the representation space learned by the model (condensed in the
t-SNE space) and these data (not used during the learning process) offers a way to
interpret the ecological signiﬁcance of patterns learned by the CNN-SDM models.

Traits-Environment Relationships Trait-environment relationship represent essen-
tial functional responses of plants to changing environmental conditions. Charac-
terizing these relationships is an essential goal in functional biogeography [29]. We
tested whether t-SNE axes unravel such relationships by mean of weighted correla-
tion analysis. We calculated the correlation between species trait and environmental
value for each training occurrence, weighted by the score of the occurrence along
each t-SNE axis. Under the null hypothesis, the t-SNE axis does not reﬂect any link-
age between trait and environment, under the alternative hypothesis, increasing score

Title Suppressed Due to Excessive Length

7

is associated to joint variation of trait and environment. We measured the weighted
correlation [24] for each t-SNE variable ˜zk and for each pair of ecological trait and
environmental variable. We used the function wtd.cor package weights in R. Fur-
thermore, because we computed many tests for all pairs of trait and environmental
variables, we corrected the p-value of the tests by the method false discovery rate
(p.adjust function in R).

2.6 Visualization

We used different types of visualisations to illustrate the main sources of ecological
variation expressed in the two-dimensional t-SNE space. We discretized the space of
the t-SNE by applying an n ×n-sized grid mesh. For each cell of this grid we retrieved
the m-coordinate vector of the center of the cell and we search for the nearest neigh-
bor among the set of vectors ˜z using scikitlearn’s nearest neigbhor function. Once the
closest point to the center of each cell is retrieved, only those that are actually inside
the respective cell are kept by a ﬁlter on these coordinates. This results in associating
for each cell the occurrence closest to the center if there is one. The different ﬁgures
of this visualization consist in the display, for each cell, of a data relative to the as-
sociated occurrence. For the ﬁrst ﬁg. 3a, we displayed the RGB patch of the remote
sensing imagery corresponding to this occurrence. For the other ﬁgures (2a and 2b)
we displayed the value of an ecological trait of the corresponding species or the real-
ization of one of the environmental variables at the point of occurrence.

The second representation is based on the 3-dimensional t-SNE space and, con-
versely, represents the realization of this space on the geographical space. This 3-
dimensional t-SNE space was obtained by the same process as the 2-dimensional
space described in detail in section 2.4 but with one difference, the dimension re-
duction was not performed with the same set of occurrences. As this representation
is geographical, it requires a better coverage of the territory than the simple random
selection of a certain number of occurrences. We selected occurrences with a method
of nearest neighbor. For a grid of points with a resolution of 1km over the whole ter-
ritory, we associated each point to the nearest occurrence. The selected occurrences
are those used for dimension reduction. Then to plot the 3-dimensional t-SNE on the
map, we re-scale each axis such as the values are included in 0-255. Each point can
then be associated to a RGB color by its coordinates. The resulting map is the plot of
each point as a color pixel at its geographical position.

3 Results and Discussion

The statistical analysis of the learned t-SNE space reveals that the CNN-based SDM
could grasp important ecological processes shaping the large scale distributions of
plants. Indeed, almost all linear models linking scores along t-SNE to species traits
provided highly signiﬁcant relationships (Table 4). We can in particular note a strong
coefﬁcient on EIV T (species preferences in Temperature) on both axes. The plant
Ellenberg indicator values could alone explain a large part of the variation of species
scores along t-SNE axes (Adjusted R2 of 0.111 and 0.231). These results show that

8

B. Deneu et al.

Table 4: Ellenberg linear models

tsne_1

tsne_2

EIV L
EIV T
EIV K
EIV AirH
EIV F
EIV R
EIV TroL
EIV S
EIV SoiT
EIV N
Constant
R2
Adjusted R2

Note:

(0.378)

(0.236)
(0.260)
(0.389)

∗

∗∗∗

∗∗∗

∗∗∗

Estimate (Std. Error)
−1.562
−5.035
2.523
0.732
1.461
0.461
2.902
−2.714
1.649
0.211 (0.212)
−5.951 (3.947)

∗∗∗

∗∗∗

∗∗∗

∗∗∗

∗∗

(0.409)

(0.213)

(0.181)
(0.366)
(0.252)

Estimate (Std. Error)

∗∗∗

(0.214)
(0.235)

∗∗∗

2.630
9.478
0.150 (0.352)
∗∗

(0.341)

−0.869
2.328
−0.686
3.851
−0.981
2.848
−0.598
−113.831

∗∗∗

∗∗∗

∗∗∗

∗∗∗

∗∗∗

∗∗∗

∗∗∗

(0.370)
(0.192)
(0.163)
(0.331)
(0.228)
(0.192)
(3.569)

0.111
0.111

0.232
0.231
p<0.05;

∗

p<0.1;

∗∗

∗∗∗

p<0.01

the model is able to capture information related to the ecology of the species in the
patches.

Fig. 2a represent the species preferences in temperature and Fig. 2b represent
Annual mean temperature of occurrences data on the t-SNE. We found a clear gra-
dient of mean annual temperature on the t-SNE. The fact that this gradient is par-
ticularly sharp on t-SNE, which is the result of a dimension reduction, indicates that
information strongly correlated with annual temperature is captured and important
in the model. It is quite logical that the ﬁgure on the associated ecological trait (EIV
T) is similar conﬁrming that the plants with the coolest temperature preferences are
found in the coldest areas and vice versa. These results highlight that the informa-
tion captured by the model is strongly related to the environment and ecology of the
species, even though this data was not used directly. Fig. 3a represent RGB patches
from the model training data on the t-SNE space and Fig. 3b represents the geo-
graphical projection of the 3-dimensional t-SNE space on the territory with the col-
ors deﬁned by the position in the t-SNE space.

These two ﬁgures highlight two complementary pieces of information. On the
one hand, the display of the patches on the t-SNE highlights the landscape factors
that the CNN is able to identify and differentiate in its representation space. Indeed
the Fig. 3a highlights different areas of the t-SNE corresponding to several major
types of distinct landscapes. We can note for example the mountain areas on the
left next to which we ﬁnd the forests a little lower down. The more agricultural ar-
eas also stand out while the lower and right part of the t-SNE is dominated by urban
type landscapes. On the other hand, Fig. 3b shows learning on a larger scale. This
map shows how the CNN has learned to distinguish large eco-geographic regions. Of
particular note is the Mediterranean region (on southern part of the map), and the

Title Suppressed Due to Excessive Length

9

(a)

(b)

Fig. 2: Visualization of the occurrences’ species preferences in temperature (EIV T)(a)
and the annual mean temperature (bio_1) at occurrences location (b) on the t-SNE
space. Artiﬁcial colors from purple (lowest values) to yellow (highest values).

(a)

(b)

Fig. 3: (a) Visualization of the remote sensing imagery patch (RGB) of occurrences on
the t-SNE space. (b) Geographical projection of the 3-dimensional t-SNE space on
the territory.

mountainous areas (i.e. the Pyrenees on the south-western part, and the Alps on the
south-eastern part), which seem to be well identiﬁed. More generally the map allows
to show coherence on a large scale, between typical vegetation zones well identiﬁed
by ecologists, and bio-geographic zones well characterized on the ﬁeld in previous
studies. The confrontation of these two results shows that the model is capable of
discerning both large regions and different habitats within the same large geograph-

10

B. Deneu et al.

ical area (such as urban-rural). The ability to identify factors at different scales based
on ﬁne scale imaging training data is an important result that highlights one of the
advantage of the CNN models. Concerning the species trait-environment relation-
ships, the detailed results matrix of each pair for each axis is given in supplementary
materials Tables C1 and C2[12]. A general ﬁnding is that most of the species trait-
environment correlations weighted by the t-SNE axes are highly signiﬁcant. This
shows that the CNN is capable of learning a relationship between environment and
species ecology through the use of high-resolution covariate patches. All these results
highlight a strong point of the CNN model which is capable of capturing information
related to the environment and the ecology of species through the use of data acces-
sible at large scale and ﬁne resolution, but also to highlight links between the envi-
ronment and the ecology of species. This model could therefore be useful in many
ecological scenarios where the objective would be to study this link. All these points
are also insights for interpreting the performance of the CNN models. By learning a
representation space common to all the studied species, the model is able to extract
common information between species that are directly correlated to environmental
factors or related to the ecology of the species.

4 Conclusion

Our study shows the interest of using convolutional neural networks for species dis-
tribution modelling (CNN-SDM), at high spatial resolution over large geographical
areas. The use of the t-SNE technique made it possible for the ﬁrst time to visu-
alise and test the learning capacities of this type of model to capture relationships
between ecological strategies of plants and environmental conditions at their occur-
rence locations. The methodological framework established here offers a new way of
statistically assessing the extent to which the relationships between the plant traits
and their environments are correlated, inspired by the conceptual and methodolog-
ical framework of functional biogeography [29]. It also allows visualizing through t-
SNE the clusters of visual information (from satellite images) deemed most relevant
during the learning phase of the CNN-SDMs. This work shows that the approach cap-
tures richer information on the landscape context than the speciﬁc ponctual data re-
lated to the environment for predicting the presence of species, and will undoubtedly
open up new perspectives in the analysis of plant-environment trait relationships.

Acknowledgement

This project has received funding from the French National Research Agency under
the Investments for the Future Program, referred as ANR-16-CONV-0004 and from
the European Union’s Horizon 2020 research and innovation program under grant
agreement No 863463 (Cos4Cloud project).

Title Suppressed Due to Excessive Length

11

References

1. Antoine, G., Wilfried, T.: Predicting species distribution: offering more than simple
habitat models. Ecology Letters 8(9), 993–1009 (2005). https://doi.org/10.1111/j.1461-
0248.2005.00792.x

2. Baran, P., Lek, S., Delacoste, M., Belaud, A.: Stochastic models that predict trout popula-
tion density or biomass on a mesohabitat scale. Hydrobiologia 337(1), 1–9 (Nov 1996).
https://doi.org/10.1007/BF00028502

3. Bartelheimer, M., Poschlod, P.: Functional characterizations of ellenberg indicator values–
a review on ecophysiological determinants. Functional ecology 30(4), 506–516 (2016)
4. Benkendorf, D.J., Hawkins, C.P.: Effects of sample size and network depth on a deep learn-
ing approach to species distribution modeling. Ecological Informatics 60, 101137 (2020)
5. Botella, C., Joly, A., Bonnet, P., Monestiez, P., Munoz, F.: A deep learning approach to
species distribution modelling. Multimedia Technologies for Environmental & Biodiver-
sity Informatics (2018)

6. Chen, D., Xue, Y., Chen, S., Fink, D., Gomes, C.P.: Deep multi-species embedding. CoRR

abs/1609.09353 (2016), http://arxiv.org/abs/1609.09353

7. Christin, S., Hervet, É., Lecomte, N.: Applications for deep learning in ecology. Methods in

Ecology and Evolution 10(10), 1632–1644 (2019)

8. Cole, E., Deneu, B., Lorieul, T., Servajean, M., Botella, C., Morris, D., Jojic, N., Bonnet, P.,

Joly, A.: The geolifeclef 2020 dataset. arXiv preprint arXiv:2004.04192 (2020)

9. Cutler, D.R., Edwards Jr., T.C., Beard, K.H., Cutler, A., Hess, K.T., Gibson, J., Lawler,
J.J.: Random forests for classiﬁcation in ecology. Ecology 88(11), 2783–2792 (2007).
https://doi.org/10.1890/07-0539.1

10. De’ath, G.: Boosted trees for ecological modeling and prediction. Ecology 88(1), 243–251

(2007). https://doi.org/10.1890/0012-9658(2007)88[243:BTFEMA]2.0.CO;2

11. Deneu, B., Servajean, M., Joly, A.: Participation of lirmm/inria to the geo-lifeclef 2020 chal-

lenge. CLEF working notes (2020)

12. Deneu, B., Joly, A., Bonnet, P., Servajean, M., Munoz, F.: Supplementary materials: How do
deep convolutional sdm trained on satellite images unravel vegetation ecology?, https:
//gitlab.inria.fr/bdeneu/supplementary-materials-maes2020-paper-19
13. Deneu, B., Servajean, M., Botella, C., Joly, A.: Location-based species recommendation us-
ing co-occurrences and environment- geolifeclef 2018 challenge. In: CLEF working notes
2018 (2018)

14. Elith, J., Leathwick, J.R.: Species Distribution Models: Ecological Explanation and Predic-
tion Across Space and Time. Annual Review of Ecology, Evolution, and Systematics 40,
677–697 (2009)

15. Elith, J., Leathwick, J.R., Hastie, T.: A working guide to boosted regression trees. Journal of
Animal Ecology 77(4), 802–813 (2008). https://doi.org/10.1111/j.1365-2656.2008.01390.x
16. Ellenberg, H.H.: Vegetation ecology of central Europe. Cambridge University Press (1988)
17. Guisan, A., Zimmermann, N.E.: Predictive habitat distribution models in ecology. Ecolog-
ical Modelling 135(2), 147 – 186 (2000). https://doi.org/https://doi.org/10.1016/S0304-
3800(00)00354-9

18. Hengl, T., de Jesus, J.M., Heuvelink, G.B., Gonzalez, M.R., Kilibarda, M., Blagoti´c, A.,
Shangguan, W., Wright, M.N., Geng, X., Bauer-Marschallinger, B., et al.: Soilgrids250m:
Global gridded soil information based on machine learning. PLoS one 12(2) (2017)
19. Hijmans, R.J., Cameron, S.E., Parra, J.L., Jones, P.G., Jarvis, A.: Very high resolution interpo-
lated climate surfaces for global land areas. International Journal of Climatology: A Jour-
nal of the Royal Meteorological Society 25(15), 1965–1978 (2005)

12

B. Deneu et al.

20. Homer, C., Dewitz, J., Yang, L., Jin, S., Danielson, P., Xian, G., Coulston, J., Herold, N., Wick-
ham, J., Megown, K.: Completion of the 2011 national land cover database for the con-
terminous united states–representing a decade of land cover change information. Pho-
togrammetric Engineering & Remote Sensing 81(5), 345–354 (2015)

21. LeCun, Y., Boser, B., Denker, J.S., Henderson, D., Howard, R.E., Hubbard, W., Jackel, L.D.:
Backpropagation applied to handwritten zip code recognition. Neural computation 1(4),
541–551 (1989)

22. Lek, S., Delacoste, M., Baran, P., Dimopoulos, I., Lauga, J., Aulagnier, S.: Application of neu-
ral networks to modelling nonlinear relationships in ecology. Ecological Modelling 90(1),
39 – 52 (1996). https://doi.org//10.1016/0304-3800(95)00142-5

23. Maaten, L.v.d., Hinton, G.: Visualizing data using t-sne. Journal of machine learning re-

search 9(Nov), 2579–2605 (2008)

24. Miller, J.E., Damschen, E.I., Ives, A.R.: Functional traits and community composition: a
comparison among community-weighted means, weighted correlations, and multilevel
models. Methods in Ecology and Evolution 10(3), 415–425 (2019)

25. Peterson, A.T.: Ecological niches and geographic distributions. Princeton University Press

(2011)

26. Phillips, S.J., Anderson, R.P., Schapire, R.E.: Maximum entropy modeling of species geo-

graphic distributions. Ecological modelling 190(3-4), 231–259 (2006)

27. Phillips, S.J., Dudík, M.: Modeling of species distributions with maxent: new
extensions and a comprehensive evaluation. Ecography 31(2), 161–175 (2008).
https://doi.org/10.1111/j.0906-7590.2008.5203.x

28. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., Wojna, Z.: Rethinking the inception archi-
tecture for computer vision. In: Proceedings of the IEEE conference on computer vision
and pattern recognition. pp. 2818–2826 (2016)

29. Violle, C., Reich, P.B., Pacala, S.W., Enquist, B.J., Kattge, J.: The emergence and promise
of functional biogeography. Proceedings of the National Academy of Sciences 111(38),
13690–13696 (2014)

