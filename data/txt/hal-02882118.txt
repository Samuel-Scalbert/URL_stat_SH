Successor-Invariant First-Order Logic on Classes of
Bounded Degree
Julien Grange

To cite this version:

Julien Grange. Successor-Invariant First-Order Logic on Classes of Bounded Degree. LICS 2020 -
Thirty-Fifth Annual ACM/IEEE Symposium on Logic in Computer Science, Jul 2020, Saarbrücken /
Virtual, Germany. ￿10.1145/3373718.3394767￿. ￿hal-02882118￿

HAL Id: hal-02882118

https://inria.hal.science/hal-02882118

Submitted on 26 Jun 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Successor-Invariant First-Order Logic on Classes
of Bounded Degree

Julien Grange
ENS Paris, PSL, INRIA, CNRS

LICS 2020

Abstract

We study the expressive power of successor-invariant ﬁrst-order logic,
which is an extension of ﬁrst-order logic where the usage of an additional
successor relation on the structure is allowed, as long as the validity of
formulas is independent on the choice of a particular successor.

We show that when the degree is bounded, successor-invariant ﬁrst-

order logic is no more expressive than ﬁrst-order logic.

1

Introduction

First order logic, FO, is the standard formalism to express properties of ﬁnite
structures. Its expressive power is well known, and very restrained, as it can
only express properties that are local, which roughly means that it can only
talk about the immediate surroundings of a small number of elements, and it is
unable to count.

A number of logics with higher expressivity can be deﬁned with FO as a
building block, such as MSO, in which quantiﬁcation over sets is allowed, and
LFP, which adds a ﬁxpoint operator to FO. These additions break the local
character of the logic.

Another way to deﬁne logics from FO is through the addition, in an invariant
way, of arithmetic predicates on the structure that are exterior to the vocabulary.
This amounts to arbitrarily identifying the universe of the structure with an
initial segment of the integers, and allowing some arithmetic on them. However,
we want these extensions to deﬁne properties of the structures, and not to
depend on a particular ordering on their elements: thus we focus on invariant
extensions of FO.

If the only predicate allowed is the order, we get order-invariant ﬁrst-order
logic, < -inv FO. Restricting a bit the additional relation, we get successor-
invariant ﬁrst-order, Succ-inv FO. In this formalism, we only grant an access to
the successor relation derived from the order, provided that the evaluation of a
sentence using this successor relation is independent of the choice of a particular
successor.

1

The problem of determining whether an FO-sentence using an order or a
successor relation is invariant wrt. this relation is undecidable, by reduction
from Trakhtenbrot’s theorem [10]. Hence we use here the term “logic” somewhat
liberally, since having a recursive syntax is a usual requirement for a logic.

The study of these two formalisms ﬁnds its motivation, among other topics
such as descriptive complexity, in database theory. As databases are commonly
stored on disk that implicitly order their memory segments, when one wishes to
express a query in FO, one has access to an additional order on the elements
of the database. However, making use of this order without care could result in
queries that evaluate diﬀerently on two implementations of the same database,
which is clearly an undesirable behavior. We want to use this order only in an
invariant way; this way, the result of a query depends only on the database it
is run on, and not on the way the data is stored on disk. This amounts exactly
to the deﬁnition of < -inv FO, or Succ-inv FO if we restrict the way this order
can be accessed.

It is straightforward that < -inv FO is at least as expressive as Succ-inv FO,
which in turn can express any FO-deﬁnable property. Gurevich constructed a
class of ﬁnite structures that can be deﬁned by an < -inv FO sentence, but which
is not FO-deﬁnable. Though this construction wasn’t published by Gurevich,
it can be found e.g.
in Section 5.2 of [8]. Rossman extended this result, and
proved in [9] that on ﬁnite structures, Succ-inv FO is strictly more expressive
than FO.

Grohe and Schwentick [7] proved that these logics were Gaifman-local, giving
an upper bound to their power of expression. Other upper bounds were given by
Benedikt and Segouﬁn [1], who proved that < -inv FO, and hence Succ-inv FO,
are included in MSO on classes of bounded treewidth and on classes of bounded
degree. Elberfeld, Frickenschmidt and Grohe [3] extended the ﬁrst inclusion to
a broader setting, that of decomposable structures. Whether these logics are
included in MSO in general is still an open question.

The classes of structures involved in the separating examples by Gurevich
and Rossman are dense, and no other example is known on classes that are
sparse. Far from it, < -inv FO and a fortiori Succ-inv FO are known to collapse
to FO on several sparse classes. Benedikt and Segouﬁn [1] proved the collapse
on trees; Eickmeyer, Elberfeld and Harwarth [2] obtained an analogous result
on graphs of bounded tree-depth; Grange and Segouﬁn [6] proved the collapse
on hollow trees.

Whether < -inv FO or Succ-inv FO collapse to FO on classes of graphs of
bounded treewidth (or even bounded pathwidth) are still open questions. We
go in another direction in this paper, and prove that Succ-inv FO collapses to
FO on classes of structures of bounded degree. To do this, we show how to
construct successors on two FO-similar structures of bounded degree, such that
the two structures remain FO-similar when considering the additional successor
relation.

2

Related work: The general method used in [2] to prove that < -inv FO col-
lapses to FO when the tree-depth is bounded is the same as ours: starting from
two FO-similar structures, they show how to construct orders that maintain
the similarity. However, the techniques we use to construct our successors are
nothing like the ones used in [2], as the settings are very diﬀerent.

Instead of directly constructing similar orders on two similar structures, [1]
and [6] exhibit a chain of intermediate structures and intermediate orders that
are pairwise similar, in order to prove the collapse on trees and hollow trees.
Once again, our construction diﬀers wildly from these ones.

2 Preliminaries

The remainder in the division of n ∈ N by m > 0 is denoted n[m].

A binary relation on a ﬁnite set X is a successor relation on X if it is
the graph of a circular permutation of X, i.e. a bijective function from X to X
with a single orbit. This diﬀers from the standard notion of successor in that
there is neither minimal nor maximal element. However, this doesn’t have any
impact on our result, as discussed at the end of the present Section.

We use the standard deﬁnition of ﬁrst-order logic FO(Σ) over a signature
Σ composed of relation and constant symbols. We only consider ﬁnite Σ-
structures, which are denoted by calligraphic upper-case letters, while their
universes are denoted by the corresponding standard upper-case letters; for in-
stance, A is the universe of the structure A.

Deﬁnition 2.1 (Succ-inv FO). A sentence ϕ ∈ FO(Σ ∪ {S}), where S is a bi-
nary relation symbol, is said to be successor-invariant if for every Σ-structure
A, and every successor relations S1 and S2 on A, (A, S1) |= ϕ iﬀ (A, S2) |= ϕ.
We can then omit the interpretation for the symbol S, and if (A, S1) |= ϕ for
any (every) successor S1, we write A |= ϕ.

The set of successor-invariant sentences on Σ is denoted Succ-inv FO(Σ).

Given two Σ-structures A and B, and L being either Succ-inv FO(Σ) or
FO(Σ), we write A ≡L
k B if A and B satisfy the same L-sentences of quantiﬁer
rank at most k. For FO(Σ) as well as for Succ-inv FO(Σ), we omit Σ when it
is clear from the context.

Deﬁnition 2.2 (Gaifman graph). The Gaifman graph GA of a Σ-structure A
is deﬁned as (A, V ) where (x, y) ∈ V iﬀ x and y appear in the same tuple of
a relation of A. In particular, if a graph is seen as a relational structure on
the vocabulary {E}, its Gaifman graph is the unoriented version of itself. By
distA(x, y), we denote the distance between x and y in GA. The degree of A is
the degree of its Gaifman graph, and a class C of Σ-structures is said to be of
bounded degree if there exists some d ∈ N such that the degree of every A ∈ C
is at most d.

Deﬁnition 2.3 (Types). We now give the deﬁnition of the type of an element.
Beware that this has a diﬀerent meaning in classical model theory, where it

3

denotes the set of sentences with one free variable that are satisﬁed by this
element. Here, the type of an element describes its surroundings in the structure.

Let c be a constant symbol that doesn’t appear in Σ.
For k ∈ N and x ∈ A, the k-neighborhood N k

A(x) of x is the (Σ ∪ {c})-
structure whose Σ-restriction is the substructure of A induced by {y ∈ A :
distA(x, y) ≤ k}, and where c is interpreted as x.

The k-type τ = tpk

A(x) is the isomorphism class of its k-neighborhood. We
say that τ is a type over Σ, and that x is an occurrence of τ . |A|τ denotes the
number of occurrences of τ in A, and we write [[A]]r =t [[B]]r to mean that for
every r-type τ , |A|τ and |B|τ are either equal, or both larger than t.

Deﬁnition 2.4 (Path and cycles). A cycle of length l ≥ 2 in the Σ ∪ {S}-
structure A is a sequence (x0, . . . , xl−1) of distinct vertices of A such that for
every 0 ≤ i < l, xi and xi+1[l] appear in the same tuple of some relation of A (in
other words, it is a cycle in GA). If furthermore (xi, xi+1[l]) ∈ S for every i, then
we say that it is an S-cycle. If for some i, (xi, xi+1[l]) ∈ S or (xi+1[l], xi) ∈ S,
then we say that the cycle goes through an S-edge. A path is deﬁned similarly,
without the requirement on xl−1 and x0, and its length is l − 1 instead of l.

From now on, we assume that Σ is purely relational (i.e. contains only

relation symbols) and doesn’t contain the binary symbol S.

For a class C of Σ-structures, we say that

Succ-inv FO = FO on C

if the properties of C deﬁnable in Succ-inv FO and in FO are the same. In other
words, if for every ϕ ∈ Succ-inv FO, there exists some ¯ϕ ∈ FO such that

∀A ∈ C, A |= ϕ iﬀ A |= ¯ϕ .

The reverse inclusion, i.e. FO ⊆ Succ-inv FO, always holds and needs no
veriﬁcation.

We are now ready to state our main result:

Theorem 2.5. For every vocabulary Σ and for every class C of Σ-structures of
bounded degree,

Succ-inv FO = FO on C .

Let’s ﬁrst state a corollary of this result. Gajarsk´y, Hlinˇen´y, Obdrˇz´alek,
Lokshtanov and Ramanujan [5] characterized the graph classes which are FO-
interpretable in a class of graphs of bounded degree as the near-uniform graph
classes.

Let D be such a class of graphs, which is FO-interpretable in a class of
graphs of bounded degree C(cid:48). The construction from the aforementioned paper
exhibits a class C of graphs of bounded degree (which may be larger that the
degree of C(cid:48)) and an FO-interpretation I such that every H ∈ D is isomorphic

4

to I(G) for some G ∈ C, and such that I admits a converse which preserves FO-
similarity (although the converse is not an FO-interpretation itself); namely,
for every k ∈ N, there exists k(cid:48) ∈ N such that for every H, H(cid:48) ∈ D such that

then there exist G, G(cid:48) ∈ C such that

H ≡FO

k(cid:48) H(cid:48)

H (cid:39) I(G) ∧ H(cid:48) (cid:39) I(G(cid:48)) ∧ G ≡FO

k G(cid:48) .

Theorem 2.5 can then be lifted to near-uniform graph classes, and we get the
following corollary:

Corollary 2.6. Let D be a near-uniform class of graphs, i.e. a class of graphs
FO-interpretable in a class of graphs of bounded degree. Then

Succ-inv FO = FO on D .

The proof of Theorem 2.5 is given in Section 4, and constitutes the core of
this paper. We give here a sketch of this proof; this will motivate the deﬁnitions
given in Section 3.

Proof overview. Our goal is, given two structures G1 and G2 of degree at most
d that are FO-similar (that is, such that G1 ≡FO
n G2 for a large enough n), to
construct a successor relation S1 on G1 and S2 on G2 such that (G1, S1) and
(G2, S2) stay FO-similar. This will entail that ≡FO reﬁnes ≡Succ-inv FO when
the degree is bounded. From there, a standard ﬁnite-model-theoretic argument
(namely, that ≡FO
has ﬁnite index and that each one of its classes is FO-
n
deﬁnable) gives the inclusion Succ-inv FO ⊆ FO on classes of bounded degree.
It thus remains to construct suitable successor relations S1 and S2. First,

we separate the types occurring in G1 and G2 into two categories:

• on the one hand, the rare types, which have few occurrences in G1 and G2
(and thus, that have the same number of occurrences in both structures,
by FO-similarity)

• on the other hand, the frequent types, which have many occurrences both

in G1 and G2.

In order to make the proof of FO-similarity of (G1, S1) and (G2, S2) as simple
as possible, we want an element of G1 (and similarly for G2 and S2) and its
successor by S1 to have the same type in G1 as much as possible, and to be far
enough in G1, in order for the types occurring in (G1, S1) to be as “regular” as
possible. As long as there are at least two diﬀerent types, the ﬁrst constraint
obviously cannot be satisﬁed, but we will construct S1 as close as possible to
satisfying it.

For instance, suppose that G1 contains three frequent types τ0, τ1 and τ2,
and one rare type χ with two occurrences. At the end of the construction, S1

5

will (mostly) look like in Figure 1, where the relations of G1 have been omitted
and the arrows represent S1, which is indeed a circular successor.

Note that all the elements of type τ1 form a segment wrt. S1, as well as all
the elements of type τ2. τ0, the ﬁrst frequent type, has a special role in that it
is used to embed all the elements of rare type (here, χ). Furthermore, and this
is not apparent in the ﬁgure, two successive elements for S1 are always distant
in G1.

•

•

•

•

•

τ0

•
χ

•

•

•

χ

•

•

τ0

•

•

•
(cid:125)
•

(cid:125)
•

•

•

•

τ0

•

•

•

(cid:125)
•

(cid:125)
•

•

τ1

•

•

•

•

τ2

•

•

•

•

•

(cid:125)
•

(cid:125)
•

Figure 1: Illustration of S1 when there are three frequent types (τ0, τ1, τ3) and
one rare type (χ) in G1. The elements of rare type are surrounded by occurrences
of the ﬁrst frequent type, τ0. Junction elements are circled.

Keeping this idea in mind, S1 (and similarly, S2) is constructed iteratively,
by adding S-edges to the initial structures one at a time. For practical reasons,
we will start the construction of S1 around occurrences of rare types: for each
element x of rare type, we ﬁnd two elements of type τ0 that are far apart in G1,
and far from x. Then we add two S-edges in order for those two elements to
become the S1-predecessor and the S1-successor of x. We repeat this process for
every element of rare type (and actually, for every element that belongs to the
neighborhood of a rare element) until each one is protected by a ball of elements
of frequent type. This is possible because there are few elements of rare type,
and many elements of any frequent type; since the degree is bounded, those
elements of frequent type are spread across the structure, and can be found far
from the current construction.

Once this is done, we apply a similar construction around elements of fre-

6

quent types that will, in the end, be the S1-predecessor or S1-successor of an
element of another frequent type - that is, elements that will be at the border
of the segments (for S1) of a given frequent type. Such elements are circled in
Figure 1. We must choose only a small number of such elements (two for each
frequent type, of which there are few due to the degree boundedness hypoth-
esis), hence we can ﬁnd enough far-apart elements of frequent type to embed
them. Once again, degree boundedness is crucial.

After these two steps, S1 has been constructed around all the singular points.
It only remains to complete S1 by adding edges between the remaining elements
(all of which are occurrences of frequent types), in such a way that elements of
a same frequent type end up forming a segment for S1, and such that S1 brings
together elements that were far apart in the initial structure G1. Once again,
the high number of occurrences of each frequent type allows us to do so.

Applying the same construction to G2, we end up with two structures (G1, S1)
and (G2, S2) that cannot be distinguished by FO-formulas of small (wrt. the
initial FO-similarity index between G1 and G2) quantiﬁer rank, which concludes
the proof.

We have given a global overview of the construction process of S1; however,
there are technical diﬃculties to take care of, which are dealt with in Section 4.
For that, we need the deﬁnitions given in Section 3, which formalize the notion
of regularity of a type in (G1, S1) and (G2, S2).

Let’s now prove that our decision to consider circular successors instead of
the more traditional linear ones (with a minimal and a maximal element) bears
no consequence on this result. If we deﬁne LinSucc-inv FO in the same way as
Succ-inv FO, but where the invariant relation is a linear successor ¯S, we get:

Lemma 2.7. For every vocabulary Σ, LinSucc-inv FO and Succ-inv FO deﬁne
the same properties of Σ-structures.

Proof. Given ϕ ∈ Succ-inv FO, let’s prove that there exists a formula ψ ∈
LinSucc-inv FO such that ψ is equivalent to ϕ (i.e.
for every Σ-structure A,
A |= ϕ iﬀ A |= ψ).

Let ψ be deﬁned as ϕ in which every atom S(x, y) has been replaced with

¯S(x, y) ∨ ¬∃z( ¯S(x, z) ∨ ¯S(z, y)).

Let A be a Σ-structure and ¯S be a linear successor on A. Then (A, ¯S) |= ψ
iﬀ (A, S) |= ϕ, where S is the circular successor obtained from ¯S by adding an
edge from the maximal element to the minimal one.

This guarantees that ψ ∈ LinSucc-inv FO, and that ψ and ϕ are equivalent.

Conversly, let ψ ∈ LinSucc-inv FO and let ϕ be the formula ∃ min, Cut(ψ),
where Cut(ψ) is obtained by replacing in ψ every ¯S(x, y) with S(x, y)∧¬y = min.
Let A be a Σ-structure, let S be a circular successor on A, and let min ∈ A.
Then (A, S, min) |= Cut(ψ) iﬀ (A, ¯S) |= ψ, where ¯S is the linear successor
obtained from S by removing the edge pointing to min. Hence (A, S) |= ϕ iﬀ
there exists a linear successor ¯S obtained from S by an edge removal such that
(A, ¯S) |= ψ, that is iﬀ A |= ψ.

7

This ensures that ϕ ∈ Succ-inv FO and that ϕ and ψ are equivalent.

Note that although LinSucc-inv FO and Succ-inv FO have the same expres-
sive power, one may be more concise than the other, in terms of quantiﬁer
rank.

3 Fractal types and layering

To prove Theorem 2.5, we will start from two structures G1 and G2 that are FO-
similar, and construct successor relations S1 and S2 on their universes so that
the structures remain FO-similar when we take into account these additional
successor relations.

We want to construct S(cid:15), for (cid:15) ∈ {1, 2}, in a way that makes tpk

(G(cid:15),S(cid:15))(a) as
regular as possible for every a ∈ G(cid:15), in order to ease the proof of FO-similarity
of (G1, S1) and (G2, S2).

Ideally, the S(cid:15)-successors and S(cid:15)-predecessors of any element should have
the same k-type in G(cid:15) as this element. On top of that, there should not be any
overlap between the k-neighborhoods in G(cid:15) of elements that are brought closer
by S(cid:15) (this “independence” is captured by the layering property, introduced in
Deﬁnition 3.2).

If we now try to visualize what tpk

(G(cid:15),S(cid:15))(a) would look like in those perfect
conditions, we realize that it reminds of a fractal (although the patterns - that
is, the types - are obviously repeated only a ﬁnite number of times).
This is why we introduce in Deﬁnition 3.1 the fractal type [τ ]k.
Aside from a small number of exceptions (namely, for types that don’t occur
frequently enough, and around the transitions between frequent types), every
element of k-type τ in G(cid:15) will have the fractal type [τ ]k in (G(cid:15), S(cid:15)).

If N is a representative of a type τ , cN is called the center of N . Recall
from Deﬁnition 2.3 that c is the constant symbol added to Σ when considering
types to pinpoint the central element of a neighborhood.

Deﬁnition 3.1 (Fractal types). We deﬁne by induction on k ∈ N, for every
k-type τ over Σ, the k-types [τ ]k, [τ ]+

k over Σ ∪ {S}.

k and [τ ]−

0 = τ (meaning that S is interpreted as the

For k = 0, [τ ]0 = [τ ]+
empty relation in [τ ]0, [τ ]+

0 = [τ ]−
0 and [τ ]−

0 ).

Starting from a representative N of center a of the isomorphism class τ , we

construct N (cid:48) as follows.

For every x ∈ N at distance d ≤ k −1 from a, let M+

of respective isomorphism type [χ]+
type of x in N , and of respective center x+ and x−.

k−d−1 and [χ]−

x and M−

x be structures
k−d−1, where χ is the (k −d−1)-

N (cid:48) is deﬁned as the disjoint union of N and all the M+

x and the M−

x , for

x (cid:54)= a, together with all the edges S(x, x+) and S(x−, x).

From there, N + (resp. N −) is deﬁned as the the disjoint union of N (cid:48) and
a ) together with the edge S(a, a+) (resp. S(a−, a)). Likewise,
a (resp. M−

M+

8

N +/− is deﬁned as the disjoint union of N (cid:48), M+
edges S(a, a+) and S(a−, a). In each case, a is taken as the center.

a and M−

a together with the

Now, [τ ]k, [τ ]+
N +/−, N + and N −.

k and [τ ]−

k are deﬁned respectively as the isomorphism type of

An illustration of this deﬁnition is given in Figure 2.

a+•

τ|k−1

x+•

χ|k−d−1

a •

d

x•

τ

a−•

τ|k−1

Figure 2: Partial representation of N +/−, of type [τ ]k. Here, χ is the (k − d)-
type of the element x, at distance d from a in τ . The dashed arrows represent
S-edges.

Deﬁnition 3.2 (Layering). We say that an r-neighborhood N over Σ ∪ {S, c}
is layered if it doesn’t contain any cycle going through an S-edge. Every [τ ]r
is obviously layered by construction.

We say that a structure over Σ ∪ {S} satisﬁes the property (Layer[r]) iﬀ

all the r-neighborhoods of this structure are layered.

It turns out (Layer[r]) can be reformulated in a way that doesn’t involve

the r-neighborhoods of the structure:

Lemma 3.3. A structure G over Σ ∪ {S} satisﬁes (Layer[r]) if and only if it
contains no cycle of length at most 2r + 1 going through an S-edge.

Proof. If G contains a cycle of length at most 2r + 1 going through an S-edge,
then the r-neighborhood of any vertex of this cycle contains the whole cycle,
thus (Layer[r]) doesn’t hold in G.

Conversly, suppose that there exists x ∈ G such that N r

G (x) contains a cycle

going through an S-edge, and let S(y, z) be such an edge.

v ∈ N r

For any u ∈ N r

G (x), we deﬁne the cone Cu at u as the set of elements
G (x) goes through u.
There are two cases, depending on the relative position of y, z and their

G (x) such that every shortest path from x to v in N r

cones:

• If z /∈ Cy and y /∈ Cz, let py→x (resp. px→z) be a path of minimal length
from y to x, not going through z (resp. from x to z, not going through y).

Let X be the set of nodes appearing both in py→x and px→z. X is not
empty, as x ∈ X, and y, z /∈ X. Let v ∈ X such that distG(x, v) is maximal

9

among the nodes of X, and let py→v (resp. pv→z) be the segment of py→x
(resp. of px→z) from y to v (resp. from v to z).
Then pv→z · (z, y) · py→v is a cycle going through an S-edge, and is of
length ≤ 2r + 1. This is illustrated in Figure 3.

Cy

y •

Cz

z•

S

v•

•
x

Figure 3: Existence of a short cycle joining y, z and v

• Otherwise, suppose without loss of generality that z ∈ Cy. This entails

that y /∈ Cz and distG(x, z) = d + 1 where d := distG(x, y).
Let the initial cycle be (z, v1, · · · , vm−1, y), with the notation v0 = z and
vm = y.
Let i be the minimal integer such that vi /∈ Cz. Let px→vi be a shortest
path from x to vi: by deﬁnition, it doesn’t intersect Cz, and has length
at most r. Thus, there exists a path py→vi = py→x · px→vi from y to vi of
length at most r + d going only through nodes outside of Cz.
Since vi−1 ∈ Cz, there exists a path pvi−1→z from vi−1 to z of length at
most r − (d + 1) going only through nodes of Cz.
Hence py→vi · (vi, vi−1) · pvi−1→z · (z, y) is a cycle going though an S-edge,
and its length is at most 2r + 1. This is depicted in Figure 4.

vi−1 •

vi•

Cz

z •

S

•
y

Figure 4: Existence of a short cycle joining y, z, vi−1 and vi

10

This characterization of (Layer[r]) allows us to state the following lemma,
It gives a method to add an S-edge without

which is now straightforward.
breaking the property (Layer[r]).

Lemma 3.4. Let r ∈ N, and (G, S) be a structure satisfying (Layer[r]).

If x, y ∈ G are such that dist(G,S)(x, y) > 2r + 1, then (Layer[r]) holds in

(G, S ∪ {(x, y)})

4 Proof of Theorem 2.5

We are now ready to prove Theorem 2.5. Recall the sketch of proof from Sec-
tion 2. We proceed in several steps:

Section 4.1 details the general framework of the proof. In Section 4.2, we

divide the types into rare ones and frequent ones.

We then begin the construction of S1: Section 4.3 is dedicated to the con-
struction of S1 around the occurrences in G1 of rare types. Then, in Section 4.4,
we keep constructing S1 around the occurrences (two for each type) of frequent
types that are designed to make, when the construction is complete, the S1-
junction between two frequent types.

At this point, S1 will be fully built around the singular points of G1. Sec-
tion 4.5 deals with the transfer of this partial successor relation S1 over to G2:
this will result in a partial S2, built in a similar way around the singular points
of G2.

In Section 4.6, S1 and S2 are completed independently, to cover G1 and
G2. These expansions do not need to be coordinated, since at this point, the
elements that are not already covered by S1 and S2 are occurrences of frequent
types and their resulting types will be regular (i.e. fractal) both in (G1, S1) and
(G2, S2).

We then give some simple examples in Section 4.7, before establishing prop-

erties of S1 and S2 in Section 4.8, and concluding the proof in Section 4.9.

4.1 General method

Let C be a class of Σ-structures of degree at most d. We show the following:
for every α ∈ N, there exists some f (α) ∈ N such that, given G1, G2 ∈ C,
f (α) G2 then G1 ≡Succ-inv FO
if G1 ≡FO
G2. For that, we will exhibit successor
relations S1 and S2 such that (G1, S1) ≡FO

α (G2, S2).

α

More precisely, using the notations from Deﬁnition 2.3, we will show that
[[(G1, S1)]]r =t [[(G2, S2)]]r where r and t depend on α and are large enough to
ensure that (G1, S1) ≡FO
α (G2, S2). The existence of such r and t follows from
the well-known Hanf threshold theorem, whose ﬁnite version is given in [4].

We will construct S1 and S2 iteratively in a way that ensures, at each step,
that the property (Layer[r]) holds in (G1, S1) and in (G2, S2). (Layer[r]) is
obviously satisﬁed in (G1, ∅). Each time we add an S1-edge or an S2-edge, we

11

will make sure that we are in the right conditions to call upon Lemma 3.4, so
that (Layer[r]) is preserved.

Deﬁnition 4.1. Note that the size of any r-neighborhood of degree at most d
is bounded by a function N of d and r; namely by N (d, r) := d · (d−1)r−1
d−2 + 1 if
d (cid:54)= 2, and by N (2, r) := 2r + 1 if d = 2.

4.2 Separation between rare and frequent types

Knowing the values of r and t as deﬁned in Section 4.1, we are now able to divide
the r-types into two categories: the rare types and the frequent types. The
intent is that the two structures have the same number of occurrences of every
rare type, and that frequent types have many occurrences (wrt. the total number
of occurrences of rare types) in both structures. This “many occurrences wrt.”
is formalized through a function g which is to be speciﬁed later on.

More precisely,

Lemma 4.2. Given d, r ∈ N and an increasing function g : N → N, there exists
p ∈ N such that for every Σ-structures G1, G2 ∈ Cd satisfying G1 ≡FO
p G2, we can
divide the r-types over Σ of degree at most d into rare types and frequent types,
such that

• every rare type has the same number of occurrences in G1 and in G2

• both in G1 and in G2, every frequent type has at least g(β) occurrences,
where β is the number of occurrences of all the rare types in the structure

• if there is no frequent type, then G1 and G2 are isomorphic.

Proof. Let χ1, · · · , χn be an enumeration of all the r-types over Σ of degree at
most d, ordered in such a way that ∀i < j, |G1|χi ≤ |G1|χj . Note that n is a
function of d and r.

The classiﬁcation of types between rare ones and frequent ones is done

through Algorithm 1.

Algorithm 1 Separation between rare and frequent types
1: β ← 0
2: i ← 1
3: while i ≤ n and |G1|χi < g(β) do
4:
5:
6: end while

β ← β + |G1|χi
i++

(cid:46) If i ≤ n, χi is the frequent type with the least

occurrences in G1.
If i = n + 1, all the types are rare.

At the end of Algorithm 1, we call χ1, · · · , χi−1 the rare types, and χi, · · · , χn

the frequent ones.

12

Note that β indeed counts the total number of occurrences of rare types in

G1.

We now deﬁne the integers (ai)1≤i≤n as a1 := g(0) and

ai+1 := max{ai, g(iai)} .

As g is monotone, it is easy to show by induction that for each rare type χj
with j < i, |G1|χj < aj.

As long as p is chosen large enough so that G1 ≡FO

p G2 entails [[G1]]r =an [[G2]]r,
we have by construction that every rare type has the same number of occurrences
(which is smaller that an) in G1 and in G2. Furthermore, in G1 as in G2, if β
denotes the total number of occurrences of rare types, every frequent type has
at least g(β) occurrences.

We just need to make sure that the two structures are isomorphic when all
the types are rare. If this is the case, then |G1| = |G2| ≤ n(an − 1). Hence,
as long as p ≥ n(an − 1), G1 ≡FO
p G2 implies G1 (cid:39) G2 when all the types are
rare.

Let τ0, · · · , τm−1 be the frequent types. From now on, we suppose that
m ≥ 1: there is nothing to do if m = 0, since G1 and G2 are isomorphic. Let β
be the total number of occurrences of rare types in G1.

4.3 Construction of S1 around elements of rare type

To begin with, let’s focus on G1, and start the construction of S1 around occur-
rences of rare types. Algorithm 2 deals with this construction.

For a given occurrence x of some rare type, we choose as its S1-successor
and S1-predecessor two occurrences of type τ0 (the ﬁrst frequent type), far
apart from one another and from x. The existence of those elements relies on
the bounded degree hypothesis. This is done on lines 8 and 11.

When line 14 is reached, every occurrence of rare type has an S1-predecessor

and an S1-successor of type τ0.

It is not enough, however, only to deal with the occurrences of rare types.
We need to “protect” them up to distance r in (G1, S1). For that purpose, we
construct the subsets Rk of G1, for 0 ≤ k ≤ r. In the following, R≤k denotes

(cid:83)
0≤j≤k

Rj.

For each k, the subset Rk is constructed in order to be the set of elements
at distance exactly k in (G1, S1) from the set of occurrences of rare types. Until
we have reached k = r (that is, distance r from occurrences of rare types),
every element of Rk is given an S1-successor (line 21) and/or an S1-predecessor
(line 26) of its type, if it doesn’t already have one. Once again, those elements
are required to be far (i.e. at distance greater than 2r + 1) from what already
has been constructed.

Provided that g is large enough, it is always possible to ﬁnd x+ and x− on
lines 8, 11, 21 and 26. Indeed, all the types considered are frequent ones, and
the size of the (2r + 1)-neighborhood of R≤k+1 is bounded by a function of d,

13

r and β (the total number of occurrences of rare types in G1). More precisely,
at any point of the construction, (G1, S1) has degree at most d + 2. Hence, the
(2r + 1)-neighborhood of Rr has size at most

βN (d + 2, 3r + 1)

(recall the deﬁnition of N from Deﬁnition 4.1), and it is enough to make sure
that

g(β) ≥ βN (d + 2, 3r + 1) + 1 .

4.4 Construction of S1 around the junctions between two

frequent types

Recall that there is a second kind of singular elements: those which will be at
the junction between two successive frequent types. That is, elements of type
τi that will, in the ﬁnal structure (G1, S1), have an S1-successor of type τi+1[m],
or an S1-predecessor of type τi−1[m].

Those junction elements need to be treated in a similar way as the oc-
currences of rare types in Section 4.3. This construction is done throughout
Algorithm 3.

The idea of Algorithm 3 is very similar to that of Algorithm 2. We start
for every frequent type τi (for loop line 2),

i and x−
by picking two elements x+
that are far from each other and from the previous construction.

i

Then we build m S1-edges between those elements on line 9: these edges are
intended to be at the junction between the frequent types in the ﬁnal structure.
The set P0 of those 2m elements will have the same role as the set R0 of
occurrences of rare types for Algorithm 2: we build S1-edges at depth r around
it. This is done through the subsets Pk of G1, for 0 ≤ k ≤ r, Pk being the set of
elements at distance k from P0 in (G1, S1). Once again, P≤k denotes (cid:83)
Pj.

0≤j≤k

For the same reason as for Algorithm 2, it is always possible to ﬁnd elements

x+ and x− on lines 17 and 22.

Note that if m = 1, there is obviously no transition elements: we simply
0 and x−
0 .

construct an S1-edge between x+

4.5 Carrying S1 over to G2

In Sections 4.3 and 4.4, S1 has been constructed around the singular points of
G1, i.e. occurrences of rare types and elements that are to make the junction
between two S1-segments of frequent types.

Before we extend S1 to the remaining elements (all of them being occurrences
of frequent types) of G1, we carry it over to G2. This transfer is possible under
the starting hypothesis that G1 and G2 are FO-similar.

Let

(cid:40)

A1 := R≤r ∪ P≤r
B := {x ∈ G1 : dist(G1,S1)(x, A1) ≤ r}

14

(x) is rare}

Algorithm 2 Construction of S1 around elements of rare type
1: S1 ← ∅
2: R0 ← {x ∈ G1 : tpr
G1
3: R1, · · · , Rr ← ∅
4: for all x ∈ R0 do
5:
6:
7:
8:

for all neighbor y /∈ R≤1 of x in G1 do

end for
ﬁnd x+ such that

R1 ← R1 ∪ {y}

(x+) = τ0 and

tpr
G1
dist(G1,S1)(x+, R≤1) > 2r + 1

9:
10:
11:

R1 ← R1 ∪ {x+}
S1 ← S1 ∪ {(x, x+)}
ﬁnd x− such that

(cid:46) We pick a node at distance greater than
2r + 1 in compliance with Lemma 3.4, so
that neighborhoods stay layered.
Recall that τ0 is the ﬁrst frequent type.

(x−) = τ0 and

tpr
G1
dist(G1,S1)(x−, R≤1) > 2r + 1

R1 ← R1 ∪ {x−}
S1 ← S1 ∪ {(x−, x)}

12:
13:
14: end for

(cid:46) At this point, every element of rare
type has an S1-predecessor and an S1-
successor of type τ0

(cid:46) tpk
G1

(x) is a frequent type

for all neighbor y /∈ R≤k+1 of x in G1 do

for all x ∈ Rk do

15: for k from 1 to r − 1 do
16:
17:
18:
19:
20:
21:

ﬁnd x+ such that

Rk+1 ← Rk+1 ∪ {y}

end for
if x doesn’t have a successor by S1 then

tpr
(x+) = tpr
G1
G1
dist(G1,S1)(x+, R≤k+1) > 2r + 1

(x) and

Rk+1 ← Rk+1 ∪ {x+}
S1 ← S1 ∪ {(x, x+)}

end if
if x doesn’t have a predecessor by S1 then

ﬁnd x− such that

22:
23:
24:
25:
26:

tpr
(x−) = tpr
G1
G1
dist(G1,S1)(x−, R≤k+1) > 2r + 1

(x) and

Rk+1 ← Rk+1 ∪ {x−}
S1 ← S1 ∪ {(x−, x)}

27:
28:
29:
30:
31: end for

end if

end for

15

Algorithm 3 Construction of S1 around the junctions between two frequent
types
1: P0, · · · , Pr ← ∅
2: for i from 0 to m − 1 do
3:

i , R≤r ∪ P0) > 2r + 1

i , R≤r ∪ P0) > 2r + 1

i ) = τi and

ﬁnd x+
i such that
(x+
tpr
G1
dist(G1,S1)(x+

P0 ← P0 ∪ {x+
i }
ﬁnd x−
i such that
(x−
tpr
G1
dist(G1,S1)(x−

i ) = τi and

4:
5:

i+1[m])}

i , x+

P0 ← P0 ∪ {x−
i }

6:
7: end for
8: for i from 0 to m − 1 do
S1 ← S1 ∪ {(x−
9:
10: end for
11: for k from 0 to r − 1 do
12:
13:
14:
15:
16:
17:

for all x ∈ Pk do

ﬁnd x+ such that

Pk+1 ← Pk+1 ∪ {y}

for all neighbor y /∈ P≤k+1 of x in G1 do

end for
if x doesn’t have a successor by S1 then

(x+) = tpr
G1

tpr
(x) and
G1
dist(G1,S1)(x+, R≤r ∪ P≤k+1) > 2r + 1

Pk+1 ← Pk+1 ∪ {x+}
S1 ← S1 ∪ {(x, x+)}

end if
if x doesn’t have a predecessor by S1 then

ﬁnd x− such that

18:
19:
20:
21:
22:

(x−) = tpr
G1

tpr
(x) and
G1
dist(G1,S1)(x−, R≤r ∪ P≤k+1) > 2r + 1

Pk+1 ← Pk+1 ∪ {x−}
S1 ← S1 ∪ {(x−, x)}

23:
24:
25:
26:
27: end for

end if

end for

If we let td

r be the number of r-types of degree at most d over Σ, we must

have that m ≤ n thus |A1| can be bounded by

(β + 2td

r)N (d + 2, r) .

Similarly, the size of B can be bounded by

(β + 2td

r)N (d + 2, 2r) ,

which is a function of β, r and d. Hence as long as f (α) is larger than that
number, the Duplicator has a winning strategy in the Ehrenfeucht-Fra¨ıss´e game

16

between G1 and G2 in which the Spoiler chooses every element of B. Let h :
B → G2 be the function resulting from such a strategy.

h deﬁnes an isomorphism from G1|B to G2|Im(h). Let A2 := h(A1). By
taking f (α) one higher than required, to make sure that Im(h) covers the r-
neighborhood in G2 of every element of A2, we have that for every x ∈ A1,
tpr
G2

(h(x)) = tpr
G1
We set S2 := {(h(x), h(y)) : (x, y) ∈ S1}. h now deﬁnes an isomorphism from
(G1,S1)(x).

(G1, S1)|B to (G2, S2)|Im(h), and for every x ∈ A1, tpr

(G2,S2)(h(x)) = tpr

(x).

4.6 Completion of S1 and S2

Now that S1 and S2 are constructed around all the singular points both in G1
and G2, it remains to extend their construction to all the other elements of the
structures. Recall that all the remaining elements are occurrences of frequent
types.

From (G(cid:15), S(cid:15)) ((cid:15) ∈ {1, 2}) at any point in the construction, let’s deﬁne the
partial function S∗
: G(cid:15) → G(cid:15) that maps x ∈ G(cid:15) to the (unique) y that
(cid:15)
is S(cid:15)-reachable (while taking the orientation into account) from x and that
doesn’t have an S(cid:15)-successor. This function is deﬁned on every element that
doesn’t belong to an S(cid:15)-cycle (and in particular, on every element without an
S(cid:15)-predecessor).

Likewise, we deﬁne S−∗
At this point, for every x /∈ A1, S∗

by reversing the arrows of S(cid:15).
1 (x) = S−∗

(cid:15)

1 (x) = x, and for every x /∈ A2,

2 (x) = S−∗
S∗

2 (x) = x.

We now run Algorithm 4. We ﬁrst treat G1, and then apply a similar method
to G2, replacing x+
i ) and h(x−
i ). The idea is, for every frequent
type τi, to insert all its remaining occurrences between (in the sense of S1) x+
i
and x−
i .

i by h(x+

i and x−

The ﬁrst approach (the loop at line 2) is greedy: while constructing S(cid:15) on
nodes of type τi, we choose as the successor of the current node any occurrence
of τi that is at distance greater than 2r + 1 from the current node s and the
closing node of type τi, S−∗
i ). This, together with Lemma 3.4, ensures that
(Layer[r]) holds after every addition. The conditions line 11 also ensure that
the ﬁnal edge addition, line 15, doesn’t break (Layer[r]).

(x−

(cid:15)

Once we cannot apply this greedy approach anymore, we know that only a
small number (which can be bounded by 2N (d + 2, 2r + 1)) of nodes of type
τi remain without S1-predecessor. The loop at line 17 considers one such node
x at a time. As long as g is large enough, we have constructed S1 around
enough elements of type τi in the greedy approach to ensure the existence of
some S1(y, z), with y, z of type τi and at distance greater than 2r + 1 from x; x
is inserted between y and z (line 20). For that, it is enough to have constructed
at least

2N (d + 2, 2r + 1) + 1

17

S1-edges in the greedy phase. This is the case in particular when there are at
least

4N (d + 2, 2r + 1) + 1

elements of type τi without S1-predecessor at the beginning of Algorithm 4,
which can be ensured by having

g(β) ≥ |A1| + 4N (d + 2, 2r + 1) + 1 .

This holds in particular when

g(β) ≥ (β + 2td

r)N (d + 2, r) + 4N (d + 2, 2r + 1) + 1 .

We will prove in Lemma 4.6 that all these insertions preserve (Layer[r]).

for i from 0 to m − 1 do

if (cid:15) = 1 then
1 (x+
s ← S∗
i )
1 (x−
t ← S−∗
i )

Algorithm 4 Completion of S(cid:15)
1: for (cid:15) from 1 to 2 do
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:

2 (h(x+
i ))
2 (h(x−
i ))

end if
while such an x exists do

s ← S∗
t ← S−∗

else

ﬁnd x with no S(cid:15)-predecessor, such that tpr

G(cid:15) (x) = τi,

dist(G(cid:15),S(cid:15))(s, x) > 2r + 1,
dist(G(cid:15),S(cid:15))(x, t) > 2r + 1 and
dist(G(cid:15),S(cid:15))(S∗
(cid:15) (x), t) > 2r + 1
S(cid:15) ← S(cid:15) ∪ {(s, x)}
s ← S∗
(cid:15) (x)
end while

(cid:46) At this point, only a bounded number of
elements of type τi are left without an
S(cid:15)-predecessor

S(cid:15) ← S(cid:15) ∪ {(s, t)}

end for
for i from 0 to m − 1 do

for all x without S(cid:15)-predecessor, s.t. tpr

G(cid:15) (x) = τi do

12:
13:
14:

15:
16:
17:
18:
19:

ﬁnd y, z /∈ A(cid:15) such that
G(cid:15) (y) = tpr

G(cid:15) (z) = τi,

tpr
(y, z) ∈ S(cid:15),
dist(G(cid:15),S(cid:15))(y, x) > 2r + 1 and
dist(G(cid:15),S(cid:15))(S∗
(cid:15) (x), z) > 2r + 1

S(cid:15) ← S(cid:15) \ {(y, z)} ∪ {(y, x), (S∗

(cid:15) (x), z)}

20:
21:
22:
23: end for

end for

end for

18

4.7 Examples of construction

Before we give the proof of correctness of these algorithms, let us see how they
apply in some simple cases

Example 4.3. Suppose that there are no occurrences of rare types, and only
one frequent type τ0, and assume r = 2.

In this case, Algorithm 2 is irrelevant, and all Algorithm 3 does is pick x−
0
and x+
0 far from each other, and start building S1 around those nodes in order
to construct their complete r-neighborhood in (G1, S1). In order to make the
ﬁgure more readable, let us consider that x−
1 have only one neighbor. In
Figure 5, the plain lines represent edges in G1, and the dashed arrows represent
S1.

0 and x+

•

•

•

•
x−
0

•

•

•

•

•

•

•
x+
0

•

Figure 5: After Algorithm 3, with one frequent type

We now apply Algorithm 4. The ﬁrst step is to add elements between (in the
sense of S1) S∗
0 ) in order to join them, in a greedy fashion.
Once this is done, there only remain a few elements that haven’t been assigned
an S1-predecessor. This is depicted in Figure 6.

0 ) and S−∗

1 (x−

1 (x+

x

•

•

•

•

•

•

•

•

•

S∗

1 (x)
•
x−
0

•
x+
0

•

•

•

•

•

•

•

•

•

Figure 6: After the greedy part of Algorithm 4, with one frequent type

Now we consider one by one each of the elements that don’t have an S1-
predecessor: let’s start with x in Figure 6. Our goal is to insert it in the S1-cycle
while still respecting (Layer[r]). For that, we ﬁnd two successive elements y, z
of the cycle that are far from x and S∗
1 (x), and we insert x between them, as
shown in Figure 7.

We treat all the elements without an S1-predecessor in the same way, until

S1 is fully built.

19

x

•

•

•
z

•

•

y

•

•

•

•

S∗

1 (x)
•
x−
0

•
x+
0

•

•

•

•

•

•

•

•

•

Figure 7: Inserting x in the S1-cycle, as in the second part of Algorithm 4, with
one frequent type

Example 4.4. Suppose now that there are two frequent types τ0 and τ1, and
still no occurrences of rare types.

The procedure is very similar: in Algorithm 3, we build the r-neighborhood

in (G1, S1) of the four nodes x−

0 , x+

0 , x−

1 and x+
1 .

After the greedy part of Algorithm 4, S1 looks like in Figure 8, where occur-
rences of τ0 are represented as • and occurrences of τ1 as ◦. The remaining of
Algorithm 4 is as unchanged.

x

•

•

•

•

•

•

•

•

•

S∗

1 (x)
•
x−
0

•

x+
0
•

◦

◦

◦

◦

◦

◦

◦
x+
1

x−
1
◦

Figure 8: After the greedy part of Algorithm 4, with two frequent types

Note that if there existed some occurrences of rare types, they would be em-

bedded in the τ0 part of the S1-cycle.

4.8 Properties of S1 and S2

We are now ready to show that, after the successive run of Algorithms 2, 3 and
4:

• S1 and S2 are indeed successor relations (Lemma 4.5)

• (G1, S1) and (G2, S2) satisfy (Layer[r]) (Lemma 4.6)

• A singular element (around a rare or a junction element) of (G1, S1) and its
corresponding element via h in (G2, S2) have the same r-type (Lemma 4.9),
while any other element in both structures has a regular (i.e. fractal) r-
type (Lemma 4.8)

20

These properties will allow us to prove in Section 4.9 that (G1, S1) and
(G2, S2) have the same number of occurrences of every r-type, up to a threshold
t.

Lemma 4.5. S1 (resp. S2) is a successor relation on G1 (resp. G2).

Proof. This result is rather transparent, but a rigorous proof requires the usage
of a somewhat cumbersome invariant.

Let us focus on G1: the proof is the same for G2, replacing every x+

i and x−

i

with h(x+

i ) and h(x−

i ).

Let a ∈ G1 be deﬁned as S−∗

1 (x−

m−1) at the beginning of Algorithm 4. By

construction, tpr

G(a) = τm−1 and a has no S1-predecessor as of now.
We show that at any point before line 15 of the loop iteration i = m − 1 of

Algorithm 4,

(i). S−∗

(ii). S−∗

1 (s) = a
1 (x−

m−1) = a

(iii). let y, z /∈ A1 such that (y, z) ∈ S1 and

tpr
G1

(y) = tpr
G1

(z) = τj

for some j; then S−∗

1 (y) = a

(iv). for every i, (x−

i , x+

i+1[m]) ∈ S1

(v). there is no S1-cycle

(vi). for every j > i, tpr
G1

(S−∗

1 (x−

j )) = τj

This is obviously satisﬁed at the beginning of Algorithm 4: there are not
1 (x+
m−1 (since

0 ) is S1-reachable from x−

yet such y, z as in (iii), and s = S∗
(x−

0 ) ∈ S1) hence (i) holds.

m+1, x+
Line 4 preserves the invariant. Indeed, the new value of s is S1-reachable
from its previous value (this is guaranteed by (iv)), which means that they have
the same image through S−∗

1 , namely a.

Let’s prove that line 12 preserves the invariant. (i) and (ii) still hold since
x (cid:54)= a:
indeed, for i < m − 1, x and a don’t share the same type, while for
i = m − 1, a = t (because of (ii)) and the distance condition prohibits x = a.
(iii) still holds, as the only new possibility for such a couple (y, z) is (s, x), which
is such that S−∗
1 (y) = a (because of (i)). (iv) obviously holds, as does (v), since
the only way for an S1-cycle to have been created is if x = S−∗
1 (s), that is
x = a. We have seen that this is absurd. (vi) is satisﬁed, as the only way for it
to fail is for x to be some S−∗
j ), for j > i, which is impossible due to type
requirements.

1 (x−

Now, let’s move to line 13. Only (i) needs veriﬁcation, and the argument is

the same as for line 4.

21

Finally, let’s look at line 15, for i < m − 1.

t (cid:54)= a since their types are
(iii) still holds, as the only new
diﬀerent, hence (i), (ii) and (v) still hold.
possibility for such a couple (y, z) is (s, t), which is such that S−∗
1 (y) = a
because of (i) (actually, (s, t) doesn’t even ﬁt the condition, since t ∈ A1). (iv)
is still satisﬁed. (vi) holds, as the only way for it to fail is for t to be some
S−∗
1 (x−

j ), for j > i, which is impossible due to type requirements.

We now prove that from line 17 until the end of Algorithm 4, there is exactly
(y) =

one S1-cycle, which contains every y, z /∈ A1 such that (y, z) ∈ S1 and tpr
G1
tpr
G1

(z) = τj for some j.
This is true after line 15 of the loop iteration m − 1, which creates the ﬁrst
1 (s). (iii) guarantees that this newly

S1-cycle, as (i) and (ii) ensure t = a = S−∗
created S1-cycle contains all the couple (y, z) satisfying the condition.

It remains to show that line 20 preserves this property: by hypothesis, y
and z belong to the S1-cycle. After line 20, there is still exactly one S1-cycle,
which corresponds to the previous one where the S1-edge has been replaced by
the S1-segment [x, S∗
1 (x)]. The only S1-edges that have been added belong to
the S1-cycle, hence the second part of the property still holds.

In the end, every element of G1 has a predecessor by S1, hence S1 is a

permutation of G1. We’ve shown that it has a single orbit.

Lemma 4.6. (Layer[r]) holds in (G(cid:15), S(cid:15)), for (cid:15) ∈ {1, 2}

Proof. This property is guaranteed by the distance conditions of the form

dist(G(cid:15),S(cid:15))(., .) > 2r + 1

imposed throughout Algorithms 2, 3 and 4, and by Lemma 3.4.

One can very easily verify that (Layer[r]) is guaranteed by Lemma 3.4 to

hold in (G(cid:15), S(cid:15)) prior to the run of Algorithm 4.

We focus on Algorithm 4, and we use Lemma 3.4 to prove that (Layer[r])
remains valid in (G(cid:15), S(cid:15)) throughout its run. There are three edge additions we
have to prove correct:

• For the edge addition of line 12, this follows directly from Lemma 3.4.

• For the edge addition of line 15, we show that the invariant

dist(G(cid:15),S(cid:15))(s, t) > 2r + 1

is satisﬁed at the beginning and at the end of the while line 10. This
invariant, together with Lemma 3.4, will be enough to conclude.

The invariant holds before the ﬁrst execution of the while loop (except for
m = 1, where it only bootstraps after two executions of the loop).

Working towards a contradiction, suppose that the invariant is broken
during an execution of the loop. We use the pre notations. There must
exists a path from S∗
(cid:15) (x) (which is to become the new value of s at the

22

end of the loop) to t in (G(cid:15), S(cid:15) ∪ {(s, x)}) of length at most 2r + 1; consider
a shortest one. As is cannot be valid in (G(cid:15), S(cid:15)) by choice of x, it must go
through the newly added edge (s, x). This means that in (G(cid:15), S(cid:15)), either
there exist paths of length at most 2r + 1 from S∗
(cid:15) (x) to s and from x
to t, or paths of length at most 2r + 1 from S∗
(cid:15) (x) to x and from s to t.
The former is absurd considering the way x was chosen, and the latter
contradicts the previous invariant.

• Let’s prove that the addition of the two S(cid:15)-edges of line 20 doesn’t break
(Layer[r]). By choice of y, we know that dist(G(cid:15),S(cid:15))(y, x) > 2r + 1.
A fortiori, we must have dist(G(cid:15),S(cid:15)\{(y,z)})(y, x) > 2r + 1, and Lemma 3.4
ensures that (G(cid:15), S(cid:15) \ {(y, z)} ∪ {(y, x)}) satisﬁes the property (Layer[r]).
Now, to the second addition: let’s prove that, at the beginning of line 20,

dist(G(cid:15),S(cid:15)\{(y,z)}∪{(y,x)})(S∗

(cid:15) (x), z) > 2r + 1 .

We then conclude with Lemma 3.4.
Suppose it’s not the case and consider a shortest path from S∗
(cid:15) (x) to z,
which must be of length at most 2r + 1. This path cannot be valid in
(G(cid:15), S(cid:15)), thus it has to go through the new edge (y, x). Since there cannot
exist a path of length at most 2r from S∗
(cid:15) (x) to y in (G(cid:15), S(cid:15)) (as this would
contradict dist(G(cid:15),S(cid:15))(S∗
(cid:15) (x), z) > 2r + 1), it has to borrow the edge from
x to y.

Then in (G(cid:15), S(cid:15) \ {(y, z)}), there is a path of length at most 2r from y to
z, which contradicts (Layer[r]) in (G(cid:15), S(cid:15)).

The following Lemma states that the only time S(cid:15) joins two nodes that have
diﬀerent r-types in G(cid:15) is when one of them is an occurrence of a rare type (in
which case its S(cid:15)-predecessor and S(cid:15)-successor are of type τ0) or when they are
the elements which make the transition between two frequent types (that is, one
is x−

i and the other is x+

i+1[m], for some i < m):

Lemma 4.7. ∀x, y ∈ G1 such that (x, y) ∈ S1 and (x /∈ R0 and y /∈ R0) and
(x /∈ P0 or y /∈ P0), then tpr
G1

(y)
∀x, y ∈ G2 such that (x, y) ∈ S2 and (x /∈ h(R0) and y /∈ h(R0)) and
(x) = tpr
G2

(x /∈ h(P0) or y /∈ h(P0)), then tpr
G2

(x) = tpr
G1

(y)

Proof. The property clearly holds at the end of Algorithm 2 and Algorithm 3.
For any i from 0 to m − 1, the only S1-edges (resp. S2-edges) that are added

during the i-th loop are between two nodes of type τi.

Recall the discussion at the beginning of Section 3. We now prove that,
as long as an element is far from any occurrence of a rare type and from the
elements that make the transition between two frequent types, its type in (G(cid:15), S(cid:15))
is the fractal of its type in G(cid:15):

23

Lemma 4.8. For (cid:15) ∈ {1, 2} and for every 0 ≤ k ≤ r and x /∈ R≤k ∪ P≤k (if
(cid:15) = 1) or x /∈ h(R≤k ∪ P≤k) (if (cid:15) = 2),

tpk

(G(cid:15),S(cid:15))(x) = [tpk
G(cid:15)

(x)]k .

Proof. We prove the result by induction on k. For k = 0, there is nothing to do
but note that no edge S(cid:15)(x, x) has been created.

Suppose that we’ve proven the result for some k < r, and let x /∈ R≤k+1 ∪

P≤k+1, or x /∈ h(R≤k+1 ∪ P≤k+1).

Let y be such that distG(cid:15) (x, y) = d, for some 1 ≤ d ≤ k + 1. By construc-
tion of the Ri and Pi, and of h, we have that y /∈ R≤k+1−d ∪ P≤k+1−d, or
y /∈ h(R≤k+1−d ∪ P≤k+1−d) (this is easily shown by induction on d). Hence,
tpk+1−d

(G(cid:15),S(cid:15))(y) = [tpk+1−d
Because Lemma 4.6 ensures that the (k + 1)-neighborhood of x in (G(cid:15), S(cid:15)) is
layered, it only remains to show that the S(cid:15)-successor x+ and predecessor x− of
x are such that tpk
(x)]k. Let’s show this for
x+.

(G(cid:15),S(cid:15))(x−) = [tpk
G(cid:15)

(G(cid:15),S(cid:15))(x+) = tpk

(y)]k+1−d.

G(cid:15)

Lemma 4.7 ensures tpr
G(cid:15)

(x+) = tpr
(x). It only remains to note that x+ /∈
G(cid:15)
R≤k ∪ P≤k, or x+ /∈ h(R≤k ∪ P≤k), and the induction hypothesis allows us to
conclude.

When we ﬁrst deﬁned h, it preserved r-types by construction. The last step
before we are able to conclude the proof of Theorem 2.5 is to make sure that
h still preserves r-types, taking into account the S(cid:15)-edges added during the run
of Algorithm 4:

Lemma 4.9. ∀x ∈ A1, tpr

(G2,S2)(h(x)) = tpr

(G1,S1)(x)

Proof. We prove by induction on 0 ≤ k ≤ r that ∀x ∈ A1, tpk
tpk

(G1,S1)(x)
There is nothing to prove for k = 0.
Moving from k to k + 1, let x ∈ A1 and let y be such that distG1 (x, y) = d,

(G2,S2)(h(x)) =

for some 1 ≤ d ≤ k + 1. Note that y ∈ B, hence it has an image by h.
If y ∈ A1, the induction hypothesis allows us to conclude that

tpk+1−d

(G2,S2)(h(y)) = tpk+1−d

(G1,S1)(y) .

Else, Lemma 4.8 ensures that:

tpr

(G2,S2)(h(y)) = [tpr
G2

(h(y))]r = [tpr
G1

(y)]r = tpr

(G1,S1)(y) .

In both cases, tpk+1−d

(G2,S2)(h(y)) = tpk+1−d

(G1,S1)(y).

Because of (Layer[r]), it only remains to show that the S(cid:15)-successors of
x and h(x), as well as their S(cid:15)-predecessors, have the same k-type in (G(cid:15), S(cid:15)).
Let’s prove this for the successors, respectively named x+ and h(x)+.

If x+ ∈ A1, then by construction h(x)+ = h(x+), and the induction hypoth-

esis allows us to conclude.

24

Otherwise, neither x+ nor h(x)+ belongs to A1. Under this hypothesis,

Lemma 4.7 ensures that

tpr
G2

(h(x)+) = tpr
G2

(h(x)) = tpr
G1

(x) = tpr
G1

(x+) .

Now, Lemma 4.8 ensures that

tpr

(G2,S2)(h(x)+) = [tpr
(h(x)+)]r
G2
= [tpr
(x+)]r
G1
= tpr
(G1,S1)(x+) .

4.9 Conclusion of the proof

We are now able to conclude the proof. Recall that we want to prove that
[[(G1, S1)]]r =t [[(G2, S2)]]r.

Let τ be an r-type over Σ ∪ {S} which occurs in (G1, S1). There are two

cases to consider:

• if τ occurs outside of A1, then Lemma 4.8 ensures that τ = [χ]r for some
frequent r-type χ. We can choose g so that χ is guaranteed to have at
least t occurrences in G1 outside of A1, and in G2 outside of A2. This is
ensured as long as

and in particular when

g(β) ≥ |A1| + t ,

g(β) ≥ (β + 2td

r)N (d + 2, r) + t .

Lemma 4.8 then ensures that τ occurs at least t times both in (G1, S1)
and in (G2, S2).

• if τ occurs only in A1, then it cannot occur in (G2, S2) outside of A2 (for

the same reasons as above).
Lemma 4.9 guarantees that τ has the same number of occurrences in A1
and in A2, hence in (G1, S1) and in (G2, S2).

Thus, by Hanf threshold theorem, we have shown that for every α ∈ N, there
exists some f (α) ∈ N such that for any Σ-structures G1, G2 of degree at most d,
f (α) G2 → G1 ≡Succ-inv FO
This means that on the class of Σ-structures of degree at most d, any equiv-
f (α),

is a ﬁnite union of equivalence classes for ≡FO
alence class C for ≡Succ-inv FO
and is consequently deﬁnable by an FO-sentence ϕC of quantiﬁer rank f (α).

G1 ≡FO

G2 .

α

α

Let P be a property of structures of degree at most d deﬁnable by a sen-
i Ci
i ϕCi

tence of Succ-inv FO of quantiﬁer rank at most α. It is a ﬁnite union (cid:83)
. Hence, the FO[f (α)]-sentence (cid:87)
of equivalence classes for ≡Succ-inv FO
deﬁnes P.

α

This proves the inclusion Succ-inv FO ⊆ FO on structures of degree at most

d.

25

5 Conclusion

We have shown that Succ-inv FO collapses to FO on any class of bounded
degree, as well as on classes of graphs which are FO-interpretable in graph
classes of bounded degree, namely near-uniform graph classes as deﬁned in [5].
Our proof gives a constructive translation from Succ-inv FO to FO on classes
of bounded degree. The quantiﬁer rank of the translated sentence is triple-
exponential in the quantiﬁer rank of the original formula. It is an easy exercise
to prove that the blowup is at least exponential, but we do not know if an
exponential translation is at all possible.

Similar considerations arise when we take into account the length of the
sentences instead of their quantiﬁer rank - in this regard, our construction is
even non-elementary, and all we know is that the blowup is at least exponential.
An interesting task would be to improve the succinctness of the translation,

or to give tighter lower bounds on such constructions.

Apart from these considerations, there are two main directions in which one
could look to extend the present result. One possibility would be to keep looking
at classes of bounded degree while climbing up in the ladder of expressivity, and
ask whether < -inv FO collapses to FO as well on these classes of structures.
New techniques would be needed, as contrary to what was the case with a
successor, the addition of an order doesn’t preserve the bounded degree property.
Furthermore, even if < -inv FO = FO in this setting, it is not clear whether
such orders can be directly constructed. It may be necessary to construct, as in
[1], a chain of intermediate structures and orders.

Alternatively, we could change the setting, and study the expressivity of
Succ-inv FO on other sparse classes of structures, e.g. on classes of bounded
If showing the collapse of Succ-inv FO to FO on these classes
treewidth.
proved itself to be out of reach, a possibility would be to aim at proving that
Succ-inv FO is Hanf-local (which would be stronger than the known Gaifman-
locality).
In that case, the starting hypothesis on the structures G1 and G2
would be stronger, as the existence of a k-type-preserving bijection between the
two structures would be assumed.

These tasks are much harder without any bound on the degree, which was
what guaranteed that we could ﬁnd elements of a given frequent type far from
each other.

References

[1] Michael Benedikt and Luc Segouﬁn. Towards a characterization of order-

invariant queries over tame graphs. J. Symb. Log., 2009.

[2] Kord Eickmeyer, Michael Elberfeld, and Frederik Harwath. Expressivity
and succinctness of order-invariant logics on depth-bounded structures. In
Mathematical Foundations of Computer Science (MFCS) - 39th Interna-
tional Symposium, 2014.

26

[3] Michael Elberfeld, Marlin Frickenschmidt, and Martin Grohe. Order in-
In Proceedings of the 31st Annual

variance on decomposable structures.
ACM/IEEE Symposium on Logic in Computer Science, LICS, 2016.

[4] Ronald Fagin, Larry J. Stockmeyer, and Moshe Y. Vardi. On monadic NP

vs. monadic co-np. Inf. Comput., 1995.

[5] Jakub Gajarsk´y, Petr Hlinen´y, Daniel Lokshtanov, Jan Obdrz´alek, and
M. S. Ramanujan. A new perspective on FO model checking of dense
graph classes. CoRR, 2018.

[6] Julien Grange and Luc Segouﬁn. Order-Invariant First-Order Logic over
Hollow Trees. In 28th EACSL Annual Conference on Computer Science
Logic (CSL 2020). Schloss Dagstuhl, 2020.

[7] Martin Grohe and Thomas Schwentick. Locality of order-invariant ﬁrst-

order formulas. ACM Trans. Comput. Log., 2000.

[8] Leonid Libkin. Elements of Finite Model Theory. Texts in Theoretical

Computer Science. An EATCS Series. Springer, 2004.

[9] Benjamin Rossman. Successor-invariant ﬁrst-order logic on ﬁnite struc-

tures. J. Symb. Log., 2007.

[10] Boris A Trakhtenbrot. Impossibility of an algorithm for the decision prob-

lem in ﬁnite classes. Doklady Akademii Nauk SSSR, 1950.

27

