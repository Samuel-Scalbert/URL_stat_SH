SUQ2: Uncertainty Quantification Queries over Large
Spatio-temporal Simulations
Noel Lemus, Fábio Porto, Yania M Souto, Rafael Pereira, Ji Liu, Esther

Pacitti, Patrick Valduriez

To cite this version:

Noel Lemus, Fábio Porto, Yania M Souto, Rafael Pereira, Ji Liu, et al.. SUQ2: Uncertainty Quantifi-
cation Queries over Large Spatio-temporal Simulations. Bulletin of the Technical Committee on Data
Engineering, 2020, 43 (1), pp.47-59. ￿lirmm-02531748￿

HAL Id: lirmm-02531748

https://hal-lirmm.ccsd.cnrs.fr/lirmm-02531748

Submitted on 3 Apr 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

SUQ2: Uncertainty Quantiﬁcation Queries over
Large Spatio-temporal Simulations

Noel Moreno Lemus a, Fabio Porto a, Yania M. Souto a, Rafael S. Pereira a,
Ji Liuc, Esther Paccitib, and Patrick Valduriez b

aLNCC, DEXL, Petropolis, Brazil
bInria and LIRMM, University of Montpellier, France
cBig Data Laboratory, Baidu Research, Beijing, China

April 3, 2020

Abstract

The combination of high-performance computing towards Exascale power
and numerical techniques enables exploring complex physical phenomena
using large-scale spatio-temporal modeling and simulation. The improve-
ments on the ﬁdelity of phenomena simulation require more sophisticated
uncertainty quantiﬁcation analysis, leaving behind measurements restricted
to low order statistical moments and moving towards more expressive proba-
bility density functions models of uncertainty. In this paper, we consider the
problem of answering uncertainty quantiﬁcation queries over large spatio-
temporal simulation results. We propose the SU Q2 method based on the
Generalized Lambda Distribution (GLD) function. GLD ﬁtting is an embar-
rassingly parallel process that scales linearly to the number of available cores
on the number of simulation points. Furthermore, the answer of queries is
entirely based on computed GLDs and the corresponding clusters, which en-
ables trading the huge amount of simulation output data by 4 values in the
GLD parametrization per simulation point. The methodology presented in
this paper becomes an important ingredient in converging simulations im-
provements to the Exascale computational power.

1

Introduction

The rapid growth of high-performance computing combined with recent advances
in numerical techniques increases the accuracy of numerical simulations. This

1

leads to practical applicability in models for predicting the behavior of weather,
hurricane forecasts [Tobergte2013] and subsurface hydrology [Baroni2014a], just
to name a few, positioning simulations as increasingly important tools for high-
impact predictions and decision-making applications.

In order to reach higher simulation accuracy of reproduced phenomena, the sci-
entiﬁc community is leaving behind the traditional deterministic approach, which
offers point predictions with no associated uncertainty [Johnstone2015], to move
towards Uncertainty Quantiﬁcation (UQ) as a common practice over simulation
results analysis. Arguing for improvements in simulation accuracy, by the assess-
ment of uncertainty quantiﬁcation of simulation results consider the extra knowl-
edge a scientist acquires whenever the simulation behaviours become more evident
over different scenarios. The increase in simulation scenarios call for more com-
puting power. In a subsurface seismic domain, for example, a simulation computes
the wave velocity at each point of an area. A scientist is interested in a particular
region of the space where a salt dome is located. She may issue a query ﬁltering
only that spatial region and checking how precise is the velocity ﬁeld in that area.
In order to achieve that, she could quantify the uncertainty involved in the region
of interest. This type of simulation that evaluates the uncertainty by analyzing
its output is referred to as forward propagation. In this paper, we focus on an-
swering uncertainty quantiﬁcation queries over large spatio-temporal simulations
(U Q2ST S). The U Q2ST S problem is challenging as: (1) it requires analyzing
large amounts of simulation output data; (2) the uncertainty at each point may ex-
hibit patterns too complex to be captured by low order statistical moments (such as
mean and standard deviation); (3) the uncertainty behavior may vary along a simu-
lation spatio-temporal region leading to a complex data pattern to be modelled and
an uncertainty expression of difﬁcult interpretation. Thus, the problem involves
conceiving a method to accurately and efﬁciently solve the U Q2ST S.

We propose the SUQ2 method to solve this problem. SUQ2 is based on the
adoption of the generalized lambda distribution (GLD) PDF type as a model of the
uncertainty at each simulation computation point, which solves issue (2). Its uni-
form representation reduces signiﬁcantly the computation of the necessary ﬁtting
function. Furthermore, by adopting a single function type, we could run clustering
algorithms on the GLD parametrization, electing a representative data distribution
for a large set of simulation points. This represents a huge saving in data storage,
which solves issue (1). Finally, the cluster representatives are used to composed a
mixture of GLDs and to measure the information entropy of the U Q2ST S, which
solves issue (3). We illustrate the adoption of the SUQ2 method with a case study
in seismology.

In our previous work [Liu2019], we designed a system to efﬁciently compute
PDFs in large saptial datasets. The system implements a Spark dataﬂow to stream-

2

line the huge amount of PDF ﬁtting computation. Our work extends the results of
this work by adopting the GLDs as a generic model for data distribution, avoiding
testing for different distribution types and uniformizing the computation of mixed
PDFs in spatial-temporal regions.

To the best of our knowledge, the ﬁrst effort to use the GLD to model uncer-
tainty in data is the work of Lampasi et. al. [Lampasi2006], followed by Movahedi
et. al. [Movahedi2013] for a task involving the computation of results reliabil-
ity. The adoption of mixture of GLDs is motivated by the work of Ning et. al.
[Ning2008]. Algorithms to use the mixture of GLDs to model datasets have been
deployed with the GLDEX R package. Wellmann et al. [Wellmann2012] propose
to use information entropy as an objective measure to compare and evaluate model
and observational results. Our SUQ2 method combines these techniques.

The rest of the paper is organized as follows: Section 2 gives the problem for-
malization and introduces the GLD function. Section 3 presents the SUQ2 method
and the workﬂow to solve the U Q2ST S problem. Section 4 gives an experimental
evaluation with a use case in seismology. Section 5 concludes.

2 Preliminaries

In this section we deﬁne some basic concepts needed for the rest of the paper. We
ﬁrst formalize the problem. Next, we present the Generalized Lambda Distribution
function, including a discussion on its shape and the mixture of GLDs.

A simulation is a combination of a numerical method implementing a math-
ematical model and a discretization that enables to approximate the solution in
points of space-time. A simulation can be used for two different types of prob-
lems: forward or inverse. Forward problems study how uncertainty propagates
through a mathematical model. In a simulation, a spatio-temporal domain is repre-
sented by a grid of positions (si, tj) ∈ S × T ⊆ R3 × R, where values of a quantity
of interest (QoI), such as velocity, are computed. In a parameter sweep application,
a simulation is executed multiple times, each with a different initial conﬁguration,
leading to multiple occurrences for a given domain position, in order to explore the
simulation behavior under different scenarios.

A simulation can be formally expressed as q = M(θ) where: θ ∈ Rn is a
vector of input parameters of the model; M is a computational model, and q ∈
Rk is a vector that represents quantities of interest (QoI). In a forward problem,
the parameters θ are given and the quantities of interest q need to be computed.
In stochastic models, at least one parameter is assigned to a probability density
function (PDF) or it is related to the parameterization of a random variable (RV)
or ﬁeld, causing q to become a random variable as well.

3

In order to estimate a stochastic behavior of the output solution q in terms of
input uncertainties θ, sampling methods analyze the values of M(θ) at multiple
sampled conditions in the Θ space (called stochastic space) directly from numeri-
cal simulations. Methods like Monte Carlo (MC) are used to randomly sample in
the stochastic space, and hence many sample calculations are required to achieve
a convergence of stochastic estimations. As a result, the method returns multi-
ple realizations of q. Then, other methods to measure the uncertainty need to be
applied.

In a more general case, the computational model q = M(θ) represents the
spatio-temporal evolution of a complex systems, and the QoI q can be represented
as Q = (q(s1, t1), q(s2, t2), ..., q(sn, tn)), where: (s1, t1), (s2, t2), ...., (sn, tn) ∈
S ×T ⊆ R3 ×R represents a set of distinct spatio-temporal locations, and q(si, tj)
represents a value of the QoI at the spatio-temporal location (si, tj).

In a stochastic problem, on each spatio-temporal location (si, tj) we have many
realizations of q(si, tj) that can be represented as a vector < q(si, tj) >. In this
context, it is frequent that more than 104 simulations are performed while exploring
the model parameter space, which leads the output dataset to have a size of order
Ns × Nt × Nsim, where Ns is the number of spatial locations, Nt is the number
of time steps, and Nsim is the number of simulations. An example of the volume
of data generated by these simulations is given in the experimental evaluation (see
Section 4), where the output dataset is about 2.4 TB.

A simple approach to solve a spatio-temporal UQ query is to consider a sim-
ple aggregation query, computing the mean and standard deviation on the selected
spatio-temporal region. This approach, albeit being simple and fast, is unable to
capture patterns exhibited by the data distribution of complex phenomena. The
solution we propose in [Liu2019] adopts probability density function (PDF) as a
more accurate modeling data distribution at each point. However, the adoption of
PDFs brings its own challenges. First, as the uncertainty may vary in different
regions of the simulation, one needs to try multiple function types, such as Gaus-
sian, Logarithm, Exponential, etc, at each spatial position to ﬁnd the one closest
to its data distribution. This leads to a huge computation cost for each simulation
spatial position. Moreover, as a region may be deﬁned by different PDF types, an-
swering solving a (U Q2ST S) requires dealing with heterogeneous function types,
making it more costly and harder to interpret the results. Thus, at the basis of the
SU Q2 method is the adoption of the GLD PDF type, which is presented in the next
section.

4

2.1 Generalized Lambda Distribution

The Generalized Lambda Distribution (GLD) has been applied to ﬁtting phenom-
ena in many ﬁelds with very good results.
It was proposed by Ramberg and
Schmeiser in 1974 [Ramberg1974] as an extention of the Tukey’s distribution, and
it is tuned to represent different data distributions through the speciﬁcation of λ pa-
rameter, where λ1 and λ2 determine location and scale parameters, while λ3 and
λ4 determine the skewness and kurtosis of the GLD(λ1, λ2, λ3, λ4). The Ramberg
and Schmeiser proposal is known as RS parameterization. The RS parametrization
has some constraints with respect to the values of (λ3, λ4), see [Karian2011]. To
circumvent those constraints, Freimer et al. [Freimer1988] introduced a new pa-
− (1−y)λ4 −1
rameterization called FKML: QF M KL(y|λ1, λ2, λ3, λ4) = λ1+ 1
λ4
λ2
As in the previous parameterization, λ1 and λ2 are the location and scale param-
eters, but in this one λ3 and λ4 are the tail index parameters. The advantage over
the previous parameterization is that there is only one constraint on the parameters,
i.e. λ2 must be positive.

(cid:104) yλ3 −1
λ3

Both representations (i.e. RS and FMKL) can present a wide variety of shapes
and therefore are utilized in practice; however, generally the FMKL GLD is pre-
ferred due to the ease in its use [Corlu2016]. In this paper, we opt for using the
FMKL GLD representation.

(cid:105)

.

2.1.1 Shapes of GLD

A GLD can describe a variety of shapes, such as U-shaped, bell shaped, triangular,
and exponentially [Su2007]. At the same time it provides good ﬁts to many well
know distributions.

These GLD properties are important to the SU Q2 method for two reasons.
First, no previous knowledge is needed to ﬁt the GLD to a dataset. Second, GLDs
can be comparatively assessed; grouped based on their shapes, which enables run-
ning clustering algorithms, electing a representative distribution, and synthesizing
the data in a cluster.

The shape of a GLD depends on its λ values. In the case of the FMKL GLD
parameterization, Freimer et al. [Freimer1988] classify the shapes into ﬁve cat-
egories depending on the variety of distributions, which can be represented by
several combinations of the shape parameters λ3 and λ4.

The ability to model different shapes is critical to the SU Q2 approach as it is

the basis for the clustering algorithms (see Section 3.2).

5

2.1.2 GLD mixture

In general, a mixture distribution is the probability distribution of a random vari-
able that is derived from a collection of other random variables. Given a ﬁnite
set of PDFs {p1(x), p2(x), . . . , pn(x)}, and weights {w1, w2, . . . , wn} such that
wi ≥ 0 and (cid:80) wi = 1, the mixture distribution can be represented by writing
the density f (x) as a sum (which is a convex combination): f (x) = (cid:80)n
i wipi(x).
Extending this concept to GLD, the mixture distribution can be represented as:
f (x) = (cid:80)n
i wiGLDi(λ1, λ2, λ3, λ4). This model is used in Section 3.3 to charac-
terize the uncertainty in a spatio-temporal region.

3 Simulation Uncertainty Quantiﬁcation Querying (SUQ2)

In a stochastic problem, on each spatio-temporal location (si, tj) we have many
realizations of q(si, tj). A schema to store this information in a relational database
can be:

S(si, tj, simId, q(si, tj))

(1)

where simId represents the id of one simulation (realization).

In this section, we ﬁrst show how to ﬁt a GLD to a spatio-temporal dataset.
Next, we present the clustering of GLDs using the lambda parameters. Then, we
present how to compute the uncertainty in a region using a mixture of GLDs and
information entropy. Figure 1 shows the SU Q2 method represented by a workﬂow
and divided into three main steps: ﬁtting process, clustering and UQ analysis.

3.1 Fitting a GLD to a spatio-temporal dataset

Given a random sample q1, q2, q3, ..., qn, the basic problem in ﬁtting a statistical
distribution to these data is the distribution from which the sample was obtained.
In our approach we divide this process into three steps: (1) ﬁting the GLD to the
data; (2) validating the resulting GLD; (3) evaluating the quality of the ﬁt.

Algorithm 1 realizes Step 1. Before starting the ﬁtting process, we need to
group all the simulation values that correspond to the same spatio-temporal loca-
tion (si, tj). As a result, we get a new dataset S∗(si, tj, < q1, q2, .., qn >), where
qi, 1 ≤ i ≤ n, represents a vector of all the values of q at point (si, tj). This
process is efﬁciently computed according to the approach developed in [Liu2019].
For each spatio-temporal location (si, tj) ∈ S × T , we use a function of the
GLDEX R package [Su2007], to ﬁt the GLD to a vector < q1, q2, .., qn >, line
2. This is an embarrassingly parallel computation method, which we adopt in
[Liu2019].

6

Once the ﬁtting process in Step 1 has been applied, a ﬁtted GLD is associated
to each simulation spatio-temporal position. The schema in Equation 1 is modi-
ﬁed to accommodate the GLD parameters in place of the list of simulation values:
S(si, tj, GLDi, j(λ1,2 , λ3,4 )).

Finally, we need to evaluate the ﬁt quality, which assesses whether the GLD
probability density function (PDF) correctly describes the dataset. We use here the
Kolmogorov-Smirnov test (KS-test), that determines if two datasets differ signiﬁ-
cantly. In this case, the datasets are the original dataset and a second one generated
using the ﬁtted GLD. As a result, this test returns the p-value, line 5. If the p-value
is bigger than 0.05, lines 6-7, we store the lambda values of those GLDs.

Algorithm 1 Fitting the GLD to a spatio-temporal dataset

1: function GLDFIT(S(si, tj, < q1, q2, ..., qn >))
2:

< λ1, λ2, λ3, λ4 >← FIT.GLD.LM(< q1, q2, ..., qn >)
isV alid(si,tj ) ← VALIDITYCHECK(< λ3, λ4 >)
if isV alid(si,tj ) then

[pvalue, D](si,tj ) ← KS(< λ1, λ2, λ3, λ4 >(si,tj ))

if pvalue(si,tj ) > 0.05 then

STORELAMBDAS(< λ1, λ2, λ3, λ4 >, si, tj)

3:

4:

5:

6:

7:

3.2 Clustering the GLD based on its lambda values

In Section 2.1.1, we discussed the two most important parameterizations of the
GLD and selected FMKL to be used for the rest of the paper. In this parametriza-
tion, λ1 represents the location of the GLD and is directly related to the mean of
the distribution. λ2 is the scale, directly related to the standard deviation, and λ3
and λ4 represent the left and right tails of the distribution. Combinations of λ3 and
λ4 can be used to estimate the skewness and kurtosis of the distribution.

As λ2 deﬁnes the dispersion, and λ3 and λ4 the shape of a GLD, the combina-
tion of these parameters determine the quantiﬁcation of the uncertainty, from the
GLD point of view.

According to Lampasi et al. [Lampasi2006], a particular GLD(λ1, λ2, λ3, λ4)

can be rewritten as:

GLD(λ1, λ2, λ3, λ4) = λ1 +

1
λ2

GLD(0, 1, λ3, λ4)

(2)

In Equation 2, the ﬁrst term applies λ1 while the second involves the remaining
parameters. Then, we can apply clustering algorithms only considering parameters
in the second term: λ2, λ3 and λ4. The clustering algorithm would be applied in

7

two steps 1. The ﬁrst clusters based on the λ2 values, according to the curve dis-
persion. Next, for each cluster obtained in the ﬁrst step, we cluster again according
to parameters λ3 and λ4, which are the parameters that deﬁne the shape of the
distribution.

Algorithm 2 Clustering the GLD based on its λ(2,3,4) values.

1: function GLDCLUSTERING(S(si, tj, < 0, λ2, λ3, λ4 >))
2:

S(si, tj, clusterIDI ) ← FIRSTSTEP(S(si, tj, λ2))
for each clusterIDI do

3:

4:

S(si, tj, clusterIDII ) ← SECONDSTEP(S(si, tj, < λ3, λ4 >

), S(si, tj, clusterIDI ))

Then, in this step of our workﬂow, we cluster the GLDs using λ2, λ3 and λ4

values. The ﬁnal result of this step is:

SC(si, tj, GLDk, clusterID)

(3)

where clusterID represents the ID of the cluster to which the GLD at the spatio-
temporal location (si, tj) belongs. With the domain modeled by clustered GLDs,
we can use this result to characterize the uncertainty in a particular spatio-temporal
region or to measure numerically the corresponding uncertainty. In Sections 3.3
and 3.4, we describe how these approaches are implemented (see Figure 1).

3.3 Use of GLD mixture to characterize uncertainty in a spatio-temporal

region

One of the main advantages of assessing the complete probability distribution of
the outputs is that we can use the PDFs to answer queries. If we consider that
the clustering of GLD has good quality, we can pick the GLD at the centroid of
each cluster as a representative of all its members. In this context, in a particular
spatio-temporal region, each cluster may be qualiﬁed with a weight given by:wk =

1
N

(cid:80)T

(cid:80)S

(cid:40)
1
0
N is the number of points in the region (Si × Tj).

j=1 w(si, tj), where: w(si, tj) =

i=1

if clusterID(si, tj) = k
otherwise

and

The weight wk is the frequentist probability of occurrence of the cluster k in
the region, and complies with the conditions deﬁned in Section 2.1.2 that wk ≥ 0
and (cid:80) wk = 1.

Remember that the mixture of the GLDs can be written as f (x) = (cid:80)K

k=1 wkGLD(λ1, λ2, λ3, λ4).

So, if we have the weights and a representative GLD for each cluster, we have the
mixture of GLD that characterizes the uncertainty in the spatio-temporal region

8

(Si × Tj). The GLD mixture process is summarized in Algorithm 3, which re-
ceives a spatio-temporal region and a clusterId associated to each spatio-temporal
point. In the main loop, lines 3 to 5, the algorithm increments the number of oc-
currences for each clusterId and the total number of points. At line 7, the mixture
expression is returned.

3.4

Information entropy as a measure of uncertainty in a spatio-temporal
region

Now, what happens if we want to measure the uncertainty quantitatively? The
information entropy is useful in this context. We use the different clusters we got
in Section 3.2 as the different outcomes of the system. The information entropy is
computed as follows H(s, t) = − (cid:80)C
c=1 pc(s, t) log pc(s, t), where c represent a
particular cluster in the set of clusters C, and pc(s, t) represents the probability of
occurrence of the cluster c in the spatio-temporal region (s, t).

Algorithm 4 computes the information entropy in a region C(Si×Tj ). In lines 2
to 7, we assess the probability of each cluster in the region. Using this result, we
can evaluate the information entropy H(s, t), line 8, and ﬁnally, return the result in
line 9.

4 Experimental Evaluation

In this section, we ﬁrst introduce the data used in our experiments. Next, we discuss
how we apply the ﬁtting and clustering techniques over the experiment dataset.
Then, we present the queries used in the performance evaluation and discuss the
results expressed as a mixture of GLDs and values computed using information
entropy.

As a case study, we use the HPC4e seismic benchmark, a collection of four 3D
models and sixteen associated tests 1 to generate the data of a cube. The models
include simple cases that can be used in the development stage of any geophysical

1The benchmark can be freely downloaded from https://hpc4e.eu/downloads/

9

Figure 1: SUQ2 workﬂow divided into three steps, (a) ﬁtting process, (b) clustering
of the GLDs and, (c) queries over the results of the clustering process.

imaging practitioner as well as extremely large cases that can only be solved in
a reasonable time using supercomputers. The models are generated based on the
required size by means of a Matlab/Octave script. The tests can be used to bench-
mark and compare the capabilities of different and innovative seismic modelling
approaches, thus simplifying the task of assessing the algorithmic and computa-
tional advantages.

4.1 Dataset

In the HPC4e benchmark, the models are designed as sets of 16 layers with con-
stant physical properties. The top layer delineates the topography and the other 15
delineate different layer interface surfaces or horizons. To generate a single cube
with dimensions 250 × 501 × 501 we can use the values provided in the bench-
mark. For example, to generate a cube in the vp(m/s) variable we can use the ﬁxed
values of Table 1. The ﬁrst slice of this cube is shown in Figure 2.

As our purpose is to study the uncertainty in the simulation output, we need
the input vp(m/s) to present a stochastic behavior. We model the input according
to the distributions depicted in Table 2. Next, using a Monte Carlo method, we
generate a sampling of 1000 realizations of the vp(m/s) variable and use a Matlab

10

vp(m/s) Layer
1618.92
1684.08
1994.35
2209.71
2305.55
2360.95
2381.95
2223.41

Layer
1
2
3
4
5
6
7
8
Table 1: Values of vp used in the gen-
eration of a single velocity ﬁeld cube.

9
10
11
12
13
14
15
16

vp(m/s)
2712.06
Layer PDF Family Parameters
[1619, 711.2]
1
Exponential
2532.2
[3368, 711.2]
2
Exponential
2841.03
[8839, 711.2]
3
Exponential
[7698, 301.5]
4
Exponential
3169.31
[7723, 294.7]
5
Uniform
[7733, 292.2]
6
Uniform
3169.31
[7658, 312.1]
7
Uniform
3642.28
8
[3687, 368.7]
Uniform
Table 2: PDFs and the parameters
3659.22
used to sample the vp attribute, to
4000.00
generate n velocity models.

Gaussian
Gaussian
Gaussian
Gaussian
Lognormal
Lognormal
Lognormal
Lognormal

Layer PDF Family Parameters
[3949, 394.9]
9
[5983, 711.2]
10
[3520, 352.0]
11
[3155, 315.5]
12
[2541, 396.4]
13
[2931, 435.3]
14
[2948, 437.0]
15
[3289, 471.1]
16

script provided by the HPC4e benchmark to generate the cube data. We perform
the simulations 1000 times, one for each realization, and generate 1000 cubes (230
GB) as output. The generated cubes are 250 × 501 × 501 multi-dimensional arrays.
In order to simplify the computational process and visualize the results, we select
the slice 200 to be used in our experiments. Then, we have 1000 realizations of a
slice with size of 250 × 501. The data schema in Equation 1 can be simpliﬁed as
we only have two spatial dimensions and no time domain. Thus, the dataset can
be represented as S(xi, yj, simId, vp(xi, yj)). In this new representation, (xi, yj)
is the 2D coordinates and vp(xi, yj) is the velocity value at point (xi, yj). simId
represents the Id of the simulation, ranging from 1 to 1000.

4.2 Fitting the GLD

The ﬁrst step is to ﬁnd the GLD that best ﬁts the dataset at each spatial location.
Running Algorithm 1, we get a new 2D array:

S(cid:48)(xi, yj, GLD(λ1, λ2, λ3, λ4))

(4)

The raw data is signiﬁcantly reduced and the new dataset is characterized by four
lambda values at each spatial location.

To check how good is the ﬁt, we use the ks.test algorithm included in the R-
package stats [Lopes2011], which return the p-value at each spatial location. Our
results show that the ﬁt of the GLD is acceptable in most cases (p-value > 0.05),
in 82 % of the spatial locations (see Figure 3). In the 18% regions where the GLD
modeling was not acceptable, some GLD extensions proposed in [Karian2011]
could be used. Since the main purpose of this paper is to demonstrate the usefulness
of the GLD in UQ, this particular problem is beyond our scope.

11

Figure 2: One slice of the 250 × 501 ×
501 cube.
In the slice, we can distin-
guish between the different layers.

Figure 3: The red color shows where the
p-value is greater than 0.05.

4.3 Clustering

Up to now, the dataset is characterized by the schema depicted by Equation 4.
Then, using a clustering algorithm, such as k-means, we group the GLDs based
on its (λ2, λ3, λ4) values, as discussed in Section 3.2. In this paper, we use the
k-means algorithm with k = 10. The choice of the clustering algorithm and the
parameterization is subject for further investigation and is beyond the scope of this
paper.

Once the clustering algorithm is applied, a new dataset is produced. In the new
dataset, for each spatial location, a label indicates the cluster the GLD belongs to,
as shown (see the schema at Equation 5) in Figure 4. Note that in Figure 4, the
blue region corresponding to cluster 11 is not a cluster itself. It is rather the region
where the GLD is not valid (see Section 4.2).

SC(xi, yj, clusterID, GLDxi,yj )

(5)

Figure 4: Result of the clustering using
k-means with k = 10.

Figure 5: Distribution of the clusters in
the (λ3, λ4) space. The points that be-
longs to a same cluster are one near the
others, as was expected.

12

If we visually compare Figure 2 with Figure 4, we observe a close similarity.
Another interesting result is shown in Figure 5, where we plot the clusters in
(λ3, λ4) space. As we mentioned in Section 2.1.1, the shape of the GLD depends
on the values of λ3 and λ4. In this scenario, the expected result is that the members
of the same cluster share similar values of λ3 and λ4. This is exactly the result we
can observe in Figure 5.

To further corroborate this fact, Figure 6 shows the PDFs of 60 members of
the 10 clusters. Visually assessing the ﬁgures gives an idea of how similar are the
shapes of the members of a same cluster and how dissimilar are the shapes of the
members of different clusters. This suggests that our approach is valid. A product
of these observations is that we can pick one member of each cluster (the centroid)
as a representative of all the members of this cluster, Table 3. The selected member
is going to be used to answer the queries in the next Sections.

Cluster λ2
1
2
3
4
5

0.0013937313
0.0005291388
0.0020630696
0.0016238358
0.0027346929

λ3
0.9585829
1.1633978
0.1349486
0.8653824
0.5084664

λ4
1.04696461
-0.07162550
0.17305941
0.83857646
0.39199164
Table 3: Clusters centroids.

Cluster λ2
6
7
8
9
10

0.0003894541
0.0021972784
0.0015421749
0.0018672401
0.4856397733

λ3
1.4076354
0.3253562
0.9491101
0.2176002
0.1404140

λ4
-0.01925743
0.01493809
0.86699555
0.17862024
0.14011298

The 125250 points of the slice are distributed through the clusters following

the histogram of Figure 7.

4.4 Spatio-temporal queries

Up to this point, the initial dataset is summarized as depicted by the schema in
Equation 5. It can be used to answer queries and validate our approach, by com-
paring the results with the raw data.

First of all, we select four spatio-temporal regions of the dataset where the
clusters suggest us different behaviors. The regions are shown in Figure 8. With
these four regions, we assess the adoption of the GLD mixture to obtain the PDF
that characterizes the uncertainty in a speciﬁc region (see Sections 4.4.1 and 4.4.2).
We use the information entropy to assign a value that measures the uncertainty at
each region. In Section 4.4.1, we expect the GLD mixture to characterize well
the raw data, and in Section 4.4.2, we hope that the information entropy is zero in
region 1 and increases between regions 2, 3 and 4.

13

Figure 6: PDFs of 60 members of the 10 clusters obtained using k-means over the
(λ2, λ3, λ4) values.

Figure 7: Distribution of the 125250
points by clusters.

Figure 8: Analysis Regions. The four
regions where selected intentionally in
this way to warranty different distribu-
tions of the clusters inside it.

4.4.1 GLD mixture

In this experiment, we use the representative GLDs at each cluster and the weight
associated to it in the region. Using these parameters, we can build a GLD mixture
that characterizes the uncertainty on that region. We use Algorithm 3 described in
Section 2.1.2. First, we query the region to ﬁnd the clusters represented inside it,
and how they are distributed. The retrieved results are shown in Table 4. If we
divide the columns of Table 4 by the sum of the elements of each column, we get
the weight needed to formulate the mixed GLDs. It is clear that the GLD in region

14

1 is represented by the GLD of cluster 4. In the other three cases, we get what is
shown in the set of equations 6.

Cluster Region 1 Region 2 Region 3 Region 4
1
2
3
4
5
6
7
8
9
10

0
0
0
1640
0
0
0
0
0
0

0
0
2596
0
0
0
1967
0
1918
901

979
268
1468
5173
269
416
3920
3432
3280
583

2250
0
0
4467
149
0
0
3335
0
0

Table 4: Distribution of the clusters by regions. The four regions are selected
intentionally this way to warrant different distributions of the clusters inside it.

GLDregion2 = 0.22GLDc1 + 0.44GLDc4 + 0.014GLDc5 + 0.33GLDc8
GLDregion3 = 0.34GLDc3 + 0.26GLDc7 + 0.25GLDc9 + 0.12GLDc10
GLDregion4 = 0.22GLDc1 + 0.44GLDc4 + 0.014GLDc5 + 0.33GLDc8

(6)

Now, we need to evaluate whether the mixture of GLDs correctly models the
uncertainty in a region. We perform the same ks-test used to evaluate the good
quality of the ﬁt, described in Section 3.1. Based on the p-value, Table 5, we can
conclude that in all 4 regions the mixture of GLDs is a good ﬁt to the raw data.

Metrics Region 1 Region 2 Region 3 Region 4
p-value

0.73

0.08

0.34

0.56

Table 5: p-values by regions.

4.4.2 Information Entropy

Based on the distribution of clusters inside the regions (see Table 4), we can com-
pute the entropy.

entropy Region 1 Region 2 Region 3 Region 4
2.024246
1.122243
value
Table 6: Information Entropy by regions.

1.41166

0

As we expect (see Table 6), the entropy in region 1 is zero, because the region
contains only members of the cluster 4. On the other regions the entropy increases
from region 2 to region 4, as expected. The information entropy is a very good
and simple measure of the uncertainty, and here it is demonstrated its usefulness
combined with the GLD.

15

5 Conclusion

In this paper, we proposed SUQ2, a method to answer uncertainty quantiﬁcation
(UQ) queries over large spatio-temporal simulations. SUQ2 trades large simulation
data by probability density functions (PDFs), thus saving huge amount of storage
space and computational cost. It enables complex data distribution representation
at each simulation point, as much as a spatio-temporal view of simulation uncer-
tainty computed by mixing spatial point PDFs. We evaluated SUQ2 using a seis-
mology use case, considering the computation of uncertainty in regions of a slice of
the seismic cube. The results show that SUQ2 method produces an accurate view
of the uncertainty in regions of space-time while considerably saving storage space
and reducing the cost associated with the PDF modeling of the dataset. To the best
of our knowledge, this is the ﬁrst work to use GLD as the basis for answering UQ
queries in spatio-temporal regions and to compile a series of techniques to produce
a query answering workﬂow.

Acknowledgments

This work has been funded by CNPq, CAPES, FAPERJ, the Inria HPDaSc and
SciDISC Associated Teams and the European Commission (HPC4E H2020) project.

References

[1] D. R. Tobergte and S. Curtis. Workshop on Quantiﬁcation, Communication, and
Interpretation of Uncertainty in Simulation and Data Science. in Journal of Chemical
Information and Modeling, 53(9):1689–1699, 2013.

[2] G. Baroni and S. Tarantola. A General Probabilistic Framework for uncertainty and
global sensitivity analysis of deterministic models: A hydrological case study.
in
Environmental Modelling and Software, 51:26–34, 2014.

[3] R. H. Johnstone, E. T. Y. Chang, R. Bardenet, T. P. de Boer, D. J. Gavaghan, P.
Pathmanathan, R. H. Clayton, and G. R. Mirams. Uncertainty and variability in
models of the cardiac action potential: Can we build trustworthy models? in Journal
of Molecular and Cellular Cardiology, 96:49–62, 2016.

[4] Z. A. Karian and E. J. Dudewicz. Handbook of ﬁtting statistical distributions with R.

2011.

[5] M. Freimer, C. T. Lin, and G. S. Mudholkar. A Study Of The Generalized
in Communications in Statistics - Theory and Methods,

Tukey Lambda Family.
17(10):3547–3567, 1988.

16

[6] C. G. Corlu and M. Meterelliyoz. Estimating the Parameters of the Generalized
Lambda Distribution: Which Method Performs Best? in Communications in Statis-
tics: Simulation and Computation, 45(7):2276–2296, 2016.

[7] S. Su. Fitting Single and Mixture of Generalized Lambda Distributions to Data via
Discretized and Maximum Likelihood Methods: GLDEX in R. Journal of Statistical
Software, 21(9), 2007.

[8] D. A. Lampasi, F. Di Nicola, and L. Podesta. Generalized lambda distribution for
the expression of measurement uncertainty. IEEE Transactions on Instrumentation
and Measurement, 55(4):1281–1287, 2006.

[9] M. M. Movahedi, M. R. Lotﬁ, and M. Nayyeri. A solution to determining the re-
liability of products Using Generalized Lambda Distribution. Research Journal of
Recent Sciences Res.J.Recent Sci, 2(10):41–47, 2013.

[10] W. Ning, Y. Gao, and E. J. Dudewicz. Fitting mixture distributions using generalized
lambda distributions and comparison with normal mixtures. American Journal of
Mathematical and Management Sciences, 28(1-2):81–99, 2008.

[11] J. F. Wellmann and K. R. Lieb. Uncertainties have a meaning: Information entropy
as a quality measure for 3-D geological models. Tectonophysics, 526-529:207–216,
2012.

[12] J. Liu,N. Lemus, E. Pacitti, F. Porto, P. Valduriez. Parallel computation of PDFs on
big spatial data using spark. in em Distributed and Parallel Databases, pp. 1-28. In
press, 10.1007/s10619-019-07260-3, 2019.

[13] R. H. C. Lopes Kolmogorov-Smirnov Test. in Lovric M. (eds) International Ency-

clopedia of Statistical Science. Springer, Berlin, Heidelberg, 2011.

[14] J. S. Ramberg, and B. W. Schmeiser. An approximate method for generating asym-
in em Communications of the ACM, 17(2), 78–82.

metric random variables.
doi:10.1145/360827.360840, 1974.

17

