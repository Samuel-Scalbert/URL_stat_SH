On the Complexity of SHAP-Score-Based Explanations:
Tractability via Knowledge Compilation and
Non-Approximability Results
Marcelo Arenas, Pablo Barceló, Leopoldo Bertossi, Mikaël Monet

To cite this version:

Marcelo Arenas, Pablo Barceló, Leopoldo Bertossi, Mikaël Monet. On the Complexity of SHAP-
Score-Based Explanations: Tractability via Knowledge Compilation and Non-Approximability Results.
Journal of Machine Learning Research, 2023, 24 (63), pp.1–58. ￿hal-04377324￿

HAL Id: hal-04377324

https://inria.hal.science/hal-04377324

Submitted on 7 Jan 2024

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

3
2
0
2

r
a

M
0
3

]
I

A
.
s
c
[

2
v
5
1
0
8
0
.
4
0
1
2
:
v
i
X
r
a

On the Complexity of SHAP-Score-Based Explanations:
Tractability via Knowledge Compilation and
Non-Approximability Results

marenas@ing.puc.cl
Marcelo Arenas
(a) Department of Computer Science & Institute for Mathematical and Computational Engineering,
School of Engineering & Faculty of Mathematics, Universidad Cat´olica de Chile
(b) IMFD Chile

Pablo Barcel´o
(a) Institute for Mathematical and Computational Engineering,
School of Engineering & Faculty of Mathematics, Universidad Cat´olica de Chile
(b) IMFD Chile (c) National Center for Artiﬁcial Intelligence, CENIA Chile

pbarcelo@uc.cl

Leopoldo Bertossi
SKEMA Business School, Montreal, Canada

leopoldo.bertossi@skema.edu

Mika¨el Monet
Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000 Lille, France

mikael.monet@inria.fr

Abstract

Scores based on Shapley values are widely used for providing explanations to classiﬁcation
results over machine learning models. A prime example of this is the inﬂuential SHAP-
score, a version of the Shapley value that can help explain the result of a learned model
on a speciﬁc entity by assigning a score to every feature. While in general computing
Shapley values is a computationally intractable problem, we prove a strong positive result
stating that the SHAP-score can be computed in polynomial time over deterministic and
decomposable Boolean circuits under the so-called product distributions on entities. Such
circuits are studied in the ﬁeld of Knowledge Compilation and generalize a wide range
of Boolean circuits and binary decision diagrams classes, including binary decision trees,
Ordered Binary Decision Diagrams (OBDDs) and Free Binary Decision Diagrams (FBDDs).
Our positive result extends even beyond binary classiﬁers, as it continues to hold if each
feature is associated with a ﬁnite domain of possible values.

We also establish the computational limits of the notion of SHAP-score by observing
that, under a mild condition, computing it over a class of Boolean models is always poly-
nomially as hard as the model counting problem for that class. This implies that both
determinism and decomposability are essential properties for the circuits that we consider,
as removing one or the other renders the problem of computing the SHAP-score intractable
(namely, #P-hard).
It also implies that computing SHAP-scores is #P-hard even over
the class of propositional formulas in DNF. Based on this negative result, we look for the
existence of fully-polynomial randomized approximation schemes (FPRAS) for computing
SHAP-scores over such class. In stark contrast to the model counting problem for DNF
formulas, which admits an FPRAS, we prove that no such FPRAS exists (under widely

 
 
 
 
 
 
Arenas, Barcel´o, Bertossi, Monet

believed complexity assumptions) for the computation of SHAP-scores. Surprisingly, this
negative result holds even for the class of monotone formulas in DNF. These techniques
can be further extended to prove another strong negative result: Under widely believed
complexity assumptions, there is no polynomial-time algorithm that checks, given a mono-
tone DNF formula ϕ and features x, y, whether the SHAP-score of x in ϕ is smaller than
the SHAP-score of y in ϕ.
Keywords: Explainable AI, Shapley values, SHAP score, knowledge compilation, FPRAS

1. Introduction

Context. Explainable artiﬁcial intelligence has become an active area of research. Central
to it is the observation that artiﬁcial intelligence (AI) and machine learning (ML) models
cannot always be blindly applied without being able to interpret or explain their results. For
example, someone who applies for a loan and sees the application rejected by an algorith-
mic decision-making system would like to receive from the system an explanation for this
decision. In ML, explanations have been commonly considered for classiﬁcation algorithms,
and there are diﬀerent approaches.
In particular, explanations can be global – focusing
on the general input/output relation of the model –, or local – focusing on how individual
features aﬀect the decision of the model for a speciﬁc input, as in the loan example above
(Ribeiro et al., 2016; Lundberg and Lee, 2017; Chen et al., 2018; Bertossi et al., 2020).
Recent literature has strengthened the importance of the latter by showing their ability to
provide explanations that are often overlooked by global explanations (Molnar, 2020). In
this work we concentrate on local explanations.

One way to deﬁne local explanations is by considering feature values as players in a
coalition game that jointly contribute to the outcome. More concretely, one treats a fea-
ture value’s contribution from the viewpoint of game theory, and ties it to the question
of how to properly distribute wealth (proﬁt) among collaborating players. This problem
was approached in general terms in Shapley (1953). One can use the established concepts
and techniques that he introduced in the context of cooperative game theory; and, more
speciﬁcally, use the popular Shapley value as a measure of the contribution of a player to
the common wealth associated with a multi-player game. It is well known that the Shapley
value possesses properties that cast it as natural and intuitive. Actually, the Shapley value
emerges as the only function that enjoys those desirable properties (Roth, 1988). The Shap-
ley value has been widely applied in diﬀerent disciplines, in particular in computer science
(Hunter and Konieczny, 2010; Michalak et al., 2013; Cesari et al., 2018; Livshits et al.,
2020, 2021); and in machine learning it has been applied to the explanation of classiﬁcation
results, in its incarnation as the SHAP-score (Lundberg and Lee, 2017; Lundberg et al.,
2020). Here, the players are the feature values of an entity under classiﬁcation.

In this paper, we concentrate on the SHAP-score for classiﬁcation models. It has a clear,
intuitive, combinatorial meaning, and inherits all the good properties of the Shapley value.
Accordingly, an explanation for a classiﬁcation result takes the form of a set of feature
values that have a high, hopefully maximum, SHAP-score. We remark that SHAP-scores
have attracted the attention of the ML community and have found several applications and
extensions (Rathi, 2019; Fidel et al., 2020; Bertossi et al., 2020; Merrick and Taly, 2020;
Takeishi and Kawahara, 2020; Covert and Lee, 2021; Kumar et al., 2020). However, its
fundamental and computational properties have not been investigated much.

2

Complexity of SHAP-Score-Based Explanations

Problems studied in the paper. For a given classiﬁcation model M , entity e and
feature x, the SHAP-score SHAP(M, e, x) intuitively represents the importance of the feature
value e(x) to the classiﬁcation result M (e). In its general formulation, SHAP(M, e, x) is
a weighted average of diﬀerences of expected values of the outcomes (c.f. Section 2 for its
formal deﬁnition). Unfortunately, computing quantities that are based on the notion of
Shapley value is in general intractable. Indeed, in many scenarios the computation turns
out to be #P-hard (Faigle and Kern, 1992; Deng and Papadimitriou, 1994; Livshits et al.,
2021; Bertossi et al., 2020), which makes the notion diﬃcult to use – if not impossible – for
practical purposes (Arora and Barak, 2009). Therefore, natural questions are: “For what
kinds of classiﬁcation models the computation of the SHAP-score can be done eﬃciently?”,
“Can one obtain lower computational complexity if one has access to the internals of the
classiﬁcation model?”, or again “In cases where exact computation is intractable, can we
eﬃciently approximate the SHAP-score?”.

In Lundberg et al. (2020) the claim is made that for certain models based on decision
trees the computation of the SHAP-score is tractable. In this work we go deeper into these
results, in particular, formulating and establishing them in precise terms, and extending
them for a larger class of classiﬁcation models. We also identify classes of models for
which SHAP-score computation is intractable. In such cases, we investigate the problem of
existence and computation of a good approximation in the form of a fully polynomial-time
randomized approximation scheme (FPRAS). Recall that FPRAS are tractable procedures
that return an answer that is, with high probability, close to the correct answer.

Given the high computational complexity of the SHAP-score, one might try to solve
related problems, other than the exact and approximate computation of all the features’
scores, that could still be useful in practice. For instance, we consider the problem that
consists in deciding, for a pair of feature values, which of the two has the highest score. This
problem could indeed be used to compute a ranking of (all or the highest) SHAP-scores,
without computing them explicitly. We also address this problem in this paper.

Model studied in the paper. We focus mainly on binary classiﬁers with binary feature
values (i.e., propositional features that can take the values 0 or 1), and that return 1
(accept) or 0 (reject) for each entity. We will call these Boolean classiﬁers. The restriction
to binary inputs can be relevant in many practical scenarios where the features are of a
propositional nature. Still, we consider classiﬁers with possibly non-binary features, but
binary outcomes, in Section 4. The second assumption that we make is that the underlying
probability distributions on the population of entities are what we call product distributions,
where each binary feature x has a probability p(x) of being equal to 1, independently of the
other feature values. This includes, as a special case, the uniform probability distribution
when each p(x) is 1
2 . Product distributions are also known as fully-factorized in the literature
(Van den Broeck et al., 2021, 2022). They have received considerable attention in the context
of computing score-based explanations, as they combine good computational properties with
enough ﬂexibility to model relevant practical scenarios (Strumbelj and Kononenko, 2010;
Datta et al., 2016; Lundberg and Lee, 2017).

Positive results on the complexity of computation of SHAP-scores in the paper are
obtained for Boolean classiﬁers deﬁned as deterministic and decomposable Boolean circuits.
This is a widely studied model in knowledge compilation (Darwiche, 2001; Darwiche and

3

Arenas, Barcel´o, Bertossi, Monet

Marquis, 2002). Such circuits encompass a wide range of Boolean circuits and binary
decision diagrams classes that are considered in knowledge compilation, and more generally
in AI. For instance, they generalize binary decision trees, ordered binary decision diagrams
(OBDDs), free binary decision diagrams (FBDDs), and deterministic and decomposable
negation normal norms (d-DNNFs) (Darwiche, 2001; Amarilli et al., 2020; Darwiche and
Hirth, 2020). These circuits are also known under the name of tractable Boolean circuits,
that is used in recent literature (Shih et al., 2019a; Shi et al., 2020; Shih et al., 2018a,b,
2019b; Peharz et al., 2020). Readers who are not familiar with knowledge compilation
can simply think about deterministic and decomposable circuits as a tool for analyzing
in a uniform manner the computational complexity of the SHAP-score on several Boolean
classiﬁer classes.

In turn, our negative results on the complexity of computation of SHAP-scores in the
paper are obtained over the class of propositional formulas in DNF. In addition to being
a well-known restriction of the class of propositional formulas for which the satisﬁability
problem is tractable, DNF formulas deﬁne an extension of deterministic and decompos-
able Boolean circuits. In fact, DNF formulas can be seen as decomposable, although not
necessarily deterministic, Boolean circuits.

Our results. Our main contributions are the following.

1. Tractability for a large class of Boolean classiﬁers. We provide a polynomial time al-
gorithm that computes the SHAP-score for deterministic and decomposable Boolean
circuits under product distributions over the entity population (Theorem 2). We ob-
tain as a corollary that the SHAP-score for Boolean classiﬁers given as binary decision
trees, OBDDs, FBDDs and d-DNNFs can be computed in polynomial time.

2. Tractability for non-binary classiﬁers. We extend the aforementioned tractability
result to the case of classiﬁers with non-binary features, which take the form of non-
binary Boolean circuits (Theorem 5). In these circuits, the nodes may now contain
equalities of the form x = v, where x is a feature, and v is a value in the domain of x.
The outcome of the classiﬁer is still binary.

3. Limits of tractability. We observe that, under a mild condition, computing the SHAP-
score on Boolean classiﬁers in a class is always polynomially as hard as the model
counting problem for that class (Lemma 7). This leads to intractability for the prob-
lem of computing the SHAP-score for all classes of Boolean classiﬁers for which model
counting is intractable. An important example of this corresponds to the class of
propositional formulas in DNF. As a corollary, we obtain that each one of the deter-
minism assumption and the decomposability assumption is necessary for tractability
(Theorem 6). These results even hold for the uniform distribution.

4. Non-approximability for DNF formulas. We give a simple proof that, under widely be-
lieved complexity assumptions, there is no FPRAS for the computation of the SHAP-
score with Boolean classiﬁers represented as DNF formulas (Proposition 8). This
holds even under the uniform distribution. This result establishes a stark contrast
with the model counting problem for DNF formulas, which admits an FPRAS (Karp
et al., 1989). We further strengthen this by showing that the non-approximability

4

Complexity of SHAP-Score-Based Explanations

result even holds for Boolean formulas represented as 2-POS-DNF, i.e., with every
conjunct containing at most two positive literals (and no negative literal), and for the
uniform distribution (Theorem 9). The proof of this last result is quite involved and
is based on a non-approximability result in relation to the size of cliques in graphs
(Feige et al., 1996; Arora and Safra, 1998; Arora et al., 1998).

5. Impossibility of comparing SHAP-scores for DNF formulas. Consider the problem of
verifying, given a DNF formula ϕ and features x, y, whether the SHAP-score of x
in ϕ is smaller than the SHAP-score of y in ϕ. Under widely believed complexity
assumptions, we establish that this problem of comparing two SHAP-scores cannot
be approximated in polynomial time, even for the case of monotone DNF formulas
(Theorem 16).

Related work. Our contributions should be compared to the results obtained in contem-
poraneous papers by Van den Broeck et al. (Van den Broeck et al., 2021, 2022). There, the
authors establish the following theorem: for every class C of classiﬁers and under product
distributions, the problem of computing the SHAP-score for C is polynomial-time equivalent
to the problem of computing the expected value for the models in C (at least under mild as-
sumptions on C). Since computing expectations is in polynomial time for tractable Boolean
circuits, this in particular implies that computing the SHAP-score is in polynomial time for
the circuits that we consider; in other words, their results capture our main positive result.
However, there is a fundamental diﬀerence in the approach taken to show tractability: their
reduction uses multiple oracle calls to the problem of computing expectations, whereas we
provide a more direct algorithm to compute the SHAP-score on these circuits.

The exact computation or approximation of the Shapley value applied to database tu-
ples is investigated in Livshits et al. (2021); Deutch et al. (2022). In Bertossi et al. (2020),
approximations of the SHAP-score are used for experimental purposes and comparisons with
other scores, such as RESP and Rudin’s FICO-score (Chen et al., 2018). However, an em-
pirical distribution is used for the approximate computation of the SHAP-score, which leads
to a simple, non-probabilistic weighted average, and to the restriction of the counterfactual
versions of an entity to those in the available sample. In Bertossi and Leon (2023), the
algorithm presented in our work (c.f. Section 3.1.3) has been used to eﬃciently compute
SHAP-scores, under the uniform distribution, for outcomes from binary neural networks,
after compiling the latter into deterministic and decomposable Boolean circuits.

Building on Livshits et al. (2021) and on the conference version of the current article,
the authors of Deutch et al. (2022) use knowledge compilation techniques that are similar to
ours to develop a polynomial-time algorithm that is able to compute a version of the Shapley
value tailored to a database context. They moreover propose an algorithm for computing
approximations of the Shapley values of tuples, but this algorithm does not come with any
theoretical guarantees.

Last, regarding approximation, there is a large body of work that aims at approximating
Shapley values using Monte Carlo techniques, see for instance Castro et al. (2009); Okhrati
and Lipani (2021); Deutch et al. (2021); Mitchell et al. (2022). The results of such works
are upper bounds for diverse settings of Shapley values – i.e., considering diﬀerent game
functions – but we are not aware of such results for the speciﬁc game function (the SHAP-
score) that we study here, for instance, theoretical results that would yield an FPRAS for

5

Arenas, Barcel´o, Bertossi, Monet

the SHAP-score. Besides, these studies do not usually contain lower bounds, since their
focus is on obtaining tractable approximations via Monte Carlo or other sampling schemes.
By contrast, obtaining lower bounds is the topic of our Sections 6 and 7, where we show the
non-existence of an FPRAS for approximating the SHAP-score of DNF formulas, as well as
the non-membership in BPP of comparing SHAP-scores for such formulas.

This paper is a considerable extension of the conference paper (Arenas et al., 2021).
In addition to containing full proofs of all the results of (Arenas et al., 2021), we present
here several new results. Among them, we provide a detailed analysis of approximability of
the SHAP-score, a complexity analysis of the problem of comparing SHAP-scores, and an
extension of the results for deterministic and decomposable Boolean circuits to the case of
non-binary features.

Paper structure. We give preliminaries in Section 2. In Section 3, we prove that the
SHAP-score can be computed in polynomial time for deterministic and decomposable Bool-
ean circuits under product probability distributions. We extend this tractability result in
Section 4 to non-binary deterministic and decomposable Boolean circuits. In Section 5, we
establish the computational limits of the exact computation of the SHAP-score, while Sec-
tion 6 studies the (non-) approximability properties of this score. The problem of comparing
the SHAP-scores of diﬀerent features is studied in Section 7. We conclude and discuss future
work in Section 8.

2. Preliminaries

2.1 Entities, distributions and classiﬁers

Let X be a ﬁnite set of binary1 features, also called variables. An entity over X is a func-
tion e : X → {0, 1}.2 We denote by ent(X) the set of all entities over X. On this set,
we consider probability distributions that we call product distributions, deﬁned as follows.
Let p : X → [0, 1] be a function that associates to every feature x ∈ X a probability
value p(x) ∈ [0, 1]. Then, the product distribution generated by p is the probability distri-
bution Πp over ent(X) such that, for every e ∈ ent(X) we have

Πp(e)

:=

(cid:18) (cid:89)

(cid:19)

p(x)

·

(cid:18) (cid:89)

(1 − p(x))

(cid:19)
.

x∈X
e(x)=1

x∈X
e(x)=0

That is, Πp is the product distribution that is determined by pre-speciﬁed marginal dis-
tributions, and that makes the features take values independently from each other. We
denote by U the uniform probability distribution, i.e., for every entity e ∈ ent(X), we have
that U(e) := 1
2|X| . Note that the uniform distribution can be obtained as a special case of
product distribution, with Πp invoking p(x) := 1/2 for every x ∈ X.

A Boolean classiﬁer M over X is a function M : ent(X) → {0, 1} that maps every entity
over X to 0 or 1. We say that M accepts an entity e when M (e) = 1, and that it rejects it

1. We will come back to this assumption in Section 4, where we will consider non-binary features.
2. Equivalently, one can see an entity as a vector of binary values, with each coordinate corresponding to
a given feature. We will however always use the functional point of view as it simpliﬁes the notation in
our proofs.

6

Complexity of SHAP-Score-Based Explanations

if M (e) = 0. Since we consider ent(X) to be a probability space, M can be regarded as a
random variable.

2.2 The SHAP-score over Boolean classiﬁers

Let M : ent(X) → {0, 1} be a Boolean classiﬁer over the set X of features. Given an
entity e over X and a subset S ⊆ X of features, we deﬁne the set cw(e, S) of entities that
are consistent with e on S as cw(e, S) := {e(cid:48) ∈ ent(X) | e(cid:48)(x) = e(x) for each x ∈ S}. Then,
given an entity e ∈ ent(X), a probability distribution D over ent(X), and S ⊆ X, we deﬁne
the expected value of M over X \ S with respect to e under D as

φD(M, e, S) := Ee(cid:48)∼D

(cid:2)M (e(cid:48)) | e(cid:48) ∈ cw(e, S)(cid:3).

In other words, φD(M, e, S) is the expected value of M , conditioned on the inputs to coincide
with e over each feature in S. For instance, if we take D to be the uniform distribution U
over ent(X), this expression simpliﬁes to

φU (M, e, S) =

(cid:88)

e(cid:48)∈cw(e,S)

1
2|X\S|

M (e(cid:48)).

The function φD is then used in the general formula of the Shapley value (Shapley, 1953;
Roth, 1988) to obtain the SHAP-score for feature values in e, as follows.

Deﬁnition 1 (Lundberg and Lee (2017)) Given a Boolean classiﬁer M over a set of
features X, a probability distribution D on ent(X), an entity e over X, and a feature x ∈ X,
the SHAP score of feature x on e with respect to M under D is deﬁned as

SHAPD(M, e, x) :=

(cid:88)

S⊆X\{x}

|S|! (|X| − |S| − 1)!
|X|!

(cid:18)

φD(M, e, S∪{x})−φD(M, e, S)

.

(1)

(cid:19)

In Section 5, we will use another equivalent expression of the SHAP-score, that we introduce
now. For a permutation π : X → {1, . . . , n} and x ∈ X, let Sx
π denote the set of features that
appear before x in π. Formally, Sx
π := {y ∈ X | π(y) < π(x)}. Then, letting Π(X) be the
set of all permutations π : X → {1, . . . , n}, observe that Equation (1) can be rewritten as

SHAPD(M, e, x) =

1
|X|!

(cid:88)

π∈Π(X)

(cid:0)φD(M, e, Sx

π ∪ {x}) − φD(M, e, Sx

π)(cid:1).

(2)

Thus, SHAPD(M, e, x) is a weighted average of the contribution of feature x on e to the
classiﬁcation result, i.e., of the diﬀerences between having it and not, under all possible
permutations of the other feature values. Observe that, from this deﬁnition, a high positive
value of SHAPD(M, e, x) intuitively means that setting x to e(x) strongly leans the classiﬁer
towards acceptance, while a high negative value of SHAPD(M, e, x) means that setting x
to e(x) strongly leans the classiﬁer towards rejection.

7

Arenas, Barcel´o, Bertossi, Monet

2.3 Deterministic and decomposable Boolean circuits

A Boolean circuit over a set of variables X is a directed acyclic graph C such that

(i) Every node without incoming edges is either a variable gate or a constant gate. A
variable gate is labeled with a variable from X, and a constant gate is labeled with
either 0 or 1;

(ii) Every node with incoming edges is a logic gate, and is labeled with a symbol ∧, ∨
or ¬. If it is labeled with the symbol ¬, then it has exactly one incoming edge;3

(iii) Exactly one node does not have any outgoing edges, and this node is called the output

gate of C.

Such a Boolean circuit C represents a Boolean classiﬁer in the expected way – we assume
the reader to be familiar with Boolean logic –, and we write C(e) for the value in {0, 1} of
the output gate of C when we evaluate C over the entity e. We consider the size |C| of
the circuit to be its number of edges. Observe that, thanks to condition (iii), the number
of gates of C is at most its number of edges plus one.

Several restrictions of Boolean circuits with good computational properties have been
studied. Let C be a Boolean circuit over a set of variables X and g a gate of C. The
Boolean circuit Cg over X is deﬁned by considering the subgraph of C induced by the set of
gates g(cid:48) in C for which there exists a path from g(cid:48) to g in C. Notice that g is the output gate
of Cg. Then, an ∨-gate g of C is said to be deterministic if for every pair g1, g2 of distinct
input gates of g, the Boolean circuits Cg1 and Cg2 are disjoint in the sense that there is no
entity e that is accepted by both Cg1 and Cg2 (that is, there is no entity e ∈ ent(X) such
that Cg1(e) = Cg2(e) = 1). The circuit C is called deterministic if every ∨-gate of C is
deterministic. The set var(g) is deﬁned as the set of variables x ∈ X such that there exists
a variable gate with label x in Cg. An ∧-gate g of C is said to be decomposable, if for every
pair g1, g2 of distinct input gates of g, we have that var(g1) ∩ var(g2) = ∅. Then C is called
decomposable if every ∧-gate of C is decomposable.

Example 1 We want to classify papers submitted to a conference as rejected (Boolean
value 0) or accepted (Boolean value 1). Papers are described by propositional features
fg, dtr, nf and na, which stand for “follows guidelines”, “deep theoretical result”, “new
framework” and “nice applications”, respectively. The Boolean classiﬁer for the papers is
given by the Boolean circuit in Figure 1. The input of this circuit are the features fg, dtr,
nf and na, each of which can take value either 0 or 1, depending on whether the feature is
present (1) or absent (0). The nodes with labels ¬, ∨ or ∧ are logic gates, and the associated
Boolean value of each one of them depends on the logical connective represented by its label
and the Boolean values of its inputs. The output value of the circuit is given by the top
node in the ﬁgure.

The Boolean circuit in Figure 1 is decomposable, because for each ∧-gate the sets of
features of its inputs are pairwise disjoint. For instance, in the case of the top node in
Figure 1, the left-hand side input has {fg} as its set of features, while its right-hand side input

3. Recall that the fan-in of a gate is the number of its input gates. In our deﬁnition of Boolean circuits, we

allow unbounded fan-in ∧- and ∨-gates.

8

Complexity of SHAP-Score-Based Explanations

fg

∧

dtr

∨

¬

nf

∧

na

Figure 1: A deterministic and decomposable Boolean Circuit as a classiﬁer.

has {dtr, nf, na} as its set of features, which are disjoint. Also, this circuit is deterministic
as for every ∨-gate two (or more) of its inputs cannot be given value 1 by the same Boolean
assignment for the features. For instance, in the case of the only ∨-gate in Figure 1, if a
Boolean assignment for the features gives value 1 to its left-hand side input, then feature
dtr has to be given value 1 and, thus, such an assignment gives value 0 to the right-hand
side input of the ∨-gate. In the same way, it can be shown that if a Boolean assignment for
the features gives value 1 to the right-hand side input of this ∨-gate, then it gives value 0
(cid:3)
to its left-hand side input.

We will use the fact that deterministic and decomposable Boolean circuits are closed
under conditioning. Let C be a Boolean circuit over variables X, and let x ∈ X. We
denote by C+x (resp., C−x) the Boolean circuit that is obtained from C by replacing every
variable gate that is labeled with x by a constant 1-gate (resp, by a constant 0-gate). In
the literature, C+x (resp., C−x) is called the conditioning by x (resp., by ¬x) of C. It is
easy to check that, if C is deterministic and decomposable, then so are C+x and C−x.

As mentioned in the introduction, deterministic and decomposable Boolean circuits
generalize many decision diagrams and Boolean circuits classes. We refer to (Darwiche,
2001; Amarilli et al., 2020) for detailed studies of knowledge compilation classes and of their
precise relationships. For the reader’s convenience, we explain in Appendix A how FBDDs
and binary decision trees can be encoded in linear time as deterministic and decomposable
Boolean circuits.

2.4 Complexity classes and encoding of probability values
In Section 5, we will consider the counting complexity class #P (Valiant, 1979) of prob-
lems that can be expressed as the number of accepting paths of a nondeterministic Turing
machine running in polynomial time. Following Valiant (1979), we deﬁne #P-hardness us-
ing Turing reductions. Prototypical examples of #P-complete problems are counting the
number of assignments that satisfy a propositional formula and counting the number of
three-colorings of a graph. While it is known that FPTIME ⊆ #P, where FPTIME is
the class of functions that can be computed in polynomial time, this inclusion is widely
believed to be strict. Therefore, proving that a problem is #P-hard implies, under such an
assumption, that it cannot be solved in polynomial time.

9

Arenas, Barcel´o, Bertossi, Monet

In Sections 6 and 7 we will use the complexity classes RP and BPP. Recall that RP
is the class of decision problems L for which there exists a polynomial-time probabilistic
Turing Machine M such that: (a) if x ∈ L, then M accepts with probability at least 3/4;
and (b) if x (cid:54)∈ L, then M does not accept x. Moreover, BPP is deﬁned exactly as RP but
with condition (b) replaced by: (b’) if x (cid:54)∈ L, then M accepts with probability at most 1/4.
Thus, BPP is deﬁned as RP but allowing errors for both the elements that are and are not
in L. Hence, PTIME ⊆ RP ⊆ BPP by deﬁnition. Besides, it is known that RP ⊆ NP, and
this inclusion is widely believed to be strict. Finally, it is not known whether BPP ⊆ NP
or NP ⊆ BPP, but it is widely believed that NP is not included in BPP.

Finally, when considering problems where probabilities can be part of the input (such
as in Theorem 2 or Theorem 5), it will always be implicit that such probabilities are given
as rational numbers p/q for p, q ∈ N, encoded as ordered pairs (p, q) where p and q are
themselves encoded in binary.

3. Tractable Computation of the SHAP-Score

In this section we prove our main tractability result, namely, that computing the SHAP-
score for Boolean classiﬁers given as deterministic and decomposable Boolean circuits can
be done in polynomial time for product probability distributions.

Theorem 2 Given as input a deterministic and decomposable circuit C over a set of fea-
tures X, rational probability values p(x) for every feature x ∈ X, an entity e : X → {0, 1},
and a feature x ∈ X, the value SHAPΠp(C, e, x) can be computed in polynomial time.

In particular, since binary decision trees, OBDDs, FBDDs and d-DNNFs are all re-
stricted types of deterministic and decomposable circuits, we obtain as a consequence of
Theorem 2 that this problem is also in polynomial time for these classes. For instance, for
binary decision trees we obtain the following result.

Corollary 3 Given as input a binary decision tree T over a set of features X, rational
probability values p(x) for every feature x ∈ X, an entity e : X → {0, 1}, and a feature x ∈
X, the value SHAPΠp(T, e, x) can be computed in polynomial time.

The authors of (Lundberg et al., 2020) provide an algorithm for computing the SHAP-
score in polynomial time for decision trees, but, unfortunately, as stated in (Van den Broeck
et al., 2021), this algorithm is not correct. Moreover, it is important to notice that The-
orem 2 is a nontrivial extension of the result for decision trees, as it is known that deter-
ministic and decomposable circuits can be exponentially more succinct than binary decision
trees (in fact, than FBDDs) at representing Boolean classiﬁers (Darwiche, 2001; Amarilli
et al., 2020).

We prove Theorem 2 in the remaining of this section. First, we prove in Section 3.1 that
the problem can be solved in polynomial time, and we extract from this proof a ﬁrst version
of our algorithm. Then, in Section 3.2, we provide an optimized version of this algorithm,
and argue why the proposed optimization reduces the complexity of the algorithm.

10

Complexity of SHAP-Score-Based Explanations

3.1 Polynomial time computability proof

In this section we prove that the SHAP-score can be computed in polynomial time. For
a Boolean classiﬁer M over a set of variables X, probability distribution D over ent(X),
entity e ∈ ent(X), and natural number k ≤ |X|, we deﬁne the quantity

HD(M, e, k) :=

(cid:88)

S⊆X
|S|=k

Ee(cid:48)∼D[M (e(cid:48)) | e(cid:48) ∈ cw(e, S)].

Our proof of Theorem 2 is divided into two modular parts. The ﬁrst part, which is
developed in Section 3.1.1, consists in showing that the problem of computing SHAPΠ·(·, ·, ·)
can be reduced in polynomial time to that of computing HΠ·(·, ·, ·). This part of the proof
is a sequence of formula manipulations, and it only uses the fact that deterministic and
decomposable circuits are closed under conditioning on a variable value (recall the deﬁnition
In the second part of the proof, which is developed
of conditioning from Section 2.3).
in Section 3.1.2, we show that computing HΠ·(·, ·, ·) can be done in polynomial time for
deterministic and decomposable Boolean circuits. It is in this part that the properties of
deterministic and decomposable circuits are used. Finally, we extract Algorithm 1 from this
proof in Section 3.1.3.

3.1.1 Reducing in polynomial-time from SHAPΠ·(·, ·, ·) to HΠ·(·, ·, ·)
In this section we show that for deterministic and decomposable Boolean circuits, and under
product distributions, the computation of the SHAP-score can be reduced in polynomial
time to the computation of HΠ·(·, ·, ·).

Suppose then that we wish to compute SHAPΠp(C, e, x), for a given deterministic and
decomposable circuit C over a set of variables X, probability mapping p : X → [0, 1],
entity e ∈ ent(X), and feature x ∈ X. Deﬁne

Diﬀk(C, e, x) :=

(cid:88)

(φΠp(C, e, S ∪ {x}) − φΠp(C, e, S)),

S⊆X\{x}
|S|=k

and let n = |X|. We then have, by deﬁnition, that

SHAPΠp(C, e, x) =

(cid:88)

S⊆X\{x}

|S|!(n − |S| − 1)!
n!

(φΠp(C, e, S ∪ {x}) − φΠp(C, e, S))

=

=

n−1
(cid:88)

k=0

n−1
(cid:88)

k=0

k!(n − k − 1)!
n!

(cid:88)

S⊆X\{x}
|S|=k

(φΠp(C, e, S ∪ {x}) − φΠp(C, e, S))

k!(n − k − 1)!
n!

Diﬀk(C, e, x).

(3)

Observe that all arithmetical terms (such as k! or n!) can be computed in polynomial
time: this is simply because n is given in unary, as it is bounded by the size of the cir-

11

Arenas, Barcel´o, Bertossi, Monet

cuit. Therefore, it is good enough to show how to compute in polynomial time the quanti-
ties Diﬀk(C, e, x) for each k ∈ {0, . . . , n − 1}. By deﬁnition of φΠ·
(cid:21)
Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S ∪ {x})]

(·, ·, ·) we have that

Diﬀk(C, e, x) =

(cid:20) (cid:88)

S⊆X\{x}
|S|=k

(cid:20) (cid:88)

−

(cid:21)
Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S)]

.

(4)

S⊆X\{x}
|S|=k

In this expression, let L and R be the left- and right-hand side terms in the subtraction.
Looking closer at R, we have by standard properties of conditional expectation that

R =

(cid:88)

Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S)]

S⊆X\{x}
|S|=k

= p(x) ·

(cid:88)

S⊆X\{x}
|S|=k

Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S) and e(cid:48)(x) = 1]

+ (1 − p(x)) ·

(cid:88)

S⊆X\{x}
|S|=k

Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S) and e(cid:48)(x) = 0].

To continue, we need to introduce some notation. For a set of features X and S ⊆ X,
we write p|S : S → [0, 1] for the mapping that is the restriction of p to S, and Πp|S :
ent(S) → [0, 1] for the corresponding product distribution on ent(S). Similarly, for an
entity e ∈ ent(X) and S ⊆ X, let e|S be the entity over S that is obtained by restricting e
to the domain S (that is, formally e|S ∈ ent(S) and e|S(y) := e(y) for every y ∈ S). Now,
remembering from Section 2.3 the deﬁnition of C+x and C−x, we obtain that

R = p(x) ·

(cid:88)

Ee(cid:48)(cid:48)∼Πp|X\{x}

[C+x(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|X\{x}, S)]

S⊆X\{x}
|S|=k

+ (1 − p(x)) ·

(cid:88)

S⊆X\{x}
|S|=k

Ee(cid:48)(cid:48)∼Πp|X\{x}

[C−x(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|X\{x}, S)]

= p(x) · HΠp|X\{x}

(C+x, e|X\{x}, k) + (1 − p(x)) · HΠp|X\{x}

(C−x, e|X\{x}, k),

(5)

where the last equality is obtained simply by using the deﬁnition of HΠ·(·, ·, ·). Hence, if we
could compute in polynomial time HΠ·(·, ·, ·) for deterministic and decomposable Boolean
circuits, then we could compute R in polynomial time as C+x and C−x can be computed in
linear time from C, and they are deterministic and decomposable Boolean circuits as well.

We now inspect the term L, which we recall is

L =

(cid:88)

Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S ∪ {x})].

S⊆X\{x}
|S|=k

12

Complexity of SHAP-Score-Based Explanations

Observe that, for S ⊆ X \ {x} and e(cid:48) ∈ cw(e, S ∪ {x}), it holds that

C(e(cid:48)) =

Therefore, if e(x) = 1, we have that

(cid:40)

C+x(e(cid:48)
C−x(e(cid:48)

|X\{x})
|X\{x})

if e(x) = 1

if e(x) = 0

.

L =

(cid:88)

Ee(cid:48)(cid:48)∼Πp|X\{x}

[C+x(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|X\{x}, S)]

S⊆X\{x}
|S|=k
= HΠp|X\{x}

(C+x, e|X\{x}, k)

whereas if e(x) = 0, we have that

L = HΠp|X\{x}

(C−x, e|X\{x}, k).

(6)

(7)

Hence, again, if we were able to compute in polynomial time HΠ·(·, ·, ·) for deterministic
and decomposable Boolean circuits, then we could compute L in polynomial time (as deter-
ministic and decomposable Boolean circuits C+x and C−x can be computed in linear time
from C). But then we deduce from (4) that Diﬀk(C, e, x) could be computed in polyno-
mial time for each k ∈ {0, . . . , n − 1}, from which we have that SHAPΠp(C, e, x) could be
computed in polynomial time (by Equation (3)), therefore concluding the existence of the
reduction claimed in this section.

3.1.2 Computing HΠ·(·, ·, ·) in polynomial time
We now take care of the second part of the proof of tractability, i.e., proving that comput-
ing HΠ·(·, ·, ·) for deterministic and decomposable Boolean circuits can be done in polynomial
time. Formally, in this section we prove the following lemma:

Lemma 4 The following problem can be solved in polynomial time. Given as input a deter-
ministic and decomposable Boolean circuit C over a set of variables X, rational probability
values p(x) for each x ∈ X, an entity e ∈ ent(X), and a natural number k ≤ |X|, compute
the quantity HΠp(C, e, k).

We ﬁrst perform two preprocessing steps on C.

Rewriting to fan-in 2. First, we modify the circuit C so that the fan-in of every ∨- and ∧-
gate is exactly 2. This can be done in linear time simply by rewriting every ∧-gate
(resp., and ∨-gate) of fan-in m > 2 with a chain of m − 1 ∧-gates (resp., ∨-gates)
of fan-in 2, and by attaching to each ∧ or ∨-gate of fan-in 1 a constant gate of the
appropriate type. It is clear that the resulting Boolean circuit is deterministic and
decomposable. Hence, from now on we assume that the fan-in of every ∨- and ∧-gate
of C is exactly 2.

Smoothing the circuit. A deterministic and decomposable circuit C is smooth (Dar-
wiche, 2001; Shih et al., 2019b) if for every ∨-gate g and input gates g1, g2 of g, we

13

Arenas, Barcel´o, Bertossi, Monet

have that var(g1) = var(g2) (we call such an ∨-gate smooth). Recall that by the previ-
ous paragraph, we assume that the fan-in of every ∨-gate is exactly 2. We then repeat
the following operation until C becomes smooth. For an ∨-gate g of C having two
input gates g1, g2 violating the smoothness condition, deﬁne S1 := var(g1) \ var(g2)
and S2 := var(g2) \ var(g1), and let dS1, dS2 be Boolean circuits deﬁned as follows.
If S1 = ∅, then dS1 consist of the single constant 1-gate. Otherwise, dS1 encodes the
propositional formula ∧x∈S1(x∨¬x) but it is constructed as a circuit in such a way that
every ∧- and ∨-gate has fan-in exactly 2. Boolean circuit dS2 is constructed exactly
as dS1 but considering the set of variables S2 instead of S1. Observe that var(dS1) = S1,
var(dS2) = S2, that dS1 and dS2 always evaluate to 1, and that all ∨-gates appearing
in dS1 and in dS2 are deterministic. Then, we transform g into a smooth ∨-gate by re-
placing gate g1 by a decomposable ∧-gate (g1 ∧dS2), and gate g2 by a decomposable ∧-
gate (g2 ∧ dS1). Clearly, this does not change the Boolean classiﬁer computed, and g is
again deterministic because g1 and (g1∧dS2) (resp., g2 and (g2∧dS1)) capture the same
Boolean classiﬁer. Moreover, since var(g1 ∧ dS2) = var(g2 ∧ dS1) = var(g1) ∪ var(g2), we
have that g is now smooth. Therefore, the circuit that we obtain after this operation
is equivalent to the one we started from, is again deterministic and decomposable,
and contains one less non-smooth ∨-gate. Hence, by repeating this operation for each
non-smooth ∨-gate, which we can do in polynomial time, we obtain an equivalent
smooth deterministic and decomposable circuit where each ∨- and ∧-gate has fan-in
exactly 2. Thus, from now on we also assume that C is smooth.

For a gate g of C, let Rg be the Boolean circuit over var(g) that is deﬁned by considering
the subgraph of C induced by the set of gates g(cid:48) in C for which there exists a path from g(cid:48)
to g in C.4 Notice that Rg is a deterministic and decomposable Boolean circuit with
output gate g. Moreover, for a gate g and natural number (cid:96) ≤ |var(g)|, deﬁne α(cid:96)
g :=
(Rg, e|var(g), (cid:96)), which we recall is equal, by deﬁnition of HΠ·(·, ·, ·), to
HΠp|var(g)

HΠp|var(g)

(Rg, e|var(g), (cid:96)) =

(cid:88)

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[Rg(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)].

We will show how to compute all the values α(cid:96)
g for every gate g of C and (cid:96) ∈ {0, . . . , |var(g)|}
in polynomial time. This will conclude the proof of Lemma 4 since, for the output gate gout
of C, we have that αk
gout = HΠp(C, e, k). Next we explain how to compute these values by
bottom-up induction on C.

Variable gate. g is a variable gate with label y ∈ X, so that var(g) = {y}. Then for e(cid:48) ∈

ent({y}) we have Rg(e(cid:48)) = e(cid:48)(y), therefore

α0

g =

(cid:88)

S⊆{y}
|S|=0

Ee(cid:48)∼Πp|{y}

[e(cid:48)(y) | e(cid:48) ∈ cw(e|{y}, S)]

= Ee(cid:48)∼Πp|{y}

[e(cid:48)(y) | e(cid:48) ∈ cw(e|{y}, ∅)]

4. The only diﬀerence between Rg and Cg (deﬁned in Section 2) is that we formally regard Rg as a Boolean

classiﬁer over var(g), while we formally regarded Cg as a Boolean classiﬁer over X.

14

Complexity of SHAP-Score-Based Explanations

= Ee(cid:48)∼Πp|{y}
= 1 · p(y) + 0 · (1 − p(y))

[e(cid:48)(y)]

= p(y)

and

α1

g =

(cid:88)

S⊆{y}
|S|=1

Ee(cid:48)∼Πp|{y}

[e(cid:48)(y) | e(cid:48) ∈ cw(e|{y}, S)]

= Ee(cid:48)∼Πp|{y}
= e(y).

[e(cid:48)(y) | e(cid:48) ∈ cw(e|{y}, {y})]

(8)

(9)

Constant gate. g is a constant gate with label a ∈ {0, 1}, and var(g) = ∅. We recall the
mathematical convention that there is a unique function with the empty domain and,
hence, a unique entity over ∅. But then

α0

g =

(cid:88)

S⊆∅
|S|=0

Ee(cid:48)∼Πp|∅

[a | e(cid:48) ∈ cw(e|∅, S)]

[a | e(cid:48) ∈ cw(e|∅, ∅)]

= Ee(cid:48)∼Πp|∅
= a.

(10)

¬-gate. g is a ¬-gate with input gate g(cid:48). Notice that var(g) = var(g(cid:48)). Then, since for e(cid:48) ∈

ent(var(g)) we have that Rg(e(cid:48)) = 1 − Rg(cid:48)(e(cid:48)), we have

α(cid:96)

g =

(cid:88)

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[1 − Rg(cid:48)(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)].

By linearity of expectations we deduce that

α(cid:96)

g =

(cid:88)

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[1 | e(cid:48) ∈ cw(e|var(g), S)]

Ee(cid:48)∼Πp|var(g)

[Rg(cid:48)(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

(cid:88)

−

S⊆var(g)
|S|=(cid:96)
1(cid:1) − α(cid:96)
g(cid:48)

= (cid:0) (cid:88)

S⊆var(g)
|S|=(cid:96)
(cid:18)|var(g)|
(cid:96)

(cid:19)

=

− α(cid:96)
g(cid:48)

(11)

for every (cid:96) ∈ {0, . . . , |var(g)|}. By induction, the values α(cid:96)
have already been computed. Thus, we can compute all the values α(cid:96)
{0, . . . , |var(g)|} in polynomial time.

g(cid:48) for (cid:96) ∈ {0, . . . , |var(g)|}
g for (cid:96) ∈

15

Arenas, Barcel´o, Bertossi, Monet

∨-gate. g is an ∨-gate. By assumption, recall that g is deterministic, smooth, and has fan-
in exactly 2. Let g1 and g2 be the input gates of g, and recall that var(g1) = var(g2) =
var(g), because g is smooth. Given that g is deterministic, observe that for every e(cid:48) ∈
ent(var(g)) we have Rg(e(cid:48)) = Rg1(e(cid:48)) + Rg2(e(cid:48)). But then for (cid:96) ∈ {0, . . . , |var(g)|} we
have

α(cid:96)

g =

(cid:88)

=

S⊆var(g)
|S|=(cid:96)
(cid:88)

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[Rg1(e(cid:48)) + Rg2(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

Ee(cid:48)∼Πp|var(g)

[Rg1(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

(cid:88)

+

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[Rg2(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

= α(cid:96)

g1 + α(cid:96)

g2,

(12)

where the second equality is by linearity of the expectation, and the last equality is
valid because g is smooth (in particular, we have that var(g1) = var(g2) = var(g)). By
induction, the values α(cid:96)
g1 and α(cid:96)
g2, for each (cid:96) ∈ {0, . . . , |var(g)|}, have already been
computed. Therefore, we can compute all the values α(cid:96)
g for (cid:96) ∈ {0, . . . , |var(g)|} in
polynomial time.

∧-gate. g is an ∧-gate. By assumption, recall that g is decomposable and has fan-in
exactly 2. Let g1 and g2 be the input gates of g. For e(cid:48) ∈ ent(var(g)) we have
that Rg(e(cid:48)) = Rg1(e(cid:48)
|var(g2)). Moreover, since var(g) = var(g1) ∪ var(g2)
and var(g1) ∩ var(g2) = ∅ (because g is decomposable), observe that every S ⊆ var(g)
can be uniquely decomposed into S1 ⊆ var(g1), S2 ⊆ var(g2) such that S = S1 ∪ S2
and S1 ∩ S2 = ∅. Therefore, for (cid:96) ∈ {0, . . . , |var(g)|} we have

|var(g1)) · Rg2(e(cid:48)

α(cid:96)

g =

(cid:88)

(cid:88)

Ee(cid:48)∼Πp|var(g)

S1⊆var(g1)
|S1|≤(cid:96)

S2⊆var(g2)
|S2|=(cid:96)−|S1|

[Rg1(e(cid:48)

|var(g1)) · Rg2(e(cid:48)

|var(g2)) |

e(cid:48) ∈ cw(e|var(g), S1 ∪ S2)].

But, by deﬁnition of the product distribution Πp|var(g) and because g is decomposable,
we have that Rg1(e(cid:48)
|var(g2)) are independent random variables, hence
we deduce

|var(g1)) and Rg2(e(cid:48)

α(cid:96)

g =

(cid:88)

(cid:88)

S1⊆var(g1)
|S1|≤(cid:96)

S2⊆var(g2)
|S2|=(cid:96)−|S1|

(cid:18)
Ee(cid:48)∼Πp|var(g)

[Rg1(e(cid:48)

|var(g1)) | e(cid:48) ∈ cw(e|var(g), S1 ∪ S2)]

· Ee(cid:48)∼Πp|var(g)

[Rg2(e(cid:48)

(cid:19)
|var(g2)) | e(cid:48) ∈ cw(e|var(g), S1 ∪ S2)]
.

(cid:88)

(cid:88)

=

S1⊆var(g1)
|S1|≤(cid:96)

S2⊆var(g2)
|S2|=(cid:96)−|S1|

(cid:18)
Ee(cid:48)(cid:48)∼Πp|var(g1)

[Rg1(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g1), S1)]

16

Complexity of SHAP-Score-Based Explanations

· Ee(cid:48)(cid:48)∼Πp|var(g2)

[Rg2(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g2), S2)]

(cid:19)
,

where the last equality is simply by deﬁnition of the product distributions, and be-
|var(g2), and similarly for Rg2(e(cid:48)
cause Rg1(e(cid:48)
|var(g2)).
But then, using the convention that α(cid:96)i
gi = 0 when (cid:96)i > |var(gi)|, for i = 1, 2, we obtain
that

|var(g1)) is independent of the value e(cid:48)

α(cid:96)

g =

(cid:88)

S1⊆var(g1)
|S1|≤(cid:96)

Ee(cid:48)(cid:48)∼Πp|var(g1)

[Rg1(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g1), S1)] ·

(cid:88)

S2⊆var(g2)
|S2|=(cid:96)−|S1|

Ee(cid:48)(cid:48)∼Πp|var(g2)

[Rg2(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g2), S2)]

Ee(cid:48)(cid:48)∼Πp|var(g1)

[Rg1(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g1), S1)] · α(cid:96)−|S1|

g2

(cid:88)

S1⊆var(g1)
|S1|≤(cid:96)

(cid:96)
(cid:88)

(cid:96)1=0

(cid:96)
(cid:88)

(cid:96)1=0

α(cid:96)−(cid:96)1
g2

·

(cid:88)

S1⊆var(g1)
|S1|=(cid:96)1

α(cid:96)−(cid:96)1
g2

· α(cid:96)1
g1

(cid:88)

(cid:96)1∈{0,...,min((cid:96),|var(g1)|)}
(cid:96)2∈{0,...,min((cid:96),|var(g2)|)}
(cid:96)1+(cid:96)2=(cid:96)

Ee(cid:48)(cid:48)∼Πp|var(g1)

[Rg1(e(cid:48)(cid:48)) | e(cid:48)(cid:48) ∈ cw(e|var(g1), S1)]

α(cid:96)1
g1 · α(cid:96)2
g2.

(13)

=

=

=

=

By induction, the values α(cid:96)1
g2, for each (cid:96)1 ∈ {0, . . . , |var(g1)|} and (cid:96)2 ∈
{0, . . . , |var(g2)|}, have already been computed. Therefore, we can compute all the
values α(cid:96)

g for (cid:96) ∈ {0, . . . , |var(g)|} in polynomial time.

g1 and α(cid:96)2

This concludes the proof of Lemma 4 and, hence, the proof that SHAP-score can be com-
puted in polynomial time for our circuits.

3.1.3 Extracting an algorithm from the proof

From the previous proof, it is possible to extract Algorithm 1, which is more amenable to
g correspond to values αg
implementation. The main idea of this algorithm is that values γ(cid:96)
(cid:96)
of the proof for the circuit D+x, while values δ(cid:96)
g of the proof for
the circuit D−x. In lines 3–27, these values are computed by bottom-up induction over the
circuit D, following the relations that we obtained in Equations (8)–(13) (but specialized
to the circuits D+x and D−x, as can be seen from lines 6–8, and by the fact that indices are
always in {0, . . . , |var(g) \ {x}|}). Hence, it only remains to show that the returned value of
the algorithm is correct. To see that, observe that we can rewrite Equations (6) and (7) into

g correspond to values α(cid:96)

L = e(x) · HΠp|X\{x}

(D+x, e|X\{x}, k) + (1 − e(x)) · HΠp|X\{x}

(D−x, e|X\{x}, k),

17

Arenas, Barcel´o, Bertossi, Monet

Algorithm 1: SHAP-scores for deterministic and decomposable Boolean circuits
(intermediate)

Input : Deterministic and decomposable Boolean circuit C over features X with
output gate gout, rational probability values p(x) for all x ∈ X,
entity e ∈ ent(X), and feature x ∈ X.

Output: The value SHAP(C, e, x) under the probability distribution Πp.

1 Transform C into an equivalent smooth circuit D where each ∨-gate and ∧-gate

has fan-in exactly 2;

2 Compute the set var(g) for every gate g in D;

3 Compute values γ(cid:96)

g for every gate g in D
and (cid:96) ∈ {0, . . . , |var(g) \ {x}|} by bottom-up induction on D as follows:

g and δ(cid:96)

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

if g is a constant gate with label a ∈ {0, 1} then

g , δ0
γ0

g ← a;

else if g is a variable gate with var(g) = {x} then

γ0
g ← 1;
δ0
g ← 0;

else if g is a variable gate with var(g) = {y} and y (cid:54)= x then

γ0
g , δ0
g , δ1
γ1

g ← p(y);
g ← e(y);

else if g is a ¬-gate with input gate g(cid:48) then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do

g ← (cid:0)|var(g)\{x}|
γ(cid:96)
g ← (cid:0)|var(g)\{x}|
δ(cid:96)
end

(cid:96)

(cid:96)

(cid:1) − γ(cid:96)
g(cid:48);
(cid:1) − δ(cid:96)
g(cid:48);

else if g is an ∨-gate with input gates g1, g2 then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do
g1 + γ(cid:96)
g2;
g1 + δ(cid:96)
g2;

γ(cid:96)
g ← γ(cid:96)
g ← δ(cid:96)
δ(cid:96)
end

else if g is an ∧-gate with input gates g1, g2 then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do

g ← (cid:80)
γ(cid:96)

g ← (cid:80)
δ(cid:96)

(cid:96)1∈{0,...,min((cid:96),|var(g1)\{x}|)}
(cid:96)2∈{0,...,min((cid:96),|var(g2)\{x}|)}
(cid:96)1+(cid:96)2=(cid:96)

(cid:96)1∈{0,...,min((cid:96),|var(g1)\{x}|)}
(cid:96)2∈{0,...,min((cid:96),|var(g2)\{x}|)}
(cid:96)1+(cid:96)2=(cid:96)

g1 · γ(cid:96)2
γ(cid:96)1
g2;

g1 · δ(cid:96)2
δ(cid:96)1
g2;

end

26
27 end

28 return

|X|−1
(cid:88)

k=0

k! (|X| − k − 1)!
|X|!

· (cid:2)(e(x) − p(x))(γk

gout − δk

gout)(cid:3);

18

Complexity of SHAP-Score-Based Explanations

which works no matter the value of e(x) ∈ {0, 1}. We can then directly combine this
expression for L with Equation (4) and the expression of R from Equation (5) to obtain

Diﬀk(D, e, x) = L − R

= (e(x) − p(x))(cid:2)HΠp|X\{x}

(D+x, e|X\{x}, k) − HΠp|X\{x}

(D−x, e|X\{x}, k)(cid:3).

But the rightmost factor is precisely (γk
is indeed correct by Equation (3).

gout − δk

gout) in Algorithm 1, so that the returned value

Example 2 We describe in this example a complete execution of Algorithm 1 over the
deterministic and decomposable Boolean circuit C in depicted Figure 1 (see Example 1).
More precisely, we show in Figure 2 how SHAP(C, e, nf) is computed under the uniform
distribution (that is, p(fg) = p(dtr) = p(nf) = p(na) = 1/2), and assuming that e(fg) = 1,
e(dtr) = 0, e(nf) = 1, and e(na) = 1. Notice that C(e) = 1.

In the ﬁrst step of the algorithm, the gate in gray in Figure 2 is added to C so that the
fan-in of every ∨- and ∧-gate is exactly 2, and the gates in blue in Figure 2 are added to
obtain a deterministic, decomposable and smooth circuit D (in particular, for every ∨-gate g
of D with input gates g1 and g2, it holds that var(g1) = var(g2)). Then in the main loop
of the algorithm, the values of γi
g are computed in a bottom-up fashion for every
gate g and i ∈ {0, . . . , |var(g) \ {nf}|}. Finally, assuming that gout is the top ∧-gate in D,
the value SHAP(C, e, nf) is computed as follows:

g and δi

SHAP(C, e, nf) =

3
(cid:88)

k! (3 − k)!
4!

· (cid:2)(e(nf) − p(nf))(γk

gout − δk

gout)(cid:3)

(cid:18) 1
4

·

1
8

+

1
12

·

3
4

+

1
12

·

3
2

+

1
4

(cid:19)

· 1

·

k=0
1
2
15
64

.

=

=

As a ﬁnal comment, we notice that by following the same procedure it can be shown that
(cid:3)
SHAP(C, e, fg) = 23/64, SHAP(C, e, dtr) = −9/64, and SHAP(C, e, na) = 15/64.

3.2 An optimized version of the algorithm

In this section, we present an optimized version of the algorithm to compute the SHAP-
score. The observation behind this algorithm is that it is possible to bypass the smoothing
step and directly work on the input circuit C.5 Our procedure can be found in Algorithm 2.
Observe that Algorithm 2 is identical to Algorithm 1, except that: (1) we do not smooth
the circuit on line 1; and (2) the expressions for ∨-gates on lines 19 and 20 have changed.
Before showing the correctness of Algorithm 2, notice that the smoothing step on line 1 of
Algorithm 1 takes time O(|C| · |X|), as described in Section 3.1.2, and the resulting circuit,
called D, has size O(|C| · |X|). As Algorithm 2 does not execute such a smoothing step, it

5. We ﬁrst presented a version that used smoothing because it made the tractability proof easier to under-

stand.

19

Arenas, Barcel´o, Bertossi, Monet

δ0 = 1
γ0 = 3
4
8
γ1 = 3
δ1 = 3
4
2
γ2 = 2 δ2 = 1
2
γ3 = 1 δ3 = 0

δ0 = 1
γ0 = 1
2
2
δ1 = 1
γ1 = 1
2
2
γ2 = 0 δ2 = 0

∧

∧

γ0 = 1
2
γ1 = 1
δ0 = 1
2
δ1 = 1

fg

γ0 = 1 δ0 = 1
γ1 = 1 δ1 = 1

∧

γ0 = 1
δ0 = 1

∨

γ0 = 1 δ0 = 1
γ1 = 1 δ1 = 1

∨

¬ γ0 = 0
δ0 = 1

nf

γ0 = 1
δ0 = 0

nf

γ0 = 1
δ0 = 0

na

γ0 = 1
2
γ1 = 1
δ0 = 1
2
δ1 = 1

dtr

γ0 = 1
2
γ1 = 0
δ0 = 1
2
δ1 = 0

¬

γ0 = 1
2
γ1 = 0
δ0 = 1
2
δ1 = 0

na

γ0 = 1
2
γ1 = 1
δ0 = 1
2
δ1 = 1

δ0 = 1
γ0 = 3
2
4
γ1 = 3
δ1 = 1
2
2
γ2 = 1 δ2 = 0

∨

γ0 = 1
δ0 = 0
4
γ1 = 1 δ1 = 0
γ2 = 1 δ2 = 0

γ0 = 1
2
γ1 = 1
δ0 = 0
δ1 = 0

∧

∧

na

γ0 = 1
2
γ1 = 1
δ0 = 1
2
δ1 = 1

¬

γ0 = 1
2
γ1 = 1
δ0 = 1
2
δ1 = 1

nf

γ0 = 1
δ0 = 0

Figure 2: Execution of Algorithm 1 over the deterministic and decomposable Boolean cir-

cuit depicted in Figure 1.

20

Complexity of SHAP-Score-Based Explanations

works directly with a circuit of size O(|C|), obtained after preprocessing input circuit C to
ensure that all ∨- and ∧-gate have fan-in 2, and it has a lower complexity.

The only thing that changed between Algorithm 1 and 2 is how we treat an ∨-gate,
which can now be non-smoothed. Therefore, to show that Algorithm 2 is correct, we need
to revisit Equation (12). The relation

α(cid:96)

g =

(cid:88)

=

S⊆var(g)
|S|=(cid:96)
(cid:88)

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[Rg1(e(cid:48)) + Rg2(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

Ee(cid:48)∼Πp|var(g)

[Rg1(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

(14)

(cid:88)

+

S⊆var(g)
|S|=(cid:96)

Ee(cid:48)∼Πp|var(g)

[Rg2(e(cid:48)) | e(cid:48) ∈ cw(e|var(g), S)]

g1 +α(cid:96)

is still true for an arbitrary deterministic ∨-gate g with children g1, g2, however this is not
equal to α(cid:96)
g2 anymore when g is not smooth. This is because, in this case, one of var(g1)
or var(g2) (or both) is not equal to var(g). Assuming without loss of generality that we have
var(g1) (cid:54)= var(g), by induction hypothesis we have α(cid:96)
(Rg1, e|var(g1), (cid:96)), which
is not the expression (14) that we obtain above. To ﬁx this, we will do as if the gate
had been smoothed, by considering the virtual circuits dS1 and dS2 that we use in the
smoothing process, but without materializing them. We recall that S1 := var(g1) \ var(g2)
and S2 := var(g2) \ var(g1), and that dS1 and dS2 are Boolean circuits that always evaluate
1 and g(cid:48)
to 1 over sets of variables S1 and S2, respectively. Let g(cid:48)
2 be the output gate of
and α(cid:96)2
those circuits. We will show how to compute the values α(cid:96)1
, for (cid:96)1 ∈ {0, . . . , |S1|}
g(cid:48)
g(cid:48)
2
1
and (cid:96)2 ∈ {0, . . . , |S2|}, directly with a closed form expression and use Equation (13) for ∧-
gates to ﬁx the algorithm. We have

g1 = HΠp|var(g1)

α(cid:96)1
g(cid:48)
1

= HΠp

|var(g(cid:48)

1)

(Rg(cid:48)

1

, e|var(g(cid:48)

1), (cid:96)) =

(cid:88)

S⊆S1
|S|=(cid:96)1

Ee(cid:48)∼Πp|S1

[Rg(cid:48)

1

(e(cid:48)) | e(cid:48) ∈ cw(e|S1, S)] =

Ee(cid:48)∼Πp|S1

[1 | e(cid:48) ∈ cw(e|S1, S)] =

(cid:88)

S⊆S1
|S|=(cid:96)1

(cid:19)

(cid:18)|S1|
(cid:96)1

.

(cid:88)

1 =

S⊆S1
|S|=(cid:96)1

Hence, by virtually considering that the circuit has been smoothed (that is, that we replaced
gate g1 with (g1 ∧ dS2) and gate g2 with (g2 ∧ dS1)), and by using the relation for ∧-gates
we can correct Equation (12) as follows:

α(cid:96)

g =

(cid:88)

α(cid:96)(cid:48)
g1 ·

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g1)|)}

+

(cid:88)

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g2)|)}

21

(cid:19)

(cid:18)|var(g2) \ var(g1)|
(cid:96) − (cid:96)(cid:48)
(cid:18)|var(g1) \ var(g2)|
(cid:96) − (cid:96)(cid:48)

α(cid:96)(cid:48)
g2 ·

(cid:19)
.

Arenas, Barcel´o, Bertossi, Monet

And this is precisely what we use in Algorithm 2 for ∨-gates, so this concludes the proof.

We note that, if we ignore the complexity of arithmetic operations (that is, if we consider
that arithmetic operations over rationals take constant time and that rationals can be stored
in constant space), Algorithm 2 runs in time O(|C| · |X|2).

4. Extension to Non-Binary Deterministic and Decomposable Circuits

In this section, we show how to extend the result of the previous section to non-binary
classiﬁers. First, we need to redeﬁne the notions of entities, product distributions and SHAP-
score to account for non-binary features. We point out that these new deﬁnitions are to be
considered for this section only, as in the rest of the paper we will again consider binary
classiﬁers. Let X be a ﬁnite set of features, and dom be a function that associates to
every feature x ∈ X a ﬁnite domain dom(x). An entity over (X, dom) is a function e that
associates to every feature an element e(x) ∈ dom(X). We denote by ent(X, dom) the set of
all entities over (X, dom). We then consider product distributions on ent(X, dom) as follows.
For every x ∈ X, let px : dom(X) → [0, 1] be such that (cid:80)
v∈dom(X) px(v) = 1. Then the
product distribution generated by (px)x∈X is the probability distribution Πp over ent(X, dom)
such that, for every e ∈ ent(X, dom) we have

Πp(e)

:=

(cid:89)

x∈X

px(e(x)).

That is, again, Πp is the product distribution that is determined by pre-speciﬁed marginal
distributions, and that makes the features take values independently from each other. A
Boolean classiﬁer M over X is a function M : ent(X, dom) → {0, 1} that maps every entity
over X to 0 or 1. The SHAP score over such classiﬁers is then deﬁned just like in Section 2.2.

Non-binary Boolean circuits. We now deﬁne a variant of deterministic and decom-
posable circuits for non-binary variables, that we will call deterministic and decomposable
non-binary Boolean circuits. Just like a Boolean circuit captures a set of binary entities
(those that satisfy the circuit), a non-binary Boolean circuit will capture a set of entities
over (X, dom). We deﬁne a non-binary Boolean circuit over (X, dom) like a Boolean circuit
(recall the deﬁnition from Section 2.3), except that each variable gate is now labeled with
an equality of the form x = v, where x ∈ X and v ∈ dom(X). Such a circuit then maps
every entity over X to 0 or 1 in the expected way, and can thus be seen as a Boolean
classiﬁer. Again, an ∧-gate is decomposable if for every pair g1, g2 of distinct input gates
of g, we have that var(g1) ∩ var(g2) = ∅; an ∨-gate is deterministic if for every pair g1, g2 of
distinct input gates of g there is no entity that satisﬁes them both; and the circuit is called
deterministic and decomposable if all its ∧-gates are decomposable and all its ∨-gates are
deterministic.

The main result of this section is that we can generalize Theorem 2 to these kind of
circuits (we presented the result for Boolean circuits over binary variables ﬁrst for clarity
of presentation):

Theorem 5 Given as input a set of features X, ﬁnite domains dom(x) for every x ∈ X,
a deterministic and decomposable non-binary Boolean circuit C over (X, dom), rational
probability values px(v) for every x ∈ X and v ∈ dom(x), an entity e ∈ ent(X, dom), and a
feature x ∈ X, the value SHAPΠp(C, e, x) can be computed in polynomial time.

22

Complexity of SHAP-Score-Based Explanations

Algorithm 2: SHAP-scores for deterministic and decomposable Boolean circuits

Input : Deterministic and decomposable Boolean circuit C over features X with
output gate gout, rational probability values p(x) for all x ∈ X,
entity e ∈ ent(X), and feature x ∈ X.

Output: The value SHAP(C, e, x) under the probability distribution Πp.

1 Preprocess C so that each ∨-gate and ∧-gate has fan-in exactly 2;

2 Compute the set var(g) for every gate g in C;

3 Compute values γ(cid:96)

g for every gate g in C
and (cid:96) ∈ {0, . . . , |var(g) \ {x}|} by bottom-up induction on C as follows:

g and δ(cid:96)

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

24

25

if g is a constant gate with label a ∈ {0, 1} then

g , δ0
γ0

g ← a;

else if g is a variable gate with var(g) = {x} then

γ0
g ← 1;
δ0
g ← 0;

else if g is a variable gate with var(g) = {y} and y (cid:54)= x then

g , δ0
γ0
g , δ1
γ1

g ← p(y);
g ← e(y);

else if g is a ¬-gate with input gate g(cid:48) then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do

g ← (cid:0)|var(g)\{x}|
γ(cid:96)
g ← (cid:0)|var(g)\{x}|
δ(cid:96)
end

(cid:96)

(cid:96)

(cid:1) − γ(cid:96)
g(cid:48);
(cid:1) − δ(cid:96)
g(cid:48);

else if g is an ∨-gate with input gates g1, g2 then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do

g ← (cid:80)
γ(cid:96)
(cid:80)
g ← (cid:80)
δ(cid:96)
(cid:80)

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g1)\{x}|)} γ(cid:96)(cid:48)

g1 · (cid:0)|var(g2)\(var(g1)∪{x})|

(cid:96)−(cid:96)(cid:48)

(cid:1) +

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g2)\{x}|)} γ(cid:96)(cid:48)

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g1)\{x}|)} δ(cid:96)(cid:48)

(cid:96)(cid:48)∈{0,...,min((cid:96),|var(g2)\{x}|)} δ(cid:96)(cid:48)

g2 · (cid:0)|var(g1)\(var(g2)∪{x})|

(cid:1) ;
g1 · (cid:0)|var(g2)\(var(g1)∪{x})|

(cid:96)−(cid:96)(cid:48)

(cid:96)−(cid:96)(cid:48)

g2 · (cid:0)|var(g1)\(var(g2)∪{x})|

(cid:96)−(cid:96)(cid:48)

(cid:1);

(cid:1) +

end

else if g is an ∧-gate with input gates g1, g2 then

for (cid:96) ∈ {0, . . . , |var(g) \ {x}|} do

g ← (cid:80)
γ(cid:96)

g ← (cid:80)
δ(cid:96)

(cid:96)1∈{0,...,min((cid:96),|var(g1)\{x}|)}
(cid:96)2∈{0,...,min((cid:96),|var(g2)\{x}|)}
(cid:96)1+(cid:96)2=(cid:96)

(cid:96)1∈{0,...,min((cid:96),|var(g1)\{x}|)}
(cid:96)2∈{0,...,min((cid:96),|var(g2)\{x}|)}
(cid:96)1+(cid:96)2=(cid:96)

g1 · γ(cid:96)2
γ(cid:96)1
g2;

g1 · δ(cid:96)2
δ(cid:96)1
g2;

end

26
27 end

28 return

|X|−1
(cid:88)

k=0

k! (|X| − k − 1)!
|X|!

· (cid:2)(e(x) − p(x))(γk

gout − δk

gout)(cid:3);

23

Arenas, Barcel´o, Bertossi, Monet

Proof First, notice that, since probability values px(v) for every x ∈ X and v ∈ dom(x)
are anyway given as part of the input, it can safely be considered that dom(x) is of linear
size. We then go through the proof of Theorem 2 and only explain what changes. For x ∈ X
and v ∈ dom(x), we denote by Cx=v the non-binary Boolean circuit that is obtained from C
by replacing every variable gate that is labeled with x = v by a constant 1-gate, and every
variable gate that is labeled with x = v(cid:48) for v(cid:48) (cid:54)= v by a constant 0-gate (it is clear that Cx=v
is again deterministic and decomposable if C satisﬁes these properties). Then, the reduction
from SHAPΠ·(·, ·, ·) to HΠ·(·, ·, ·) from Section 3.1.1 still works, for instance the term R from
Equation (4) becomes

R =

(cid:88)

Ee(cid:48)∼Πp[C(e(cid:48)) | e(cid:48) ∈ cw(e, S)]

S⊆X\{x}
|S|=k
(cid:88)

v∈dom(X)

=

px(v) · HΠp|X\{x}

(Cx=v, e|X\{x}, k).

We now look at the computation of HΠ·(·, ·, ·) and inspect what changes in Lemma 4. We
can rewrite to fan-in 2 and smooth the circuit in the same way,6 and the quantities α(cid:96)
g
are also deﬁned in the same way. The relations that we used to compute the values α(cid:96)
g do
not change, except the ones for variable gates: for a variable gate g labeled with x = v,
Equations (8) and (9) become, respectively, α0

g = px(v) and

α1

g =

(cid:40)
1
0

if e(x) = v
otherwise

.

This in particular allows us to prove that the SHAP-score can be computed in polynomial
time for (not necessarily binary) decision trees, or for variants of OBDDs/FBDDs that
use non-binary features, as deterministic and decomposable non-binary Boolean circuits
generalize them.

5. Limits on the Tractable Computation of the SHAP-Score

We have shown in the previous sections that the SHAP-score can be computed in polynomial
time for deterministic and decomposable circuits under product distributions. A natural
question, then, is whether both determinism and decomposability are necessary for this
positive result to hold. In this section we show that this is the case, at least under standard
complexity assumptions, and even when we consider the uniform distribution. Recall that
we are now back to considering Boolean classiﬁers. Formally, we prove the following:

Theorem 6 The following problems are #P-hard.

1. Given as input a decomposable (but not necessarily deterministic) Boolean circuit C
over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the
value SHAPU (C, e, x).

6. For smoothing, we use the circuits dS := (cid:86)

x∈S((cid:87)

v∈dom(x) x = v).

24

Complexity of SHAP-Score-Based Explanations

2. Given as input a deterministic (but not necessarily decomposable) Boolean circuit C
over a set of features X, an entity e : X → {0, 1}, and a feature x ∈ X, compute the
value SHAPU (C, e, x).

Intuitively, for the ﬁrst item, this comes from the fact that an arbitrary Boolean circuit
can always be transformed in polynomial time (in fact in linear time) into an equivalent
decomposable (but not necessarily deterministic) Boolean circuit, simply by applying De
Morgan’s laws to eliminate all ∧-gates. Hence the problem on those circuits it at least
as hard as on unrestricted Boolean circuits; and the argument is similar for the second
item. Therefore, to show Theorem 6, it is good enough to prove that the problem is indeed
intractable over unrestricted Boolean circuits. We now prove these claims formally.

We start by showing that there is a general polynomial-time reduction from the problem
of computing the number of entities that satisfy M , for M an arbitrary Boolean classiﬁer,
to the problem of computing the SHAP-score over M under the uniform distribution. This
holds under the mild condition that M (e) can be computed in polynomial time for an input
entity e, which is satisﬁed for all the Boolean circuits and binary decision diagrams classes
considered in this paper. The proof of this result follows from well-known properties of
Shapley values, and a closely related result can be found as Theorem 5.1 in (Bertossi et al.,
2020).

Lemma 7 Let M be a Boolean classiﬁer over a set of features X, and let #SAT(M ) :=
|{e ∈ ent(X) | M (e) = 1}|. Then for every e ∈ ent(X) we have:

#SAT(M ) = 2|X|

(cid:18)

M (e) −

(cid:88)

x∈X

SHAPU (M, e, x)

(cid:19)
.

Proof The validity of this equation will be a consequence of the following property of the
SHAP-score: for every Boolean classiﬁer M over X, entity e ∈ ent(X) and feature x ∈ X,
it holds that

(cid:88)

x∈X

SHAPU (M, e, x) = φU (M, e, X) − φU (M, e, ∅).

(15)

This property is often called the eﬃciency property of the Shapley value. Although this is
folklore, we prove Equation (15) here for the reader’s convenience. Recall from Equation (2)
that the SHAP-score can be written as

SHAPU (M, e, x) =

1
|X|!

(cid:88)

π∈Π(X)

(cid:0)φU (M, e, Sx

π ∪ {x}) − φU (M, e, Sx

π)(cid:1).

Hence, we have that

(cid:88)

x∈X

SHAPU (M, e, x) =

=

1
|X|!

1
|X|!

(cid:88)

(cid:88)

(cid:0)φU (M, e, Sx

π ∪ {x}) − φU (M, e, Sx

π)(cid:1)

(cid:0)φU (M, e, Sx

π ∪ {x}) − φU (M, e, Sx

π)(cid:1)

x∈X

π∈Π(X)
(cid:88)

(cid:88)

π∈Π(X)

x∈X

25

Arenas, Barcel´o, Bertossi, Monet

=

1
|X|!

(cid:88)

(cid:0)φU (M, e, X) − φU (M, e, ∅)(cid:1)

π∈Π(X)

= φU (M, e, X) − φU (M, e, ∅),

where the second to last equality is obtained by noticing that the inner sum is a tele-
scoping sum. This establishes Equation (15). Now, by deﬁnition of φU (·, ·, ·) we have
that φU (M, e, X) = M (e) and φU (M, e, ∅) = 1
2|X|

e(cid:48)∈ent(X) M (e(cid:48)), so we obtain

(cid:80)

(cid:88)

x∈X

SHAPU (M, e, x) = M (e) −

#SAT(M )
2|X|

,

thus proving Lemma 7.

We stress out here that this result holds for any Boolean classiﬁer and is not restricted

to the classes of Boolean circuits that we consider in this paper.

Theorem 6 can then easily be deduced from Lemma 7 and the following two facts: (a)
counting the number of satisfying assignments of an arbitrary Boolean circuit is a #P-hard
problem (Provan and Ball, 1983); and (b) every Boolean circuit can be transformed in linear
time into a Boolean circuit that is deterministic (resp, decomposable), simply by using De
Morgan’s laws to get rid of the ∨-gates (resp., ∧-gates). For instance, the reduction to
prove the ﬁrst item of Theorem 6 is as follows: on input an arbitrary Boolean circuit C,
use De Morgan’s laws to remove all ∧-gates, thus obtaining an equivalent circuit C(cid:48) which
is vacuously decomposable (since it does not have any ∧-gates), and then use the oracle to
computing SHAP-scores together with Lemma 7 with an arbitrary entity (for instance, the
one that assigns zero to all features) in order to compute #SAT(C).

6. Non-Approximability of the SHAP-Score

We now study the approximability of the SHAP-score. As we have shown in the previous
section with Lemma 7, computing the SHAP-score is generally intractable for classes of mod-
els for which model counting is intractable. Yet, it could be the case that one can eﬃciently
approximate the SHAP-score, just like in some cases one can eﬃciently approximate the
number of models of a formula even though computing this quantity exactly is intractable.
For instance, model counting of DNF formulas is #P-hard (Provan and Ball, 1983) but ad-
mits a Fully Polynomial-time Randomized Approximation Scheme, or FPRAS (Karp et al.,
1989). Unfortunately, as we show next, intractability of computing the SHAP-score contin-
ues to hold when one considers approximability, and this even for very restricted kinds of
Boolean classiﬁers and under the uniform probability distribution.

To simplify the notation in this section, we will drop the subscript U for the uniform
distribution, and write SHAP(·, ·, ·) instead of SHAPU (·, ·, ·), and φ(·, ·, ·) instead of φU (·, ·, ·).
Let C be a class of Boolean classiﬁers and ε ∈ (0, 1). We say that the problem of computing
the SHAP score for C admits an ε polynomial-time randomized approximation (ε-PRA),
if there exists a randomized algorithm A satisfying the following conditions. For every
Boolean classiﬁer M ∈ C over a set of features X, entity e over X, and feature x ∈ X, it

26

Complexity of SHAP-Score-Based Explanations

holds that:

Pr (cid:0)|A(M, e, x) − SHAP(M, e, x)| ≤ ε · |SHAP(M, e, x)|(cid:1) ≥

3
4

.

Moreover, there exists a polynomial p(·) such that A(M, e, x) works in time O(p((cid:107)M (cid:107) +
(cid:107)e(cid:107))), where (cid:107)M (cid:107) and (cid:107)e(cid:107) are the sizes of M and e represented as input strings, respectively.
We recall that the notion of FPRAS mentioned before is deﬁned as the concept of PRA,
but imposing the stronger requirements that ε is part of the input and the algorithm is
polynomial in 1

ε as well.

We start by presenting a simple proof that for every ε ∈ (0, 1), the problem of computing
the SHAP score for Boolean classiﬁers given as DNF formulas does not admit an ε-PRA,
unless NP = RP.7

Proposition 8 For every ε ∈ (0, 1), the problem of computing the SHAP score for Boolean
classiﬁers given as DNF formulas does not admit an ε-PRA, unless NP = RP. This result
holds even if we restrict to the uniform distributions on the entities.

Proof We ﬁrst recall the following fact: if a function f admits an ε-PRA, then the problem
of determining, given a string x, whether f (x) = 0 is in BPP (although this is folklore, we
provide a proof in Appendix B). We use this to prove that if we could approximate the
SHAP-score over DNF formulas, then we could solve the validity problem over DNF formulas
in BPP. Recall that the validity problem over DNF formulas is the decision problem that,
given as input a DNF formula ϕ, accepts if all valuations satisfy ϕ, and rejects otherwise
(in other words, it rejects if ¬ϕ is satisﬁable and accepts otherwise). Since this problem
is coNP-complete and BPP is closed under complement, this would imply that NP ⊆ BPP,
and thus that NP = RP (Ko, 1982). Let ϕ be a DNF formula over a set of variables X. We
consider the DNF formula ϕ(cid:48) := ϕ ∨ x with x /∈ X, and the uniform probability distribution
over ent(X ∪ {x}). Let e be an arbitrary entity over X ∪ {x} such that e(x) = 1. We show
that ϕ is valid if and only if SHAP(ϕ(cid:48), e, x) = 0, which, by the previous remarks, is good
enough to conclude the proof. By deﬁnition we have

SHAP(ϕ(cid:48), e, x) =

(cid:88)

S⊆X

|S|! (|X| − |S|)!
(|X| + 1)!

(cid:18)

φ(ϕ(cid:48), e, S ∪ {x}) − φ(ϕ(cid:48), e, S)

.

(cid:19)

Observe that for each S ⊆ X, it holds that φ(ϕ(cid:48), e, S ∪ {x}) = 1 (given the deﬁnition
of ϕ(cid:48) and the fact that e(x) = 1), and that 0 ≤ φ(ϕ(cid:48), e, S) ≤ 1. Now, if ϕ is valid,
then it is clear that φ(ϕ(cid:48), e, S) = 1 for every S ⊆ X, so that indeed SHAP(ϕ(cid:48), e, x) = 0.
Assume now that ϕ is not valid. By what preceded, it is good enough to show that for
some S ⊆ X we have φ(ϕ(cid:48), e, S) < 1. But this clearly holds for S = ∅, because ϕ is
not valid and all entities have the same probability (so that no entity has probability zero).

Hence, this result already establishes an important diﬀerence with model counting: for
the case of DNF formulas, the model counting problem admits an FPRAS (Karp et al.,
1989) and, thus, an ε-PRA for every ε ∈ (0, 1).

7. Recall that it is widely believed that RP is properly contained in NP, as mentioned in Section 2.

27

Arenas, Barcel´o, Bertossi, Monet

It is important to mention that the proof of Proposition 8 uses, in a crucial way, the fact
that the validity problem for DNF formulas is intractable. We prove next a strong negative
result, which establishes that not even for positive DNF formulas – for which the validity
problem is trivial – it is possible to obtain an ε-PRA for computing the SHAP-score. Let
ϕ = D1 ∨ D2 ∨ · · · ∨ Dk be a formula in DNF, that is, each formula Di is a conjunction
of positive literals (propositional variables) and negative literals (negations of propositional
variables). Then ϕ is said to be in POS-DNF if each formula Di is a conjunction of positive
literals, (hence, ϕ is a monotone formula), and ϕ is said to be in 2-POS-DNF if ϕ is in
POS-DNF and each formula Di contains at most two (positive) literals. Our main result of
this section is the following.

Theorem 9 For every ε ∈ (0, 1), the problem of computing the SHAP score for Boolean
classiﬁers given as 2-POS-DNF formulas does not admit an ε-PRA, unless NP = RP. This
result holds even if we restrict to the uniform distributions on the entities.

Furthermore, we can show that the same intractability result also holds for closely related
classes of Boolean classiﬁers. As before, let ϕ = D1 ∨ D2 ∨ · · · ∨ Dk be a formula in DNF.
Then ϕ is in NEG-DNF if each formula Di is a conjunction of negative literals, and ϕ is
in 2-NEG-DNF if it is in NEG-DNF and each formula Di is a conjunction of at most two
(negative) literals. We deﬁne similarly formulas in 2-POS-CNF and in 2-NEG-CNF. We
then obtain the following result.

Corollary 10 Let C ∈ {2-POS-DNF, 2-NEG-DNF, 2-POS-CNF, 2-NEG-CNF}. Then for
every ε ∈ (0, 1), the problem of computing the SHAP score for Boolean classiﬁers given as
formulas in C does not admit an ε-PRA, unless NP = RP. This result holds even if we
restrict to the uniform distributions on the entities.

It should be noticed that 2-NEG-CNF formulas are special cases of HORN-SAT formulas,
so that the previous result also applies for HORN-SAT.

We prove Theorem 9 in Section 6.1, and then show how the proof can be adapted to

prove Corollary 10 in Section 6.2

6.1 Proof of Theorem 9

We will use some results and techniques related to approximating cliques in graphs. More
speciﬁcally, all graphs G = (N, E) considered in this proof are assumed to be undirected
and loop-free (that is, edges of the form (a, a) are not allowed). Besides, we assume that
each graph G = (N, E) satisﬁes the following condition:

(A) there exist at least two isolated nodes in G, that is, two distinct nodes a, b ∈ N such

that (a, c) (cid:54)∈ E and (b, c) (cid:54)∈ E for every node c ∈ N .

The assumption that condition (A) is satisﬁed will allow us to simplify some calculations.
Besides, it is clear that condition (A) can be checked in polynomial time.

We deﬁne the problem GapClique as follows. The input of GapClique is a graph G =

(N, E) and a number m ≤ |N |, and its output is:

• yes if G contains a clique with m nodes,

28

Complexity of SHAP-Score-Based Explanations

• no if every clique of G contains at most (cid:98) m

3 (cid:99) nodes.

From the PCP theorem and its applications to hardness of approximation (Feige et al.,
1996; Arora and Safra, 1998; Arora et al., 1998), it is known that GapClique is NP-hard (in
fact even if 1
3 is replaced by any δ ∈ (0, 1)). In other words, there exists a polynomial-time
reduction that takes as input a Boolean formula ϕ and that outputs a graph G and an
integer m such that (1) if ϕ is satisﬁable then G contains a clique with m nodes; and (2)
if ϕ is not satisﬁable then every clique of G contains at most (cid:98) m

3 (cid:99) nodes.

The idea of our proof of Theorem 9 is then to show that if the problem of computing the
SHAP score for Boolean classiﬁers given as 2-POS-DNF formulas admits an ε-PRA, then
there exists a BPP algorithm for GapClique. Hence, we would conclude that NP ⊆ BPP,
which in turn implies that NP = RP (Ko, 1982). The proof is technical, and it is divided
into ﬁve modular parts, highlighted in bold in the remaining of this section.

The SHAP-score of a Boolean classiﬁer of the form M ∨x. Given a set of features X,
a Boolean classiﬁer M over X, and an S ⊆ X, deﬁne

#SAT(M, S) := |{e ∈ ent(X) | M (e) = 1 and e(y) = 1 for every y ∈ S}|.

We can relate the SHAP-score of a Boolean classiﬁer of the form M ∨ x to the quanti-
ties #SAT(¬M, S) as follows:

Lemma 11 Let X be a set of features, n = |X|, x ∈ X, M be a Boolean classiﬁer over
X \ {x}, and 1 be the entity over X such that 1(y) = 1 for every y ∈ X. Then

SHAP(M ∨ x, 1, x) =

n−1
(cid:88)

k=0

k!(n − k − 1)!
n!

·

1
2n−k

(cid:88)

#SAT(¬M, S).

S⊆X\{x} : |S|=k

Proof Let M (cid:48) be a Boolean classiﬁer over X. Given S ⊆ X \ {x}, we have that:

φ(M (cid:48), 1, S ∪ {x}) =

(cid:88)

1
2|X\(S∪{x})|

· M (cid:48)(e)

(cid:88)

M (cid:48)

+x(e(cid:48))

e(cid:48)∈cw(1|X\{x},S)
(cid:88)

M (cid:48)

+x(e(cid:48)).

e(cid:48)∈cw(1|X\{x},S)

e∈cw(1,S∪{x})
1
2|X\(S∪{x})|

=

=

2
2|X\S|

· M (cid:48)(e)

Besides, we have that:

φ(M (cid:48), 1, S) =

(cid:88)

1
2|X\S|

e∈cw(1,S)
(cid:88)

e∈cw(1,S) : e(x)=0

=

=

1
2|X\S|

· M (cid:48)(e) +

(cid:88)

e∈cw(1,S) : e(x)=1

1
2|X\S|

· M (cid:48)(e)

1
2|X\S|

·

(cid:18) (cid:88)

M (cid:48)

−x(e(cid:48)) +

(cid:88)

e(cid:48)∈cw(1|X\{x},S)

e(cid:48)∈cw(1|X\{x},S)

29

M (cid:48)

+x(e(cid:48))

(cid:19)
.

Arenas, Barcel´o, Bertossi, Monet

Therefore, we conclude that:

φ(M (cid:48), 1, S ∪ {x}) − φ(M (cid:48), 1, S) =

1
2|X\S|

·

(cid:18) (cid:88)

M (cid:48)

+x(e) −

(cid:88)

M (cid:48)

−x(e)

(cid:19)
.

e∈cw(1|X\{x},S)

e∈cw(1|X\{x},S)

Considering this equation with M (cid:48) := M ∨ x, we deduce that:

φ(M ∨ x, 1, S ∪ {x}) − φ(M ∨ x, 1, S) =
(cid:18) (cid:88)

(M ∨ x)+x(e) −

(cid:88)

(cid:19)

(M ∨ x)−x(e)

=

·

·

·

1
2|X\S|

1
2|X\S|

1
2|X\S|

1
2|X\S|

e∈cw(1|X\{x},S)

(cid:18) (cid:88)

e∈cw(1|X\{x},S)

(cid:18) (cid:88)

1 −

(cid:88)

e∈cw(1|X\{x},S)

(cid:19)

M (e)

=

e∈cw(1|X\{x},S)
(cid:19)

(1 − M (e))

=

e∈cw(1|X\{x},S)

· #SAT(¬M, S).

By considering the deﬁnition of the SHAP score, we obtain that:

SHAP(M ∨ x, 1, x) =

(cid:88)

S⊆X\{x}

|S|!(|X| − |S| − 1)!
|X|!

(cid:18)

(cid:19)

·

φ(M ∨ x, 1, S ∪ {x}) − φ(M ∨ x, 1, S)

=

n−1
(cid:88)

(cid:88)

k=0

S⊆X\{x} : |S|=k

|S|!(|X| − |S| − 1)!
|X|!

·

1
2|X\S|

· #SAT(¬M, S) =

n−1
(cid:88)

k=0

k!(n − k − 1)!
n!

·

1
2n−k

(cid:88)

#SAT(¬M, S).

S⊆X\{x} : |S|=k

This concludes the proof of Lemma 11.

A 2-POS-DNF formula for cliques. Given a graph G = (N, E) we deﬁne the for-
mula θ(G) in 2-POS-DNF by

θ(G) :=

(cid:95)

a ∧ b.

(a,b)∈(N ×N )
a(cid:54)=b and (a,b)(cid:54)∈E

(16)

Notice that the set of propositional variables occurring in θ(G) is the same as the set N of
nodes of G, given that G satisﬁes condition (A). For S ⊆ N we deﬁne

#CLIQUE(G, S)

:= |{Y | Y is a clique of G and S ⊆ Y }|.

Using Lemma 11, we can relate the SHAP-score of the 2-POS-DNF formula θ(G) ∨ x to the
quantities #CLIQUE(G, S) for S ⊆ N as follows.

30

Complexity of SHAP-Score-Based Explanations

Lemma 12 For every graph G = (N, E) and x /∈ N , letting n = |N | and 1 be the entity
over N ∪ {x} such that 1(y) = 1 for every y ∈ N ∪ {x}, we have:

SHAP(θ(G) ∨ x, 1, x) =

1
2(n + 1)

n
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

S⊆N : |S|=k

#CLIQUE(G, S).

Proof The crucial observation is that the following relation holds for every S ⊆ N :

#CLIQUE(G, S) = #SAT(¬θ(G), S).

Indeed, this can be seen by deﬁning the bijection that to every subset Y of N associates
the valuation νY of θ(G) such that νY (x) = 1 if and only if x ∈ Y , and then checking that
[Y is a clique of G with S ⊆ Y ] if and only if [νY |= ¬θ(G) and νY (x) = 1 for all x ∈ S].
Therefore, we have from Lemma 11 that

SHAP(θ(G) ∨ x, 1, x) =

n
(cid:88)

k=0

k!(n − k)!
(n + 1)!

·

1
2n+1−k

(cid:88)

S⊆N : |S|=k

#SAT(¬θ(G), S)

=

1
2(n + 1)

n
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

S⊆N : |S|=k

#CLIQUE(G, S).

Working with ampliﬁed graphs.
In this proof, we consider an ampliﬁcation technique
from (Sinclair, 1993). More precisely, given a graph G = (N, E) and a natural number r ≥ 1,
deﬁne the ampliﬁed graph Gr = (N r, Er) of G as follows. For each a ∈ N , let N a :=
{a1, . . . , ar} and N r := (cid:83)

a∈N N a, and let Er be the following set of edges:

Er

:= {(ai, aj) | ai, aj ∈ N a and i (cid:54)= j} ∪ {(ai, bj) | ai ∈ N a, bj ∈ N b and (a, b) ∈ E}.

Thus, the ampliﬁed graph Gr is constructed by copying r times each node of G, by con-
necting for each node of G all of its copies as a clique, and ﬁnally by connecting copies ai,
bj of nodes a, b of G, respectively, whenever a and b are connected in G by an edge. Notice
in particular that G1 is simply G. An example of this construction for r = 2 is illustrated
in Figure 3.

Let then T be a clique of Gr. We say that T is a witness of the clique {a ∈ N | N a ∩T (cid:54)=
∅} of G. Observe that a clique of Gr witnesses a unique clique of G by deﬁnition, but that
a clique of G can have multiple witnessing cliques in Gr. Moreover, letting S be a clique
of G, we write Wit(Gr, S) for the set of cliques of Gr that are witnesses of S. We then show
the following three properties of Gr:

(i) if S1, S2 are distinct cliques of G, then Wit(Gr, S1)∩Wit(Gr, S2) = ∅. Indeed, assuming
without loss of generality that S1 (cid:54)⊆ S2 (the case S2 (cid:54)⊆ S1 being symmetrical) and
letting a ∈ S1 \ S2, it is clear by that, by deﬁnition of being a witness, for any T ∈
Wit(Gr, S1) we must have N a ∩ T (cid:54)= ∅, whereas for any T ∈ Wit(Gr, S2) we have N a ∩
T = ∅.

31

Arenas, Barcel´o, Bertossi, Monet

a

d

b

c

a1

d2

a2

b1

d1

c2

b2

c1

Figure 3: Illustration of the ampliﬁcation construction for r = 2. On the left a graph G,
on the right the corresponding graph G2. We only illustrate the construction
for r = 2, as for r ≥ 3 this very quickly becomes unreadable.

(ii) if S is a clique of G, then |Wit(Gr, S)| = (2r − 1)|S|. Indeed, let T ∈ Wit(Gr, S). By
deﬁnition of being a witness, T cannot contain any node of the form ai for a /∈ S.
Moreover, for every a ∈ S, by deﬁnition of being a witness again, the set T ∩ N a
must be a non-empty subset of N a. Since for every a ∈ N there are exactly (2r − 1)
non-empty subsets of N a, this shows that |Wit(Gr, S)| ≤ (2r − 1)|S|. Additionally,
any set of the form (cid:83)
a∈S Sa where each Sa is a non-empty subset of N a is in fact
in Wit(Gr, S): this is simply because S itself is a clique of S and by deﬁnition of the
graph Gr. This shows that |Wit(Gr, S)| ≥ (2r − 1)|S|, hence |Wit(Gr, S)| = (2r − 1)|S|
indeed.

(iii) for every natural number (cid:96), if all cliques of G have size at most (cid:96), then all cliques
of Gr have size at most (cid:96) · r. Indeed, for any clique T of Gr, letting S be the clique
of S that T witnesses, it is clear that |T | ≤ r · |S| (with the equality being reached
when T ∩ N a = N a for every a ∈ S).

We use these properties to prove our next lemma.

Lemma 13 Let G = (N, E) be a graph, x /∈ N , n := |N |, and m, r be natural numbers
such that 1 ≤ m ≤ n and r ≥ 1. Then:

(a) If every clique of G contains at most (cid:98) m

3 (cid:99) nodes, then

SHAP(θ(Gr) ∨ x, 1, x) ≤

3 (cid:99)r+n

22(cid:98) m
2n·r+1

.

(b) If G contains a clique with m nodes, then

SHAP(θ(Gr) ∨ x, 1, x) ≥

1
(n · r + 1)

·

2mr
2n·r+1 .

Proof

32

Complexity of SHAP-Score-Based Explanations

(a) Given that |N r| = n · r, we have from Lemma 12 that:

SHAP(θ(Gr) ∨ x, 1, x) =

1
2(n · r + 1)

n·r
(cid:88)

k=0

k!(n · r − k)!
(n · r)!

·

1
2n·r−k

(cid:88)

#CLIQUE(Gr, S).

S⊆N r : |S|=k

Now, since every clique of G contains at most (cid:98) m
that all cliques of Gr have size at most (cid:98) m
that #CLIQUE(Gr, S) = 0 for any S ⊆ N r with |S| = k. Therefore, we have that

3 (cid:99) nodes, we have by Item (iii)
3 (cid:99) · r it holds

3 (cid:99) · r. Hence when k > (cid:98) m

SHAP(θ(Gr) ∨ x, 1, x) =

1
2(n · r + 1)

(cid:98) m
3 (cid:99)·r
(cid:88)

k=0

k!(n · r − k)!
(n · r)!

·

1
2n·r−k

(cid:88)

#CLIQUE(Gr, S) ≤

S⊆N r : |S|=k

1
2(n · r + 1)

1
2(n · r + 1)

·

·

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

(cid:98) m
3 (cid:99)·r
(cid:88)

k=0

(cid:98) m
3 (cid:99)·r
(cid:88)

k=0

k!(n · r − k)!
(n · r)!

(cid:88)

#CLIQUE(Gr, S) =

S⊆N r : |S|=k

1
(cid:0)n·r
k

(cid:1)

(cid:88)

#CLIQUE(Gr, S).

S⊆N r : |S|=k

Now, deﬁning #CLIQUE(G, (cid:96)) := |{Y | Y is a clique of G and |Y | = (cid:96)}|, observe that
we have

(cid:88)

#CLIQUE(Gr, S) =

(cid:88)

(cid:88)

1

S⊆N r : |S|=k

S⊆N r : |S|=k

Y clique of Gr
S⊆Y

(cid:88)

|N r|
(cid:88)

S⊆N r : |S|=k

(cid:96)=k

(cid:88)

1

Y clique of Gr
|Y |=(cid:96)
S⊆Y

(cid:88)

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:88)

S⊆N r : |S|=k

(cid:96)=k

Y clique of Gr
|Y |=(cid:96)
S⊆Y

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:88)

(cid:88)

1

1

(cid:96)=k

S⊆N r : |S|=k

Y clique of Gr
|Y |=(cid:96)
S⊆Y

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k

(cid:88)

Y clique of Gr
|Y |=(cid:96)

(cid:88)

1

S⊆Y : |S|=k

=

=

=

=

33

Arenas, Barcel´o, Bertossi, Monet

=

=

=

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k

(cid:19)

(cid:18)|Y |
k

(cid:88)

Y clique of Gr
|Y |=(cid:96)

(cid:18)(cid:96)
k

(cid:19) (cid:88)

1

Y clique of Gr
|Y |=(cid:96)

(cid:19)

(cid:18)(cid:96)
k

#CLIQUE(Gr, (cid:96)),

where the third equality is simply because all cliques of Gr have size at most (cid:98) m
again by Item (iii). Hence, we have that

3 (cid:99) · r,

SHAP(θ(Gr) ∨ x, 1, x) ≤

1
2(n · r + 1)

1
2(n · r + 1)

1
2(n · r + 1)

1
2(n · r + 1)

·

·

·

·

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

((cid:98) m
3 (cid:99) · r + 1)
2(n · r + 1)

·

1
2n·r−(cid:98) m

3 (cid:99)r

n · r + 1
2(n · r + 1)

·

1
2

·

1
2n·r−(cid:98) m

3 (cid:99)r

3 (cid:99)r

1
2n·r−(cid:98) m
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=0

(cid:98) m
3 (cid:99)·r
(cid:88)

k=0
(cid:98) m
3 (cid:99)·r
(cid:88)

k=0
(cid:98) m
3 (cid:99)·r
(cid:88)

1
(cid:0)n·r
k

(cid:1)

(cid:1)

1
(cid:0)n·r
k
(cid:98) m
3 (cid:99)·r
(cid:88)

k=0
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=k

(cid:19)

(cid:18)(cid:96)
k

#CLIQUE(Gr, (cid:96)) ≤

(cid:18)n · r
k

(cid:19)

#CLIQUE(Gr, (cid:96)) =

#CLIQUE(Gr, (cid:96)) ≤

#CLIQUE(Gr, (cid:96)) ≤

(cid:96)=0

k=0
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=0
(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=0

#CLIQUE(Gr, (cid:96)) ≤

#CLIQUE(Gr, (cid:96)) =

#CLIQUE(Gr, (cid:96)).

But notice that (cid:80)(cid:98) m
3 (cid:99)·r
(cid:96)=0 #CLIQUE(Gr, (cid:96)) is simply the total number of cliques of Gr.
Given a clique S of G with (cid:96) elements, remember that by Item (ii) we have that
|Wit(Gr, S)| = (2r − 1)(cid:96). Hence, given that each clique of G has at most (cid:98) m
3 (cid:99) nodes,
(cid:1) cliques with (cid:96) nodes, and that every clique of Gr witnesses
that G has at most (cid:0)n
(cid:96)
a unique clique of G, we have that the total number of cliques of Gr is bounded
as follows:

(cid:98) m
3 (cid:99)·r
(cid:88)

(cid:96)=0

#CLIQUE(Gr, (cid:96)) ≤

(cid:98) m
3 (cid:99)
(cid:88)

(cid:96)(cid:48)=0

(cid:18)n
(cid:96)(cid:48)

(cid:19)

(2r − 1)(cid:96)(cid:48)

.

34

Complexity of SHAP-Score-Based Explanations

Therefore, we conclude that:

SHAP(θ(Gr) ∨ x, 1, x) ≤

≤

=

≤

=

≤

=

(cid:98) m
3 (cid:99)
(cid:88)

(cid:96)(cid:48)=0
(cid:98) m
3 (cid:99)
(cid:88)

(cid:96)(cid:48)=0

(cid:18)n
(cid:96)(cid:48)

(cid:18)n
(cid:96)(cid:48)

(cid:19)

(2r − 1)(cid:96)(cid:48)

(cid:19)

(2r − 1)(cid:98) m
3 (cid:99)

· (2r − 1)(cid:98) m
3 (cid:99)

· (2r − 1)(cid:98) m
3 (cid:99)

(cid:98) m
3 (cid:99)
(cid:88)

(cid:96)(cid:48)=0
n
(cid:88)

(cid:96)(cid:48)=0

(cid:19)

(cid:19)

(cid:18)n
(cid:96)(cid:48)

(cid:18)n
(cid:96)(cid:48)

· (2r − 1)(cid:98) m

3 (cid:99) · 2n

· 2(cid:98) m

3 (cid:99)r · 2n

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

1
2n·r−(cid:98) m

3 (cid:99)r

1
2

1
2

1
2

1
2

·

·

·

·

3 (cid:99)r

3 (cid:99)r

3 (cid:99)r

·

1
2n·r−(cid:98) m
1
2n·r−(cid:98) m
1
2n·r−(cid:98) m
3 (cid:99)r+n

1
2
1
2
22(cid:98) m
2n·r+1

.

·

(b) First, we claim that Gr contains at least 2mr cliques. Indeed, let S be a clique with m
nodes that G contains (by hypothesis). Every subset S(cid:48) of S is also a clique of G. Now,
by Item (i) and Item (ii), we have that the number of witnesses of all the subcliques
of S is equal to

(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:91)

S(cid:48)⊆S

Wit(Gr, S(cid:48))

(cid:12)
(cid:12)
(cid:12)
(cid:12)

=

=

=

(cid:88)

|Wit(Gr, S(cid:48))|

S(cid:48)⊆S
m
(cid:88)

(cid:96)=0
m
(cid:88)

(cid:96)=0

(cid:19)

(2r − 1)(cid:96)

(cid:18)m
(cid:96)

(cid:19)

(2r − 1)(cid:96)1m−(cid:96)

(cid:18)m
(cid:96)

= (2r − 1 + 1)m
= 2mr.

All terms in the summation of SHAP(θ(Gr) ∨ x, 1, x) are non-negative. Hence, we
have that:

SHAP(θ(Gr) ∨ x, 1, x) =

1
2(n · r + 1)

n·r
(cid:88)

k=0

k!(n · r − k)!
n · r!

·

1
2n·r−k

(cid:88)

#CLIQUE(Gr, S) ≥

S⊆N r : |S|=k

1
2(n · r + 1)

·

0!(n · r)!
(n · r)!

·

1
2n·r

(cid:88)

#CLIQUE(Gr, S) =

S⊆N r : |S|=0

35

Arenas, Barcel´o, Bertossi, Monet

1
2(n · r + 1)

·

1
2n·r · #CLIQUE(Gr, ∅).

But #CLIQUE(Gr, ∅) is the total number of cliques of Gr, which we have just proved
to be greater than or equal to 2mr. Therefore

SHAP(θ(Gr) ∨ x, 1, x) ≥

1
(n · r + 1)

·

2mr
2n·r+1 ,

which concludes the proof of Lemma 13.

A technical lemma. Last, we will need the following technical lemma.
Lemma 14 For every ε ∈ (0, 1), there exists nε ∈ N such that for every n, m ∈ N with
n ≥ nε and m ≥ 1, it holds that:

(1 + ε) · 22(cid:98) m

3 (cid:99)n2+n < (1 − ε) ·

2mn2
(n3 + 1)

.

The proof is straightforward and can be found in Appendix C.1.

Putting it all together. We now have all the necessary ingredients to prove Theorem 9.
Assume that the problem of computing the SHAP score for Boolean classiﬁers given as 2-
POS-DNF formulas admits an ε-PRA, for some ﬁxed ε ∈ (0, 1), that we will denote by A.
By using A, we deﬁne the following BPP algorithm B for GapClique. Let G = (N, E) be a
graph with n = |N | and m ∈ {0, . . . , n}. Then B(G, m) performs the following steps:

1. If m = 0, then return yes.

2. Let nε be the constant in Lemma 14. If n ≤ nε, then by performing an exhaustive
search, check whether G contains a clique with m nodes or if every clique of G contains
at most (cid:98) m

3 (cid:99) nodes. In the former case return yes, in the latter case return no.

3. Construct the formula θ(Gn2) ∨ x, where x is a fresh feature (not occurring in N n2).

Notice that θ(Gn2) ∨ x is a formula in 2-POS-DNF.

4. Use algorithm A to compute s := A(θ(Gn2) ∨ x, 1, x).

5. If

s > (1 + ε) ·

22(cid:98) m

3 (cid:99)n2+n
2n3+1

,

then return yes; otherwise return no.

Algorithm B works in polynomial time since nε is a ﬁxed natural number (given that
ε is a ﬁxed value in (0, 1)), ampliﬁed graph Gn2 can be computed in polynomial time
from G, formula θ(Gn2) ∨ x can be constructed in polynomial time from Gn2, algorithm
A(θ(Gn2) ∨ x, 1, x) works in time p((cid:107)θ(Gn2) ∨ x(cid:107) + (cid:107)1(cid:107)) for a polynomial p(·), and bound
(1 + ε) · 22(cid:98) m
proof we need to show that the error probability of algorithm B is bounded by 1
4 .

can be computed in polynomial time in n. Therefore, to conclude the

3 (cid:99)n2+n
2n3+1

36

Complexity of SHAP-Score-Based Explanations

• Assume that every clique of G contains at most (cid:98) m

3 (cid:99) nodes. Then the error probability
of algorithm B is equal to Pr(B(G, m) returns yes). By using the deﬁnition of B and
Lemma 13 (a) with r = n2, we obtain that:

Pr(B(G, m) returns yes) =

(cid:18)

A(θ(Gn2

(cid:18)

A(θ(Gn2

(cid:18)

A(θ(Gn2

Pr

Pr

Pr

) ∨ x, 1, x) > (1 + ε) ·

(cid:19)

22(cid:98) m

3 (cid:99)n2+n
2n3+1

≤

) ∨ x, 1, x) > (1 + ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

≤

) ∨ x, 1, x) > (1 + ε) · SHAP(θ(Gn2

) ∨ x, 1, x) ∨

A(θ(Gn2

) ∨ x, 1, x) < (1 − ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

=

(cid:18)

A(θ(Gn2

1 − Pr

) ∨ x, 1, x) ≤ (1 + ε) · SHAP(θ(Gn2

) ∨ x, 1, x) ∧

A(θ(Gn2

) ∨ x, 1, x) ≥ (1 − ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

=

1 − Pr

(cid:18)(cid:12)
(cid:12)
A(θ(Gn2
(cid:12)
(cid:12)

1 −

3
4

=

1
4

,

) ∨ x, 1, x) − SHAP(θ(Gn2

) ∨ x, 1, x)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

ε ·

(cid:12)
(cid:12)
(cid:12)
(cid:12)

SHAP(θ(Gn2

) ∨ x, 1, x)

(cid:12)
(cid:19)
(cid:12)
(cid:12)
(cid:12)

≤

where in the last step we use the fact that A is an ε-PRA for the problem of computing
the SHAP score for Boolean classiﬁers given as 2-POS-DNF formulas, and the fact
that SHAP(θ(Gn2) ∨ x, 1, x) ≥ 0 (as can be seen from Lemma 12).

• Assume now that G contains a clique with m nodes. We can assume that n > nε,
since otherwise we know that B returns the correct answer in Step 2. Given that
n > nε, we know from Lemma 14 that:

(1 + ε) ·

22(cid:98) m

3 (cid:99)n2+n
2n3+1

< (1 − ε) ·

1
(n3 + 1)

·

2mn2
2n3+1

.

(17)

The error probability of algorithm B is equal to Pr(B(G, m) returns no). By using
the deﬁnition of B, Lemma 13 (b) with r = n2, and inequality (17), we obtain that:

Pr(B(G, m) returns no) =

(cid:18)

A(θ(Gn2

(cid:18)

A(θ(Gn2

(cid:18)

A(θ(Gn2

Pr

Pr

Pr

) ∨ x, 1, x) ≤ (1 + ε) ·

) ∨ x, 1, x) < (1 − ε) ·

22(cid:98) m

3 (cid:99)n2+n
2n3+1
1
(n3 + 1)

·

(cid:19)

≤

(cid:19)

2mn2
2n3+1

≤

) ∨ x, 1, x) < (1 − ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

≤

37

Arenas, Barcel´o, Bertossi, Monet

(cid:18)

A(θ(Gn2

Pr

) ∨ x, 1, x) < (1 − ε) · SHAP(θ(Gn2

) ∨ x, 1, x) ∨

A(θ(Gn2

) ∨ x, 1, x) > (1 + ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

=

(cid:18)

A(θ(Gn2

1 − Pr

) ∨ x, 1, x) ≥ (1 − ε) · SHAP(θ(Gn2

) ∨ x, 1, x) ∧

A(θ(Gn2

) ∨ x, 1, x) ≤ (1 + ε) · SHAP(θ(Gn2

(cid:19)

) ∨ x, 1, x)

=

1 − Pr

(cid:18)(cid:12)
(cid:12)
A(θ(Gn2
(cid:12)
(cid:12)

1 −

3
4

=

1
4

,

) ∨ x, 1, x) − SHAP(θ(Gn2

) ∨ x, 1, x)

(cid:12)
(cid:12)
(cid:12)
(cid:12)

≤

ε ·

(cid:12)
(cid:12)
(cid:12)
(cid:12)

SHAP(θ(Gn2

) ∨ x, 1, x)

(cid:12)
(cid:19)
(cid:12)
(cid:12)
(cid:12)

≤

where the last step is obtained as in the previous case. This concludes the proof of
Theorem 9.

6.2 Proof of Corollary 10

First, we explain how the result for 2-NEG-DNF can be obtained from the result for 2-
POS-DNF (Theorem 9). For an entity e over a set of features X, let us write InvPol(e)
the entity deﬁned by InvPol(e)(x) := 1 − e(x) for every x ∈ X. For a Boolean classiﬁer M
over variables X, we write InvPol(M ) the Boolean classiﬁer deﬁned by InvPol(M )(e) :=
M (InvPol(e)); in other words, we have changed the polarity of all the features. Then the
following holds:

Lemma 15 Let M be a Boolean classiﬁer over X, e an entity over X and x ∈ X. We
have

SHAP(M, e, x) = SHAP(InvPol(M ), InvPol(e), x).

Proof For every S ⊆ X, we have that

φ(InvPol(M ), InvPol(e), S) =

(cid:88)

e(cid:48)∈cw(InvPol(e),S)

(cid:88)

e(cid:48)∈cw(e,S)
(cid:88)

e(cid:48)∈cw(e,S)
(cid:88)

e(cid:48)∈cw(e,S)

1
2|X\S|

1
2|X\S|

1
2|X\S|

=

=

=

= φ(M, e, S),

38

1
2|X\S|

InvPol(M )(e(cid:48))

InvPol(M )(InvPol(e(cid:48)))

M (InvPol(InvPol(e(cid:48))))

M (e(cid:48))

Complexity of SHAP-Score-Based Explanations

which proves the lemma.

But it is clear that if M is a Boolean classiﬁer deﬁned with a 2-POS-DNF formula ϕ,
then InvPol(M ) is the Boolean classiﬁer deﬁned by the formula obtained from ϕ by replacing
every occurrence of a variable x by the literal ¬x; that is, a formula in 2-NEG-DNF.
Combining Theorem 9 with Lemma 15 then establishes Corollary 10 for the case of 2-NEG-
DNF. The same argument shows that the results for 2-POS-CNF and 2-NEG-CNF are
equivalent, so all that remains to do in this section is to prove the result, say, for 2-NEG-
CNF. But this simply comes from the fact that the negation of a 2-POS-DNF formula is a
2-NEG-CNF formula, and from the fact that, for a Boolean classiﬁer M we have that

SHAP(M, e, x) = −SHAP(¬M, e, x).

(18)

This last property can be easily shown by considering that φ(M, e, S)+φ(¬M, e, S) = 1, for
every Boolean classiﬁer M over a set of features X and every subset S of X. This concludes
the proof of Corollary 10.

7. On Comparing the Values of the SHAP-Score

We now turn our attention to the problem of comparing the SHAP-score of the features
of an entity. The reason we are interested in this problem is that it could be the case
that computing the SHAP-score exactly or approximately is intractable (as we have shown
in the last two sections), but yet that we are able to compare the relevance of features.
In this section we will again use the uniform distribution and drop the subscripts U. We
now deﬁne the problem that we consider. Given a class C of Boolean classiﬁers, the input
of the problem CompSHAP(C) is a Boolean classiﬁer M ∈ C over a set of features X,
an entity e over X and two features x, y ∈ X, and the question to answer is whether
SHAP(M, e, x) > SHAP(M, e, y).8

We prove that this problem is unlikely to be tractable, even for very restricted Boolean
classiﬁers. A formula ϕ is said to be in 3-POS-DNF if ϕ is in POS-DNF and every disjunct
in ϕ contains at most three variables. Then we have that:

Theorem 16 Let C3-POS-DNF be the class of Boolean classiﬁers given as 3-POS-DNF for-
mulas. If CompSHAP(C3-POS-DNF) ∈ BPP, then NP = RP.

Moreover, as in the previous section, Lemma 15 and Equation (18) directly imply that this
result extends to the closure of 3-POS-DNF formulas by duals and negations:

Corollary 17 Let F ∈ {3-POS-DNF, 3-NEG-DNF, 3-POS-CNF, 3-NEG-CNF} and CF
be the class of Boolean classiﬁers given as formulas in F.
If CompSHAP(CF ) ∈ BPP,
then NP = RP.

Hence, all we have to do is to prove Theorem 16. The proof is again technical and divided
in two parts, highlighted in bold in the rest of this section.

8. Note that > can be replaced by any of ≥, <, or ≤, as this does not change the problem.

39

Arenas, Barcel´o, Bertossi, Monet

An intermediate problem: DistCompSHAP(C). As a ﬁrst step, we consider a variation
of the problem CompSHAP. Let C be a class of Boolean classiﬁers. The input of the problem
DistCompSHAP(C) is a pair of Boolean classiﬁers M, M (cid:48) ∈ C over the same set of features X
and the question to answer is whether

SHAP(M ∧ ¬x, e, x) > SHAP(M (cid:48) ∧ ¬y, e(cid:48), y).

where x, y are two features not occurring in X, e is the entity over X ∪ {x} such that
e(x) = 0 and e(z) = 1 for every z ∈ X, and e(cid:48) is the entity over X ∪ {y} such that e(cid:48)(y) = 0
and e(cid:48)(z) = 1 for every z ∈ X. We claim that DistCompSHAP over 3-NEG-CNF formulas
can be reduced in polynomial time to CompSHAP over 2-POS-DNF formulas:

Lemma 18 Let C2-NEG-CNF be the class of Boolean classiﬁers given as 2-NEG-CNF formu-
las. There exists a polynomial-time many-one reduction from DistCompSHAP(C2-NEG-CNF)
to CompSHAP(C3-POS-DNF).

This in particular
DistCompSHAP(C2-NEG-CNF). We need three lemmas to prove Lemma 18.

if CompSHAP(C3-POS-DNF)

implies that

is in BPP then so is

Lemma 19 Given a Boolean classiﬁer M over a set of features X, an entity e over X and
features x, y ∈ X, we have that:

SHAP(M, e, x) − SHAP(M, e, y) =

(cid:88)

S⊆X\{x,y}

|S|! (|X| − |S| − 2)!
(|X| − 1)!

(cid:0)φ(M, e, S ∪ {x}) − φ(M, e, S ∪ {y})(cid:1).

Proof We prove this in Appendix C.2.

Lemma 20 Let X be a set of features, n = |X|, x ∈ X, M be a Boolean classiﬁer over
X \ {x} and e be the entity over X such that e(x) = 0 and e(y) = 1 for every y ∈ X \ {x}.
Then we have that:

SHAP(M ∧ ¬x, e, x) =

n−1
(cid:88)

k=0

k!(n − k − 1)!
n!

·

1
2n−k

(cid:88)

#SAT(M, S).

S⊆X\{x} : |S|=k

Proof This can be established in the same way as Lemma 11 is proved.

Lemma 21 Let X be a set of features, n = |X|, x, y ∈ X, M, M (cid:48) be Boolean classiﬁers
over X \ {x, y} and e be the entity over X such that e(x) = 0, e(y) = 0 and e(z) = 1 for
every z ∈ X \ {x, y}. Then we have that:

SHAP(M ∧ ¬x, e|X\{y}, x) − SHAP(M (cid:48) ∧ ¬y, e|X\{x}, y) =

SHAP((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, y) − SHAP((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, x).

40

Complexity of SHAP-Score-Based Explanations

Proof Let S ⊆ X \ {x, y}. We have that:

φ((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, S ∪ {x}) =

(cid:88)

e(cid:48)∈cw(e,S∪{x})
1
2|X\(S∪{x})|

1
2|X\(S∪{x})|

1
2|X\(S∪{x})|

· ((¬M (cid:48) ∧ x) ∨ (¬M ∧ y))(e(cid:48)) =

(cid:88)

(¬M ∧ y)(e(cid:48)) =

e(cid:48)∈cw(e,S∪{x})
(cid:18)

(cid:88)

(¬M ∧ y)(e(cid:48)) +

e(cid:48)∈cw(e,S∪{x}) : e(cid:48)(y)=1

(cid:88)

(¬M ∧ y)(e(cid:48))

(cid:19)

=

e(cid:48)∈cw(e,S∪{x}) : e(cid:48)(y)=0

1
2|X\(S∪{x})|

1
2|X\(S∪{x})|

1
2|X\(S∪{x})|

(cid:88)

(¬M )(e(cid:48)) =

e(cid:48)∈cw(e,S∪{x}) : e(cid:48)(y)=1

(cid:88)

(¬M )(e(cid:48)) =

e(cid:48)∈cw(e|X\{x,y},S)

· #SAT(¬M, S).

Similarly we have that:

φ((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, S ∪ {y}) =

1
2|X\(S∪{y})|

· #SAT(¬M (cid:48), S).

Hence, we have from Lemma 19 (applied to the classiﬁer (¬M (cid:48) ∧ x) ∨ (¬M ∧ y)) that:

SHAP((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, y) − SHAP((¬M (cid:48) ∧ x) ∨ (¬M ∧ y), e, x) =

(cid:88)

S⊆X\{x,y}

|S|!(|X| − |S| − 2)!
(|X| − 1)!

·

(cid:18)

1
2|X\(S∪{y})|

· #SAT(¬M (cid:48), S) −

1
2|X\(S∪{x})|

· #SAT(¬M, S)

=

(cid:19)

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

#SAT(¬M (cid:48), S)

(cid:19)

−

S⊆X\{x,y} : |S|=k

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

#SAT(¬M, S)

=

(cid:19)

S⊆X\{x,y} : |S|=k

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

(cid:0)2n−2−k − #SAT(M (cid:48), S)(cid:1)

(cid:19)

−

S⊆X\{x,y} : |S|=k

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

(cid:0)2n−2−k − #SAT(M, S)(cid:1)

(cid:19)

=

S⊆X\{x,y} : |S|=k

41

Arenas, Barcel´o, Bertossi, Monet

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

(cid:19)

#SAT(M, S)

−

S⊆X\{x,y} : |S|=k

(cid:18) n−2
(cid:88)

k=0

k!(n − k − 2)!
(n − 1)!

·

1
2n−k−1

(cid:88)

#SAT(M (cid:48), S))

(cid:19)

S⊆X\{x,y} : |S|=k

We can now use Lemma 20 to conclude the proof.

Proof of Lemma 18 Let M, M (cid:48) be Boolean classiﬁers in C2-NEG-CNF over a set of vari-
ables X, which are inputs of DistCompSHAP. Remember that we want to decide whether

SHAP(M ∧ ¬x, e, x) > SHAP(M (cid:48) ∧ ¬y, e(cid:48), y),

where x, y are two features not occurring in X, e is the entity over X ∪ {x} such that
e(x) = 0 and e(z) = 1 for every z ∈ X, and e(cid:48) is the entity over X ∪ {y} such that
e(cid:48)(y) = 0 and e(cid:48)(z) = 1 for every z ∈ X. Observe that ¬M is a formula in 2-POS-DNF,
and that ¬M ∧ y is a formula in 3-POS-DNF (obtained by adding y to every term of ¬M ).
Similarly, ¬M (cid:48) ∧ x is a formula in 3-POS-DNF. Therefore, (¬M (cid:48) ∧ x) ∨ (¬M ∧ y) is also a
formula in 3-POS-DNF, and then Lemma 21 can be used to establish the polynomial-time
many-one reduction.

This concludes the ﬁrst part of the proof. Next, we show that DistCompSHAP is unlikely
to be in BPP for the class of Boolean classiﬁers given as 2-NEG-CNF formulas.

Intractability of DistCompSHAP over 2-NEG-CNF. We now prove that
if
DistCompSHAP(C2-NEG-CNF) ∈ BPP, then NP = RP. Notice that this implies that Theo-
rem 16 holds, given that in the previous section we prove that if CompSHAP(C3-POS-DNF) ∈
BPP, then DistCompSHAP(C2-NEG-CNF) ∈ BPP.

In what follows, we consider the same class of graphs as in the proof of Theorem 9,
that is, the class of all undirected and loop-free graphs G = (N, E) containing at least
two isolated nodes (see Condition (A)). Besides, recall the deﬁnition of the 2-POS-DNF
formula θ(G) from Equation (16). We start our proof with the following lemma:

Lemma 22 Let G = (N, E) be a graph with n = |N | nodes, x be a propositional variable
not occurring in θ(G), and e be an entity such that e(x) = 0 and e(y) = 1 for each variable y
occurring in θ(G). Then we have that:

SHAP(¬θ(G) ∧ ¬x, e, x) =

1
2(n + 1)

n
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

S⊆N : |S|=k

#CLIQUE(G, S).

Proof The proof is similar to that of Lemma 12, but this time we use Lemma 20 instead
of Lemma 11.

We will also need the fact that this quantity cannot be approximated:

42

Complexity of SHAP-Score-Based Explanations

b1

b2

b5

b3

b4

a1

a2

a3

Figure 4: Illustration of the graph G8,3.

Lemma 23 For every ε ∈ (0, 1), the following problem does not admit an ε-PRA, un-
less NP = RP. Given as input a graph G, compute SHAP(¬θ(G) ∧ ¬x, e, x), where x is a
fresh variable not occurring in θ(G) and e is an entity such that e(x) = 0 and e(y) = 1 for
each variable y occurring in θ(G).

Proof From the proof of Theorem 9, we get that there is no ε-PRA for the following
problem, unless NP = RP. Given as input a graph G, compute the quantity:

1
2(n + 1)

n
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

S⊆N : |S|=k

#CLIQUE(G, S).

Hence, Lemma 22 allows us to conclude that Lemma 23 holds.

The idea of our proof is then the following. We will prove that if DistCompSHAP(C2-NEG-CNF)
is in BPP, then there exists a 9
10 -PRA for the problem in Lemma 23, hence deducing
that NP = RP. To this end, we introduce a class of graphs and calculate the values of
SHAP(¬θ(G) ∧ ¬x, e, x) over them. Given n, t ∈ N with t ≤ n, we deﬁne the graph Gn,t =
(Nn,t, En,t) with Nn,t = {a1, . . . , at} ∪ {b1, . . . , bn−t} and En,t = {(bi, bj) | i, j ∈ {1, . . . n −
t} and i (cid:54)= j}. In other words, Gn,t is the disjoint union of a clique with n − t nodes and of a
graph consisting of t isolated nodes. For instance, the graph G8,3 is illustrated in Figure 4.
We calculate the values SHAP(¬θ(Gn,t) ∧ ¬x, e, x) in the next lemma.

Lemma 24 Let n, t ∈ N such that t ≤ n, x be a variable not occurring in θ(Gn,t) and e an
entity such e(x) = 0 and e(y) = 1 for every variable y occurring in θ(Gn,t). Then:

SHAP(¬θ(Gn,t) ∧ ¬x, e, x) =

t
n(n + 1)2n +

1
(t + 1)2t+1 .

Proof By Lemma 22 we have

SHAP(¬θ(Gn,t) ∧ ¬x, e, x) =

1
2(n + 1)

n
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

#CLIQUE(G, S).

S⊆Nn,t : |S|=k

Let A be the set of the t isolated nodes of Gn,t and B be the set of the n − t nodes of Gn,t
that form a clique. In the above expression, it is clear that if S intersects both A and B then
#CLIQUE(G, S) is empty (because S is already not a clique). Moreover, if S is included

43

Arenas, Barcel´o, Bertossi, Monet

in A and is not empty, then #CLIQUE(G, S) is 1 if |S| = 1 and is empty otherwise. Finally,
if S is included in B then we have #CLIQUE(G, S) = 2n−t−|S|. Thus, we obtain

SHAP(¬θ(Gn,t) ∧ ¬x, e, x) =

1
2(n + 1)

1!(n − 1)!
n!

·

1
2n−1

(cid:88)

1

S⊆A : |S|=1

+

1
2(n + 1)

=

t
n(n + 1)2n

+

1
2(n + 1)

n−t
(cid:88)

k=0

n−t
(cid:88)

k=0

k!(n − k)!
n!

·

1
2n−k

(cid:88)

2n−t−k

S⊆B : |S|=k

k!(n − k)!
n!

·

1
2n−k

(cid:19)

(cid:18)n − t
k

2n−t−k

=

t
n(n + 1)2n +

1
2(n + 1)2t

n−t
(cid:88)

k=0

(n − t)!(n − k)!
n!(n − t − k)!

We prove in Appendix C.3 that the sum on the right is equal to n+1

t+1 , so we get

SHAP(¬θ(Gn,t) ∧ ¬x, e, x) =

=

t
n(n + 1)2n +
t
n(n + 1)2n +

1
2(n + 1)2t ·
1
(t + 1)2t+1 ,

n + 1
t + 1

which was to be shown.

As a ﬁnal ingredient, we will also need the following simple observation:

Lemma 25 Let G = (N, E) be a graph with n = |N |, x be a variable not occurring in θ(G)
and e an entity such e(x) = 0 and e(y) = 1 for every variable y occurring in θ(G). Assum-
ing, without loss of generality, that Gn,t has the same nodes as G, for each t ∈ {0, . . . , n},
we have that:

SHAP(¬θ(Gn,n) ∧ ¬x, e, x) ≤ SHAP(¬θ(G) ∧ ¬x, e, x) ≤ SHAP(¬θ(Gn,2) ∧ ¬x, e, x).

Proof By looking at Lemma 22, we see that SHAP(¬θ(G) ∧ ¬x, e, x) can only increase
when edges are added to the graph G. Therefore, this quantity is lower bounded by the
quantity for the graph with n isolated nodes (that is, Gn,n) and upper bounded by the
quantity for the graph Gn,2, given that we only consider graphs with at least two isolated
nodes.

We have the necessary ingredients to ﬁnish the proof of Theorem 16. Assume that there
exists a BPP algorithm A for the problem DistCompSHAP(C2-NEG-CNF). Then the input
of A is a pair of Boolean classiﬁers M, M (cid:48) over a set of features X given as 2-NEG-CNF
formulas, and the task is to verify whether SHAP(M ∧ ¬x, e, x) > SHAP(M (cid:48) ∧ ¬y, e(cid:48), y),

44

Complexity of SHAP-Score-Based Explanations

where x, y are two features not occurring in X, e is an entity over X ∪{x} such that e(x) = 0
and e(z) = 1 for every z ∈ X, and e(cid:48) is an entity over X ∪ {y} such that e(cid:48)(y) = 0 and
e(cid:48)(z) = 1 for every z ∈ X. Using the ampliﬁcation lemma of BPP (Goldreich, 2008, p. 231),
we can ensure that A satisﬁes the following conditions:

• if SHAP(M ∧ ¬x, e, x) > SHAP(M (cid:48) ∧ ¬y, e(cid:48), y), then

Pr(A(M, M (cid:48)) outputs yes) ≥

(cid:18)

1 −

1
4((cid:107)M (cid:107) + (cid:107)M (cid:48)(cid:107))

(cid:19)
.

• If SHAP(M ∧ ¬x, e, x) ≤ SHAP(M (cid:48) ∧ ¬y, e(cid:48), y), then

Pr(A(M, M (cid:48)) outputs no) ≥

(cid:18)

1 −

1
4((cid:107)M (cid:107) + (cid:107)M (cid:48)(cid:107))

(cid:19)

.

Moreover, A(M, M (cid:48)) works in time O(p((cid:107)M (cid:107) + (cid:107)M (cid:48)(cid:107))), where p(·) is a ﬁxed polynomial,
and (cid:107)M (cid:107), (cid:107)M (cid:48)(cid:107) are the sizes of M and M (cid:48) represented as input strings, respectively. By
using BPP algorithm A, we will deﬁne an algorithm B for approximating, given a graph
G = (N, E) containing at least 2 isolated nodes, the value SHAP(¬θ(G) ∧ ¬x, e, x), where x
is a feature not occurring in N and e is the entity over N ∪ {x} such that e(x) = 0 and
e(z) = 1 for every z ∈ N . More precisely, we will show that B is a 9
10 -PRA for this problem.
As mentioned above, this concludes the proof of Theorem 16 by Lemma 23 and Lemma 18.
We now deﬁne B.

Given a graph G = (N, E) containing at least 2 isolated nodes, and assuming that

n = |N |, algorithm B(G) performs the following steps:

1. If n < 4 then compute the exact value of SHAP(¬θ(G) ∧ ¬x, e, x) by using an exhaus-

tive approach.

2. For t = 2 to n:

(a) if A(¬θ(G), ¬θ(Gn,t)) = yes, then return

SHAP(¬θ(Gn,t−1) ∧ ¬x, e, x) + SHAP(¬θ(Gn,t) ∧ ¬x, e, x)

(cid:19)

(cid:18)

1
2

3. Return SHAP(¬θ(Gn,n) ∧ ¬x, e, x).

Algorithm B works in polynomial time since each graph Gn,t can be constructed in polyno-
mial time in n, 2-NEG-CNF formulas ¬θ(G) and ¬θ(Gn,t) can be constructed in polynomial
time from graphs G and Gn,t, algorithm A(¬θ(G), ¬θ(Gn,t)) works in time O(p((cid:107)¬θ(G)(cid:107) +
(cid:107)¬θ(Gn,t)(cid:107))), and the value returned in either Step 2a or Step 3 can be computed in poly-
nomial time in n by Lemma 24.

As the ﬁnal step of this proof, we need to show that:

(cid:18)
(cid:12)
(cid:12)B(G) − SHAP(¬θ(G) ∧ ¬x, e, x)(cid:12)

(cid:12) ≤

Pr

· (cid:12)
(cid:12)SHAP(¬θ(G) ∧ ¬x, e, x)(cid:12)
(cid:12)

(cid:19)

≥

3
4

.

(19)

9
10

45

Arenas, Barcel´o, Bertossi, Monet

We can assume without loss of generality that n ≥ 4, since otherwise the algorithm has
computed the exact value. Assume initially that every call A(¬θ(G), ¬θ(Gn,t)) in algo-
rithm B returns the correct result (we will come back to this assumption later). Because
the values SHAP(¬θ(Gn,t)∧¬x, e, x) are strictly decreasing with t (this is clear by looking at
the expression in Lemma 22), by Lemma 25 we have that either SHAP(¬θ(G) ∧ ¬x, e, x) =
SHAP(¬θ(Gn,n)∧¬x, e, x) or there exists t ∈ {3, . . . , n} such that A(¬θ(G), ¬θ(Gn,t)) = yes
and A(¬θ(G), ¬θ(Gn,t−1)) = no (notice that A(¬θ(G), ¬θ(Gn,2)) = no since G contains at
least 2 isolated nodes). In the former case, the third step of our algorithm ensures that
we return the correct value, so let us focus on the latter case. For some t ∈ {3, . . . , n}, we
have that:

SHAP(¬θ(Gn,t) ∧ ¬x, e, x) < SHAP(¬θ(G) ∧ ¬x, e, x) ≤

SHAP(¬θ(Gn,t−1) ∧ ¬x, e, x).

(20)

Therefore, by considering that the returned value in Step 2a of invocation B(G) is the
average of the left and right terms of the above interval, we obtain that:

(cid:12)B(G) − SHAP(¬θ(G) ∧ ¬x, e, x)(cid:12)
(cid:12)

(cid:12) ≤

SHAP(¬θ(Gn,t−1) ∧ ¬x, e, x) − SHAP(¬θ(Gn,t) ∧ ¬x, e, x)

(cid:19)
.

(cid:18)

1
2

Now, we have by Lemma 24 that:

SHAP(¬θ(Gn,t−1) ∧ ¬x, e, x) − SHAP(¬θ(Gn,t) ∧ ¬x, e, x)

=

(cid:19)

(cid:18)

1
2

t
n(n + 1)2n+1 −

1
(t + 1)2t+2 =

1
n(n + 1)2n+1 ≤

1
t2t+1 −

t − 1
n(n + 1)2n+1 +
1
1
(t + 1)2t+2 −
t2t+1 −
1
1
(t + 1)2t+2 =
t2t+1 −
t + 2
2t

1
(t + 1)2t+1

·

But notice that t+2

2t = 1

2 + 1

t ≤ 9

10 since t ≥ 3. Therefore we have

(cid:12)B(G) − SHAP(¬θ(G) ∧ ¬x, e, x)(cid:12)
(cid:12)

(cid:12) ≤

≤

=

≤

·

·

1
(t + 1)2t+1
(cid:18)

t
n(n + 1)2n +

(cid:19)

1
(t + 1)2t+1

· SHAP(¬θ(Gn,t) ∧ ¬x, e, x)

· SHAP(¬θ(G) ∧ ¬x, e, x),

(21)

9
10
9
10
9
10
9
10

where the last inequality comes from Equation (20).

46

Complexity of SHAP-Score-Based Explanations

To ﬁnish with the proof, we need to remove the assumption that every call
A(¬θ(G), ¬θ(Gn,t)) in algorithm B returns the correct result, and instead compute a lower
bound on the probability that this assumption is true. More precisely, we need to show
that the probability that every call A(¬θ(G), ¬θ(Gn,t)) in algorithm B returns the correct
result is at least 3
4 , as this lower bound together with (21) imply that (19) holds (given that
SHAP(¬θ(G)∧¬x, e, x) = |SHAP(¬θ(G)∧¬x, e, x)| by Lemma 25). For every t ∈ {2, . . . , n},
we have that:

Pr(A(¬θ(G), ¬θ(Gn,t)) outputs the correct result) ≥

1 −

(cid:18)

(cid:18)

≥

1 −

(cid:19)

1
4((cid:107)M (cid:107) + (cid:107)M (cid:48)(cid:107))
1
4n

(cid:19)

since (cid:107)M (cid:107) + (cid:107)M (cid:48)(cid:107) ≥ n. Hence,

(cid:18) n
(cid:94)

Pr

t=2

(cid:0)A(¬θ(G), ¬θ(Gn,t)) outputs the correct result(cid:1)

(cid:19)

(cid:18)

≥

1 −

(cid:18)

≥

1 −

(cid:19)n−1

(cid:19)n

1
4n

1
4n

But it is well known that the function f : x (cid:55)→ (cid:0)1 − 1
4x
and that f (4) > 3

4 . Hence, since we assumed n ≥ 4, we obtain

(cid:1)x is strictly increasing for x ≥ 1,

(cid:18) n
(cid:94)

Pr

t=2

(cid:0)A(¬θ(G), ¬θ(Gn,t)) outputs the correct result(cid:1)

(cid:19)

≥

3
4

.

This concludes the proof of Theorem 16.

8. Final Remarks

Our algorithm for computing the SHAP-score could be used in practical scenarios. Indeed,
some classes of classiﬁers can be compiled into tractable Boolean circuits. This is the
case, for instance, of Bayesian Classiﬁers (Shih et al., 2018b), Binary Neural Networks (Shi
et al., 2020), and Random Forests (Choi et al., 2020). The idea is to start with a Boolean
classiﬁer M given in a formalism that is hard to interpret – for instance a binary neural
network – and to compute a tractable Boolean circuit M (cid:48) that is equivalent to M (this
computation can be expensive). One can then use M (cid:48) and the nice properties of tractable
Boolean circuits to explain the decisions of the model. Hence, this makes it possible to
apply the results in this paper on the SHAP-score to those classes of classiﬁers.

A Boolean circuit representing (or compiled from) another opaque classiﬁer, as those
just mentioned, is also more interpretable (Rudin, 2019), adding a useful property to that
of tractability. Still, it would be interesting to compare the explanations obtained from
the compiled circuit with those that can be obtain directly from, say, the original neural
network. After all, the SHAP-score can be applied to both. First and recent experiments of
this kind are reported in Bertossi and Leon (2023). We should mention, however, that there
are some recent methods to explain the results from a neural network that do not rely only

47

Arenas, Barcel´o, Bertossi, Monet

on its input/output relation (c.f. (Samek et al., 2021) for a recent and thorough review).
Quite recent approaches to the identiﬁcation and modeling of causal structures in deep
learning should open the door for new methodologies for interpretation and explanation
(Ahmed et al., 2020; Sch¨olkopf et al., 2021).

To a large extent, explanations in ML are based on diﬀerent forms of counterfactual- or
causality-based approaches; and the concept of explanation as such is left rather implicit.
However, explanations have been treated in more explicit terms in many disciplines, and,
in particular, in AI, under consistency-based and abductive diagnosis, the main two forms of
model-based diagnosis (Struss, 2008). These are explanations in knowledge representation
with open models. Recent progress has been made in applying model-based diagnosis in
Explainable ML. C.f. Bertossi (2023) and Marques-Silva (2022) for technical details and
references. However, a deeper investigation of this connection in the context of explanations
for classiﬁcation is open.

We conclude this discussion by mentioning a few research directions that our work
opens. First, it would be interesting to extend our tractability results of Sections 3 and 4 to
a setting that could allow for continuous variables, instead of the discrete variables that we
have considered so far. A starting point for such an investigation could for instance be the
framework of probabilistic circuits proposed by Van den Broeck et al. (2019): these are data
structures that can be used to represent probability distributions (possibly with continuous
variables) so as to ensure the tractability of certain tasks, such as expectation computation
or probabilistic inference. Since these circuits are very similar in nature to the deterministic
and decomposable circuit classes that we consider here, it seems that they could also be
used for the SHAP-score. Another natural direction would be to study the complexity
of approximately computing the SHAP-score under so-called empirical distributions, as is
done in Van den Broeck et al. (2021, 2022) for the case of exact computation where they
show that it is intractable in general. For instance, is it the case that there is still no
FPRAS for approximating the SHAP-score of DNF formulas (or monotone DNFs) under
these distributions? Last, we leave open the question of ﬁnding a natural class of Boolean
classiﬁers for which we could eﬃciently approximate the SHAP-score (via an FPRAS),
or eﬃciently compare the SHAP-score of diﬀerent features, whereas computing this score
exactly would be intractable. As we mentioned in Section 6, given that exact model counting
for DNF formulas is intractable but has an FPRAS, and given the strong connections
between model counting and the SHAP-score established in Section 5 or by Van den Broeck
et al. (2021, 2022), DNF formulas were a natural candidate for this. But, quite surprisingly,
our non-approximability results indicate that this is not the case.

Acknowledgments

Part of this work has been funded by ANID - Millennium Science Initiative Program -
Code ICN17002. M. Arenas has been funded by Fondecyt grant 1191337. P. Barcel´o has
been funded by Fondecyt Grant 1200967, and also by the National Center for Artiﬁcial
Intelligence CENIA FB210017, Basal ANID. L. Bertossi is a Senior Researcher at the
IMFD, Chile, and a Professor Emeritus at Carleton University, Ottawa, Canada.

48

Complexity of SHAP-Score-Based Explanations

References

Ossama Ahmed, Frederik Tr¨auble, Anirudh Goyal, Alexander Neitz, Manuel W¨uthrich,
Yoshua Bengio, Bernhard Sch¨olkopf, and Stefan Bauer. Causalworld: A robotic
manipulation benchmark for causal structure and transfer learning.
arXiv preprint
arXiv:2010.04296, 2020. URL https://arxiv.org/abs/2010.04296.

Antoine Amarilli, Florent Capelli, Mika¨el Monet, and Pierre Senellart. Connecting knowl-
edge compilation classes and width parameters. Theory Comput. Syst., 64(5):861–914,
2020. URL https://arxiv.org/abs/1811.02944.

Marcelo Arenas, Pablo Barcel´o, Leopoldo Bertossi, and Mika¨el Monet. The tractability of
SHAP-score-based explanations over deterministic and decomposable boolean circuits. In
Proceedings of AAAI, 2021. URL https://arxiv.org/abs/2007.14045.

Sanjeev Arora and Boaz Barak. Computational Complexity - A Modern Approach. Cam-
bridge University Press, 2009. URL https://theory.cs.princeton.edu/complexity/
book.pdf.

Sanjeev Arora and Shmuel Safra. Probabilistic checking of proofs: A new characterization
of NP. Journal of the ACM (JACM), 45(1):70–122, 1998. URL https://www.cs.umd.
edu/users/gasarch/TOPICS/pcp/AS.pdf.

Sanjeev Arora, Carsten Lund, Rajeev Motwani, Madhu Sudan, and Mario Szegedy.
Proof veriﬁcation and the hardness of approximation problems. Journal of the ACM
(JACM), 45(3):501–555, 1998. URL https://madhu.seas.harvard.edu/papers/1992/
almss-conf.pdf.

Leopoldo Bertossi. Attribution-scores and causal counterfactuals as explanations in arti-
ﬁcial intelligence. CoRR, abs/2303.02829, 2023. doi: 10.48550/arXiv.2303.02829. URL
https://doi.org/10.48550/arXiv.2303.02829. To appear in Reasoning Web. Causal-
ity, Explanations and Declarative Knowledge, Springer LNCS 13759, 2023.

Leopoldo Bertossi and Jorge E. Leon. Opening up the neural network classiﬁer for Shap
score computation. CoRR, abs/2303.06516, 2023. doi: 10.48550/arXiv.2303.06516. URL
https://doi.org/10.48550/arXiv.2303.06516.

Leopoldo Bertossi, Jordan Li, Maximilian Schleich, Dan Suciu, and Zografoula Vagena.
Causality-based explanation of classiﬁcation outcomes. In Proceedings of the Fourth In-
ternational Workshop on Data Management for End-to-End Machine Learning, pages
1–10, 2020. URL https://arxiv.org/abs/2003.06868.

Javier Castro, Daniel G´omez, and Juan Tejada. Polynomial calculation of the Shapley value

based on sampling. Computers & Operations Research, 36(5):1726–1730, 2009.

Giulia Cesari, Encarnaci´on Algaba, Stefano Moretti, and Juan A. Nepomuceno. An appli-
cation of the Shapley value to the analysis of co-expression networks. Applied Network
Science, 3(1):35, 2018. URL https://hal.archives-ouvertes.fr/hal-02103359.

49

Arenas, Barcel´o, Bertossi, Monet

Chaofan Chen, Kangcheng Lin, Cynthia Rudin, Yaron Shaposhnik, Sijia Wang, and Tong
Wang. An interpretable model with globally consistent explanations for credit risk. arXiv
preprint arXiv:1811.12615, 2018. URL https://arxiv.org/abs/1811.12615.

Arthur Choi, Andy Shih, Anchal Goyanka, and Adnan Darwiche. On symbolically encoding
the behavior of random forests. arXiv preprint arXiv:2007.01493, 2020. URL https:
//arxiv.org/abs/2007.01493.

Ian Covert and Su-In Lee. Improving KernelSHAP: Practical Shapley value estimation using
In International Conference on Artiﬁcial Intelligence and Statistics,

linear regression.
pages 3457–3465. PMLR, 2021. URL https://arxiv.org/abs/2012.01536.

Adnan Darwiche. On the tractable counting of theory models and its application to truth
maintenance and belief revision. Journal of Applied Non-Classical Logics, 11(1-2):11–34,
2001. URL https://arxiv.org/abs/cs/0003044.

Adnan Darwiche and Auguste Hirth. On the reasons behind decisions. In ECAI, pages

712–720. IOS Press, 2020. URL https://arxiv.org/abs/2002.09284.

Adnan Darwiche and Pierre Marquis. A knowledge compilation map. Journal of Artiﬁcial
Intelligence Research, 17:229–264, 2002. URL https://arxiv.org/abs/1106.1819.

Anupam Datta, Shayak Sen, and Yair Zick. Algorithmic transparency via quantitative input
inﬂuence: Theory and experiments with learning systems. In 2016 IEEE symposium on
security and privacy (SP), pages 598–617. IEEE, 2016. URL https://www.andrew.cmu.
edu/user/danupam/datta-sen-zick-oakland16.pdf.

Xiaotie Deng and Christos H Papadimitriou. On the complexity of cooperative solution

concepts. Mathematics of Operations Research, 19(2):257–266, 1994.

Daniel Deutch, Nave Frost, Amir Gilad, and Oren Sheﬀer. Explanations for data repair
through Shapley values. In Proceedings of the 30th ACM International Conference on
Information & Knowledge Management, pages 362–371, 2021. URL https://amirgilad.
github.io/publication/cikm21/CIKM21.pdf.

Daniel Deutch, Nave Frost, Benny Kimelfeld, and Mika¨el Monet. Computing the Shapley
value of facts in query answering. In Proceedings of the 2022 International Conference
on Management of Data, pages 1570–1583, 2022. URL https://arxiv.org/abs/2112.
08874.

Ulrich Faigle and Walter Kern. The Shapley value for cooperative games under precedence

constraints. International Journal of Game Theory, 21(3):249–266, 1992.

Uriel Feige, Shaﬁ Goldwasser, L´aszl´o Lov´asz, Shmuel Safra, and Mario Szegedy. Interactive
proofs and the hardness of approximating cliques. Journal of the ACM (JACM), 43(2):
268–292, 1996. URL http://ftp.cs.elte.hu/~lovasz/morepapers/fglss.pdf.

Gil Fidel, Ron Bitton, and Asaf Shabtai. When explainability meets adversarial learn-
In 2020 International

ing: Detecting adversarial examples using SHAP signatures.

50

Complexity of SHAP-Score-Based Explanations

Joint Conference on Neural Networks (IJCNN), pages 1–8. IEEE, 2020. URL https:
//arxiv.org/abs/1909.03418.

Oded Goldreich. Computational complexity: a conceptual perspective. Cambridge University

Press, 2008. URL http://www.wisdom.weizmann.ac.il/~oded/cc-book.html.

Anthony Hunter and S´ebastien Konieczny. On the measure of conﬂicts: Shapley inconsis-
tency values. Artiﬁcial Intelligence, 174(14):1007–1026, 2010. URL http://www.cril.
univ-artois.fr/~konieczny/papers/aij10a.pdf.

Richard M Karp, Michael Luby, and Neal Madras. Monte-carlo approximation algorithms
for enumeration problems. Journal of algorithms, 10(3):429–448, 1989. URL https:
//www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/KLM.pdf.

Ker-I Ko. Some observations on the probabilistic algorithms and NP-hard problems. In-

formation Processing Letters, 14(1):39–43, 1982.

I Elizabeth Kumar, Suresh Venkatasubramanian, Carlos Scheidegger, and Sorelle Friedler.
Problems with Shapley-value-based explanations as feature importance measures.
In
International Conference on Machine Learning, pages 5491–5500. PMLR, 2020. URL
https://arxiv.org/abs/2002.11097.

Ester Livshits, Leopoldo Bertossi, Benny Kimelfeld, and Moshe Sebag. The Shapley value
of tuples in query answering. In ICDT, volume 155 of LIPIcs, pages 20:1–20:19, 2020.
URL https://arxiv.org/abs/1904.08679.

Ester Livshits, Leopoldo Bertossi, Benny Kimelfeld, and Moshe Sebag. The Shapley value
of tuples in query answering. Log. Methods Comput. Sci., 17(3), 2021. doi: 10.46298/
lmcs-17(3:22)2021. URL https://doi.org/10.46298/lmcs-17(3:22)2021.

Scott M Lundberg and Su-In Lee. A uniﬁed approach to interpreting model predictions. In

NeurIPS, pages 4765–4774, 2017. URL https://arxiv.org/abs/1705.07874.

Scott M Lundberg, Gabriel Erion, Hugh Chen, Alex DeGrave, Jordan M Prutkin, Bala Nair,
Ronit Katz, Jonathan Himmelfarb, Nisha Bansal, and Su-In Lee. From local explanations
to global understanding with explainable AI for trees. Nature Machine Intelligence, 2(1):
56–67, 2020. URL https://arxiv.org/abs/1905.04610.

Jo˜ao Marques-Silva. Logic-based explainability in machine learning. CoRR, abs/2211.00541,
2022. doi: 10.48550/arXiv.2211.00541. URL https://doi.org/10.48550/arXiv.2211.
00541. To appear in Reasoning Web. Causality, Explanations and Declarative Knowledge,
Springer LNCS 13759, 2023.

Luke Merrick and Ankur Taly. The explanation game: Explaining machine learning models
using Shapley values. In CD-MAKE, volume 12279 of Lecture Notes in Computer Science,
pages 17–38. Springer, 2020. URL https://arxiv.org/abs/1909.08128.

Tomasz P Michalak, Karthik V Aadithya, Piotr L Szczepanski, Balaraman Ravindran,
and Nicholas R Jennings. Eﬃcient computation of the Shapley value for game-theoretic

51

Arenas, Barcel´o, Bertossi, Monet

network centrality. Journal of Artiﬁcial Intelligence Research, 46:607–650, 2013. URL
https://arxiv.org/abs/1402.0567.

Rory Mitchell, Joshua Cooper, Eibe Frank, and Geoﬀrey Holmes. Sampling permutations
for Shapley value estimation. 2022. URL https://www.jmlr.org/papers/volume23/
21-0439/21-0439.pdf.

C. Molnar. Interpretable machine learning: A guide for making black box models explainable.

2020. URL https://christophm.github.io/interpretable-ml-book/.

Ramin Okhrati and Aldo Lipani. A multilinear sampling algorithm to estimate Shapley
In 2020 25th International Conference on Pattern Recognition (ICPR), pages

values.
7992–7999. IEEE, 2021. URL https://arxiv.org/abs/2010.12082.

Robert Peharz, Steven Lang, Antonio Vergari, Karl Stelzner, Alejandro Molina, Martin
Trapp, Guy Van den Broeck, Kristian Kersting, and Zoubin Ghahramani. Einsum
networks: Fast and scalable learning of tractable probabilistic circuits. arXiv preprint
arXiv:2004.06231, 2020.

J Scott Provan and Michael O Ball. The complexity of counting cuts and of computing
the probability that a graph is connected. SIAM Journal on Computing, 12(4):777–788,
1983.

Shubham Rathi. Generating counterfactual and contrastive explanations using SHAP. arXiv

preprint arXiv:1906.09293, 2019. URL http://arxiv.org/abs/1906.09293.

Marco T´ulio Ribeiro, Sameer Singh, and Carlos Guestrin. “Why should I trust you?”:
Explaining the predictions of any classiﬁer. In SIGKDD, pages 1135–1144. ACM, 2016.
URL https://arxiv.org/abs/1602.04938.

Alvin E Roth. The Shapley value: essays in honor of Lloyd S. Shapley. Cambridge Univer-

sity Press, 1988. URL http://www.library.fa.ru/files/Roth2.pdf.

Cynthia C. Rudin. Stop explaining black box machine learning models for high stakes
decisions and use interpretable models instead. Nature Machine Intelligence, 1:206–215,
2019. URL https://arxiv.org/abs/1811.10154.

Wojciech Samek, Gr´egoire Montavon, Sebastian Lapuschkin, Christopher J Anders, and
Klaus-Robert M¨uller. Explaining deep neural networks and beyond: A review of methods
and applications. Proceedings of the IEEE, 109(3):247–278, 2021. URL https://doi.
org/10.1109/JPROC.2021.3060483.

Bernhard Sch¨olkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalch-
brenner, Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning.
Proceedings of the IEEE, 2021. URL https://arxiv.org/abs/2102.11107.

Lloyd S. Shapley. A value for n-person games. Contributions to the Theory of Games, 2
(28):307–317, 1953. URL http://www.library.fa.ru/files/Roth2.pdf#page=39.

52

Complexity of SHAP-Score-Based Explanations

Weijia Shi, Andy Shih, Adnan Darwiche, and Arthur Choi. On tractable representations
of binary neural networks. In KR, pages 882–892, 2020. URL https://arxiv.org/abs/
2004.02082.

Andy Shih, Arthur Choi, and Adnan Darwiche. Formal veriﬁcation of Bayesian network
classiﬁers. In International Conference on Probabilistic Graphical Models, pages 427–438,
2018a. URL http://proceedings.mlr.press/v72/shih18a.html.

Andy Shih, Arthur Choi, and Adnan Darwiche. A symbolic approach to explaining Bayesian
network classiﬁers. In IJCAI, pages 5103–5111, 2018b. URL https://arxiv.org/abs/
1805.03364.

Andy Shih, Adnan Darwiche, and Arthur Choi. Verifying binarized neural networks by
Angluin-style learning. In International Conference on Theory and Applications of Sat-
isﬁability Testing, pages 354–370. Springer, 2019a. URL http://web.cs.ucla.edu/
~andyshih/assets/pdf/SDCsat19.pdf.

Andy Shih, Guy Van den Broeck, Paul Beame, and Antoine Amarilli. Smoothing structured
decomposable circuits. In NeurIPS, pages 11412–11422, 2019b. URL https://arxiv.
org/abs/1906.00311.

Alistair Sinclair. Algorithms for random generation and counting - a Markov chain approach.
Progress in theoretical computer science. Birkh¨auser, 1993. ISBN 978-0-8176-3658-6.

Erik Strumbelj and Igor Kononenko. An eﬃcient explanation of individual classiﬁcations
using game theory. The Journal of Machine Learning Research, 11:1–18, 2010. URL
https://www.jmlr.org/papers/volume11/strumbelj10a/strumbelj10a.pdf.

Peter Struss. Model-based problem solving.

Foundations of Artiﬁcial Intelligence,
URL https://cse.sc.edu/~mgv/csce781sp13/presentations/

3:395–465, 2008.
struss-handbook-chapter.pdf.

Naoya Takeishi and Yoshinobu Kawahara. On anomaly interpretation via Shapley values.
arXiv preprint arXiv:2004.04464, 2020. URL https://arxiv.org/abs/2004.04464.

Leslie G Valiant. The complexity of computing the permanent. Theoretical computer sci-
ence, 8(2):189–201, 1979. URL https://core.ac.uk/download/pdf/82500417.pdf.

Guy Van den Broeck, Nicola Di Mauro, and Antonio Vergari. Tractable probabilistic models:
Representations, algorithms, learning, and applications, 2019. URL http://web.cs.
ucla.edu/~guyvdb/slides/TPMTutorialUAI19.pdf. Tutorial at UAI 2019.

Guy Van den Broeck, Anton Lykov, Maximilian Schleich, and Dan Suciu. On the tractability
of SHAP explanations. In Proceedings of AAAI, 2021. URL https://arxiv.org/abs/
2009.08634.

Guy Van den Broeck, Anton Lykov, Maximilian Schleich, and Dan Suciu. On the tractability
of SHAP explanations. Journal of Artiﬁcial Intelligence Research, 74:851–886, 2022. URL
https://www.jair.org/index.php/jair/article/view/13283.

53

Arenas, Barcel´o, Bertossi, Monet

Appendix A. Encoding Binary Decision Trees and FBDDs into
Deterministic and Decomposable Boolean Circuits

In this section we explain how FBDDs and binary decision trees can be encoded in linear
time as deterministic and decomposable Boolean circuits. First we need to deﬁne these
formalisms.

Binary Decision Diagrams A binary decision diagram (BDD) over a set of variables
X is a rooted directed acyclic graph D such that: (i) each internal node is labeled with a
variable from X, and has exactly two outgoing edges: one labeled 0, the other one labeled 1;
and (ii) each leaf is labeled either 0 or 1. Such a BDD represents a Boolean classiﬁer in the
following way. Let e be an entity over X, and let πe = u1, . . . , um be the unique path in D
satisfying the following conditions: (a) u1 is the root of D; (b) um is a leaf of D; and (c)
for every i ∈ {1, . . . , m − 1}, if the label of ui is x ∈ X, then the label of the edge (ui, ui+1)
is equal to e(x). Then the value of e in D, denoted by D(e), is deﬁned as the label of the
leaf um. Moreover, a binary decision diagram D is free (FBDD) if for every path from the
root to a leaf, no two nodes on that path have the same label, and a binary decision tree is
an FBDD whose underlying graph is a tree.

Encoding FBDDs and binary decision trees into deterministic and decomposable
Boolean circuits (Folklore). Given an FBDD D over a set of variables X, we explain
how D can be encoded as a deterministic and decomposable Boolean circuit C over X.
Notice that the technique used in this example also apply to binary decision trees, as they are
a particular case of FBDDs. The construction of C is done by traversing the structure of D
in a bottom-up manner. In particular, for every node u of D, we construct a deterministic
and decomposable circuit α(u) that is equivalent to the FBDD represented by the subgraph
of D rooted at u. More precisely, for a leaf u of D that is labeled with (cid:96) ∈ {0, 1}, we
deﬁne α(u) to be the Boolean circuit consisting of only one constant gate with label (cid:96). For
an internal node u of D labeled with variable x ∈ X, let u0 and u1 be the nodes that we
reach from u by following the 0- and 1-labeled edge, respectively. Then α(u) is the Boolean
circuit depicted in the following ﬁgure:

∨

∧

∧

α(u0)

x

α(u1)

¬

x

It is clear that the circuit that we obtain is equivalent to the input FBDD. We now argue
that this circuit is deterministic and decomposable. For the ∨-gate shown in the ﬁgure, if
an entity e is accepted by the Boolean circuit in its left-hand size, then e(x) = 0, while if an
entity e is accepted by the Boolean circuit in its right-hand size, then e(x) = 1. Hence, we
have that this ∨-gate is deterministic, from which we conclude that α(u) is deterministic,

54

Complexity of SHAP-Score-Based Explanations

as α(u0) and α(u1) are also deterministic by construction. Moreover, the ∧-gates shown in
the ﬁgure are decomposable as variable x is mentioned neither in α(u0) nor in α(u1): this is
because D is a free BDD. Thus, we conclude that α(u) is decomposable, as α(u0) and α(u1)
are decomposable by construction. Finally, if uroot is the root of D, then by construction
we have that α(uroot) is a deterministic and decomposable Boolean circuit equivalent to D.
Note that this encoding can trivially be done in linear time. Thus, we often say, by abuse
of terminology, that “FBDDs (or binary decision trees) are restricted kinds of deterministic
and decomposable circuits”.

Appendix B. Proof of a folklore fact

Fact 26 (Folklore) Let f be a function that admits an ε-PRA for ε ∈ (0, 1). Then the
problem of determining, given a string x, whether f (x) = 0 is in BPP.

Proof Let A be an ε-PRA for f , that is, a randomized algorithm that takes as input
a string x, and computes in polynomial time in the size of x a value A(x) such that
((cid:63)) Pr (cid:0)|f (x) − A(x)| ≤ ε |f (x)|(cid:1) ≥ 3
4 . We claim that the following algorithm is a BPP
algorithm for deciding if f (x) = 0: compute A(x), and if this is equal to zero then ac-
cept, otherwise reject. We will assume without loss of generality that f (x) ≥ 0, as the
case f (x) ≤ 0 can be handled in the same way. Observe that ((cid:63)) can be equivalently
rewritten as (†) Pr (cid:0)(1 − ε)f (x) ≤ A(x) ≤ (1 + ε)f (x)(cid:1) ≥ 3

4 . But then:

• Assume ﬁrst that f (x) = 0. Then by (†) we have that Pr (cid:0)A(x) = 0(cid:1) ≥ 3

4 as well, so

that we accept with probability at least 3
4 .

• Assume now that f (x) (cid:54)= 0. Then (†) gives us Pr (cid:0)A(x) ≥ (1 − ε)f (x) > 0(cid:1) ≥ 3
that we reject with probability at least 3
4 .

4 , so

This concludes the proof.

Appendix C. Proofs of Intermediate Results

C.1 Proof of Lemma 14

We notice that the inequality holds if and only if

1 + ε
1 − ε

· (n3 + 1) · 2n < 2mn2−2(cid:98) m

3 (cid:99)n2

.

Moreover, given that m ≥ 1, we have that:

2mn2−2(cid:98) m

3 (cid:99)n2

3 n2

≥ 2mn2− 2m
m
3 n2
= 2
n2
3 .

≥ 2

55

Arenas, Barcel´o, Bertossi, Monet

Therefore, we conclude that the inequality in the statement of the lemma holds from the
fact that there exists z0 such that:

1 + ε
1 − ε

· (z3 + 1) · 2z < 2

z2
3

for every z ≥ z0.

This is indeed clear, as the dominating factor of the left term is 2O(z) whereas that of the
the right term is 2O(z2).

C.2 Proof of Lemma 19

We prove the more general claim that for any Boolean classiﬁer M over features X, proba-
bility distribution D over ent(X), entity e ∈ ent(X) and features x, y ∈ X, we have

SHAPD(M, e, x) − SHAPD(M, e, y) =

(cid:88)

S⊆X\{x,y}

|S|! (|X| − |S| − 2)!
(|X| − 1)!

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S ∪ {y})(cid:1).

Indeed, we have:

SHAPD(M, e, x) − SHAPD(M, e, y) =

(cid:88)

S⊆X\{x}

(cid:88)

−

S⊆X\{y}

|S|! (|X| − |S| − 1)!
|X|!

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S)(cid:1)

|S|! (|X| − |S| − 1)!
|X|!

(cid:0)φD(M, e, S ∪ {y}) − φD(M, e, S)(cid:1)

We cut the ﬁrst sum in half by considering (1) those S that are ⊆ X \ {x, y} and (2)
those S ⊆ X such that with y ∈ S and x /∈ S; and do the same for the second sum. We
end up with

SHAPD(M, e, x) − SHAPD(M, e, y) =
|S|! (|X| − |S| − 1)!
|X|!

(cid:88)

S⊆X\{x,y}

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S ∪ {y})(cid:1)

+

−

(cid:88)

S⊆X\{x,y}

(cid:88)

S⊆X\{x,y}

(|S| + 1)! (|X| − |S| − 2)!
|X|!

(|S| + 1)! (|X| − |S| − 2)!
|X|!

(cid:0)φD(M, e, S ∪ {x, y}) − φD(M, e, S ∪ {y})(cid:1)

(cid:0)φD(M, e, S ∪ {x, y}) − φD(M, e, S ∪ {x})(cid:1)

(cid:88)

=

S⊆X\{x,y}

|S|! (|X| − |S| − 1)!
|X|!

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S ∪ {y})(cid:1)

(cid:88)

+

S⊆X\{x,y}

(|S| + 1)! (|X| − |S| − 2)!
|X|!

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S ∪ {y})(cid:1)

56

Complexity of SHAP-Score-Based Explanations

(cid:88)

=

S⊆X\{x,y}

|S|! (|X| − |S| − 2)!
(|X| − 1)!

(cid:0)φD(M, e, S ∪ {x}) − φD(M, e, S ∪ {y})(cid:1).

This concludes the proof.

C.3 The summation in Lemma 24

To ease the proof, we let s = n − t. Then we want to compute

n−t
(cid:88)

k=0

(n − t)!(n − k)!
n!(n − t − k)!

=

s
(cid:88)

k=0

s!(s + t − k)!
(s + t)!(s − k)!

.

We have that:

s
(cid:88)

k=0

s!(s + t − k)!
(s + t)!(s − k)!

=

=

=

=

s!
(s + t)!

s!t!
(s + t)!

s!t!
(s + t)!

s!t!
(s + t)!

·

·

·

·

s
(cid:88)

k=0
s
(cid:88)

k=0
s
(cid:88)

k=0
s
(cid:88)

k=0

(s + t − k)!
(s − k)!

(s + t − k)!
t!(s − k)!

(cid:19)

(cid:18)s + t − k
s − k

(cid:18)t + k
k

(cid:19)

.

Next, we show that the following equality holds by induction on s:

s
(cid:88)

k=0

(cid:19)

(cid:18)t + k
k

=

(cid:18)s + t + 1
s

(cid:19)
.

First, consider s = 0:

s
(cid:88)

k=0

(cid:19)

(cid:18)t + k
k

=

0
(cid:88)

k=0

(cid:19)

(cid:18)t + k
k

=

(cid:19)

(cid:18)t + 0
0

= 1 =

(cid:19)

(cid:18)0 + t + 1
0

=

(cid:18)s + t + 1
s

(cid:19)
.

Now, assuming that (23) holds, we have that:

(22)

(23)

s+1
(cid:88)

k=0

(cid:19)

(cid:18)t + k
k

=

=

=

=

(cid:19)

(cid:18)t + s + 1
s + 1
(cid:18)t + s + 1
s + 1

(cid:19)

by (23)

by Pascal’s rule

(cid:19)

.

s
(cid:88)

(cid:18)t + k
k

(cid:19)

+

+

(cid:19)

k=0
(cid:18)s + t + 1
s
(cid:18)s + t + 2
s + 1
(cid:18)s + 1 + t + 1
s + 1

(cid:19)

57

Arenas, Barcel´o, Bertossi, Monet

Hence, we conclude from (22) and 23 that:

s
(cid:88)

k=0

s!(s + t − k)!
(s + t)!(s − k)!

=

=

=

s!t!
(s + t)!

(cid:19)

(cid:18)s + t + 1
s

·

·

s!t!
(s + t)!
s + t + 1
t + 1

(s + t + 1)!
s!(t + 1)!

,

and this is n+1

t+1 , as promised.

58

