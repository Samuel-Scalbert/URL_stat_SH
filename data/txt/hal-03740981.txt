UniRank: Unimodal Bandit Algorithm for Online
Ranking
Camille-Sovanneary Gauthier, Romaric Gaudel, Elisa Fromont

To cite this version:

Camille-Sovanneary Gauthier, Romaric Gaudel, Elisa Fromont. UniRank: Unimodal Bandit Algo-
ICML 2022 - 39th International Conference on Machine Learning, Jul
rithm for Online Ranking.
2022, Baltimore, United States. pp.1-31. ￿hal-03740981￿

HAL Id: hal-03740981

https://inria.hal.science/hal-03740981

Submitted on 2 Aug 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

UniRank: Unimodal Bandit Algorithm for Online Ranking

Camille-Sovanneary Gauthier * 1 2 Romaric Gaudel * 3 Elisa Fromont 4 5 2

Abstract

We tackle, in the multiple-play bandit setting, the
online ranking problem of assigning L items to
K predeﬁned positions on a web page in order
to maximize the number of user clicks. We pro-
pose a generic algorithm, UniRank, that tackles
state-of-the-art click models. The regret bound
of this algorithm is a direct consequence of the
unimodality-like property of the bandit setting
with respect to a graph where nodes are ordered
sets of indistinguishable items. The main con-
tribution of UniRank is its O (L/∆ log T ) regret
for T consecutive assignments, where ∆ relates
to the reward-gap between two items. This re-
gret bound is based on the usually implicit con-
dition that two items may not have the same at-
tractiveness. Experiments against state-of-the-art
learning algorithms specialized or not for differ-
ent click models, show that our method has better
regret performance than other generic algorithms
on real life and synthetic datasets.

1. Introduction

We consider Online Recommendation Systems (ORS) which
choose K relevant items among L potential ones (L ≥ K),
such as songs, ads or movies to be displayed on a web-
site. The user feedbacks, such as listening time, clicks,
rates, etc., reﬂecting the user’s appreciation with respect to
each displayed item, are collected after each recommenda-
tion. As these feedbacks are only available for the items
which were actually presented to the user, this setting cor-
responds to an instance of the multi-armed bandit problem
with semi-bandit feedback (Gai et al., 2012; Chen et al.,

*Equal contribution 1Louis Vuitton, F-75001 Paris, France
2IRISA UMR 6074 / INRIA rba, F-35000 Rennes, France
3Univ Rennes, Ensai, CNRS, CREST - UMR 9194, F-35000
Rennes, France 4Univ. Rennes 1, F-35000 Rennes, France
5 Institut Universitaire de France, M.E.S.R.I., F-75231 Paris.
Correspondence to: Camille-Sovanneary Gauthier <camille-
sovanneary.gauthier@louisvuitton.com>.

Proceedings of the 39 th International Conference on Machine
Learning, Baltimore, Maryland, USA, PMLR 162, 2022. Copy-
right 2022 by the author(s).

2013). Besides, some displayed items are not looked at and
lead to a negative feedback while they would be appreciated
by the user. It raises a speciﬁc challenge related to rank-
ing: the attention toward a displayed item is impacted by
its position. Numerous approaches have been proposed to
handle this partial attention (Radlinski et al., 2008; Combes
et al., 2015; Lagr´ee et al., 2016) referred to as multiple-play
bandit or online learning to rank. Several models of partial
attention, a.k.a. click models, are considered in the state of
the art (Richardson et al., 2007; Craswell et al., 2008) and
have been transposed to the bandit framework (Kveton et al.,
2015a; Komiyama et al., 2017). In current paper, in the same
line as (Zoghi et al., 2017; Lattimore et al., 2018) we pro-
pose an algorithm which handles multiple state-of-the-art
click models.

The main contribution of our work is a new bandit algo-
rithm, UniRank, dedicated to a generic online learning to
rank setting. UniRank takes inspiration from unimodal
bandit algorithms (Combes & Prouti`ere, 2014; Gauthier
et al., 2021b): we implicitly consider a graph G on the parti-
tions of the item-set such that the considered bandit setting
is unimodal w.r.t. G, and UniRank chooses each recom-
mendation in the G-neighborhood of an elicited partition.
Thanks to this restricted exploration, UniRank is the ﬁrst al-
gorithm dedicated to a generic setting with a O(L/∆ log T )
regret upper-bound, while previous state-of-the-art algo-
rithms were suffering a O(LK/∆ log T ) regret. Note that
this O(L/∆ log T ) upper-bound requires all items’ attrac-
tiveness to be different, which is a usual assumption satisﬁed
by real world applications. Otherwise, UniRank recovers
the O(LK/∆ log T ) bound. From an application point of
view, UniRank has several interesting features: it handles
multiple state-of-the-art click models altogether; it is simple
to implement and efﬁcient in terms of computation time; it
does not require the knowledge of the time horizon T ; and
it exhibits a smaller empirical regret than other generic al-
gorithms by leaning on the different attractiveness property
when this property is satisﬁed.

As an indirect contribution, UniRank demonstrates that uni-
modality is a key tool to analyze the intrinsic complexity of
some combinatorial semi-bandit problems. We also demon-
strate the ﬂexibility of unimodal bandit algorithms and of the
proof of their regret upper-bound. In particular, we extend
(Combes & Prouti`ere, 2014)’s analysis to a graph which is

UniRank: Unimodal Bandit Algorithm for Online Ranking

Table 1. Required click model and upper-bound on cumulative regret for T consecutive recommendations for some well-known recom-
mender algorithms that chose K items among L. The exact deﬁnition of ∆ is speciﬁc to each algorithm. The symbol ∗ means that
Assumption 3.1∗, deﬁned in Section 3.1, is satisﬁed. κκκ denotes the vector of observation-probabilities of PBM, and γ is the degree of the
graph explored by the unimodal bandit algorithm.

Algorithm

UniRank (our algorithm)

TopRank (Lattimore et al., 2018)

Click model
CM∗
PBM∗, . . .
PBM, CM, . . .
PBM, CM, . . .

Regret

O ((L − K)/∆ log T )
O (L/∆ log T )
O (LK/∆ log T )
O (LK/∆ log T )

CascadeKL-UCB (Kveton et al., 2015a) CM
GRAB (Gauthier et al., 2021b)
PB-MHB (Gauthier et al., 2021a)
PBM-PIE (Lagr´ee et al., 2016)
SAM (Sentenac et al., 2021)
OSUB (Combes & Prouti`ere, 2014)

O ((L − K)/∆ log T )
O (L/∆ log T )
unknown

PBM∗
PBM (κκκ1 = 0)
PBM (κκκ known) O ((L − K)/∆ log T )
Matching∗
Unimodal

O (L log L/∆ log T )
O (γ/∆ log T )

unimodal in a weaker sense: (i) UniRank takes its decisions
given an optimistic index which is not based on the expected
reward but on the probability for an item to be more attrac-
tive than another one and (ii) some sub-optimal nodes in the
graph have no better node in their neighborhood.

The paper is organized as follows: Section 2 presents the
related work and Section 3 deﬁnes our target setting. We
then introduce UniRank in Section 4, and theoretical guar-
antees and empirical performance are presented respectively
in Section 5 and Section 6. We conclude in Section 7.

2. Related Work

Table 1 shows a comparison of the assumptions and the
regret upper-bounds of the most related algorithms.

Several bandit algorithms are designed to handle the online
learning to rank setting while the user follows one of the
currently deﬁned click models, namely the position based
model (PBM) (Komiyama et al., 2015; Lagr´ee et al., 2016;
Komiyama et al., 2017; Gauthier et al., 2021a;b) or the cas-
cading model (CM) (Kveton et al., 2015a;b; Combes et al.,
2015; Zong et al., 2016; Katariya et al., 2016; Li et al., 2016;
Cheung et al., 2019). To the best of our knowledge, only the
algorithms BatchRank (Zoghi et al., 2017), TopRank (Latti-
more et al., 2018), and BubbleRank (Li et al., 2019a) handle
users following a general model covering both behaviors.
These three algorithms exhibit a regret upper-bound for T
consecutive recommendations of at least O(LK/∆ log T ),
where ∆ depends on the attraction probability θθθ of items.

One ingredient of TopRank and BubbleRank is a statistic to
compare two items independently of the position at which
they are displayed. The algorithm we propose also makes
use of this statistic. However, we deﬁne an exploration
strategy which does not require the knowledge of the time-

horizon T and which induces a O(L/∆ log T ) regret upper-
bound when items have strictly different attractiveness.

UniRank also builds upon an extension of the unimodal
bandit setting (Combes & Prouti`ere, 2014; Gauthier et al.,
2021b). This setting assumes the knowledge of a graph G on
the set A of bandit arms, such that the expected reward µaaa
associated to each arm aaa satisﬁes the following assumption:

Assumption 2.1 (Unimodality1). There exists a unique arm
aaa∗ ∈ A with highest expected reward, and for any arm
aaa ∈ A, either (i) aaa = aaa∗, or (ii) there exists aaa+ in the
neighborhood NG (aaa) of aaa given G such that µaaa+ > µaaa.

The unimodal bandit algorithms are aware of G, but ignore
the weak order induced by the edges of G. However, they
rely on G to efﬁciently browse the arms up to the best one.
Typically, the algorithm OSUB (Combes & Prouti`ere, 2014)
selects at each iteration t, an arm aaa(t) in the neighborhood
NG (˜aaa(t)) given G of the current best arm ˜aaa(t) (a.k.a. the
leader). By restricting the exploration to this neighbor-
hood, the regret suffered by OSUB scales in O(γ/∆ log T ),
where γ is the maximum degree of G, to be compared with
O(|A|/∆ log T ) if the arms were independent. OSUB is
designed for the standard bandit setting and makes use of es-
timators of the expected reward of arms to select the leader
and chose the arm to play. In comparison, UniRank extends
OSUB’s idea to the semi-bandit setting, relies on a new vari-
ant of the unimodality property (see Lemma 5.4), selects the
leader and the recommended arm based on other statistics,
and does not require the ‘forced exploitation’ step which
consists in recommending the leader each γ-th iteration.

1Usually, the unimodality is deﬁned as the existence of a strictly
increasing path from any sub-optimal arm to aaa∗. Assumption 2.1
is equivalent and we use it in this paper as it directly relates to the
shape of the theoretical analysis.

UniRank: Unimodal Bandit Algorithm for Online Ranking

Finally, (Gauthier et al., 2021b) also builds upon the uni-
modality framework to solve a learning to rank problem in
the bandit setting. However, the corresponding algorithm
(GRAB) is dedicated to the PBM click model. In this model,
there is a natural statistic to look at to measure the quality of
an item and a position: the probability of click when present-
ing item i in position k. This statistic is independent of the
items at other positions. Within a CM model, such a statistic
does not exist. Instead, we refer to a statistic related to the
relative attractiveness of items i and j (which we denote
ˆsi,j). Secondly, in the PBM model, only weak assumptions
are needed to guarantee a unique optimal recommendation,
which is required to get the unimodality property. With a
CM model, any recommendation including the K best items
leads to the optimal reward. To recover the unicity of the
best arm, our algorithm is not targeting the best reward, but
the best ranking of items (which implies the best reward).
However, when facing PBM model, our algorithm requires
an assumption which is omitted by GRAB: the position are
indexed from the most look-at position to the least one.

the cumulative regret

(cid:34)

R(T ) = E

T µ∗ −

(cid:35)

µaaa(t)

,

T
(cid:88)

t=1

(1)

where the expectation is taken w.r.t. the recommendations
from the algorithm and the clicks.

Illustration 3.1 (Click model PBM). With the click model
PBM, at each iteration t, the user looks at the position k with
probability κk, independently of the displayed items aaa(t).
Moreover, whenever she observes the position k, she clicks
on the corresponding item ak(t) with probability θak(t), in-
dependently of her other actions. Overall, the clicks cak(t)(t)
are independent and ρ(aaa(t), k) = E (cid:2)cak(t)(t)(cid:3) = κkθak(t).
Therefore, the optimal recommendation consists in display-
ing the item i with the (cid:96)-th highest value θi at the position
k with the (cid:96)-th highest value θk. Hence, if θ1 > θ2 >
· · · > θK > maxK<k(cid:54)L θk and κ1 > κ2 > · · · > κK,
µ∗ = (cid:80)K

k=1 κkθk.

3. Learning to Rank in a Semi-Bandit Setting

3.1. Modeling Assumption

We consider the following online learning to rank (OLR)
problem with clicks feedback. For any integer n,
let
[n] denote the set {1, . . . , n}. A recommendation aaa =
(a1, . . . , aK) is a permutation of K distinct items among L,
where ak is the item displayed at position k and aaa([K]) :=
{ak : k ∈ [K]} is the set of all displayed items. We denote
P L
K the set of such permutations. Throughout the paper,
we will use the terms permutation and recommendation
interchangeably to denote an element of P L
K.

An instance of our OLR problem is a tuple (L, K, ρ), where
L is the number of available items, K (cid:54) L is the number
of positions to display the items, and ρ is a function from
P L
K × [K] to (0, 1] such that for any recommendation aaa and
position k, ρ(aaa, k) is the probability for a user to click on
the item displayed at position k when recommending aaa.

A recommendation algorithm is only aware of L and K and
has to deliver T consecutive recommendations. At each
iteration t ∈ [T ], the algorithm recommends a permutation
aaa(t) and observes the values ca1(t)(t), . . . , caK (t)(t), where
for any position k, cak(t)(t) equals 1 whenever the user
clicks on the item ak(t), and 0 otherwise. To keep notations
simple, we also deﬁne ci(t) = 0 for each undisplayed item
i ∈ [L] \ aaa(t)([K]). Note that the recommendation at time t is
only based on previous recommendations and observations.

While the individual clicks are observed, the reward of the al-
gorithm is their sum r(t) := (cid:80)K
i=1 ci(t).
Let µaaa denote the expectation of r(t) when the recommen-
dation is aaa(t) = aaa, and µ∗ := maxaaa∈P L
µaaa the highest
expected reward. The aim of the algorithm is to minimize

k=1 cak(t)(t) = (cid:80)L

K

Up to now, an OLR problem assumes two main properties:
(i) a click at a position is a random variable only condi-
tioned by the recommendation and the position, and (ii) the
expectation of the corresponding distribution is ﬁxed. We
now introduce the three assumptions required by UniRank,
which are fulﬁlled by PBM and CM click models.

We ﬁrst assume an order on items. Note that the existence
of an order on item is a weak assumption by itself (we may
chose any random order). The strength of this assumption
derives from Assumptions 3.2 and 3.3 which enforces this
order to relate with expected reward.

Assumption 3.1 (Strict weak order). There exists a prefer-
ential attachment function g : [L] → R on items, and for
any pair of items (i, j),

• if g(i) > g(j), item i is said more attractive than item

j, which we denote i (cid:31) j;

• if g(i) = g(j), item i is said equivalent to item j,

which we denote i ∼ j.

Illustration 3.2 (Strict weak order with PBM). With PBM,
a typical choice for the function g is g : i (cid:55)→ θi.

Assumption 3.1 ensures the existence of a strict weak or-
der (cid:31) on items: the items may be ranked by attractiveness,
some items being equivalent. A typical example with L = 4
would be 1 (cid:31) 2 ∼ 3 (cid:31) 4, meaning item 1 is more attrac-
tive than any other item, and items 2 and 3 are equivalent
and more attractive than item 4. Such situation may also
be represented with an ordered partition: ({1}, {2, 3}, {4}),
where if the subset E is listed before the subset F , then for

UniRank: Unimodal Bandit Algorithm for Online Ranking

any item i ∈ E and any item j ∈ F , i (cid:31) j. In the rest of the
paper we will use either the preferential attachment func-
tion, or its associated strict weak order, or the corresponding
ordered partition depending on the most appropriate repre-
sentation.

The strongest results of the theoretical analysis require the
slightly stronger assumption which ensures that the K best
items are uniquely deﬁned. This assumption is equivalent
to any of both hypothesis: (i) the order (cid:31) is total on the K
best items and the K-ith item is strictly more attractive than
remaining L − K items, and (ii) each of the K ﬁrst subsets
of the ordered partition is composed of only one item.
Assumption 3.1∗ (Strict total order on top-K items). There
exists a preferential attachment function g : [L] → R and
a permutation aaa ∈ P L
K s.t. g(a1) > g(a2) > · · · > g(aK)
and for any item j ∈ [L] \ aaa([K]), g(aK) > g(j).

Our next assumption states that recommending the items
according to the order (cid:31) associated to the preferential at-
tachment leads to an optimal recommendation.

Deﬁnition 3.1 (Compatibility with a strict weak order). Let
(cid:31) be a strict weak order on items, and aaa be a recommenda-
tion. The recommendation aaa is compatible with (cid:31) if

1. for any position k ∈ [K − 1], either ak (cid:31) ak+1 or

ak ∼ ak+1;

2. for any item j ∈ [L] \ aaa([K]), either aK (cid:31) j or aK ∼ j.

Assumption 3.2 (Optimal reward). Any recommendation aaa
compatible with (cid:31) is optimal, meaning µaaa = µ∗.
Illustration 3.3 (Optimal reward with PBM). With PBM,
if the positions are ranked by decreasing observation prob-
abilities and g(i) = θi, this assumption means that the
recommendation placing the k-th most attractive item at the
k-th most observed position is optimal, which indeed is true.

Assumption 3.2 is of utmost importance for UniRank as it
means that identifying a partition of the items coherent with
(cid:31) is sufﬁcient to ensure optimal recommendations.

Let us now consider the last assumption which regards the
expectation of the random variable ci(t) − cj(t).
Deﬁnition 3.2 (Expected click difference). Let i and j be
two items, and aaa a recommendation. The probability of
difference and the expected click difference between items i
and j w.r.t. the recommendation aaa are respectively:

Algorithm 1 UniRank: Unimodal Bandit Algorithm for
Online Ranking

Require: number of items L, number of positions K
1: for t = 1, 2, . . . do
2:
3:

compute the leader partition ˜PPP (t)
PPP (t) ← argmaxPPP ∈{ ˜PPP (t)}∪N ( ˜PPP (t)) bPPP (t)
draw the recommendation aaa(t) uniformly at random
in A (PPP (t))
observe the clicks vector ccc(t)

4:

5:
6: end for

the permutation aaa where item i is replaced by item j (resp.
j by i). If neither i nor j belongs to aaa, (i, j) ◦ aaa is aaa.

Assumption 3.3 (Order identiﬁability). The strict weak or-
der (cid:31) on items is identiﬁable, meaning that for any couple
of items (i, j) in [L]2 s.t. i (cid:31) j, and for any recommen-
dation aaa ∈ P L
K s.t. at least one of both items is displayed,
˜δi,j(aaa) (cid:54)= 0 and ˜∆i,j(aaa) > 0 .
Illustration 3.4 (Expected click difference with PBM).
With the click model PBM, if the positions are ranked
by decreasing observation probabilities, for any recom-
mendation aaa, any position k ∈ [K] and any position
(cid:96) ∈ [L] \ {k}, denoting i and j the items at respective posi-
tions k and (cid:96), ˜δi,j(aaa) = 1
2 (θi + θj) (κk + κ(cid:96)) − 2θiθjκkκ(cid:96)
and ˜∆i,j(aaa) = θi−θj
di,j(aaa), where di,j(aaa) > 1. Therefore,
θi+θj
if g(i) = θi, Assumption 3.3 is fulﬁlled.

The expected click difference reﬂects the fact that an item
leads to more clicks than another independently of the po-
sition of both items (other items being unchanged). Hence,
Assumption 3.3 points out that when an item is more at-
tractive than another one, it has a higher probability to be
clicked upon, all other things being equal. This assumption
is natural and ensures that the order on items may be recov-
ered from the expected click difference, which is observed.

Finally, the following lemma, proven in Appendix D, states
that both CM and PBM models fulﬁll our assumptions.

Lemma 3.1. Let (L, K, ρ) be an online learning to rank
problem with users following CM or PBM model with posi-
tions ranked by decreasing observation probabilities. Then
Assumptions 3.1, 3.2, and 3.3 are fulﬁlled. Furthermore,
Assumption 3.1∗ is fulﬁlled if, for any top-K item i and any
item j in [L] \ {i}, either i (cid:31) j or j (cid:31) i.

˜δi,j(aaa) = Paaa(t)∼U ({aaa,(i,j)◦aaa}) [ci(t) (cid:54)= cj(t)] and
˜∆i,j(aaa) = Eaaa(t)∼U ({aaa,(i,j)◦aaa}) [ci(t) − cj(t) | ci(t) (cid:54)= cj(t)] ,

where (i, j) ◦ aaa is the permutation aaa such that items i and j
have been swapped, and U(S) is the uniform distribution on
the set S. If only i (respectively j) belongs to aaa, (i, j) ◦ aaa is

4. UniRank Algorithm

Our algorithm, UniRank, is detailed in Algorithm 1, and Fig-
ure 1 unfolds one of its iterations. This algorithm takes inspi-
ration from the unimodal bandit algorithm OSUB (Combes
& Prouti`ere, 2014) by selecting at each iteration t an arm
to play PPP (t) in the neighborhood of the current best one

UniRank: Unimodal Bandit Algorithm for Online Ranking

1

2

3

4

5

6

7

˜PPP =

(cid:16) ˜P1, ˜P2, ˜P3, ˜P4
N ( ˜PPP ) = {({1, 2, 3}, {4, 5}, {6, 7}) ,

(cid:17)

({1, 2}, {3, 4, 5}, {6, 7}) ,

= ({1, 2}, {3}, {4, 5}, {6, 7})

% merge of ˜P1 and ˜P2
% merge of ˜P2 and ˜P3

({1, 2}, {3}, {4, 5, 6}, {7}) , % try 6

({1, 2}, {3}, {4, 5, 7}, {6})} % try 7

PPP = ({1, 2}, {3, 4, 5}, {6, 7})

% the 2nd neighbor wins

aaa = (2, 1, 3, 5)

Figure 1. One iteration of UniRank with L = 7 items and K = 4
positions (t is omitted for clarity). Each arrow i → j in the
top graph on items means the statistic ˆsi,j is non-negative.
With these values, the leader partition (represented with dashed
ellipses) is ˜PPP = ({1, 2}, {3}, {4, 5}, {6, 7}), where ˜P4 = {6, 7}
gathers remaining items as the 3 ﬁrst partitions contain
more than K items. Then, we assume that max(¯¯s3,1, ¯¯s3,2) >
max(max(¯¯s4,3, ¯¯s5,3), max(¯¯s6,4, ¯¯s6,5), max(¯¯s7,4, ¯¯s7,5),
partition
Therefore,
plays
PPP = ({1, 2}, {3, 4, 5}, {6, 7}).
Finally the recommenda-
tion aaa is obtained by concatenating a random permutation
of P1 = {1, 2} with a random permutation of 2 items from
P2 = {3, 4, 5}.

optimistic

UniRank

the

0).

˜PPP (t) (a.k.a.
the leader). However, UniRank’s arms are
not recommendations but sets of recommendations repre-
sented by ordered partitions. Hence, the recommendation
aaa(t) is drawn uniformly at random in the subset A(PPP (t)) of
recommendations compatible with PPP (t).

Let us now ﬁrst deﬁne the notations used by UniRank and
then present its concrete behaviour.

Statistic ˆsi,j(t) UniRank’s choices are based on the statis-
tic ˆsi,j(t) and the optimistic estimator of its expected value:
the Kullback-Leibler-based one denoted ¯¯si,j(t). ˆsi,j(t)
is the average value of ci(s) − cj(s) for s in [t − 1],
where we restrict ourselves to iterations at which items
i and j are in the same subset of the played partition
PPP (s) = (cid:0)P1(s), . . . , Pd(s)(s)(cid:1), and ci(s) (cid:54)= cj(s). Speciﬁcally,

ˆsi,j(t) :=

1
Ti,j(t)

t−1
(cid:88)

s=1

Oi,j(s) (ci(s) − cj(s)) ,

mistic indices

¯¯si,j(t) := 2 ∗ f

(cid:18) 1 + ˆsi,j(t)
2

, Ti,j(t), ˜t ˜PPP (t)(t)

(cid:19)

− 1,

where f is a function from [0, 1] × N × N to [0, 1] and
f (ˆµ, N, t) := sup{µ ∈ [ˆµ, 1] : N × kl(ˆµ, µ) ≤ log(t) +
3 log(log(t))}, with kl(p, q) := p log p
q + (1 − p) log 1−p
1−q
the Kullback-Leibler divergence (KL) from a Bernoulli dis-
tribution of mean p to a Bernoulli distribution of mean q;
f (ˆµ, N, t) := 0 when ˆµ = 1, N = 0, or t = 0; and ˜t ˜PPP (t)(t)
is the number of iterations the partition at which ˜PPP has previ-
ously been the leader. This optimistic index is the one used
for KL-based bandit algorithms, after a rescaling of ˆsi,j(t)
to the interval [0, 1]. Note that, unlike ˆsi,j(t), ¯¯si,j(t) is not
antisymmetric, and ¯¯sj,i(t) (cid:62) 0 while ˆsi,j(t) > 0 indicates
that it is unclear whether i is more attractive than j or not.

Leader Elicitation At each iteration, UniRank ﬁrst builds
a partition ˜PPP (t) = ( ˜P1(t), . . . , ˜P ˜d(t)) using Algorithm 2
(see. Appendix C). This partition is coherent with ˆsi,j(t),
meaning that for any couple of items (i, j) in [L]2, if
ˆsi,j(t) > 0 then either i belongs to a subset ˜Pc(t) ranked
before the subset of j, or there exists a cycle (i1, i2, . . . , iN )
such that i1 = iN = i, i2 = j, and for any n ∈ [N − 1],
ˆsin,in+1(t) > 0. We also ensure that the ˜d − 1 ﬁrst sub-
sets of ˜PPP (t) gather at least K items: (cid:80) ˜d−2
c=1 | ˜Pc(t)| < K (cid:54)
(cid:80) ˜d−1
c=1 | ˜Pc(t)|. This means that the items in ˜P ˜d(t) are the
ones which are never displayed by the recommendations in
A( ˜PPP (t)). Note that the subset ˜P ˜d(t) may be empty.
The partition ˜PPP (t) is built by repeating the process of (i)
identifying the smallest subset of items dominating all other
items (meaning the items i for which ˆsi,j(t) > 0 for any
remaining item j), and (ii) removing this subset. A special
care is taken to gather in the same subset remaining items
as soon as the ﬁrst subsets contain more than K items.

Optimistic Partition Elicitation The partition ˜PPP (t) plays
the role of leader, meaning that at each iteration, UniRank
solves an exploration-exploitation dilemma and picks either
˜PPP (t) or a permutation PPP (t) in the neighborhood N ( ˜PPP (t))
of ˜PPP (t), where N ( ˜PPP ) :=

(cid:110)(cid:16) ˜P1, . . . , ˜Pc−1, ˜Pc ∪ ˜Pc+1, ˜Pc+2, . . . ˜P ˜d
(cid:17)
(cid:17)
(cid:110)(cid:16) ˜P1, . . . , ˜P ˜d−2, ˜P ˜d−1 ∪ {j}, ˜P ˜d \ {j}

∪

: c ∈ [ ˜d − 2]

(cid:111)

(cid:111)
: j ∈ ˜P ˜d

.

where Oi,j(s) := 1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9) 1{ci(s) (cid:54)= cj(s)} de-
notes that the difference between items i and j is observable
at iteration s, Ti,j(t) := (cid:80)t−1
s=1 Oi,j(s), and ˆsi,j(t) := 0
when Ti,j(t) = 0. Note that ˆsi,j(t) is antisymmetric
(ˆsi,j(t) = −ˆsj,i(t)) and ˆsi,j(t) > 0 (equivalent to ˆsj,i(t) <
0) indicates that i is probably more attractive than j.

The statistics ˆsi,j(t) are paired with their respective opti-

This neighborhood results either (i) from the merge of two
consecutive subsets ˜Pc(t) and ˜Pc+1(t) of the partition ˜PPP (t),
or (ii) from the addition to ˜P ˜d−1(t) of an item j from the last
subset. For each neighbor PPP of type (i), the optimistic index
¯¯sj,i(t) to reﬂect whether or
bPPP (t) is max(i,j)∈ ˜Pc(t)× ˜Pc+1(t)
not at least one of the items in ˜Pc+1(t) may potentially be
more attractive than one of the items in ˜Pc(t). Similarly, for

UniRank: Unimodal Bandit Algorithm for Online Ranking

each neighbor PPP of type (ii), the optimistic index bPPP (t) is
maxi∈ ˜P ˜d−1(t)

¯¯sj,i(t).

fulﬁlls

Remark 4.1 (Recommendation chosen at random). Taking
a random permutation is required to control the statistic
ˆsi,j(t). Indeed, the theoretical analysis requires the prob-
ability for i to be ranked before j in the recommendation
to be even. Overall, the aim is to identify a partition PPP ∗
such that any permutation in A (PPP ∗) is compatible with the
unknown strict weak order on items.

5. Theoretical Analysis

The proof of the upper-bound on the regret of UniRank
follows a similar path as the proof of OSUB (Combes &
Prouti`ere, 2014): (i) apply a standard bandit analysis to
control the regret under the condition that the leader ˜PPP (t) is
an optimal partition, and (ii) upper-bound by O(log log T )
the expected number of iterations such that ˜PPP (t) is not an
optimal partition. However, both steps differ from (Combes
& Prouti`ere, 2014). First, UniRank handles partitions in-
stead of recommendations. Secondly, it builds upon ˆsi,j(t)
instead of estimators of the expected reward. While ˆsi,j(t)
is the average of dependent random variables with different
expected values, these expected values are greater than some
non-negative constant ˜∆i,j when i (cid:31) j, which is sufﬁcient
to lower-bound ˆsi,j(t) away from 0 as required by the proof
of the regret upper-bound (see Appendices E.1, E.2, and E.3
for details). Finally, the proof is adapted to handle the fact
that Ti,j(t) randomly increases when we play items i and j
due to the exploration-exploitation rule, which is unusual in
the bandit literature. Up to our knowledge, this exploration-
exploitation strategy and its analysis are new in the bandit
community. We believe that it opens new perspectives for
other semi-bandit settings.

Note that, as in (Sentenac et al., 2021) and (Gauthier et al.,
2021b), we restrict the theoretical analysis to the setting
where the order on top-items is total, meaning we use As-
sumption 3.1∗. Without loss of generality, we also assume
that 1 (cid:31) 2 (cid:31) · · · (cid:31) K (cid:31) [L] \ [K] to shorten the notations.
Hence the only partition PPP ∗ which is such that, any permu-
tation aaa in A (PPP ∗) is compatible with the unknown strict
order on items, is ({1}, . . . , {K}, [L] \ [K]).

We now propose the main theorem that upper-bounds the
regret of UniRank.

∀k ∈ [L] \ {1}, E

(cid:34) T

(cid:88)

(cid:110)

1

t=1

(cid:54) 16
˜δ∗
˜∆2
k
k

˜PPP (t)=PPP ∗,
∃c,Pc(t)={min(k−1,K),k}

(cid:35)

(cid:111)

log T + O (log log T )

(2)

(cid:34) T

(cid:88)

(cid:35)
1{ ˜PPP (t) (cid:54)= PPP ∗}

and E

= O (log log T ) ,

(3)

t=1

and hence

R(T ) (cid:54)

L
(cid:88)

k=2

8∆k
˜δ∗
˜∆2
k
k

log T +O (log log T ) = O

(cid:19)

log T

,

(cid:18) L
∆

where for any position k > 1, denoting (cid:96) := min(k −1, K),
˜δ∗
Paaa(t)∼U (A(PPP )) [c(cid:96)(t) (cid:54)= ck(t)] ,
k := minPPP ∈N (PPP ∗):∃c,((cid:96),k)∈P 2
˜∆k := minaaa∈P L
∆k := µ(1,...,K) − µ((cid:96),k)◦(1,...,K),
and ∆ := mink∈{2,...,L}

K :{(cid:96),k}∩aaa([K])(cid:54)=∅ ˜∆(cid:96),k(aaa),

˜∆2

k/∆k.

˜δ∗
k

c

The ﬁrst upper-bound (Equation (2)) controls the expected
number of iterations at which UniRank explores while the
leader is the optimal partition. Both types of exploration are
covered: the merging of two consecutive subsets of ˜PPP (t),
and the addition of a sub-optimal arm to the last subset of the
chosen partition PPP (t). The second upper-bound (Equation
(3)) deals with the expected number of iterations at which
the leader is not the optimal partition. Let us now express
the same bounds while assuming one of the state-of-the-art
click models.
Corollary 5.2 (Facing CM∗). Under the hypotheses of The-
orem 5.1, with the clik-model CM with probability θi to click
on item i when it is observed, UniRank fulﬁlls

R(T ) (cid:54)

L
(cid:88)

k=K+1
(cid:18)

16

θK + θk
θK − θk

log T + O (log log T )

= O

(L − K)

θK + θK+1
θK − θK+1

(cid:19)

log T

.

Corollary 5.3 (Facing PBM∗). Under the hypotheses of
Theorem 5.1, if the user follows PBM with the probability θi
of clicking on item i when it is observed and the probability
κk of observing the position k, then UniRank fulﬁlls

R(T ) = O

(cid:19)

log T

,

(cid:18) L
∆

Theorem 5.1 (Upper-bound on the regret of UniRank as-
suming a total order on top-K items). Let (L, K, ρ) be
an OLR problem satisfying Assumptions 3.1∗, 3.2, and 3.3
and such that 1 (cid:31) 2 (cid:31) · · · (cid:31) K (cid:31) [L] \ [K]. Denoting
PPP ∗ = ({1}, . . . , {K}, [L] \ [K]) the optimal partition as-
sociated to this order, when facing this problem, UniRank

where ∆ := min{ θK −θK+1
θK +θK+1

,

mink∈{2,...,K}

((κk−1+κk)(θk−1+θk)−4κk−1κkθk−1θk)(θk−1−θk)
(κk−1−κk)(θk−1+θk)2

}.

Note that the regret upper-bound reduces to O((L −
K)/∆ log T ) with CM since, with this model, the recom-
mendation is optimal as soon as optimal items are displayed.

UniRank: Unimodal Bandit Algorithm for Online Ranking

A more detailed version of these corollaries is given in the
appendix, together with their proofs and Theorem 5.1’s
proof. These proofs builds upon the following pseudo-
unimodality property.

Lemma 5.4 (Pseudo-unimodality assuming a total order on
top-K items). Under the hypotheses of Theorem 5.1, for any
ordered partition of the items ˜PPP =

(cid:17)
(cid:16) ˜P1, . . . , ˜P ˜d

(cid:54)= PPP ∗,

• either ∃c ∈ [ ˜d], such that |Pc| > 1 and i∗ (cid:31)
argmaxj∈Pc\{i∗} g(j), where i∗ = argmaxi∈Pc g(i);

• or ∃c ∈ [ ˜d − 1], ∃(i, j) ∈ ˜Pc × ˜Pc+1, such that j (cid:31) i.

The ﬁrst alternative implies that the subset ˜Pc should be
split, which will be discovered by recommending permu-
tations compatible with either ˜PPP or one of its neighbors.
The second alternative implies that j should be in a subset
ranked before the subset containing i, which will be discov-
ered by recommending the permutation in the neighborhood
of ˜PPP which puts i and j in the same subset.

5.1. Discussion

We gather here some remarks regarding the optimality of
the theoretical results and their extension to a weak order.
Remark 5.1 (Optimality of UniRank’s upper-bound).
While deriving the exact
lower-bound on the ex-
pected regret
in this setting is out of the scope of
our paper, we believe that this bound takes the form
(cid:17)
µ∗−µk
O
k ,νk) log(T )
,
kl(ν∗
k=2
∈
where for k
{K + 1, . . . , L}), µk, ν∗
from the
best partition and the best random variables to compare
item k to item k − 1 (resp. to item K).

{2, . . . , K} (respectively k
k, and νk result

k ,νk) log(T ) + (cid:80)L

µ∗−µk
kl(ν∗

(cid:16)(cid:80)K

k=K+1

∈

In (Combes et al., 2015) (Propositions 1 and 2) and in
(Lagr´ee et al., 2016) (Theorem 6) a bound with only the
second sum is proven. The ﬁrst sum is missing as both
papers consider more restricting settings where the compar-
ison between items k ∈ {2, . . . , K} and k − 1 is free in
terms of regret: CM for (Combes et al., 2015), and PBM
with κκκ known for (Lagr´ee et al., 2016).

We also believe that TopRank’s upper-bound on the
regret with our additional hypothesis either remains
O(KL/∆ log(T )) or reduces to O(L log L/∆ log(T )).2
Indeed, while UniRank reduces the exploration by only
comparing each item k to the item min(k − 1, L), in the
worst case scenario TopRank compares each item k to each
item k(cid:48) ∈ {1, . . . , min(k − 1, L)} in order to conclude that
k(cid:48) should not be at one of the top-min(k − 1, L) positions.

2This second bound is proven in (Sentenac et al., 2021) for a
matching problem handled with an algorithm similar to TopRank.

Remark 5.2 (Exploration not at the top). With CM model,
exploring at the top reduces the regret: it leads to less explo-
ration, while the instantaneous regret remains unchanged.
However, this results does not hold with PBM (see Theorem
6 in (Lagr´ee et al., 2016) for details): while exploring at the
top decreases the number of explorations, it also increases
the regret per exploration; and the best trade-off depends on
the values θθθ and κκκ.

Therefore, as in (Lagr´ee et al., 2016), we only explore
through local changes in the recommendation. Note that
these local changes are also more ”user-friendly”: as soon
as the right leader has been identiﬁed, a sub-optimal item is
always tried at the bottom of the recommendation, which is
less surprising for users than a sub-optimal item displayed
as the top recommendation.
Remark 5.3 (Upper-bound on the regret of UniRank assum-
ing a weak order on items). If the order on the best items is
not total, the proof of Theorem 5.1 may be adapted to get a
O (LK/∆ log T ) bound. Indeed, under the strict weak or-
der assumption, there exists a set of optimal partitions, and
therefore, any permutation compatible with a neighbor of
any of these partitions may be recommended O (1/∆ log T )
times. In the worst case scenario, K items are equivalent
and strictly more attractive than the L − K remaining items,
and the set of the permutations compatible with a neighbor
partition is composed of K(L − K) permutations, which
translates into a O (LK/∆ log T ) regret bound. Note that
(Lattimore et al., 2018) proves a Ω (LK/∆ log T ) lower-
bound on the regret assuming that the best items have the
same attractiveness which means that the upper-bound of
UniRank for this speciﬁc setting is optimal.

6. Experiments

In this section, we compare UniRank to TopRank (Lattimore
et al., 2018), PB-MHB (Gauthier et al., 2021a), GRAB (Gau-
thier et al., 2021b), and CascadeKL-UCB (Kveton et al.,
2015a). The experiments are conducted on the KDD Cup
2012 track 2 dataset, on the Yandex dataset (Yandex, 2013),
and on a model with artiﬁcial parameters. We use the cumu-
lative regret to evaluate the performance of each algorithm.

6.1. Experimental Settings

In order to evaluate our algorithm, we design six experi-
ments inspired by the ones conducted in (Lattimore et al.,
2018). The standard metric used is the expected cumulative
regret (see Equation (1)), denoted as regret, which is
the sum, over T consecutive recommendations, of the
difference between the expected reward of the best answer
and of the answer of a given ORS. The best algorithm is the
one with the lowest regret. We use two click models for
our experiments: the Position Based Model (PBM) and the
Cascading Model (CM). To play according to those models,

UniRank: Unimodal Bandit Algorithm for Online Ranking

we extract the parameters of the chosen model from the
KDD Cup 2012 track 2 (KDD for short) database and the
Yandex database (Yandex, 2013), and we experiment with a
set of parameters (denoted Simul) chosen to highlight the
O (L/∆ log T ) regret of UniRank: L = 10, K = 5, θθθ =
[0.1, 0.08, 0.06, 0.04, 0.02, 10−4, 10−4, 10−4, 10−4, 10−4],
and κκκ = [1, 0.9, 0.83, 0.78, 0.75].

Yandex database comes from fully anonymized real-life logs
of actions toward the Yandex search engine. It contains 703
million items displayed among 65 million search queries
and sharing 167 million hits (clicks). We consider the 10
most frequent queries in our experiments. We use the GPL3
Pyclick library (Chuklin et al., 2015) to infer the CM and
PBM parameters of each query with the expectation maxi-
mization algorithm. Depending on the query, this leads to
θi values ranging from 0.51 to 0.94, and κi values ranging
from 0.71 to 1.00 when considering PBM and θi values
ranging from 0.03 to 0.50 for CM.

We also extract parameters from the KDD dataset. Due
to the type of data contained in this dataset, we can only
extract parameters for the PBM model. This dataset consists
of session logs of soso.com, a Tencent’s search engine. It
tracks clicks and displays of advertisements on a search en-
gine result web-page, w.r.t. the user query. For each query,
3 positions are available for a various number of ads to dis-
play. Each of the 150M lines contains information about the
search (UserId, QueryId. . . ) and the ads displayed (AdId,
Position, Click, Impression). We are looking for the best
ads per query, namely the ones with a higher probability to
be clicked. To follow previous works, instead of looking for
the probability to be clicked per display, we target the prob-
ability to be clicked per session. This amounts to discarding
the information Impression. We also ﬁlter the logs to restrict
the analysis to (query, ad) couples with enough information:
for each query, ads are excluded if they were displayed less
than 1,000 times at any of the 3 possible positions. Then, we
ﬁlter queries that have less than 5 ads satisfying the previous
condition. We end up with 8 queries and from 5 to 11 ads
per query. The overall process leads to θi values ranging
from 0.004 to 0.149, and κk values ranging from 0.10 to
1.00, depending on the query.

Then we simulate the users’ interactions given these param-
eters as it is commonly done in bandits settings. Similarly
to (Lattimore et al., 2018), we look at the results averaged
on the queries, while displaying K items among the L most
attractive ones selected among all items possible for each
query. With Yandex dataset, K = 5 and L = 10, while
with KDD dataset K = 3 and L varies from 5 to 11. We
run our experiments on an internal cluster to compute 20
independent sets of 107 consecutive recommendations for
each of the 10 most frequent Yandex queries and each of the
8 KDD queries. It leads respectively to 200 games per set-

Table 2. Average computation time (in ms) per recommendation.
For each top 10 query of Yandex dataset, 20 runs are performed
assuming CM model and L = 10.

Algorithm
UniRank
TopRank
PB-MHB
GRAB
CascadeKL-UCB

Computation Time (ms)
1.0 ± 0.2
0.7 ± 0.3
13.9 ± 4.9
0.9 ± 0.3
0.9 ± 0.0

ting and algorithm for Yandex and 160 games for KDD. As
TopRank requires the knowledge of the horizon T , we test
the impact of this parameter by setting it to the right value
(107), to a too high value (1012), and to a too small value
(105) with doubling trick. To tune PB-MHB, we use the
values recommended by (Gauthier et al., 2021a) for these
datasets.

6.2. Results

Our results are shown in Figure 2. As expected, CascadeKL-
UCB (respectively PB-MHB) outperforms other algorithms
in the CM (resp. PBM) model for which it is designed.
However, PB-MHB is computationally expensive (see Ta-
ble 2) and lacks a theoretical analysis. Surprisingly, al-
though GRAB is designed for PBM model, it suffers a high
regret when confronted to the query 8107157 of Yandex and
to Simul with PBM model.

Secondly, UniRank and TopRank enjoy a logarithmic re-
gret in all settings and our algorithm UniRank outperforms
TopRank for the models such that the K best items do not
have the same attractiveness θi: query 8107157 of Yandex,
simul PBM, and simul CM. When confronted to other mod-
els, UniRank has a regret strictly smaller than TopRank be-
fore the iteration t = 106, and smaller or equal to TopRank
at the horizon. Moreover, as already explained, TopRank is
aware of the horizon T and may stop (over)exploring early,
as can be observed in the CM model after iteration 105. If
TopRank targets a horizon T = 1012 or uses the doubling
trick it suffers a higher regret than UniRank.

Regarding the computational complexity, as shown in Ta-
ble 2, PB-MHB is signiﬁcantly slower with a computation
time per recommendation ten times higher than any other al-
gorithm. These other algorithms have a similar computation
time of approximately 1 ms per recommendation.

Overall, as TopRank, UniRank is consistent over all set-
tings, and require a reasonable computation time. Moreover,
contrary to TopRank, (i) UniRank drastically decreases its
regret by taking advantage of the differences of attractive-
ness between items, and (ii) UniRank does not require the

UniRank: Unimodal Bandit Algorithm for Online Ranking

(a) KDD PBM

(b) Yandex PBM

(c) Yandex CM

Generic Algorithms

Alg. Dedicated to PBM

Alg. Dedicated to CM

(d) Yandex 8107157 PBM

(e) Simul PBM

(f) Simul CM

Figure 2. Cumulative regret w.r.t. iterations. K = 5 and L = 10 for Yandex and Simul models (b,c,e,f); K = 3 and L ∈ {5, . . . , 11} for
KDD model (a); K = 5 and L = 6 for Yandex 8107157 (d) which corresponds to the parameters of the query 8107157 of Yandex. The
plotted curves correspond to the average over 200, 160, or 20 independent sequences of recommendations (20 sequences per query). The
(small) shaded areas depict the standard error of our regret estimates.

knowledge of the horizon T .

between both approaches.

7. Conclusion

Ethical Statement

We have presented UniRank, a unimodal bandit algorithm
for online ranking. The regret bound in O (L/∆ log T ) of
our algorithm, is a direct consequence of the unimodality-
like property of the bandit setting with respect to a graph
where nodes are ordered partitions of items. Even though the
proof is inspired by OSUB (Combes & Prouti`ere, 2014), the
fact that UniRank handles partitions instead of recommenda-
tions, uses different estimators and builds upon an unusual
exploration-exploitation strategy makes it original, and we
believe that our theoretical analysis opens new perspec-
tives for other semi-bandit settings. Experiments against
state-of-the-art learning algorithms show that our method
is consistent in all settings, enjoys a smaller regret than
TopRank and GRAB on speciﬁc settings, and has a much
smaller computation time than PB-MHB.

While in industrial applications, contextual information is
also used to build recommendations (Li et al., 2019b; Chen
et al., 2019; Ermis et al., 2020; Gampa & Fujita, 2021), in
this paper we restricted ourselves to independent arms to
simplify the presentation of the approach. However, the
integration of unimodal bandit algorithms working on para-
metric spaces (Combes et al., 2020) should bridge the gap

Regarding the societal impact of the proposed approach, it
is worth mentioning that the approach aims at identifying
and recommending the most popular items. Therefore, the
approach may increase the monopoly effects: the most at-
tractive items are displayed more often, so their reputation
increases, and then they may become even more attractive. . .
However bandit algorithms continuously explore and there-
fore continuously offer an opportunity to less popular items
to increase their reputation.

Acknowledgements

We thank the reviewers for their valuable comments towards
clariﬁcation of the paper. This research was partially sup-
ported by the Inria Project Lab “Hybrid Approaches for
Interpretable AI” (HyAIAI) and the network on the founda-
tions of trustworthy AI, integrating learning, optimisation,
and reasoning (TAILOR) ﬁnanced by the EU’s Horizon
2020 research and innovation program under agreement
952215.

101103105107Iteration100101102103104Cumulative Expected Regret101103105107Iteration100101102103104105Cumulative Expected Regret101103105107Iteration100101102103104Cumulative Expected Regret101103105107Iteration101100101102103104105Cumulative Expected Regret101103105107Iteration100101102103104Cumulative Expected Regret101103105107Iteration100101102103104Cumulative Expected RegretUniRankTopRank,T=107 TopRank, T=1012TopRank, doublingGRABPB-MHB, c=103, m=1CascadeKL-UCBUniRank: Unimodal Bandit Algorithm for Online Ranking

References

Chen, M., Beutel, A., Covington, P., Jain, S., Belletti, F.,
and Chi, E. H. Top-k off-policy correction for a reinforce
In Proc. of the 12th ACM Int.
recommender system.
Conf. on Web Search and Data Mining, WSDM ’19, pp.
456–464, 2019.

Chen, W., Wang, Y., and Yuan, Y. Combinatorial multi-
armed bandit: General framework and applications.
In proc. of the 30th Int. Conf. on Machine Learning,
ICML’13, 2013.

Cheung, W. C., Tan, V., and Zhong, Z. A thompson sam-
pling algorithm for cascading bandits. In proc. of the
22nd Int. Conf. on Artiﬁcial Intelligence and Statistics,
AISTATS’19, 2019.

Chuklin, A., Markov, I., and de Rijke, M. Click Models for

Web Search. Morgan & Claypool Publishers, 2015.

Combes, R. and Prouti`ere, A. Unimodal bandits: Regret
lower bounds and optimal algorithms. In proc. of the 31st
Int. Conf. on Machine Learning, ICML’14, 2014.

Combes, R., Magureanu, S., Prouti`ere, A., and Laroche,
C. Learning to rank: Regret lower bounds and efﬁcient
algorithms. In proc. of the ACM SIGMETRICS Int. Conf.
on Measurement and Modeling of Computer Systems,
2015.

Combes, R., Prouti`ere, A., and Fauquette, A. Unimodal ban-
dits with continuous arms: Order-optimal regret without
smoothness. Proc. ACM Meas. Anal. Comput. Syst., 4(1),
May 2020.

Craswell, N., Zoeter, O., Taylor, M., and Ramsey, B. An
experimental comparison of click position-bias models.
In proc. of the Int. Conf. on Web Search and Data Mining,
WSDM ’08, 2008.

Ermis, B., Ernst, P., Stein, Y., and Zappella, G. Learning
to rank in the position based model with bandit feed-
back. In Proc. of the 29th ACM Int. Conf. on Information
& Knowledge Management, CIKM’20, pp. 2405–2412,
2020.

Gai, Y., Krishnamachari, B., and Jain, R. Combinatorial
network optimization with unknown variables: Multi-
armed bandits with linear rewards and individual obser-
vations. IEEE/ACM Trans. Netw., 20(5):1466–1478, Oc-
tober 2012.

Gampa, P. and Fujita, S. Banditrank: Learning to rank using
contextual bandits. In Karlapalem, K., Cheng, H., Ra-
makrishnan, N., Agrawal, R. K., Reddy, P. K., Srivastava,
J., and Chakraborty, T. (eds.), Advances in Knowledge
Discovery and Data Mining, PAKDD’21, pp. 259–271.
Springer International Publishing, 2021.

Garivier, A. and Capp´e, O. The kl-ucb algorithm for
bounded stochastic bandits and beyond. In proc. of the
24th Annual Conf. on Learning Theory, COLT’11, 2011.

Gauthier, C.-S., Gaudel, R., and Fromont, E. Bandit al-
gorithm for both unknown best position and best item
display on web pages. In 19th International Symposium
on Intelligent Data Analysis, Apr 2021, Porto (virtual),
Portugal. pp.1-12, IDA, 2021a.

Gauthier, C.-S., Gaudel, R., Fromont, E., and Lompo, B. A.
Parametric graph for unimodal ranking bandit. In Proc.
of the 38th Int. Conf. on Machine Learning, ICML’21, pp.
3630–3639, 2021b.

Katariya, S., Kveton, B., Szepesv´ari, C., and Wen, Z. DCM
bandits: Learning to rank with multiple clicks. In proc.
of the 33rd Int. Conf. on Machine Learning, ICML’16,
2016.

Komiyama, J., Honda, J., and Nakagawa, H. Optimal regret
analysis of thompson sampling in stochastic multi-armed
bandit problem with multiple plays. In proc. of the 32nd
Int. Conf. on Machine Learning, ICML’15, 2015.

Komiyama, J., Honda, J., and Takeda, A. Position-based
multiple-play bandit problem with unknown position bias.
In proc. of the 31st conf. on Neural Information Process-
ing Systems, NeurIPS’17, 2017.

Kveton, B., Szepesv´ari, C., Wen, Z., and Ashkan, A. Cas-
cading bandits: Learning to rank in the cascade model.
In proc. of the 32nd Int. Conf. on Machine Learning,
ICML’15, pp. 767–776, 2015a.

Kveton, B., Wen, Z., Ashkan, A., and Szepesv´ari, C. Com-
binatorial cascading bandits. In proc. of the 29th conf.
on Neural Information Processing Systems, NeurIPS’15,
2015b.

Lagr´ee, P., Vernade, C., and Capp´e, O. Multiple-play bandits
in the position-based model. In proc. of the 30th conf.
on Neural Information Processing Systems, NeurIPS’16,
2016.

Lattimore, T., Kveton, B., Li, S., and Szepesvari, C.
Toprank: A practical algorithm for online stochastic rank-
ing. In proc. of the 32nd conf. on Neural Information
Processing Systems, NeurIPS’18, 2018.

Li, C., Kveton, B., Lattimore, T., Markov, I., de Rijke, M.,
Szepesv´ari, C., and Zoghi, M. Bubblerank: Safe online
learning to re-rank via implicit click feedback. In proc. of
the 35th Uncertainty in Artiﬁcial Intelligence Conference,
UAI’19, 2019a.

Li, S., Wang, B., Zhang, S., and Chen, W. Contextual
combinatorial cascading bandits. In proc. of the 33rd Int.
Conf. on Machine Learning, ICML’16, 2016.

UniRank: Unimodal Bandit Algorithm for Online Ranking

Li, S., Lattimore, T., and Szepesv´ari, C. Online learning
to rank with features. In Proc. of the 36th Int. Conf. on
Machine Learning, ICML’19, 2019b.

Radlinski, F., Kleinberg, R., and Thorsten, J. Learning
diverse rankings with multi-armed bandits. In proc. of the
25th Int. Conf. on Machine Learning, ICML’08, 2008.

Richardson, M., Dominowska, E., and Ragno, R. Predicting
clicks: Estimating the click-through rate for new ads. In
proc. of the 16th International World Wide Web Confer-
ence, WWW ’07, 2007.

Sentenac, F., Yi, J., Calauzenes, C., Perchet, V., and Vo-
jnovic, M. Pure exploration and regret minimization
in matching bandits. In Proc. of the 38th Int. Conf. on
Machine Learning, ICML’21, pp. 9434–9442, 2021.

Yandex. Yandex personalized web search challenge.
URL https://www.kaggle.com/c/

2013.
yandex-personalized-web-search-challenge.

Zoghi, M., Tunys, T., Ghavamzadeh, M., Kveton, B.,
Szepesvari, C., and Wen, Z. Online learning to rank
in stochastic click models. In proc. of the 34th Int. Conf.
on Machine Learning, ICML’17, 2017.

Zong, S., Ni, H., Sung, K., Ke, N. R., Wen, Z., and Kveton,
B. Cascading bandits for large-scale recommendation
problems. In proc. of the 32nd Conference on Uncertainty
in Artiﬁcial Intelligence, UAI ’16, 2016.

UniRank: Unimodal Bandit Algorithm for Online Ranking

A. Organisation of the Appendix

The appendix is organized as follows. After listing most of the notations used in the paper in Appendix B, we prove Lemma
3.1 in Appendix D. Then we prove some technical lemmas in Appendix E, which are required by the proof of Theorem 5.1
in Appendix F. Finally, we discuss the regret upper-bound of UniRank for some speciﬁc settings in Appendix G.

B. Notations

Table 4 summarizes the notations used throughout the paper and the appendix. Below are additional notations necessary for
the proofs.
Deﬁnition B.1 (Speciﬁc notations to count events and observations). The proofs are based on the concentration of the
statistic ˆsi,j(t) which is the average over Ti,j(t) observations. The number Ti,j(t) itself is a sum: the sum of the random
variables 1{ci(s) (cid:54)= cj(s)} | ∃c, (i, j) ∈ Pc(s)2, where s is in [t]. To discuss the concentration of this sum, for any
1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9) the number of iterations at which the random variable
iteration t in [T ], we denote ti,j(t) := (cid:80)t−1
is observed.
Deﬁnition B.2 (Recommended subset). Let (L, K, ρ) be an online learning to rank problem, PPP be an ordered partition of
[L] in d subsets, and c ∈ [d] the index of one of these subsets. The subset Pc is recommended (denoted Rec(Pc)) if the
recommendations compatible with PPP include some items from Pc. More speciﬁcally, the subset Pc is recommended if
| (cid:83)
Deﬁnition B.3 (Expectations on clicks). let i and j be two different items.

(cid:96)∈[c−1] P(cid:96)| < K.

s=1

We denote

˜δi,j :=

min
PPP :∃c,(i,j)∈P 2

c ∧Rec(Pc)

Paaa(t)∼U (A(PPP )) [ci(t) (cid:54)= cj(t)]

the smallest probability for ci(t) to be different from cj(t) while both items are in the same subset of the chosen partition
PPP (t) (and may potentially be clicked upon). If we assume 1 (cid:31) 2 (cid:31) · · · (cid:31) L, we also denote

˜δ∗
i :=

min
PPP ∈N (({1},...,{K},{K+1,...,L})):∃c,(min(i−1,K),i)∈P 2
c

Paaa(t)∼U (A(PPP ))

(cid:2)cmin(i−1,K)(t) (cid:54)= ci(t)(cid:3)

the smallest probability for cmin(i−1,K)(t) to be different from ci(t) while both items min(i − 1, K) and i are in the same
subset of the chosen partition PPP (t) (and may potentially be clicked upon), and PPP (t) is in the neighborhood of the optimal
partition PPP ∗ = ({1}, . . . , {K}, {K + 1, . . . , L}).

If i (cid:31) j, we denote

˜∆i,j :=

min
PPP :∃c,(i,j)∈P 2

c ∧Rec(Pc)

Eaaa(t)∼U (A(PPP )) [ci(t) − cj(t) | ci(t) (cid:54)= cj(t)] =

min

aaa∈P L

K :{i,j}∩aaa([K])(cid:54)=∅

˜∆i,j(aaa),

the smallest expected difference of clicks between items i and j while both items are in the same subset of the chosen
partition PPP (t) (and may potentially be clicked upon).

Symmetrically, if j (cid:31) i, we denote

˜∆i,j :=

max
PPP :∃c,(i,j)∈P 2

c ∧Rec(Pc)

Eaaa(t)∼U (A(PPP )) [ci(t) − cj(t) | ci(t) (cid:54)= cj(t)] =

max

aaa∈P L

K :{i,j}∩aaa([K])(cid:54)=∅

˜∆i,j(aaa),

the greatest expected difference of clicks between items i and j while both items are in the same subset of the chosen
partition PPP (t) (and may potentially be clicked upon).

Lemma E.1 in Appendix E.1 ensures the proper deﬁnition of these notations under Assumptions 3.1, 3.2, and 3.3, and states
that ˜δi,j = ˜δj,i > 0 and ˜∆i,j = − ˜∆j,i > 0 if i (cid:31) j.
Deﬁnition B.4 (Reward gap). Let (L, K, ρ) be an OLR problem satisfying Assumption 3.2 and such that the or-
der on items is a total order. Without loss of generality, let us assume that 1 (cid:31) 2 (cid:31) · · · (cid:31) L.. Denoting
PPP ∗ = ({1}, . . . , {K}, {K + 1, . . . , L}) the optimal partition associated to this order and taking c (cid:62) 2, the reward
gap of item c is

∆c := ρ (aaa∗, min(c − 1, K)) + ρ (aaa∗, c)

− ρ ((min(c − 1, K), c) ◦ aaa∗, min(c − 1, K)) − ρ ((min(c − 1, K), c) ◦ aaa∗, c)

UniRank: Unimodal Bandit Algorithm for Online Ranking

SYMBOL

MEANING

T
t
L
i
K
k
[n]
P L
K
θθθ
θi
κκκ
κk
A
aaa
aaa(t)
ak
aaa∗
ρ
ρ(aaa, k)
ccc(t)
ci(t)
r(t)
µaaa
µ∗
∆
∆c
˜δi,j

˜δ∗
k

˜∆i,j

R(T )
(cid:31)
(i, j) ◦ aaa
PPP
Pc
A (PPP )
˜PPP (t)
PPP ∗
G
N ( ˜PPP )

ti,j (t)

Ti,j (t)

˜t ˜PPP (t)
˜δi,j (aaa)
˜∆i,j (aaa)
ˆsi,j (t)

¯¯sj,i(t)
f
kl(p, q)

U (S)
c

K × [K] TO [0, 1] GIVING THE PROBABILITY OF CLICK

TIME HORIZON
ITERATION
NUMBER OF ITEMS
INDEX OF AN ITEM
NUMBER OF POSITIONS IN A RECOMMENDATION
INDEX OF A POSITION
SET OF INTEGERS {1, . . . , n}
SET OF PERMUTATIONS OF K DISTINCT ITEMS AMONG L
VECTORS OF PROBABILITIES OF CLICK
PROBABILITY OF CLICK ON ITEM i
VECTORS OF PROBABILITIES OF VIEW
PROBABILITY OF VIEW AT POSITION k
SET OF BANDIT ARMS
AN ARM IN A
THE ARM CHOSEN AT ITERATION t
ITEM DISPLAYED AT POSITION K IN THE RECOMMENDATION aaa
BEST ARM
FUNCTION FROM P L
PROBABILITY OF CLICK ON THE ITEM DISPLAYED AT POSITION k WHEN RECOMMENDING aaa
CLICKS VECTOR AT ITERATION t
CLICKS ON ITEM I AT ITERATION t
REWARD COLLECTED AT ITERATION t, r(t) = (cid:80)L
EXPECTATION OF r(t) WHILE RECOMMENDING aaa, µaaa = E[r(t) | aaa(t) = aaa]
HIGHEST EXPECTED REWARD, µ∗ = maxaaa∈PL
K
GENERIC REWARD GAP BETWEEN ONE OF THE SUB-OPTIMAL ARMS AND ONE OF THE BEST ARMS
REWARD GAP WHILE EXCHANGING ITEMS min(c − 1, K) AND c IN THE OPTIMAL RECOMMENDATION,
SMALLEST PROBABILITY FOR ci(t) TO BE DIFFERENT FROM cj (t)
WHILE BOTH ITEMS ARE IN THE SAME SUBSET OF THE CHOSEN PARTITION PPP (t)
SMALLEST PROBABILITY FOR cmin(k−1,K)(t) TO BE DIFFERENT FROM ck , WHILE BOTH ITEMS ARE IN THE SAME
SUBSET OF THE CHOSEN PARTITION PPP (t) AND PPP (t) IS IN THE NEIGHBORHOOD OF THE OPTIMAL PARTITION
SMALLEST (RESPECTIVELY HIGHEST) EXPECTED DIFFERENCE OF CLICK BETWEEN ITEMS i AND j IF i (cid:31) j (RESP. j (cid:31) i)
WHILE BOTH ITEMS ARE IN THE SAME SUBSET OF THE CHOSEN PARTITION PPP (t)
CUMULATIVE (PSEUDO-)REGRET, R(T ) = T µ∗ − E
STRICT WEAK ORDER
PERMUTATION SWAPPING ITEMS I AND J IN RECOMMENDATION aaa
ORDERED PARTITION OF ITEMS REPRESENTING A SUBSET OF RECOMMENDATIONS, PPP = (P1, . . . , Pd)
cth
SET OF RECOMMENDATIONS aaa AGREEING WITH PPP
BEST PARTITION AT ITERATION t GIVEN THE PREVIOUS CHOICES AND FEEDBACKS (CALLED LEADER)
PARTITION SUCH THAT ANY PERMUTATION aaa IN A (PPP ∗) IS COMPATIBLE WITH THE STRICT WEAK ORDER ON ITEMS.
GRAPH CARRYING A PARTIAL ORDER ON THE PARTITIONS OF ITEMS
NEIGHBORHOOD IN G OF THE PARTITION PPP , N ( ˜PPP ) :=

c=1 Pc = [L], AND Pc ∩ Pc(cid:48) IS EMPTY WHEN c (cid:54)= c(cid:48)

PART OF PPP SUCH AS (cid:83)d

t=1 µaaa(t)

i=1 ci(t)

(cid:104)(cid:80)T

µaaa

(cid:105)

(cid:17)
(cid:110)(cid:16) ˜P1(t), . . . , ˜Pc−1(t), ˜Pc(t) ∪ ˜Pc+1(t), ˜Pc+2(t), . . . ˜P ˜d(t)
(cid:17)
(cid:110)(cid:16) ˜P1(t), . . . , ˜P ˜d−1(t) ∪ {j}, ˜P ˜d−1(t) \ {j}, ˜P ˜d(t)

: j ∈ ˜P ˜d(t)

(cid:111)

.

∪

s=1

s=1

1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9)

1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9) 1{ci(s) (cid:54)= cj (s)}

NUMBER OF ITERATIONS AT WHICH ITEMS i AND j HAVE BEEN GATHERED IN THE SAME SUBSET OF ITEMS Pc(s),
ti,j (t) := (cid:80)t−1
NUMBER OF ITERATIONS AT WHICH ITEMS i AND j HAVE BEEN GATHERED IN THE SAME SUBSET OF ITEMS Pc(s)
AND LEAD TO A DIFFERENT CLICK VALUE, Ti,j (t) = (cid:80)t−1
NUMBER OF TIME A PERMUTATION ˜PPP AS BEEN THE LEADER, ˜t ˜PPP (t) := (cid:80)t−1
PROBABILITY OF DIFFERENCE, ˜δi,j (aaa) = P
EXPECTED CLICK DIFFERENCE, ˜∆i,j (aaa) = E
UNIRANK’S MAIN STATISTIC TO INFER THAT i (cid:31) j, ˆsi,j (t) :=

1
Ti,j (t)
KULLBACK-LEIBLER BASED OPTIMISTIC ESTIMATOR, ¯¯sj,i(t) := 2 ∗ f
KULLBACK-LEIBLER INDEX FUNCTION, f (ˆµ, T, t) := inf{µ ∈ [0, ˆµ] : T × kl(ˆµ, µ) ≤ log(t) + 3 log(log(t))},
KULLBACK-LEIBLER DIVERGENCE FROM A BERNOULLI DISTRIBUTION OF MEAN p
TO A BERNOULLI DISTRIBUTION OF MEAN q, kl(p, q) = p log
+ (1 − p) log
UNIFORM DISTRIBUTION ON THE SET S
(IN PB-MHB) PARAMETER CONTROLLING SIZE OF THE STEP IN THE METROPOLIS HASTING INFERENCE

aaa(cid:48)∼U ({aaa,(i,j)◦aaa}) [ci − cj | ci (cid:54)= cj ]

(cid:80)t−1
s=1
(cid:16) 1+ˆsi,j (t)
2

1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9) (ci(s) − cj (s))
(cid:17)
, Ti,j (t), ˜t ˜PPP (t)

aaa(cid:48)∼U ({aaa,(i,j)◦aaa}) [ci (cid:54)= cj ]

(cid:110) ˜PPP (s) = ˜PPP

(cid:16) 1−p
1−q

(cid:16) p
q

− 1

s=1

(cid:111)

(cid:17)

(cid:17)

1

Table 4. Summary of the notations.

: c ∈ [ ˜d − 2]

(cid:111)

UniRank: Unimodal Bandit Algorithm for Online Ranking

Algorithm 2 Elicitation of the leader partition ˜PPP (t)
Require: number of items L, number of positions K, iteration index t, statistics ˆsi,j(t)
1: ˜d ← 1; R ← [L]; n ← L
2: repeat
3:
4:
5:
6: B ← {i1, . . . , i(cid:96)−1}; ˜P ˜d(t) ← B
˜d ← ˜d + 1; R ← R \ B; n ← |R|
7:
(cid:12)
(cid:12)
(cid:12)

for each i ∈ R, Si ← | {j ∈ R : ˆsi,j(t) > 0} |
sort items in R by Si: Si1 > Si2 > · · · > Sin
(cid:96) ← min (cid:8)(cid:96) ∈ [n] : ∀k < (cid:96), ∀k(cid:48) (cid:62) (cid:96) : ˆsik,ik(cid:48) (t) > 0(cid:9)

(cid:12)
(cid:83) ˜d
(cid:12)
(cid:12)

˜P˜c(t)

˜c=1

(cid:62) K
8: until
9: ˜d ← ˜d + 1 ; ˜P ˜d(t) ← R
10: return ˜PPP (t)

Note that for c (cid:54) K, ∆c := ρ(aaa∗, c − 1) + ρ(aaa∗, c) − ρ((c − 1, c) ◦ aaa∗, c − 1) − ρ((c − 1, c) ◦ aaa∗, c), and for c (cid:62) K + 1,
∆c = ρ(aaa∗, K) − ρ((K, c) ◦ aaa∗, K).

C. Algorithm for the Elicitation of the leader partition ˜PPP (t)

D. Proof of Lemma 3.1 (PBM and CM Fulﬁlls Assumptions 3.1, 3.2, and 3.3)

For both CM and PBM click models, we note θi the click probability of item i. For PBM we have κk the probability that a
user see the position k.

Proof. Let us begin with some preliminary remarks.

First, with PBM model, the positions are ranked by decreasing observation probability, meaning that κa1
κaK .

(cid:62) κa2

(cid:62) · · · (cid:62)

Secondly, by deﬁnition, ρ(k, aaa) > 0 for any position k and recommendation aaa, which implies that:

• mini θi > 0 and maxi θi < 1 in CM model;

• κK > 0 in PBM model.

Let us now prove that Assumptions 3.1, 3.2 and 3.3 are fulﬁlled by PBM and CM click models with the strict weak order (cid:31)
deﬁned by i (cid:31) j ⇐⇒ θi > θj.
By deﬁnition of (cid:31), Assumption 3.1 is fulﬁlled taking the the preferential attachment function g : i (cid:55)→ θi, and Assumption 3.1∗
is fulﬁlled as soon as θi (cid:54)= θj for any item i in top-K items and any item j (cid:54)= i.
For Assumption 3.2, we have to prove that having aaa compatible with (cid:31) is optimal, meaning µaaa = µ∗.

Let aaa be a permutation compatible with (cid:31).
In the case of CM, µaaa = 1 − (cid:80)K
compatible with (cid:31), which is deﬁned based on values θi, it satisﬁes this property. Hence, CM fulﬁlls Assumption 3.2.
For PBM, µaaa = (cid:80)K
k=1 θak κk. As the series (κk)k∈[K] is non-increasing, µaaa is maximized if (θk)k∈[K] is also non-
increasing and if θK (cid:62) maxk(cid:62)K+1 θk. These properties are ensured by the fact that aaa is compatible with (cid:31) and that (cid:31) is
deﬁned based on values θi. Hence, PBM fulﬁlls Assumption 3.2.

k=1(1 − θak ). In order to maximize µaaa, one has to select the K higher values of θθθ. As aaa is

We now prove that CM and PBM fulﬁll Assumption 3.3. Let i and j be two distinct items such that i (cid:31) j and aaa ∈ P L
recommendation such that at least one of both items is displayed.
First, Eaaa(cid:48)∼U ({aaa,(i,j)◦aaa}) [ci(t) (cid:54)= cj(t) | aaa(t) = aaa(cid:48)] is non-null with PBM model as ci(t) and cj(t) are independent and as at

K be a

UniRank: Unimodal Bandit Algorithm for Online Ranking

least one of the four variables ci(t) | aaa(t) = aaa, ci(t) | aaa(t) = (i, j) ◦ aaa, cj(t) | aaa(t) = aaa, cj(t) | aaa(t) = (i, j) ◦ aaa has an
expectation which is non-zero and strictly smaller than 1 (due to κK > 0 and θi > θj).
Similarly, Eaaa(cid:48)∼U ({aaa,(i,j)◦aaa}) [ci(t) (cid:54)= cj(t) | aaa(t) = aaa(cid:48)] is non-null with CM model as at most one of both items can be
clicked at each iteration and the shown item has non-zero probability to be clicked (by deﬁnition of ρ).
Then, we consider ˜∆i,j(aaa) as

˜∆i,j(aaa) =

Paaa(cid:48)∼U ({aaa,(i,j)◦aaa})(ci = 1, cj = 0) − Paaa(cid:48)∼U ({aaa,(i,j)◦aaa})(ci = 0, cj = 1)
Paaa(cid:48)∼U ({aaa,(i,j)◦aaa})(ci = 1, cj = 0) + Paaa(cid:48)∼U ({aaa,(i,j)◦aaa})(ci = 0, cj = 1)

We want to control the sign of ˜∆i,j(aaa), which is also the sign of its numerator, as its denominator (noted D ˜∆i,j (aaa)) is
non-negative.

The recommendation aaa(cid:48) is drawn uniformly in {aaa, (i, j) ◦ aaa} thus

Paaa(cid:48)∼U ({aaa,(i,j)◦aaa})(ci = 1, cj = 0) =

1
2

Paaa(ci = 1, cj = 0) +

1
2

P(i,j)◦aaa(ci = 1, cj = 0).

When considering a CM click model, we have Paaa(ci = 1, cj = 0) = (cid:81)k−1
(cid:81)l−1

p=1(1 − θap )θj when i and j ∈ aaa.

p=1(1 − θap )θi and Paaa(ci = 0, cj = 1) =

In that case, we have:

1
2

(cid:81)k−1

p=1(1 − θap )θi + 1
2

˜∆i,j(aaa) =

which can be simpliﬁed in:

(cid:81)l−1

p=1(1 − θap )θi −

(cid:81)l−1

p=1(1 − θap )θj + 1
2

(cid:16) 1
2
D ˜∆i,j (aaa)

(cid:81)k−1

p=1(1 − θap )θj

(cid:17)

1
2

˜∆i,j(aaa) =

(cid:16)(cid:81)k−1

p=1(1 − θap ) + (cid:81)l−1
D ˜∆i,j (aaa)

p=1(1 − θap )

(cid:17)

(θi − θj)

.

Since maxi θi < 1, (cid:81)k−1
˜∆i,j(aaa) > 0 ⇐⇒ θi > θj ⇐⇒ i (cid:31) j.
Now if i /∈ aaa then Paaa(ci = 1, cj = 0) = 0 as the position is not seen. We have:

p=1(1 − θap ) + (cid:81)l−1

p=1(1 − θap ) > 0, thus the sign of ˜∆i,j(aaa) is the sign of (θi − θj) and

˜∆i,j(aaa) =

1

2 ((cid:81)l−1

p=1(1 − θap ))(θi − θj)

D ˜∆i,j (aaa)

which leads to the same conclusion as the previous case. By symmetry, we have the same conclusion with j /∈ aaa.
Now with a PBM click model, we have Paaa(ci = 1, cj = 0) = κkθi(1 − κlθj) as ci = 1 and cj = 0 are independant events.

Thus, we have:

˜∆i,j(aaa) =

which can be simpliﬁed in:

1

2 κkθi(1 − κlθj) + 1

2 κlθi(1 − κkθj) − (cid:0) 1
D ˜∆i,j (aaa)

2 κlθj(1 − κkθi) + 1

2 κkθj(1 − κlθi)(cid:1)

˜∆i,j(aaa) =

1
2 (κk + κl)(θi − θj)
D ˜∆i,j (aaa)

As κk or κl is positive if i or j is presented, similarly to the CM case we have ˜∆i,j(aaa) > 0 ⇐⇒ θi > θj ⇐⇒ i (cid:31) j.

UniRank: Unimodal Bandit Algorithm for Online Ranking

This proof can be extended to i or j /∈ aaa by taking κk = 0 when k > K.

We can conclude that both CM and PBM fulﬁlls Assumption 3.3.

E. Technical Lemmas Required by the Proof of Theorem 5.1

In this section, we gather technical Lemmas required to prove the regret upper-bound of UniRank. These lemmas regard
the concentration away from zero of the statistic ˆsi,j(t) (Appendices E.1 and E.2), and the sufﬁcient optimism brought by
¯¯sj,i(t) (Appendix E.3).

E.1. Minimum Expected Click Difference
Assumption 3.3 builds upon ˜∆i,j(aaa) which measures the difference of attractiveness between i and j while all other items
are at ﬁxed positions. In the theoretical analysis of UniRank, we handle situations where other items may also change in
position thanks to the following Lemma.

Lemma E.1 (Minimum expected click difference). Let (L, K, ρ) be an OLR problem satisfying Assumptions 3.2 and 3.3
with (cid:31) the order on items, and let i and j be two items such that i (cid:31) j. Then, for any partition of items PPP , if there exists
c and Eaaa(t)∼U (A(PPP )) [ci(t) (cid:54)= cj(t)] (cid:54)= 0, then Eaaa(t)∼U (A(PPP )) [ci(t) − cj(t) | ci(t) (cid:54)= cj(t)] > 0 and
c such that (i, j) ∈ P 2
therefore

˜δi,j > 0

and

˜∆i,j > 0.

Symmetrically,
Eaaa(t)∼U (A(PPP )) [ci(t) (cid:54)= cj(t)] (cid:54)= 0, then Eaaa(t)∼U (A(PPP )) [ci(t) − cj(t) | ci(t) (cid:54)= cj(t)] < 0 and therefore

for any partition of

if j (cid:31) i,

items PPP ,

there exists c such that (i, j) ∈ P 2

if

c and

˜δi,j > 0

and

˜∆i,j < 0.

Proof. The proof consists in writing Eaaa(t)∼U (A(PPP )) [ci(t) (cid:54)= cj(t)] (cid:54)= 0 two times as a sum other aaa(t) ∈ U(A (PPP )), and
in reindexing one of both sums by (i, j) ◦ aaa(t) ∈ U(A (PPP )). Then, adding the terms of both sums we get a sum of terms
˜∆i,j(aaa) which by assumption 3.3 are positive. Hence this sum is positive, which concludes the proof.

E.2. Upper-bound on the Number of High Deviations for Variables with Lower-Bounded Mean

The Proof of Theorem 5.1 requires the control of the expected number of high deviations of the statistic ˆsi,j(t). We control
this expectation through Lemma E.4 which derives from the application of Lemmas E.2 and E.3 to ˆsi,j(t) and ˆTi,j(t).
Hereafter, we express and prove the three lemmas. Note that Lemmas E.2 and E.3 are extensions of Lemmas 4.3 and B.1 of
(Combes & Prouti`ere, 2014) to a setting where the handled statistic is a mixture of variables following different laws of
bounded expectation.

Lemma E.2 (Concentration bound with lower-bounded mean). Let (X a
t )t(cid:62)1 with a ∈ R, be |R| < ∞ independent
sequences of independent random variables bounded in [0, B] deﬁned on a probability space (Ω, F, P). Let Ft be an
increasing sequence of σ−ﬁelds of F such that for each t, σ((X a
t )a∈R) ⊂ Ft and for s > t and a a
recommendation, X a
t )t≥1 of Bernoulli variables (for all
t > 0, (cid:15)a

s is independent from Ft. Consider |R| previsible sequences ((cid:15)a

t is Ft−1 − mesurable) such that for all t > 0, (cid:80)

t ∈ {0, 1}. Let δ > 0 and for every t ∈ {1, . . . , n} let

1 )a∈R, . . . , (X a

i (cid:15)a

S(t) =

t
(cid:88)

(cid:88)

s=1

i

s(X i
(cid:15)i

s − E[X i

s]),

T (t) =

t
(cid:88)

(cid:88)

s=1

i

(cid:15)i
s,

ˆµ(t) =

S(t)
N (t)

.

Deﬁne φ ∈ {t0, . . . , T + 1} a F-stopping time such that either T (φ) (cid:62) s or φ = T + 1.

Then

P (S(φ) (cid:62) T (φ)δ, φ (cid:54) T ) (cid:54) exp(−

2nδ2
B2 ).

UniRank: Unimodal Bandit Algorithm for Online Ranking

Proof. Let λ > 0, and deﬁne Gt = exp(λ(S(t) − δT (t)))1{t (cid:54) T }. We have that:

P(S(φ) (cid:62) T (φ)δ, φ (cid:54) T ) = P(exp(λ(S(φ) − δT (φ))1{φ (cid:54) T } (cid:62) 1)

= P(gφ (cid:62) 1)
(cid:54) E[Gφ].

Next we provide an upper bound for E[Gφ]. We deﬁne the following quantities:

s = εi
Y i

s(λ(X i

s − E[X i

s]) − λ2B2/8)

˜Gt = exp

(cid:32) t

(cid:88)

(cid:88)

s=1

i

(cid:33)

Y i
s

1{t (cid:54) T }.

Taking λ = 4δ/B2, Gt can be written:

Gt = ˜Gt exp(−T (t)(λδ − λ2B2/8) = ˜Gt exp(−2T (t)δ2/B2).

As T (t) (cid:62) n if φ (cid:54) T we can upper bound Gφ by:

Gφ = ˜Gφ exp(−2T (φ)δ2/B2) (cid:54) ˜Gφ exp(−2nδ2/B2).

It is noted that the above inequality holds even when φ = T + 1, since GT +1 = ˜GT +1 = 0. Hence:

E[Gφ] (cid:54) E[ ˜Gφ] exp(−2nδ2/B2)

We prove that
measurable:

(cid:17)

(cid:16) ˜Gt

t

is a super-martingale. We have that E[ ˜GT +1 | FT ] = 0 (cid:54) ˜GT . For s (cid:54) T − 1, since Bt+1 is F

E[ ˜Gt+1 | Ft] = ˜Gt((1 −

εi
t+1) +

(cid:88)

i

(cid:88)

i

εi
t+1

E[exp(Y i

t+1)]).

As proven in (Hoeffding, 1963)[eq. 4.16] since X i

t+1 ∈ [0, B]:

E[exp(λ(X i

t+1 − E[X i

t+1])] (cid:54) exp(λ2B2/8),

t+1)] (cid:54) 1 and

so E[exp(Y i
a supermartingale, Doob’s optional stopping theorem yields: E[ ˜Gφ] (cid:54) E[ ˜G0] = 1, and so

is a super-martingale: E[ ˜Gt+1 | Ft] (cid:54) ˜Gt. Since φ (cid:54) T + 1 almost surely, and

t

(cid:17)

(cid:16) ˜Gt

(cid:17)

(cid:16) ˜Gt

is

t

P(S(φ) (cid:62) T (φ)δ, φ (cid:54) T ) (cid:54) E[Gφ]

(cid:54) E[ ˜Gφ] exp(−2nδ2/B2)
(cid:54) exp(−2nδ2/B2),

which concludes the proof

Lemma E.3 (Expected number of large deviation with lower-bounded mean). Let (L, K, ρ) be an OLR problem, Ft the
natural σ-algebra generated by the OLR problem, and F = (Ft)t∈Z the corresponding ﬁltration. We denote Ot :=
(aaa(1), ccc(1), . . . , aaa(t − 1), ccc(t − 1)) the set of random values observed up to time t − 1. Let Zt ∈ [0, B] and Bt ∈ {0, 1}
be two Ft−1-measurable random variables, Λ ⊆ N be a random set of instants, and ε > 0. For any t ∈ Z, we denote
S(t) := (cid:80)t
s=0 Bs. If for any t > 0, E [Zt | Ot, Bt = 1] (cid:62) δ and there exists a sequence of

s=0 BsZs and T (t) := (cid:80)t

UniRank: Unimodal Bandit Algorithm for Online Ranking

random sets (Λ(n))n>0 such that (i) Λ ⊆ (cid:83)
(iv) the event t ∈ Λ(n) is F-measurable. Then

n>0 Λ(n), (ii) for all n > 0 and all t ∈ Λ(n), T (t) (cid:62) εn, (iii) |Λ(n)| (cid:54) 1, and



E

(cid:88)



t≥1

1{t ∈ Λ : S(t) <



T (t)}

 ≤

δ
2

2B2
(cid:15)δ2

Proof. Let T ∈ N. For all n ∈ N, |Λ(n)| (cid:54) 1, we deﬁne Φn as T + 1 if Λ(n) ∩ [T ] is empty and {Φn} = Λ(n) otherwise.
Since Λ ⊆ (cid:83)

n>0 Λ(n), we have

(cid:26)

T
(cid:88)

1

t=1

t ∈ Λ : S(t) <

(cid:27)

T (t)

δ
2

(cid:54) (cid:88)
n(cid:62)1

(cid:26)

1

S(Φn) <

T (Φn), Φn (cid:54) T

(cid:27)

.

δ
2

Taking expectations,

(cid:34) T

(cid:88)

(cid:26)

1

E

t=1

t ∈ Λ : S(t) <

(cid:27)(cid:35)

T (t)

δ
2

(cid:20)
S(Φn) <

P

δ
2

(cid:54) (cid:88)
n(cid:62)1

T (Φn), Φn (cid:54) T

(cid:21)

For any t ∈ N, denote S(cid:48)(t) := (cid:80)t
S(cid:48)(t) < S(t) − T (t)δ. Therefore, for any n ∈ N

s=0 Bs(Zs − E [Zs | 0s, Bs = 1]). As for any s ∈ N, E [Zs | 0s, Bs = 1] > δ,

(cid:20)
S(Φn) <

P

δ
2

T (Φn), Φn (cid:54) T

(cid:21)

(cid:54) P

(cid:20)
S(cid:48)(Φn) < −

T (Φn), Φn (cid:54) T

(cid:21)

δ
2

and

(cid:34) T

(cid:88)

(cid:26)

1

E

t=1

t ∈ Λ : S(t) <

(cid:27)(cid:35)

T (t)

δ
2

(cid:54) (cid:88)
n(cid:62)1

(cid:20)
S(cid:48)(Φn) < −

P

δ
2

T (Φn), Φn (cid:54) T

(cid:21)

By Lemma E.2, since Φn is a stopping time upper bounded by T + 1, and T (Φn) (cid:62) εn,

(cid:34) T

(cid:88)

(cid:26)

1

E

t=1

t ∈ Λ : S(t) <

(cid:27)(cid:35)

T (t)

δ
2

(cid:54) (cid:88)
n(cid:62)1

(cid:18)

exp

−

(cid:19)

εnδ2
2B2

(cid:54) 2B2
εδ2 ,

where the last inequality drives from the (cid:80)

0
This upper-bound is valid for any T , which concludes the proof.

n(cid:62)1 exp (−nw) (cid:54) (cid:82) +∞

exp (−uw) du = 1
w .

Lemma E.4 (Expected number of large deviation for our statistics). Let (L, K, ρ) be an OLR problem satisfying Assumptions
3.2 and 3.3 with (cid:31) the order on items, and let i and j be two items. If there exists a sequence of random sets (Λ(n))n>0
such that (i) Λ ⊆ (cid:83)
n>0 Λ(n), (ii) for all n > 0 and all t ∈ Λ(n), ti,j(t + 1) (cid:62) εn, (iii) |Λ(n)| (cid:54) 1, and (iv) the event
t ∈ Λ(n) is F-measurable. Then,

(cid:40)



E

(cid:88)



1

t≥1

t ∈ Λ, Ti,j(t) <

(cid:41)

ti,j(t)

 = O(1)

˜δi,j
2

(4)

and

(cid:40)



E

(cid:88)



1

t≥1

t ∈ Λ,

ˆsi,j(t)
˜∆i,j

<

1
2

(cid:41)

 = O(1),

UniRank: Unimodal Bandit Algorithm for Online Ranking

meaning

(cid:40)

(cid:40)



E

(cid:88)



1

t≥1



E

(cid:88)



1

t≥1

t ∈ Λ, ˆsi,j(t) <

t ∈ Λ, ˆsi,j(t) >

(cid:41)

 = O(1)

(cid:41)

 = O(1)

˜∆i,j
2

˜∆i,j
2

, if i (cid:31) j;

, if j (cid:31) i.

(5)

(6)

Proof. Let assume i (cid:31) j. We ﬁrst prove Claim (4) and then prove Claim (5) using Claim (4).
For any t (cid:54) 1, we deﬁne both following Ft−1-measurable random variables

Zt := 1 {ci(t) (cid:54)= cj(t)}

Bt := 1 (cid:8)∃c, (i, j) ∈ Pc(t)2(cid:9) ,

and we denote Ot := (aaa(1), ccc(1), . . . , aaa(t − 1), ccc(t − 1)) the set of random values observed up to time s − 1. Note that
Ti,j(t + 1) = (cid:80)t

s=1 Bs, and E [Zt | 0t, Bt = 1] > ˜δi,j by Lemma E.1.

s=1 BsZs, ti,j(t + 1) = (cid:80)t

Therefore by Lemma E.3

meaning



E

(cid:88)



t≥1

1{t ∈ Λ : Ti,j(t + 1) <

˜δi,j
2

ti,j(t + 1)}


 (cid:54) 2
(cid:15)˜δ2
i,j

,



E

(cid:88)



t≥1

1{t ∈ Λ : Ti,j(t) <


 (cid:54) 1 +

ti,j(t)}

˜δi,j
2

2
(cid:15)˜δ2
i,j

= O(1),

which corresponds to Claim (4).

Let now prove Claim (5) using the following decomposition

(cid:34) T

(cid:88)

1

E

(cid:40)

t=1

t ∈ Λ, ˆsi,j(t) <

˜∆i,j
2

(cid:41)(cid:35)

(cid:40)

(cid:34) T

(cid:88)

1

(cid:54) E

t ∈ Λ, ˆsi,j(t) <

˜∆i,j
2

Ti,j(t) <

(cid:41)(cid:35)

ti,j(t)

˜δi,j
2

t=1
(cid:34) T

(cid:88)

+ E

t=1

(cid:40)

1

t ∈ Λ, ˆsi,j(t) <

˜∆i,j
2

, Ti,j(t) (cid:62)

(cid:41)(cid:35)

ti,j(t)

,

˜δi,j
2

Where the ﬁrst right-hand side term is smaller than E
control the second term by applying again Lemma E.3.
For any t (cid:54) 1, we deﬁne both following Ft−1-measurable random variables

t≥1

1

t ∈ Λ, Ti,j(t) <

(cid:104)(cid:80)

(cid:110)

˜δi,j
2 ti,j(t)

(cid:111)(cid:105)

and therefore is a O(1). We

Zt := ci(t) − cj(t)

Bt := 1 (cid:8)∃c, (i, j) ∈ Pc(t)2, ci(t) (cid:54)= cj(t)(cid:9) ,

Note that Zt ∈ [−1, 1], ˆsi,j(t + 1)Ti,j(t + 1) = (cid:80)t
Lemma E.1 as i (cid:31) j.

s=1 BsZs, Ti,j(t + 1) = (cid:80)t

s=1 Bs, and E [Zt | 0t, Bt = 1] > ˜∆i,j by

(cid:110)
t ∈ N : Ti,j(t) (cid:62) ˜δi,j

2 ti,j(t)

(cid:111)

We also deﬁne A := Λ ∩
(cid:110)
t ∈ N : Ti,j(t) (cid:62) ˜δi,j
Ti,j(t) (cid:62) ˜δi,j
Lemma E.3

(cid:111)
. Then, (i) as Λ ⊆ (cid:83)

2 ti,j(t)

n>0 A(n), (ii) for all n > 0 and all t ∈ A(n),
2 ti,j(t) (cid:62) ˜δi,j
2 εn, (iii) |A(n)| (cid:54) |Λ(n)| (cid:54) 1, and (iv) the event t ∈ A(n) is F-measurable. Therefore by


n>0 Λ(n), A ⊆ (cid:83)

and for any n ∈ N, A(n)

:= Λ(n) ∩

E

(cid:88)



t≥1

1{t ∈ A : ˆsi,j(t + 1)Ti,j(t + 1) <

˜∆i,j
2

Ti,j(t + 1)}


 (cid:54)

8
˜δi,jε ˜∆2
i,j

,

meaning

UniRank: Unimodal Bandit Algorithm for Online Ranking



E

(cid:88)



t≥1

(cid:26)

1

(cid:27)

˜∆i,j
t∈Λ,ˆsi,j (t)<
2 ,
˜δi,j
Ti,j (t)(cid:62)
2 ti,j (t)


 (cid:54) 1 +

8
˜δi,jε ˜∆2
i,j

= O(1).

Overall, E

(cid:104)(cid:80)T

t=1

1 (cid:8)

t∈Λ,ˆsi,j (t)<

(cid:9)(cid:105)

˜∆i,j
2

Other claims are proved symmetrically.

= O(1) + O(1) = O(1) which corresponds to Claim (5).

E.3. Upper-Bound on the Number of Lower-Estimations of an Optimistic Estimator
This section presents two results aiming at upper-bounding the number of iterations at which ˜∆j,i is lower-estimated by
¯¯sj,i(t) if j (cid:31) i. These new results are extensions of Lemma 9 and Theorem 10 of (Garivier & Capp´e, 2011) to a setting
where the handled statistic is a mixture of variables following different laws of bounded expectation.
Lemma E.5. Let X be a random variable taking value in [0, 1] and let µ ≤ E[X]. then for all λ < 0,

E[exp(λX)] ≤ 1 − µ + µ exp(λ),

Proof. The function f : [0, 1]
hence f (x) ≤ 0 for all x ∈ [0, 1]. Consequently,

R
−→ deﬁned by f (x) = exp(λx) − x(exp(λ) − 1) − 1 is convex and such that f (0) = f (1) = 0,

E[exp(λX)] ≤ E[X(exp(λ) − 1) + 1] = E[X](exp(λ) − 1) + 1

As λ < 0 and µ ≤ E[X], we have E[X](exp(λ) − 1) ≤ µ(exp(λ) − 1) and

E[exp(λX)] ≤ µ(exp(λ) − 1) + 1

Lemma E.6. Let (X a
[0, 1] deﬁned on a probability space (Ω, F, P) with common expectations µa = E[X a
Let Ft be an increasing sequence of σ−ﬁelds of F such that for each t, σ((X a
and a a recommendation, X a
(for all t > 0, (cid:15)a

t )t(cid:62)1 with a ∈ R, be |R| < ∞ independent sequences of independent random variables bounded in
t ] of minimal value µ = mina∈R µa.
t )a∈R) ⊂ Ft and for s > t
t )t≥1 of Bernoulli variables

1 )a∈R, . . . , (X a
s is independent from Ft. Consider |R| previsible sequences ((cid:15)a

t is Ft−1 − mesurable) such that for all t > 0, (cid:80)

t ∈ {0, 1}. Let δ > 0 and for every t let

i (cid:15)a

S(t) =

t
(cid:88)

(cid:88)

s=1

i

sX i
(cid:15)i
s,

N (t) =

t
(cid:88)

(cid:88)

s=1

i

(cid:15)i
s,

ˆµ(t) =

S(t)
N (t)

u(t) = max{q > ˆµ(t) : N (t)d(ˆµ(t), q) ≤ δ}

Then

P(u(t) < µ) ≤ e(cid:100)δ log(t)(cid:101) exp(−δ)

Proof. For every λ < 0, by Lemma E.5, it holds that log(E[exp(λX a
W λ

0 = 1 and for t ≥ 1,

W λ

t = exp(λS(t) − N (t)φµ(λ))

1 )]) ≤ log(1 − µ + µ exp(λ)) = φµ(λ) for all a. Let

(W λ

t )t≥0 is a super-martingale relative to (Ft)t≥0. In fact,

E[exp(λ{S(t + 1) − S(t)})|Ft] = E[exp(λ

t+1X i
(cid:15)i

t+1)|Ft]

(cid:88)

i

As (X i

t )t are independent sequences, we can rewrite :

E[exp(λ{S(t + 1) − S(t)})|Ft] =

(cid:89)

i

E[exp(λ(cid:15)i

t+1X i

t+1)|Ft] =

exp((cid:15)i

t+1 log(E[exp(λX i

t+1)|Ft]))

(cid:89)

i

UniRank: Unimodal Bandit Algorithm for Online Ranking

(cid:88)

= exp(

i

t+1 log(E[exp(λX i
(cid:15)i

1)|Ft])) ≤ exp(

(cid:88)

(cid:15)i
t+1φµ(λ)) = exp({N (t + 1) − N (t)}φµ(λ))

i

which can be rewritten as

E[exp(λS(t + 1) − N (t + 1)φµ(λ))|Ft] ≤ exp(λS(t) − N (t)φµ(λ))

The rest of the proof follows (Garivier & Capp´e, 2011). Using the ”peeling trick”: the interval {1, . . . , t} of possible values
for N (t) is divided into slices {tk−1 + 1, . . . , tk} of geometrically increasing size. Each slice is treated independently. We
assume that δ > 1 and we construct the slicing as follow : t0 = 0 and for k ∈ N∗, tk = (cid:98)(1 + η)k(cid:99), with η = 1/(δ − 1).
Let D = (cid:100) log t
log 1+η (cid:101) be the ﬁrst interval such that tD ≥ t and Ak the event {tk−1 ≤ N (t) ≤ tk} ∩ {u(t) < µ} . We have :

P(u(t) < µ) ≤ P(

D
(cid:91)

Ak) ≤

k=1

D
(cid:88)

k=1

P(Ak)

Note that by deﬁnition of u(t), we have u(t) < µ if and only if ˆµ(t) < µ and N (t)d(ˆµ(t), µ) > δ. Let s be the smallest
integer such that δ/(s + 1) ≤ d(0, µ). If N (t) ≤ s, then

N (t)d(ˆµ, µ) ≤ sd(ˆµ, µ) ≤

sd(0, µ)

<
by deﬁnition of s

δ.

as ˆµ≤µ
Thus, we can’t have ˆµ < µ and N (t)d(ˆµ, µ) > δ and P(u(t) < µ) = 0 . We have for all k such that tk ≤ s, P(Ak) = 0
and we have u(t) > µ when N (t) ∈ {tk−1 + 1, . . . , tk} and tk ≤ s.
Now lets see how u(t) can be upper bounded by µ when N (t) > s. For k such that tk ≥ s, we note ˜tk−1 = max{tk−1, s}
and we take z < µ such as d(z, µ) = δ/(1 + η)k and x ∈]0, µ[ such that d(x, µ) = δ/N (t). We deﬁne λ(x) =
log(x(1 − µ)) − log(µ(1 − x)) < 0 so that we can rewrite d(x, µ) as d(x, µ) = λ(x)x − φµ(λ(x)).

• with N (t) > ˜tk−1, we have d(z, µ) = δ

δ
(1+µ)N (t)

(1+µ)k ≥
N (t) > δ

• with N (t) ≤ tk, we have d(ˆµ(t), µ) > δ

(1+η)k = d(z, µ). As ˆµ < µ, we have ˆµ(t) ≤ z

Hence on the event {˜tk−1 < N (t) ≤ tk} ∩ {ˆµ(t) < µ} ∩ {d(ˆµ(t), µ)} it holds that λ(z)ˆµ(t) − φµ(λ(z)) ≥ λ(z)z −
φµ(λ(z)) = d(z, µ) ≥

δ
(1+η)N (t)

It leads to :

{˜tk−1 < N (t) ≤ tk} ∩ {u(t) < µ} ⊂ {λ(z)ˆµ(t) − φµ(λ(z)) ≥

δ
(1 + η)N (t)

⊂ {λ(z)S(t) − N (t)φµ(λ(z)) ≥

⊂ {W λ

n (z) > exp

δ
(1 + η)
(cid:19)

(cid:18) δ

(1 + η)

As (W λ

t )t≥0 is a supermartingale, E[W λ(z)

n

] ≤ E[W λ(z)

n

P({˜tk−1 < N (t) ≤ tk} ∩ {u(t) < µ}) ≤ P

W λ

n (z) > exp

] = 1, and the Markov inequality yields :
(cid:18)
(cid:18) δ
(cid:18)

(cid:19)(cid:19)

(1 + η)

≤ exp

−

As η = 1/(δ − 1), D = (cid:100) log n

log 1+η (cid:101) and log(1 + 1/(δ − 1)) ≥ 1/δ, we obtain :

P(u(t) < µ) ≤







(cid:16)

log n
1 + 1
δ−1

(cid:17)

log







exp(−δ + 1) ≤ e(cid:100)δ log(t)(cid:101) exp(−δ)

}

}

}

(cid:19)

δ
(1 + η)

UniRank: Unimodal Bandit Algorithm for Online Ranking

F. Proof of Theorem 5.1 (Upper-Bound on the Regret of UniRank Assuming a Total Order on

Items)

Before proving the regret upper-bound of UniRank, we prove Lemmas F.1 and F.2 which are respectively bounding the
exploration when the leader is the optimal one, and the number of iterations at which the leader is sub-optimal. Finally, the
regret upper-bound of UniRank is given in Appendix F.3.

F.1. Upper-Bound on the Number of Sub-Optimal Merges of UniRank when the Leader is the Optimal Partition

Lemma F.1 (Upper-bound on the number of sub-optimal merges of UniRank when the leader is the optimal partition).
Under the hypotheses of Theorem 5.1, for any position c ∈ {2, . . . , L} UniRank fulﬁlls

(cid:34) T

(cid:88)

1

E

t=1

(cid:110)

˜PPP (t)=PPP ∗,
∃c(cid:48),Pc(cid:48) (t)={min(c−1,K),c}

(cid:35)

(cid:111)

(cid:54)

16

˜δ∗
c

˜∆2

min(c−1,K),c

log T + O (log log T ) .

Proof. Let c ∈ {2, . . . , L} be a position, and denote i (respectively j) the item min(c − 1, K) (resp. c). We aim at upper-
bounding the number of iterations such that the leader ˜PPP (t) is the optimal partition PPP ∗, and either the subsets PPP ∗
c−1 = {i}
and PPP ∗
K = {i} in the chosen
partition PPP (t). Both situations require ¯¯sj,i(t) to be positive.

c = {j} are merged in the chosen partition PPP (t), or j ∈ PPP ∗

K+1(t) is added to the subset PPP ∗

Let decompose this number of iterations:

(cid:34) T

(cid:88)

1

E

t=1

(cid:110)

˜PPP (t)=PPP ∗,
∃c(cid:48),Pc(cid:48) (t)={min(c−1,K),c}

(cid:35)

(cid:111)

(cid:54) E

(cid:54) E

(cid:34) T

(cid:88)

t=1
(cid:34) T

(cid:88)

1

1

t=1
(cid:34) T

(cid:88)

t=1
(cid:34) T

(cid:88)

t=1

+ E

+ E

(cid:111)
(cid:110) ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},
¯¯sj,i(t)(cid:62)0

(cid:35)

(cid:26) ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},
ˆsj,i(t)>

˜∆j,i
2

(cid:27)(cid:35)

1

1

(cid:26) ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},

(cid:27)(cid:35)

T ∗

j (t)<

˜δ∗
j
2 t∗

j (t)

(cid:40) ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},
˜∆j,i
2 ,

T ∗
j (t)(cid:62)

˜δ∗
j
2 t∗

j (t), ˆsj,i(t)(cid:54)
¯¯sj,i(t)(cid:62)0

(cid:41)(cid:35)

,

where t∗

and T ∗

j (t) := (cid:80)t−1
s=1
j (t) := (cid:80)t−1
1

s=1

(cid:110) ˜PPP (t) = PPP ∗(cid:111)
1
(cid:110) ˜PPP (t) = PPP ∗(cid:111)

1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9),
1 (cid:8)∃c, (i, j) ∈ Pc(s)2(cid:9) 1{ci(s) (cid:54)= cj(s)}.

Let bound the ﬁrst term in the right-hand side.

(cid:111)
(cid:110)
t : ˜PPP (t) = PPP ∗, ∃c(cid:48), Pc(cid:48)(t) = {i, j}

Denote Λ =
gathered in a subset of PPP (t). We decompose that set as Λ ⊆ (cid:83)
ti,j(t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s), ti,j(n) (cid:62) ti,j(n) = s.

the set of iterations at which ˜PPP (t) = PPP ∗ and both items i and j are
s∈N Λ(s), with Λ(s) := {t ∈ Λ : ti,j(t) = s}. |Λ(s)| (cid:54) 1 as

Note also that with the current hypothesis on the order, i (cid:31) j, hence by Lemma E.4,


(cid:40)

E

(cid:88)



1

t≥1

t ∈ Λ, ˆsj,i(t) >

 = O(1).

(cid:41)

˜∆j,i
2

The second term is bounded similarly with the same set Λ but with a different decomposition: Λ ⊆ (cid:83)
Λ(s) := {t ∈ Λ : t∗
j (n) (cid:62) t∗
t∗
Therefore, the same proof as the one used in Lemma E.4 gives

s∈N Λ(s), with
j (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s),

j (t) = s}. |Λ(s)| (cid:54) 1 as t∗

j (n) = s.



E

(cid:88)



1

t≥1

(cid:40)

t ∈ Λ, T ∗

j (t) <

(cid:41)

t∗
j (t)

 = O(1)

˜δ∗
j
2

UniRank: Unimodal Bandit Algorithm for Online Ranking

It remains to upper-bound the third term.

(cid:26)

Let note C :=

t ∈ [T ] : ˜PPP (t) = PPP ∗, ∃c(cid:48), Pc(cid:48)(t) = {i, j}, T ∗

j (t) (cid:62)

Let t ∈ C.
By Pinsker’s inequality and as ¯¯sj,i(t) (cid:62) 0,

˜δ∗
2 t∗
j

j (t), ˆsj,i(t) (cid:54) ˜∆j,i

2 , ¯¯sj,i(t) (cid:62) 0

(cid:27)

.

1
2

(cid:54)

¯¯sj,i(t) + 1
2
(cid:54) ˆsj,i(t) + 1
2

(cid:115)

+

log(˜tPPP ∗ (t)) + 3 log(log(˜tPPP ∗ (t)))
2Ti,j(t)

(cid:115)

(cid:54)

˜∆j,i
4

+

1
2

+

log(˜tPPP ∗ (t))) + 3 log(log(˜tPPP ∗ (t))))
2Ti,j(t)

.

Hence, Ti,j(t) (cid:54) 8 log(˜tPPP ∗ (t)))+24 log(log(˜tPPP ∗ (t))))

as ˜∆i,j = − ˜∆j,i > 0 given Lemma E.1. Then, by deﬁnition of C and

i,j

˜∆2
j (t) (cid:54) Ti,j(t), and (iii) ˜δ∗

j

(cid:62) ˜δi,j > 0 given Lemma E.1, t∗

j (t) (cid:54) 2T ∗
j (t)
˜δ∗
j

(cid:54) 2Ti,j (t)

˜δ∗
j

(cid:54)

as (i) ˜tPPP ∗ (t) (cid:54) t (cid:54) T , (ii) T ∗
16 log(T )+48 log(log(T ))
˜∆2

.

˜δ∗
j

i,j

Therefore, C ⊆

(cid:26)

t ∈ [T ] : ˜PPP (t) = PPP ∗, ∃c(cid:48), Pc(cid:48)(t) = {i, j}, t∗

j (t) (cid:54) 16 log(T )+48 log(log(T ))

˜δ∗
j

˜∆2

i,j

(cid:27)

, and

(cid:34) T

(cid:88)

1

E

t=1

which concludes the proof.

(cid:40) ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},
˜∆j,i
2 ,

T ∗
j (t)(cid:62)

˜δ∗
j
2 t∗

j (t), ˆsj,i(t)(cid:54)
¯¯sj,i(t)(cid:62)0

(cid:41)(cid:35)

= E [|C|]

(cid:54) E

(cid:20)(cid:12)
(cid:26)t∈[T ]: ˜PPP (t)=PPP ∗, ∃c(cid:48),Pc(cid:48) (t)={i,j},
(cid:12)
(cid:12)
j (t)(cid:54) 16 log(T )+48 log(log(T ))
t∗
(cid:12)
˜δ∗
j

˜∆2

i,j

(cid:27)(cid:12)
(cid:12)
(cid:12)
(cid:12)

(cid:21)

(cid:54) 16 log(T ) + 48 log(log(T ))
˜δ∗
j

˜∆2
i,j

,

F.2. Upper-Bound on the Expected Number of Iterations at which the Leader is not the Optimal Partition

Lemma F.2 (Upper-bound on the expected number of iterations at which the leader is not the optimal partition). Under the
hypotheses of Theorem 5.1, UniRank fulﬁlls

(cid:34) T

(cid:88)

(cid:35)
1{ ˜PPP (t) (cid:54)= PPP ∗}

E

= O (log log T ) .

t=1

Proof. Let ˜PPP (cid:54)= PPP ∗ be an ordered partition of items of size d, and let upper-bound the expected number of iterations at
which ˜PPP (t) = ˜PPP by O (log log T ). As there is a ﬁnite number of partitions, this will conclude the proof.

In this proof, for any couple of items (i, j) we denote ˜ti,j(t) := (cid:80)t−1
the number of
iterations at which both items have been gathered in the same subset of PPP (s) while the leader was ˜PPP . For each partition PPP
1
in the neighborhood N
the number of iterations at which
PPP has been chosen while the leader was ˜PPP .
The proof depends on the difference between ˜PPP and PPP ∗. By Lemma 5.4,

, we also denote tPPP (t) := (cid:80)t−1

(cid:110) ˜PPP (t) = ˜PPP , PPP (t) = PPP

(cid:110) ˜PPP (t) = ˜PPP , ∃c, (i, j) ∈ Pc(s)2(cid:111)

(cid:16) ˜PPP

s=1

s=1

(cid:111)

1

(cid:17)

• either ∃c ∈ [ ˜d], such that |Pc| > 1 and i∗ (cid:31) argmaxj∈Pc\{i∗} g(j), where i∗ = argmaxi∈Pc g(i);

UniRank: Unimodal Bandit Algorithm for Online Ranking

• or ∃c ∈ [ ˜d − 1], ∃(i, j) ∈ ˜Pc × ˜Pc+1, such that j (cid:31) i.

We ﬁrst upper-bound the expected number of iterations at which ˜PPP (t) = ˜PPP under the ﬁrst condition, and then prove a similar
upper-bound under the second condition.

Assume that there exists c ∈ [ ˜d], such that |Pc| > 1 and i (cid:31) argmaxj∈Pc\{i∗} g(j), where i = argmaxi∈Pc g(i). Let t
be an iteration such that ˜PPP (t) = ˜PPP . By Assumption 3.3 and by design of the algorithm, if for each item j ∈ ˜Pc \ {i}, the
sign of ˆsi,j(t) would be the same as the sign of ˜∆i,j > 0, then i would be alone in ˜Pc(t). So ˆsi,j(t) (cid:54) 0 for at least one
item j ∈ ˜Pc \ {i}. Let control the number of iteration at which this is true by considering the following decomposition:

where

and

(cid:110)

t : ˜PPP (t) = ˜PPP

(cid:111)

⊆

(cid:91)

Ai,j ∪ Bi,j ∪ Ci,j,

j∈ ˜Pc\{i}

(cid:40)

Ai,j :=

t : ˜PPP (t) = ˜PPP , Ti,j(t) <

(cid:41)

ti,j(t)

,

˜δi,j
2

(cid:40)

Bi,j :=

t : ˜PPP (t) = ˜PPP ,

ˆsi,j(t)
˜∆i,j

<

(cid:41)

,

1
2

(cid:40)

Ci,j :=

t : ˜PPP (t) = ˜PPP , Ti,j(t) (cid:62)

˜δi,j
2

ti,j(t),

ˆsi,j(t)
˜∆i,j

(cid:62) 1
2

(cid:41)

, ˆsi,j(t) (cid:54) 0,

.

Let j be an item in ˜Pc \ {i}, and let ﬁrst upper-bound the expected size of Ai,j and Bi,j, and then the expected size of Ci,j.
Note that at each iteration such that ˜PPP (t) = ˜PPP , i and j are in the same subset of the partition PPP (t), therefore ˜ti,j(t) = ˜t ˜PPP (t).

(cid:110)

(cid:111)

t : ˜PPP (t) = ˜PPP

the set of iterations at which ˜PPP (t) = ˜PPP , and decompose that set as Λ ⊆ (cid:83)

Denote Λ =
s∈N Λ(s), with
Λ(s) := {t ∈ Λ : ˜t ˜PPP (t) = s}. |Λ(s)| (cid:54) 1 as ˜t ˜PPP (t) increases for each t ∈ Λ. Note that for each s ∈ N and n ∈ Λ(s),
ti,j(n) (cid:62) ˜ti,j(n) = ˜t ˜PPP (t) = s.
Then by Lemma E.4

and

E [|Ai,j|] = E

(cid:40)



(cid:88)



1

t≥1

t ∈ Λ, Ti,j(t) <

(cid:41)

ti,j(t)

 = O(1)

˜δi,j
2

E [|Bi,j|] = E

(cid:40)



(cid:88)



1

t≥1

t ∈ Λ,

ˆsi,j(t)
˜∆i,j

<

1
2

(cid:41)

 = O(1).

Let now upper-bound the expected size of Ci,j.
As i (cid:31) j, ˜∆i,j > 0.
Let t ∈ Ci,j. As ˆsi,j(t) (cid:54) 0, t (cid:54) T , and ˜t ˜PPP (t) = ˜ti,j(t) (cid:54) ti,j(t) (cid:54) 2
˜δi,j

Ti,j(t),

which is absurd. Hence, Ci,j = ∅, and E [|Ci,j|] = 0.

0 (cid:62) ˆsi,j(t) (cid:62)

˜∆i,j
2

> 0,

UniRank: Unimodal Bandit Algorithm for Online Ranking

Overall, if there exists c ∈ [ ˜d], such that |Pc| > 1 and i (cid:31) argmaxj∈Pc\{i} g(j), where i = argmaxi∈Pc g(i),

(cid:104)
1{ ˜PPP (t) = ˜PPP }

(cid:105)

E

(cid:54) (cid:88)

E [|Ai,j|] + E [|Bi,j|] + E [|Ci,j|]

j∈ ˜Pc\{i}

= O(1) + O(1) + 0

= O(1)

Assume that there exists c ∈ [ ˜d − 1], and (i, j) ∈ ˜Pc × ˜Pc+1, such that j (cid:31) i. By design of UniRank, each neighbor of
˜PPP takes one of both forms:

(cid:16) ˜P1, . . . , ˜Pc−1, ˜Pc ∪ ˜Pc+1, ˜Pc+2, . . . ˜P ˜d
(cid:17)
(cid:17)
(cid:16) ˜P1, . . . , ˜P ˜d−2, ˜P ˜d−1 ∪ {j}, ˜P ˜d \ {j}

.

,

1.

2.

Let PPP be such neighbor. In the ﬁrst scenario we denote i(PPP ) := argmini∈Pc g(i) and j(PPP ) := argmaxj∈Pc+1 g(j). In the
g(i), and j(PPP ) the item j. Finally, we denote N + the set of neighbors PPP
second scenario we denote i(PPP ) := argmini∈P ˜d−1
of ˜PPP such that j(PPP ) (cid:31) i(PPP ), and N − its complement { ˜PPP } ∪ N ( ˜PPP ) \ N +.
It is also worth noting that with current hypothesis on ˜PPP ,

• |N +| + |N −| =

(cid:12)
(cid:12)
(cid:12)N

(cid:16) ˜PPP

(cid:17)(cid:12)
(cid:12) + 1 (cid:54) L;
(cid:12)

• N + is non-empty (due to current assumption on ˜PPP );

• for each partition PPP ∈ N ( ˜PPP ), tPPP (t) = ˜ti(PPP ),j(PPP )(t);

• by design of the algorithm, at each iteration t such that ˜PPP (t) = ˜PPP , ˆsi(PPP ),j(PPP )(t) > 0 for each partition PPP ∈ N ( ˜PPP ) as

i(PPP ) is in a subset before j(PPP ) in ˜PPP .

To bound E

(cid:104)

(cid:105)
1{ ˜PPP (t) = ˜PPP }

, we use the decomposition {t ∈ [T ] : ˜PPP (t) = ˜PPP } = ∪PPP +∈N +APPP + ∪ B where

APPP + =

(cid:111)
(cid:110)
t : ˜PPP (t) = ˜PPP , tPPP +(t) (cid:62) ε˜t ˜PPP (t)

,

B =

(cid:111)
(cid:110)
t : ˜PPP (t) = ˜PPP , ∀PPP ∈ N +, tPPP +(t) < ε˜t ˜PPP (t)

,

and ε :=

1
(cid:17)(cid:12)
(cid:16) ˜PPP
(cid:12)
(cid:12) + 1

(cid:12)
(cid:12)
(cid:12)N

(cid:62) 1
L

.

(cid:104)

(cid:105)
1{ ˜PPP (t) = ˜PPP }

E

(cid:54) (cid:88)
PPP ∈N +

E [|APPP +|] + E [|B|] .

Hence,

Bound on E [|APPP +|] Let PPP ∈ N + be a permutation.
First, let’s t be in APPP +. Note that ˜∆i(PPP +),j(PPP +) < 0, as j(PPP +) (cid:31) i(PPP +). Therefore, as ˆsi(PPP +),j(PPP +)(t) > 0,
(cid:80)

(cid:26)

(cid:20)

, and thus E [|APPP +|] = E

1

t≥1

t ∈ APPP +, ˆsi(PPP +),j(PPP +)(t) >

˜∆i(PPP + ),j(PPP + )
2

(cid:27)(cid:21)
.

˜∆i(PPP + ),j(PPP +)
2

ˆsi(PPP +),j(PPP +)(t) >

Secondly, let’s decompose APPP + as APPP + ⊆ (cid:83)
s∈N Λ(s), with Λ(s) := {t ∈ APPP + : ˜t ˜PPP (t) = s}. |Λ(s)| (cid:54) 1 as ˜t ˜PPP (t) increases
for each t ∈ APPP +. Note that for each s ∈ N and n ∈ Λ(s), ti(PPP +),j(PPP +)(n) (cid:62) ˜ti(PPP +),j(PPP +)(n) = tPPP +(n) (cid:62) ε˜t ˜PPP (t) = εs.

• DPPP − :=
N +

• EPPP − :=

(cid:26)

Thus, as j(PPP +) (cid:31) i(PPP +), by Lemma E.4

UniRank: Unimodal Bandit Algorithm for Online Ranking

(cid:40)



E

(cid:88)



1

t≥1

t ∈ APPP +, ˆsi(PPP +),j(PPP +)(t) >

˜∆i(PPP +),j(PPP +)
2

(cid:41)

 = O(1).

Overall, E [|APPP +|] = E

(cid:20)

(cid:80)

t≥1

(cid:26)

1

t ∈ APPP +, ˆsi(PPP +),j(PPP +)(t) >

(cid:27)(cid:21)

˜∆i(PPP + ),j(PPP + )
2

= O (1) .

Bound on E [|B|] We ﬁrst split B in two parts: B = Bt0 ∪ BT
:= {t ∈
B : ˜t ˜PPP (t) > t0}, and t0 is chosen as small as possible to satisfy a constraint required later on in the proof. Namely,
, with t0 = 0 if N ( ˜PPP ) \ N + is empty. Note that t0
t0 = maxPPP −∈N ( ˜PPP )\N + inf
only depends on ˜δj(PPP −),i(PPP −) and ˜∆i(PPP −),j(PPP −) for PPP − ∈ N ( ˜PPP ) \ N +.
We also deﬁne

t0 , where Bt0 := {t ∈ B : ˜t ˜PPP (t) (cid:54) t0}, BT
t0

(cid:114) log(s)+3 log(log(s))
˜δj(PPP −),i(PPP − )(εs−1)

˜∆i(PPP −),j(PPP −)
8

s :

<

(cid:27)

(cid:26)

(cid:26)

t ∈ [T ] : ˜PPP (t) = ˜PPP , PPP (t) = PPP −, Tj(PPP −),i(PPP −)(t) <

˜δj(PPP − ),i(PPP −)
2

tj(PPP −),i(PPP −)(t)

(cid:27)

, for each PPP − ∈ N ( ˜PPP )\

t ∈ [T ] : ˜PPP (t) = ˜PPP , PPP (t) = PPP −, ˆsi(PPP −),j(PPP −)(t) <

(cid:27)

˜∆i(PPP − ),j(PPP − )
2

, for each PPP − ∈ N ( ˜PPP ) \ N +

• FPPP + :=

(cid:110)

t ∈ [T ] : ˜PPP (t) = ˜PPP ,

¯¯sj(PPP ),i(PPP )(t)+1
2

(cid:54) ˜∆j(PPP ),i(PPP )+1
2

(cid:111)

for each PPP + ∈ N +.

Let t ∈ BT

t0 . We have

˜t ˜PPP (t) =

(cid:88)

tPPP +(t) +

(cid:88)

tPPP − (t),

PPP +∈N +

PPP −∈N −

PPP +∈N + tPPP +(t) + (cid:80)

and by deﬁnition of B, tPPP +(t) < ε˜t ˜PPP (t) for each PPP + ∈ N +. So, there exists PPP − ∈ N − such that tPPP −(t) > ε˜t ˜PPP (t)
(otherwise, ˜t ˜PPP (t) = (cid:80)
Let’s elicit an iteration ψ(t) with speciﬁc properties. We denote s(cid:48) the ﬁrst iteration such that tPPP − (s(cid:48)) (cid:62) ε˜t ˜PPP (t). At this
iteration, tPPP −(s(cid:48)) = (cid:100)ε˜t ˜PPP (t)(cid:101), and tPPP − (s(cid:48)) = tPPP −(s(cid:48) − 1) + 1, meaning that ˜PPP (s(cid:48) − 1) = ˜PPP and PPP (s(cid:48) − 1) = PPP −, and
tPPP −(s(cid:48) − 1) = (cid:100)ε˜t ˜PPP (t)(cid:101) − 1. Therefore, the set {s ∈ [t] : ˜PPP (s) = ˜PPP , PPP (s) = PPP −, tPPP − (s) = (cid:100)ε˜t ˜PPP (t)(cid:101) − 1} is non-empty.
We deﬁne ψ(t) as the minimum on this set

PPP −∈N − tPPP − (t) < (|N +| + |N −|)ε˜t ˜PPP (t) = ˜t ˜PPP (t), which is absurd).

ψ(t) := min{s ∈ [t] : ˜PPP (s) = ˜PPP , PPP (s) = PPP −, tPPP − (s) = (cid:100)ε˜t ˜PPP (t)(cid:101) − 1}.

PPP −∈N − (DPPP − ∪ EPPP − ) ∪ (cid:83)

PPP +∈N + FPPP +. Assume that ψ(t) /∈ (cid:83)

PPP +∈N + FPPP +. The partition PPP − is in N −, so either PPP − = ˜PPP or PPP − ∈ N ( ˜PPP ) \ N +.

Let prove by contradiction that ψ(t) ∈ (cid:83)
EPPP − ) ∪ (cid:83)
˜∆j(PPP ),i(PPP )+1
The set N + is non-empty, so there exists a partition PPP + ∈ N +. As ψ(t) /∈ (cid:83)
,
2
where ˜∆j(PPP ),i(PPP ) > 0 as j(PPP ) (cid:31) i(PPP ). Thus ¯¯sj(PPP ),i(PPP )(ψ(t)) > 0 and PPP (ψ(t)) = PPP − cannot be ˜PPP by design of UniRank.
Therefore PPP − ∈ N ( ˜PPP ) \ N +.
Thus, either N ( ˜PPP ) \ N + is empty and we get a contradiction, or i(PPP −) and j(PPP −) are properly deﬁned, and, by design
of UniRank, ¯¯sj(PPP −),i(PPP −)(ψ(t)) (cid:62) 0. Moreover, since ˜PPP (ψ(t)) = ˜PPP − and ψ(t) /∈ DPPP − ∪ EPPP − , Tj(PPP −),i(PPP −)(ψ(t)) (cid:62)
˜δj(PPP − ),i(PPP −)
2

tj(PPP −),i(PPP −)(ψ(t)) and ˆsi(PPP −),j(PPP −)(ψ(t)) (cid:62)

¯¯sj(PPP ),i(PPP )(ψ(t))+1
2

˜∆i(PPP −),j(PPP −)
2

PPP −∈N − (DPPP − ∪

PPP +∈N + FPPP +,

>

.

Therefore,

Tj(PPP −),i(PPP −)(ψ(t)) (cid:62)

˜δj(PPP −),i(PPP −)
2

tj(PPP −),i(PPP −)(ψ(t)) (cid:62)

=

˜δj(PPP −),i(PPP −)
2

tPPP − (ψ(t)) =

˜δj(PPP −),i(PPP −)
2
˜δj(PPP −),i(PPP −)
2

˜tj(PPP −),i(PPP −)(ψ(t))

((cid:100)ε˜t ˜PPP (t)(cid:101) − 1) (cid:62)

˜δj(PPP −),i(PPP −)
2

(ε˜t ˜PPP (t) − 1)

UniRank: Unimodal Bandit Algorithm for Online Ranking

and by Pinsker’s inequality and the fact that ψ(t) (cid:54) t and ˜t ˜PPP (s) is non-decreasing in s, and ˜t ˜PPP (t) > t0,

(cid:62)

1
2

−¯¯sj(PPP −),i(PPP −)(ψ(t)) + 1
2

(cid:62)

=

−ˆsj(PPP −),i(PPP −)(ψ(t)) + 1
2

log(˜t ˜PPP (ψ(t))) + 3 log(log(˜t ˜PPP (ψ(t))))
2Tj(PPP −),i(PPP −)(ψ(t))

(cid:115)

−

(cid:115)

−

log(˜t ˜PPP (ψ(t))) + 3 log(log(˜t ˜PPP (ψ(t))))
2Tj(PPP −),i(PPP −)(ψ(t))

log(˜t ˜PPP (t)) + 3 log(log(˜t ˜PPP (t)))
˜δj(PPP −),i(PPP −)(ε˜t ˜PPP (t) − 1)

(cid:115)

+

−

ˆsi(PPP −),j(PPP −)(ψ(t)) + 1
2
˜∆i(PPP −),j(PPP −)
4
˜∆i(PPP −),j(PPP −)
4
˜∆i(PPP −),j(PPP −)
8

−

+

+

(cid:62) 1
2

(cid:62) 1
2
1
2

=

˜∆i(PPP −),j(PPP −)
8

which contradicts the fact that ˜∆i(PPP −),j(PPP −) > 0.
Overall, we always get a contradiction, so, for any t ∈ BT

⊆ (cid:83)

n∈(cid:83)

PPP −∈N − (DPPP − ∪EPPP − )∪(cid:83)

PPP +∈N + FPPP +. For any t in BT
t0

Hence, BT
t0
(cid:83)
and tPPP − (n + 1) = tPPP − (n) + 1. So |BT
t0
E [|B|] (cid:54) t0 + E (cid:2)|BT
t0

PPP −∈N − (DPPP − ∪ EPPP − ) ∪ (cid:83)
PPP +∈N + FPPP +.
∩ {t ∈ [T ] : ψ(t) = n}. Let n be in (cid:83)
PPP −∈N − (DPPP − ∪ EPPP − ) ∪
∩{t ∈ [T ] : ψ(t) = n}, there exists a partition PPP − ∈ N − such that tPPP − (n) = (cid:100)ε˜t ˜PPP (t)−1(cid:101),

t0 , ψ(t) ∈ (cid:83)
BT
t0

PPP +∈N + FPPP +

∩ {t ∈ [T ] : ψ(t) = n} | (cid:54) L and

|(cid:3) (cid:54) t0 + |N −|(E [|D|] + E [|E|] + E [|F |]).

It remains to upper-bound E [|D|], E [|E|], and E [|F |] to conclude the proof.

Bound on E [|DPPP − |] and E [|EPPP −|] Let PPP − ∈ N ( ˜PPP ) \ N + The upper-bound on E [|DPPP − |] and E [|EPPP −|] are obtained
through Lemma E.4. Let Λ :=
s∈N Λ(s), where
Λ(s) := {t ∈ Λ : ti(PPP −),j(PPP −)(t) = s}. |Λ(s)| (cid:54) 1 as ti(PPP −),j(PPP −)(t) increases for each t ∈ Λ. Note that for each s ∈ N
and n ∈ Λ(s), ti(PPP −),j(PPP −)(n) (cid:62) ti(PPP −),j(PPP −)(n) = s. Then, by Lemma E.4, as i(PPP −) (cid:31) j(PPP −)

t ∈ [T ] : ˜PPP (t) = ˜PPP , PPP (t) = PPP −(cid:111)
(cid:110)

and let use the decomposition Λ ⊆ (cid:83)

E [|DPPP − |] = E

(cid:34) T

(cid:88)

t=1

1{t ∈ Λ : Ti(PPP −),j(PPP −)(t) <

˜δi(PPP −),j(PPP −)
2

(cid:35)
ti(PPP −),j(PPP −)(t)}

= O(1)

and

E [|EPPP − |] = E

(cid:34) T

(cid:88)

t=1

1{t ∈ Λ : ˆsi(PPP −),j(PPP −)(t) <

˜∆i(PPP −),j(PPP −)
2

(cid:35)

}

= O(1).

Bound on E [|FPPP +|] By Lemma E.6, for each partition PPP + ∈ N +, E [|FPPP +|] = O(log(log(T ))).

(cid:104)

(cid:105)
1{ ˜PPP (t) = ˜PPP }

Overall E
O (log log T ), which concludes the proof.

(cid:54) |N +|O(1) + t0 + |N −| ((|N −| − 1)O(1) + (|N −| − 1)O(1) + |N +|O(log log T )) =

F.3. Final Step of the Proof of Theorem 5.1 (Upper-Bound on the Regret of UniRank Assuming a Total Order on

Items)

The proof of Theorem 5.1 from Lemmas F.1 and F.2 is mainly based on an appropriate decomposition of the regret.

Proof of Theorem 5.1. The upper-bound on the expected number of iterations at which UniRank explores while the leader
is the optimal partition is given by Lemma F.1.

The upper-bound on the expected number of iterations at which the leader is not the optimal partition is given by Lemma F.2.

UniRank: Unimodal Bandit Algorithm for Online Ranking

Let now consider the impact of these upper-bounds on the regret of UniRank.

Let remind that P ∗
aaa∗ := (1, 2, . . . , K).

c = {c} for c ∈ [K], d∗ = K + 1, and P ∗

K+1 = [L] \ [K]. Therefore, µ∗ = µa∗ = (cid:80)K

k=1 ρ(aaa∗, k), where

Let ﬁrst upper-bound the regret suffered at iteration t while the the leader is the optimal partition:

µaaa(t) | ˜PPP (t) = PPP ∗(cid:105)
(cid:104)

R∗

t = µ∗ − Eaaa(t)
K
(cid:88)

=

ρ(aaa∗, k) − Eaaa(t)

ρ(aaa(t), k) | ˜PPP (t) = PPP ∗(cid:105)
(cid:104)

k=1

K
(cid:88)

k=1

=

(cid:16)

P

ak(t) = k | ˜PPP (t) = PPP ∗(cid:17) (cid:16)

ρ(aaa∗, k) − Eaaa(t)

ρ(aaa(t), k) | ak(t) = k, ˜PPP (t) = PPP ∗(cid:105)(cid:17)
(cid:104)

K
(cid:88)

(cid:16)

P

+

ak−1(t) = k | ˜PPP (t) = PPP ∗(cid:17) (cid:16)

ρ(aaa∗, k − 1) − Eaaa(t)

(cid:104)

ρ(aaa(t), k − 1) | ak−1(t) = k, ˜PPP (t) = PPP ∗(cid:105)(cid:17)

k=2

K
(cid:88)

k=2

(cid:16)

P

ak(t) = k − 1 | ˜PPP (t) = PPP ∗(cid:17) (cid:16)

ρ(aaa∗, k) − Eaaa(t)

(cid:104)

ρ(aaa(t), k) | ak(t) = k − 1, ˜PPP (t) = PPP ∗(cid:105)(cid:17)

L
(cid:88)

(cid:16)

P

(cid:96)=K+1

aK(t) = (cid:96) | ˜PPP (t) = PPP ∗(cid:17) (cid:16)

ρ(aaa∗, k) − Eaaa(t)

(cid:104)

ρ(aaa(t), K) | aK(t) = (cid:96), ˜PPP (t) = PPP ∗(cid:105)(cid:17)

+

+

Let’s focus on the ﬁrst right hand-side term. As the probability of click at position k only depends on the set of items in
positions 1 to k − 1, and as under the condition ak(t) = k ∧ ˜PPP (t) = PPP ∗, aaa(t) and aaa∗ have the same set of items in positions
1 to k − 1, ρ(aaa∗, k) = Eaaa(t)

ρ(aaa(t), k) | ak(t) = k, ˜PPP (t) = PPP ∗(cid:105)

. Hence that term is equal to 0.

(cid:104)

Let now take a look at the second term. By design of UniRank, as ak−1(t) = k ∧ ˜PPP (t) = PPP ∗, there exists c(cid:48) such that
Pc(t) = {k − 1, k}, and

P

(cid:16)

ak−1(t) = k | ˜PPP (t) = PPP ∗(cid:17)

= P

(cid:16)

=

P

1
2

ak−1(t) = k, Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)
Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)
(cid:16)

.

Similarly, the third term corresponds to the existence of c(cid:48) such that Pc(t) = {k − 1, k}, and

P

(cid:16)

ak(t) = k − 1 | ˜PPP (t) = PPP ∗(cid:17)

=

1
2

P

(cid:16)

Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)

.

By summing both terms, we have to handle

1
2

P

(cid:16)

Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)

·

(cid:16)
ρ(aaa∗, k − 1) + ρ(aaa∗, k) − Eaaa(t)

ρ(aaa(t), k − 1) + ρ(aaa(t), k) | ak−1(t) = k, ak(t) = k − 1, ˜PPP (t) = PPP ∗(cid:105)(cid:17)
(cid:104)

,

which is equal to 1
2

P

(cid:16)

Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)

∆k, where

∆k := ρ(aaa∗, k − 1) + ρ(aaa∗, k) − ρ((k − 1, k) ◦ aaa∗, k − 1) − ρ((k − 1, k) ◦ aaa∗, k),

as the probability of click at any position k(cid:48) only depends on the set of items in positions 1 to k(cid:48) − 1.

Finally, following the same argumentation, the last term is equal to 1
2
ρ(aaa∗, K) − ρ((K, (cid:96)) ◦ aaa∗, K).

P

(cid:16)

Pc(t) = {K, (cid:96)} | ˜PPP (t) = PPP ∗(cid:17)

∆(cid:96), where ∆(cid:96) :=

Overall

UniRank: Unimodal Bandit Algorithm for Online Ranking

R∗

t =

K
(cid:88)

k=2

1
2

P

(cid:16)

Pc(t) = {k − 1, k} | ˜PPP (t) = PPP ∗(cid:17)

∆k

L
(cid:88)

+

(cid:96)=K+1

1
2

P

(cid:16)

Pc(t) = {K, (cid:96)} | ˜PPP (t) = PPP ∗(cid:17)

∆(cid:96)

=

L
(cid:88)

k=2

1
2

P

(cid:16)

Pc(t) = {min(k − 1, K), k} | ˜PPP (t) = PPP ∗(cid:17)

∆k.

Let ﬁnally upper-bound the overall regret.

R(T ) =

=

T
(cid:88)

t=1

T
(cid:88)

t=1

µ∗ − Eaaa(t)

(cid:2)µaaa(t)

(cid:3)

P

(cid:16) ˜PPP (t) (cid:54)= PPP ∗(cid:17) (cid:16)

µ∗ − Eaaa(t)

(cid:104)

µaaa(t) | ˜PPP (t) (cid:54)= PPP ∗(cid:105)(cid:17)

T
(cid:88)

P

+

t=1

(cid:16) ˜PPP (t) = PPP ∗(cid:17) (cid:16)

µ∗ − Eaaa(t)

µaaa(t) | ˜PPP (t) = PPP ∗(cid:105)(cid:17)
(cid:104)

(cid:54)

T
(cid:88)

t=1

(cid:16) ˜PPP (t) (cid:54)= PPP ∗(cid:17)

P

K

T
(cid:88)

(cid:16) ˜PPP (t) = PPP ∗(cid:17) L

(cid:88)

P

+

t=1
(cid:54) O (log log T )

k=2

1
2

P

(cid:16)

Pc(t) = {min(k − 1, K), k} | ˜PPP (t) = PPP ∗(cid:17)

∆k

T
(cid:88)

L
(cid:88)

+

t=1

k=2

1
2

P

(cid:17)
(cid:16) ˜PPP (t) = PPP ∗, Pc(t) = {min(k − 1, K), k, }

∆k

= O (log log T )

T
(cid:88)

P

(cid:17)
(cid:16) ˜PPP (t) = PPP ∗, Pc(t) = {min(k − 1, K), k, }

L
(cid:88)

+

∆k
2

t=1
k=2
(cid:54) O (log log T )
(cid:32)
L
(cid:88)

+

∆k
2

k=2

16
˜∆2
k

˜δ∗
k

L
(cid:88)

k=2

8∆k
˜δ∗
˜∆2
k
k
(cid:18) L
∆

(cid:19)

,

log T

=

log T + O (log log T )

log T + O (log log T )

(cid:33)

= O

where for any index k (cid:62) 2

˜∆k := ˜∆min(k−1,K),k

and

∆ := min

k∈{2,...,K}

˜δ∗
˜∆2
k
k
8∆k

,

which concludes the proof.

UniRank: Unimodal Bandit Algorithm for Online Ranking

G. UniRank’s Theoretical Results While Facing State-of-the-Art Click Models

Here, we prove Corollaries 5.2 and 5.3 and then discuss the relationship between our upper-bounds and the known lower
bounds.

G.1. Proof of Corollary 5.2 (Upper-Bound on the Regret of UniRank when Facing CM∗ Click Model)
Corollary G.1 is a more precise version of Corollary 5.2. Its proof consists in identifying the gaps ˜δ∗
is the index of an item.
Corollary G.1 (Facing CM∗ click model). Under the hypotheses of Theorem 5.1, if the user follows CM with probability θi
to click on item i when it is observed, then for any index k (cid:62) 2,

k, ˜∆k, and ∆k, where k

˜δ∗
k = (θk−1 + θk − θk−1θk)

k−2
(cid:89)

(cid:96)=1

(1 − θ(cid:96))

(θK + θk)

K−1
(cid:89)

(1 − θ(cid:96))

1
2

˜δ∗
k =

˜∆k (cid:62)

(cid:96)=1
θmin(K,k−1) − θk
θmin(K,k−1) + θk

,

∆k = 0

∆k = (θK − θk)

K−1
(cid:89)

(cid:96)=1

(1 − θ(cid:96))

Hence, UniRank fulﬁlls

if k (cid:54) K,

if k (cid:62) K + 1,

if k (cid:54) K,

if k (cid:62) K + 1.

R(T ) (cid:54)

L
(cid:88)

k=K+1
(cid:18)

16

θK + θk
θK − θk

log T + O (log log T )

= O

(L − K)

θK + θK+1
θK − θK+1

(cid:19)

log T

.

Proof of Corollary G.1. Values ˜δ∗
Let us prove the lower-bound on ˜∆k. Let i and j be two items such that i (cid:54)= j. Let aaa be a recommendation such that
P(ci(t) (cid:54)= cj(t) | aaa(t) = aaa) > 0.

k and ∆k derive from a straightforward computation given CM model.

Without loss of generality, assume i appears in aaa in position k, and if j appears in aaa, it is in a position (cid:96) > k. Then

˜∆i,j(aaa) =

A 1+B

2 (θi − θj)
2 (θi + θj) − ABθiθj

A 1+B

(cid:62) θi − θj
θi + θj

,

c=1 (1 − θac ) and B := (cid:81)(cid:96)−1

with A := (cid:81)k−1
Hence the lower-bounding values for ˜∆k, by noting that the term A is lower-bounded by (cid:81)K−1
Regarding the last formula in Lemma G.1, it derives from the fact that θK +θk
θK −θk
k = K + 1.

c=k+1 (1 − θac) if j appears in aaa and 0 otherwise.

(cid:96)=1 (1 − θ(cid:96)) .

is maximized when θk is maximized, meaning

G.2. Proof of Corollary 5.3 (Upper-Bound on the Regret of UniRank when Facing PBM∗ Click Model)
Corollary G.2 is a more precise version of Corollary 5.3. Its proof consists in identifying the gaps ˜δ∗
is the index of an item.
Corollary G.2 (Facing PBM∗ click model). Under the hypotheses of Theorem 5.1, if the user follows PBM with the
probability θi of clicking on item i when it is observed and the probability κk of observing the position k, then for any index

k, ˜∆k, and ∆k, where k

k (cid:62) 2,

UniRank: Unimodal Bandit Algorithm for Online Ranking

(θk−1 + θk) (κk−1 + κk) − 2θk−1θkκk−1κk

˜δ∗
k =

˜δ∗
k =

(θK + θk) κK

1
2
1
2
θmin(K,k−1) − θk
θmin(K,k−1) + θk
∆k = (θk−1 − θk) (κk−1 − κk)
∆k = (θK − θk) κK

˜∆k (cid:62)

,

if k (cid:54) K,

if k (cid:62) K + 1,

if k (cid:54) K,
if k (cid:62) K + 1.

Hence, UniRank fulﬁlls

R(T ) (cid:54)

K
(cid:88)

k=2

8(κk−1 − κk)(θk−1 + θk)2
˜δ∗
k(θk−1 − θk)
(cid:19)

= O

log T

,

(cid:18) L
∆

log T +

L
(cid:88)

k=K+1

16

θK + θk
θK − θk

log T + O (log log T )

where ∆ := min{mink∈{2,...,K}

˜δ∗
k(θk−1−θk)

(κk−1−κk)(θk−1+θk)2 , mink∈{K+1,...,L}

θK −θk
θK +θk

}.

Proof of Corollary G.2. Values ˜δ∗
Let us prove the lower-bound on ˜∆k. Let i and j be two items such that i (cid:54)= j. Let aaa be a recommendation such that
P(ci(t) (cid:54)= cj(t) | aaa(t) = aaa) > 0.

k and ∆k derive from a straightforward computation given PBM model.

If both i and j appear in aaa, denote k < (cid:96) these positions. Then

˜∆i,j(aaa) =

1
2 (κk + κ(cid:96))(θi − θj)
1
2 (κk + κ(cid:96))(θi + θj) − 2κkκ(cid:96)θiθj

(cid:62) θi − θj
θi + θj

.

If only one of both items i and j appears in aaa then ˜∆i,j(aaa) = θi−θj
θi+θj

.

Hence for any index k (cid:62) 2, ˜∆k (cid:62) θmin(K,k−1)−θk
θmin(K,k−1)+θk

.

