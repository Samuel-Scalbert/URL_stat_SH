Song Lyrics Summarization Inspired by Audio
Thumbnailing
Michael Fell, Elena Cabrio, Fabien Gandon, Alain Giboin

To cite this version:

Michael Fell, Elena Cabrio, Fabien Gandon, Alain Giboin. Song Lyrics Summarization Inspired by
Audio Thumbnailing. RANLP 2019 - Recent Advances in Natural Language Processing, Sep 2019,
Varna, Bulgaria. ￿hal-02281138￿

HAL Id: hal-02281138

https://hal.science/hal-02281138

Submitted on 8 Sep 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Song Lyrics Summarization Inspired by Audio Thumbnailing

Michael Fell, Elena Cabrio, Fabien Gandon, Alain Giboin
Universit´e Cˆote d’Azur, CNRS, Inria, I3S, France
{firstname.lastname}@inria.fr

Abstract

Given the peculiar structure of songs, applying
generic text summarization methods to lyrics
can lead to the generation of highly redundant
In this paper, we pro-
and incoherent text.
pose to enhance state-of-the-art text summa-
rization approaches with a method inspired by
audio thumbnailing. Instead of searching for
the thumbnail clues in the audio of the song,
we identify equivalent clues in the lyrics. We
then show how these summaries that take into
account the audio nature of the lyrics outper-
form the generic methods according to both an
automatic evaluation and human judgments.

1

Introduction

Automatic text summarization is the task of pro-
ducing a concise and ﬂuent summary while pre-
serving key information content and overall mean-
ing of a text (Allahyari et al., 2017). Numerous ap-
proaches have been developed to address this task
and applied widely in various domains including
news articles (Cheng and Lapata, 2016), scientiﬁc
papers (Mei and Zhai, 2008), web content as blogs
(Hu et al., 2007), customer reviews (Pecar, 2018)
and social media messages (He and Duan, 2018).
Just as we may need to summarize a story, we
may also need to summarize song lyrics, for in-
stance to produce adequate snippets for a search
engine dedicated to an online song collection or
for music digital libraries. From a linguistic point
of view however, lyrics are a very peculiar genre
of document and generic summarization methods
may not be appropriate when the input for summa-
rization comes from a speciﬁc domain or type of
genre as songs are (Nenkova et al., 2011). Com-
pared to news documents, for instance, lyrics have
a very different structure. Given the repeating
the segmentation
forms, peculiar structure (e.g.
into verse, chorus, etc.) and other unique charac-
teristics of song lyrics, we need the summariza-

tion algorithms to take advantage of these addi-
tional elements to more accurately identify rele-
vant information in song lyrics. But just as such
characteristics enable the exploration of new ap-
proaches, other characteristics make the applica-
tion of summarization algorithms very challeng-
ing, as the presence of repeated lines, the discourse
structure that strongly depends on the interrelation
of music and words in the melody composition,
the heterogeneity of musical genres each featuring
peculiar styles and wording (Brackett, 1995), and
simply the fact that not all songs tell a story.

In this direction, this paper focuses on the fol-
lowing research questions: What is the impact of
the context in summarizing song lyrics?. This
question is broken down into two sub questions: 1)
How do generic text summarization methods per-
form over lyrics? and 2) Can such peculiar con-
text be leveraged to identify relevant sentences to
improve song text summarization? To answer our
research questions, we experiment with generic
unsupervised state-of-the-art text summarization
methods (i.e. TextRank, and a topic distribution
based method) to perform lyrics summarization,
and show that adding contextual information helps
such models to produce better summaries. Specif-
ically, we enhance text summarization approaches
with a method inspired by audio thumbnailing
techniques, that leverages the repetitive structure
of song texts to improve summaries. We show how
summaries that take into account the audio nature
of the lyrics outperform the generic methods ac-
cording to both an automatic evaluation over 50k
lyrics, and judgments of 26 human subjects.

In the following, Section 2 reports on related
work. Section 3 presents the lyrics summarization
task and the proposed methods. Sections 4 and 5
report on the experiments and on the evaluation,
respectively. Section 6 concludes the paper.

2 Summarization Methods

This section reports on the related work on both
text and audio summarization methods.

2.1 Text Summarization

In the literature, there are two different families
of approaches for automatic text summarization:
extraction and abstraction (Allahyari et al., 2017).
Extractive summarization methods identify impor-
tant elements of the text and generate them verba-
tim (they depend only on extraction of sentences
or words from the original text). In contrast, ab-
stractive summarization methods interpret and ex-
amine the text to generate a new shorter text that
conveys the most critical information from the
original text. Even though summaries created by
humans are usually not extractive, most of the
summarization research has focused on extractive
methods. Purely extractive summaries often give
better results (Nallapati et al., 2016), due to the
fact that latter methods cope with more complex
problems such as semantic representation, infer-
ence and natural language generation. Existing ab-
stractive summarizers often rely on an extractive
pre-processing component to produce the abstract
of the text (Berg-Kirkpatrick et al., 2011; Knight
and Marcu, 2000). Consequently, in this paper we
focus on extractive summarization methods, also
given the fact that lyrics i) strongly use ﬁgurative
language which makes abstractive summarization
even more challenging; and ii) the choice of the
words by the composer may also have an impor-
tance for capturing the style of the song.

In the following, we focus on unsupervised
methods for text summarization, the ones targeted
in our study (no available gold-standard of human-
produced summaries of song texts exists). Most
methods have in common the process for sum-
mary generation: given a text, the importance of
each sentence of that text is determined. Then, the
sentences with highest importance are selected to
form a summary. The ways different summarizers
determine the importance of each sentence may
differ: Statistics-based summarizers extract indi-
cator features from each sentence, e.g. (Fattah and
Ren, 2009) use among others the sentence position
and length and named entities as features. Topic-
based summarizers aim to represent each sentence
by its underlying topics. For instance, (Hennig,
2009) apply Probabilistic Latent Semantic Anal-
ysis, while Latent Dirichlet Allocation is used in

(Arora and Ravindran, 2008) to model each sen-
tence’s distribution over latent topics. Another
type of summarization methods is graph-based
summarizers. Three of the most popular graph-
based summarizers are TextRank (Mihalcea and
Tarau, 2004), LexRank (Erkan and Radev, 2004),
and (Parveen et al., 2015). These methods work
by constructing a graph whose nodes are sentences
and whose graph edge weights are sentence sim-
ilarities. Then, the sentences that are central to
the graph are found by computing the PageRank
(Page et al., 1999). Contrarily to all previously
described methods, systems using supervised ma-
chine learning form another type of summarizers.
For instance, (Fattah, 2014) treats extractive sum-
marization as a binary classiﬁcation task, where
they extract indicator features from sentences of
gold summaries and learn to detect the sentences
that should be included in a summary.

Context-Speciﬁc Summarization.
If speciﬁc
knowledge about the application scenario or the
domain of
is available,
the summarized text
generic summarization methods can be adapted to
take into account the prior information. In query-
based summarization (Otterbacher et al., 2005;
Wang et al., 2016), the user’s query is taken into
account when generating a summary. Summa-
rization of a scientiﬁc paper can be improved by
considering the citations of it, as in (Delort et al.,
2003). However, to the best of our knowledge no
summarization methods have been proposed for
the domain of song texts. In this paper we present
a summarization method that uses prior knowl-
edge about the text it summarizes to help generic
summarizers generate better summaries.

Evaluation Criteria and Methods. Summaries
should i) contain the most important information
from input documents, ii) not contain redundant
information, iii) be readable, hence they should
be grammatical and coherent (Parveen and Strube,
2015). While a multitude of methods to iden-
tify important sentences has been described above,
several approaches aim to make summaries less
redundant and more coherent. The simplest way
to evaluate summaries is to let humans assess
the quality, but this is extremely expensive. The
factors that humans must consider when giving
scores to each candidate summary are grammati-
cality, non redundancy, integration of most impor-
tant pieces of information, structure and coherence

(Saggion and Poibeau, 2013). The more common
way is to let humans generate possibly multiple
summaries for a text and then automatically assess
how close a machine-made summary is to the hu-
man gold summaries computing ROUGE scores
(Lin, 2004), which boils down to measuring n-
gram overlaps between gold summaries and auto-
matic summary. More recently there have been
attempts to rate summaries automatically with-
out the need for gold summaries (Nenkova et al.,
2011). The key idea is that a summary should be
similar to the original text in regard to characteris-
tic criteria as the word distribution. (Mackie et al.,
2014) ﬁnd that topic words are a suitable metric to
automatically evaluate micro blog summaries.

2.2 Audio Summarization

Lyrics are texts that accompany music. Therefore,
it is worthwhile to see if methods in audio sum-
marization can be transferred to lyrics summariza-
tion. In audio summarization the goal is to ﬁnd the
most representative parts in a song, in Pop songs
those are usually the chorus and the bridge, in in-
strumental music the main theme. The task of cre-
ating short audio summaries is also known as au-
dio thumbnailing (Bartsch and Wakeﬁeld, 2005;
Chai and Vercoe, 2003; Levy et al., 2006), as the
goal is to produce a short representation of the
music that ﬁts onto a thumbnail, but still covers
the most representative parts of it. In a recent ap-
proach of audio thumbnailing (Jiang and M¨uller,
2015), the authors generate a Double Thumbnail
from a musical piece by ﬁnding the two most rep-
resentative parts in it. For this, they search for
candidate musical segments in an a priori unseg-
mented song. Candidate musical segments are de-
ﬁned as sequences of music that more or less ex-
actly repeat themselves. The representativeness of
each candidate segment to the whole piece is then
estimated by their ﬁtness metric. They deﬁne the
ﬁtness of a segment as a trade-off between how ex-
actly a part is repeated and how much of the whole
piece is covered by all repetitions of that segment.
Then, the audio segments along with their ﬁtness
allow them to create an audio double thumbnail
consisting of the two ﬁttest audio segments.

3 Lyrics Summarization

Song texts are arranged in segments and lines. For
instance the song text depicted in Figure 1 con-
sists of 8 segments and 38 lines. Given a song text

S consisting of n lines of text, S = (x1, ..., xn),
we deﬁne the task of extractive lyrics summariza-
tion as the task of producing a concise summary
sum of the song text, consisting of a subset of the
original text lines: sum(S) ⊆ S, where usually
|sum(S)| << |S|. We deﬁne the goal of a sum-
mary as to preserve key information and the over-
all meaning of a song text. To address this task, we
apply the following methods from the literature:
the popular graph-based summarizer TextRank;
an adaptation of a topic-based method (TopSum).
Moreover, we introduce a method inspired by au-
dio thumbnailing (which we dub Lyrics Thumb-
nail) which aims at creating a summary from the
most representative parts of the original song text.
While for TextRank we rely on the off-the-shelf
implementation of (Barrios et al., 2016), in the fol-
lowing we describe the other two methods.

3.1 TopSum

We implement a simple topic-based summariza-
tion model
that aims to construct a summary
whose topic distribution is as similar as possible
to that of the original text. Following (Kleedorfer
et al., 2008), we train a topic model by factorizing
a tf-idf-weighted term-document matrix of a song
text corpus (see Section 4.2) using non-negative
matrix factorization into a term-topic and a topic-
document matrix. Given the learnt term-topic ma-
trix, we compute a topic vector t for each new doc-
ument (song text). In order to treat t as a (pseudo-
) probability distribution over latent topics ti, we
normalize t by applying λt.t/(cid:80)
ti∈t ti to it. Given
the distributions over latent topics for each song
text, we then incrementally construct a summary
by greedily adding one line from the original text
at a time (same mechanism as in KLSum algo-
rithm in (Haghighi and Vanderwende, 2009)); that
line x∗ of the original text that minimizes the dis-
tance between the topic distribution tS of the orig-
inal text S and the topic distribution of the incre-
mental summary sum(S):

x∗ = argmin

x∈(S\sum(S))

{W (tS, tsum(S)+x)}

W is the Wasserstein distance (Villani, 2008)
and is used to measure the distance between two
probability distributions (an alternative to Jensen-
Shannon divergence (Louis and Nenkova, 2013)).

Figure 1: Song text of “Let’s start a band” by Amy MacDonald along with two example summaries.

3.2 Lyrics Thumbnail

Inspired by (Jiang and M¨uller, 2015), we transfer
their ﬁtness measure for audio segments to com-
pute the ﬁtness of lyrics segments. Analog to an
audio thumbnail, we deﬁne a Lyrics Thumbnail as
the most representative and repetitive part of the
song text. Consequently, it usually consists of (a
part of) the chorus. In our corpus the segments are
annotated (as double line breaks in the lyrics), so
unlike in audio thumbnailing, we do not have to
induce segments, but rather measure their ﬁtness.
In the following, we describe the ﬁtness measure
for lyrics segments and how we use this to produce
a summary of the lyrics.

Lyrics Fitness Given a segmented song text
S = (S1, ..., Sm) consisting of text segments Si,
where each Si consists of |Si| text lines, we clus-
ter the Si into partitions of similar segments. For
instance, the lyrics in Figure 1 consists of 8 seg-
ments and 38 lines and the cluster of chorus con-
sists of {S5, S6, S7}. The ﬁtness F it of the seg-
ment cluster C ⊆ S is deﬁned through the preci-
sion pr of the cluster and the coverage co of the
cluster. pr describes how similar the segments in
C are to each other while co is the relative amount
of lyrics lines covered by C:

pr(C) = (

(cid:88)

1)−1 ·

(cid:88)

sim(Si, Sj)

Si,Sj ∈C
i<j

Si,Sj ∈C
i<j

co(C) = (

(cid:88)

|Si|)−1 ·

Si∈S

(cid:88)

Si∈C

|Si|

where sim is a normalized similarity measure be-
tween text segments. F it is the harmonic mean

between pr and co. The ﬁtness of a segment Si
is deﬁned as the ﬁtness of the cluster to which Si
belongs:

∀Si ∈ C : F it(Si) = F it(C) = 2

pr(C) · co(C)
pr(C) + co(C)

For lyrics segments without repetition the ﬁt-
ness is deﬁned as zero. Based on the ﬁtness F it
for segments, we deﬁne a ﬁtness measure for a text
line x. This allows us to compute the ﬁtness of ar-
bitrary summaries (with no or unknown segmen-
tation). If the text line x occurs fi(x) times in text
segment Si, then its line ﬁtness f it is deﬁned as:

f it(x) = (

(cid:88)

fi(x))−1 ·

Si∈S

(cid:88)

Si∈S

fi(x) · F it(Si)

Fitness-Based Summary Analog to (Jiang and
M¨uller, 2015)’s audio thumbnails, we create
ﬁtness-based summaries for a song text. A Lyrics
Double Thumbnail consists of two segments: one
from the ﬁttest segment cluster (usually the cho-
rus), and one from the second ﬁttest segment clus-
ter (usually the bridge).1 If the second ﬁttest clus-
ter has a ﬁtness of 0, we generate a Lyrics Sin-
gle Thumbnail solely from the ﬁttest cluster (usu-
ally the chorus). If the thumbnail generated has a
length of k lines and we want to produce a sum-
mary of p < k lines, we select the p lines in
the middle of the thumbnail following (Chai and
Vercoe, 2003)’s “Section-transition Strategy” that

1We pick the ﬁrst occurring representative of the segment
cluster. Which segment to pick from the cluster is a potential
question for future work.

they ﬁnd to capture the “hook” of the music more
likely.2

4 Experimental Setting

We now describe the WASABI dataset of song
lyrics (Section 4.1), and the tested conﬁgurations
of the summarization methods (Section 4.2).

4.1 Dataset

From the WASABI corpus (Meseguer-Brocal
et al., 2017) we select a subset of 190k unique song
texts with available genre information. As the cor-
pus has spurious genres (416 different ones), we
focus on the 10 most frequent ones in order to
evaluate our methods dependent on the genre. We
add 2 additional genres from the underrepresented
Rap ﬁeld (Southern Hip Hop and Gangsta Rap).
The dataset contains 95k song lyrics.

To deﬁne the length of sum(S) (see Section
3), we rely on (Bartsch and Wakeﬁeld, 2005) that
recommend to create audio thumbnails of the me-
dian length of the chorus on the whole corpus.
We therefore estimate the median chorus length on
our corpus by computing a Lyrics Single Thumb-
nail on each text, and we ﬁnd the median chorus
length to be 4 lines. Hence, we decide to gener-
ate summaries of such length for all lyrics and all
summarization models to exclude the length bias
in the methods comparison3. As the length of the
lyrics thumbnail is lower-bounded by the length
of the chorus in the song text, we keep only those
lyrics with an estimated chorus length of at least 4.
The ﬁnal corpus of 12 genres consists of 50k lyrics
with the following genre distribution: Rock: 8.4k,
Country: 8.3k, Alternative Rock: 6.6k, Pop: 6.9k,
R&B: 5.2k, Indie Rock: 4.4k, Hip Hop: 4.2k,
Hard Rock: 2.4k, Punk Rock: 2k, Folk: 1.7k,
Southern Hip Hop: 281, Gangsta Rap: 185.

4.2 Models and Conﬁgurations

We create summaries using the three summariza-
tion methods described in Section 3, i.e. a graph-
based (TextRank), a topic-based (TopSum), and
ﬁtness-based (Lyrics Thumbnail) method, plus
two additional combined models (described be-
low). While the Lyrics Thumbnail is generated
from the full segment structure of the lyrics in-
cluding its duplicate lines, all other models are fed

2They also experiment with other methods to create a

thumbnail, such as section initial or section ending.

3We leave the study of other measures to estimate the

summary length to future work.

with unique text lines as input (i.e.
rendundant
lines are deleted). This is done to produce less re-
dundant summaries, given that for instance, Tex-
tRank scores each duplicate line the same, hence
it may create summaries with all identical lines.
TopSum can suffer from a similar shortcoming: if
there is a duplicate line close to the ideal topic dis-
tribution, adding that line again will let the incre-
mental summary under construction stay close to
the ideal topic distribution. All models were in-
structed to produce summaries of 4 lines, as this
is the estimated median chorus length in our cor-
pus (see Section 4.1). The summary lines were
arranged in the same order they appear in the orig-
inal text.4 We use the TextRank implementation5
of (Barrios et al., 2016) without removing stop
words (lyrics lines in input can be quite short,
therefore we avoid losing all content of the line if
removing stop words). The topic model for Top-
Sum is built using non-negative matrix factoriza-
tion with scikit-learn6 (Pedregosa et al., 2011) for
30 topics on the full corpus of 190k lyrics.7 For
the topical distance, we only consider the distance
between the 3 most relevant topics in the original
text, following the intuition that one song text usu-
ally covers only a small amount of topics. The
Lyrics Thumbnail is computed using String-based
distance between text segments to facilitate clus-
tering. This similarity has been shown in (Watan-
abe et al., 2016) to indicate segment borders suc-
In our implementation, segments are
cessfully.
clustered using the DBSCAN (Ester et al., 1996)
algorithm.8 We also produce two summaries by
combining TextRank + TopSum and TextRank +
TopSum + Lyrics Thumbnail, to test if summaries
can beneﬁt from the complementary perspectives
the three different summarization methods take.

Model Combination For any lyrics line, we can
obtain a score from each of the applied methods.
TextRank provides a score for each line, TopSum
provides a distance between the topic distributions
of an incremental summary and the original text,
and f it provides the ﬁtness of each line. We treat
our summarization methods as blackboxes and use
a simple method to combine the scores the dif-
ferent methods provide for each line. Given the

4In case of repeated parts, the ﬁrst position of each line

was used as original position.

5https://github.com/summanlp/textrank
6https://scikit-learn.org
7loss=’kullback-leibler’
8eps=0.3, min samples=2

original text separated into lines S = (x1, ..., xn),
a summary is constructed by greedily adding one
line x∗ at a time to the incremental summary
sum(S) ⊆ S such that the sum of normalized
ranks of all scores is minimal:

x∗ = argmin

(cid:91)

(cid:88)

{

x

A

RA(x)}

The

(S \ sum(S))

and A ∈
∈
Here x
{TextRank, TopSum, ﬁt}.
normalized
rank RA(x) of the score that method A assigns to
line x is computed as follows: ﬁrst, the highest
scores9 are assigned rank 0, the second highest
scores get rank 1, and so forth. Then the ranks are
linearly scaled to the [0,1] interval, so each sum
of ranks (cid:80)

A RA(x) is in [0,3].

Model Nomenclature For abbreviation, we call
the TextRank model henceforth Mr,
the Top-
Sum model Ms, the ﬁtness-based summarizer Mf ,
model combinations Mrs and Mrsf , respectively.

5 Evaluation

We evaluate the quality of the produced lyrics
summary both soliciting human judgments on the
goodness and utility of a given summary (Section
5.1), and through an automatic evaluation of the
summarization methods (Section 5.2) to provide a
comprehensive evaluation.

5.1 Human Evaluation

We performed human evaluation of the different
summarization methods introduced before by ask-
ing participants to rate the different summaries
presented to them by specifying their agreement /
disagreement according to the following standard
criteria (Parveen and Strube, 2015):

Informativeness: The summary contains the

main points of the original song text.

Non-redundancy: The summary does not con-

tain duplicate or redundant information.

Coherence: The summary is ﬂuent to read and

grammatically correct.
Plus one additional criterion coming from our def-
inition of the lyrics summarization task:

Meaning: The summary preserves the meaning

of the original song text.

An experimental psychologist expert in Human
Computer Interaction advised us in deﬁning the

9In the case of topical distance, a “higher score” means a

lower value.

questionnaire and setting up the experiment. 26
participants - 12 nationalities, 18 men, 8 women,
aged from 21 to 59 - were taking a questionnaire
(Google Forms), consisting of rating 30 items with
respect to the criteria deﬁned before on a Likert
scale from 1 (low) to 5 (high). Each participant
was presented with 5 different summaries - each
produced by one of the previously described sum-
marization models - for 6 different song texts. Par-
ticipants were given example ratings for the dif-
ferent criteria in order to familiarize them with the
procedure. Then, for each song text, the original
song text along with its 5 summaries were pre-
sented in random order and had to be rated ac-
cording to the above criteria. For the criterion of
Meaning, we asked participants to give a short ex-
planation in free text for their score. The selected
6 song texts10 have a minimum and a median cho-
rus length of 4 lines and are from different genres,
i.e. Pop/Rock (4), Folk (1) and Rap (1), similar
to our corpus genre distribution. Song texts were
selected from different lengths (18-63 lines), gen-
ders of singer (3 male, 3 female), topics (family,
life, drugs, relationship, depression), and mood
(depressive, angry, hopeful, optimistic, energetic).
The artist name and song title were not shown to
the participants.

Results Figure 2 shows the ratings obtained for
each criterion. We examine the signiﬁcant dif-
ferences between the models performances by
performing a paired two-tailed t-test. The sig-
niﬁcance levels are: 0.05∗, 0.01∗∗, 0.001∗∗∗, and
n.s. First, Informativeness and Meaning are rated
higher∗∗ for the combined model Mrs compared
to the single models Mr and Ms. Combining
all three models improves the summaries further:
both for Informativeness and Meaning the model
Mrsf is rated higher∗∗∗ than Mrs. Further, sum-
maries created by Mrsf are rated higher∗∗∗ in Co-
herence than summaries from any other model -
except from Mf (n.s. difference). Summaries
are rated on the same level (n.s. differences) for
Non-redundancy in all but the Mr and Mf sum-
maries, which are perceived as lower∗∗∗ in Non-
redundancy than all others. Note, how the model
Mrsf is more stable than all others by exhibit-
ing lower standard deviations in all criteria except

10“Pills N Potions” by Nicki Minaj, “Hurt” by Nine Inch
Nails, “Real to me” by Brian McFadden, “Somebody That I
Used To Know” by Gotye, “Receive” by Alanis Morissette,
“Let’s Start A Band” by Amy MacDonald

Figure 2: Human ratings per summarization model in terms of average and standard deviation.

Non-redundancy. The criteria Informativeness and
Meaning are highly correlated (Pearson correla-
tion coefﬁcient 0.84). Correlations between other
criteria range between 0.29 and 0.51.

Overall, leveraging the Lyrics Fitness in a song
text summary improves summary quality. Espe-
cially with respect to the criteria that, we believe,
indicate the summary quality the most - Informa-
tiveness and Meaning - the Mrsf method is signif-
icantly better performing and more consistent.

Figure 1 shows an example song text and exam-
ple summaries from the experiment. Summary 1 is
generated by Mf and consists of the chorus. Sum-
mary 2 is made by the method Mrsf and has rel-
evant parts of the verses and the chorus, and was
rated much higher in Informativeness and Mean-
ing. We analyzed the free text written by the par-
ticipants to comment on the Meaning criterion, but
no relevant additional information was provided
(the participants mainly summarized their ratings).

5.2 Automatic Evaluation

We computed four different indicators of summary
quality on the dataset of 50k songs described in
Section 4.1. Three of the criteria use the similar-
ity between probability distributions P, Q, which
means we compute the Wasserstein distance be-
tween P and Q (cf.
Section 3.1) and apply
λx. x−1 to it.11 The criteria are:
Distributional Semantics:

similarity between
the word distributions of original and summary, cf.
(Louis and Nenkova, 2013). We give results rela-
tive to the similarity of the best performing model
(=100%).

Topical: similarity between the topic distribu-
tions of original and summary. Restricted to the
3 most relevant topics of the original song text.
We give results relative to the similarity of the best
performing model (=100%).

Coherence: average similarity between word
distributions in consecutive sentences of the sum-
mary, cf. (ShaﬁeiBavani et al., 2018). We give re-
sults relative to the coherence of the original song
text (=100%).

Lyrics ﬁtness: average line-based ﬁtness f it (cf.
Section 3) of the lines in the summary. We give
results relative to the Lyrics ﬁtness of the original
song text (=100%).

Results When evaluating each of the 12 genres,
we found two clusters of genres to behave very
similarly. Therefore, we report the results for these
the Rap genre cluster contains Hip
two groups:
Hop, Southern Hip Hop, and Gangsta Rap. The
Rock / Pop cluster contains the 9 other genres.
Results of the different automatic evaluation met-
rics are shown in Table 1. Distributional Seman-
tics metrics have previously been shown (Louis
and Nenkova, 2013; ShaﬁeiBavani et al., 2018)
to highly correlate with user responsiveness judg-
ments. We would expect correlations of this met-
ric with Informativeness or Meaning criteria there-
fore, as those criteria are closest to responsiveness,
but we have found no large differences between
the different models for this criterion. The sum-
maries of the Ms model have the highest similar-
ity to the original text and the Mf have the low-
est similarity of 90%. The difference between the
highest and lowest values are low.

11This works as we always deal with distances > 0.

For the Topical similarity, the results are mostly

Evaluation criterion

Genre

Distributional
Semantics [%]

Topical [%]

Coherence [%]

Lyrics
ﬁtness [%]

Rock / Pop
Rap
(cid:80)

Rock / Pop
Rap
(cid:80)

Rock / Pop
Rap
(cid:80)

Rock / Pop
Rap
(cid:80)

Mr Ms Mrs Mf Mrsf
97
92
99
94
98
92
76
44
80
58
77
46
99
110
112
112
101
110
63
71
0
0
55
62

100
100
100
100
100
100
95
115
97
53
0
47

90
86
90
41
48
42
99
107
100
201
309
214

93
92
93
64
66
64
100
107
101
183
249
191

original text

n/a

n/a

100

100

Table 1: Automatic evaluation results for the 5 summarization models and 2 genre clusters. Distributional Seman-
tics and Topical are relative to the best model (=100%), Coherence and Fitness to the original text (=100%).

in the same order as the Distributional Semantics
ones, but with much larger differences. While the
Ms model reaches the highest similarity, this is a
self-fulﬁlling prophecy, as summaries of Ms were
generated with the objective of maximizing topical
similarity. The other two models that incorporate
Ms (Mrs and Mrsf ), show a much higher topical
similarity to the original text than Mr and Mf .

Coherence is rated best in Mr with 110%. All
other models show a coherence close to that of the
original text - between 97% and 101%. We be-
lieve that the increased coherence of Mr is not lin-
guistically founded, but merely algorithmic. Mr
produces summaries of the most central sentences
in a text. The centrality is using the concept of
sentence similarity. Therefore, Mr implicitly op-
timizes for the automatic evaluation metric of co-
herence, based on similar consecutive sentences.
Sentence similarity seems to be insufﬁcient to pre-
dict human judgments of coherence in this case.

As might be expected, methods explicitly in-
corporating the Lyrics ﬁtness produce summaries
with a ﬁtness much higher than the original text -
214% for the Mf and 191% for the Mrsf model.
The methods not incorporating ﬁtness produce
summaries with much lower ﬁtness than the origi-
nal - Mr 62%, Ms 47%, and Mrs 55%. In the Rap
genre this ﬁtness is even zero, i.e. summaries (in
median) contain no part of the chorus.

Overall, no single automatic evaluation crite-
rion was able to explain the judgments of our
human participants. However, considering Topi-
cal similarity and ﬁtness together gives us a hint.
The model Mf has high ﬁtness (214%), but low
Topical similarity (42%). The Ms model has the
highest Topical similarity (100%), but low ﬁtness
(47%). Mrsf might be preferred by humans as it

strikes a balance between Topical similarity (64%)
and ﬁtness (191%). Hence, Mrsf succeeds in cap-
turing lines from the most relevant parts of the
lyrics, such as the chorus, while jointly represent-
ing the important topics of the song text.

6 Conclusion

In this paper we have deﬁned and addressed
the task of lyrics summarization. We have ap-
plied both generic unsupervised text summariza-
tion methods (TextRank and a topic-based method
we called TopSum), and a method inspired by au-
dio thumbnailing on 50k lyrics from the WASABI
corpus. We have carried out an automatic evalua-
tion on the produced summaries computing stan-
dard metrics in text summarization, and a human
evaluation with 26 participants, showing that using
a ﬁtness measure transferred from the musicology
literature, we can amend generic text summariza-
tion algorithms and produce better summaries.

In future work, we will model the importance
of a line given the segment to avoid cutting off im-
portant parts of the chorus, as we sometimes ob-
served. Moreover, we plan to address the chal-
lenging task of abstractive summarization over
song lyrics, with the goal of creating a summary
of song texts in prose-style - more similar to what
humans would do, using their own words.

Acknowledgement

This work is partly funded by the French Research
the WASABI
National Agency (ANR) under
project (contract ANR-16-CE23-0017-01).

References

Mehdi Allahyari, Seyed Amin Pouriyeh, Mehdi Asseﬁ,
Saeid Safaei, Elizabeth D. Trippe, Juan B. Gutier-
rez, and Krys Kochut. 2017. Text summarization
techniques: A brief survey. CoRR, abs/1707.02268.

Rachit Arora and Balaraman Ravindran. 2008. Latent
dirichlet allocation based multi-document summa-
rization. In Proceedings of the second workshop on
Analytics for noisy unstructured text data, pages 91–
97. ACM.

Federico Barrios, Federico L´opez, Luis Argerich, and
Rosa Wachenchauzer. 2016. Variations of the simi-
larity function of textrank for automated summariza-
tion. CoRR, abs/1602.03606.

Mark A. Bartsch and Gregory H. Wakeﬁeld. 2005. Au-
dio thumbnailing of popular music using chroma-
based representations. Trans. Multi., 7(1):96–104.

Taylor Berg-Kirkpatrick, Dan Gillick, and Dan Klein.
2011. Jointly learning to extract and compress. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages
481–490, Stroudsburg, PA, USA. Association for
Computational Linguistics.

David Brackett. 1995.

Interpreting Popular Music.

Cambridge University Press.

Wei Chai and Barry Vercoe. 2003. Music thumbnail-
In Proceedings of the
ing via structural analysis.
eleventh ACM international conference on Multime-
dia, pages 223–226.

Jianpeng Cheng and Mirella Lapata. 2016. Neural
summarization by extracting sentences and words.
In Proceedings of the 54th Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 484–494. Association for Com-
putational Linguistics.

Jean Yves Delort, Bernadette Bouchon-Meunier, and
Maria Rifqi. 2003. Enhanced web document sum-
marization using hyperlinks. In Proceedings of the
Fourteenth ACM Conference on Hypertext and Hy-
permedia, HYPERTEXT ’03, pages 208–215, New
York, NY, USA. ACM.

G¨unes Erkan and Dragomir R Radev. 2004. Lexrank:
Graph-based lexical centrality as salience in text
summarization. Journal of artiﬁcial intelligence re-
search, 22:457–479.

Martin Ester, Hans-Peter Kriegel, J¨org Sander, Xiaowei
Xu, et al. 1996. A density-based algorithm for
discovering clusters in large spatial databases with
noise. In Kdd, volume 96, pages 226–231.

Mohamed Abdel Fattah. 2014. A hybrid machine
learning model for multi-document summarization.
Applied intelligence, 40(4):592–600.

Mohamed Abdel Fattah and Fuji Ren. 2009. Ga, mr,
ffnn, pnn and gmm based models for automatic text
summarization. Comput. Speech Lang., 23(1):126–
144.

Aria Haghighi and Lucy Vanderwende. 2009. Explor-
ing content models for multi-document summariza-
In Proceedings of Human Language Tech-
tion.
nologies: The 2009 Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 362–370. Association for
Computational Linguistics.

Ruifang He and Xingyi Duan. 2018. Twitter summa-
rization based on social network and sparse recon-
struction. In AAAI.

Leonhard Hennig. 2009. Topic-based multi-document
summarization with probabilistic latent semantic
analysis. In Proceedings of the International Con-
ference RANLP-2009, pages 144–149.

Meishan Hu, Aixin Sun, Ee-Peng Lim, and Ee-Peng
Lim. 2007. Comments-oriented blog summarization
In Proceedings of the Six-
by sentence extraction.
teenth ACM Conference on Conference on Informa-
tion and Knowledge Management, CIKM ’07, pages
901–904, New York, NY, USA. ACM.

Nanzhu Jiang and Meinard M¨uller. 2015. Estimat-
ing double thumbnails for music recordings.
In
2015 IEEE International Conference on Acous-
tics, Speech and Signal Processing (ICASSP), pages
146–150.

Florian Kleedorfer, Peter Knees, and Tim Pohle. 2008.
Oh oh oh whoah! towards automatic topic detection
in song lyrics. In Ismir, pages 287–292.

Kevin Knight and Daniel Marcu. 2000.

Statistics-
based summarization - step one: Sentence compres-
In Proceedings of the Seventeenth National
sion.
Conference on Artiﬁcial Intelligence and Twelfth
Conference on Innovative Applications of Artiﬁcial
Intelligence, pages 703–710. AAAI Press.

Mark Levy, Mark Sandler, and Michael Casey. 2006.
Extraction of high-level musical structure from au-
dio data and its application to thumbnail generation.
In 2006 IEEE International Conference on Acous-
tics Speech and Signal Processing Proceedings, vol-
ume 5, pages V–V. IEEE.

Chin-Yew Lin. 2004. Rouge: A package for automatic
In Text Summarization

evaluation of summaries.
Branches Out.

Annie Louis and Ani Nenkova. 2013. Automatically
assessing machine summary content without a gold
standard. Computational Linguistics, 39(2).

Stuart Mackie, Richard McCreadie, Craig Macdonald,
and Iadh Ounis. 2014. On choosing an effective au-
tomatic evaluation metric for microblog summarisa-
tion. In Proceedings of the 5th Information Interac-
tion in Context Symposium, pages 115–124. ACM.

Scikit-learn: Machine learning in Python. Journal
of Machine Learning Research, 12:2825–2830.

Horacio Saggion and Thierry Poibeau. 2013. Auto-
matic Text Summarization: Past, Present and Fu-
ture, pages 3–21. Springer, Berlin, Heidelberg.

Elaheh ShaﬁeiBavani, Mohammad Ebrahimi, Ray-
mond Wong, and Fang Chen. 2018. Summariza-
tion evaluation in the absence of human model sum-
maries using the compositionality of word embed-
dings. In Proceedings of the 27th International Con-
ference on Computational Linguistics, pages 905–
914. Association for Computational Linguistics.

C´edric Villani. 2008. Optimal transport: old and new,
volume 338. Springer Science & Business Media.

Lu Wang, Hema Raghavan, Vittorio Castelli, Radu
Florian, and Claire Cardie. 2016. A sentence
compression based framework to query-focused
arXiv preprint
multi-document summarization.
arXiv:1606.07548.

Kento Watanabe, Yuichiroh Matsubayashi, Naho Orita,
Naoaki Okazaki, Kentaro Inui, Satoru Fukayama,
Tomoyasu Nakano, Jordan Smith, and Masataka
Goto. 2016. Modeling discourse segments in lyrics
using repeated patterns. In Proceedings of COLING
2016, the 26th International Conference on Compu-
tational Linguistics: Technical Papers, pages 1959–
1969.

Qiaozhu Mei and ChengXiang Zhai. 2008. Generating
impact-based summaries for scientiﬁc literature. In
ACL.

Gabriel Meseguer-Brocal, Geoffroy Peeters, Guil-
laume Pellerin, Michel Buffa, Elena Cabrio, Cather-
ine Faron Zucker, Alain Giboin, Isabelle Mirbel, Ro-
main Hennequin, Manuel Moussallam, Francesco
Piccoli, and Thomas Fillon. 2017. WASABI: a Two
Million Song Database Project with Audio and Cul-
tural Metadata plus WebAudio enhanced Client Ap-
In Web Audio Conference 2017 – Col-
plications.
laborative Audio #WAC2017, London, United King-
dom. Queen Mary University of London.

Rada Mihalcea and Paul Tarau. 2004. Textrank: Bring-
ing order into text. In Proceedings of the 2004 Con-
ference on Empirical Methods in Natural Language
Processing.

Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2016.
Summarunner: A recurrent neural network based se-
quence model for extractive summarization of docu-
ments. In AAAI.

Ani Nenkova, Kathleen McKeown, et al. 2011. Auto-
matic summarization. Foundations and Trends R(cid:13) in
Information Retrieval, 5(2–3):103–233.

Jahna Otterbacher, G¨unes¸ Erkan, and Dragomir R
Radev. 2005. Using random walks for question-
In Proceedings of the
focused sentence retrieval.
conference on Human Language Technology and
Empirical Methods in Natural Language Process-
ing, pages 915–922. Association for Computational
Linguistics.

Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web. Technical report,
Stanford InfoLab.

Daraksha Parveen, Hans-Martin Ramsl, and Michael
Strube. 2015. Topical coherence for graph-based ex-
tractive summarization. In Proceedings of the 2015
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 1949–1954.

Daraksha Parveen and Michael Strube. 2015.

Inte-
grating importance, non-redundancy and coherence
In Pro-
in graph-based extractive summarization.
ceedings of the 24th International Conference on
Artiﬁcial Intelligence, IJCAI’15, pages 1298–1304.
AAAI Press.

Samuel Pecar. 2018. Towards opinion summarization
of customer reviews. In Proceedings of ACL 2018,
Student Research Workshop, pages 1–8. Association
for Computational Linguistics.

Fabian Pedregosa, Gael Varoquaux, Alexandre Gram-
fort, Vincent Michel, Bertrand Thirion, Olivier
Grisel, Mathieu Blondel, Peter Prettenhofer, Ron
Weiss, Vincent Dubourg, Jake Vanderplas, Alexan-
dre Passos, David Cournapeau, Mathieu Brucher,
Mathieu Perrot, and Edouard Duchesnay. 2011.

