Knowledge Enhanced Graph Neural Networks for Graph
Completion
Luisa Werner, Nabil Layaïda, Pierre Genevès, Sarah Chlyah

To cite this version:

Luisa Werner, Nabil Layaïda, Pierre Genevès, Sarah Chlyah. Knowledge Enhanced Graph Neural
Networks for Graph Completion. The 10th IEEE International Conference on Data Science and
Advanced Analytics, Oct 2023, Thessalokini, Greece. ￿hal-04041691v3￿

HAL Id: hal-04041691

https://inria.hal.science/hal-04041691v3

Submitted on 30 Aug 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Knowledge Enhanced Graph Neural Networks

1st Luisa Werner
Universit´e Grenoble Alpes, INRIA
Grenoble, France
luisa.werner@inria.fr

2nd Nabil Laya¨ıda
INRIA
Grenoble, France
nabil.layaida@inria.fr

3rd Pierre Genev`es
CNRS, INRIA
Grenoble, France
pierre.geneves@inria.fr

4th Sarah Chlyah
INRIA
Grenoble, France
sarah.chlyah@inria.fr

Abstract—Graph data is omnipresent and has a wide variety
of applications, such as in natural science, social networks, or the
semantic web. However, while being rich in information, graphs
are often noisy and incomplete. As a result, graph completion
tasks, such as node classiﬁcation or link prediction, have gained
attention. On one hand, neural methods, such as graph neural
networks, have proven to be robust tools for learning rich
representations of noisy graphs. On the other hand, symbolic
methods enable exact reasoning on graphs. We propose Knowl-
edge Enhanced Graph Neural Networks (KeGNN), a neuro-
symbolic framework for graph completion that combines both
paradigms as it allows for the integration of prior knowledge
into a graph neural network model. Essentially, KeGNN consists
of a graph neural network as a base upon which knowledge
enhancement layers are stacked with the goal of reﬁning predic-
tions with respect to prior knowledge. We instantiate KeGNN
in conjunction with two well-known graph neural networks,
Graph Convolutional Networks and Graph Attention Networks,
and evaluate KeGNN on multiple benchmark datasets for node
classiﬁcation.

Index Terms—neuro-symbolic integration, graph neural net-

works, relational learning, knowledge graphs, fuzzy logic

I. INTRODUCTION

Graphs are ubiquitous across diverse real-world applications
such as e-commerce [1] , natural science [2] or social networks
[3]. Graphs connect nodes by edges and allow to enrich them
with features. This makes them a versatile and powerful data
structure that encodes relational information. As graphs are
often derived from noisy data, incompleteness and errors are
common issues. Consequently, graph completion tasks such
as node classiﬁcation or link prediction have become increas-
ingly important. These tasks are approached from different
directions. In the ﬁeld of deep learning, research on graph
neural networks (GNNs) has gained momentum. Numerous
models have been proposed for various graph topologies and
applications [4]–[7]. The key strength of GNNs is to ﬁnd
meaningful representations of noisy graph data, that can be
used to improve prediction tasks [8]. Despite this advantage, as
a subcategory of deep learning methods, GNNs are criticized
for their limited interpretability and large data consumption
[9]. Alongside, the research ﬁeld of symbolic AI addresses
the above-mentioned tasks. In symbolic AI, solutions are
found by performing logic-like reasoning steps that are exact,
interpretable and data-efﬁcient [10]. For large graphs, however,
symbolic methods are often computationally expensive or even
infeasible. Since techniques from deep learning and from
symbolic AI have complementary pros and cons, the ﬁeld of

neuro-symbolic AI aims to combine both paradigms. Neuro-
symbolic AI not only paves the way towards the application
of AI to learning with limited data, but also allows for jointly
using symbolic information (in the form of logical rules) and
sub-symbolic information (in the form of real-valued data).
This helps to overcome the black-box nature of deep learning
methods and to improve interpretability through symbolic
representations [9], [11], [12].
In this work, we present

the neuro-symbolic approach
Knowledge enhanced Graph Neural Networks (KeGNN) to
conduct node classiﬁcation given graph data and a set of prior
knowledge. In KeGNN, knowledge enhancement layers [13]
are stacked on top of a GNN and adjust its predictions in
order to increase the satisfaction of some prior knowledge.
In addition to the parameters of the GNN, the knowledge
enhancement
layers contain learnable clause weights that
reﬂect the impact of the prior knowledge on the predictions.
Both components form an end-to-end differentiable model.
KeGNN can be seen as a variant of knowledge enhanced
neural networks (KENN), which stack knowledge enhance-
ment layers onto a multi-layer perceptron (MLP) and have
been proven successful in semantic point cloud segmenta-
tion, image segmentation and multi-label classiﬁcation [14]–
[16]. However, relational information in sparse graphs can
only be introduced through the logical clauses with binary
predicates in the knowledge enhancement layer and not at
base neural network level. In contrast, KeGNN is based on
GNNs that process the graph structure, which makes both
the neural and symbolic components sufﬁciently powerful
to exploit the graph structure. In this work, we instantiate
KeGNN in conjunction with two well-known GNNs: Graph
Attention Networks [17] and Graph Convolutional Networks
[18]. We apply KeGNN to the benchmark datasets for node
classiﬁcation Cora, Citeseer, PubMed [19] and Flickr [20].

II. METHOD: KEGNN

KeGNN is a neuro-symbolic approach that can be applied to
node classiﬁcation tasks with the capacity of handling graph
structure at the base neural network level. The model takes
two types of input: (1) real-valued graph data and (2) prior
knowledge expressed in ﬁrst-order logic.

A. Graph-structured Data

A Graph G = (N, E) consists of a set of n nodes N
and a set of k edges E where each edge of the form (vi, vj)

Fig. (1) Example extract of the Citeseer citation graph.

connects two nodes vi ∈ N and vj ∈ N. The neighborhood
N (vi) describes the set of ﬁrst-order neighbors of vi. For
an attributed and labelled graph, nodes are enriched with
features and labels. Each node has a feature vector x ∈ Rd of
dimension d and a label vector y ∈ Rm. The label vector y
contains one-hot encoded ground truth labels for m classes. In
matrix notation, the features and labels of the entire graph are
described as X ∈ Rn×d and Y ∈ Rn×m. A graph is typed if
type functions fE and fN assign edge types and node types to
the edges and nodes, respectively. A graph with constant type
functions (that assign the same edge and node type to all edges
and nodes) is called homogeneous, whereas for heterogeneous
graphs, nodes and edges may have different types [5].

Example 2.1: A Citation Graph GCit consists of documents
and citations. Figure 1 shows an extract of the Citeseer citation
graph that is used as example to guide through this paper.
The documents are represented by a set of nodes NCit and
citations by a set of edges ECit. Documents can be attributed
with features XCit that describe their content as Word2Vec
[21] vectors. Each node is labelled with one of the six topic
categories {AI, DB, HCI, IR, ML, AG}1 that are encoded in
YCit. Since all nodes (documents) and edges (citations) have
the same type, GCit is homogeneous.

B. Prior Knowledge

Some prior knowledge K is provided to KeGNN. It can
be described as a set of (cid:96) logical clauses expressed in the
logical language L that is deﬁned as sets of constants C,
variables X and predicates P. Predicates have an arity r of
one (unary) or two (binary): P = PU ∪ PB. Predicates of
arity r > 2 are not considered in this work. Unary predicates
express properties, whereas binary predicates express relations.
L supports negation (¬) and disjunction (∨). Each clause
ϕ ∈ K = {ϕ1, . . . , ϕ(cid:96)} can be formulated as a disjunction of
(possibly negated) atoms (cid:87)q
j=1 oj with q atoms {o1, . . . , oq}.

1The classes are abbreviations for the categories Artiﬁcial Intelligence,
Databases, Human-Computer Interaction, Information Retrieval, Machine
Learning and Agents.

Since the prior knowledge is general, all clauses are assumed
to be universally quantiﬁed. Clauses can be grounded by
assigning constants to the free variables. A grounded clause is
denoted as ϕ[x1, x2, ...|c1, c2, ...] with variables xi ∈ X and
constants ci ∈ C. The set of all grounded clauses in a graph
is G(K, C).

Example 2.2: The graph GCit in Figur 1 can be expressed
in L. Nodes are represented by a set of constants C =
{a, b, . . . , f }. Node labels are expressed as a set of unary
predicates PU = {AI, DB, . . . , AG} and edges as a set of
binary predicates PB = {Cite}. L has a set of variables
X = {x, y}. The atom AI(x), for example, expresses the
membership of x to the class AI and Cite(x, y) expresses the
existence of a citation between x and y. Some prior knowledge
K can be written as a set of (cid:96) = 6 disjunctive clauses in L.
Here, the assumption is denoted that two papers that cite each
other have the same document class:

ϕAI : ∀xy¬AI(x) ∨ ¬Cite(x, y) ∨ AI(y)
ϕDB : ∀xy¬DB(x) ∨ ¬Cite(x, y) ∨ DB(y)

. . .

The atoms are grounded by replacing the variables x and y
with the constants {a, b, . . . f } to obtain the sets of unary
groundings {AI(a), ML(b), . . . , IR(f)} and binary groundings
{Cite(a, d), Cite(a, e), . . . , Cite(a, f)}. Assuming a closed
world and exclusive classes, other facts could be derived,
such as {¬DB(a), ¬IR(a), . . . , ¬Cite(a, b)}. For the sake of
simplicity, these are omitted here.

C. Node Classiﬁcation

Node classiﬁcation is a subtask of knowledge graph com-
pletion on a graph G with the objective to assign classes to
nodes where they are unknown. This task is accomplished
given node features X, edges E and some prior knowledge K
encoded as a set of clauses in L. A predictive model is trained
on a subset of the graph Gtrain with ground truth labels Ytrain
and validated on a test set Gtest for which the ground truth

labels are compared to the predictions in order to assess the
predictive performance. Node classiﬁcation can be studied in a
transductive or inductive setting. In a transductive setting, the
entire graph is available for training, but the true labels of the
test nodes are masked. In an inductive setting, only the nodes
in the training set and the edges connecting them are available,
making it more challenging to classify unseen nodes.

D. Fuzzy Semantics

Let us consider an attributed and labelled graph G and
the prior knowledge K. While K can be deﬁned in the
logic language L, the neural component in KeGNN relies
on continuous and differentiable representations. To interpret
Boolean logic in the real-valued domain, KeGNN uses fuzzy
logic [22], which maps Boolean truth values to the continuous
interval [0, 1] ⊂ R. A constant in C is interpreted as a real-
valued feature vector x ∈ Rd. A predicate P ∈ P with arity
r is interpreted as a function fP : Rr×d (cid:55)→ [0, 1] that takes r
feature vectors as input and returns a truth value.

Example 2.3: In the example, a unary predicate PU ∈ PU =
{AI, DB, . . .} is interpreted as a function fPU : Rd (cid:55)→ [0, 1]
that takes a feature vector x and returns a truth value indicating
whether the node belongs to the class encoded as PU . The
binary predicate Cite ∈ PB is interpreted as the function
(cid:40)

fCite(vi, vj) =

1,
0,

if (vi, vj) ∈ ECit
else.

fCite returns the truth value 1 if there is an edge between two
nodes vi and vj in GCit and 0 otherwise.

T-conorm functions ⊥ : [0, 1] × [0, 1] (cid:55)→ [0, 1] [23] take
real-valued truth values of two literals2 and deﬁne the truth
value of their disjunction. The G¨odel t-conorm function for
two truth values ti, tj is deﬁned as

⊥(ti, tj) (cid:55)→ max(ti, tj).

To obtain the truth value of a clause ϕ : o1∨...∨oq, the function
⊥ is extended to a vector t of q truth values: ⊥(t1, t2, ..., tq) =
⊥(t1, ⊥(t2...⊥(tq−1, tq))). Fuzzy negation over truth values
is deﬁned as t (cid:55)→ 1 − t [22].

Example 2.4: Given the clause ϕAI

: ∀xy ¬AI(x) ∨
¬Cite(x, y) ∨ AI(y) and its grounding ϕAI[x, y|a, b] : AI(a) ∨
¬Cite(a, b) ∨ AI(b) to the constants a and b and truth
values for the grounded predicates AI(a) = t1, AI(b) = t2
and Cite(a, b) = t3,
is
max{max{(1 − t1), (1 − t3)}, t2}.

the truth value of ϕAI[x, y|a, b]

E. Model Architecture

The way KeGNN computes the ﬁnal predictions can be
divided in two stages. First, a GNN predicts the node classes
given the features and the edges. Subsequently, the knowledge
enhancement layers use the predictions as truth values for the
grounded unary predicates and update them with respect to
the knowledge. An overview of KeGNN is given in Figure 2.

2A literal is a (possibly negated) grounded atom, e.g. AI(a)

1) Neural Component: The role of the GNN in the neural
component
is to exploit feature information in the graph
structure. The key strength of a GNN is to enrich node
representations with graph structure by nesting k message
passing layers [8]. Per layer, the representations of neighboring
nodes are aggregated and combined to obtain updated repre-
sentations. The node representation vk+1
in the k-th message
passing layer is

i

i = combine(cid:0)vk
vk+1

i , aggregate(cid:0){vk

j |vk

j ∈ N (vi)}(cid:1)(cid:1).

The layers contain learnable parameters that are optimized
with backpropagation. In this work, we consider two well-
known GNNs as components for KeGNN: Graph Convolu-
tional Networks (GCN) [18] and Graph Attention Networks
(GAT) [17]. While GCN considers the graph structure as given,
GAT allows for assessing the importance of the neighbors with
attention weights αij between node vi and node vj. In case
of multi-head attention, the attention weights are calculated
multiple times and concatenated which allows for capturing
different aspects of the input data. In KeGNN,
the GNN
implements the functions fPU (see Section II-D). In other
words, the predictions are used as truth values for the grounded
unary predicates in the symbolic component.

2) Symbolic Component: To reﬁne the predictions of the
GNN, one or more knowledge enhancement layers are stacked
onto the GNN to update its predictions Y to Y(cid:48). The goal
is to increase the satisfaction of the prior knowledge. The
predictions Y of the GNN serve as input to the symbolic
component where they are interpreted as fuzzy truth values
for the unary grounded predicates U := Y with U ∈ Rn×m.
Fuzzy truth values for the groundings of binary predicates
are encoded as a matrix B where each row represents an
edge (vi, vj) and each column represents an edge type e.
In the context of node classiﬁcation, the GNN returns only
predictions for the node classes, while the edges are assumed
to be given. A binary grounded predicate is therefore set to
truth value 1 (true) if an edge between two nodes vi and vj
exists:

B[(vi,vj ),e] =

(cid:40)

1,
0,

if (vi, vj) of type e ∈ E
else.

Example 2.5: In case of the beforementioned citation graph

of Figure 1, U and B are deﬁned as:

U :=








AI(a)
AI(b)
...
AI(f)

. . . AG(a)
. . . AG(b)

...

. . . AG(f)








B :=























Cite(a, d)
Cite(a, e)
Cite(a, c)
...
Cite(c, e)
Cite(e, f)

To enhance the satisfaction of clauses that contain both unary
and binary predicates, their groundings are joined into one
matrix M ∈ Rk×p with p = 2 · |PU | + |PB|. M is computed
by joining U and B so that each row of M represents an edge

Fig. (2) Overview of KeGNN.

(vi, vj). As a result, M contains all required grounded unary
predicates for vi and vj.

Example 2.6: For the example citation graph, we obtain M

as follows:



for this clause are δMϕAI =
δ¬AIx(a)
δ¬AIx(a)
δ¬AIx(a)
...
δ¬AIx(e)

. . .
. . .
. . .

wAI ·








0
0
0

. . .

0

δAIy(c)
δAIy(e)
δAIy(d)
...
δAIy(f)

0
0
0
...
0

. . .
. . .
. . .

δ¬Cit(a,c)
δ¬Cit(e,a)
δ¬Cit(c,d)

. . .

δ¬Cit(e,f)










A knowledge enhancement layer consists of multiple clause
enhancers. A clause enhancer is instantiated for each clause
ϕ ∈ K. Its aim is to compute updates δMϕ for the groundings
in M that increase the satisfaction of ϕ.

First, fuzzy negation is applied to the columns of M that
correspond to negated atoms in ϕ. Then δMϕ is computed by
a t-conorm boost function φ [13]. This function φ : [0, 1]q (cid:55)→
[0, 1]q takes q truth values and returns changes to those truth
values such that the satisfaction is increased: ⊥(t) ≤ ⊥(t +
φ(t)). [13] propose the following differentiable t-conorm boost
function

φwϕ (t)i = wϕ ·

eti
j=1 etj

(cid:80)q

.

The boost function φwϕ employs a clause weight wϕ that
is initialized in the beginning of the training and optimized
during training as a learnable parameter. The updates for
the groundings calculated by φwϕ are proportional to wϕ.
Therefore, wϕ determines the magnitude of the update and
thus reﬂects the impact of a clause. The changes to the
atoms that do not appear in a clause are set to zero. The
boost function is applied row-wise to M as illustrated in the
following example.

Example 2.7: Given the clause ϕAI

: ∀xy¬AI(x) ∨
¬Cite(x, y) ∨ AI(y) and the clause weight wAI, the changes

The values of δMϕAI are calculated by φwAI, for example:

δ¬AIx(a) = φwAI(z)a = −

e−zAI(a)
e−zAI(a) + e−zCit(a,c) + ezAI(c)

Each clause enhancer computes updates δMϕ to increase
the satisfaction of a clause independently. The updates of
all clause enhancers are ﬁnally added, resulting in a matrix
δM = (cid:80)
ϕ∈K δMϕ. To apply the updates to the initial
predictions, δM has to be added to Y. The updates in δM
can not directly be applied to the predictions Y of the GNN.
Since the unary groundings U were joined with the binary
groundings B, multiple changes may be proposed for the
same grounded unary atom. For example, for the grounded
atom AI(c) the changes δ¬AIy(c) and δ¬AIx(c) are proposed,
since c appears in the grounded clauses ϕAI[x, y|a, c] and
ϕAI[x, y|c, e]. In GCit the node c appears in ﬁrst place of edge
(a, c) and in second place of edge (c, e). Therefore, all updates
for the same grounded atom are summed, which reduces the
size of M to the size of U.

To ensure that the updated predictions remain truth values in
the range of [0, 1], the knowledge enhancement layer updates
at ﬁrst the preactivations Z of the GNN and then applies
the activation function σ to the updated preactivations Z(cid:48) in
order to obtain the ﬁnal predictions: Y(cid:48) = σ(Z(cid:48)). Therefore,
a knowledge enhancement layer transforms Z to Z(cid:48) (with
Z, Z(cid:48) ∈ Rn×m). In the last step, the updates by the knowledge
enhancer are added to the preactivations Z of the GNN and
passed to σ to obtain the updated predictions

Y(cid:48) = σ

(cid:32)

Z +

(cid:33)

δUϕ

(cid:88)

ϕ∈K

Neural Component Symbolic Component InterpretationGNNKnowledge Enhancementadaeacdbceefa
b
c
d
e
fa
b
c
d
e
fAI  DB  HCI  IR  ML  AG AI(a) DB(a) … AG(a) AI(b) DB(b) … AG(b) … Unary GroundingsAI(x)Cite(x.y)AI(y) DB(x)Cite(x.y)AI(y) … Prior Knowledge¬∨¬∨¬∨¬∨a
b
c
d
e
fAI  DB  HCI  IR  ML  AG Predictions YUpdated  Predictions Y’Features    ¬∨Fuzzy Operators Cite(a.d) Cite(a.e) … Binary GroundingsEdgeswhere δUϕ is the matrix obtained by extracting the changes
to the unary predicates from δMϕ. Regarding the binary
groundings, the values in B are set to a high positive value
that results in one when σ is applied.

III. RELATED WORK

The ﬁeld of knowledge graph completion is addressed
from several research directions. Symbolic methods exist that
conduct link prediction given a set of prior knowledge [24]
[25]. Embedding-based methods [26] are mostly sub-symbolic
methods to obtain node embeddings that are used for knowl-
edge graph completion tasks. Usually, their common objective
is to ﬁnd similar embeddings for nodes that are located closely
in the graph. The majority of these methods only encodes the
graph structure, but does not consider node-speciﬁc feature
information [27]. However, KeGNN is based on GNNs that
are suited for learning representations of graphs attributed
with node features. It stacks additional layers that interpret the
outputs of the GNN in fuzzy logic and modify them to increase
the satisﬁability. Therefore, it is considered a neuro-symbolic
method. In the multifaceted neuro-symbolic ﬁeld, KeGNN
can be placed in the category of knowledge-guided learning
[13], where the focus lies on learning in the presence of
additional supervision introduced as prior knowledge. Within
this category, KeGNN belongs to the model-based approaches,
where prior knowledge in the form of knowledge enhancement
layers is an integral part of the model [14]. Beyond, loss-
based methods such as logic tensor networks [28] exist that
encode the satisﬁability of prior knowledge as an optimization
objective.

Further, in [29] neuro-symbolic approaches dealing with
graph structures are classiﬁed into three categories. First,
logically informed embedding approaches [30], [31] use pre-
deﬁned logical rules that provide knowledge to a neural
system, while both components are mostly distinct. Second,
approaches for knowledge graph embedding with logical con-
straints [32], [33] use prior knowledge as constraints on the
neural knowledge graph embedding method in order to modify
predictions or embeddings. Thirdly, neuro-symbolic methods
are used for learning rules for graph reasoning tasks [34],
[35]. This allows for rule generation or conﬁdence scores for
prior knowledge and makes the models robust to exceptions
or soft knowledge. KeGNN best falls into the second category,
since the prior knowledge is interpreted in fuzzy logic to
be integrated with the neural model and update the GNN’s
predictions. The idea of conﬁdence values in category three
shares the common property of weighting knowledge as with
KeGNN’s clause weights. However, even though KeGNN’s
clause weights introduce a notion of impact of a clause when
predictions are made, they cannot directly be interpreted as
the conﬁdence in a rule.

In the well-known Kautz Taxonomy [36] that classiﬁes
neuro-symbolic approaches according to the integration of
neural and symbolic modules, KeGNN falls best
into the
category Neuro[Symbolic] (Type 6) of fully-integrated

neuro-symbolic systems that embed symbolic reasoning in a
neural architecture.

IV. EXPERIMENS

To evaluate the performance of KeGNN, we apply it to the
datasets Citeseer, Cora, PubMed and Flickr that are common
benchmarks for node classiﬁcation in a transductive setting.
In the following, KeGNN is called KeGCN and KeGAT when
instantiated to a GCN or a GAT, respectively. As additional
baseline, we consider KeMLP, that stacks knowledge enhance-
ment layers onto an MLP, as proposed in [14]. Further, the
standalone neural models MLP, GCN and GAT are used
as baselines. While Citeseer, Cora and PubMed are citation
graphs that encode citations between scientiﬁc papers (as in
Example 2.2), Flickr contains images and shared properties
between them. All datasets can be modelled as homogeneous,
labelled and attributed graphs as deﬁned in Section II-A.
Table I gives an overview of the named datasets in this work.
The datasets are publicly available on the dataset collection3
of PyTorch Geometric [37]. For the split into train, valid and
test set, we take the predeﬁned splits in [38] for the citation
graphs and in [20] for Flickr. Word2Vec vectors [21] are used
as node features for the citation graphs and image data for
Flickr. Figure 1 visualizes the graph structure of the underlying
datasets in this work as a homogeneous, attributed and labelled
graph on the example of Citeseer.

The set of prior logic for the knowledge enhancement layers
is manually deﬁned. In this work, we encode the assumption
that the existence of an edge for a node pair points to their
membership to the same class and hence provides added value
to the node classiﬁcation task. In the context of citation graphs,
this implies that two documents that cite each other refer to
the same topic, while for Flickr, linked images share the same
properties. Following this pattern for all datasets, a clause
ϕ: ∀xy : ¬Clsi(x)∨ ¬Link(x, y) ∨ Clsi(y) is instantiated
for each node class Clsi, i ∈ {1, . . . , m}. More details on the
experiments are given in Section IV-B. The source code of the
experiments are publicly available4. .

A. Results

To compare the performance of all models, we examine
the average test accuracy over 50 runs (10 for Flickr) for
the knowledge enhanced models KeMLP, KeGCN, KeGAT
and the standalone base models MLP, GCN, GAT on the
named datasets. The results are given in Table II. For Cora
and Citeseer, KeMLP leads to a signiﬁcant improvement over
MLP (p-value of one-sided t-test (cid:28) 0.05). In contrast, no
signiﬁcant advantage of KeGCN or KeGAT in comparison
to the standalone base model is observed. Nevertheless, all
GNN-based models are signiﬁcantly superior to KeMLP for
Cora. This includes not only KeGCN and KeGAT, but also
the GNN baselines. For Citeseer, KeGAT and GAT both
outperform KeMLP. In the case of PubMed, only a signiﬁcant
improvement of KeMLP over MLP can be observed, while the

3https://pytorch-geometric.readthedocs.io/en/latest/modules/datasets.html
4https://gitlab.inria.fr/tyrex/kegnn

Name
Citeseer
Cora
PubMed
Flickr

#nodes
3,327
2,708
19,717
89,250

#edges
9,104
10,556
88,648
899,756

#features
3,703
1,433
500
500

#Classes
6
7
3
7

train/valid/test split
1817/500/1000
1208/500/1000
18217/500/1000
44624/22312/22312

TABLE (I) Overview of the datasets Citeseer, Cora, PubMed and Flickr

Cora

0.8538
(0.0057)
0.748
(0.0102)
0.8855
(0.0062)
0.5007
(0.0063)
TABLE (II) Average test accuracy of 50 runs (10 for Flickr). The standard deviations are reported in brackets.

0.8517
(0.0068)
0.7718
(0.0072)
0.8769
(0.0040)
0.4970
(0.0124)

KeMLP GCN
0.8072
(0.0193)
0.7529
(0.0067)
0.8931
(0.0048)
0.4659
(0.0012)

KeGCN GAT
0.8587
(0.0057)
0.7506
(0.0096)
0.8840
(0.0087)
0.4974
(0.0180)

KeGAT
0.8498
(0.0066)
0.7734
(0.0073)
0.8686
(0.0081)
0.4920
(0.0189)

MLP
0.7098
(0.0080)
0.7278
(0.0081)
0.8844
(0.0057)
0.4656
(0.0018)

PubMed

CiteSeer

Flickr

the prediction performance. Therefore, in Figure 3 we analyze
the accuracy grouped by the node degree for the entire graph
for MLP vs. KeMLP and GCN vs. KeGCN. The ﬁndings for
KeGAT are in line with those for KeGCN. It is observed that
KeMLP performs better compared to MLP as the node degree
increases. By contrast, when comparing GCN and KeGCN,
for both models, the accuracy is observed superior for nodes
with a higher degree.

This shows that rich graph structure is helpful for the node
classiﬁcation in general. Indeed, the MLP is a simple model
that misses information on the graph structure and thus beneﬁts
from graph structure contributed by KeMLP in the form of
binary predicates. On the contrary, standalone GNNs can
process graph structure by using message passing techniques
to transmit learned node representations between neighbors.
The prior knowledge introduced in the knowledge enhancer is
simple. It encodes that two neighbors are likely to be of the
same class. An explanation for the small difference in perfor-
mance is that GNNs may be able to capture and propagate
this simple knowledge across neighbors implicitly, using its
message passing technique. In other words we observe that,
in this particular case, the introduced knowledge happens to
be redundant for GNNs. However, the introduced knowledge
signiﬁcantly improves the accuracy of MLPs. In this context,
we discuss perspectives for future work in Section V.

2) Robustness to wrong knowledge: Furthermore, a ques-
tion of interest is how the knowledge enhanced model ﬁnd
a balance between knowledge and graph data in case of
is not consistent with the graph data. In
knowledge that
other words, can the KeGNN successfully deal with nodes
having mainly neighbors that belong to a different ground truth
class and thus contribute misleading information to the node
classiﬁcation?

To analyze this question, we categorize the accuracy by
the proportion of misleading nodes in the neighborhood, see
Figure 4. Misleading nodes are node neighbors that have a
different ground truth class than the node to be classiﬁed. It
turns out that KeMLP is particularly helpful over MLP when
the neighborhood provides the right information. However, if
the neighborhood is misleading (if most or even all of the

Fig. (3) The accuracy grouped by the node degree for MLP
vs. KeMLP (above) and GCN vs. KeGCN (middle) and GAT
vs. KeGAT(below) on Citeseer.

GNN-based models and their enhanced versions do not provide
any positive effect. For Flickr, no signiﬁcant improvement be-
tween the base model and the respective knowledge enhanced
model can be observed. Nevertheless, all GNN-based models
outperform KeMLP, reporting signiﬁcantly higher mean test
accuracies for KeGAT, GAT, GCN and KeGCN.

1) Exploitation of the Graph Structure: It turns out that
the performance gap between MLP and KeMLP is larger than
for KeGNN in comparison to the standalone GNN. To explain
this observation, we examine how the graph structure affects

015>520.10.20.30.40.50.6AccuracyAccuracy Grouped by Node DegreeMLPKeMLP3401245>530.10.20.30.40.50.60.7Accuracy0125>5Node Degree0.10.20.30.40.50.60.70.8AccuracyFig. (6) Clause compliance during training for GCN vs.
KeGCN (left) and MLP vs. KeMLP (right) on Citeseer.

Fig. (4) The accuracy grouped by the ratio of misleading
ﬁrst-order neighbors for GCN vs. KeGCN (left), MLP vs.
KeMLP (right), GCN vs. KeMLP (below) on Citeseer.

a class Clsi, a set of nodes V, a set of nodes of the class Clsi:
Vi = {vi|vi ∈ V ∧ Cls(vi) == i}, and the neighborhood
N (vi) of vi, the clause compliance of clause ϕ on graph G
is deﬁned as follows:

neighbors belong to a different class), an MLP that ignores
the graph structure can lead to even better results. When
comparing KeGCN and GCN, there is no clear difference.
This is expected, since both models are equally affected by
misleading nodes as they utilize the graph structure. Just
as a GCN, the KeGCN is not necessarily robust to wrong
prior knowledge since the GCN component uses the entire
neighborhood, including the misleading nodes.

When comparing GCN to KeMLP, see plot below in Fig-
ure 4, KeMLP is more robust to misleading neighbors. While
GCN takes the graph structure as given and includes all
neighbors equally in the embeddings by graph convolution, the
clause weights in the knowledge enhancement layers provide
a way to devalue knowledge. If the data frequently contradicts
a clause, the model has the capacity to reduce the respective
clause weight in the learning process and reduce its impact.

3) Clause Weight Learning: Further, we want to examine
whether the clause weights learned during training are aligned
with the knowledge in the ground truth data. The clause
weights provide insights on the magnitude of the updates made
by a clause. The clause compliance [13] measures how well

Compliance(G, ϕ) =

(cid:80)

vi∈Vi

(cid:80)

(cid:80)

vj ∈N (v) 1[ if vj ∈ Vi]
|N (vi)|

vi∈Vi

(1)
In other words, the clause compliance counts how often
among nodes of a class Clsi the neighboring nodes have the
same class [13]. The clause compliance can be calculated on
the ground truth classes of the training set or the predicted
classes. As a reference, we measure the clause compliance
based on the ground truth labels in the training set. Figure 5
displays the learned clause weights for KeGCN and KeMLP
versus the clause compliance on the ground truth labels of
the training set. For KeMLP, a positive correlation between
the learned clause weights and the clause compliance on the
training set
is observed. This indicates that higher clause
weights are learned for clauses that are satisﬁed in the training
set. Consequently, these clauses have a higher impact on the
updates of the predictions. In addition, the clause weights
corresponding to clauses with low compliance values make
smaller updates to the initial predictions. Accordingly, clauses
that are rarely satisﬁed learn lower clause weights during the
training process. In the case of KeGCN, the clause weights are
predominantly set to values close to zero. This is in accordance
with the absence of a signiﬁcant performance gap between
GCN and KeGCN. Since the GCN itself already leads to
valid classiﬁcations, smaller updates are required by the clause
enhancers.

Fig. (5) Learned clause weights vs. clause compliance for
KeMLP (left) and KeGCN (right) on Citeseer.

the prior knowledge is satisﬁed in a graph. Given a clause ϕ,

Furthermore, we analyze how the compliance evolves dur-
ing training to investigate whether the models learn predictions
that increase the satisfaction of the prior knowledge. Figure 6
plots the evolution of the clause compliance for the six clauses
for GCN vs. KeGCN and MLP vs. KeMLP. It is observed
that GCN and KeGCN yield similar results as the evolution
of the compliance during training for both models is mostly
aligned. For MLP vs. KeMLP the clause compliance of the
prediction of the MLP converges to lower values for all classes
than the clause compliance obtained with the KeMLP. This

0%<25%<50% <75%<100%100%Percentage 0.10.20.30.40.50.60.70.8AccuracyGCNKeGCN0%<25%<50% <75%<100%100%Percentage 0.10.20.30.40.50.6AccuracyMLPKeMLP0%<25%<50% <75%<100%100%Percentage0.10.20.30.40.50.60.7AccuracyGCNKeMLP0.20.4 0.60.81.0Learned Clause Weight0.20.30.40.50.6Clause ComplianceKeMLP0.00.20.4 0.60.81.01.2Learned Clause Weight0.20.30.40.50.60.7Clause ComplianceKeGCN05101520253035Epoch0.60.70.80.9ComplianceEvolution of complianceforall xy: not Cls 0(x) or not Cite(x,y) or Cls0(y)forall xy: not Cls 1(x) or not Cite(x,y) or Cls1(y)forall xy: not Cls 2(x) or not Cite(x,y) or Cls2(y)forall xy: not Cls 3(x) or not Cite(x,y) or Cls3(y)forall xy: not Cls 4(x) or not Cite(x,y) or Cls4(y)forall xy: not Cls 5(x) or not Cite(x,y) or Cls5(y)-- = base NN, line = after enhancement0510152025Epoch0.00.10.20.30.40.50.60.7ComplianceEvolution of complianceforall xy: not Cls 0(x) or not Cite(x,y) or Cls0(y)forall xy: not Cls 1(x) or not Cite(x,y) or Cls1(y)forall xy: not Cls 2(x) or not Cite(x,y) or Cls2(y)forall xy: not Cls 3(x) or not Cite(x,y) or Cls3(y)forall xy: not Cls 4(x) or not Cite(x,y) or Cls4(y)forall xy: not Cls 5(x) or not Cite(x,y) or Cls5(y)-- = base NN, line = after enhancement gives evidence that the knowledge enhancement layer actually
improves the satisﬁability of the prior knowledge. As already
observed, this gives evidence that the standalone GCN is able
to implicitly satisfy the prior knowledge even though it is not
explicitly deﬁned.

are displayed in Table III. We set the random seed for all
experiments to 1234.

The reference models MLP, GCN and GAT are trained with
the same parameter set as the respective knowledge enhanced
models.

B. Additional Experiment Details

1) Implementation: The code4 is based on PyTorch [39]
and the graph learning library PyTorch Geometric [37]. The
Weights & Biases tracking tool [40] is used to monitor the
experiments. All experiments are conducted on a machine
running an Ubuntu 20.4 equipped with an Intel(R) Xeon(R)
Silver 4114 CPU 2.20GHz processor, 192G of RAM and one
GPU Nvidia Quadro P5000.

2) Model Parameters and Hyperparameter Tuning:
KeGNN contains a set of hyperparameters. Batch normal-
ization [41] is applied after each hidden layer of the GNN.
The Adam optimizer [42] is used as optimizer for all models.
Concerning the hyperparameters speciﬁc to the knowledge
enhancement layers, the initialization of the preactivations of
the binary predicates (which are assumed to be known) is taken
as a hyperparameter. They are set to a high positive value for
edges that are known to exist and correspond to the grounding
of the binary predicate. Furthermore, different initializations of
clause weights and constraints on them are tested. Moreover,
the number of stacked knowledge enhancement layers is a hy-
perparameter. We further allow the model to randomly neglect
a proportion of edges by setting an edges drop rate parameter.
Further, we test whether the normalization of the edges with
the diagonal matrix ˜D = (cid:80)
˜Ai,j (with ˜A = A+I) is helpful.
To ﬁnd a suitable set hyperparameters for each dataset and
model, we perform a random search with up to 800 runs
and 48h time limit and choose the parameter combination
which leads to the highest accuracy on the validation set. The
hyperparameter tuning is executed in Weights and Biases [40].
The following hyperparameter values are tested:

j

• Adam optimizer parameters: β1: 0.9, β2: 0.99, (cid:15): 1e-07
• Attention heads: {1, 2, 3, 4, 6, 8, 10}
• Batch size: {128, 512, 1024, 2048, full batch}
• Binary preactivation: {0.5, 1.0, 10.0, 100.0, 500.0}
• Clause weights initialization: {0.001, 0.1, 0.25, 0.5, ran-

dom uniform distribution on [0,1)}

• Dropout rate: 0.5
• Edges drop rate: random uniform distribution [0.0, 0.9]
• Edge normalization: {true, false}
• Early stopping: δmin : 0.001, patience: {1, 10, 100}
• Hidden layer dimension: {32, 64, 128, 256}
• Learning rate: random uniform distribution [0.0001, 0.1]
• Clause weight clipping: wmin : 0.0, wmax: random

uniform distribution: [0.8, 500.0]

• Number of knowledge enhancement layers:

{1, 2, 3, 4, 5, 6}

• Number of hidden layers: {2, 3, 4, 5, 6}
• Number of epochs 200 (unless training stopped early)
The obtained parameter combinations for the models KeMLP,
KeGCN and KeGAT for Cora, Citeseer, PubMed and Flickr

V. LIMITATIONS AND PERSPECTIVES

The method of KeGNN is limited in some aspects, which we
present in this section. In this work, we focus on homogeneous
graphs. In reality, however, graphs are often heterogeneous
with multiple node and edge types [4]. Adaptations are neces-
sary on both the neural and the symbolic side to apply KeGNN
to heterogeneous graphs. The restriction to homogeneous
graphs also limits the scope of formulating complex prior
knowledge. Eventually, the datasets used in this work and the
set of prior knowledge are too simple for KeGNN to exploit its
potential and lead to a signiﬁcant improvement over the GNN.
The experimental results show that the knowledge encoded
in the symbolic component leads to signiﬁcant improvement
over an MLP that is not capable to capture and learn that
knowledge. This indicates that for more complex knowledge
that is harder for a GNN to learn, KeGNN has the potential
to bring higher improvements. A perspective for further work
is the extension of KeGNN to more generic data structures
such as incomplete and heterogeneous knowledge graphs in
conjunction with more complex prior knowledge.

Another limitation of KeGNN is scalability. With an increas-
ing number of stacked knowledge enhancement layers, the
affected node neighborhood grows exponentially, which can
lead to signiﬁcant memory overhead. This problem is referred
as neighborhood explosion [7] and is particularly problematic
in the context of training on memory-constrained GPUs. This
affects both the GNN and the knowledge enhancement layers
that encode binary knowledge. Methods from scalable graph
learning [20], [43], [44] represent potential solutions for the
neighborhood explosion problem in KeGNN.

Furthermore, limitations appear in the context of link predic-
tion with KeGNN. For link prediction, a neural component is
required that predicts fuzzy truth values for binary predicates.
At present, KeGNN can handle clauses containing binary
predicates, but their truth values are initialized with artiﬁcial
predictions, where a high value encodes the presence of an
edge. This limits the application of KeGNN to datasets for
which the graph structure is complete and known a priori.

VI. CONCLUSION

In this work, we introduced KeGNN, a neuro-symbolic
model that integrates GNNs with symbolic knowledge en-
hancement layers to create an end-to-end differentiable model.
This allows the use of prior knowledge to improve node
classiﬁcation while exploiting the strength of a GNN to learn
expressive representations. Experimental studies show that the
inclusion of prior knowledge has the potential to improve
simple neural models (as observed in the case of MLP).
However,
the knowledge enhancement of GNNs is harder
to achieve on the underlying and limited benchmarks for

mode

atten
-tion
heads

batch
size

binary
preacti-
vation

initial
clause
weight

0.001

edges
drop
rate

0.22

KeMLP

PubMed

KeGCN

KeGAT

KeMLP

Flickr

KeGCN

KeGAT

KeMLP

Cora

KeGCN

KeGAT

KeMLP

Citeseer

KeGCN

KeGAT

-

-

8

-

-

8

-

-

1

-

-

3

1024

10.0

full batch

1.0

random 0.66

1024

128

1024

2048

512

512

10.0

10.0

500.0

500.0

10.0

100.0

full batch

1.0

128

full batch

1024

10.0

0.5

0.5

0.5

0.001

0.001

0.1

0.5

0.07

0.2

0.24

0.12

0.47

random 0.17

0.5

0.5

0.25

0.1

0.27

0.01

0.35

0.88

es
pati-
ence

100

10

10

10

10

100

1

1

10

10

10

10

hidden
chan-
nels

256

256

256

32

128

64

32

256

64

256

128

32

learn-
ing
rate

0.057

0.043

0.016

0.001

0.016

norma
-lize
edges

false

false

true

true

true

0.0039

false

0.026

0.032

0.033

0.028

0.037

0.006

true

false

true

true

false

true

KE
layers

hidden
layers

2

1

5

1

4

1

4

2

1

1

3

2

4

2

2

2

4

3

2

2

2

2

5

2

TABLE (III) Hyperparameters and experiment conﬁguration for PubMed and Flickr

which the injection of simple knowledge concerning local
neighborhood is redundant with the representations that GNNs
are able to learn. Nevertheless, KeGNN has not only the
potential to improve graph completion tasks from a perfor-
mance perspective, but also to increase interpretability through
clause weights. This work is a step towards a holistic neuro-
symbolic method on incomplete and noisy semantic data, such
as knowledge graphs.

ACKNOWLEDGMENTS

This work has been partially supported by the MIAI
Knowledge communication and evolution chair (ANR-19-
P3IA-0003).

REFERENCES

[1] W. Liu, Y. Zhang, J. Wang, Y. He, J. Caverlee, P. Chan, D. Yeung, and
P.-A. Heng, “Item relationship graph neural networks for e-commerce,”
vol. PP, 03 2021, pp. 1–15.

[2] A. Sanchez-Gonzalez, N. Heess,

physics

learnable

J. T. Springenberg,

J. Merel,
M. Riedmiller, R. Hadsell, and P. Battaglia, “Graph networks
as
in
Proceedings of the 35th International Conference on Machine Learning,
ser. Proceedings of Machine Learning Research, J. Dy and A. Krause,
PMLR, 10–15 Jul 2018, pp. 4470–4479. [Online].
Eds., vol. 80.
Available: https://proceedings.mlr.press/v80/sanchez-gonzalez18a.html

inference

control,”

engines

and

for

[3] Y. Wu, D. Lian, Y. Xu, L. Wu, and E. Chen, “Graph convolutional
networks with markov random ﬁeld reasoning for social spammer
detection,” vol. 34, no. 01, Apr. 2020, pp. 1054–1061.
[Online].
Available: https://ojs.aaai.org/index.php/AAAI/article/view/5455

[4] X. Yang, M. Yan, S. Pan, X. Ye, and D. Fan, “Simple and efﬁcient
[Online]. Available:

heterogeneous graph neural network,” 2022.
https://arxiv.org/abs/2207.02547

[5] Y. Ma and J. Tang, Deep Learning on Graphs. Cambridge University

Press, 2021.

[6] Z. Wu, S. Pan, F. Chen, G. Long, C. Zhang, and P. S. Yu, “A
comprehensive survey on graph neural networks,” vol. 32, no. 1.
Institute of Electrical and Electronics Engineers (IEEE), jan 2021, pp. 4–
24. [Online]. Available: https://doi.org/10.1109%2Ftnnls.2020.2978386
[7] K. Duan, Z. Liu, P. Wang, W. Zheng, K. Zhou, T. Chen, X. Hu,
and Z. Wang, “A comprehensive study on large-scale graph training:
Benchmarking and rethinking,” in Thirty-sixth Conference on Neural
Information Processing Systems Datasets and Benchmarks Track, 2022.
[8] L. Wu, P. Cui, J. Pei, and L. Zhao, Graph Neural Networks: Foundations,
Frontiers, and Applications. Singapore: Springer Singapore, 2022.

[9] Z. Susskind, B. Arden, L. K. John, P. Stockton, and E. B. John,
“Neuro-symbolic AI: an emerging class of AI workloads and their
characterization,” vol. abs/2109.06133, 2021.

[10] L. De Raedt, S. Dumanˇci´c, R. Manhaeve, and G. Marra, “From statistical
relational to neural-symbolic artiﬁcial intelligence,” in Proceedings of
the Twenty-Ninth International Joint Conference on Artiﬁcial Intelli-
gence, ser. IJCAI’20, 2021.

[11] M. Garnelo and M. Shanahan, “Reconciling deep learning with
symbolic artiﬁcial
intelligence: representing objects and relations,”
vol. 29, 2019, pp. 17–23, artiﬁcial Intelligence. [Online]. Available:
https://www.sciencedirect.com/science/article/pii/S2352154618301943

[12] G. Marra, M. Diligenti, F. Giannini, M. Gori, and M. Maggini,
“Relational neural machines,” in ECAI 2020 - 24th European Conference
on Artiﬁcial Intelligence, 29 August-8 September 2020, Santiago de
Compostela, Spain, August 29 - September 8, 2020 - Including 10th
Conference on Prestigious Applications of Artiﬁcial Intelligence (PAIS
2020), ser. Frontiers in Artiﬁcial Intelligence and Applications, G. D.
Giacomo, A. Catal´a, B. Dilkina, M. Milano, S. Barro, A. Bugar´ın, and
J. Lang, Eds., vol. 325.
IOS Press, 2020, pp. 1340–1347. [Online].
Available: https://doi.org/10.3233/FAIA200237

[13] A. Daniele and L. Seraﬁni, “Neural networks enhancement with logical
knowledge,” https://arxiv.org/abs/2009.06087, 2020, unpublished.
[14] ——, “Knowledge enhanced neural networks for relational domains,” in
AIxIA 2022 – Advances in Artiﬁcial Intelligence, A. Dovier, A. Monta-
nari, and A. Orlandini, Eds. Cham: Springer International Publishing,
2023, pp. 91–109.

[15] E. Grilli, A. Daniele, M. Bassier, F. Remondino, and L. Seraﬁni,
“Knowledge enhanced neural networks for point cloud semantic
segmentation,” vol. 15, no. 10, 2023.
[Online]. Available: https:
//www.mdpi.com/2072-4292/15/10/2590

[16] A. Daniele and L. Seraﬁni, “Knowledge enhanced neural networks,”
in PRICAI 2019: Trends in Artiﬁcial Intelligence, A. C. Nayak and
A. Sharma, Eds. Cham: Springer International Publishing, 2019, pp.
542–554.

[17] P. Veliˇckovi´c, G. Cucurull, A. Casanova, A. Romero, P. Li`o, and
Y. Bengio, “Graph attention networks,” in International Conference on
Learning Representations, 2018.

[18] T. N. Kipf and M. Welling, “Semi-Supervised Classiﬁcation with
Graph Convolutional Networks,” in Proceedings of the 5th International
Conference on Learning Representations, ser. ICLR ’17, 2017. [Online].
Available: https://openreview.net/forum?id=SJU4ayYgl

[19] Z. Yang, W. W. Cohen, and R. Salakhutdinov, “Revisiting semi-
supervised learning with graph embeddings,” in Proceedings of the
33rd International Conference on International Conference on Machine
Learning - Volume 48, ser. ICML’16.

JMLR.org, 2016, p. 40–48.

[20] H. Zeng, H. Zhou, A. Srivastava, R. Kannan, and V. Prasanna, “Graph-
saint: Graph sampling based inductive learning method,” in International
Conference on Learning Representations, 2020.

[40] L. Biewald, “Experiment

tracking with weights and biases,” 2020,
[Online]. Available: https:

from wandb.com.

software
available
//www.wandb.com/

[41] S.

[42] D.

Ioffe

and C. Szegedy,

“Batch normalization: Accelerating
deep network training by reducing internal covariate shift,” in
Proceedings of the 32nd International Conference on Machine Learning,
ser. Proceedings of Machine Learning Research, F. Bach and D. Blei,
Eds., vol. 37. Lille, France: PMLR, 07–09 Jul 2015, pp. 448–456.
[Online]. Available: https://proceedings.mlr.press/v37/ioffe15.html
“Adam: A method

for
Ba,
stochastic optimization,” in 3rd International Conference on Learning
Representations, ICLR 2015, San Diego, CA, USA, May 7-9, 2015,
Conference Track Proceedings, Y. Bengio and Y. LeCun, Eds.,
2015. [Online]. Available: http://arxiv.org/abs/1412.6980

P. Kingma

and

J.

[43] M.

Fey,

F. Weichert,

J. E. Lenssen,

J. Leskovec,
“Gnnautoscale: Scalable
and expressive graph neural networks
via historical embeddings,” in Proceedings of the 38th International
Conference on Machine Learning,
of Machine
Learning Research, M. Meila and T. Zhang, Eds., vol. 139.
PMLR, 18–24 Jul 2021, pp. 3294–3304.
[Online]. Available:
https://proceedings.mlr.press/v139/fey21a.html

ser. Proceedings

and

[44] W. L. Hamilton, R. Ying, and J. Leskovec, “Inductive representation
learning on large graphs,” in Proceedings of the 31st International
Conference on Neural Information Processing Systems, ser. NIPS’17.
Red Hook, NY, USA: Curran Associates Inc., 2017, p. 1025–1035.

[21] H. Caselles-Dupr´e, F. Lesaint, and J. Royo-Letelier, “Word2vec applied
to recommendation: Hyperparameters matter,” in Proceedings of the
12th ACM Conference on Recommender Systems,
’18.
New York, NY, USA: Association for Computing Machinery, 2018, p.
352–356. [Online]. Available: https://doi.org/10.1145/3240323.3240377

ser. RecSys

[22] L. Zadeh, “Fuzzy logic,” Computer, vol. 21, no. 4, pp. 83–93, 1988.
[23] E. Klement, R. Mesiar,

and E. Pap, Triangular Norms,

ser.
Springer Netherlands, 2013. [Online]. Available:

Trends in Logic.
https://books.google.fr/books?id=HXzvCAAAQBAJ

[24] D. Dou, H. Wang, and H. Liu, “Semantic data mining: A survey
of ontology-based approaches,” in Proceedings of the 2015 IEEE 9th
International Conference on Semantic Computing (IEEE ICSC 2015),
2015, pp. 244–251.

[25] C. Meilicke, M. W. Chekol, D. Rufﬁnelli, and H. Stuckenschmidt,
“Anytime bottom-up rule learning for knowledge graph completion,”
in Proceedings of the 28th International Joint Conference on Artiﬁcial
Intelligence, ser. IJCAI’19. AAAI Press, 2019, p. 3137–3143.

[26] Y. Dai, S. Wang, N. N. Xiong,

“A survey
on knowledge graph embedding: Approaches,
and
benchmarks,” Electronics, vol. 9, no. 5, 2020. [Online]. Available:
https://www.mdpi.com/2079-9292/9/5/750

and W. Guo,

applications

[27] R. Abboud and I.

link
prediction on knowledge graphs,” 2021. [Online]. Available: https:
//arxiv.org/abs/2106.07297

I. Ceylan, “Node classiﬁcation meets

[28] S. Badreddine, A. d'Avila Garcez, L. Seraﬁni, and M. Spranger,
“Logic tensor networks,” vol. 303. Elsevier BV, feb 2022, p. 103649.
[Online]. Available: https://doi.org/10.1016%2Fj.artint.2021.103649
[29] L. N. DeLong, R. F. Mir, M. Whyte, Z. Ji, and J. D. Fleuriot,
“Neurosymbolic ai for reasoning on graph structures: A survey,” 2023.
[Online]. Available: https://arxiv.org/abs/2302.07200

[30] W. Li, R. Peng, and Z. Li, “Knowledge graph completion by jointly
learning structural features and soft logical rules,” IEEE Transactions
on Knowledge and Data Engineering, vol. 35, no. 3, pp. 2724–2735,
2023.

[31] N.

Jain, T.-K. Tran, M. H. Gad-Elrab,

and D. Stepanova,
“Improving knowledge graph embeddings with ontological reasoning,”
The Semantic Web – ISWC 2021: 20th International Semantic
in
Web Conference, ISWC 2021, Virtual Event, October 24–28, 2021,
Proceedings. Berlin, Heidelberg: Springer-Verlag, 2021, p. 410–426.
[Online]. Available: https://doi.org/10.1007/978-3-030-88361-4 24
[32] B. Fatemi, S. Ravanbakhsh, and D. Poole, “Improved knowledge graph
embedding using background taxonomic information,” vol. 33, 07 2019,
pp. 3526–3533.

[33] S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo, “Jointly
rules,” in Proceedings
embedding knowledge graphs and logical
of the 2016 Conference on Empirical Methods in Natural Language
Processing. Austin, Texas: Association for Computational Linguistics,
Nov. 2016, pp. 192–202. [Online]. Available: https://aclanthology.org/
D16-1019

[34] Y. Hu, Z. Ye, M. Wang, J. Yu, D. Zheng, M. Li, Z. Zhang, Z. Zhang,
and Y. Wang, “Featgraph: A ﬂexible and efﬁcient backend for graph
neural network systems,” in SC20: International Conference for High
Performance Computing, Networking, Storage and Analysis, 2020, pp.
1–13.

[35] M. Qu, J. Chen, L.-P. Xhonneux, Y. Bengio, and J. Tang, “{RNNL}ogic:
Learning logic rules for reasoning on knowledge graphs,” in Interna-
tional Conference on Learning Representations, 2021.

[36] H. A. Kautz, “The third ai summer: Aaai robert s. engelmore memorial

lecture,” https://onlinelibrary.wiley.com/doi/10.1002/aaai.12036, 2022.

[37] M. Fey and J. E. Lenssen, “Fast graph representation learning with
PyTorch Geometric,” 2019. [Online]. Available: https://arxiv.org/abs/
1903.02428

[38] J. Chen, T. Ma, and C. Xiao, “Fastgcn: Fast

learning with graph
convolutional networks via importance sampling.” in ICLR (Poster).
OpenReview.net, 2018. [Online]. Available: http://dblp.uni-trier.de/db/
conf/iclr/iclr2018.html#ChenMX18

[39] A. Paszke, S. Gross, F. Massa, A. Lerer, J. Bradbury, G. Chanan,
T. Killeen, Z. Lin, N. Gimelshein, L. Antiga, A. Desmaison, A. K¨opf,
E. Yang, Z. DeVito, M. Raison, A. Tejani, S. Chilamkurthy, B. Steiner,
L. Fang, J. Bai, and S. Chintala, “Pytorch: An imperative style,
high-performance deep learning library,” 2019. [Online]. Available:
https://arxiv.org/abs/1912.01703

