Learning to Classify Logical Formulas Based on Their
Semantic Similarity
Ali Ballout, Célia da Costa Pereira, Andrea G. B. Tettamanzi

To cite this version:

Ali Ballout, Célia da Costa Pereira, Andrea G. B. Tettamanzi. Learning to Classify Logical Formulas
Based on Their Semantic Similarity. PRIMA 2022 - Principles and Practice of Multi-Agent Systems
- 24th International Conference, Nov 2022, Valencia, Spain. pp.364-380, ￿10.1007/978-3-031-21203-
1_22￿. ￿hal-03913481￿

HAL Id: hal-03913481

https://inria.hal.science/hal-03913481

Submitted on 27 Dec 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Learning to Classify Logical Formulas based on
their Semantic Similarity

Ali Ballout1, C´elia da Costa Pereira2, and Andrea G. B. Tettamanzi1

1 Universit´e Cˆote d’Azur, CNRS, Inria, I3S, France
ali.ballout@inria.fr, andrea.tettamanzi@univ-cotedazur.fr
2 Universit´e Cˆote d’Azur, CNRS, I3S, France
Celia.DA-COSTA-PEREIRA@univ-cotedazur.fr

Abstract. An important task in logic, given a formula and a knowledge
base which represents what an agent knows of the current state of the
world, is to be able to guess the truth value of the formula. Logic rea-
soners are designed to perform inferences, that is, to decide whether a
formula is a logical consequence of the knowledge base, which is stronger
than that and can be intractable in some cases. In addition, under the
open-world assumption, it may turn out impossible to infer a formula
or its negation. In many practical situations, however, when an agent
has to make a decision, it is acceptable to resort to heuristic methods
to determine the probable veracity or falsehood of a formula, even in
the absence of a guarantee of correctness, to avoid blocking the decision-
making process and move forward. This is why we propose a method to
train a classification model based on available knowledge in order to be
able of accurately guessing whether an arbitrary, unseen formula is true
or false. Our method exploits a kernel representation of logical formulas
based on a model-theoretic measure of semantic similarity. The results
of experiments show that the proposed method is highly effective and
accurate.

1

Introduction and Related Work

A defining feature for intelligent agents is their ability to reason, that is to draw
logical conclusions from the available premises, which constitute their knowl-
edge [3, 5]. While this capability is very important, an equally important and
useful, but weaker, capability for an agent would be to be able to recognize if
a given formula is likely to be true or false, given the current knowledge, in the
current state of the world, even though not necessarily in general.

As a matter of fact, we often experience situations where our incomplete
knowledge would not allow us to make exact inferences, yet this does not prevent
us to make decisions, because even when we don’t know a fact that we need in
order to move forward, we are able to make an educated guess (i.e., a prediction
based on what we already know) about the veracity of that fact and proceed
with our decision making.

It is this weaker task that we are interested in studying here. We propose
a simple but effective idea, which is to train a classifier against the knowledge

base of the agent, which may be viewed as a set of formulas labeled with their
truth value. The formulas are represented as vectors of similarities to the labeled
formulas; to this end, we propose a model-theoretic semantic similarity measure
which can be computed efficiently. This kernel-representation and its associated
similarity measure are the key ingredients of our proposal.

Recently, a rise of interest in developing connectionist methods for reasoning
can be observed, with proposals such the so-called Logic Tensor Networks [4], or
the Logic-Integrated Neural Network [14] to integrate the power of deep learn-
ing and logic reasoning, or approaches that employ state-of-the-art methods for
training deep neural networks to learn to perform some basic ontology reasoning
tasks [11]. As a further witness of the attention this research field is attracting,
some conferences are beginning to feature tutorials on it, like KDD’21 [15] and
there is even an upcoming Dagstuhl seminar on “Machine Learning and Logical
Reasoning: The New Frontier”.3

Unlike these approaches, what we propose does not require sophisticated neu-
ral architectures or resource-intensive deep learning; in addition, we do not attack
the more ambitious challenge of logical deduction, but just that of heuristically
guessing (as human beings do), the truth value of a formula, independently of
its being logically entailed by the available knowledge.

Actually, what people do in case of incomplete knowledge is to somehow mea-
sure the similarity between known/familiar situations and unknown/unfamiliar
situations [16]. Several cognitive tasks, such as learning and interpolation re-
quire the concept of similarity to be performed [9]. There exists a vast litera-
ture on similarity measures, with many proposal arising in the field of machine
learning [7]. However, it appears that the problem of measuring the similarity
of logical formulas has been less investigated and, when it has, that’s often in
relation with specific contexts.

While not directly addressing the problem of defining similarity among logical
formulas, Bowles [6] studies the nature of relevance and irrelevance of a propo-
sition with respect to another. His work shares with the definition of semantic
similarity that we propose here, a basic intuition, which is that the probability
that one proposition is true given that another one is true should play a central
role. The definition of relevance proposed by Makinson in [13], instead, is not
in line with what we are proposing here because it is defined in terms of letter-
sharing. A way of measuring the similarity of a Boolean vector to a given set of
Boolean vectors, motivated in part by certain data mining or machine learning
problems, was proposed by Anthony and Hammer [2]. A similarity measure for
Boolean function was proposed by Fiˇser et al. [10] in a quite different context,
that of circuit synthesis, which explains the differences with our proposal. One
measure of similarity between functions is the existence of a Lipschitz mapping
(with small constant) between them [12]. A problem somehow related to the one
we are dealing with is the problem of measuring the similarity between logical
arguments, which has been studied by Amgoud and David [1].

3 Dagstuhl Seminar 22291, July 17–22, 2022.

2

Through an empirical validation we show that the framework we propose
allows a number of quite standard and unsophisticated classification techniques,
like support-vector machines, to learn very accurate models that are capable of
“guessing” whether a given, unseen formula is true or false in the current state
of affairs, without the need to perform any logical deduction.

The rest of the paper is structured as follows: Section 2 states the problem
of formula classification; Section 3 defines a semantic similarity measure for
formulas that is the cornerstone of the proposed approach. Section 4 provides
an empirical validation of the approach and Section 5 draws some conclusions
and suggestions for future work.

2 Problem Statement

Let Φ be a set of formulas in a logical language L and let I be an interpretation,
which represents a particular state of affairs or the current state of the world.
Under interpretation I, the formulas in Φ may be labeled as being true or false.
One could thus construct a table






ϕ1, ϕI
1
ϕ2, ϕI
2
...
...




 ,

where ϕi ∈ Φ ⊂ L, for i = 1, 2, . . . , and ϕI
is the truth value of ϕi according to
i
interpretation I. This table can be viewed as a representation of a knowledge
base K consisting of all the formulas ϕi ∈ Φ such that ϕI
i = T and all the
formulas ¬ϕi ∈ Φ such that ϕI
i = F . K represents what an agent knows (or
believes) about the current state of affairs but, of course, I, the actual state of
affairs, is not known in full, which is like saying that the open world hypothesis
holds.

Consider now the problem of guessing or predicting whether a new formula
ψ /∈ Φ is true or false in I, given K. To be sure, one could use a reasoner
to check whether K ⊢ ψ or K ⊢ ¬ψ. If the reasoner is sound and complete,
this can even allow one to decide whether K |= ψ or K |= ¬ψ. However, even
in cases where K ̸|= ψ and K ̸|= ¬ψ, which are entirely possible in an open
world, it would be useful for an agent to be able to make educated guesses at
the truth value of ψ. By an educated guess we mean a prediction, based on the
truth values of the formulas the agent already knows. If a model to make that
type of predictions existed and were fast and accurate enough, the agent might
even used it instead of the reasoner, for time-critical tasks where having a quick
answer is more important than having an answer that is guaranteed to be always
correct.

What we have just described is a classification problem, where given a set
of labeled examples (here, formulas with their truth value), a model is sought
for that is able to accurately predict the label of an unseen case (i.e., a new
formula).

3

To solve this problem, we propose to use a kernel representation, i.e., to
represent formulas as vectors of similarities to a restricted set of formulas
whose label is already known (Φ) and to train a classification model on these
labeled examples, later to be used to classify new, unseen formulas. To this aim,
we will stick to very standard and unsophisticated classification methods.

3 Semantic Similarity

We need to define similarity among logical formulas. It is quite obvious that
such a similarity should not be based on syntax, due to the fact that formulas
with widely different syntactical forms may be equivalent. Now, the semantics
of logical formulas is defined in model-theoretic terms. What we are looking for
is, therefore, a model-theoretic notion of formula similarity.

To keep technical complications at a minimum and without loss of generality,
let us consider propositional logic. As a matter of fact, more expressive logical
languages can be mapped to the propositional case (e.g., description logics and
first-order logic under the Herbrand semantics).

Definition 1 (Language) Let A be a finite set of atomic propositions and let
L be the propositional language such that A ∪ {⊤, ⊥} ⊆ L, and, ∀ϕ, ψ ∈ L,
¬ϕ ∈ L, ϕ ∧ ψ ∈ L, ϕ ∨ ψ ∈ L.

Additional connectives can be defined as useful shorthands for combination

of connectives of L, e.g., ϕ ⊃ ψ ≡ ¬ϕ ∨ ψ.

We will denote by Ω = {0, 1}A the set of all interpretations on A, which we
may also call the “universe”. An interpretation I ∈ Ω is a function I : A → {0, 1}
assigning a truth value pI to every atomic proposition p ∈ A and, by extension,
a truth value ϕI to all formulas ϕ ∈ L; I |= ϕ means that ϕI = 1 (I is a model
of ϕ); if S ⊆ L is a set of formulas, I |= S means I |= ϕ for all ϕ ∈ S; S |= ϕ
means that ∀I |= S, I |= ϕ. The notation [ϕ] denotes the set of all models of
formula ϕ ∈ L: [ϕ] = {I ∈ Ω : I |= ϕ}. The semantics of a formula ϕ ∈ L is the
set of its models, [ϕ].

We might begin by defining the semantic distance between two formulas ϕ
and ψ as the Hamming distance between the two binary string that represent
their respective sets of models:

d(ϕ, ψ) =

[ϕI ̸= ψI],

(cid:88)

I∈Ω

(1)

where [expr] denotes the indicator function, which equals 1 if expr is true and 0
otherwise.

According to this definition, d(ϕ, ¬ϕ) = ∥Ω∥ and d(ϕ, ϕ) = 0, which is in good
agreement with our intuition. Also, two formulas that are totally unrelated,4 like,

4 Two formulas may be said to be totally unrelated if knowing the truth value of one

does not give any information about the truth value of the other.

4

say, p and q, where p, q ∈ A, will have a distance which is half-way in between
these two extreme cases, d(p, q) = 1

2 ∥Ω∥.

One problem with this notion of distance is that the distance between two
given formulas depends on the number of propositional constants in the language,
which is a little counter-intuitive. For instance, d(p, q) = 2 if A = {p, q}, but
d(p, q) = 4 if A = {p, q, r}, and so on. In addition, to compute it, we have to
consider all interpretations in Ω, even though many of them might be indifferent
when it comes to two given formulas: for example, pqr and pq¯r are indifferent
when comparing p to q.

The former problem disappears if, instead of a distance, we define a similarity,

ranging between 0 and 1 based on the same idea, as follows:

sim(ϕ, ψ) =

1
∥Ω∥

(cid:88)

I∈Ω

[ϕI = ψI].

(2)

The latter problem is also solved by defining Aϕ ⊆ A as the set of atoms that
occur in formula ϕ and by letting Ωϕ,ψ = 2Aϕ∪Aψ ; Equation 2 can now be
rewritten as

sim(ϕ, ψ) =

1
∥Ω∥

(cid:88)

I∈Ω

[ϕI = ψI] =

1
∥Ωϕ,ψ∥

(cid:88)

[ϕI = ψI].

(3)

I∈Ωϕ,ψ

According to this definition, for all formula ϕ ∈ L, sim(ϕ, ϕ) = 1, sim(ϕ, ¬ϕ) = 0
and, no matter how many atoms are involved, if Aϕ ∩ Aψ = ∅, sim(ϕ, ψ) = 1
2 .

Another interesting property of this semantic similarity is the following,

which ensures that the proposed similarity is consistent with logical negation.

Theorem 1. Let ϕ ψ be any two formulas of L. Then

sim(ϕ, ψ) = 1 − sim(¬ϕ, ψ).

Proof. For all interpretation I, ϕI = ψI ⇔ ¬ϕI ̸= ψI and ϕI ̸= ψI ⇔ ¬ϕI =
ψI. Therefore, {I : ϕI = ψI} = {I : ¬ϕI ̸= ψI} = Ω \ {I : ¬ϕI = ψI} and we
can thus write

sim(ϕ, ψ) =

=

1
∥Ω∥

1
∥Ω∥

[ϕI = ψI] =

1
∥Ω∥

(cid:88)

I∈Ω

∥{I : ϕI = ψI}∥

∥Ω \ {I : ¬ϕI = ψI}∥ =

∥Ω∥
∥Ω∥

−

1
∥Ω∥

∥{I : ¬ϕI = ψI}∥

= 1 −

1
∥Ω∥

(cid:88)

I∈Ω

[¬ϕI = ψI] = 1 − sim(¬ϕ, ψ).

⊓⊔

Another interesting property of the semantic similarity, as we have defined
it, is that, if Ωϕ,ψ is too large, we are not obliged to perform an exact com-
putation of sim(ϕ, ψ), but we can approximate it with acceptable accuracy by
randomly sampling n interpretations from Ωϕ,ψ and counting for how many of

5

them ϕI = ψI. Indeed, sim(ϕ, ψ) may be construed as a probability, namely the
probability that, in a random interpretation, ϕ and ψ are both true or both false.
What we get is an unbiased estimator of sim(ϕ, ψ), which behaves like a bino-
mial parameter ˆsϕ,ψ, whose confidence interval is given by the Wald confidence
interval, based on the asymptotic normality of ˆsϕ,ψ and estimating the standard
error. This (1 − α) confidence interval for sim(ϕ, ψ) would be

ˆsϕ,ψ ± zα/2

(cid:113)

ˆsϕ,ψ(1 − ˆsϕ,ψ)/n,

(4)

where zc denotes the 1 − c quantile of the standard normal distribution.

For example, if we set n = 30, with a 99% confidence, the actual similarity
will be within a deviation of 2.576(cid:112)1/120 = 0.2351 from ˆsϕ,ψ, in the worst case,
which corresponds to ˆsϕ,ψ = 0.5; for n = 100, the approximation error will be
less than 0.1288 and for n = 1000 it will be less than 0.0407. As a matter of fact,
a precise computation of the similarity between formulas is not really required
for the proposed approach to work.

This also suggests a way to deal with non-finite interpretations, which might

arise in expressive languages involving variables and functions.

4 Experiments and Results

4.1 An Example from the Block World

As a first test and example of our proposal, we define a language with four
individual constants, A, B, C, Table, one unary predicate, covered(·), and one
binary predicate on(·, ·). The Herbrand base of this language is finite and consists
of twenty ground atoms, but we can only consider a subset of it, after dropping
atoms like on(A, A), covered(Table), and on(Table, A), which would always be
false in every state of the block world:

A12 = { covered(A), on(A, B), on(A, C), on(A, Table),
covered(B), on(B, A), on(B, C), on(B, Table),
covered(C), on(C, A), on(C, B), on(C, Table) }.

Notice that, given this A12, ∥Ω12∥ = 212 = 4, 096. By adding another block D
to this world we can obtain a larger set of atoms

A20 = { covered(A), on(A, B), on(A, C), on(A, D), on(A, Table),
covered(B), on(B, A), on(B, C), on(B, D), on(B, Table),
covered(C), on(C, A), on(C, B), on(C, D), on(C, Table),
covered(D), on(D, A), on(D, B), on(D, C), on(D, Table) },

of size 20, with ∥Ω20∥ = 220 = 1, 048, 576, and, similarly, by adding a further
block E, a set A30 of 30 atoms, with ∥Ω30∥ = 230 = 1, 073, 741, 824.

The language may then be completed by a minimal set of logical operators,

¬, ∧, ∨. Then we select a reference interpretation, for example

I ∗
12 = {on(A, Table), on(C, Table), on(B, A), covered(A)},

6

corresponding to a given state of a very simple block world containing one table
and three blocks, arranged as in Figure 1a.

B

A

C

B

A

D

C

B

A

(a)

(b)

D

C

(c)

E

Fig. 1: The three block worlds corresponding to the reference interpretations,
20, and (c) to I ∗
respectively, (a) to I ∗
30.

12, (b) to I ∗

We then generate a set Φ of random logical formulas and we assign them a

truth label based on I ∗ and train various models on it.

4.2 Experimental Protocol

The experiment was divided into two parts. In the first part, we created 3
datasets, each of which is based on a different universe generated using the
language explained in Section 4.1. The universes are depicted in Figure 1. We
used these sets to test the performance of models learned using our proposed
similarity measure. We considered different universe complexities and used very
small training sets to simulate a realistic scenario. For this part, no sampling
was done, all interpretations in Ωϕ,ψ were considered as per Equation 3. This
can be very time-consuming when the two formulas involve many atoms. For
the second part, we created 3 additional sets for each of the universes used in
the first part. These additional sets contain the exact same formulas as those in
the first part, the only difference being the way the similarity was calculated. To
investigate what we mentioned in Section 3 regarding the ability to approximate
the similarity with acceptable accuracy by randomly sampling n interpretations,
we approximated the similarities for each of the 3 additional sets using n = 30,
n = 100, and n = 1000 respectively. We then compared the performance of each
of these sets with the base one created in the first part.5

Part One: Baseline Experiment. To see how the proposed method performs,
we created the 3 universes depicted in Figure 1, and denoted by Ω12, Ω20, and
Ω30. The universes consist of 12, 20, and 30 atoms respectively (sets A12, A20,
and A30 as defined above). The following are the reference interpretations:

5 All the code and data used for the experiments described in this paper can
https://github.com/ali-ballout/

be
Learning-to-Classify-Logical-Formulas-based-on-their-Semantic-Similarity.

found in the

repository:

following

7

– I ∗
– I ∗

12 = {on(A, Table), on(C, Table), on(B, A), covered(A)}, cf. Figure 1a;
20 = {on(A, Table), on(C, Table), on(B, A), on(D, C), covered(A), covered(C)},

cf. Figure 1b;

– I ∗

30 = {on(A, Table), on(C, Table), on(E, Table), on(B, A), on(D, C), covered(A),

covered(C)}, cf. Figure 1c;

Following that, we generated 500 random formulas for each of the universes
using Algorithm 1. Algorithm 1 generates a given number N of random formulas,
taking as input a list of ground atoms A. It is recursive and chooses its next
step and which symbols to add at random. It uses a variable that reduces the
probability of adding a nested subformula the more complex a formula becomes.
We then labeled each of the formulas with its truth, based on the reference
interpretation of its universe. The next step was to create the similarity matrix
for each set of formulas. For this part, no sampling was done, in other words
all interpretations were taken into account and no noise was added. The simi-
larity between each formula and all other formulas in the set is calculated using
Equation 3. To simplify, we compare formula ϕ to all other formulas in the set
of 500 formulas. At each comparison we check all the unique atoms included
in the compared formulas ϕ and ψ, for an example of what atoms are refer to
A12 in Section 4.1. We then generate all interpretations for this set of unique
atoms extracted from both formulas. Then we record the truth for each of the
formulas based on each of the generated interpretations. After that, we count
the instances where the truth of formulas ϕ and ψ are the same. We divide that
number by the total number of generated interpretations and the result obtained
is the similarity between ϕ and ψ. We do this, once, for all pairs of formulas to
obtain a symmetric similarity matrix of the shape 500×500. Figure 2 depicts the

T ruth F ormula
T ruth0
T ruth1
...

ϕ0
ϕ1
...

ϕ0
1
S1,0
...

ϕ1
S0,1
1
...

. . .
ϕm
. . . S0,m
. . . S1,m
...
. . .

T ruthm−1 ϕm−1

Sm−1,0 Sm−1,1 . . . Sm−1,m

T ruthm

ϕm

Sm,0

Sm,1

. . .

1

Fig. 2: Formula similarity matrix with truth labels.

similarity matrix between formulas of a set of formulas of size m with S being
the similarity between each pair. The diagonal is all 1 since it is the similarity
between a formula ϕ and itself. The truth labels of all the formulas are attached
as column Truth to the similarity matrix to obtain the final product of the pro-
cess, which is the input to be used for training and testing a machine learning
model.

Now that we have created our labeled datasets, we need to choose a machine
learning method that is suitable for the task. Through a process of model selec-

8

tion we decided to use a support vector classifier, it performed the best with the
small training sets that we provided. After performing a grid search we deter-
mined the best hyper parameters, we set the regularization parameter C to 0.1
and the kernel type to polynomial, of degree 3. We ran, for each of the 3 datasets,
a 20-fold cross validation processes to establish the baseline performance of our
proposed method. All results presented in Table 1 are averages of the scores
obtained from all the runs for each dataset. Similarly, confusion matrices dis-
played in Figure 3 are the result of summing up all confusion matrices of the 20
runs and then normalizing them. We set the number of formulas included in the
training sets of each universe to less than or equal to ∥A∥ of said universe, the
training set sizes were as follows: 10 for Ω12, 20 for Ω20, and 30 for Ω30. Table 2
presents the labeled formulas used in the training set of one of the runs for Ω12.

No agent, human or artificial, has in its knowledge the exhaustive list of all
possible formulas. The rationale for using small training sets in our experiments
is that the knowledge base of an agent is unlikely to contain many formulas;
some of them might be handcrafted and be part of the “background knowledge”
of the agent, and the others acquired through sensors or messages received from
other agents. In any case, it is a principle of economy that the knowledge of an
agent be encoded using as few and as simple formulas as required. We want to
test our proposal against a realistic scenario in which the available knowledge
(the formulas whose truth value is known) is very small compared to the number
of semantically distinct formulas that can be stated in the language. This also
has the advantage of demonstrating the generalization capability of our models.

Notice that, for a language whose set of interpretations is Ω, there are 2∥Ω∥
semantically distinct formulas, which is a really huge number, although most of
them would be very complicated formulas that one would not expect to find in
a real knowledge base. However, even factoring out very complicated formulas,
the number of possible formulas would be exceedingly large.

To be sure, there exists a choice of formulas that would make the problem
we are studying absolutely trivial. That is when the training set contains at
least ∥A∥ formulas, each consisting of a single literal (i.e., a positive or negated
atom), such that the atoms of these formulas are all distinct. It is easy to see
that those formulas, with their truth labeling, would directly give the reference
interpretation, from which the truth value of any other formula can be mechan-
ically computed in linear time with respect to the length of the formula, without
performing any logical deduction or reasoning.

This is the reason why the formulas of each dataset are extracted from a
distribution that is skewed in favor of simpler (i.e., realistic), but not too simple
formulas. Indeed, we ensure that the training set does not contain literals for
all the atoms, by counting the number of literals that are randomly generated
and rejecting additional literals once the maximum number of literals has been
reached. That maximum is set to ∥A∥/2, well below ∥A∥.

9

Since the dataset consists of randomly generated formulas, it is unbalanced,6
so in addition to the accuracy score, which we report because it gives an intu-
itive idea of the probability that the prediction is correct, we will provide the
Matthews correlation coefficient (MCC) which is a statistical rate between −1
and 1 that produces a high score only if the prediction obtained good results in
all of the four confusion matrix categories (true positives, false negatives, true
negatives, and false positives), proportionally both to the size of positive ele-
ments and the size of negative elements in the dataset. So its a very good metric
when we don’t have a perfectly balanced dataset [8]. Results of this part of the
experiment are presented in Table 1.

Algorithm 1 Generating random formulas

Require: A set of atoms A
Ensure: f ormulas, a list of generated formulas

N ← N umber of random f ormulas to generate
f ← one randomly generated f ormula
literals ← 0
for i = 1 → N do

▷ A counter used to limit the number of literals as sentences

i ← i + 1
f ← random formula(A, 0)
if f in f ormulas then

i = i − 1
continue

else if length(f.symbols) == 1 then
if literals < length(A)/2 then

literals = literals + 1

else

i = i − 1
continue

end if

else

f ormulas.append(f )

end if

end for

function random formula(A, level)

▷ Recursive; the nesting level, initially = 0, is used to progressively reduce the probability of

adding nested subformulas

if randrange(level + 4) then

return choice(A)

end if
if randrange(3) = 0 then

return ¬random formula(A, level + 1)

end if
return random formula(A, level + 1) · choice(∧, ∨)·

random formula(A, level + 1)

▷ level+3

level+4 probability of stopping

▷ with probability 1
3

end function
Note: The generation process is slightly biased towards sentences that are neither too simple, nor
too complex.

6 The dataset for universe Ω12 has 272 false formulas and 227 true ones (1 missing
because it was a duplicate), for universe Ω20 278 false and 222 true, and for universe
Ω30 300 false and 200 true; of course, these figures vary (between training and test
set) for every fold obtained from these datasets.

10

Algorithm 2 Approximating the similarity by sampling interpretations

Require: 2 formulas ϕ and ψ to be compared
Require: a sample size n
Ensure: ϕ and ψ, in the same universe Ω
Ensure: n > 0

A ← ϕ.atoms ∪ ψ.atoms
interpretations ← Sample interpretations(A, n)
counter ← 0
for w in interpretations do

if ϕ.truth(w) == ψ.truth(w) then

counter ← counter + 1

end if

end for
ˆsϕ,ψ ← counter

n

function Sample interpretations(A, n)
interpretations ← array(size = n)
for i = 0 → n − 1 do

b ← array(size = A.length)
for j = 0 → A.length − 1 do
b[j] ← randrange(2)

end for
interpretations[i] ← b

end for
return interpretations

end function

▷ Array to store n interpretations

▷ Array the size of the list of atoms

Part Two: Sampling Experiment. In this part of our experiment we inves-
tigate a property of our proposed similarity, which is the ability to approximate
sim(ϕ, ψ) with acceptable accuracy by randomly sampling n interpretations from
Ωϕ,ψ. We will name this approximation ˆsϕ,ψ.

To this end, we created 3 new matrices for each set of formulas used in Sec-
tion 4.2. We ended up with 9 new datasets, 3 for each of the universes depicted
in Figure 1 and describe in Section 4.2. The similarity in the 9 new matrices was
calculated differently than in Section 4.2. For this part, we approximated the
similarity between formulas by randomly sampling a set number n of all inter-
pretations, instead of taking all of them into account as we did in Section 4.2.
The number of random samples n considered for creating the matrices is n = 30,
n = 100, and n = 1000. This allows us to simulate the scenario of having a ma-
chine with low computational capacity trying to process a set of interpretations
that is too large, and utilizing sampling as a solution. It also allows us to see
how the method performs when noise is introduced.

The way the similarity is approximated using sampling is not much different
from how it is calculated: we still count the instances where formulas ϕ and
ψ have the same truth, but for n randomly sampled interpretations instead of
all interpretations. Algorithm 2 is used to approximate the similarity between
two formulas. In simple terms, when Algorithm 2 compares two formulas ϕ and
ψ, instead of generating all interpretations corresponding to the set of unique
atoms A composing those formulas, it generates a number n of these interpre-
tations randomly. This sampling is done with replacement, which means that it
is possible that a given interpretation gets sampled multiple times, especially in
case n is larger than the number of all interpretations. We then proceed to count

11

the instances where formulas ϕ and ψ have the same truth out of these sampled
interpretations. After that, we divide the obtained number by n, the size of the
sample, since we are now dealing with n interpretations and not all of them. The
result from that division is the approximation ˆsϕ,ψ of the similarity sim(ϕ, ψ)
between ϕ and ψ. We do this for the sets of formulas we randomly generated in
Section 4.2 for each of our universes 3 times, once for each number n of samples
we mentioned.

With these 9 new matrices we are able to study how the sample size n
might affect the performance of the method when dealing with different universe
complexities. It will also show us how well an approximation of the similarity
performs. We used the same model to test the performance and the same scoring
metrics as the baseline. We used the same training set sizes for each universe
as in the baseline. The results of this part of the experiment are available in
Table 1.

Universe

Training set Size

sample size

Accuracy score MCC

Ω12

Ω20

Ω30

10

20

30

no sampling

30

100

1000

no sampling

30

100

1000

no sampling

30

100

0.77

0.76

0.77

0.77

0.81

0.81

0.82

0.82

0.83

0.79

0.82

0.56

0.54

0.56

0.55

0.63

0.62

0.63

0.65

0.66

0.56

0.62

1000
Table 1: Accuracy and MCC for experiments done on each universe.

0.64

0.83

4.3 Results and Analysis

Baseline Results We start our analysis with the first part of our experiment,
detailed in Section 4.2. The results can be found in Table 1 and the corresponding
confusion matrices to offer support in Figure 3. A small sample of formulas from
the test set for the smallest universe, with the labels predicted by the model, is
provided in Table 3. From this experiment we can determine:

1. The overall performance of our proposed method without sampling while
dealing with universes of different complexities, using very small training
sets.

12

2. The effect the training set size has on performance with respect to the com-

plexity of the universe addressed.

Regarding the first, Table 1 shows that the overall performance of our pro-
posed method is good. The highest accuracy achieved was 83% for a training
set size of 30 formulas and a universe of complexity 30, MCC being 0.66 which
is a very good result when training using an unbalanced set. As a worst case,
the method achieved 77% accuracy with a minimal training set size of 10 for-
mulas and universe complexity of 12, MCC of 0.56 is acceptable considering the
small training set relative to the complexity of the universe. Indeed, 30 formu-
las for a language with 30 propositional symbols is a really sparse training set,
when one thinks that this language has ∼ 109 interpretations and there exist
∼ 10300,000,000 semantically distinct formulas one can construct!

Formula

(on(C, B) ∧ on(B, C)) ∨ (¬¬¬¬on(A, B) ∨ on(B, A))

¬(¬(on(A, B) ∧ ((on(C, T bl) ∨ ¬¬on(C, B)) ∧ covered(A))) ∨ (on(C, A) ∨ on(B, C)))

¬(((covered(B) ∨ ¬on(B, A)) ∨ (on(B, T bl) ∧ (on(B, A) ∧ on(C, A)))) ∧ covered(B))

¬¬¬on(A, C)

(on(B, C) ∨ covered(A)) ∨ covered(A)

¬(¬on(A, C) ∧ ¬covered(C))

(on(A, C) ∨ on(C, A)) ∧ ¬(covered(C) ∧ on(A, T bl))

on(C, T bl) ∧ on(C, B)

on(C, B) ∨ on(B, C)

¬on(C, B) ∧ (¬¬¬on(C, B) ∧ covered(B))

Label

True

False

True

True

True

False

False

False

False

False

Table 2: A sample training set made of 10 formulas from universe Ω12.

After demonstrating that our proposed method is capable of achieving good
results with very small training sets, we move on to the second point. We can see
that the proposed method can achieve an average accuracy of 80% throughout
the runs that use a very small training set of 10 formulas for Ω12, 20 formulas for
Ω20, and 30 formulas for Ω30. It would be natural to think that as the universe
complexity increases, a model would require a larger training set to maintain
performance, which is what the results shown in Table 1 and Figure 3 confirm.
From the results see in Table 1 where no sampling was considered, we can see
that increasing the number of formulas included in the training set had a very
significant effect on performance. This effect was not limited to maintaining
performance, but it resulted in an improvement of up to 8% in accuracy and
0.14 in terms of MCC.

To put things into perspective, for Ω12 we used for training 10 formulas
out of a possible ∼ 101233 compared to 30 out of a possible ∼ 10300,000,000 for

13

Formula

¬(¬(¬(on(B, A) ∧ covered(B)) ∨ ((covered(C) ∨ on(A, )B) ∧
on(C, T bl))) ∨ ¬((on(B, A) ∧ on(A, T bl)) ∧ ¬covered(A)))

Actual

Predicted

False

False

(on(A, T bl) ∧ on(B, A)) ∨ ¬¬((on(A, C) ∧ ((on(A, T bl) ∨
covered(A)) ∧ covered(A))) ∨ on(C, B))

True

True

covered(B) ∧ on(A, T bl)

((covered(B) ∨ (¬on(A, B) ∧ on(C, T bl))) ∧ (((on(B, A) ∧
(on(A, C)∧on(C, T bl)))∨(on(C, A)∨on(A, T bl)))∧on(A, T bl)))∨
on(C, A)

((covered(A) ∧ covered(B)) ∨ (covered(A) ∨ ¬(((covered(A) ∨
on(B, C))∨(on(B, C)∧on(B, T bl)))∨on(C, A))))∨((on(B, A)∨
on(A, C)) ∧ (((on(C, T bl) ∧ on(B, C)) ∧ on(A, C)) ∧ covered(A)))

False

True

True

True

True

True

covered(B) ∧ (((on(C, B) ∨ ((on(C, B) ∧ on(B, T bl)) ∧
((¬covered(B) ∨ (on(A, B) ∧ ¬on(A, C))) ∨ (¬¬on(B, C) ∧
(covered(C) ∨ on(A, B)))))) ∨ covered(C)) ∧ (¬(on(A, C) ∨
on(B, C))∧((covered(A)∨on(C, B))∨(on(A, T bl)∧(on(A, T bl)∨
on(C, B))))))
Table 3: A small sample of the test set with formulas varying in complexity from
universe Ω12.

False

False

Ω30. In other words, the transition from Ω12 with 4096 interpretations to Ω30
with ∼ 109, resulted in a gain of 8% accuracy by just adding 20 formulas to
the training set. The increase in the size of the training set is modest relative
to the size of Ω30 or the number of semantically distinct formulas that can be
constructed, while the gain of accuracy and balance in predictions in terms of
MCC is significant.

We observed that the truth value of “simple” formulas turns out to be harder
to predict for the trained models than that of “complicated” formulas (see, e.g.,
Table 3). While this must have to do with the geometry of the space of the kernel
representation of formulas induced by the semantic similarity, this phenomenon
will have to be the object of further investigation.

Sampling Results We now shift our attention to part two of the experiment
detailed in Section 4.2. The results of this experiment are also shown in Table 1
and the corresponding confusion matrices to offer support are found in Figure 3.
At first glance at Table 1, we can tell that the overall performance of the
model does not degrade much when the similarity is approximated using the
lowest number of samples n = 30. Indeed, we have a loss of accuracy of almost
4% for 2 of our universes. But this is an acceptable result when considering that
in this case we would no longer have to calculate the exact similarity especially
when we are limited by computational power. In fact, in this case, we would be
looking at 30 random interpretations instead of ∼ 109 for a universe the size of
Ω30.

14

The degradation in accuracy and MCC decreases as we increase the num-
ber of samples from 30 to 100 and then to 1000, it even approaches baseline
performance. This proves what we mentioned in Section 3, we are able to ap-
proximate the similarity with very high accuracy even with a low number of
sampled interpretations when compared to the number of all interpretations.

On the other hand, another increase in the number of samples from 100 to
1000 has no significant effect on performance, which is interesting considering
that this introduces noise (since we allow for repetitions) yet it does not degrade
performance. It also means that for a universe of complexity ∥A∥ there exists
an optimal number of samples n that achieves baseline-similar performance.

(a) Ωbase

12

(b) Ω30
12

(c) Ω100
12

(d) Ω1000

12

(e) Ωbase

20

(f) Ω30
20

(g) Ω100
20

(h) Ω1000

20

(i) Ωbase

30

(j) Ω30
30

(k) Ω100
30

(l) Ω1000

30

Fig. 3: Confusion matrices of the similarity approximation using sampling experiment for each
universe. Each row represents 4 cases for each universe, starting with the baseline (no sampling)
and then n = 30, n = 100, and n = 1000 respectively. Each sub-figure is captioned by the universe
notation Ω12,20,30 and in superscript the sample size n used to approximate similarity.

5 Conclusion

We have proposed a framework that allows an agent to train, based on a set of
formulas whose truth values are known, a classification model that predicts the
truth-value of a new, arbitrary formula. This framework uses a semantic simi-
larity between formulas, which is a key ingredient of our proposal, to perform

15

a kernel encoding of the formulas, which is then exploited by the classification
model. We have tested an implementation of this framework using SVM, showing
that the classification model is highly accurate (with accuracy around 80%) even
when the similarity is approximated by severely undersampling the interpreta-
tions. The practical implications of these results are that the proposed approach
is tractable even for languages with a large (or infinite but enumerable) number
of atoms; indeed, computing a good approximation of the similarity of two for-
mulas can be done in linear time, as it depends only on the size of the (random)
interpretations sampled.

There is no guarantee that all the predictions made by a model be altogether
consistent. There is no built-in mechanism to ensure that and the mutual consis-
tency of all the prediction is not part of the measure of the quality of a classifier:
every prediction is made by the model and assessed independently of the oth-
ers. Of course, if the predictions were all correct, they would also be consistent
and that’s what we observe empirically, that the predictions tend to be mostly
consistent.

Since the knowledge of an agent may not be complete, some formulas, which
are not entailed by it and whose negation is not entailed either, both predictions
would be acceptable, and one might be tempted to count them as correct. How-
ever, this is not what we did: for the purpose of testing our method, what we did
was to arbitrarily fix one interpretation and say it corresponded to the actual
state of affairs; use it to label the training set and evaluate the predictions of the
classifiers against the label that would be thus assigned, even for those formulas
whose truth value is not constrained by the available knowledge. In a sense, we
were as strict as one can be when judging a classifier.

Future work might involve testing other more sophisticated classification

methods and applying the proposed framework to real-world scenarios.

Acknowledgments

This work has been partially supported by the French government, through
the 3IA Cˆote d’Azur “Investments in the Future” project managed by the Na-
tional Research Agency (ANR) with the reference number ANR-19-P3IA-0002,
as well as through the ANR CROQUIS (Collecte, repr´esentation, compl´etion,
fusion et interrogation de donn´ees de r´eseaux d’eau urbains h´et´erog`enes et in-
certaines) project, grant ANR-21-CE23-0004 of the French National Research
Agency (ANR).

References

1. Amgoud, L., David, V.: Measuring similarity between logical arguments. In:
Thielscher, M., Toni, F., Wolter, F. (eds.) Principles of Knowledge Representa-
tion and Reasoning: Proceedings of the Sixteenth International Conference, KR
2018, Tempe, Arizona, 30 October - 2 November 2018. pp. 98–107. AAAI Press
(2018)

16

2. Anthony, M., Hammer, P.L.: A boolean measure of similarity. Discrete Applied

Mathematics 154(16), 2242–2246 (November 2006)

3. Antoniou, G., Ghose, A.: What is default reasoning good for? applications revisited.
In: 32nd Annual Hawaii International Conference on System Sciences (HICSS-32),
January 5-8, 1999, Maui, Hawaii, USA. IEEE Computer Society (1999)

4. Badreddine, S., d’Avila Garcez, A., Serafini, L., Spranger, M.: Logic tensor net-
works. Artif. Intell. 303, 103649 (2022), https://doi.org/10.1016/j.artint.
2021.103649

5. Blee, J., Billington, D., Sattar, A.: Reasoning with levels of modalities in BDI
logic. In: Ghose, A.K., Governatori, G., Sadananda, R. (eds.) Agent Computing
and Multi-Agent Systems, 10th Pacific Rim International Conference on Multi-
Agents, PRIMA 2007, Bangkok, Thailand, November 21-23, 2007. Revised Papers.
Lecture Notes in Computer Science, vol. 5044, pp. 410–415. Springer (2007)
6. Bowles, G.: Propositional relevance. Informal Logic 2(12), 65–77 (Spring 1990)
7. Cheruvu, A., Radhakrishna, V.: A survey of similarity measures for time stamped

temporal datasets. In: DATA. pp. 193–197. ACM (2021)

8. Chicco, D., Jurman, G.: The advantages of the matthews correlation coefficient
(mcc) over f1 score and accuracy in binary classification evaluation. BMC Genomics
21 (2020)

9. Esteva, F., Godo, L., Rodr´ıguez, R.O., Vetterlein, T.: On Ruspini’s models of
similarity-based approximate reasoning. In: IPMU (1). Communications in Com-
puter and Information Science, vol. 1237, pp. 3–13. Springer (2020)

10. Fiˇser, P., Kubal´ık, P., Kub´atov´a, H.: Output grouping method based on a simi-
larity of boolean functions. In: Proc. of 7th Int. Workshop on Boolean Problems
(IWSBP), Freiberg (Germany), September 21–22. pp. 107–113 (2006)

11. Hohenecker, P., Lukasiewicz, T.: Ontology reasoning with deep neural networks.

J. Artif. Intell. Res. 68, 503–540 (2020)

12. Johnston, T., Scott, A.: Lipschitz bijections between boolean functions. Combina-

torics, Probability and Computing 30, 513–525 (2021)

13. Makinson, D.: Propositional relevance through letter-sharing. J. Appl. Log. 7(4),

377–387 (2009)

14. Shi, S., Chen, H., Ma, W., Mao, J., Zhang, M., Zhang, Y.: Neural logic reasoning.
In: d’Aquin, M., Dietze, S., Hauff, C., Curry, E., Cudr´e-Mauroux, P. (eds.) CIKM
’20: The 29th ACM International Conference on Information and Knowledge Man-
agement, Virtual Event, Ireland, October 19-23, 2020. pp. 1365–1374. ACM (2020),
https://doi.org/10.1145/3340531.3411949

15. Tran, T., Le, V., Le, H., Le, T.M.: From deep learning to deep reasoning. In: KDD
’21: Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery
& Data Mining. pp. 4076–4077 (2021)

16. Wendler, J., Bach, J.: Recognizing and predicting agent behavior with case based
reasoning. In: RoboCup. Lecture Notes in Computer Science, vol. 3020, pp. 729–
738. Springer (2003)

17

