Interactive Mapping Specification with Exemplar Tuples
Angela Bonifati, Ugo Comignani, Emmanuel Coquery, Romuald Thion

To cite this version:

Angela Bonifati, Ugo Comignani, Emmanuel Coquery, Romuald Thion. Interactive Mapping Spec-
ification with Exemplar Tuples. ACM Transactions on Database Systems, 2019, 44 (3), pp.44.
￿10.1145/3321485￿. ￿hal-02096764￿

HAL Id: hal-02096764

https://inria.hal.science/hal-02096764

Submitted on 25 Sep 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

1

Interactive Mapping Specification with Exemplar Tuples

While schema mapping specification is a cumbersome task for data curation specialists, it becomes unfeasible
for non-expert users, who are unacquainted with the semantics and languages of the involved transformations.
In this paper, we present an interactive framework for schema mapping specification suited for non-expert
users. The underlying key intuition is to leverage a few exemplar tuples to infer the underlying mappings and
iterate the inference process via simple user interactions under the form of boolean queries on the validity of
the initial exemplar tuples. The approaches available so far are mainly assuming pairs of complete universal
data examples, which can be solely provided by data curation experts, or are limited to poorly expressive
mappings.

We present several exploration strategies of the space of all possible mappings that satisfy arbitrary user
exemplar tuples. Along the exploration, we challenge the user to retain the mappings that fit the user’s
requirements at best and to dynamically prune the exploration space, thus reducing the number of user
interactions. We prove that after the refinement process, the obtained mappings are correct. We present an
extensive experimental analysis devoted to measure the feasibility of our interactive mapping strategies and
the inherent quality of the obtained mappings.

CCS Concepts: • Information systems → Data exchange;

Additional Key Words and Phrases: data integration; mapping refinement; user interactions

ACM Reference format:
. 2018. Interactive Mapping Specification with Exemplar Tuples. ACM Trans. Datab. Syst. 1, 1, Article 1
(May 2018), 38 pages.
https://doi.org/0000001.0000001

1 INTRODUCTION
Schema mappings [19] are declarative specifications, typically in first-order logic, of the semantic
relationship between elements of a source schema and a target schema. They constitute key data
programmability primitives, leading database users to be empowered with programming facilities
on top of large shared databases. Mappings are usually specified and tested in enterprise IT and
several other domains by data architects, also known as developers of engineered mappings [11].
Several paradigms have been proposed to aid data architects to specify engineered mappings. The
first paradigm relies on visual specification of mappings using user-friendly graphical interfaces,
as in several mapping designers [10, 30]. Such graphical tools help the data architects design a
mapping between schemas in a high-level notation. A major drawback of these approaches is that
the generation of mappings in a programming language or in a query language from graphical
primitives is dependent of the specific tool. As a consequence, the same graphical specification might
be translated into different and incomparable declarative mappings by two different tools, leading
to inconsistencies. In order to tackle such impedance mismatch, model management operators
have been proposed in [11] to provide a general-purpose mapping designer that can be adapted

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee
provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the
full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored.
Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires
prior specific permission and/or a fee. Request permissions from permissions@acm.org.
© 2018 Copyright held by the owner/author(s). Publication rights licensed to Association for Computing Machinery.
0362-5915/2018/5-ART1 $15.00
https://doi.org/0000001.0000001

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:2

A.Bonifati et al.

(i) Source instance E1
S :

(ii) Canonical mapping:

(iii) Target instance E1

T :

A (Airline):

IdAirline Name

Town
L.A.
Miami

AA
MAI

a0
a1
F (Flight):
IdFlight
f0
f1

From
Miami
L.A.

To
L.A.
Miami

IdAirline
a0
a1

TA (TravelAgency):

IdAgency Name Town
L.A.

ag0

TC

(iv) Source instance E2
S :

A (Airline):

IdAirline Name

Town
Paris

AF

a0
F (Flight):
IdFlight
f0
f1

From
Lyon
Paris

To
Paris
Lyon

IdAirline
a0
a1

TA (TravelAgency):
IdAgency Name

ag0

DT

Airp (Airport):

Town
Paris

IdAirport Name Town
Lyon

ap0

SE

F(idF0, town2, town1, idAir0)

∧ F(idF1, town1, town2, idAir1)
∧ A(idAir0, name1, town1)
∧ A(idAir1, name2, town2)
∧ TA(idAg, name3, town1)
→ ∃idC0, idC1, idC2, idF2, idF3,

Co(idC2, name3, town1)
∧ Co(idC0, name1, town1)
∧ Co(idC1, name2, town2)
∧ Dpt(town2, idF2, idC0)
∧ Arr(town1, idF2, idC0)
∧ Dpt(town1, idF3, idC1)
∧ Arr(town2, idF3, idC1)

Co (Company):

IdCompany Name

c0
c1
c2
Dpt (Departure):

AA
MAI
TC

Town
L.A.
Miami
L.A.

Town
Miami
L.A.

IdFlight
f2
f3

IdCompany
c0
c1

Arr (Arrival):

Town
L.A.
Miami

IdFlight
f2
f3

IdCompany
c0
c1

(v) Canonical mapping:

(vi) Target instance E2

T :

F(idF0, town2, town1, idAir0)

∧ F(idF1, town1, town2, idAir1)
∧ A(idAir0, name1, town1)
∧ TA(idAg, name3, town1)
∧ Airp(idAp, name2, town2)

→ ∃idC0, idA, idF2,

Co(idC0, name1, town1)
∧ Dpt(town2, idF2, idC0)
∧ Arr(town1, idF2, idC0)
∧ Airp′(idA, name2, town2)

Co (Company):

IdCompany Name

c0
Dpt (Departure):
IdFlight
f2
Arr (Arrival):

Town
Lyon

Town
Paris

AF

IdCompany
c0

Town
Paris

IdFlight
f3

IdCompany
c0

(vii) Final mapping after refinement:
Σf inal = {TA(idAg, name3, town1) → ∃idC2, Co(idC2, name3, town1);
′′)

′, idAir0) ∧ A(idAir0, name1, town1

F(idF0, town2, town1

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1

′, idF2, idC0) ∧ Co(idC0, name1, town1

′′)}

Fig. 1. Running example: exemplar tuples (E
(ii) and (v), and Final mapping (vii).

1
S, E

1
T ) and (E

2
S, E

2
T ) (i), (iii), (iv) and (vi), resp.; Canonical mapping

to a wide variety of tools for data programmability. Model management, however, is also suited
for expert users. The third paradigm is to generate the desired mappings from representative data
examples [4, 5, 24], i.e., a pair of source and target instances, provided by the expert user. However,
such data examples are assumed to be solutions of the mapping at hand and representative of
all other solutions. Notwithstanding the progress made in mapping specification thanks to the
aforementioned approaches, all the above paradigms have in common the fact that they are intended
for expert users. Such users are typically acquainted with mapping specification tools and possess
complete knowledge of the mapping domains, the formal semantics of mappings and their solution.
Ultimately, they are capable of formulating queries or writing customized code.

As also observed in [11], at the other end of the spectrum lies end-users, who find relationships
between data and build mapping examples as they go, as in mining heterogeneous data sources,
web search, scientific and personal data management. More and more ordinary users are in fact
confronted on a daily basis with user-driven data exploration scenarios, such as those exposed by
dataspaces [20]. As a consequence, the problem of mapping specification for such classes of users
is even more compelling.

To tackle the above problem, in this paper we set forth a novel approach for Interactive Mapping
Specification (IMS) that bootstraps with exemplar tuples, corresponding to a limited number of

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:3

tuples provided by non-expert users. Such tuples are employed to challenge the user with simple
boolean questions, which are intended to drive the inference process of the mapping that the user
has in mind and that is unknown beforehand.

(IMS) Given exemplar tuples as input pairs {(E1
T )} provided by a non-expert user and
a mapping M that the user has in mind, the Interactive Mapping Specification problem is to discover,
by means of boolean interactions, a mapping M ′ such that each (Ei
T )}
satisfy M ′ and M ′ generalizes M.

T ); . . . ; (En

T ); . . . ; (En

T ) ∈ {(E1

S, E1

S, E1

S , En

S , En

S, Ei

Notice that the user-provided exemplar tuples may turn to be not well chosen or even ambiguous
with respect to the mapping M that the user has in mind. Moreover, exemplar tuples are not
supposed to be solutions nor universal solutions of the mapping that needs to be inferred. Whereas
a wealth of research on schema mapping understanding and refinement has been conducted in
databases [4, 17, 21, 22, 33] since the pioneering work of Clio [28], these approaches assume more
sophisticated input (such as an initial mapping to refine and the schemas and schema constraints)
and/or more complex user interactions. Although exemplar tuples reminisce data examples [5], they
are fundamentally different in that they are not meant to be universal. Furthermore, the mappings
we consider in this paper are unrestricted GLAV mappings. We present a detailed comparison with
previous work in Section 7, and a comparative analysis with [6, 13] in Section 6.

Query specification has been recognized as challenging for non-expert users and more time-
consuming than executing the query itself [25]. We argue that mapping specification is even
more arduous for such users, merely because mappings embody semantic relationships between
inherently complex queries. Despite many recent efforts on query specification for non-expert
users [1, 2, 12, 18, 27], these works are not applicable to mapping specification for non-expert users,
which we address in this paper (for more details, we refer the reader to Section 7).

Figure 1 illustrates our running scenario, where a non-expert user needs to establish a mapping
between two databases exhibiting travel information. The source database schemas are made of
four relations, Airline, Flight, TravelAgency, and Airport (abbreviated respectively as A, F, TA and
Airp). The target database schemas contains four relations Company, Departure and Arrival (resp.
Co, Dpt and Arr).

S, E1

S, E1

In this scenario, user provide two pairs of source and target exemplar tuples sets : (E1
S, E2

T ) and
(E2
T ). For each of this pairs, source and target databases are reported in the left-hand and right-
hand sides of the Figure 1, respectively. We can observe that the number of tuples per each table is
small: the user is not intended to provide a complete instance but only a small set of representative
tuples. We can also easily identify a few inherent ambiguities within the provided exemplar tuples.
For instance, in (E1
T ), the constant L.A. represents both the town where the travel agency is
located (in relation TA, which contains travel agencies information) and the destination of a flight
(in the corresponding relation F). If we would consider these exemplar tuples as the ground truth,
we would translate them into canonical mapping illustrated in Figure 1 (ii) and (v). Such mappings,
however, reflects the ambiguities of the provided exemplar tuples, by assuming that all solutions
must have two airline and that the travel agency (resp. the airport) must be located in the same
city than an airline headquarters. Thus, from a logical viewpoint, such mappings are way too
specific. Moreover, such mappings can be quite large and unreadable in real-world scenarios, as they
embeds all the exemplar tuples altogether. Our mapping specification process builds upon end-user
exemplar tuples, which can be ambiguous and ill-defined. Hence, it aims at deriving smaller refined
and normalized mappings through simple user interactions, in order to obtain more controllable
mappings closer to what the user has in mind (illustrated in Figure 1 (iv)). The rest of the paper is
devoted to explain such a transformation.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:4

A.Bonifati et al.

The main contributions of our paper are summarized as follows:

• We define a mapping specification process for non-expert users that bootstraps with exemplar
tuples, and works for general GLAV mappings. The user is challenged with boolean questions
over even smaller refinement-driven tuples generated from the initial exemplar tuples. The space
of possible solutions is represented as a quasi-lattice, on top of which a dynamic pruning keeps
the number of user interactions reasonably low. The introduction of quasi-lattices, instead of
separate upper semi-lattices as used in [13], allows to avoid redundant explorations and leads to
reduce the number of required user interactions.

• We prove that the generated mappings have irreducible right-hand sides. Combined with redundant
mapping elimination, this guarantees that the obtained refined mappings are in normal form [23].
Intuitively, normalized mapping are more self-explanatory and understandable for end-users
compared to monolithic canonical mappings.

• We prove that the refinement process always produces a more general mapping than the canonical
mapping and is always implied by the mapping expected by the user. As an example, an illustration
of the obtained mapping for our running example is in Figure 1 (iv), which can be confronted
with the canonical mappings of Figure 1 (ii) and (iv). We define the condition under which our
system will produce a mapping logically equivalent to the one expected by the user. This is a
major improvement of the work done by [13], as they provide less formal guarantees about the
produced mapping.

• We introduce the adoption of integrity constraints (ICs) in order to reduce the number of asked
questions, when the approach in [13] does not allow the use of such constraints. To this end, we
present a modified version of the problem statement, namely IMSIC and we study the various
classes of allowed ICs.

• We experimentally gauge diminution of the number of asked questions induced by the intro-
duction of quasi-lattices compared to the work in [13]. Moreover, we experimentally gauge the
effectiveness of our approach, by comparing the sizes of exemplar tuples with the size of universal
solutions.
The rest of this paper is organized as follows. Section 2 introduces the notation used in the rest
of our paper. Specific background on the mapping generation from exemplar tuples is detailed in
Section 3.1. The bulk of our approach is described in Section 3.2. A formal general framework is
described in Section 4, as well as proofs of correctness and completeness of this framework and
the implementation detailled in previous section. Formal considerations about the use of integrity
constraints in order to reduce the number of questions is presened in Section 5 and an extensive
experimental study is presented in Section 6. Related work is devoted to Section 7. We conclude
the paper in Section 8.

2 PRELIMINARIES
We briefly introduce various concepts from the data exchange framework [19] that we use in this
paper. Given two disjoint countably infinite sets of constants C and variables V, we assume a
bijective function ¯θ , such that if ¯θ (xi ) = ci , then ci ∈ C is the constant associated to the variable
xi ∈ V and ¯θ −1(c) = x. A tuple over a relation R has the form R(c1, . . . , cn) where ci ∈ C, while
an atom has the form R(x1, . . . , xn) where xi ∈ V. The bijection ¯θ naturally extends to a bijection
between (conjunctions of) atoms and (sets of) tuples.

A (schema) mapping is a triple M = (S, T, Σ) with S is a source schema, T is a target schema
disjoint from S, and Σ is a set of tuple-generating dependency (tgd for short) over schemas S and
T. A tgd is a first-order logical formula the form ϕ(x) → ∃y,ψ (x, y) where x and y are vectors of
variables, x being universally quantified, and where both ϕ and ψ are conjunctions of atoms. In

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:5

this paper, we only consider source-to-target tgd (s-t tgds for short), in which atoms in ϕ are over
relations in S and atoms in ψ are over relation in T. We consider GLAV mappings where a tgd can
contain more than one atom in ϕ and in ψ .

Two tgds σ1 : ϕ1(x 1) → ∃y1,ψ1(x 1, y1) and σ2 : ϕ2(x 2) → ∃y2,ψ2(x 2, y2) are ψ -equivalent if
there exists a morphism µ : ψ2(x 2, y2) → ψ1(x 1, y1) such that ψ1 ≡ µ(ψ2), and µ match existential
variables in y2 only with existential variables in y1 and universally quantified variables in x 2 are
matched only with universal variables in x 1. We denote ψ -equivalence between two tgds σ1 and σ2
by the following notation: σ1 ≡ψ σ2.

Analogously, two tgds σ1 : ϕ1(x 1) → ∃y1,ψ1(x 1, y1) and σ2 : ϕ2(x 2) → ∃y2,ψ2(x 2, y2) are
ϕ-equivalent if there exists a morphism µ : ϕ2(x 2) → ϕ1(x 1) such that ϕ1 ≡ µ(ϕ2). We denote
ϕ-equivalence between two tgds σ1 and σ2 by the following notation: σ1 ≡ϕ σ2.

An instance ET over T is a solution for a source instance ES over S under a mapping M = (S, T, Σ)
iff (ES, ET ) |= Σ. A mapping M = (S, T, Σ) logically entails a mapping M ′ = (S, T, Σ′), denoted by
M |= M ′, if for every (ES, ET ) if (ES, ET ) |= Σ then (ES, ET ) |= Σ′. Two mappings M and M ′ are
logically equivalent, denoted by M ≡l M ′, if M |= M ′ and M ′ |= M. When comparing mappings,
we say that M is more general than M ′ if M |= M ′. Informally, this means that tgds in M are
triggered more often than those in M ′.

Let ES and ES

′ be two instances over the same schema. A homomorphism from ES to ES is a
′ such that for any tuple R(c1, . . . , cn) in the
function h from constants in ES to constants in ES
instance ES, the tuple R(h(c1), . . . , h(cn)) belongs to ES. An instance ET is an universal solution for
the instance ES under a mapping M if ET is a solution for ES and if for each solution ET
′ for ES
′ such that h(c) = c for every constant c
under M, there exists a homomorphism h : ET → ET
appearing both in ET and ET

It was shown in [19] that the result of chasing ES with Σ is a universal solution. The application
of the chase procedure, denoted by chase(Σ, ES), is as follows: for each tgd ϕ(x) → ∃y,ψ (x, y) ∈ Σ,
if there exists a substitution µ of x such that all atoms in ϕ(x) can be mapped to tuples in ES, extend
this substitution to µ ′ by picking a fresh new constant for each variable in y and finally add all
atoms of ψ (x, y) instantiated to tuples with µ ′ into ET . Another key result of the literature that we
use in this paper is borrowed from [9] and states that Σ |= ϕ(x) → ∃y,ψ (x, y) if and only if there
exists a substitution µ ′ extending an arbitrary µ such that µ ′(ψ (x, y)) ⊆ chase(Σ, µ(ϕ(x))).

′.

The chase procedure give us a way to test the logical implication of mappings by the use of the

following property : M |= M ′ if and only if ∀σ ′ ∈ Σ′,ψσ ′ ⊆ chase(Σ, ϕσ ′)[26].

Finally, for the schema mapping normalization, we borrow two notions from [23]: split-reduced
mappings and σ -redundant mappings. While split-reduction breaks a tgd into a logically equivalent
set of tgds with right-hand sides having non overlapping existentially quantified variables, σ -
redundancy encodes the presence of unnecessary tgds. We report formal definitions below. Let
σ : ϕ(x) → ∃y,ψ (x, y) be a tgd. We say that σ is split-reduced if there is no pair of tgds σ1 : ϕ1(x) →
∃y1,ψ1(x, y1) and σ2 : ϕ2(x) → ∃y2,ψ (x, y2) such that y1 ∩ y2 = ∅ and {σ } ≡l {σ1; σ2}. A mapping
(S, T, Σ) is split-reduced if, for all tgd σ ∈ Σ, σ is split-reduced. According to [23], given a mapping M,
it is always possible to find a split-reduced mapping M ′ that is equivalent to M. Let M = (S, T, Σ)
be a schema mapping and σ ∈ Σ a tgd. We say that M is σ -redundant, w.r.t. logical equivalence, iff
Σ \ {σ } ≡l Σ. Such equivalence can be tested using the chase procedure as a proof procedure for the
implication problem by checking whether Σ \ {σ } |= σ .

We briefly recall a few notions on partitions. A partition of a set W is a set P of disjoint and
non-empty subsets of V called blocks, such that (cid:208)
b ∈ P b = W. The set of all partitions of W is
denoted by Part(W). Two objects of W that are in the same block of a partition P are denoted by

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:6

A.Bonifati et al.

a ≡P b. The set of all partitions of W form a complete lattice under the partial order :

P0 ≤ P1 ⇔ ∀x, y ∈ W, (cid:0)x ≡P0 y ⇒ x ≡P1 y(cid:1)

This partial order formally captures the intuitive notion of refinement of a partition.

3 MAPPING REFINEMENT
In this section, we describe the key components of our interactive mapping specification process,
as depicted in Figure 2.

3.1 Exemplar tuples and mappings
Exemplar tuples are defined as a pair of source and target instances (ES, ET ). Tuples in these two
instances can be arbitrary chosen in the sense that there’s no need for him to provide an instance
ET which is an universal solution to ES through his expected mapping. Instead, given the source
instance ES, the user can populate the target instance ET with only few tuples coming from the
universal solution to ES through his expected mapping. In other words, The formal definition of
such a pair of instance is given in the following definition :

Definition 3.1 (Exemplar tuples). Let Σexp be a mapping. Then an exemplar tuple for Σexp is a

pair of instances (ES, ET ) such that :

ET ⊆ chase(Σexp, ES)
Henceforth, they are simply called exemplar tuples whenever Σexp is clear from the context. A

set of exemplar tuples is denoted by the letter E.

Example 3.2. Given a mapping Σ = {S(x, y) → ∃z,T (x, z); S ′(x, y) → T (x, z) ∧ T ′(z, y)}. Given
a source instance I = {S(a, b); S(c, d); S ′(e, f)}. Then, a possible exemplar tuple can be the pair
(ES, ET ) with ES = I and :

ET ⊆ {T (a, n1);T (c, n2);T (e, n3);T ′(n3, f)}
An other exemplar tuple can be the pair ({S(a, b); S(c, d)}, {T (a, n1)}), which exemplifies the tgd

S(x, y) → ∃z,T (x, z) of Σ.

A counter example is the pair ({S(a, b); S(c, d)}, {T (a, n1);T ′(n2, b)}). Here, the tgd S(x, y) →
∃z,T (x, z) is exemplified by the tuples S(a, b) and T (a, n1), but this pair is not an exemplar tuples
because the tuple T ′(n2, b) cannot be deduced from Σ with the source tuples {S(a, b); S(c, d)}, and
thus is not consistent with our definition 3.1.

Given a set of exemplar tuples E, this set is said to be fully-informative for a mapping Σexp if it

respect the following definition :

Definition 3.3 (Fully-informative exemplar tuples set). Let Σexp be a mapping in normal form.
Then a fully-informative exemplar tuples set for Σexp is a set of exemplar tuples E such that each
connected component of the tgd in Σexp is exemplified at least once, i.e. :

∀σ ∈ Σexp, ∃(ES, ET ) ∈ E, ∃E ′

S ⊆ ES s.t. (chase(σ , E ′
This definition capture the need of having sufficient information conveyed by the set of exemplar
tuples provided by the user, in order to allow to retrieve the mapping the user as in mind (or a
logically equivalent mapping). This will be proved in Section 4.

S) (cid:44) ∅) ∧ (chase(σ , E ′

S) ⊆ ET )

Example 3.4. We reuse the sets Σ and I of the previous example 3.2. As stated in example 3.2, the
pair ({S(a, b); S(c, d)}, {T (a, n1)}) is an exemplar tuple for Σ. But this example does not exemplify
the tgd S ′(x, y) → T (x, z) ∧ T ′(z, y), so it violates definition 3.3.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:7

In the following set, a pair for the tgd S ′(x, y) → T (x, z) ∧ T ′(z, y) is added, leading to a fully-

informative exemplar tuples sets for Σ :

By opposite, the set :

{({S(a, b); S(c, d)}, {T (a, n1)});
({S ′(e, f)}, {T (e, n3);T ′(n3, f)})}

{({S(a, b); S(c, d)}, {T (a, n1)});
({S ′(e, f)}, {T (e, n3)})}

is not fully-informative for Σ as there is no exemplar tuple that exemplifies the connected component
of tgd S ′(x, y) → T (x, z) ∧ T ′(z, y).

Given an input pair (ES, ET ), we build a canonical mapping as follows. More precisely, given a
pair (ES, ET ), the canonical mapping associated to (ES, ET ) is the tgd ϕ → ψ where ϕ = ¯θ −1(ES) and
ψ = ¯θ −1(ET ). Informally, the left-hand side ϕ is constructed from ES by replacing all tuples in ES by
their atoms counterparts, with the constants being replaced by variables. The right-hand side of
the canonical mapping is obtained in a similar fashion.

Example 3.5. The canonical mappings corresponding to the exemplar tuples of Figure 1 are

represented in Figure 1 (ii) and (v).

However, notice that the canonical mappings of Example 3.5 are extremely rigid. For instance, in
the canonical mapping (ii) we can observe that tuples in the source relation TA are mandatorily
needed in order to obtain tuples in the target relation Arr.

This is due to the fact that a canonical mapping is the most specific mapping obtained from the
exemplar tuples: it contains all the atoms corresponding to ES on its left-hand side. Since exemplar
tuples are not universal by definition 1, this mapping are far too constrained. The envisioned
workaround is to refine the canonical mappings into a less constrained one by leveraging simple
user interactions.

Intuitively, the refinement of the canonical mappings is done through the following steps: the
first is a pre-processing that leads to a single normalized mapping, in which each large tgd of a
canonical mappings is divided into equivalent set of smaller ones; the second and the third steps
revolve around mapping refinement via user interactions that lets simplify the left-hand sides of
the tgds. We devote the rest of this subsection to the first step, while we describe the latter steps in
the next subsections.

We define formal criteria that capture the quality of a mapping M intuitively as follows: each
tgd in Σ should have a minimal right-hand side and there should be no spurious tgd in Σ. To
that purpose, we rely on the two previously introduced notions, i.e. split-reduced mappings and
σ -redundant mappings[23]. The splitting of the original mapping into smaller tgds turns out to
be convenient for mapping refinement, in that it lets the user focus only on the necessary atoms
implied in the left-hand sides of each reduced tgd. However, as a side effect of split-reduction, we
may get redundant tgds in the set Σ. Such redundant tgds are unnecessary and need to be removed
to avoid inquiring the user about useless mappings. Finally, we say that (S, T, Σ) is normalized when
each tgd in Σ is split-reduced and there is no σ -redundant tgd in Σ.

1If exemplar tuples (ES, ET ) were universal, then (ES, ET ) |= σ where σ is the canonical mapping associated to (ES, ET ).

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:8

Input:
set of input
pairs

(E 1

S, E 1

T )...(E n

S , E n
T )

A.Bonifati et al.

Normalization

Σnor m

Atom
refinement

Σat Re f
(normalized)

Join
refinement

Σf inal
(normalized)

Output:
refined mapping
Σf inal

Question

Answer:
Yes or No

Question

Answer:
Yes or No

Fig. 2. Interactive mapping specification process.

Example 3.6. The split-reduction on the canonical mappings of Figure 1(ii) and (v) leads to the

following set of tgds Σsplit Reduced :

ϕ1 =F(idF0, town2, town1, idAir0) ∧ F(idF1, town1, town2, idAir1) ∧ A(idAir0, name1, town1)

∧ A(idAir1, name2, town2) ∧ TA(idAg, name3, town1)

ϕ2 =F(idF0, town2, town1, idAir0) ∧ F(idF1, town1, town2, idAir′) ∧ A(idAir0, name1, town1)

∧ Airp(idAp, name2, town2) ∧ TA(idAg, name3, town1)

Σsplit Reduced = {
ϕ1 → ∃idC2, Co(idC2, name3, town1);
ϕ1 → ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1);
ϕ1 → ∃idC1, idF3, Dpt(town1, idF3, idC1) ∧ Arr(town2, idF3, idC1) ∧ Co(idC1, name1, town2);
(3)
ϕ2 → ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)} (4)

(2)

(1)

The σ -redundancy suppression on Σsplit Reduced allow to suppress the redundant tgd (3), which is
logically equivalent to tgd (2). The σ -redundancy suppression cannot be applied to tgds (2) and (4)
as their left-hand sides are different.

This lead to the normalized mapping Σnorm :
Σnorm = {
ϕ1 → ∃idC2, Co(idC2, name3, town1);
ϕ1 → ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1);
(2)
ϕ2 → ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)} (4)

(1)

3.2 Refinement of mappings
The previous section has defined the pre-processing step that leads to a normalized canonical
mapping. We now introduce the two refinement steps that constitute the core of our proposal. The
assumption underlying our approach is that a non-expert user provides a set of exemplar tuples
E in input and, during the mapping refinement steps, this user will interacts with our system via
simple boolean questions about the validity of small data examples. If the provided set of exemplar
tuples is a fully informative set, then the output mapping is guaranteed to be equivalent to the
mapping expected by the user, as it will be proved in Section 4.

In this paper, we assume that the questions about the validity of this data examples are answered

by an oracle. This oracle answer question using the following procedure :

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:9

Definition 3.7 (oracle answering procedure.). Let Mexp = ⟨S,T , Σexp ⟩ be the mapping expected

by the oracle. Let (ϕ → ψ ) be a tgd.
Then, the oracle answer true to the question “Are the tuples ¯θ (ϕ) enough to produce ¯θ (ψ )?” if :

ψσ ⊆ chase(ϕσ , Σexp )

The choice of such a modelisation of users is motivated by the intuition that even if a non-expert
user is not able to express the mapping he expects with a logical language, he can rely on domain
knowledges to answer if the information contained in a set of source tuples is sufficient to infer a
given set of target tuples. In this paper, we don’t consider other kinds of users that correspond to a
relaxation of the previous conditions and we leave this part to future investigation.

In the rest of this section, for ease of exposition, we assume that the user provides only two pairs
S, E1
T ) of exemplar tuples. However, in practice, the user might provide a larger set

(E1
T ) and (E2
S, E2
of exemplar tuples.

S , Ek

For a given input pair (Ek

T ), the number of mappings satisfying it may be quite large. Therefore,
it is important to provide efficient exploration strategies of the space of mappings in order to reduce
the number of questions to ask to the user. An important method used here relies on the fact that
we can partition the normalized canonical mapping obtained from user’s exemplar tuples in blocks
of ψ -equivalent tgds. These sets of tgds are handled together to find morphisms between subsets
of their left-hand sides. Such morphisms corresponds to equivalent tgds extracted from different
exemplar tuples, so we need to avoid exploring them more than once to reduce the size of the
explored space. This is a major difference with the refinement presented in [13], in which each
exemplar tuple is explored separately, leading to redundant superfluous interactions with the user.
Two successive steps are applied during refinement: the atom refinement step and the join
refinement step. We illustrate such steps in Figure 2, along with the corresponding user interactions
required to obtain the final result, i.e., the refined tgds that meet the user’s requirements. The atom
refinement step aims at removing unnecessary atoms in the left-hand side of the tgds within the
normalized mapping obtained in the pre-processing. The join refinement step applies the removal of
unnecessary joins between atoms in each tgd as output by the previous step. During both steps, the
user is challenged with specific questions devoted to address ambiguities of the provided exemplar
tuples and refine the normalized canonical mapping obtained in the pre-processing step. We focus
on the first step in Section 3.3 and we postpone the description of the second step to Section 3.4.

In our approach, we use universally quantified variables as the targets of the refinement algo-
rithms and assume that the existential variables in the right-hand side of the tgds are unambiguous
(and appear as such in the input exemplar tuples). In other words, value invention (e.g., the pro-
duction of labeled nulls in SQL) in the target exemplar tuples is supposed to be correct and the
user is not inquired about them. This also implies that our algorithms do not create fresh existential
variables in the tgds. The introduction of such variables would drastically increase the number
of mappings to explore and their coverage would entail non-trivial extension of our algorithms,
which are beyond the scope of this paper.

3.3 Atom refinement
As discussed in Section 3.1, the normalization produces a split-reduced mapping from the canonical
mapping in which each tgd has a large left-hand side ϕ. However, some atoms in ϕ may be irrelevant,
preventing the triggering of a tgd and causing further ambiguities. To alleviate these ambiguities,
Algorithm 1 applies atom refinement on each block of the partition of ψ -equivalent tgds. In the
following, we explain its key components and properties.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:10

A.Bonifati et al.

Algorithm 1 TgdsAtomRefinement(Σ)
Input: A set of tgds Σ to be atom refined.
Output: A set of tgds Σ′ where each tgd is atom refined.
1: PΣ ← generate partition of ψ -equivalent tgds from Σ
2: Σ′ ← ∅
3: for all b ∈ PΣ do
4:
5:

let b be ψ -equivalent over ψb
Ccand ← generate set of possibles left-hand side candidates from b
Cvalid ← generate the upper bound of the quasi-lattice over b
Cinvalid ← ∅
while Ccand (cid:44) ∅ do

6:
7:
8:
9:
10:
11:

12:
13:
14:
15:
16:

e ← SelectAtomSet(Ccand , Cvalid )
if AskAtomSetValidity(e,ψb ) then

add e to Cvalid
remove supersets of e from Cvalid
remove e and its supersets from Ccand

else

add e to Cinvalid
remove e and its subsets from Ccand

end if
end while
for all e ∈ Cvalid do

add the tgd (e → ψ ) to Σ′

17:
18:
19:
20:
21:
22: end for
23: return Σ′

end for

3.3.1 Groups of ψ -equivalent tgds. The first step of atom refinement aims at grouping ψ -
equivalent tgds together in order to allow a more efficient exploration of the search space. To this
purpose, given Σnorm = {σ1 . . . σn } the set of tgds generated during normalisation, we create a
partition Pnorm of Σnorm in which each block is constituted by ψ -equivalent tgds. More formally,
we produce the partition Pnorm such that:

∀σi , σj ∈ Σnorm, σi ≡Pnor m σj ⇔ σi ≡ψ σj
3.3.2 Quasi-lattice for Atom Refinement. The baseline structure for the atom refinement of a
block B ∈ Pnorm is a quasi-lattice. A quasi-lattice is a restriction of a complete lattice to a subset
of its nodes, included between an upper and a lower bound.

In our setting, given {ϕ1; . . . ; ϕn } the set of the left-hand parts of the tgds in B, the quasi-lattice
i=1 ϕi ) is the powerset of
i=1 ϕi )

is build over the complete lattice L = (Pow((cid:208)n
the set of all atoms in the left-hand sides of the tgds in B. For all elements ex and ey of Pow((cid:208)n
the least-upper-bound of the set {ex , ey } is their union.

i=1 ϕi ), ⊆h) where Pow((cid:208)n

As atom refinement does not add new constraints in the tgds, we does not create conjunctions
which are not subsets of the left-hand side of at least one tgds in B. Thus we can define the upper
bound of the quasi-lattice as the set {At(ϕ1); . . . ; At(ϕn)} where At(ϕi ) is the set of atoms in the
conjunction ϕi .

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:11

Example 3.8. Considering the tgds in Σnorm of Example 3.6, the left-hand sides are made of
conjunction ϕ1 and ϕ2. The elements of the quasi-lattices we consider are the subsets of the two
following sets of atoms (respectively, the sets of atoms in ϕ1 and ϕ2) :
{F(idF0, town2, town1, idAir0); F(idF1, town1, town2, idAir1);

A(idAir0, name1, town1); A(idAir1, name2, town2); TA(idAg, name3, town1)}

{F(idF0, town2, town1, idAir0); F(idF1, town1, town2, idAir1);

A(idAir0, name1, town1); Airp(idAp, name2, town2); TA(idAg, name3, town1)}
It is worth to note that many of the subsets of this two sets are homomorphically equivalents. Such
an equivalence can be used to leverage common parts of the tgds.

Recalling that our system does not create new existentially quantified variables in the tgds,
we need to prune each sets of atoms leading to violate this rule. An existential variables in a
tgd correspond to a variable occurring only in the right-hand side, i.e., a variable leading to the
creation of new value in the target instance. So, each candidate left-hand side conjunction that
does not contain the whole set of right-hand side universal variables will be excluded from the
set of candidates. Thus, the set of smallest left-hand side conjunctions containing, at least, all the
universal variables of the right-hand side conjunction define the lower bound of our quasi-lattice.
This restriction takes effect in line 6 of Algorithm 1.

Example 3.9. We illustrate the atom refinement on Example 3.6. As the process stay analogous

for each tgd in Σnorm, we focus on the tgds (2) and (4) which right-hand side is:
ϕ1 ≡h ϕ2 ≡h ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)
The set of universally quantified variables in this conjunction is {town2, town1, name1}. A re-
fined tgd needs to contain at least these variables in its left-hand side. The smallest subsets of the
set of atoms given in Example 3.8 for which this assumption is valid are:

for tgd (2), and :

{F(idF0, town2, town1, idAir0); A(idAir0, name1, town1)},
{F(idF1, town1, town2, idAir0); A(idAir0, name1, town1)} and
{A(idAir0, name1, town1); A(idAir1, name2, town2))}

{F(idF0, town2, town1, idAir0); A(idAir0, name1, town1)},
{F(idF1, town1, town2, idAir0); A(idAir0, name1, town1)} and
{A(idAir0, name1, town1); Airp(idAp, name2, town2)}

for tgd (4). This sets constitute the lower bound of our quasi-lattice.

Each set which is not a superset of one of these two sets is pruned in line 6 of Algorithm 1.
In addition, we do not allow the creation of new constraints, this lead to consider left-hand sides

of the tgds (2) and (4) as the upper-bound of our exploration space.

The explorable part of the resulting quasi-lattice is shown in Figure 3.

3.3.3 Exploring the quasi-lattice. During the exploration of the space of possible candidates, the

user is challenged upon one element of the quasi-lattice at a time, as in line 10 of Algorithm 1.

This element can be chosen according to a given exploration strategy, corresponding to the call
of SelectAtomSet in line 9. We will experimentally compare four different exploration strategies
in Section 6.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:12

A.Bonifati et al.

{A1; A2; F0; F1;T A}

{A1; F0; F1; Ap;T A}

{A1; A2; F0;T A}

{A1; A2; F0; F1}

{A1; A2; F1;T A}

{A1; F0; F1;T A}

{A1; F0; Ap;T A}

{A1; F0; F1; Ap}

{A1; F1; Ap;T A}

{A1; A2;T A}

{A1; A2; F0}

{A1; A2; F1}

{A1; F0;T A}

{A1; F0; F1}

{A1; F1;T A}

{A1; F0; Ap}

{A1; F1; Ap}

{A1; Ap;T A}

{A1; A2}

{A1; F0}

{A1; F1}

{A1; Ap}

Fig. 3. Atom sets quasi-lattice on examples 3.9 and 3.10. With atoms: A1 = A(idAir, name1, town1),
A2 = A(idAir′, name2, town2), F0 = F(idF0, town2, town1, idAir), F1 = F(idF1, town1, town2, idAir′), T A =
TA(idAg, name3, town1) and Ap = Airp(idAp, name2, town2).

An important property of the upper semilattice of atom refinement implies that, once the user
validates one of the candidates, then all the supersets of such candidate can be excluded from
further exploration, thus effectively pruning the search space.

Example 3.10. Following previous Example 3.9, we are refining tgds (2) and (4). Figure 3 illustrate
the exploration space with the left side corresponding to atom sets specifics to tgd (2), the right
side corresponding to atom sets specifics to tgd (4) and the central part corresponding to common
atom sets between (2) and (4).

Assume, for the sake of the example, that we employ a breadth-first bottom-up strategy, starting
the exploration of the upper semilattice in Figure 3 at its bottom-up level with {A1; A2},{A1; F0},{A1; F1}
and {A1; Ap}. The user is asked about the validity of {A1; A2} (the bottom left light gray box of
Figure 3) with the following question:

“Are the tuples A(a0, AA, L.A.) and A(a1, MAI, Miami) enough to produce
Dpt(Miami, f2, c0), Arr(L.A., f2, c0) and Co(c0, AA, L.A.)?”
We can observe that a positive answer implies an ambiguity, namely that the second flight
company is based in the same town of the departure of the flight, which is not the case in real-world
examples. Hence, the user will be likely to answer ‘No’ to the above question.

Next, assume now that Algorithm 1 proceeds with {A1; F0}. This atom set is common between the
T ) to generate the question.

tgds (2) and (4), consequently we can use tuples from (E1
Here we take tuples from (E1

T ) or (E2
T ), leading to the following question:

S, E2

S, E1

S, E1

“Are the tuples F(f0, Miami, L.A., a0) and A(a0, AA, L.A.) enough to produce
Dpt(Miami, f2, c0), Arr(L.A., f2, c0) and Co(c0, AA, L.A.)?”
Assuming that the user will answer ‘Yes’ to this question, the supersets of {A1; F0} will be pruned

(crossed out boxes of Figure 3) and the following tgd will be output by the algorithm:

F(idF0, town2, town1, idAir0) ∧ A(idAir0, name1, town1)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)
We continue the exploration of the current level with sets {A1; F1} and {A1; Ap}. Assuming that
the user does not validate these sets, he will be finally challenged about the last available sets
then on the next level of the semilattice, namely on the sets {A1; A2;T A},{A1; A2; F1}, {A1; F1;T A},
{A1; F1; Ap}and {A1; Ap;T A} which are also labels as invalid. In the end, for the combination of
tgds (2) and (4), Algorithm 1 will output the single tgd (5).

(5)

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:13

We now state that when shifting from the initial canonical mapping to its refined form as given

by Algorithm 1, we obtain a more general set of tgds.

Lemma 3.11. Let M = (S, T, Σ) be a canonical mapping and let Σ′ be a mapping obtained
from atom refinement of M, then, for all source instances ES, there exists a morphism µ such that
µ(chase(Σ, ES)) ⊆ chase(Σ′, ES). By the correctness of the chase procedure, the logical entailment
Σ′ |= Σ holds.

Proof. For each tgd σ = ϕ → ψ ∈ M there exists at least one tgd σ ′ = ϕ ′ → ψ ∈ M ′ that is an
atom refinement of σ . Then, ϕ ′ must correspond to a node in the semilattice, such that ϕ ′ ⊆ ϕ. We
introduce an function re f : M → M ′ that associate to each σ in M one of its refinements (that
may be arbitrarily chosen if there are several such tgds in M ′).

Let ν be an instantiation mapping to compute chase(M, ES). That is, there exists a tgd σ = ϕ →
ψ ∈ M such that ν (ϕ) ⊆ ES and ν (ψ ) ⊆ chase(M, ES). Moreover each existential variable in ψ
is mapped by ν to a fresh labeled null, which means that is ν −1 is defined for such values. Since
ϕ ′ ⊆ ϕ, ν (ϕ ′) ⊆ ES. Therefore, there exists an instantiation mapping ν ′ such that (1) ν ′(ϕ ′) ⊆ ES
(2) ν ′(ψ ′) ⊆ chase(M ′, ES) and (3) for all variables x in ϕ ′, ν ′(x) = ν (x). However, ν ′ and ν can
differ in two ways: the domain of ν ′ can be smaller than the domain of ν and the labeled nulls that
are assigned to existential variables in ψ can be different because the chase generate fresh null
values at each tgd application. By construction of Ep in Algorithm 1, any variable x in ψ is either
an existential variable or a universal variable in ϕ ′. Thus, every variable x in ψ is either mapped
to fresh null values by ν and ν ′ or, alternatively, ν (x) = ν ′(x). We introduce µν a morphism from
ν (ψ ) ⊆ chase(M, ES) to ν ′(ψ ) ⊆ chase(M ′, ES), defined as µν (c) = c if there exists x in ϕ ′ such
that ν(x) = c and µν (c) = ν ′(ν −1(c)) otherwise (that if c is a fresh value generated by chase(M, ES)).
Let us consider two instantiation mappings ν1 and ν2 used in chase(M, ES) and their associated
morphisms µν1 and µν2. Let c be a value in dom(µν1)∩dom(µν2). If c is fresh and in dom(µν1), it means
than it is the image of an existential variable by ν1, which means that it cannot be the image of any
variable by ν2, and thus c (cid:60) dom(µν2) which contradicts c ∈ dom(µν1) ∩dom(µν2). Thus c is not fresh,
thus µν1(c) = c = µν2(c). We define µ {ν1,ν2 } as µ {ν1,ν2 }(c) = µν1(c) if c ∈ dom(µν1) and µ {ν1,ν2 }(c) =
µν2(c) otherwise. One can remark that µ {ν1,ν2 } |dom(µν1 )= µν1 and µ {ν1,ν2 } |dom(µν2 )= µν2. By iterating
this construction on the finite set Λ of all instantiation mappings ν used in chase(M, ES), we can
build a morphism µ = µΛ.

Let t be a tuple in chase(M, ES). There exists an instantiation morphism ν used in chase(M, ES)
and a tgd ϕ → ψ such that t ∈ ν (ψ ). Since µν (ν (ψ )) ⊆ chase(M ′, ES) and µ |dom(µν )= µν we deduce
□
µ(t) ∈ chase(M ′, ES).

The following Example 3.12 shows that the previous lemma would not hold if Algorithm 1 is

allowed to create new existential variables.

Example 3.12. Given a pair (ES, ET ) such that ES = {R(x, y); S(z)} and ET = {T (x)}. The canonical
mapping corresponding to (ES, ET ) is Σ = {R(x, y) ∧ S(z) → T (x)}. Suppose that atom refinement
allows the creation of existentially quantified variables. By applying this refinement on Σ, we may
obtain the mapping Σ′ = {S(z) → ∃x,T (x)}. Chasing ES under Σ and Σ′ will lead to following
results:

chase(ES, Σ) = {T (x)}

chase(ES, Σ′) = {T (x1)}

for which there is no morphism µ such that µ(chase(ES, Σ)) ⊆ chase(ES, Σ′), because the constant
x has to be preserved.

The following Lemma 3.13 states that the intermediate mappings obtained after the atom refine-

ment step is split-reduced and, at the opposite of the work in [13], have no σ -redundant tgds.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:14

A.Bonifati et al.

Lemma 3.13. Given a normalized canonical mapping M = (S, T, Σ), application of atom refinement

on the tgds in Σ always produces a mapping which is split-reduced and without σ -redundancy.

Proof. As M is already normalized, it is split-reduced. During the refinement step, only atoms in
the left-hand side are suppressed, so there is no way to break joins between existentially quantified
variables as they are located only in the right-hand side. This means that M ′ is split-reduced.

Also, the refinement use one quasi-lattices for each block of ψ -equivalent tgds. So the only
way to create equivalent tgds is to validate two equivalent left-hand sides conjunctions in a same
quasi-lattice, and there is no equivalent nodes in such quasi-lattice. This mean that M ′ has no
σ -redundant tgds.

□

3.3.4 Questioning about atoms set validity. In the atom refinement algorithm, the user is chal-
lenged on the validity of the left-hand side atoms of the canonical mapping at line 10 of Algorithm 1.
We build on the correspondence between these atoms and the tuples that appear in the sources
ESi to ask pertinent questions, as those shown in Example 3.10. The AskAtomSetValidity(e,ψb )
subroutine that appears in Algorithm 1 constructs a pair (ESe,ψb , ET e,ψb ) by transforming the
candidate subset e into ESe,ψb , formally ESe,ψb = (cid:8) ¯θ (a)|a ∈ e(cid:9)). Then the chase procedure is used
to compute ET e,ψb , formally ET e,ψb = chase(e → ψb , ESe,ψb ).

Example 3.14. This example focuses on the generation of the exemplar tuples underlying the
questions of Example 3.10 while refining the tgds (2) and (4). We are challenging the user about the
validity of the set of atoms e = {F(idF0, town2, town1, idAir0); A(idAir0, name1, town1)}, which is a
subset of the left-hand side of the tgds (2) and (4). For each tgd, these atoms are built from the sets
S = {F(f0, Miami, L.A., a0); A(a0, AA, L.A.)} and E2′
E1′
S = {F(f0, Lyon, Paris, a0); A(a0, AF, Paris)}
,respectively a subset the of instances E1
S. We want to challenge the user whether the
following generalization of the tgds (2) and (4) is sufficient:

S and E2

σ =F(idF0, town2, town1, idAir0) ∧ A(idAir0, name1, town1)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)
T (resp. E2′
T ),

S ) to obtain the following instance E1′

The chase procedure applies σ on E1′

S (resp. E2′

from which the first question appearing in Example 3.10 is derived:

1′
T = {Dpt(Miami, f2, c0); Arr(L.A., f2, c0); Co(c0, AA, L.A.)}
2′
T = {Dpt(Lyon, f2, c0); Arr(Paris, f2, c0); Co(c0, AF, Paris)}

E

E

3.4 Join refinement between variables of a tgd
In relational data, multiple occurrences of the same value do not necessarily imply a semantic
relationship between the attributes containing such a value. An example from our running scenario
is the occurrence of the constant L.A. both as the city where an airline company is located, and as
the arrival and departure city of flights booked by that airline company. However, the canonical
mapping imposes such co-occurrences that may be due to spurious use of the same variable. Thus,
the canonical mapping may introduce irrelevant joins in the left-hand side of the tgds. In order
to produce the mapping the user has in his mind, we primarily need to distinguish relevant joins
from irrelevant ones. This section presets the join refinement step and details the join Algorithm 2
that explores the candidate joins in each tgd by inquiring the user about the validity of such joins.
As joins in conjunctive queries are encoded by multiple occurrences of a variable, we refer to
these variables as to join variables, refining a join corresponds to replace some occurrences with

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:15

Algorithm 2 TgdsJoinRefinement(Σ)
Input: A set of tgds Σ to be join refined.
Output: A set of tgds Σ′ where each tgd is join refined.

1: Σ′ ← ∅
2: for all σ ∈ Σ do
3:
4:
5:

let σ = ϕ(x) → ∃y,ψ (x, y)
Σt ← {σ }
for all x ∈ x do

6:
7:
8:
9:
10:
11:

if variable x occurs more than once in ϕ then

Σexplor ed ← Σt
Σt ← ∅
for all σ ′ ∈ Σexplor ed do

Σt ← Σt ∪ VarJoinsRefinement(Σt , σ ′, x)

end for

end if

end for
Σ′ ← Σ′ ∪ Σt

12:
13:
14:
15: end for
16: return Σ′

fresh variables. In Algorithm 2 this replacement of join variables by fresh ones is conducted by the
subroutine named VarJoinsRefinement which is detailed in Algorithm 3. The subroutine explores
the partitions of these newly introduced variables and questions the user to check if the joins are
relevant (some fresh variables are unified) or not (they are kept renamed). A block in the set of all
partitions represents the variables to be unified together.

(5)

Example 3.15. Recall tgd (5) from Example 3.10 obtained after the atom-refined mapping below:
F(idF0, town2, town1, idAir0) ∧ A(idAir0, name1, town1)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)
There is an ambiguity on the use of the same town as the town of arrival and departure of flights
and the town where a travel agency is located, as shown by the multiple occurrences of the join
variable town1 at four different positions. Each occurrence of town1 is replaced with a fresh variable
(namely town1
′, town1
F(idF0, town2, town1

′′, town1
′′′ and town1
′, idAir0) ∧ A(idAir0, name1, town1

′′′′) yielding the following candidate tgd:

′′)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1
In the corresponding quasi-lattice of the set {town1

′′′′)
′′′′}, the upper-
bound corresponds to the case where no refinement is needed, all occurrences being replaced with
the original town1.

′′′, idF2, idC0) ∧ Co(idC0, name1, town1

′′′, town1

′′, town1

′, town1

Given a variable x in a tgd σ = ϕ → ψ , we consider the set of its occurrences in ϕ ∪ ψ . Since
we do not wish to introduce new existentially quantified variables, each variable occurrence in ψ
must be bound to at least one variable occurrence in ϕ. In order to achieve this, we only consider
the partitions in which all blocks contain at least one occurrence in ϕ. Those partitions are called
well-formed.

Well-formed partitions are equipped with a quasi-lattice structure: given two partitions P and
P ′, if P ≤ P ′ and P is well-formed, then P ′ is well-formed as well. In particular, if P ≤ P ′ then

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:16

A.Bonifati et al.

all unifications encoded by P are also performed encoded in P ′. This means that if P is acceptable
for the user, then it is also the case for P ′. Conversely, if P ′ is not acceptable for the user (i.e., some
joins are missing), then neither is P. We employ these criteria to prune the search space during the
exploration of the quasi-lattice of occurrences of x. This quasi-lattice structure allow us to avoid
exploration of partitions leading to redundant tgd, which is not the case with the use of separate
semilattices as used in [13].

Example 3.16. Following Example 3.15, town1

′′′ and town1

′ or town1

′′. This means that partitions containing one of the blocks {town1

′′′′ must be in a partition containing
′′′},

′′′′} or {town1

′′′, town1

′′′′} are not well-formed and will be excluded.

either town1
{town1

Algorithm 3 Subroutine:VarJoinsRefinement(Σt , σ , x)
Input: A set of previously join refined tgds Σt .
Input: A tgd σ .
Input: A variable x ∈ σ on which the refinement is made.
Output: A set of tgds Σout of join refinements of σ for variable x.
1: generate from σ a tgd σ ′ where occurrences of x are renamed with fresh variables and a

morphism µor iд such that µor iд(σ ′) = σ

2: let σ ′ = ϕ ′ → ψ ′
3: Jcand ← generate set of possibles candidates join partitions from σ ′
4: Jv ← generate supremum of the join lattice from σ ′
5: while Jcand (cid:44) ∅ do
6:
7:
8:

P ← SelectPartition(Jcand , Jv )
σ ′′ ← UnifyVariables(σ ′, P)
if (∄σt ∈ Σt , σt |= σ ′′) ∧ AskJoinsValidity(σ ′′) then

add P to Jv
remove upper partitions of P from Jv
remove P and its upper partitions from Jcand

remove P and its lower partitions from Jcand

else

9:
10:
11:
12:
13:
14:
end if
15: end while
16: Σout ← ∅
17: for all P ∈ Jv do
18:
19:
20: end for
21: return Σout

σ ′′ ← UnifyVariables(σ ′, P)
add σ ′′ to Σout

Algorithm 2 implements the join refinement by iterating variable refinements on each universal
variable of each tgd. As we do not consider the possibility of creating new joins, but only the
suppression of joins which already exists, each original variable is considered separately. However,
since each call to VarJoinsRefinement may generate multiple refined tgds, one for each refined
join variable, we need to combine these refinements. This is done by verifying that the join partition
currently evaluated does not lead to produce a tgd which is redundant or prunable. This is done in
Algorithm 3 at line 8, by checking if there’s another tgd σt ∈ Σt which is a model of the currently
evaluated tgd (i.e. σt is logically equivalent or more general than the evaluated tgd).

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:17

Subroutine VarJoinsRefinement(σ , x) explores the part of the quasi-lattice of a variable x
corresponding to a tgd σ , asking questions to the user in order to determine the proper join
refinement. In line 1, occurrences of x are replaced with fresh variables yielding a tgd σ ′ and a
morphism µor iд such that µor iд(σ ′) = σ . Line 3 initializes the quasi-lattice by excluding malformed
partitions as stated above. The SelectPartition subroutine selects a partition in the set of partitions
and encodes the specific exploration strategy on top of the quasi-lattice. Any suitable exploration
strategy can be plugged in here, as shown in the experimental study presented in Section 6. Function
UnifyVariables(σ , P) (lines 7 and 18 of the Algorithm) returns a tgd corresponding to σ where
variables from the same block of a partition P are unified. The user is asked about the validity of this
unification in line 8 and the search space and results are pruned according to his answer in lines 10,
11 and 13. One can easily prove the following Lemma, which is the counterpart of Lemma 3.11 for
join refinement. Hence, Lemma 3.17 establishes the logical entailment of the join-refined mapping.

Lemma 3.17. Let Σ be a mapping and let Σ′ be a mapping obtained from Σ after join refinement,

then Σ′ |= Σ.

Proof. Let σ = ϕ → ψ be a tgd and x be a universal variable in σ . First, we prove that for all

σ ′′ ∈ VarJoinsRefinement(σ , x), σ ′′ |= σ .

Let σ ′ = ϕ ′ → ψ ′ be the tgd obtained from σ by replacing occurrences of x with a fresh variable,
and µor iд be the morphism such that µor iд(σ ′) = σ . Let σ ′′ = ϕ ′ → ψ ′. As σ ′′ results from the
unification of fresh variables in σ ′, there is a morphism µunif such that µunif (σ ′) = σ ′′. Let µσ ′′
be the morphism defined by: µσ ′′(y) = x if y results from the unification of fresh variables in σ ′,
µσ ′′(y) = y otherwise. By construction, µσ ′′(σ ′′) = σ . One can remark that existential variables in
ψ ′′ are the same as the ones in ψ , thus µσ ′′ is injective for these variables.

In Algorithm 2, Σt contains tgds that are either elements of Σ or obtained by applying Var-
Refinement to previous elements of Σt . Because of line 8, VarRefinement always returns at least
one tgd. Thus, for each initial tgd σ in Σ, there is a tgd σ ′ in Σ′ coming from successive calls of
VarRefinement starting with σ . By transitivity of |= we deduce that σ ′ |= σ . Thus, Σ′ |= σ . Since
□
this holds for all tgds in Σ, we conclude that Σ′ |= Σ.

Example 3.18. We recall the tgd (5) from Example 3.10:

F(idF0, town2, town1, idAir0) ∧ A(idAir0, name1, town1)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)

(5)

Its set of universal variables is x = {idF0, town2, town1, idAir0, name1}. As Algorithm 2 only
considers variables that appears several times (line 6), we only consider town1 and idAir0 of x.
′′
Considering first the idAir0 variable, a renaming of each of its occurrences to idAir0
leads to the following tgd:

′ and idAir0

F(idF0, town2, town1, idAir0

′) ∧ A(idAir0

′′, name1, town1)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1, idF2, idC0) ∧ Co(idC0, name1, town1)

(6)

′} ; {idAir0
′′}}. The
The quasi-lattice contains two partitions {{idAir0
′′}}, i.e., to have the identifier of an airline
′} ; {idAir0
user is asked about the validity of {{idAir0
company unrelated to its flight. The user will likely answer ‘No’ to the above question, thus keeping
′′}} of the quasi-lattice valid. Since these join is relevant, the tgd
the upper-bound {{idAir0
is not modified.

′′}} and {{idAir0

′; idAir0

′; idAir0

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:18

A.Bonifati et al.

Then, we consider the town1 variable. A renaming of each of its occurrences leads to the following

tgd previously given in Example 3.15:

F(idF0, town2, town1

′, idAir0) ∧ A(idAir0, name1, town1

′′)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1

′′′, idF2, idC0) ∧ Co(idC0, name1, town1

′′′′)

There are five partitions that do not create new existential variables, namely :

′; town1
′; town1

{{town1
{{town1
and {{town1

′′′} ; {town1
′′′; town1

′′; town1
′′′′} ; {town1
′′′; town1

′′′′}} , {{town1
′′}} , {{town1
′′′′}} .

′; town1

′′; town1

′; town1
′} ; {town1

′′′′} ; {town1
′′; town1

′′; town1
′′′; town1

′′′}} ,
′′′′}}

The user is asked about the validity of the candidate partition {{town1
with the following question:

′; town1

′′′} ; {town1

′′; town1

′′′′}}

“Are the tuples F(f0, Miami, L.A.′, a0) and A(a0, AA, L.A.′′) enough to produce
Dpt(Miami, f2, c0), Arr(L.A.′, f2, c0) and Co(c0, AA, L.A.′′)?”

Since this partition is acceptable for the user, he will probably answer ‘Yes’. Therefore, the upper-
′′′′}} of the quasi-lattice is pruned and the following tgd

′′′; town1

′′; town1

bound {{town1
′; town1
is added to the output:

F(idF0, town2, town1

′, idAir0) ∧ A(idAir0, name1, town1

′′)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1

′, idF2, idC0) ∧ Co(idC0, name1, town1

′′)

The exploration continues with the remaining candidate partitions. However, as the remaining
partitions either relate an airline’s headquarters to an arrival or a flight to a company’s headquarters,
the user will consistently answer ‘No’ to these questions.

As formalized in the following Lemma 3.19, the join refinement step preserves the split-reduction
property of mappings and, at the opposite of the work in [13], does not might introduce σ -redundant
tgds. Hence, similarly to the atom refinement step and its associated Lemma 3.13, a normalization
step following join refinement is not necessary.

Lemma 3.19. Given a normalized mapping M = (S, T, Σ), application of join refinement on the

tgds in Σ always produces a mapping which is normalized.

Proof. By definition, if a tgd σ is split-reduced and contain more than one atom in its right-
hand side, these atoms (at least two) are joined using existentially quantified variables. Since join
refinement only focuses on universal variables, existential variables are preserved. Thus, all atoms
in the right-hand side of join refined tgds are joined together using these existential variables,
which means that join refined tgds are also split-reduced.

As Σ is normalized, each of its tgd is split-reduced. Since for each tgd in Σ, the application of
the join refinement step results in new tgds that are also split-reduced. Thus, the set Σ′ of all these
refined tgds is a split-reduced mapping.

As each tgd is produced only if there’s no logically equivalent tgd previously produced (Algo-

rithm 3 at line 8), then no additional step of σ -redundancy suppression is needed.

As the mapping produced is split-reduced and does not contain σ -redundancy, then it is normalized.
□

In the join refinement step, the suppression of joins can generate additional tuples in the target
instance. For such a reason, similarly to the generation of questions in the atom refinement step,

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:19

. . .

Mcan

|=

Minf
|=
Mexp

∅

Given a mapping Mexp expected by an user :

|= Mcan is proved in Theorem 4.5
Minf
Mexp |= Minf is proved in Theorem 4.6
Confluence to a mapping Mf inal is proved in Theorem 4.7
Convergence is proved in Theorem 4.8

. . .

If a fully informative exemplar tuples set is provided :

Mf inal ≡ Mexp is proved in Theorem 4.14

Fig. 4. Summary of the main theorems about our framework (in Section 4).

the source instance is again chased to generate such additional tuples 2. Similarly to the subroutine
described in Section 3.3.4 for atom refinement, the AskJoinsValidity subroutine that appears in
Algorithm 2 constructs a pair (ES σ , ET σ ) by instantiating the left-hand side of a candidate tgd σ to
obtain a source instance ES σ and then chasing it to build ET σ .

Example 3.20. We illustrate the questions asked to the user in Example 3.18. We challenge the
′′′′}} in the following

′′′} ; {town1

′′; town1

′; town1

user on the validity of the partition P = {{town1
tgd:
σ =F(idF0, town2, town1

′, idAir0) ∧ A(idAir0, name1, town1

′′)

→ ∃idC0, idF2, Dpt(town2, idF2, idC0) ∧ Arr(town1

′, idF2, idC0) ∧ Co(idC0, name1, town1
′′)
The instance ES σ obtained from the left-hand side of σ through the bijection ¯θ is the following:
σ = {F(f0, Miami, L.A.′, a0); A(a0, AA, L.A.′′)}

ES

Chasing ES σ with σ leads to:

ET

σ = {Dpt(Miami, f2, c0); Arr(L.A.′, f2, c0); Co(c0, AA, L.A.′′)}

Those exemplar tuples are finally rewritten into questions as shown in Example 3.18.

At the end of this step, the mapping Mf inal is returned to the user as the result of the framework

execution.

4 FORMAL GUARANTEES OF THE FRAMEWORK
In this section, we prove the correctness and the completeness of our interactive mapping specifi-
cation framework.

First, we describe the set of questions that can be asked by our framework and the transition
rule that describes how the framework rewrites the mapping at each iteration. Then, we show that
if the user provides a set of exemplar tuples for his expected mapping, then our framework will
converge to a single mapping in the space of all possible inferred mappings. Finally, we show that
if the user provides a set of exemplar tuples that fully describe the mapping that he has in mind,
then our framework will always return a logically equivalent mapping to the latter mapping. The

2We recall that the chase is polynomial for Σ consisting of only s-t tgds. Thus, repeating it several times as additional tuples
come, is appropriate.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:20

A.Bonifati et al.

mains theorems of this section are summarized in Figure 4, which offers a guideline for the reader
through the main theorems.

The set of all possible tgds explored by our process, and the set of questions about the validity of

those tgds are expressed as follows :

Definition 4.1 (Explored set of candidates tgds). Let Mcan be a canonical mapping. The set of

candidates tgds is defined as follows :
Mcandidat es = (cid:216)

{ϕ ′ → ψ ′|ϕ ′ (cid:44) ∅ ∧ ψ ′ (cid:44) ∅ ∧ (∃µ such that µ(ϕ ′) ⊆ ϕ ∧ µ(ψ ′) ⊆ ψ )}

(ϕ→ψ )∈Mc an

Definition 4.2 (Set of asked questions). Let Mcan be a canonical mapping. Let Mcandidat es be the
set of tgds explored by our framework for Mcan. The set of questions Q that can be asked by our
framework is the set :

Q = {“Are the tuples ¯θ (ϕ) enough to produce ¯θ (ψ )?” | (ϕ → ψ ) ∈ Mcandidat es }
Given a previously inferred mapping, a question and the oracle’s answer to this question, our

framework will produce a new mapping. This is expressed by the following transition rule :

Definition 4.3 (Transition rule). Let Minf be a mapping. Let q be a question about the validity of

the tgd ϕ → ψ .

Then we have :

M

q
−→ M ′ such that : if answer (q, Oracle)

then M ′ = M ∪ (ϕ → ψ )
else M ′ = M

Remark 1. The framework is non-deterministic as there are multiple possible questions q that can

be asked from a single mapping M.

Our framework uses the canonical mapping, computed from the user’s set of exemplar tuples,
as the initial mapping. Then, our framework iteratively rewrites this mapping by asking the
questions in the set Q defined in definition 4.2. This exploration can be expressed as a succession
of applications of transition rule over Q. More formally :

Definition 4.4 (Exploration). Let Mcan be a canonical mapping. Let Q be the set of questions that

can be asked over Mcan.

Then, an exploration of the set Q is a series of applications of the transition rule :

Mcan

q1
−→ . . .

qn−−→ Minf such that {q1; . . . ; qn } ∈ Q

Minf is called an inferred mapping.
Correctness of the framework. We will now show that, given an expected mapping Mexp and a
canonical mapping Mcan obtained from a set of exemplar tuples for Mexp , then every mapping
Minf inferred by our framework is such that Mexp |= Minf

First, we show that the inferred mappings imply the canonical mapping. This comes from the
fact that our framework will relax constraints of the canonical mapping, without introducing new
ones.

|= Mcan.

Theorem 4.5. Let Mcan

q1
−→ . . .

qn−−→ Minf be an exploration. Then :
|= Mcan

Minf

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:21

Proof. This theorem follows from the definition 4.3. This definition shows that consecutive
applications of the rewriting rules will only add new tgds without suppressing tgds in Mcan. Thus,
□
Minf ⊇ Mcan, from which follow Minf

|= Mcan.

In addition to this theorem, we show that our framework will only produce mappings implied
by the expected mapping. This guarantees that the inferred mapping will not produce extraneous
tuples that would not be produced by the expected mapping.

Theorem 4.6. Let Mexp be the expected mapping by Oracle. Let E be a set of exemplar tuples for
qn−−→ Minf be an

Mexp . Let Mcan be the canonical mapping computed from E. Let Mcan
exploration. Then :

q1
−→ . . .

Proof. The proof is done by induction over an exploration :

Mexp |= Minf

• Suppose that we have an exploration Mcan

q1
−→ . . .

qn−−→ Minf such that Mexp |= Minf . The

application of a new rewriting rule will lead to the following exploration :

Mcan

q1
−→ . . .

qn−−→ Minf

qn+1
−−−→ M ′

inf

with qn+1 being a question over a tgd ϕ → ψ .
– if answer (qn+1, Oracle) = false then, by definition 4.3, M ′
inf
.
– if answer (qn+1, Oracle) = true then, by definition 4.3, M ′
inf

hypothesis : Mexp |= M ′
inf

= Minf ∪ {ϕ → ψ }. Also, by
definition 3.7, if the oracle answer true to qn+1 then ψ ⊆ chase(ϕ, Mexp ), i.e. Mexp |=
{ϕ → ψ }. Since Mexp |= Minf by induction hypothesis, we obtain Mexp |= M ′
inf

.

= Minf . By the induction

• From E we have the non-normalized canonical mapping :

Mcan_r aw = { ¯θ −1(ES) → ¯θ −1(ET ) | (ES, ET ) ∈ E}

By definition 3.1 of the exemplar tuples we also have :

∀(ES, ET ) ∈ E, ET ⊆ chase(Mexp, ES)

As ¯θ −1 is an isomorphism, we can do the following substitution :

∀( ¯θ −1(ES) → ¯θ −1(ET )) ∈ Mcan_r aw , ¯θ −1(ET ) ⊆ chase(Mexp, ¯θ −1(ES))
which means, by definition of mapping implication, that Mexp |= Mcan_r aw .
By correctness of the normalization rules (split-reduction and σ -redundancy suppression [23]),
we have Mcan ≡ Mcan_r aw , and thus Mexp |= Mcan.

□

Moreover, our framework will always converge to one unique mapping regardless of the order
in which questions are asked. This is shown in the following theorems showing the confluence and
the convergence of our framework :

Theorem 4.7 (Confluence). Let M be a mapping. Let M

Mm be two explorations from M.
Then there exists a mapping M ′ such that we can find two explorations :

q1
−→ . . .

qn−−→ Mn and M

q′
1−→ . . .

q′
m−−→

Mn

qn+1
−−−→ . . .

qn+k−−−−→ M ′ and Mm

q′
m+1
−−−−→ . . .

q′
m+k′
−−−−→ M ′

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:22

A.Bonifati et al.

Proof. When a question is asked, the tgd corresponding to this question will be added or not to
the inferred mapping, depending on the oracle answer. This process is completely independent from
the previously asked questions and does not modify the set of questions that are asked. Therefore,
the order in which questions are asked does not influence the result. Thus, it is easy to construct
the two sets questions {qn+1; . . . ; qn+k } and {q′
{qn+1; . . . ; qn+k } = {q′
m+1; . . . ; q′
{q′

m+1; . . . ; q′
m+1; . . . ; q′
m+k } = {qn+1; . . . ; qn+k } \ {q′

} as follows :
m+k
m+k ′ } \ {q1; . . . ; qn }
m }

1; . . . ; q′

□

Theorem 4.8 (Convergence). Let Mcan

Then :

q1
−→ . . .

qk−−→ Mk

qk +1
−−−→ . . . be an infinite exploration.

∃k ∈ N such that ∀k ′ ≥ k, Mk ≡ Mk ′
Proof. This follows from definition 4.2 of the set of all questions that can be asked, and from
Theorem 4.7. If the whole set of questions is explored, then asking one of this question one more
time, or asking a question isomorphic to a question of this set, will only lead to an equivalent
□
mapping.

Following from the convergence theorem, we can define a complete exploration for our framework

as follows :

Definition 4.9 (Complete exploration). Let Mcan be a canonical mapping. Let Q be the set of

questions that can be asked over Mcan.

Then, a complete exploration of the set Q is a series of applications of the transition rules :

such that :

Mcan

q1
−→ . . .

qn−−→ Mf inal where {q1; . . . ; qn } ∈ Q

∀q ∈ Q, Mf inal

q
−→ Mf inal

Completeness of the framework. If an user produce a set of exemplar tuples that does not contain
the necessary information to derive each tgd in his expected mapping, then it’s easily seen that
the final mapping obtained after a complete exploration cannot be equivalent to the expected one.
However, we will now show that if the user provides a fully informative set of exemplar tuples for
his expected mapping, our framework will always return a mapping logically equivalent to the
user’s expected mapping.

To do so, we will first show that for every expected mapping, there exists an ideal set of questions
such that if they are all asked to the user, then the framework will return a mapping logically
equivalent to the expected mapping. Then we show that, for every fully informative set of exemplar
tuples for the user’s expected mapping, our framework will always ask the ideal set of questions.

Definition 4.10 (Ideal exemplar tuples set). Let M be a mapping. Let E be a set of exemplar tuples
for M. Then E is an ideal exemplar tuples set if the canonical mapping Mcan extracted from E is
such that Mcan ≡ M.

Lemma 4.11. For all GLAV mapping M, there exists an ideal exemplar tuples set Eideal .
Proof. W.l.o.g., we suppose that M is normalized. From M we can construct a set :

E = {( ¯θ (ϕ), ¯θ (ψ ))|(ϕ → ψ ) ∈ M}
As each exemplar tuple (ES, ET ) ∈ E come directly from a tgd σ ∈ M, it follows that ET ⊆
chase(σ , ES). It follows that E is an exemplar tuples set for M.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:23

Also, as the non-normalized canonical mapping Mcan_r aw is obtained by applying the morphism

from tuples to atoms ¯θ −1 to each exemplar tuple in E and by definition of E, we obtain :

Mcan_r aw = {( ¯θ −1( ¯θ (ϕ)) → ¯θ −1( ¯θ (ψ )))|(ϕ → ψ ) ∈ M}

= {(ϕ → ψ )|(ϕ → ψ ) ∈ M}
= M

We know than the normalization of Mcan_r aw lead to a mapping Mcan ≡ Mcan_r aw , so Mcan ≡

M. Thus, the set E is an ideal exemplar tuples set for M.

□

Lemma 4.12. Let Mexp be the mapping expected by the oracle Oracle.

Let E be a set of exemplar tuples for Mexp .
Let Mcan be the canonical mapping computed from E.
Let Eideal be the ideal exemplar tuples set for Mexp .
Let Q = {q1; ...; qn } be the following set of questions :

q1
−→ . . .

Let Mcan
Then Mf inal ≡ Mexp

q2
−→ . . .

{“Is ES enough to deduce ET ?” | (ES, ET ) ∈ Eideal }
qn−−→ Mf inal be an exploration over the set of questions Q.

Proof. By construction of Eideal (proof of Lemma 4.11), then Oracle will always answer true
to each question in Q. We also know by the construction of Eideal that to each tgd in Mexp it
corresponds to one, and only one, pair (ES, ET ) ∈ Eideal .
q
−→ Mi+1 over a question q ∈ Q will add a
Thus, each application of the transition rule Mi
tgd from Mexp to Mi . At the end of the exploration over Q, we obtain the mapping Mf inal =
Mcan ∪ Mexp . Thus, Mf inal ⊇ Mexp and consequently Mf inal

|= Mexp .

□

From Theorem 4.6, we also have that Mexp |= Mf inal , so Mf inal ≡ Mexp .
Lemma 4.13. Let Mexp be the mapping to describe (supposed in normal form).

Let EF I be a fully-informative exemplar tuples set for Mexp .
Let Mcan be the canonical mapping constructed from EF I .
Let Q be the set of questions asked from Mcan.
Let Eideal be the ideal exemplar tuples set for Mexp as described in Lemma 4.11.

Then we have :

i.e., our framework leads to explore the ideal exemplar tuples set Eideal .

Proof. For each tgd (ϕ → ψ ) ∈ Mexp there exists an exemplar tuple (ES, ET ) such that :

Eideal ⊆ Q

∃E ′

S ⊆ ES s.t. (chase(σ , E ′

S) (cid:44) ∅) ∧ (chase(σ , E ′

S) ⊆ ET )

By construction of Mcan, for each tgd (ϕ → ψ ) ∈ Mexp there exists a tgd (ϕ ′ → ψ ′) ∈ Mcan such
that :

∃ϕ ′′ ⊆ ϕ ′ s.t. (chase(σ , ϕ ′′) (cid:44) ∅) ∧ (chase(σ , ϕ ′′) ⊆ ψ )
So, there’s a substitution µ such that all atoms in ϕ can be mapped to atoms in ϕ ′′ and an extension

µ ′ of µ mapping all atoms of ψ to atoms in ψ ′′ = chase(σ , ϕ ′′). This lead to :

µ(ϕ) ⊆ ϕ ′′ ⊆ ϕ ′ and µ ′(ψ ) ⊆ ψ ′′ ⊆ ψ ′

.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:24

A.Bonifati et al.

By construction of Eideal , for each tgd (ϕ → ψ ) ∈ Mexp there exists (ES, ET ) ∈ Eideal such
that ϕ = ¯θ −1(ES) and ψ = ¯θ −1(ET ). Thus, we can find a tgd (ϕ ′ → ψ ′) ∈ Mcan such that there is a
morphism µ and its extension µ ′ such that µ( ¯θ −1(ES)) ⊆ ϕ ′ and µ ′( ¯θ −1(ET )) ⊆ ψ ′. From this and
from Definition 4.1 and Definition 4.2, for all exemplar tuples (ES, ET ) ∈ Eideal the question about
the validity of tgd ¯θ −1(ES) → ¯θ −1(ET ) is in the set Q.
□

Theorem 4.14 (Our framework can always produce a mapping logically eqivalent to
the expected one). Let Mexp be the mapping expected by the oracle Oracle. Let EF I be a fully
informative exemplar tuples set for Mexp . Let Mcan be the canonical mapping computed from EF I .
Let Mcan

qn−−→ Mf inal be a complete exploration performed by our framework. Then :

q1
−→ . . .

Mf inal ≡ Mexp
Proof. In Lemma 4.12 we show that if our framework ask all the questions of the ideal exemplar
tuples set for the expected mapping Mexp , then the output mapping M will be such that M ≡ Mexp .
In Lemma 4.13 we show that, given a fully informative exemplar tuples set for Mexp , then our
framework will ask all questions of the ideal exemplar tuples set for Mexp . From this follow our
□
theorem.

We will show now that the limitation over the pruning maintain the completeness of the

framework.

Theorem 4.15. Given an execution of our framework, the pruning does not affect the completeness

of our approach.

Proof. The pruning work in two ways :
• if Mexp |= σ , then we prune each questions about a tgd σ ′ such that σ |= σ ′. Trivially, there
is no need to explore implied tgd of an already validated tgd as they can be validated by
transitivity. Also, there is no need add them to the final mapping, as they can only create
redundant tuples.

• if Mexp ̸|= σ , trivially we can prune each questions about a tgd σ ′ such that σ ′ |= σ .

□

5 EMBEDDING INTEGRITY CONSTRAINTS
In the previous section, we have described the core of our approach. Now, we will describe how a
user can introduce integrity constraints to help the lattice pruning. Integrity constraints provide a
way to define guidelines over a database schema, and ensure that the instances over this schema
will comply to these guidelines. In practice, the most commonly used integrity constraints are
primary keys and foreign keys (a particular case of inclusion dependencies). Such constraints are
classic tools of database design, and therefore are easily available in real integration scenarios.

Introduction of integrity constraints constitutes an extension of our initial (IMS) problem. This
Interactive Mapping Specification with Integrity Constraints approach (IMSIC) can be stated as follows :

(IMSIC) Given a set of exemplar tuples E and a (possibly empty) set of constraints ΣI C provided by a
non-expert user, given a mapping M that the user has in mind, the Interactive Mapping Specification
with Integrity Constraints problem is to discover, by means of boolean interactions, a mapping M ′
such that each (ES, ET ) ∈ E satisfy M ′, M ′ is valid w.r.t. ΣI C and M ′ generalizes M.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:25

Considered schema
Source
Target

Primary keys
Not applicable
Section 5.2

Foreign keys
Section 5.1
Beyond scope

Fig. 5. Summary of the main theorems about our framework (in Section 4).

The possible cases of use of integrity constraints are summarized in Figure 5. Foreign keys over
source schema and primary keys over target schema are addressed, respectively, in Section 5.1 and
Section 5.2. Primary keys over the source schema cannot be used for our pruning, as this constraint
should be satisfied by the source instances provided by users. Else, it will mean that user provided
an instance which already violates the constraints over his schema, so this instance cannot be used
to exemplify his schema mapping problem. The use of foreign keys over the target schema lead to
non-trivial extension that are beyond the scope of this paper.

5.1 Use of foreign keys under source schema
The introduction of foreign keys constraints (and, more generally, of inclusion dependencies) can
inform us about which tuple (containing a foreign key) can only occur in the presence of another
tuple (referenced by the foreign key). This information between tuples can be represented by a
graph as defined as follows :

Definition 5.1 (Foreign key constraint.). Let R be a database schema. Let S and T be two relation
symbols such that S, T ∈ R. Let X and Y be two distinct sequences of attributes over, respectively,
S and T .

Then a foreign keys constraint is a constraint such that :

S[X ] ⊆ T [Y ] and Y is a key of T
Foreign keys are a particular case of inclusion dependencies constraints, for which Y don’t need

to be a key of T . Our system works with inclusion dependencies, so foreign keys are handled.

In our algorithm, we use inclusion dependency graphs to represent the constraints conveyed by
the provided inclusion constraints over a conjunction of atoms. In such a graph, given each pair
of atoms in the conjunction, there exists an directed edge between these atoms if they satisfy a
provided inclusion constraint. More formally :

Definition 5.2 (Inclusion dependency graph.). Let ϕ be a conjunction of atoms over a schema S.

Let ΣIC_S be a set of integrity constraints over S.

The inclusion dependency graph over ϕ is the directed graph :

Gϕ = (atoms(ϕ), E)

with :

E = {⟨a1, a2⟩ | a1 ∈ ϕ, a2 ∈ ϕ, ∃σ ∈ ΣI C_S, ⟨ ¯θ (a1), ¯θ (a2)⟩ |= σ }
In this section, we make use of this graph during the atom refinement step as illustrated in the

following example :

Example 5.3. Given two schemas S = {S(x, y); U (x, y, z); V (z, x);W (z, x)} and T = {T (x)}. Given

an exemplar tuple (ES, ET ) over S and T such that :

ES = {S(a, b), U (a, b, c), V (c, a),W (c, a), S(d, e)}
ET = {T (a)}

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:26

A.Bonifati et al.

S(a, b)

S(d, e)

U .xU .y ⊆S .x S .y

U (a, b, c)

V .z ⊆U .z

V (c, a)

W .z ⊆U .z

W (c, a)

Fig. 6. Dependency graph of the atoms in ϕES (Example 5.3).

Given the corresponding conjunctions :

ϕES = S(a, b) ∧ U (a, b, c) ∧ V (c, a) ∧ W (c, a) ∧ S(d, e)
ψET = T (a)
and the set of foreign keys over the source schema S:

Σf k = {U .x, U .y ⊆ S.x, S.y; V .z ⊆ U .z;W .z ⊆ U .z}
Then we can draw the dependency graph of the atoms in ϕES shown in Figure 6 (for the sake
of clarity, edges are labeled with the corresponding inclusion dependency even if not used in our
algorithm) :

We can see that S(m, n) it is not linked to any other atom. At the opposite, atom V (z, x) is linked
to atom U (x, z), and this last one is linked to atom S(x, y). Therefore, we are sure that a tuple
triggering atom V (z, x) will always occur with tuples corresponding to atoms U (x, z) and S(x, y).
As a consequence, we can skip exploring conjunctions like V (z, x) and U (x, z) ∧ V (z, x) during
atom refinement step.

To make use of this, we propose Algorithm 4 in order to apply this optimization during atom
refinement. In this algorithm, for the sake of clarity, we abuse the notation of Gϕ = (atoms(ϕ), E)
by simply writing G when it’s obvious. To use it in Algorithm 1, the line

Ccand ← SourceFk_PruneUselessConjuction(Ccand , Cval id , Σsour ce F k )

need to be inserted just after line 6.

This algorithm takes the set of candidate conjunctions that can be explored and prune it w.r.t. to
inclusion dependencies. To achieve that, the algorithm begins by the construction of the dependency
graph previously for each upper-bound of the quasi-lattices. Then, for each dependency graphs
over an upper-bound, the algorithm check if the candidates that are subsets of this upper-bound
respect all the dependencies of the graph. If such a candidate does not respect every dependency,
it is pruned from the set of candidates output by the algorithm. In the following, we provide an
example that substantiates the informal description of the algorithm.

Example 5.4 (Pruning of quasi-lattice : the need of evaluating each supremum separately.). Given
two schemas S = {S(x, y); S ′(x, z); U (x, z)} and T = {T (x)}. Given two exemplar tuples over S and
T such that :

1
1
T ) = ({S(a, b), U (a, c)}, {T (a)})
(E
S, E
2
2
T ) = ({S ′(a, b), U (a, c)}, {T (a)})
(E
S, E

and the set of foreign keys over schema S:

Σf k = {U .x ⊆ S.x; U .x ⊆ S ′.x }
During atom refinement, as these tgds are ψ -equivalent, we will explore the atoms sets quasi-lattice
shown in Figure 7a

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:27

Algorithm 4 SourceFk_PruneUselessConjuction(Ccand , Σf k )
Input: A set Ccand of the candidate conjunctions to evaluate (as produced by Algorithm 1, line 5)
Input: A set Cup of the upper bound of the quasi lattice over Ccand (as produced by Algorithm 1,

line 6)

Input: A set of foreign keys or other inclusion dependencies on the source schema Σf k .
Output: A set C ′

of a the pruned set of candidates.

cand

▷ Generation of dependency graphs for each upper-bound

Et ← extract the pairs of atoms ⟨a1, a2⟩ such that a1, a2 ∈ ϕup and ¯θ (a1)[X ] ⊆ ¯θ (a2)[Y ]
Eϕup ← Eϕup ∪ Et

▷ Pruning of candidates

1: FG ← ∅
2: for all ϕup ∈ Cup do
Eϕup ← ∅
3:
for all (R[X ] ⊆ S[Y ]) ∈ Σf k do

4:

end for
Let G = (atoms(ϕup ), Eϕup )
FG ← FG ∪ {G}

9:
10: end for

cand

← Ccand

11: C ′
12: for all G ∈ FG do
13:

5:
6:

7:
8:

14:

15:

16:

end for

17:
18:
19: end for
20: return C ′

cand

Let G = (atoms(ϕup ), Eϕup )
for all c ∈ C ′
cand

such that c ⊆ ϕ do

if ∃⟨a1, a2⟩ ∈ Eϕup
cand

← C ′

cand

C ′
end if

such that a1 ∈ c ∧ a2 (cid:60) c then
\ c

{S; U }

{S ′; U }

{S }

{U }

∅

{S ′}

S(a, b)

U .x ⊆S .x

U (a, c)

U .x ⊆S ′.x

S ′(a, c)

(a) Explored atoms sets quasi-lattice.

(b) Dependency graph without separate upper bound elements

S(a, b)

U .x ⊆S .x

U (a, c)

and

S ′(a, c)

U .x ⊆S ′.x

U (a, c)

(c) Dependency graphs when separate upper bound elements

Fig. 7. Explored quasi-lattice and dependency graphs of Example 5.4

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:28

A.Bonifati et al.

If we don’t produce separate dependency graphs for each element in the upper bound, we will
obtain the graph in Figure 7b (for the sake of clarity, edges are labelled with the corresponding
inclusion dependency even if not used in our algorithm): This graph will lead to the pruning of
each conjunction except S(a, b) and S ′a, c). This is due to the fact that the perfectly acceptable
conjunction S(a, b) ∧ U (a, c) and S ′(a, c) ∧ U (a, c) does not contain the whole set of dependencies
expressed in the graph, and will be pruned by the condition line 15. In other words, this graph is
only usable if the conjunction S ∧ S ′ ∧ U can be accessed during atom refinement.

To avoid such a case, our algorithm constructs a dependency graph for each element in the
upper-bound of the quasi-lattice. This allows to check, for each dependency graph of an element in
the upper bound, if a candidate subset of this element does not express each of its dependencies. In
our example, this lead to generate the two small dependency graphs shown in Figure 7c.

This graphs leads to prune conjunction U (a, c) but not the conjunction S(a, b) ∧ U (a, c) as it
respects the dependency of the graph at the left and is not included in the other upper-bound
element S ′(a, c) ∧ U (a, bc) (this prevents to evaluate this conjunction with the dependency graph
at the right, which should have led to its pruning). The exact same principle leads to avoid the
pruning of the conjunction S ′(a, c) ∧ U (a, c).

Lemma 5.5. Given a quasi-lattice of atoms conjunctions as produced by our atom refinement step.
Given the dependency graphs that are generated separately for each element e of the upper-bound of
the quasi-lattice. If, for each graph of an element e, this graph is checked on a subset of e, then no valid
conjunction will be suppressed.

Proof. Given an element e and its corresponding graph G, then our algorithm will suppress
only candidates that are subsets of e and that violate at least one inclusion dependency represented
in G.

Moreover, given an atom δ ∈ e such that e \ δ violate an inclusion dependency in G, this means
that there is an atom γ ∈ e such that there is an inclusion dependency from γ to δ , i.e. γ will always
occur with the corresponding atom δ . Thus, there is no need to explore conjunction e \ δ as this
conjunction will be triggered as often as conjunctions e.

□

5.2 Use of primary keys under target schema
During the steps of our framework, exploration can lead to evaluate tgds which can lead to break
primary key constraints over the target schema as illustrated in the following example :

Example 5.6. Given exemplar tuples :

A Att1 Att2 Att3

a
a
c

b
b
b

a
c
c

→

B Att4 Att5 Att6

a

b

a

The join refinement of variable a will explore the following possibilities :
σ : A(a, b, a) → B(a, b, a)
σ1 : A(a, b, a′) → B(a, b, a′)
σ2 : A(a, b, a′) → B(a′, b, a)
σ3 : A(a, b, a′) → B(a, b, a)
σ4 : A(a, b, a′) → B(a′, b, a′)
Knowing that the pair of attributes (B.Att4, B.Att5) is a primary key allow us to prune σ1 and σ2
as the result of chasing the source instance A with σ1 and σ2 will lead, respectively, to instances
{B(a, b, a); B(a, b, c; B(c, b, c)} and {B(a, b, a); B(c, b, c; B(c, b, c)} which violate the constraint.

chase(σ , ES) = {B(a, b, a); B(c, b, c)}
chase(σ1, ES) = {B(a, b, a); B(a, b, c); B(c, b, c)}
chase(σ2, ES) = {B(a, b, a); B(c, b, a); B(c, b, c)}
chase(σ3, ES) = {B(a, b, a); B(c, b, c)}
chase(σ4, ES) = {B(a, b, a); B(c, b, c)}

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:29

To handle that, we propose the Algorithm 5 which, given a set of primary key constraints provided
by a user, allow to avoid exploration of candidates which can lead to break these constraints. To
use it in algorithm 3, the condition line 8 needs to be changed by :

(∄σt ∈ Σt , σt |= σ ′′) ∧ AskJoinsValidity(σ ′′) ∧ ¬TargetPk_InvalidTgd(σ ′′, Σ, {E

1
S; . . . ; En

S })

Algorithm 5 TargetPk_InvalidTgd(σ , Σ, {E1
Input: A tgd σ to evaluate.
Input: A set of primary key constraints Σt ar дet P k .
Input: A set of source instance {E1

S; . . . ; En

S; . . . ; En

S })

and/or other sources).

S } provided by the user (sources of the exemplar tuples

Output: return true if the conjunction can be pruned, else return false.

S ∈ {E1
S; . . . ; En
1: for all Ei
S } do
T = chase(σ , Ei
let Ei
S)
2:
T violates a primary key in Σt ar дet P k
tbool ← evaluate if Ei
res ← res ∨ tbool

3:
4:
5: end for
6: return res

In the following lemma, we show that the introduction of our optimization over primary keys

under target schema only prunes invalid candidates :

Lemma 5.7. Given a candidate tgd during join refinement steps, then Algorithm 5 only prune invalid

candidates.

Proof. Our optimization lead to prune candidate tgds which will lead to violate the user’s
constraint if such tgds are applied to the user’s examples. Thus, their invalidity is trivially seen. □

6 EXPERIMENTS
Our experimental study has three main objectives: (i) to provide a comparative analysis of the
quasi-lattice approach with the semi-lattice approach proposed in [13], (ii) to evaluate the benefit
of using exemplar tuples with respect to universal solutions for mapping refinement, and (iii) to
provide a comparative analysis with [6].
Experimental settings. We have implemented our framework using OCaml 4.03 on a 2.6GHz
4-core, 16Gb laptop running Debian 9. We have borrowed mappings from seven real integration
scenarios of the iBench benchmark [8]. The left part of Table 1 reports the size of each considered
mapping scenario as the total number of tgds (|Σ|) and the average number of occurrences of their
variables ( ¯N ) defined as ¯N = Σv ∈V Nv /|V |, with V being the set of distinct variables and Nv the
number of occurrences of each v variable within the tgds. Since there exists a bijection between
variables and constants, ¯N also stands for the average number of occurrences of constants per
instance in the exemplar tuples.
Methodology. In all experiments, we consider the iBench mapping scenarios as the ideal mappings
that the user has in mind. Starting from these mapping scenarios, we construct exemplar tuples as
follows. Each tgd σ ∈ Σ of the form ϕ → ψ is transformed into a pair of instances (ES σ , ET σ ), ES σ
(ET σ , resp.) being generated by replacing each atom in ϕ (ψ , resp.) by its tuple counterpart with
freshly picked constants for each variable in the tgd. Thus, for each scenario Σ = {σ1, . . . , σn }, we
obtain a set of exemplar tuples EΣ = {(ES σ1, ET σ1), . . . , (ES σn , ET σn )}.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:30

A.Bonifati et al.

σ1 : S(x, x, z) → T (x, x, z)

σ2 : S(x, y, x) → T (x, y, x)

S(x, y, z) → T (y, x, z)

σexp : S(x, y, z) → T (x, y, z)

S(x, y, z) → T (z, y, x)

Fig. 8. Quasi-lattice of Example 6.1

These exemplar tuples are used as a baseline in our experimental study, as we expect that an
“ideal” user, who does not make any mistakes, would actually produce such examples. In order
to introduce user ambiguities in the above tuples, we have built alternative test cases, in which
the exemplar tuples EΣ are degraded . The degradation procedure is meant to reproduce users’
common mistakes while specifying exemplar tuples.

As opposed to [13], we only focus here on atom degradation. The reason is that the introduction
of quasi-lattice does not add much improvement to the join refinement step, unless in some specific
cases as illustrated the following example :

Example 6.1. Let the expected mapping be :

Let the exemplar tuples provided by the user be :

Σexp = {σexp : S(x, y, z) → T (x, y, z)}

(ES 1, ET 1) = ({S(a, a, c)}, {T (a, a, c)})
(ES 2, ET 2) = ({S(a, b, a)}, {T (a, b, a)})

Then this set of exemplar tuples lead to the following canonical mapping :

Σcan = {σ1 : S(x, x, z) → T (x, x, z);
σ2 : S(x, y, x) → T (x, y, x)}

Hence, the occurrences of the constant a to represent variable y in (ES 1, ET 1) and variable z in
(ES 2, ET 2) lead to explore the quasi-lattice of tgds shown in Figure 8 during join refinement of x.
For our comparison with the approach used in [13], we have not created a new degradation
method to artificially improve our results. We keep the method in [13] which is more realistic and
give us a fair comparison.

Atom degradation procedure is parametrized by the total number of extraneous tuples added
to EΣ, with the constraint that at most one tuple is added to each individual instance ES σi . An
extraneous tuple is generated by randomly choosing a source instance ES σi , picking a tuple at
random within it, copying it and then replacing one constant of the tuple with a fresh one.

Example 6.2. By applying the degradation procedure on the tgd σ from Example 3.20, the follow-
′σ ). An extraneous F ′ atom is added, the degradation

′σ , ET

ing exemplar tuples may be yielded (ES
being underlined:

ES

ET

′σ = {F(f0, Miami, L.A.′, a0); F ′(f0, Miami, L.A.′, a0); A(a0, AA, L.A.′′)}
′σ = {Dpt(L.A.′, f2, c0); Arr(L.A.′, f2, c0); Co(c0, AA, L.A.′′)}

In our experimental study, we have deteriorated each initial set of examples EΣ by adding 0, 2, 5,

8 or 10 tuples.

For each of the above configurations, we repeated the degradation procedure 30 times in order

to obtain an equivalent number of degraded test cases.

Moreover, we simulate the user’s answers during the interactive part of our approach with the
following assumption: the user always replies correctly to a given challenge (i.e. an input pair

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:31

′ such that µ(ET ) ⊆ ET

′, otherwise ’No’ is returned.

(ES, ET )) w.r.t. the original mapping Σ from the scenario. In order to simulate the user answer, ES is
′. ’Yes’ is produced as an answer if there exists a substitution µ from ET into
chased to obtain ET
ET
Benefit of quasi-lattices. In the first experiment, we gauge the effectiveness of using quasi-
lattices structures compared to the isolated semi-lattices used in [13]. We focus on the Breadth-First
exploration strategies, both in Top-Down and Bottom-Up versions, as they’ve been shown to be the
more efficient in [13]. The use of quasi-lattices show to have a statistically significant correlation
with the number of questions asked during atom refinement (p − value = 4.74e − 14, tested with a
MANOVA). In the following, we will analyse the results of our experiments.

Table 1 presents the reduction obtained by the use of quasi-lattices (in percent) over the average
number of questions per tgd asked to the user (∆ ¯x), and over the maximum number of questions
per tgd (∆xm) for a scenario. It can be seen that the reduction of the average number of questions by
the use of quasi-lattices range from 0% to 12.7%, with a global reduction of 3.2%. Also, the reduction
of the maximal number of questions by the use of quasi-lattices range from 0% to 27%, with a global
reduction of 11.8%.

The efficiency of the optimisation is not directly correlated with the number of tgds in a scenario.
This is illustrated with scenarios amalgam2 and SDB1-to-SDB3, where the biggest one (amalgam2)
lead to a small amelioration, when the other one lead to the highest reduction of the number of
questions asked. This can be explained by the structure of the tgds contained by the scenarios. When
scenarios contain numerous but non overlapping tgds (i.e., our degraded exemplar tuples sets lead
to few ψ -equivalent tgds), most of the quasi-lattices cover one tgd at a time and consequently are
equivalent to the semi-lattices used in [13]. In the other case, even with less tgds than in amalgam2,
the use of quasi-lattices during refinement of scenario SDB1-to-SDB3 lead to an important reduction
of the number of question asked because this scenario contains tgds which are differentiated by
more subtle differences than in amalgam2. Such scenarios with numerous ψ -equivalent tgds leads
to exemplar tuples sets which are efficiently handled by the use of quasi-lattices.

Figure 9 illustrates the number of questions asked for each configuration. We recall that, in a
boxplot : the central bar correspond to the median; the lower and upper edges are, respectively,
the first and fourth quartiles; the lower and upper whisker are, respectively, the minimum and
maximum values excluding outliers; the isolated points are the outliers.

The boxplots shown that in the worst case values stay unchanged, and in the scenarios with the
highest number of questions asked (such as SDB1-to-SBD3 and amalgam2) the use of quasi-lattice
leads to efficiently decrease the number of questions asked. This is shown by the decrease of
the fourth quartiles value (i.e., the value such that 75% of data have a lower value) and by the
suppression (complete or partial) of outliers occurrences.

It is worth to note that, in some cases such as the scenario GUS-to-BIOSQL with 2 degradations
in Figure 9.(d), the use of quasi-lattices lead to a greater upper whisker for the same degraded
scenarios. This is due to the fact that upper whisker does not consider outliers. Hence, for degraded
scenarios leading to outliers without the use of quasi-lattices, the reduction of the number of
questions with the use of quasi-lattice lead to datapoints that are no more classified as outliers and
increase the upper whisker value. This can be seen in Figure 9 on scenario GUS-to-BIOSQL with
2 degradations, In this scenario, the case without quasi-lattices leads to outliers values up to 16
question, when the use of quasi-lattice. over the same degraded scenario reduce the number of
interactions to a maximum of 13 questions (which is not an outlier value).
Benefit of (non-universal) exemplar tuples. Our second experiment aims to evaluate the ben-
efit of using exemplar tuples as opposed to universal examples adopted in [6] for the mapping
S to obtain
inference process. For each scenario, we apply the chase to all the source instances Ei

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:32

A.Bonifati et al.

Scenarios

name

Degradations

a1-to-a2

amalgam2

dblp-amalgam

GUS-to-BIOSQL

SDB1-to-SDB2

SDB1-to-SDB3

SDB2-to-SDB3

Mean

0
2
5
8
0
2
5
8
10
0
2
5
8
10
0
2
5
8
0
2
5
8
10
0
2
5
8
10
0
2
5
8
10

|Σ|
8
8
8
8
71
71
71
71
71
10
10
10
10
10
8
8
8
8
10
10
10
10
10
11
11
11
11
11
9
9
9
9
9

¯N
2.5
2.5
2.5
2.5
1.3
1.3
1.3
1.3
1.3
1.4
1.4
1.4
1.4
1.4
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
1.5
2.1
2.1
2.1
2.1
2.1

Reduction obtained with
use of quasi-lattice

∆ ¯x
0%
3%
4.2%
5.6%
0%
0.5%
1%
0.8%
0.9%
0%
0.2%
0.8%
1%
1.6%
0%
1.7%
2.3%
2.2%
0%
1.7%
3.2%
4.6%
5.1%
12.7%
12.4%
12.1%
12.4%
11.6%
0%
0.4%
1.2%
1.4%
1.6%
3.2%

∆xm
0%
13.3%
16%
17.2%
0%
9.1%
19.9%
8.8%
7.7%
0%
12.5%
14.3%
6.7%
8.7%
0%
18.75%
15%
11.5%
0%
15.8%
16%
16.6%
14.7%
14.3%
20%
22%
26.9%
27%
0%
12.5%
9.1%
11.1%
9.5%
11.8%

Table 1. Scenarios characteristics; reduction of the number of asked questions obtained with use of quasi-
lattices over average (∆ ¯x) and maximum (∆xm ) number of questions per tgd and for each dataset.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:33

Fig. 9. Comparison of the number of questions per tgd asked during atom refinement step, with and without
use of the quasi-lattices, from 0 to 10 atom degradations.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

(a) SDB2-to-SBD3(b) SDB1-to-SBD3(c) SDB1-to-SBD2(d) GUS-to-BIOSQL(e) dblp-amalgam(f) amalgam2(g) a1-to-a20 degradations2 degradations5 degradations8 degradations10 degradations0 degradations2 degradations5 degradations8 degradations10 degradations0 degradations2 degradations5 degradations8 degradations10 degradations0 degradations2 degradations5 degradations8 degradations0 degradations2 degradations5 degradations8 degradations10 degradations0 degradations2 degradations5 degradations8 degradations10 degradations0 degradations2 degradations5 degradations8 degradations1:34

A.Bonifati et al.

Fig. 10. Growth of the ratio r wrt. number of degradations.

S , En

T ); . . . ; (En
S )|

S, E1
i =1 | chase(M, E i
Σn
i =1 |E i
T |

S). This lets us compute the number of universal exemplar tuples, which we compare
chase(M, Ei
with the number of targets (non-universal) exemplar tuples used in our approach. Concretely, for
exemplar tuples {(E1
T )} and the corresponding expected mapping M, we calculate
the ratio r = Σn
− 1 of additional atoms in the generated solution. In order to get a
comprehensive view of the effects of atom and join degradations, both degradations occur together
in this experiment. Precisely, in Figure 10, we present the results where an equal number of atom
and join degradations are used. The x axis corresponds to the total number of degradations (e.g.,
the value 20 corresponds to the case with 10 atoms and 10 join degradations), while the y axis
corresponds to the aforementioned ratio r .

In all the employed scenarios, we can observe the effectiveness and practicality of using exemplar
tuples as opposed to the universal data examples of EIRENE: universal exemplar tuples are from
30% to 458% larger than the non-universal ones used in our approach. Moreover, in all scenarios,
we can observe a strong linear correlation between the number of degradations and the number of
additional target tuples needed by universal examples. Hence, the more degradations the exemplar
tuples have, the larger is the benefit of using our approach. Notice that the scenario that is the less
sensitive to the variation of the number of degradations is amalgam2, which is also the scenario
with the greatest number of tgds. Such a scenario is also among those that exhibited the maximum
benefit of using fewer exemplar tuples rather. Although the precise amount of gain is clearly
dependent on the dataset and on the number of degradations, we can observe that, in all scenarios,
the advantage of using non-universal exemplar tuples is non-negligible, thus making our approach a
practical solution for mapping specification.
Relative benefit of interactivity. A key contribution of our mapping specification method is that
it helps the user to interactively correct errors (e.g., unnecessary atoms during atom refinement,
collisions of constants during join refinement) that may appear in the exemplar tuples. In this
section, we aim at quantifying this benefit via a comparison with a baseline approach, i.e., the one
in which refinement steps are disabled. As a baseline, we adopted the canonical GLAV generation
performed in EIRENE3. As EIRENE is not intended to handle errors in its input data examples, we

3For the sake of fairness, EIRENE’s canonical GLAV are split-reduced and σ -redundant tgds are suppressed.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Number of added degradationsRatio between total size of chased and original target instances (%)01020304050051015a1−to−a2010030005101520amalgam202040608005101520dblp−amalgam050100150200051015GUS−to−BIOSQL010020030040005101520SDB1−to−SDB2010020030005101520SDB1−to−SDB3020406080051015SDB2−to−SDB3Interactive Mapping Specification with Exemplar Tuples

1:35

Scenarios

Number of extraneous atoms added
8
0

10

2

5

SDB2-to-SDB3
SDB1-to-SDB2
SDB1-to-SDB3
dblp-amalgam
GUS-to-BIOSQL
a1-to-a2
amalgam2

Average

0
0
0
0
0
0
0

0

12.4
11.1
7.3
12.2
11.7
8.3
3.1

27.0
23.8
16.2
25.3
25.8
18.5
7.5

36.9
33.3
23.6
35.5
35.7
26.6
10.9

9.5

20.6

28.9

-
38.5
28.0
40.7
-
-
12.8

30

Table 2. Relative difference (in percent) between EIRENE and our system.

had to make sure that exemplar tuples in our case are an acceptable input for EIRENE, in particular
that they pass the so-called “homomorphism extension test”. In other words, we bootstrap our
algorithms on universal exemplar tuples (ES, ET ) in order to warrant such comparison.

We use the sum of the number of left-hand side atoms of the tgds as the comparison criterion:
the larger it is, the more “complex” is the mapping for the end user. This optimality criterion is
inspired by a compound measure proposed in [23]. Notice that this comparison only deals with
extraneous atoms during atom refinement and does not consider collision of values, which is done
during join refinement. For such a reason, and also due to the fact that here we are compelled to
use universal data examples instead of few arbitrary exemplar tuples in order to compare with
EIRENE, this comparison should be taken with a grain of salt.

The obtained results are presented in Table 2. If no extraneous atom is added to the left-hand sides
of mappings, then there is no qualitative difference between the two approaches. However, when
extraneous atoms are introduced, a remarkable difference can be observed: EIRENE’s canonical
mapping is about 20% larger on average (across all scenarios) when 5 such atoms are introduced,
and goes up to 30% on average with 10 atoms. Hence, our mappings are noticeably simpler than
EIRENE’s ones. Such an improvement is both beneficial for the readability of mappings as well as for
their efficiency because spurious atoms are eliminated.

7 RELATED WORK
A pioneering work on the usage of data examples in mapping understanding and refinement [33]
relies on Clio’s [28] schema correspondences as specified in a graphical user interface. By leveraging
such correspondences, Yan et al. [33] propose alternative data associations among relevant source
instances leading to construct mappings in an incremental fashion with the intervention of the
mapping designer. The dichotomy between the expected user instance and the generated instance
has been further investigated in Routes [17]. The input required by Routes consists of both a source
instance and a mapping that the user readily intends to debug. The user then builds test cases for
the mapping at hand by probing values in the target instance, and the system returns a provenance
trace to explain how and why the probed values are computed. This approach closely resembles
testing as done for software development. By opposite, our method requires as inputs a source and
target exemplar tuples and no prior mapping connecting them. The final objective of our approach,
which especially targets users unfamiliar with schema mappings, is to build the mapping that
the user had in mind via simple boolean user interactions. To draw a comparison with software

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:36

A.Bonifati et al.

development, our method generates a specification (i.e. a mapping expressed in first-order logic)
starting solely from supplied unit test cases (i.e. small exemplar tuples).

As in Yan et al. [33], Muse [4] leverages data examples to differentiate between alternative map-
ping specifications of the designer and drives the mapping design process based on the designer’s
actions. However, the techniques proposed in [4] are more sophisticated than the ones in [33], in
that they address the problem of the grouping semantics of mappings and their alternative seman-
tics in case of ambiguity. Muse also poses a number of yes/no questions to the designer to clarify
the grouping semantics. However, the number of questions are driven by the schema elements
along with schema constraints that are used to reduce the number of questions. In our approach,
we do not assume prior knowledge of the schema constraints. TRAMP [21] and Vagabond [22] focus
on the understandability of user errors in mappings by using provenance. However, explanations
returned by Vagabond are to be interpreted by users who are familiar with the mapping language
and its underlying semantics.

The use of data examples as evaluation tools has begun in [3, 31], which investigated the
possibility of uniquely characterizing a schema mapping by means of a set of data examples. Hence,
such unique characterization, up to logical equivalence of the obtained mappings, using a finite
set of universal data examples was shown to be possible only in the case of LAV dependencies
and for fragments of GAV dependencies [3, 31]. As a negative result, it was shown in [3] that
already simple s-t tgds mappings, such as copy E(x, y) → F (x, y), cannot be characterized by a
finite set of universal data examples under the class of GLAV mappings. Given the impossibility of
uniquely characterizing GLAV mappings in real settings, [5, 6] made the choice of being less specific.
Precisely, they decided to characterize, for a given schema mapping, the set of valid “non-equivalent”
mappings with respect to the class of GLAV. To achieve that, they rely on the notion of “most
general mapping”. It was shown that, given a schema mapping problem, a most general mapping
always exists in the class of GLAV mappings if there exists at least one valid mapping for the
considered problem [5].

In EIRENE [6], the authors show how the user can generate a mapping that fits universal data
examples given as input. Whereas EIRENE expects a set of universal data examples, we lift the
universality assumption arguing that universal data examples are hard to be produced by a non-
expert user. Moreover, as we have shown in Section 6, universal target instances tend to be
significantly larger than our exemplar tuples. One previous work targeting non-expert users is
MWeaver [29], where the user is asked to toss tuples in the target instance by fetching constants
within the available complete source instance. However, this work has different assumptions with
respect to ours: it aims at searching a source sample among all possible samples satisfying the
provided target tuples, focusing on GAV mappings only. Our system inspects a few input tuples,
on which interactive refinement is enabled, and expressive GLAV mappings can be inferred via
simple user feedback. As mentioned in the introduction, we significantly improve the approach
in [13] by providing formal guarantees of the quality of the obtained mappings, a more efficient
data structure to explore the search space and the adoption of integrity constraints as metadata in
order to reduce the number of user interactions.

All the aforementioned approaches are meant to produce the best exact mapping. However,
one can use data examples to produce approximate mappings. Gottlob and Senellart propose a
cost-based method to estimate the best approximate mapping given a set of possible repairs of the
initial mapping [24]. The cost function takes account for the length of the generated tgds and the
number of repairs that are needed to obtain a tgd that fully explain the instance ET . Approximation
of schema mappings has been considered recently in [15] by considering more expressive fragments
of GLAV and GAV.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

Interactive Mapping Specification with Exemplar Tuples

1:37

Cate et al. [14] show how computational learning (i.e., the exact learning model introduced by D.
Angluin [7] and the Probably Approximately Correct model introduced by L. Valiant [32]) can be
used to infer mappings from data examples. Their analysis is restricted to GAV schema mappings.
Recently, Cate et al.[16] have employed active learning to learn GAV mappings and proved its
utility in practice.

Besides mapping specification and learning, researchers have investigated the problem of in-
ferring relational queries [1, 2, 12, 27]. The work in [1, 2] focuses on learning quantified Boolean
queries by leveraging schema information under the form of primary-foreign key relationships
between attributes. Their goal is to disambiguate a natural language specification of the query,
whereas we use raw tuples to guess the unknown mapping that the user has in mind. In [12],
the problem of inferring join predicates in relational queries is addressed. Consistent equi-join
predicates are inferred by questioning the user on a unique denormalized relation. We differ from
their work as follows: we focus on mapping specification and consider the broad class of GLAV
mappings whereas they focus on query specification for a limited fragment of (equi-join) queries.
Finally, [27] presents the exemplar query evaluation paradigm, which relies on exemplar queries
to identify a user sample of the desired result of the query and a similarity function to identify
database structures that are similar to the user sample. For the latter, the input database is assumed
to be known, which is not an assumption in our framework. Since exemplar queries are answered
upon an input database, they are considered as unambiguous, whereas this is not necessarily the
case in our framework, whose goal is to refine and disambiguate exemplar tuples to derive the
unknown mapping that the user has in mind.

8 CONCLUSIONS
We have addressed the problem of interactive schema mapping inference starting from arbitrary
sets of exemplar tuples, as provided by non-expert users. We have shown that simplification of
the mappings is possible by alternating normalization and refinement steps, the latter under the
form of simple boolean questions. Compared to [13], we provide more tight formal guarantees,
quasi-lattices to explore the space of possible mappings and the adoption of integrity constraints in
order to reduce the number of questions that need to be asked to the user.

This paper lays the foundations of a practical framework that makes data exchange feasible for
the masses. Much work is left to be done in order to make mapping specification an activity for
non-expert users, for instance by adding features like error acceptance in user responses. Different
gradients of users with more or less expertise can be captured with user modeling, which is beyond
the scope of our work. Another future direction is to leverage machine learning techniques, such as
Inductive Logic Programming, to automatically explore the space of mappings and confront their
results with those obtained in our framework.

REFERENCES
[1] A. Abouzied, D. Angluin, C. H. Papadimitriou, J. M. Hellerstein, and A. Silberschatz. Learning and verifying quantified

boolean queries by example. In Proceedings of PODS, pages 49–60, 2013.

[2] A. Abouzied, J. M. Hellerstein, and A. Silberschatz. Playful query specification with dataplay. PVLDB, 5(12):1938–1941,

2012.

[3] B. Alexe, B. T. Cate, P. G. Kolaitis, and W.-C. Tan. Characterizing schema mappings via data examples. TODS,

36(4):23:1–23:48, 2011.

[4] B. Alexe, L. Chiticariu, R. J. Miller, and W. C. Tan. Muse: Mapping understanding and design by example. In Proceedings

of the ICDE, pages 10–19, 2008.

[5] B. Alexe, B. ten Cate, P. G. Kolaitis, and W. C. Tan. Designing and refining schema mappings via data examples. In

Proceedings of SIGMOD, pages 133–144, 2011.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

1:38

A.Bonifati et al.

[6] B. Alexe, B. Ten Cate, P. G. Kolaitis, and W.-C. Tan. Eirene: Interactive design and refinement of schema mappings via

data examples. Proceedings of VLDB, 2011.

[7] D. Angluin. Queries and concept learning. Machine Learning, 2(4):319–342, 1987.
[8] P. C. Arocena, B. Glavic, R. Ciucanu, and R. J. Miller. The ibench integration metadata generator. Proceedings of VLDB,

9(3):108–119, 2015.

[9] C. Beeri and M. Y. Vardi. A proof procedure for data dependencies. Journal of the ACM, 31(4):718–741, 1984.
[10] Z. Bellahsene, A. Bonifati, and E. Rahm, editors. Schema Matching and Mapping. Data-Centric Systems and Applications.

Springer, 2011.

[11] P. A. Bernstein and S. Melnik. Model management 2.0: Manipulating richer mappings. In SIGMOD, 2007.
[12] A. Bonifati, R. Ciucanu, and S. Staworko. Learning join queries from user examples. ACM Trans. Database Syst.,

40(4):24:1–24:38, Jan. 2016.

[13] A. Bonifati, U. Comignani, E. Coquery, and R. Thion. Interactive mapping specification with exemplar tuples. In
Proceedings of the 2017 ACM International Conference on Management of Data, SIGMOD ’17, pages 667–682, New York,
NY, USA, 2017. ACM.

[14] B. T. Cate, V. Dalmau, and P. G. Kolaitis. Learning schema mappings. ACM TODS, 38(4):28, 2013.
[15] B. T. Cate, P. G. Kolaitis, K. Qian, and W.-C. Tan. Approximation Algorithms for Schema-Mapping Discovery from

Data Examples. ACM Trans. Database Syst., 42(2):12:1–12:41, 2017.

[16] B. T. Cate, P. G. Kolaitis, K. Qian, and W.-C. Tan. Active learning of gav schema mappings. In Proceedings of PODS,

2018.

[17] L. Chiticariu and W.-C. Tan. Debugging schema mappings with routes.
conference on Very large data bases, pages 79–90. VLDB Endowment, 2006.

In Proceedings of the 32nd international

[18] G. I. Diaz, M. Arenas, and M. Benedikt. Sparqlbye: Querying RDF data by example. PVLDB, 9(13):1533–1536, 2016.
[19] R. Fagin, P. G. Kolaitis, R. J. Miller, and L. Popa. Data exchange: semantics and query answering. Theoretical Computer

Science, 336(1):89–124, 2005.

[20] M. J. Franklin, A. Y. Halevy, and D. Maier. A first tutorial on dataspaces. PVLDB, 1(2):1516–1517, 2008.
[21] B. Glavic, G. Alonso, R. J. Miller, and L. M. Haas. Tramp: Understanding the behavior of schema mappings through

provenance. Proc. VLDB Endow., 3(1-2):1314–1325, Sept. 2010.

[22] B. Glavic, J. Du, R. J. Miller, G. Alonso, and L. M. Haas. Debugging data exchange with vagabond. PVLDB, 4(12):1383–

1386, 2011.

[23] G. Gottlob, R. Pichler, and V. Savenkov. Normalization and optimization of schema mappings. VLDB J., 20(2):277–302,

2011.

[24] G. Gottlob and P. Senellart. Schema mapping discovery from data instances. Journal of the ACM, 57(2):6, 2010.
[25] H. V. Jagadish, A. Chapman, A. Elkiss, M. Jayapandian, Y. Li, A. Nandi, and C. Yu. Making database systems usable. In

Proceedings of SIGMOD, pages 13–24, 2007.

[26] D. Maier, A. O. Mendelzon, and Y. Sagiv. Testing Implications of Data Dependencies. 4(4):455–469.
[27] D. Mottin, M. Lissandrini, Y. Velegrakis, and T. Palpanas. Exemplar queries: Give me an example of what you need.

PVLDB, 7(5):365–376, 2014.

[28] L. Popa, Y. Velegrakis, M. A. Hernández, R. J. Miller, and R. Fagin. Translating web data. In Proceedings of VLDB, pages

598–609, 2002.

[29] L. Qian, M. J. Cafarella, and H. Jagadish. Sample-driven schema mapping. In Proceedings of SIGMOD, pages 73–84.

ACM, 2012.

[30] P. Shvaiko and J. Euzenat. A survey of schema-based matching approaches. Journal on Data Semantics, pages 146–171,

2005.

[31] B. Ten Cate, P. G. Kolaitis, and W.-C. Tan. Database constraints and homomorphism dualities. In CP. Springer, 2010.
[32] L. G. Valiant. A theory of the learnable. Commun. ACM, 27(11):1134–1142, Nov. 1984.
[33] L. Yan, R. J. Miller, L. M. Haas, and R. Fagin. Data-driven understanding and refinement of schema mappings. In

Proceedings of SIGMOD, pages 485–496, 2001.

ACM Transactions on Database Systems, Vol. 1, No. 1, Article 1. Publication date: May 2018.

