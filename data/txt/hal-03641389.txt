LifeCLEF 2022 Teaser: An Evaluation
of Machine-Learning Based Species Identification
and Species Distribution Prediction
Alexis Joly, Hervé Goëau, Stefan Kahl, Lukáš Picek, Titouan Lorieul, Elijah

Cole, Benjamin Deneu, Maximilien Servajean, Andrew Durso, Isabelle Bolon,

et al.

To cite this version:

Alexis Joly, Hervé Goëau, Stefan Kahl, Lukáš Picek, Titouan Lorieul, et al.. LifeCLEF 2022 Teaser:
An Evaluation of Machine-Learning Based Species Identification and Species Distribution Prediction.
ECIR 2022 - 44th European Conference on Information Retrieval Research, Apr 2022, Stavanger,
Norway. pp.390-399, ￿10.1007/978-3-030-99739-7_49￿. ￿hal-03641389￿

HAL Id: hal-03641389

https://hal.inrae.fr/hal-03641389

Submitted on 10 Mar 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

LifeCLEF 2022 Teaser: An Evaluation
of Machine-Learning Based Species
Identiﬁcation and Species Distribution
Prediction

Alexis Joly1(B)

, Herv´e Go¨eau2

, Stefan Kahl6

, Luk´aˇs Picek10

,

Titouan Lorieul1
Maximilien Servajean7

, Elijah Cole9

, Andrew Durso11

, Benjamin Deneu1

,
, Isabelle Bolon8

Herv´e Glotin3

, Robert Planqu´e4

, Willem-Pier Vellinga4

,
, Holger Klinck6,

Tom Denton12, Ivan Eggel5, Pierre Bonnet2

and Milan ˇSulc13

, Henning M¨uller5

,

1 Inria, LIRMM, Univ Montpellier, CNRS, Montpellier, France
alexis.joly@inria.fr
2 CIRAD, UMR AMAP, Montpellier, Occitanie, France
3 Univ. Toulon, Aix Marseille Univ., CNRS, LIS, DYNI Team,
Marseille, France
4 Xeno-canto Foundation, Amsterdam, The Netherlands
5 HES-SO, Sierre, Switzerland
6 KLYCCB, Cornell Lab of Ornithology, Cornell University, Ithaca, USA
7 LIRMM, AMIS, Univ Paul Val´ery Montpellier, University Montpellier, CNRS,
Montpellier, France
8 ISG, Department of Community Health and Medicine,
UNIGE, Geneva, Switzerland
9 Department of Computing and Mathematical Sciences, Caltech, Pasadena, USA
10 Department of Cybernetics, FAV, University of West Bohemia, Plzen, Czechia
11 Department of Biological Sciences, Florida Gulf Coast University,
Fort Myers, USA
12 Google LLC, San Francisco, USA

13 Department of Cybernetics, FEE, CTU in Prague, Prague, Czech Republic

Abstract. Building accurate knowledge of the identity, the geographic
distribution and the evolution of species is essential for the sustainable
development of humanity, as well as for biodiversity conservation. How-
ever, the diﬃculty of identifying plants, animals and fungi is hinder-
ing the aggregation of new data and knowledge. Identifying and nam-
ing living organisms is almost impossible for the general public and is
often diﬃcult even for professionals and naturalists. Bridging this gap
is a key step towards enabling eﬀective biodiversity monitoring systems.
The LifeCLEF campaign, presented in this paper, has been promoting
and evaluating advances in this domain since 2011. The 2022 edition
proposes ﬁve data-oriented challenges related to the identiﬁcation and

LifeCLEF 2022 Teaser

prediction of biodiversity: (i) PlantCLEF: very large-scale plant identiﬁ-
cation, (ii) BirdCLEF: bird species recognition in audio soundscapes,
(iii) GeoLifeCLEF:
species,
(iv) SnakeCLEF: Snake Species Identiﬁcation in Medically Important
scenarios, and (v) FungiCLEF: Fungi recognition from images and meta-
data.

sensing based prediction of

remote

1 LifeCLEF Lab Overview

Accurately identifying organisms observed in the wild is an essential step in
ecological studies. Unfortunately, observing and identifying living organisms
requires high levels of expertise. For instance, vascular plants alone account
for more than 300,000 diﬀerent species and the distinctions between them can
be quite subtle. The world-wide shortage shortage of trained taxonomists and
curators capable of identifying organisms has come to be known as the taxo-
nomic impediment. Since the Rio Conference of 1992, it has been recognized as
one of the major obstacles to the global implementation of the Convention on
Biological Diversity1. In 2004, Gaston and O’Neill [7] discussed the potential
of automated approaches for species identiﬁcation. They suggested that, if the
scientiﬁc community were able to (i) produce large training datasets, (ii) pre-
cisely evaluate error rates, (iii) scale up automated approaches, and (iv) detect
novel species, then it would be possible to develop a generic automated species
identiﬁcation system that would open up new vistas for research in biology and
related ﬁelds.

Since the publication of [7], automated species identiﬁcation has been stud-
ied in many contexts [6,9,13,23,25,30,31,36]. This area continues to expand
rapidly, particularly due to advances in deep learning [5,8,24,26,32–35]. In order
to measure progress in a sustainable and repeatable way, the LifeCLEF2 research
platform was created in 2014 as a continuation and extension of the plant iden-
tiﬁcation task that had been run within the ImageCLEF lab3 since 2011 [10–12].
Since 2014, LifeCLEF expanded the challenge by considering animals in addition
to plants, and including audio and video content in addition to images [14–21].
About 100-500 research groups annually register to LifeCLEF in order to either
download the data, register to the mailing list or beneﬁt from the shared eval-
uation tools. The number of participants who ﬁnally crossed the ﬁnish line by
submitting runs was respectively: 22 in 2014, 18 in 2015, 17 in 2016, 18 in 2017,
13 in 2018, 16 in 2019, 16 in 2020, 1,022 in 2021 (including the 1,004 participants
of the BirdCLEF Kaggle challenge). The 2022 edition proposes ﬁve data-oriented
challenges: three in the continuity of the 2021 edition (BirdCLEF, GeoLifeCLEF
and SnakeCLEF), one new challenge related to fungi recognition with a focus
on the combination of visual information with meta-data and on edible vs. poi-
sonous species (FungiCLEF), and a considerable expansion of the PlantCLEF

1 https://www.cbd.int/.
2 http://www.lifeclef.org/.
3 http://www.imageclef.org/.

A. Joly et al.

challenge towards the identiﬁcation of the world’s ﬂora (about 300K species). In
the following sections, we describe for each of the ﬁve challenges the motivation,
the used data collection and the evaluated task.

2 PlantCLEF Challenge: Identify the World’s Flora

Motivation: It is estimated that there are more than 300,000 species of vascular
plants in the world. Increasing our knowledge of these species is of paramount
importance for the development of human civilization (agriculture, construc-
tion, pharmacopoeia, etc.), especially in the context of the biodiversity crisis
[22]. However, the burden of systematic plant identiﬁcation by human experts
strongly penalizes the aggregation of new data and knowledge. Since then, auto-
matic identiﬁcation has made considerable progress in recent years as highlighted
during all previous editions of PlantCLEF. Deep learning techniques now seem
mature enough to address the ultimate but realistic problem of global identiﬁca-
tion of plant biodiversity in spite of many problems that the data may present
(a huge number of classes, very strongly unbalanced classes, partially erroneous
identiﬁcations, duplications, variable visual quality, diversity of visual contents
such as photos or herbarium sheets, etc.).
Data Collection: the training dataset that will be used this year can be dis-
tinguished in 2 main categories: labeled and unlabeled (i.e. with or without
species labels provided and checked by humans). The labeled training dataset
will be based on a dataset of more than 5M images covering more than 290k
plant species based on a web crawl with Google and Bing search engines and
the Encyclopedia of Life webportal. All datasets provided in previous editions
of PlantCLEF can also be used and the use of external data will be encouraged,
notably via the gbif-dl4 package which facilitates the download of media data
from the world’s largest biodiversity database (GBIF5) by wrapping its public
API. The unlabeled training dataset will be based on more than 9 million pic-
tures coming from the Pl@ntNet platform [4] (associated with a pseudo-label
but without human veriﬁcation). Finally, the test set will be a set of tens of
thousands pictures veriﬁed by world class experts related to various regions of
the world and taxonomic groups.
Task Description: the task will be evaluated as a plant species retrieval task
based on multi-image plant observations from the test set. The goal will be to
retrieve the correct plant species among the top results of a ranked list of species
returned by the evaluated system. The participants will ﬁrst have access to the
training set and a few months later, they will be provided with the whole test set.
Semi-supervised or unsupervised approaches will be strongly encouraged and a
starter package with a pre-trained model based on this type of method exploiting
the unlabeled training dataset will be provided.

4 https://github.com/plantnet/gbif-dl.
5 https://www.gbif.org/.

LifeCLEF 2022 Teaser

3 BirdCLEF Challenge: Bird Species Identiﬁcation

in Soundscape Recordings

Motivation: Recognizing bird sounds in complex soundscapes is an important
sampling tool that often helps to reduce the limitations of point counts6. In the
future, archives of recorded soundscapes will become increasingly valuable as
the habitats in which they were recorded will be lost in the near future. It is
imperative to develop new technologies that can cope with the increasing amount
of audio data and that can help to accelerate the process of species diversity
assessments. In the past few years, deep learning approaches have transformed
the ﬁeld of automated soundscape analysis. Yet, when training data is sparse,
detection systems struggle with the recognition of rare species. The goal of this
competition is to establish training and test datasets that can serve as real-world
applicable evaluation scenarios for endangered habitats and help the scientiﬁc
community to advance their conservation eﬀorts through automated bird sound
recognition.
Data Collection: We will build on the experience from previous editions and
adjust the overall task to encourage participants to focus on few-shot learning
and task-speciﬁc model designs. We will select training and test data to suit
this demand. As for previous years, Xeno-canto will be the primary source for
training data, expertly annotated soundscape recordings will be used for testing.
We will focus on bird species for which there is limited training data, but we will
also include common species so that participants can train good recognition sys-
tems. In search of suitable test data, we will consider diﬀerent data sources with
varying complexity (call density, chorus, signal-to-noise ratio, anthropophony),
and quality (mono and stereo recordings). We also want to focus on very spe-
ciﬁc real-world use cases (e.g., conservation eﬀorts in Hawaii) and frame the
competition based on the demand of the particular use case. Additionally, we
are considering including unlabeled data to encourage self-supervised learning
regimes.
Task Description: The competition will be held on Kaggle and the evaluation
mode will resemble the 2021 test mode (i.e., hidden test data, code competi-
tion). We will use established metrics like F1 score and LwLRAP which reﬂect
use cases for which precision is key and also allow organizers to assess system
performance independent of ﬁne-tuned conﬁdence thresholds. Participants will
be asked to return a list of species for short audio segments extracted from
labeled soundscape data. In the past, we used 5-second segments, and we will
consider increasing the duration of these context windows to better reﬂect the
overall ground truth label distribution. However, the overall structure of the task
will remain unchanged, as it provides a well-established base that has resulted
in signiﬁcant participation in past editions (e.g., 1,004 participants and 9,307
submissions in 2021). Again, we will strive to keep the dataset size reasonably

6 e.g. some species might be oversampled or undersampled.

A. Joly et al.

small (<50 GB) and easy to process, and we will also provide introductory code
repositories and write-ups to lower the entry level of the competition.

4 GeoLifeCLEF Challenge: Species Prediction Based

on Occurrence Data, Environmental Data and Remote
Sensing Data

Motivation: Automatically predicting the list of species that are the most
likely to be observed at a given location is useful for many scenarios in bio-
diversity conservation, ecotourism, land management, etc. First of all, it allows
improve species identiﬁcation tools by reducing the list of candidate species
that are observable at a given location (be they automated, semi-automated
or based on classical ﬁeld guides or ﬂora). More generally, it facilitates biodi-
versity inventories through the development of location-based recommendation
services (typically on mobile phones), it favours the involvement of non-expert
nature observers, as well as accelerate the annotation or validation of species
observed by non-experts to produce high quality datasets. Last but not least, it
might serve educational purposes thanks to biodiversity discovery applications
providing functionalities such as contextualized educational pathways.
Data Collection: The GeoLifeCLEF dataset (already used in 2020 and 2021)
contains about 2 million observations of around 30 thousand plant and ani-
mal species. Each observation is paired with very high-resolution covariates
(aerial imagery, land cover, altitude) and environmental rasters (bioclimatic
variables, soil type, etc.). The dataset took months to build in its raw format
(∼850 GB) and we reformatted it in a more convenient and memory eﬃcient
format (∼100 GB). Indeed, it has not yet been used to its full potential due (i)
to the computing power required to train models on it, and, (ii) to the complex-
ity and the wide variety of challenges of the tackled task. In 2021, the challenge
focused on measuring the eﬃciency of remote sensing imagery to predict the
presence of species at a given location. In 2022, the objective is to make this
competition more realistic by changing the evaluation protocol: the models will
be evaluated on new presence/absence observation data. This means that the
2022 challenge will tackle two main issues in species presence prediction: (i) tak-
ing into consideration the sampling bias due to the presence-only nature of the
training observation data, and, (ii) predicting relevant sets of species present at
the given location.
Task Description: Given the test set of locations (i.e. geo-coordinates) and
corresponding high-resolution and environmental covariates, the goal of the task
will be to return for each location a ranked list of species sorted according to
the likelihood that they might have been observed at that location. The metric
used will be a multi-label metric such as mean average precision (mAP).

LifeCLEF 2022 Teaser

5 SnakeCLEF Challenge: Automated Snake Species

Identiﬁcation with Country-Level Focus

Motivation: Developing a robust system for identifying snake species from pho-
tographs is an important goal in biodiversity and global health. With over half a
million of deaths and disability from venomous snakebite annually, understand-
ing the global distribution of more than 3,900 snake species and diﬀerentiating
them from images (particularly images of low quality) will signiﬁcantly improve
epidemiology data and treatment outcomes. From previous editions, we learned
>90%, Accu-
that “machines” are capable of accurate recognition (Macro F1c
racy ∼95%) even in the scenarios with long-tailed class distributions and ∼800
species. Thus, testing over real Medically Important Scenarios and integrat-
ing information on species toxicity is the next step to provide a more reliable
“machine” prediction.
Data Collection: The dataset used in previous editions [27,29] will be extended
with new and rare species as well as with images from countries with no or just
a few samples, reducing the uneven species distributions across all the countries
included in the data. For testing, we tailored two sets, one for a machine evalu-
ation and the second for the HUMAN vs AI comparison. The SnakeCLEF 2022
dataset covers 1,000 snake species on more than 500,000 images and from approx-
imately 200 countries – adding 224 new species. In addition, we include: (i) snake
species toxicity level, allowing us to research methods for lowering the possibility
of medically-critical mis-prediction, i.e., confusion of venomous species with non-
venomous. (ii) country-species mapping ﬁle describing species-country presence
based on the The Reptile Database and allowing better worldwide regularization.
Task Description: Given the set of images and corresponding geographic local-
ity information, the goal of the task is to return for each image a ranked list
of species sorted according to the likelihood that they are in the image and
might have been observed at that location and minimising the venomous/non-
venomous confusion.

6 FungiCLEF Challenge: Fungi Recognition from Images

and Metadata

Motivation: Automatic recognition of fungi species assists mycologists, citizen
scientists and nature enthusiasts in species identiﬁcation in the wild. Its avail-
ability supports the collection of valuable biodiversity data. In practice, species
identiﬁcation typically does not depend solely on the visual observation of the
specimen but also on other information available to the observer – such as habi-
tat, substrate, location and time. Thanks to rich metadata, precise annotations,
and baselines available to all competitors, the challenge provides a benchmark
for image recognition with the use of additional information. Moreover, simi-
larly to SnakeCLEF, the toxicity of a mushroom can be crucial for the decision

A. Joly et al.

of a mushroom picker. The task will explore the decision process beyond the
commonly assumed 0/1 cost function.
Data Collection: The challenge dataset is based on the DF20 dataset [28],
contains 295,938 training images belonging to 1,604 species observed mostly in
Denmark. All training samples passed an expert validation process, guaranteeing
high quality labels. Rich observation metadata about habitat, substrate, time,
location, EXIF etc. are provided. The challenge comes with two diﬀerent test
sets: (i) The ﬁrst is unique in its annotation process, as all test images belong to
physical samples sent for DNA sequencing. (ii) The second, with approximately
60k images, covers the whole year and includes observations collected across all
substrate and habitat types.
Task Description: Given the set of images and corresponding metadata, the
goal of the task is to return for each image a ranked list of species sorted accord-
ing to the likelihood of the species appearing in the image. A baseline procedure
to include meta-data in the decision problem, as well as pre-trained baseline
image classiﬁers, will be provided as part of the task description to all partici-
pants.

7 Timeline and Registration Instructions

All information about the timeline and participation in the challenges is provided
on the LifeCLEF 2022 web pages [3]. The challenges themselves are ran on
the AIcrowd platform [1] and the Kaggle platform [2] for the registration, the
submission of runs, the display of the leaderboard, etc.

8 Conclusions and Perspectives

To fully reach its objective, an evaluation campaign such as LifeCLEF requires
a long-term research eﬀort so as to (i) encourage non-incremental contributions,
(ii) measure consistent performance gaps, (iii) progressively scale-up the problem
and (iv) enable the emergence of a strong community. The 2022 edition of the
lab supports this vision and also includes the following innovations:

– A new task on fungi recognition from images and metadata.
– A widening of the plant task at the scale of the world ﬂora (100K-300K

species).

– The inclusion of new data for the bird task with a focus on unsupervised

training, stereo audio recordings and concrete conservation use cases.

– The inclusion of presence-absence test data for the GeoLifeCLEF challenge.
– The evaluation of decision problems for poisonous and venomous species iden-
tiﬁcation represents a task beyond 0/1 cost function, not represented in com-
puter vision benchmarks.

Acknowledgements. This project has received funding from the European Union’s
Horizon 2020 research and innovation programme under grant agreement No◦ 863463
(Cos4Cloud project), and the support of #DigitAG.

LifeCLEF 2022 Teaser

References

1. AICrowd. https://www.aicrowd.com/
2. Kaggle. https://www.kaggle.com/
3. LifeCLEF (2022). https://www.imageclef.org/LifeCLEF2022
4. Aﬀouard, A., Goeau, H., Bonnet, P., Lombardo, J.C., Joly, A.: Pl@ntnet app in the
era of deep learning. In: 5th International Conference on Learning Representations
(ICLR 2017), 24–26 April 2017, Toulon, France (2017)

5. Go¨eau, H., et al.: Plant Identiﬁcation: Experts vs. Machines in the Era of Deep
Learning. In: Joly, A., Vrochidis, S., Karatzas, K., Karppinen, A., Bonnet, P. (eds.)
Multimedia Tools and Applications for Environmental & Biodiversity Informatics.
MSA, pp. 131–149. Springer, Cham (2018). https://doi.org/10.1007/978-3-319-
76445-0 8

6. Cai, J., Ee, D., Pham, B., Roe, P., Zhang, J.: Sensor network for the monitoring of
ecosystem: Bird species recognition. In: Intelligent Sensors, Sensor Networks and
Information, 2007. ISSNIP 2007. 3rd International Conference on (2007). https://
doi.org/10.1109/ISSNIP.2007.4496859

7. Gaston, K.J., O’Neill, M.A.: Automated species identiﬁcation: why not? Philos.

Trans. Royal Soc. London B: Biol. Sci. 359(1444), 655–667 (2004)

8. Ghazi, M.M., Yanikoglu, B., Aptoula, E.: Plant identiﬁcation using deep neural
networks via optimization of transfer learning parameters. Neurocomputing 235,
228–235 (2017)

9. Glotin, H., Clark, C., LeCun, Y., Dugan, P., Halkias, X., Sueur, J.: Proceeding 1st
workshop on Machine Learning for Bioacoustics - ICML4B. ICML, Atlanta USA
(2013). http://sabiod.org/ICML4B2013 book.pdf

10. Go¨eau, H., et al.: The imageclef 2013 plant identiﬁcation task. In: CLEF task
Overview 2013, CLEF: Conference and Labs of the Evaluation Forum, Sep. 2013,
Valencia, Spain. Valencia (2013)

11. Go¨eau, H., et al.: The imageclef 2011 plant images classiﬁcation task. In: CLEF
task Overview 2011, CLEF: Conference and Labs of the Evaluation Forum, Sep.
2011, Amsterdam, Netherlands. (2011)

12. Go¨eau, H., et al.: Imageclef 2012 plant images identiﬁcation task. In: CLEF Task
Overview 2012, CLEF: Conference and Labs of the Evaluation Forum, Sep. 2012,
Rome, Italy. Rome (2012)

13. Joly, A., et al.: Interactive plant identiﬁcation based on social image data. Ecol.

Inf. 23, 22–34 (2014)

14. Joly, A., et al.: Overview of LifeCLEF 2018: a large-scale evaluation of species
identiﬁcation and recommendation algorithms in the era of ai. In: Jones, G.J.,
et al. (eds.) CLEF: Cross-Language Evaluation Forum for European Languages.
Experimental IR Meets Multilinguality, Multimodality, and Interaction, vol. LNCS.
Springer, Avigon, France (Sep 2018)

15. Joly, A., et al.: Overview of LifeCLEF 2019: Identiﬁcation of Amazonian Plants,
South & North American Birds, and Niche Prediction. In: Crestani, F., et al.
(eds.) CLEF 2019 - Conference and Labs of the Evaluation Forum. Experimental
IR Meets Multilinguality, Multimodality, and Interaction, vol. LNCS, pp. 387–401.
Lugano, Switzerland (Sep 2019). https://doi.org/10.1007/978-3-030-28577-7 29,
https://hal.umontpellier.fr/hal-02281455

398

A. Joly et al.

16. Joly, A., et al.: LifeCLEF 2016: Multimedia Life Species Identiﬁcation Challenges.
In: Fuhr, N., et al. (eds.) CLEF: Cross-Language Evaluation Forum. Experimental
IR Meets Multilinguality, Multimodality, and Interaction, vol. LNCS, pp. 286–310.
Springer, ´Evora, Portugal (Sep 2016). https://doi.org/10.1007/978-3-319-44564-
9 26, https://hal.archives-ouvertes.fr/hal-01373781

17. Joly, A., et al.: LifeCLEF 2017 Lab Overview: Multimedia Species Identiﬁcation
Challenges. In: Jones, G.J., et al. (eds.) CLEF: Cross-Language Evaluation Forum.
Experimental IR Meets Multilinguality, Multimodality, and Interaction, vol. LNCS,
pp. 255–274. Springer, Dublin, Ireland (Sep 2017). https://doi.org/10.1007/978-3-
319-65813-1 24, https://hal.archives-ouvertes.fr/hal-01629191

18. Joly, A., et al.: LifeCLEF 2014: Multimedia Life Species Identiﬁcation Challenges.
In: CLEF: Cross-Language Evaluation Forum. Information Access Evaluation.
Multilinguality, Multimodality, and Interaction, vol. LNCS, pp. 229–249. Springer
International Publishing, Sheﬃeld, United Kingdom (Sep 2014). https://doi.org/
10.1007/978-3-319-11382-1 20, https://hal.inria.fr/hal-01075770

19. Joly, A., et al.: Lifeclef 2015: multimedia life species identiﬁcation challenges. In:
Experimental IR Meets Multilinguality, Multimodality, and Interaction, pp. 462–
483. Springe, Chem (2015)

20. Joly, A., et al.: Overview of lifeclef 2020: a system-oriented evaluation of auto-
mated species identiﬁcation and species distribution prediction. In: International
Conference of the Cross-Language Evaluation Forum for European Languages, pp.
342–363. Springer, Chem (2020)

21. Joly, A., et al.: Overview of lifeclef 2021: an evaluation of machine-learning based
species identiﬁcation and species distribution prediction. In: International Con-
ference of the Cross-Language Evaluation Forum for European Languages, pp.
371–393. Springer, Chem (2021)

22. Koh, L.P., Dunn, R.R., Sodhi, N.S., Colwell, R.K., Proctor, H.C., Smith, V.S.:
Species coextinctions and the biodiversity crisis. Science 305(5690), 1632–1634
(2004)

23. Lee, D.J., Schoenberger, R.B., Shiozawa, D., Xu, X., Zhan, P.: Contour matching
for a ﬁsh recognition and migration-monitoring system. In: Optics East, pp. 37–48.
International Society for Optics and Photonics (2004)

24. Lee, S.H., Chan, C.S., Remagnino, P.: Multi-organ plant classiﬁcation based on
convolutional and recurrent neural networks. IEEE Trans. Image Process. 27(9),
4287–4301 (2018)

25. NIPS International Conference on Neural Information Processing Scaled for Bioa-

coustics, from Neurons to Big Data (2013). http://sabiod.org/nips4b

26. Norouzzadeh, M.S., Morris, D., Beery, S., Joshi, N., Jojic, N., Clune, J.: A deep
active learning system for species identiﬁcation and counting in camera trap
images. Methods Ecol. Evol. 12(1), 150–161 (2021)

27. Picek, L., Ruiz De Casta˜neda, R., Durso, A.M., Sharada, P.M.: Overview of the
snakeclef 2020: Automatic snake species identiﬁcation challenge. In: CLEF task
overview 2020, CLEF: Conference and Labs of the Evaluation Forum, Sep. 2020,
Thessaloniki, Greece (2020)

28. Picek, L., Sulc, M., Matas, J., Heilmann-Clausen, J., Jeppesen, T., Læssøe, T.,
Frøslev, T.: Danish fungi 2020 - not just another image recognition dataset. In:
Proceedings of the IEEE/CVF Winter Conference on Applications of Computer
Vision (WACV) (2022)

29. Picek, L., Durso, A.M., Ruiz De Casta˜neda, R., Bolon, I.: Overview of SnakeCLEF
2021: Automatic snake species identiﬁcation with country-level focus. In: Working
Notes of CLEF 2021 - Conference and Labs of the Evaluation Forum (2021)

LifeCLEF 2022 Teaser

399

30. Towsey, M., Planitz, B., Nantes, A., Wimmer, J., Roe, P.: A toolbox for animal

call recognition. Bioacoustics 21(2), 107–125 (2012)

31. Trifa, V.M., Kirschel, A.N., Taylor, C.E., Vallejo, E.E.: Automated species recog-
nition of antbirds in a Mexican rainforest using hidden Markov models. J. Acoust.
Soc. Am. 123, 2424 (2008)

32. Van Horn, G., Mac Aodha, O., Song, Y., Cui, Y., Sun, C., Shepard, A., Adam,
H., Perona, P., Belongie, S.: The inaturalist species classiﬁcation and detection
dataset. CVPR (2018)

33. Villon, S., Mouillot, D., Chaumont, M., Subsol, G., Claverie, T., Vill´eger, S.: A
new method to control error rates in automated species identiﬁcation with deep
learning algorithms. Sci. Reports 10(1), 1–13 (2020)

34. W¨aldchen, J., M¨ader, P.: Machine learning for image based species identiﬁcation.

Methods Ecol. Evol. 9(11), 2216–2225 (2018)

35. W¨aldchen, J., Rzanny, M., Seeland, M., M¨ader, P.: Automated plant species
identiﬁcation-trends and future directions. PLoS Comput. Biol. 14(4), e1005993
(2018)

36. Yu, X., Wang, J., Kays, R., Jansen, P.A., Wang, T., Huang, T.: Automated identiﬁ-
cation of animal species in camera trap images. EURASIP J. Image Video Process.
2013(1), 1–10 (2013). https://doi.org/10.1186/1687-5281-2013-52

View publication stats

