Enabling Reproducible Analysis of Complex Workflows
on the Edge-to-Cloud Continuum
Daniel Rosendo, Alexandru Costan, Gabriel Antoniu, Patrick Valduriez

To cite this version:

Daniel Rosendo, Alexandru Costan, Gabriel Antoniu, Patrick Valduriez. Enabling Reproducible Anal-
ysis of Complex Workflows on the Edge-to-Cloud Continuum. BDA 2021 - 37e Conférence sur la Ges-
tion de Données - Principes, Technologies et Applications, Philippe Rigaux, Oct 2021, Paris, France.
￿hal-03332524￿

HAL Id: hal-03332524

https://hal.science/hal-03332524

Submitted on 2 Sep 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Enabling Reproducible Analysis of Complex
Workﬂows on the Edge-to-Cloud Continuum

PhD Student: Daniel Rosendo∗ Advisors: Alexandru Costan∗, Gabriel Antoniu∗, Patrick Valduriez†
∗University of Rennes, Inria, CNRS, IRISA - Rennes, France
†University of Montpellier, Inria, CNRS, LIRMM - Montpellier, France
{daniel.rosendo, alexandru.costan, gabriel.antoniu, patrick.valduriez}@inria.fr

Abstract—Distributed digital

infrastructures for com-
putation and analytics are now evolving towards an in-
terconnected ecosystem allowing complex applications to
be executed from IoT Edge devices to the HPC Cloud
(aka the Computing Continuum, the Digital Continuum,
or the Transcontinuum). Understanding end-to-end perfor-
mance in such a complex continuum is challenging. This
breaks down to reconciling many, typically contradicting
application requirements and constraints with low-level
infrastructure design choices. One important challenge
is to accurately reproduce relevant behaviors of a given
application workﬂow and representative settings of the
physical infrastructure underlying this complex continuum.
We introduce a rigorous methodology for such a process
and validate it through E2Clab. It is the ﬁrst platform
to support the complete experimental cycle across the
Computing Continuum: deployment, analysis, optimiza-
tion. Preliminary results with real-life use cases show
that E2Clab allows one to understand and improve per-
formance, by correlating it to the parameter settings,
the resource usage and the speciﬁcs of the underlying
infrastructure.

Index Terms—Methodology, Computing Continuum, Re-

producibility, Machine Learning, Optimization.

I. CONTEXT

The explosion of data generated from the Internet of
Things (IoT) and the need for real-time analytics has re-
sulted in a shift of the data processing paradigms towards
decentralized and multi-tier computing infrastructures
and services. New challenging application scenarios are
emerging from a variety of domains such as healthcare,
self-driving vehicles, precision agriculture, etc. This con-
tributes to the emergence of what is called the Computing
Continuum [1]. It seamlessly combines resources and
services at the center (e.g., in Cloud datacenters), at the
Edge, and in-transit, along the data path. Typically data
is ﬁrst generated and preprocessed (e.g., ﬁltering, basic
inference) on Edge devices, while Fog nodes further
process partially aggregated data. Then,
if required,
data is transferred to HPC-enabled Clouds for Big Data
analytics, AI model training, and global simulations.

II. PROBLEM STATEMENT

Despite an always increasing number of dedicated
systems for data processing on each component of
the continuum, this vision of ubiquitous computing re-
mains largely unrealized. This is due to the complexity
of deploying large-scale, real-life applications on such
heterogeneous infrastructures, which breaks down to
conﬁguring a myriad of system-speciﬁc parameters and
reconciling many requirements or constraints, e.g., in
terms of communication latency, energy consumption,
resource usage, data privacy. A ﬁrst step towards re-
ducing this complexity and enabling the Computing
Continuum vision is to enable a holistic understanding
of performance in such environments. That is, ﬁnding
a rigurous approach to answering questions like: (1)
Which system parameters and infrastructure conﬁgu-
rations impact on performance and how? (2) Where
should the workﬂow components be executed to minimize
communication costs and end-to-end latency?

III. STATE OF THE ART

Approaches based on workﬂow modelling [2] and
simulation [3] raise some important challenges in terms
of speciﬁcation, modelling, and validation in the con-
text of the Computing Continuum. For example, it is
increasingly difﬁcult to assess the impact of the inherent
complexity of hybrid Edge-Cloud deployments on per-
formance. At this stage, experimental evaluation remains
the main approach to gain accurate insights of perfor-
mance metrics and to build precise approximations of
the expected behavior of large-scale applications on the
Computing Continuum, as a ﬁrst step prior to modelling.

IV. CHALLENGES

A key challenge in this context is to be able to repro-
duce in a representative way the application behavior
in a controlled environment, for extensive experiments
in a large-enough spectrum of potential conﬁgurations of
the underlying Edge-Fog-Cloud infrastructure. In partic-
ular, this means rigorously mapping the scenario charac-
teristics to the experimental environment, identifying and

controlling the relevant conﬁguration parameters of ap-
plications and system components, deﬁning the relevant
performance metrics. The above process is non-trivial
due to the multiple combination possibilities of heteroge-
neous hardware/software resources, system components
for data processing, analytics or model training.

V. PHD OBJECTIVES

In order to allow other researchers to leverage the
experimental results and advance knowledge in different
domains, experimental methodologies need to enable
three R’s of research quality: Repeatability, Replicabil-
ity, and Reproducibility (3R’s). This translates to estab-
lishing a well-deﬁned experimentation methodology and
providing transparent access to the experiment artifacts
and experiment results.

The Computing Continuum vision calls for a rigorous
and systematic methodology to map real-world appli-
cation components and dependencies to infrastructure
resources, a complex process that can be error prone.
Key research goals are: 1) to identify relevant character-
istics of the application workloads and of the underlying
infrastructure as a means to enable accurate experimenta-
tion and benchmarking in relevant infrastructure settings
in order to understand their performance; and 2) to
ensure research quality aspects such as the 3R’s.

VI. OUR CONTRIBUTION: E2Clab

E2Clab [4] implements a methodology that supports
the complete experimental cycle across the edge-to-
cloud continuum, including deployment, conﬁguration,
optimization, and experiment execution in a reproducible
way. It may be used by researches to deploy real-
life applications on large-scale testbeds and perform
meaningful experiments in a systematic manner. The
main contributions of this work are:

A rigorous methodology for designing experiments
with real-world workloads on the Computing Con-
tinuum spanning from the Edge to the Cloud;
this
methodology provides guidelines to move from real-
world use cases to the design of relevant testbed setups
for experiments enabling researchers to understand per-
formance and to ensure the 3R’s properties.

A novel framework named E2Clab that

imple-
ments this methodology and allows researchers to deploy
their use cases on real-world large-scale testbeds, e.g.,
G5k [5]. To the best of our knowledge, E2Clab is the
ﬁrst platform to support the complete analysis cycle of
an application on the Computing Continuum: (i) the
conﬁguration of the experimental environment; (ii) the
mapping between the application parts and machines
on the Edge, Fog and Cloud; (iii) the deployment and
monitoring of the application on the infrastructure; and
(iv) the automated execution and gathering of results.

A large scale experimental validation on the
G5K [5] testbed with Pl@ntNet [6], a real-life use case.
E2Clab allows optimizing the Pl@ntNet’s performance
based on the analysis of the parameter settings and
correlation to processing time and resource usage [7].

VII. PRELIMINARY RESULTS
We illustrate [4] E2Clab usage with a real-life Smart
Surveillance System deployed on the Grid’5000 testbed,
showing that our framework allows one to understand
how the Cloud-centric and the hybrid Edge-Cloud pro-
cessing approaches impact performance metrics such
as latency and throughput. Besides, we validate [7]
E2Clab with Pl@ntNet, another real-life use case. We
demonstrate that E2Clab guides on the optimization of
the Pl@ntNet performance based on the analysis of the
parameter settings and correlation to processing time and
resource usage. Preliminary results show that Pl@ntNet’s
deployment conﬁgurations found by E2Clab perform
better than the current ones used in the production
servers.

VIII. NEXT RESEARCH STEPS

We are exploring parallel and scalable optimization
techniques that supports surrogate modeling optimization
for large-scale multi-objective optimization problems. In
this direction, we have an ongoing collaboration with
Argonne National Laboratory members, where we are
discussing potential solutions to support the optimiza-
tion of complex application workﬂows on the Edge-to-
Cloud Continuum. Furthermore, since E2Clab supports
reproducible experiments, we will explore and propose
techniques for runtime provenance collection in large-
scale and distributed experimental environments. The
goal is to provide additional context that more accu-
rately explains the experiment execution and results. This
research direction is a collaboration with the Federal
University of Rio de Janeiro, Brazil.

REFERENCES

[1] ETP4HPC Strategic Research Agenda.

[Online]. Available:

https://www.etp4hpc.eu/sra.html

[2] S. Sadiq et al., “Data Flow and Validation in Workﬂow
Modelling,” in Proceedings of the 15th Australasian database
conference-Volume 27, 2004, pp. 207–214.

[3] S. Svorobej et al., “Simulating Fog and Edge Computing Sce-
narios: An Overview and Research Challenges,” Future Internet,
vol. 11, no. 3, p. 55, 2019.

[4] D. Rosendo et al., “E2clab: Exploring the computing continuum
through repeatable, replicable and reproducible edge-to-cloud ex-
periments,” in IEEE CLUSTER.

IEEE, 2020, pp. 176–186.

[5] R. Bolze et al., “Grid’5000: A Large Scale And Highly Reconﬁg-
urable Experimental Grid Testbed,” IJHPCA, vol. 20, no. 4, pp.
481–494, 2006.

[6] A. Joly et al., “A look inside the pl@ntnet experience,” Multimedia

Systems, vol. 22, no. 6, pp. 751–766, 2016.

[7] D. Rosendo et al., “Reproducible performance optimization of
complex applications on the edge-to-cloud continuum,” arXiv
preprint arXiv:2108.04033, 2021.

