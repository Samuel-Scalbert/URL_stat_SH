A Hybrid Bi-LSTM-CRF Model for Sequence Labeling
Applied to the Sourcing Domain
Hasnaa Daoud, Molka Tounsi Dhouib, Jerôme Rancati, Catherine Faron,

Andrea Tettamanzi

To cite this version:

Hasnaa Daoud, Molka Tounsi Dhouib, Jerôme Rancati, Catherine Faron, Andrea Tettamanzi. A
Hybrid Bi-LSTM-CRF Model for Sequence Labeling Applied to the Sourcing Domain. PFIA-APIA
2020 - 5ème Conférence Nationale sur les Applications Pratiques de l’Intelligence Artificielle, Jun 2020,
Angers, France. ￿hal-02932095￿

HAL Id: hal-02932095

https://inria.hal.science/hal-02932095

Submitted on 7 Sep 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

A Hybrid Bi-LSTM-CRF Model for Sequence Labeling Applied to
the Sourcing Domain

Hasnaa Daoud1, Molka Tounsi Dhouib1,2, Jerôme Rancati1,
Catherine Faron2, Andrea G. B. Tettamanzi2

1 Silex France
2 Université Côte d’Azur, Inria, CNRS, I3S, Sophia Antipolis, France

{hasnaa.daoud, molka.tounsi, jerome.rancati}@silex-france.com,
{dhouib,faron,tettaman}@i3s.unice.fr

Résumé
Dans un certain nombre de domaines, les entreprises sont
souvent confrontées à la tâche de traiter au quotidien des
quantités importantes de demandes textuelles. L’extraction
automatique des informations clés à partir des demandes
clients, peut aider à accélérer le processus de traitement.
Silex France est aujourd’hui confrontée à ces enjeux dans
le cadre du traitement des demandes de sourcings.
Dans cet article, nous partageons nos résultats d’étique-
tage de séquences en nous basant sur une méthode hybride
BiLSTM-CRF, dans un contexte industriel. Le travail est in-
tégré dans la plate-forme B2B Silex pour la recommanda-
tion des prestataires de services. Les expériences faites sur
les données de la plateforme B2B Silex montrent qu’avec
un bon choix de features à extraire et des hyperparamètres,
la combinaison du modèle Bi-LSTM-CRF permet de réus-
sir l’extraction d’infomation à partir des demandes tex-
tuelles, même dans un contexte de petites données (small
data). En effet, le contenu textuel traité est sous forme de
phrases complètes générées par des utilisateurs, et est ainsi
exposé à des erreurs de frappe. Pour gérer ce type de don-
nées, nous combinons plusieurs types de features extraites
décrivant le contenu textuel tels que : (i) la sémantique, (ii)
la syntaxe, (iii) les caractères des mots, (iv) la position des
mots.

Mots-clés
Traitement du Langage Naturel, Extraction d’Information,
Etiquetage de Séquences, Réseaux de neurones artiﬁciels

Abstract
In a number of areas, companies are often faced with the
task of dealing with large amounts of textual customers’ re-
quests. Automating information extraction like key phrases
from customers’ requests can help to accelerate the proces-
sing process. Silex France is currently facing this challenge
in the context of processing sourcing requests.
In this article, we share our sequence labeling results ba-
sed on a hybrid method Bi-LSTM-CRF, in an industrial
context. This work was integrated in the B2B Silex plat-
form for service providers recommendation. Experiments

with the B2B Silex platform data show that, with a good
choice of features to extract and optimal choice of hyper-
parameters, the combination of the Bi-LSTM and CRF
helps to achieve good results even in a context of small
data. Indeed, the textual content processed is in the form of
complete sentences generated by users, and thus is subject
to typing errors. To handle this type of data we combine
several types of extracted features describing the textual
content such as : (i) semantics, (ii) syntax, (iii) word cha-
racters, (iv) position of words.

Keywords
Natural Language Processing, Information Extraction, Se-
quence Labeling, Artiﬁcial Neural Networks

Introduction

1
Natural Language Processing (NLP) is a branch of Artiﬁ-
cial Intelligence (AI) that helps computers understand, in-
terpret and manipulate human language. Information Ex-
traction (IE) is a crucial task in the ﬁeld of NLP and linguis-
tics that is widely used for tasks such as Question Answe-
ring, Machine Translation, Entities Extraction, Event Ex-
traction...
In this paper, we report on an IE task we conducted in
the context of Silex company which develops a SaaS e-
sourcing platform for the identiﬁcation of the best pro-
viders that meet expressed needs. It takes into conside-
ration the requested service, costs, deadlines, innovation,
and quality [4]. There are two main user communities wi-
thin Silex platform : (i) service providers, and (ii) service
buyers. Silex aims to automatically analyze the textual des-
criptions of service requests and providers in order to better
evaluate opportunities in a faster way with more targeted
sourcings.
We aim to extract key phrases from customers’ requests.
In the context of sourcing requests, a key phrases usually
indicates a product, a service, an occupation (job title) or
a skill. These are the main entities in Sourcing domain.
These types of information can be considered as contex-
tualized named entities. In fact, it turns out that in some
requests, a customer may talk about his own services, but

we aim to extract only the services he needs.
We propose an IE approach based on a Bi-LSTM-CRF ar-
chitecture, able to analyze textual descriptions (service pro-
viders and service requests) and extract the relevant parts of
the text that summarize a provider’s offer/ a customer need
(such as services, products, occupations, skills). In this pa-
per, we focus on information extraction from service re-
quests.
Processing of service requests is more challenging than that
of service offers : (i) text requests are generally short (50
words on average in our case) ; (ii) the content of these des-
criptions is user-generated, and then is subject to typing er-
rors ; (iii) ﬁnally, a user may describe his own products or
services to contextualize his request, which would create
confusion. This raises the issue of distinguishing between
the real user’s need and the general context of the sourcing
request description. Therefore the task is not the extraction
of any expression describing a service or a product in a
sourcing request.
Our main research question is : How to extract relevant in-
formation that summarizes a customer’s need ? We focus
on the following sub-questions :

— Which is the best approach to extract information

from short texts ?

— Which types of embeddings must we use to extract

relevant information in our case ?

— How to deal with the limited number of data ?
Our approach is based on the Bi-LSTM-CRF framework
[11] ; a Bidirectional Long-term and Short-term Mermory
(Bi-LSTM) encodes an input sequence words and a Condi-
tional Random Fields model (CRF) labels every sequence
word. In [11], the authors use two types of embeddings :
word embeddings and character based embeddings (com-
puted using a Bi-LTSM). The ﬁnal embeddings, which
constitutes inputs of the main Bi-LSTM-CRF are obtained
by concatenating word embeddings and character based
embeddings.
Our contribution lies in the addition of two other types of
embeddings computed with two Bi-LSTMs : (i) Syntactic
embeddings and (ii) Position embeddings. Also, to answer
Silex use case, since we have only 858 annotated service
requests, we adapted the architecture hyper-parameters to
our context of small data.
This paper is organized as follows : Section 2 presents the
related works. Section 3 describes our information extrac-
tion approach. Section 4 describes our data and our imple-
mentation. Section 5 reports and discusses the results of our
experiments. Section 6 concludes with an outline of future
work.

2 Related Works

There are three common techniques in the literature for the
NER task [17, 12] : (i) knowledge-based unsupervised sys-
tems, (ii) feature-engineered supervised systems and (iii)
feature-inferring neural network systems.
Our work is mostly related to feature-inferring neural net-
work systems. [3] proposes semi-supervised method where

a deep neural network model learns internal representa-
tions on the basis of vast amounts of mostly unlabeled trai-
ning data. This model presents two main limitations : (i)
it doesn’t take into account long-term dependencies bet-
ween words because it is based on a simple feed-forward
neural network and limits the use of context to a ﬁxed-size
window ; (ii) by using only word embedding, the model
is unable to exploit other features such as letter’s cases or
complex aspects of user-generated content. These types of
considerations could be useful, especially for rare words.
To overcome some of the limitations of [3]’s model, deep
learning algorithms such as Recurrent Neural Networks
(RNN) are successfully applied for sequence labeling task.
Authors of [18] present a detailed comparison between the
Convolution Neural Networks (CNN), and RNN in the par-
ticular context of NER. The speciﬁcity of RNN is that it
allows a neural network to exhibit temporal dynamic be-
havior to process input sequences with no limitation on
the input size. However, RNN are not adapted when in-
put sequences are getting too long ; in a RNN, gradients are
back-propagated through all time steps as well. This means
that the longer our sequence size is, the more gradients we
will be taking the product of. This leads to the vanishing
gradient problem. Long-term and Short-term Memory Net-
works (LSTMs) are a particular type of RNN that are desi-
gned to avoid this problem through the use of LSTM cells,
which makes it easy to learn about long term dependen-
cies [5].
[11] proposes a more powerful neural network model that
incorporates a bi-directional LSTM (Bi-LSTM) and CRF.
This model is based on robust learning with the dropout,
which allows good recognition results of NER. The bi-
directional LSTM model takes into account the whole
context enables to effectively train a model with the ﬂexible
use of long range context [6].
In addition to the architecture, the way we present input
data to a neural network matters. For example, we can
see a textual sentence in different ways : (i) sequence of
words, (ii) sequence of letters, (iii) sequence of chunks...
Enriching the input sequences with accessible additional
data can also help to have better results. Character-based
representations are very important in our use case. In fact,
our data are user-generated. Then, it is important to cap-
ture morphological and orthographic patterns. [2] presents
a hybrid bidirectional LSTM and bidirectional CNN neural
network architecture that helps to exploit explicit character
level features such as preﬁxes and sufﬁxes, which could be
useful especially with rare words for which word embed-
dings are poorly (or are not) trained. [14] introduces the
neural character embedding in the NER task for English
and achieves the state-of-the-art. [1] explored ways to im-
prove point-of-sale labeling using different types of auxi-
liary losses, and different representations of words. They
built their model based on Bi-LSTM layers and showed
that introducing word representations through their charac-
ters gives better results in terms of model speed and per-
formance. [9] proposes a simple yet effective dependency-
guided LSTM-CRF model that takes the complete depen-

dency trees and captures syntactic properties for the Named
Entities Recognition task. Furthermore, [11] incorporated
character-level structure into word representation. Each in-
put vector consists of two parts : (i) pre-trained word-level
representation [13] and (ii) task-related character-level re-
presentation. The authors of [11] adopted a bidirectional
LSTM to capture information in both forward and back-
ward directions and concatenate the outputs of these two
LSTMs.
Most related works cited in this paper use only word em-
bedding, or combine them with character based representa-
tions [9, 1], while we enrich input sequences with Part Of
Speech tagging and word position information. The way
we represent sequences improves the results in our use
case.

3 Methodology

Bi-LSTM-CRF model is introduced by Huang and al [8].
It has been compared to LSTM, Bi-LSTM and LSTM-
CRF models. Best results in the paper are achieved with
Bi-LTSM-CRF model in different sequence tagging tasks
(Part-of-Speech Tagging, Chunking, and NER tasks). In
the ﬁrst part of this section, we present the state of the art
Bi-LSTM-CRF model and how we use it in our architec-
ture. In the second part, we detail the features we introduce
to enrich word embeddings.

3.1 Architecture

3.1.1 Bi-LSTM :

Bidirectional LSTM or Bi-LSTM model [7] is composed of
two LSTMs each one processes the sequence in a different
direction.
The main characteristics of LSTM are (i) the ability to ope-
rate on sequential data and (ii) the ability to capture long
term dependencies thanks to a memory-cell.
LSTM takes as input a sequence of vectors X =
(x1, x2, ..., xn) and returns another sequence of vectors,
named hidden states vectors H = (h1, h2, ..., hn) as out-
put.
Below, we detail mathematical equations in LSTM net-
work we used in this work :

it = σ(Wxixt + bxi + Whih(t−1) + bhi)
ft = σ(Wif xt + bif + Whf h(t−1) + bhf )
Ct = tanh(WiCxt + biC + WhCh(t−1) + bhC)
ot = σ(Wioxt + bio + Whoh(t−1) + bho)
ct = ft x c(t−1) + itxCt
ht = ot x tanh(ct)

1

Where xt is the input at time t, ht is the hidden state at time
t, ct is the cell state at time t, ht is the hidden state of the
layer at time t-1 or the initial hidden state at time 0, and
it, ft, Ct , ot are the input, forget, cell, and output gates,
respectively. σ is the sigmoid function.
Figure 1 presents the LSTM architecture, where pink

1. x is Hadamard product

FIGURE 1 – LSTM Architecture.

circles represent arithmetic operators and rectangles re-
present LSTM gates.
The drawback of the LSTM model is that it processes in-
put from left to right, which involves that it can only en-
code dependencies on previous tokens. That is why a se-
cond LSTM is used to process input in the reverse direction
(i.e., from right to left). This new layer makes it possible to
detect dependencies on the right context of a token.
In our model, we use Bi-LTSMs to :

— Extract character based embeddings, syntactic re-
presentations, and position representations. This
part will be detailed in section 3.2.

— Combine all of these representations to extract
complete dependency information. The idea is to
concatenate the above representations and pre-
trained word embeddings to have complete repre-
sentations of words, then to pass the obtained re-
presentations by a Bi-LSTM.

3.1.2 Linear Conditional Random Field
The way sequences are encoded is not the only important
part in a sequence labeling problem. The chosen classiﬁer
also plays a crucial role. One simple approach is to classify
each word independently. The problem with this approach
is that it assumes that given the input, all of the entity labels
are independent.
In order to relax this assumption, Generative Models na-
med HMMs (Hidden Markov Models) make two assump-
tions : (i) Each state depends only on its immediate pre-
decessor. (ii) Each observation variable depends only on
the current state. This last statement makes it impossible to
add additional knowledge in the model (e.g contextual in-
formation). Using conditional Random Fields (CRF) [10]
is a solution to overcome this issue. CRFs are undirected
graphical models and are partially similar to HMMs. None-
theless, they are not Generative but Discriminative Models
trained to maximize the conditional probability of obser-
vation and state sequences [15]. The primary advantage of
CRFs over HMMs is their conditional nature, resulting in
the relaxation of the independence assumptions required by

HMMs in order to ensure tractable inference.
In our Bi-LSTM-CRF model, after extracting a sequence
hidden vectors (h1, h2, h3, ..., hn) with Bi-LSTMs (with n
the sequence length), we compute scores associated with
each label j at position t in the sequence with a linear layer.
We consider P the resulted matrix of size n × k (with k the
number of labels) :

Pt = Whpht + bhp∀t ∈ [[1, n]]

(1)

with :

— ht = (htl , htr ) hidden vector at position t in the se-
quence (concatenation of two hidden vectors ; right
context hidden vector and left context hidden vec-
tor)

— Whp weight matrix of dimension (k, m) (with m

the hidden vectors size)

— bhp bias vector of dimension k

As explained earlier, CRF model does not rely only on ma-
trix P since we assume that predicted variables in a se-
quence depend on each other.
Inference in linear CRF models is based on maximizing the
following conditional probability :

P (y|H) =

exp(score(H, y))
y(cid:48)∈Y exp(score(H, y(cid:48)))

(cid:80)

(2)

with :

— H the matrix of hidden vectors

: H =

[h1, h2, h3, ..., hn]

— P (y|H) the conditional probability of a sequence

of tags y .

— Y the set of possible tag sequences.

score function is deﬁned as follows :

score(H, y) =

n
(cid:88)

t=1

Ayt,yt+1 +

n
(cid:88)

t=1

Pt,yt

(3)

With A the transition scores matrix (Ai,j transition score
from state i to state j)

3.2 Features
Our main contribution in this paper is the addition of new
kinds of features extracted using Bi-LSTMs. Our model
uses four different kinds of embeddings for each sequence
word. Three types of these embeddings are trained with
Bi-LSTMs, they are concatenated with pretrained FastText
word embeddings, and used as the input sequence to our
main Bi-LSTM-CRF model.
Figure 2 schematizes how the different types of embed-
dings are trained.

3.2.1 Word embedding
Word embeddings are vector representations trained on a
large corpus of texts such as encyclopedias, news texts,
or literature. There are many language modeling and fea-
ture learning techniques that help to map words to vectors
that allow to represent the contextual proximity of different
words. It is possible to train from scratch these vector re-
presentations on the particular task of keyword sequence

FIGURE 2 – Model architecture (Embeddings Extraction + Main
BiLSTM-CRF)

tagging using our data. However, it turns out that the size
of our data will not allow us to cover a large vocabulary.
Therefore, we chose to use pre-trained word vectors for
French, learned using fastText 2 on a Wikipedia dump. The
French model we used contains 1.152.449 words mapped
to 300-dimensional vectors [13].

3.2.2 Syntactic Word Representations
Manual analysis of our data shows that syntax plays an im-
portant role to locate the user’s need in a sequence. Hence
the need to extract features representing syntax and de-
pendency between words. This type of information (i.e.,
syntactic structure and dependencies) is important to com-
plete the semantic information. For example, many sour-
cings requests contain verbs like (rechercher, souhaiter,
chercher ...), in these cases recognizing the sentence object
would help the model to recognize the customer’s need.
We then trained part-of-speech (POS) embeddings, using a
Bi-LSTM Model.

3.2.3 Character-level Word Representations
Fasttext pretrained Word embedding allows to extract in-
formation about the meaning of words, but the covered vo-
cabulary remains limited to the vocabulary of the training
corpus. Therefore, rare words or words with spelling errors
cannot be represented. Hence the importance of Character-
level Word Representations since any word is made up of a
number of characters and characters set is ﬁnite. For every
word, we use a BiLSTM that takes as input the sequence of
word’s characters, and returns the last hidden states vector.
We consider this vector as a character level based represen-

2. https ://fasttext.cc/docs/en/pretrained-vectors.html

tation.

3.2.4 Position Representation
This kind of information is important in our use case : ba-
sed on manual analysis of our data, it turns out that the
main subject is mentioned at the beginning of the text. We
are convinced that this is generally valid for written text re-
quests. Thus, it would be interesting if the model takes into
account the position of words. This way, the model will be
able to understand that it is highly likely that the words at
the beginning of the text are relevant information. We use
a Bi-LSTM model to extract this type of embedding.
All these types of representations are concatenated and
used as input of the main Bi-LSTM-CRF bloc as shown
in Figure 2.

4 Experiments

4.1 Dataset
Our dataset is composed of 883 descriptions of service re-
quests distributed as follows : (i) 594 service request des-
criptions in the train set, (ii) 198 service request descrip-
tions in the development set, and (iii) 90 service request
descriptions in the test set.
Data are annotated by Sourcing experts at Silex according
to the BIOES format, which stands for Beginning, Inside,
Outside, End, and Single to indicate the position of a token
in a tagged segment. Descriptions are annotated as follow :

— B- : to mark the beginning of an entity
— I- : to mark the inside of an entity
— E- : to mark the end of an entity
— S- : to mark a single entity
— O : to mark a token outside all of entities

Table 1 shows an example annotation using the BIOES for-
mat.

Word
Je
recherche
un
plombier

POS
Label
PRON
O
VERB
O
O
DET
NOUN S-

DET
O
La
NOUN O
société
NOUN O
BNB
O
VERB
souhaite
O
VERB
créer
DET
O
des
NOUN B-
supports
de
I-
ADP
communication NOUN E-
.
.

.
.

.
.

rated new training examples by applying some transforma-
tions of the available ones. These transformations must pre-
serve the entities’ labels.
In the ﬁeld of NLP, it is difﬁcult to increase text due to the
complexity of natural language. Some methods in the lite-
rature use shufﬂing, which involves changing the order of
sentences in the text or random deletion of certain words
from the text. However, this augmentation techniques may
change the whole context of the text. In natural language
processing, it is not a good idea to augment data using
signal transformation techniques (images [16], speech re-
cognition...), because the order of characters is important
to keep a strict syntactic and semantic meaning. Other aug-
mentation techniques make more sense in the context of
our work, such as injecting punctuation noise or modifying
certain characters in words. Otherwise, it is difﬁcult to add
more semantics, the best way to do so is to use human sen-
tence rephrasing, but it is an expensive operation. There-
fore, the most natural choice in data augmentation for us
is to replace words with their synonyms based on a dictio-
nary of synonyms of the most frequent words in the ﬁeld
of sourcing.
We therefore chose to augment our training dataset by :

— introducing punctuation noise
— changing characters of some words (which simu-

lates spelling errors in user-generated data)
— replacing some words with their synonyms
This way, we multiplied our training set size by three.

Implementation

4.2
To implement our model, we used the Pytorch library,
which supports GPU computing. For all Bi-LSTMs in our
model, we used the torch.nn.LSTM class, which allows to
create LSTMs and to set parameters such as the number of
layers, bidirectionality, input feature size, hidden state vec-
tor size. We implemented the CRF based on equations of
section 3.1.2. We use the Viterbi algorithm for ﬁnding the
most likely sequence of hidden states.

4.3 Hyper-parameters
Table 2 shows the hyper-parameters we use in Bi-LSTM
layers used for character-based, position and syntactic fea-
tures extraction.

Features

Syntactic features
Character-level based features
Position features

Embedding Hidden vectors
dimensions
25
25
25

dimensions
30
50
30

TABLE 2 – Hyper-parameters for the features extraction layers

TABLE 1 – Example of input training data

Artiﬁcial neural networks generally require a large corpus
of training data in order to learn efﬁciently the task. To
overcome this limitation of the training set size (594 ser-
vice requests), we augmented the training set. We gene-

For the ﬁnal Bi-LSTM bloc (see Figure 2) used to combine
all the features of Table 2 with Fasttext word embeddings,
we chose a hidden layer of size 400.
In our experiments, we started by initializing the semantic
word embedding layer with FastText pre-trained embed-
dings, and we updated them during training. We found that

this causes overﬁtting because of a high number of para-
meters. We then chose to freeze the semantic word em-
bedding layer, which helped us to improve the results.
In addition to increasing the data, to avoid over-ﬁtting, we
chose a high dropout value of 0.5.
In the literature, the number of Bi-LSTMs hidden layers is
usually equal to the same number of embedding units. We
compared the results with different units’ numbers in the
main Bi-LSTM and we were able to get better results when
the size of the hidden layers is equal to 400.
In this paper, we conducted four experiments to compare
the performance of four kinds of models :

— I : Bi-LSTM model with only word embedding and

logistic regression classiﬁcation model

— II : Bi-LSTM model with only word embedding and

CRF classiﬁcation model

— III : Bi-LSTM-CRF model with word embedding,
character-based representations, and Bi-LSTM po-
sition based representation.

— IV : Bi-LSTM-CRF model with word embed-
ding, character-based representations, Bi-LSTM
position-based representation and syntactic word
representations.

5 Result and Discussion
The problem we deal with is different from ordinary NER
tasks, since we detect text segments summarizing a user’s
need. Let us note that even expert annotators ﬁnd it some-
times hard to decide on the segment to annotate. Thus, we
chose to evaluate the four models in two different ways :
(i) Precision and Recall, (ii) Cosine similarity.

5.1 Precision and Recall
We started with an evaluation based on precision, recall,
and the F1 score as the basis for choosing the best model.
In our evaluation, we do not consider the complete anno-
tated entity, but rather words of the entity separately. For
example, in the sentence “I am looking for a plumber able
to repair a faucet Sprinkle”, we do not fully penalize the
algorithm if it does not detect the complete repair a faucet
Sprinkle segment. But we count words that it could detect
in that segment. Indeed, if we suppose that the model de-
tects only repair a faucet, this may be enough to unders-
tand the need’s subject. We also ignore conjunctions, de-
terminants and punctuation in the evaluation. Table 3 pre-
sents the results obtained in terms of precision, recall and
F1 score.

Recall

Model Dev
I
II
III
IV

58.88
64.03
63.06
67.57

Test
61.31
66.61
66.61
70.20

Precision
Test
76.61
76.66
80.11
73.77

Dev
77.02
75.21
75.62
76.03

F1

Dev
66.74
69.17
68.77
71.55

Test
68.11
71.29
72.74
71.94

TABLE 3 – Precision, Recall and F1-score without data augmen-
tation

Figure 3 and Figure 4 respectively show the evolution of

FIGURE 3 – Evolution of score F 1Dev

FIGURE 4 – Evolution of the function (loss)

the F1 score and the evolution of the loss function across
epochs.
One can see that model IV which uses all types of features
is the best model across all epochs. Model I, which takes
as word representations only word embedding with logis-
tic regression for tagging, has the lowest score. Figure 4
shows that from epoch 30, the loss function continues to
decrease without improving the F1 score. From this epoch,
the model starts to overﬁt on training data.
Using syntactic information with POS tagging signiﬁcantly
improves Dev and Test recall, and balances well precision
and recall (see Table 3). We also note that with this model,
we were able to get a similar F1 scores in dev and test data
(difference of 0.39%). The switch from CPU to GPU com-
puting allowed us to gain in terms of performance (more
than 1 difference for the F 1 score, which is due to the dif-
ference between implementations of the libraries used on
CPU and GPU) and in terms of training time (from 350
seconds per epoch to 75 seconds per epoch for model IV) .
With data augmentation (Table 4), we have mainly impro-
ved the F 1Dev scores of the different models. The recall

Recall

Model Dev
I
II
III
IV

60.94
65.64
63.64
67.05

Test
61.93
67.71
68.49
68.02

Precision
Test
73.79
70.23
72.68
77.58

Dev
77.31
75.50
75.28
75.34

F1

Dev
68.15
70.22
70.13
70.96

Test
67.35
68.94
70.52
72.49

TABLE 4 – Results with data augmentation

associated with test dataset was relatively improved for the
ﬁrst three models, but the precision decreased relatively,
except for model IV.
We can deduce that the best model in terms of Test and
Dev scores is model IV that uses a Bi-LSTM-CRF ap-
plied on the concatenation of semantic embedding, POS
embedding, Character based embedding, and Position em-
bedding.
We point out that the difference between dev and test scores
is due to the small amount of annotated data.
The disadvantage of this evaluation method in the particu-
lar case of our work is that it gives equal importance to
all extracted words. However, it turns out that some words
are more important than others, especially words for which
meaning appears several times in a service request extrac-
ted segments. In the sentence "I am looking for a plumber
able to repair a faucet Sprinkle", "plumber" and "faucet"
are two words that generally appear in the same context and
could be considered as the most important extracted words.
"Sprinkle" ; the faucet brand, is the least important word.
However, with precision and recall evaluation, all words
are given the same weight, and the model will be penalized
in the same way if it does not detect the word Sprinkle or
the word plumber.
We mentioned earlier that the manual annotation was not
obvious to the experts. Here is a second possible scenario :
in the previous example, an annotator decides to annotate
only "plumber" as a unique key phrase, and the model an-
notates only "repair a faucet", even if there is an important
semantic similarity between the two segments, the model
will be penalized in terms of Precision and Recall scores.
Hence, to deal with this issue, we propose a meaning-based
evaluation.

5.2 Evaluation using cosine similarity distri-

bution

To address all of the above problems, we tried to present
the results otherwise, which corresponds to the purpose of
this work.
Indeed, the goal is to be able to reduce a service request
description into a set of keywords. So we thought of calcu-
lating the cosine similarity between embedding of expert
annotated segments and embedding of segments detected
by the algorithm for each service request, and then plot the
histogram of the results. A service request extracted seg-
ments’ embedding is computed by averaging on FastText
pretrained word embeddings of their words. We ignore stop
words and punctuation. In Figure 5, we present four histo-
grams each associated to a different model.

Note that each type of features added to the model helps to
move the distribution a little bit to the right. We can clearly
see the difference between the distribution of model I and
the distribution of model IV : the distribution of model IV
is tightest around 1, with a highest peak.

6 Conclusion
In this paper, we proposed a method that relies on Bi-
LSTM-CRF for sequence labeling to summarize sourcing
requests. We combined several types of features to re-
present every word in a sequence. The key of success of
our method is an original combination of input features.
In addition to word embedding, we extract three other
kinds of embeddings : (i) character-level based embed-
dings, (ii) syntax based embeddings and (iii) position em-
beddings. These additional embeddings are extracted using
Bi-LSTMs and are concatenated with word embedding. We
have shown that syntax and position of words help to im-
prove the quality of the information extraction in our use
case. We also shared hyper-parameters that give us the best
training and choices we made to overcome overﬁtting pro-
blems. Moreover, we have shown that Bi-LSTM-CRF ar-
chitectures for information extraction can provide value
even in a small data context.
This work was integrated into Silex sourcing platform to
recommend similar service requests, which considerably
reduces the processing time in 60% of cases. This re-
commendation is based on semantic similarity between re-
quests based on their extracted segments.
As future work we aim to experiment new extraction ap-
proaches based on transformers like BERT or Camembert
for French texts. We also aim to evaluate the generality of
our approach designed for the sourcing domain by experi-
menting it in a general benchmark.

Références
[1] Daniil Anastasyev, Ilya Gusev, and Eugene Inden-
Improving part-of-speech tagging via multi-
bom.
task learning and character-level word representa-
tions. arXiv preprint arXiv :1807.00818, 2018.

[2] Jason PC Chiu and Eric Nichols. Named entity
recognition with bidirectional lstm-cnns. Transac-
tions of the Association for Computational Linguis-
tics, 4 :357–370, 2016.

[3] Ronan Collobert,

Jason Weston, Léon Bottou,
Michael Karlen, Koray Kavukcuoglu, and Pavel
Kuksa. Natural language processing (almost) from
Journal of machine learning research,
scratch.
12(Aug) :2493–2537, 2011.

[4] Rémi ESCHENLAUER. Le sourcing, June 2013.

[5] Felix A Gers, Jürgen Schmidhuber, and Fred Cum-
mins. Learning to forget : Continual prediction with
lstm. 1999.

[6] Alex Graves, Abdel-rahman Mohamed, and Geoffrey
Hinton. Speech recognition with deep recurrent neu-
ral networks. In 2013 IEEE international conference

(a) Model I

(b) Model II

(c) Model III

(d) Model IV

FIGURE 5 – Distribution of cosine similarity between segments automatically detected and segments annotated by human experts

[14] Cicero Nogueira dos Santos and Victor Guima-
Boosting named entity recognition with
arXiv preprint

raes.
neural character embeddings.
arXiv :1505.05008, 2015.

[15] Charles Sutton, Andrew McCallum, et al. An intro-
duction to conditional random ﬁelds. Foundations
and Trends R(cid:13) in Machine Learning, 4(4) :267–373,
2012.

[16] Luke Taylor and Geoff Nitschke.

Improving deep
learning using generic data augmentation. arXiv pre-
print arXiv :1708.06020, 2017.

[17] Vikas Yadav and Steven Bethard. A survey on recent
advances in named entity recognition from deep lear-
arXiv preprint arXiv :1910.11470,
ning models.
2019.

[18] Zenan Zhai, Dat Quoc Nguyen, and Karin Verspoor.
Comparing cnn and lstm character-level embeddings
in bilstm-crf models for chemical and disease named
entity recognition. arXiv preprint arXiv :1808.08450,
2018.

on acoustics, speech and signal processing, pages
6645–6649. IEEE, 2013.

[7] Alex Graves and Jürgen Schmidhuber. Framewise
phoneme classiﬁcation with bidirectional lstm and
other neural network architectures. Neural networks,
18(5-6) :602–610, 2005.

[8] Zhiheng Huang, Wei Xu, and Kai Yu. Bidirectional
lstm-crf models for sequence tagging. arXiv preprint
arXiv :1508.01991, 2015.

[9] Zhanming Jie and Wei Lu. Dependency-guided lstm-
arXiv preprint

crf for named entity recognition.
arXiv :1909.10148, 2019.

[10] John Lafferty, Andrew McCallum, and Fernando CN
Pereira. Conditional random ﬁelds : Probabilistic mo-
dels for segmenting and labeling sequence data. 2001.

[11] Guillaume Lample, Miguel Ballesteros, Sandeep Su-
bramanian, Kazuya Kawakami, and Chris Dyer. Neu-
ral architectures for named entity recognition. arXiv
preprint arXiv :1603.01360, 2016.

[12] Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li. A
survey on deep learning for named entity recognition.
arXiv preprint arXiv :1812.09449, 2018.

[13] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S
Corrado, and Jeff Dean. Distributed representations
of words and phrases and their compositionality. In
Advances in neural information processing systems,
pages 3111–3119, 2013.

