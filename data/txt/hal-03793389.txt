Reasoning about manipulation in multi-agent systems
Christopher Leturc, Grégory Bonnet

To cite this version:

Christopher Leturc, Grégory Bonnet. Reasoning about manipulation in multi-agent systems. Journal
￿hal-
of Applied Non-Classical Logics, 2022, 32 (2-3), pp.89-155.
03793389￿

￿10.1080/11663081.2022.2124067￿.

HAL Id: hal-03793389

https://hal.science/hal-03793389

Submitted on 21 Oct 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Reasoning about Manipulation in Multi-Agent Systems

Christopher Leturca and Gr´egory Bonnetb

aInria, Universit´e Cˆote d’Azur, CNRS, I3S, France
bNormandie Univ, UNICAEN, ENSICAEN, CNRS, GREYC, 14000 Caen

ARTICLE HISTORY
Compiled October 21, 2022

ABSTRACT
In many applications, selﬁsh, dishonest or malicious agents may ﬁnd an interest
in manipulating others. While many works deal with designing robust systems or
designing manipulative strategies, few works are interested in deﬁning in a broad
sense what is a manipulation and how we can reason with such a notion. In this
article, based on a social science literature, we give at ﬁrst a general deﬁnition of
manipulation that can be applied in multi-agent systems. A manipulation is a de-
liberate eﬀect of an agent (called a manipulator ) to instrumentalize another agent
(called a victim), while making sure to conceal that eﬀect. Secondly, we show how
this deﬁnition is related with diﬀerent ﬁelds in computer science where the concept
of manipulation is studied. Finally, we present a logical framework, called KBE,
to express and reason about manipulations. Since manipulation relies on deliber-
ate eﬀects, KBE introduces a deliberate BIAT operator which abstracts deliberate
consequences of actions. We prove that this logic is sound and complete and, we
formally deﬁne manipulation. Furthermore, based on KBE, we express related no-
tions such as coercion, persuasion, or deception and we show that these notions are
diﬀerent from manipulation.

KEYWORDS
Deception; Manipulation; Modal logics; Neighborhood semantics.

1. Introduction

In many applications, selﬁsh, dishonest or malicious agents may ﬁnd an interest in
manipulating others. In computer science and social science, manipulation is viewed
as controlling or inﬂuencing somebody or something, often in a dishonest way so that
they do not realize it. For example, reputation systems evaluate the trust that one
agent should place in another depending on other agent’s testimonies (Hoﬀman, Zage,
& Nita-Rotaru, 2009; Josang & Golbeck, 2009; Ruan & Durresi, 2016). However, agents
may have interest in those systems in lying so as to mislead others, and push them to
interact with some speciﬁc agents. Such behaviour is a manipulation in the sense that,
to be eﬀective, the liar must ensure that the other agents are unaware he intended to
mislead them.

In the ﬁeld of artiﬁcial intelligence, many works dealt with manipulation as in
computational social choice (Gibbard, 1973; Parkes & Ungar, 2000; Robinson, 1985;
Sanghvi & Parkes, 2004), game theory (Ettinger & Jehiel, 2010; Wagner & Arkin,

CONTACT Christopher Leturc Email: christopher.leturc@inria.fr

2009), or recommendation systems (Mobasher, Burke, Bhaumik, & Sandvig, 2007;
Resnick & Sami, 2008). From a general perspective, there are many works on concepts
closely related to manipulation (Masters, Smith, Sonenberg, & Kirley, 2021). For in-
stance, in modal logic literature, some works have modeled social inﬂuence (Lorini
& Sartor, 2016) and deception (Sakama, Caminada, & Herzig, 2015; Van Ditmarsch,
Van Eijck, Sietsma, & Wang, 2012). Interestingly, social science deals with manip-
ulation as a combination of many concepts, e.g. strategies, deception, obfuscation,
intentionality (Akopova, 2013; Cohen, 2017; Handelman, 2009; Todd, 2013). A review
of social science literature allows us to consider a general deﬁnition of manipulation,
i.e. acting in such a way to produce a deliberate eﬀect of inﬂuencing another agent
while concealing this inﬂuence.

This article is an extended version of our previous work (Leturc & Bonnet, 2020).
In this work, we deﬁned a modal logic that allows one to reason about this concept
of manipulation. To this end and to express deliberate eﬀects, we have proposed a
deliberate BIAT modality and combined it with a STIT-like modality to catch all
consequences of actions and side-eﬀects of actions. Concealment was expressed through
epistemic and doxastic modalities. In the present article, we extend this previous work
with two new contributions: (1) we provide a broad state-of-the-art about manipulation
in social science, and about logical systems to express such notion; (2) we provide the
complete proofs of all theorems given in Leturc and Bonnet (2020).

The remainder of this article is structured as follows. In Section 2, we present a
review of the notion of manipulation drawn from social science literature, and we
propose a general deﬁnition of manipulation. In Section 3, in view of the previous
deﬁnition of manipulation, we survey available logical tools that are able to express it.
In Section 4, we propose a logical framework and show that it is sound and complete.
In Section 5, we formally deﬁne manipulation, and show our formal framework can
also be used to model coercion, persuasion and deception. Finally, in Section 6 we
instantiate an example.

2. Deﬁning manipulation

The notion of manipulation is present in several ﬁelds of computer science such as
in social choice theory (Gibbard, 1973), or in reputation systems (Vall´ee & Bonnet,
2015) where it is deﬁned as a strategy allowing an agent to inﬂuence and control
the individual (or collective) decision-making process of a group of agents using false
information in order to push the latter to make a decision in favour of the manipulating
agent. However, this is a restrictive notion of manipulation, as shown by works on
social psychology, manipulative agent does not necessarily use the transmission of false
information to manipulate. For example, the “foot in the door” consists in getting the
victim to engage in a preparatory behavior to facilitate a decision in favor of the
manipulator (Joule, Beauvois, & Deschamps, 2002). As another example, social proof
consists in showing a victimized agent a set of behaviours that other agents exhibit
in order to inﬂuence him or her to imitate those agents (Cialdini, 2012). All those
manners – using false informations, behaviors or social proof – are diﬀerent concrete
strategies to manipulate. In order to model manipulation in a broader way, we need
a suﬃciently broad deﬁnition of manipulation and we propose to extract it through
social science literature. For this reason, Section 2.1 presents a survey on manipulation
from the point of view of these ﬁelds. This state-of-the-art then allows us to give a
deﬁnition of the term in Section 2.2.

2

2.1. Manipulation in social science

Social scientists often disagree on the deﬁnition of manipulation. For some of them,
manipulation is considered to be the act of altering the judgment of individuals by
depriving them of some of their deliberate choices (Kligman & Culver, 1992; Saint
Clair, 1966; Sunstein, 2015). However as stated by (Handelman, 2009; Rudinow, 1978;
Sorlin, 2017), such a deﬁnition would lead to consider rational persuasion, deception or
coercion as manipulation whereas most people would distinguish them. Consequently,
there are four ways to consider manipulation in social science literature: considering
it as a “vague concept”, as strategies to alter the others’ judgment, as an exercise of
power over others, and ﬁnally as the invisible exercise of power. We review each of these
points-of-view and extract their main features to propose a deﬁnition of manipulation
for modeling.

2.1.1. Manipulation seen as a vague concept

By reviewing several situations in which the term ”manipulation” is frequently used
but giving counterexamples to each of them, the philosopher Felicia Nimue Ackerman
claims that it is impossible to characterize manipulation because it is a “combina-
torially vague concept” (Ackerman, 1995). By “combinatorially vague concept”, she
means that there are a variety of conditions under which the term is frequently used but
none of them are suﬃcient to discriminate with certainty between manipulative and
non-manipulative situations. To support her claim, Ackerman made a broad review
of those conditions, including for instance use of indirect, cunning and subtle means,
falsiﬁcation or omission of information, deception, pressure and unethical behaviors,
presence of hidden motives, and so on. While Ackerman claims that we cannot know
what combinations of these conditions actually constitute manipulation. We reject this
point-of-view for at least two reasons: (1) considering manipulation as a vague concept
makes impossible to give an explicit formal deﬁnition of manipulation and reasoning
with it as proposed in this paper and, (2) it would mean that eﬀorts to model manipu-
lation are doomed to failure unless to consider machine learning techniques to classify
the data space into categories such as “manipulation” or “not manipulation”, which
is currently not the aim of this paper.

2.1.2. Manipulation seen as strategies to tamper the others’ judgment

For many social scientists, manipulation is characterized by the use of psychological
methods that can alter the victim’s judgement, making him vulnerable to the manip-
ulator’s inﬂuence and unable to perceive the manipulation. For this reason, manipula-
tion can be deﬁned as strategies to exploit the others’ weaknesses: manipulation is any
successful and intentional act of inﬂuencing an agent’s beliefs or behavior, directly or
indirectly, by causing changes in mental processes (Baron, 2003; Faden & Beauchamp,
1986; Kahneman, 2011; Mills, 1995; Rudinow, 1978; Wilkinson, 2013). Those changes
can be:

(1) increasing or decreasing the available options to the victim;
(2) oﬀering a reward or threatening punishment to the victim;
(3) directly inﬂuencing the victim’s mental states.

This point-of-view focuses on the strategies behind a manipulation. Obviously, in
the literature there exists many deﬁnitions of strategy and the reader may refer to
Mintzberg’s review (Mintzberg, 1987). A manipulation can be based on exploiting

3

Basis of the strategy Examples

Exploiting
weaknesses

agents’

Deﬂecting norms

Abusing trust

Using rationality

Relying on emotions

Playing on knowledge /
beliefs

Cognitive dissonance (Festinger, 1962), discursive decep-
tion (Van Dijk, 2006), free will compliance (Joule et al.,
2002)
Reciprocity, social proof or social commitment (Cialdini,
2001)
Aggressive marketing (Calo, 2013), authority abuse (Luh-
mann, 1979), self-disclosure (A¨ımeur & Sahnoune, 2020)
Authority arguments Handelman (2009), nudges and dis-
creet rewards (Wilkinson, 2013)
Coercion (Wood, 2014), emotional blackmail (Gunderson,
1984), seduction (Strauss, 2006)
Deception (Whiten & Byrne, 1988), hidding truth (Maillat
& Oswald, 2009) or bullshitting (McGinn, 2014).

Table 1. A taxonomy of manipulation strategies in social science

an agent weakness as a cognitive dissonance, deﬂecting norms as social commitment,
abusing trust as betrayal, playing on the rational behavior of the victim, relying on
emotions such as playing on fear with coercion, or a manipulation strategy can be
based on knowledge or beliefs as lying, or bullshitting. Table 1 sums up and gives
examples of those kind of manipulation strategies.

Exploiting agent weaknesses
The theory of free will compliance, introduced in social psychology by Joule et al.
(2002), describes a set of behavioral manipulation techniques. Among them, baiting
involves asking a victim for a simple service, such as asking the time. It turns out
that after obtaining this ﬁrst service, it is easier to ask for a more compelling service.
Thus, a manipulator may have the deliberate intention to use one of these techniques
to manipulate humans. Another kind of weakness are cognitive biases (Kahneman,
2011). An agent can exploit those cognitive bias in order to induce another agent to
make commitments of which he is unable to see the importance.

Deﬂecting norms
A manipulator can deﬂect a social norm to his own beneﬁt. In social psychology,
presents a set of norms on which a manipulator can rely to push another agent to
realize his desire. For example, the norm of reciprocity is an internalized norm that
says to always reciprocate with agents who oﬀer us a service. Thus, a manipulator
may circumvent this norm by voluntarily oﬀering a costless service or resource to a
victim to push him to provide a costier service requested in return by the manipulator
(Cialdini, 2001).

Abusing trust
According to Castelfranchi and Falcone (2010), trust is the backbone of society. It is
also a tool of manipulation. Indeed, a manipulation strategy consists in building trust
in order to better control the other agents of the system. In marketing, trust is a tool
to get a customer to buy a product he does not need and without his awareness (Calo,
2013). For example, salespeople can announce a “scarcity” (Cialdini, 2001) to give a
customer the illusion that a product is of quality because there is not much left in
stock.

4

Using rationality
Rationality is a behaviour of agents who always want to maximize what they can
hope to gain from a given situation. It can be used to inﬂuence decisions without the
agent even being aware of this inﬂuence. Governments can use rationality as an argu-
ment to undermine political opponents. For instance, the 2003 Iraq war was presented
as “rational warfare” to gain support (Handelman, 2009). Other examples of manip-
ulations that can circumvent or subvert the victim’s rational abilities are the use of
nudges, or small discreet rewards to push an agent in the “good” direction (Wilkinson,
2013).

Relying on emotions
Manipulations between humans can have an emotional basis. A manipulative agent
simulates certain emotional states, for example when a child cries to get a new toy
from his parents. The child deliberately puts himself in this state to aﬀect the parents’
emotional state in order to get what he wants. In psychiatry, this emotionally based
manipulation strategy is found in many examples such as when a person threatens to
commit suicide. In this case, the threat aims at getting something from the others: a
listening ear, a service, hoping to get back together with a person (Gunderson, 1984).

Playing on knowledge and beliefs
The linguist Eddo Rigotti presents a typology of the main processes that allow a
manipulating agent to mislead another agent by playing on his beliefs and knowl-
edge (Rigotti, 2005). For example, sophistry is a technique that consists in pushing
another agent to deduce something false in order to exploit this error. Another exam-
ple consists in hiding the truth of a proposition which could weaken or contradict the
manipulator’s discourse (Maillat & Oswald, 2009).

2.1.3. Manipulation seen as the exercise of power over others

Beyond the strategies an agent can use to manipulate, for many researchers, manipu-
lation is primarily characterized as a form of power exercised over others (Abell, 1977;
Goodin, 1980; Kligman & Culver, 1992; Maoz, 1990; Todd, 2013).

Manipulation is not simply a loss of autonomy.
While manipulation is sometimes characterized as a loss of autonomy (Poulin, 2010;
Raz, 1986) (e.g. when a parasite takes control of its host), the philospher Patrick Todd
claims it is not enough to deﬁne manipulation because it is necessary to distinguish
between manipulation as the manipulation of an object, and manipulation as a case in
which agents act in a manipulative manner (Todd, 2013). However, loss of autonomy
is necessary for the manipulation to take place.

Manipulation is a deliberate intention.
Many social scientists state that manipulation is primarily an intention to act on
another agent with inﬂuence. This inﬂuence is said to be manipulative if it is delib-
erately and intentionally used by the manipulator while the inﬂuence is said to be
not manipulative as long as it is sincere, i.e. in accordance with what the inﬂuencer
takes to be true, relevant, and appropriate (Kligman & Culver, 1992; Noggle, 1996).
Indeed, when an agent manipulates another, the act is knowingly deliberate. As so-
cial science rejects the concept of unintentional manipulation, using a mechanism of
inﬂuence without knowing it, and therefore without having intended it, cannot be
considered as a manipulation.

5

Manipulation is the intention to change something.
Kligman and Culver (1992) deﬁne manipulation as the manpilator’s intention to
change something in his environment. For example, a manipulator may deliberately
withhold or selectively present certain information and omit others, exploiting the ig-
norance or beliefs of his victim in order to maintain control over his perceived options
and direct him in the direction desired by the manipulator. For Maoz (1990), political
manipulation is an attempt by one or more individuals to structure a collective deci-
sion as to maximize (resp. minimize) the chances of a favourable (resp. unfavourable)
outcome. For Abell (1977), manipulation is a process where a manipulative agent A
control a manipulated agent B’s preferences by reducing B’s understanding of the sit-
uation or B’s means of action. Interestingly, all those deﬁnitions are similar to those
used in game theory and social choice theory. For example, manipulating a voting sys-
tem consists in providing a false preference proﬁle to ensure a result preferred to the
one normally obtained with the true preference proﬁle (G¨ardenfors, 1976; Gibbard,
1973).

Manipulation does not always go against the interests of the others.
When one agent manipulates the other, he is doing it for his own interest, and this
often goes against the interests of the others. That is why Goodin (1980) claims that
manipulation is primarily a deceptive inﬂuence compelling one to act against one’s will.
In the same way, Barnhill (2014) states manipulation is also the intention of inﬂuencing
certain traits or psychological dispositions in order to bring the victim into ideals of
beliefs, desires or emotions in a way that is generally not in the victim’s self-interest
in the current context. However, all manipulations do not go against the self-interest
of the manipulated agent. For example, the placebo eﬀect that is sometimes used in
medicine to make a patient believe that he will be cured with an ineﬀective drug is a
manipulation in the patient’s interest (Turner, Deyo, Loeser, Von Korﬀ, & Fordyce,
1994). That is why some authors consider the existence of benevolent manipulations
(Rosenberg & Pearlin, 1962) meaning somebody exhibits a manipulative behavior in
order to push someone else to do something in the latter’s interest. Obviously, it means
that the manipulator has a representation (possibly impropered) of the “victim”’s
interest.

Manipulation is an instrumentalization of the others.
Being benevolant or not, manipulation can be viewed in all cases as a psychosocial
maneuver that uses aggression, coercion, intelligence, deception and trickery to inﬂu-
ence someone in order to achieve a manipulator’s desire (Bowers, 2003; Rigotti, 2005;
Saint Clair, 1966). Rigotti (2005) said the victim of a manipulation pursues the aim
of the manipulator in the illusion of pursuing his or her own goal. While Saint Clair
(1966) states that there must be an incompatibility between the manipulator’s desires
and the manipulated’s ones, Bowers (2003) claims that manipulation seeks to achieve
a desired goal without regard to the interests or needs of the manipulated agent. In
both cases, achieving the manipulator’s desires is the fundamental point associated
with manipulation. That is why social science considers the manipulation as a form of
intrumentalization, namely using somebody as a mean to achieve a goal.

2.1.4. Manipulation seen as the invisible exercise of a power

Interestingly, many researchers states manipulation is primarily an hidden inﬂu-
ence (de Saussure & Schulz, 2005; Handelman, 2009; Van Dijk, 2006; Ware, 1981).

6

For instance in clinical settings, manipulation is then associated with a patient’s ef-
forts (e.g. somatic complaints, provocative actions or misleading messages, and self-
destructive acts) to use covert means to gain control or support from signiﬁcant per-
sons (Gunderson, 1984). In linguistics, manipulation is a malevolant intention of the
speaker with a character of hidden inﬂuence (Akopova, 2013; Rigotti, 2005): a manip-
ulation is carried out when the addressee can no longer see the speaker’s intentions
behind what he or she is asserting. More generally, Handelman (2009) states the prac-
tical meaning of the manipulation is that the target is subject to a hidden inﬂuence
and believes that his or her choices are made freely and independently. The manip-
ulation is therefore intended to motivate the target to operate in a form that, under
normal conditions, would likely cause him or her to resist or reject the interaction.
That is why this inﬂuence must be above all indirect, invisible and secret in order to
take place. While this secrecy can simply mean the victim cannot use his deliberative
capabilities (Sunstein, 2015) to know or understand what is happening (Ware, 1981),
awareness is also considered: manipulation can be viewed as a form of control in which
the manipulated is not aware of what is happening or of the manipulator’s strategy
(de Saussure & Schulz, 2005; Van Dijk, 2006).

2.2. Towards a general deﬁnition of manipulation

However, although we have highlighted signiﬁcant diﬀerences among researchers, it
appears that there is agreement among them on certain points. Hence, we use these
commonalities to consider a general deﬁnition of manipulation. One of the main char-
acteristics of manipulation is that it is, on the one hand, the exercise of power over
others, and on the other hand, the exercise of a concealed power from the manipulated
agents.

Firstly, manipulation is a power which is distinct from the more general concept
of inﬂuence. While inﬂuence may be exerted in an unintentional way, manipulation is
ﬁrst and foremost a voluntary eﬀect of a manipulator to use the victim to accomplish
something (Akopova, 2013; Cohen, 2017; Handelman, 2009; Todd, 2013). Manipulation
is necessarily intentional, and the use of the concept of “unintentional manipulation”
is strongly rejected (Kligman & Culver, 1992). Indeed, we cannot call it manipulation
if the so-called manipulator did not deliberate about manipulating a victim. Thus,
an agent who unwittingly inﬂuences another agent without his knowledge cannot be
manipulating. That is why we consider in the sequel manipulation as an instrumen-
talization of a victim. Unlike inﬂuence, which can relate to beliefs, knowledge or even
intentions, instrumentalization is a deliberate inﬂuence on the eﬀects produced by a
victim whether those latters are deliberate or not.

Secondly, this instrumentalization is concealed from the victim. Manipulation can-
not simply be reduced to coercion and persuasion (Handelman, 2009; Kligman &
Culver, 1992; Sorlin, 2017) as it is something that happens completely invisibly, and
by the time we start talking about manipulation, the act has already been committed.
So, when we talk about manipulation, whether it is in the past tense or the second
person, we are deﬁnitely stating something that the victim did not know. So the in-
evitable conclusion is that the target is necessarily unable to identify that he was
subjected to a manipulative inﬂuence. The linguist Sandrine Sorlin claims that if one
can say “he tried to manipulate me but failed”, we cannot say “he manipulated me but
failed” (Sorlin, 2017). He insists on the fact that success is embedded in manipulation.
Manipulation implies the success of this enterprise.

7

Finally, manipulation is not similar to deception (Handelman, 2009; Kligman &
Culver, 1992; Sorlin, 2017). Indeed, deception may be related to lying which can be
one possible strategy to manipulate a victim. However not all manipulations are based
on lies: e.g. telling the truth may be also a way to manipulate and induce somebody
in the wrong way. That is why a manipulation should not be confused with its inner
strategy. To summarize, manipulation has three fundamental characteristics:

(1) it is a deliberate eﬀect of a manipulator (i.e. an applied strategy);
(2) it is an instrumentalization of a victim (i.e. an inﬂuence);
(3) it is always hidden from the victim (i.e. a concealment).

Consequently manipulation is an instrumentalization and it is concealed from the
target. Hence, by considering a synthesis of the deﬁnitions given in (Akopova, 2013;
Cohen, 2017; Handelman, 2009; Todd, 2013), we retain the following deﬁnition of
manipulation.

Deﬁnition 2.1. A manipulation is a deliberate eﬀect of an agent (called a ma-
nipulator ) to instrumentalize another agent (called a victim), while making sure to
conceal that eﬀect.

It is important to notice that this deﬁnition makes sense in Artiﬁcial Intelligence
literature, even in speciﬁc domains where manipulation has its own deﬁnition. In
order to support our claim let us consider three domains: game theory (Ettinger &
Jehiel, 2010), social choice theory (Gibbard, 1973) and reputation systems (Hoﬀman,
Zage, & Nita-Rotaru, 2009) where manipulation has been widely studied. Obvious
manipulation is not limited to those domains. The interested reader may refer to
Masters et al. (2021) to have other examples.

(1) Game theory deals with the strategic interactions between agents and is based
on the assumption they are rational, i.e. the agents always seek to maximize
their personal or collective reward function according to the decisions they can
make. In this setting, manipulation is just considered as a strategy: manipulators
must decide if they have an interest to manipulate while victims must decide if
they have an interest to not play an counter-manipulation strategy. A reﬁnement
of this notion has been proposed by Ettinger and Jehiel (2010): manipulation
is expressed through a Bayesian game on which the victims are associated to
cognitive types that describe how much they believe the other types of player
have a manipulation strategy, and how much they are able to distinguish the
strategies of the various types of their opponents. Here, manipulation is a de-
liberate strategy (a chosen action) with instrumentalization (the manipulator’s
utility depends on the victim’s strategy) and concealment (as the less the victim
is able to distinguish the manipulation strategy, the more interest there is to
manipulate).

(2) Social choice theory deals with collective decision making based on the agents’
preferences. Here, manipulation consists in as lying on our own preferences so as
to obtain an outcome in our favor (Gibbard, 1973). Thus, it reduces manipula-
tion as a particular strategy in which an agent is deliberately not sincere about
its real preference proﬁle. However, it also implies instrumentalization and con-
cealment. Social choice theory deals with agents seeking for collective decisions.
A manipulator lies (its deliberate strategy) and pushes other agents to make a
given collective decision (it is an intrumentalization). Concealment results from

8

the fact that, to be eﬀective, other agents must not be aware (or knowledgeable)
of that strategy because, if it was the case, rational agents may adapt their be-
haviors to make the manipulation fail if it is in their interest (for instance by
removing the manipulator from the decision process).

(3) Reputation systems are systems where agents interact, collect, share, and
aggregate the results of their past interactions to decide where they should be
agents they can trust for future interactions. In this setting, manipulation con-
sists in either lying on his identity (to avoid to accumulate bad evaluations),
producing wrong evaluation (to increase or reduce another agent’s reputation),
interacting in order to blur the other agents (so they produce wrong evalua-
tions), or do not collecting or sharing some messages in order to isolate another
agent (Hoﬀman, Zage, & Nita-Rotaru, 2009). As for the social choice theory,
manipulation is here a deliberate strategy. Instrumentalization comes from the
fact the manipulation wants to push the other agents to interact with him, or
to forbid some agents to interact with the others. Finally, concealment comes
from the fact that, if the other agents were aware or knew the manipulation,
they should be able to isolate the manipulator.

While manipulation has been studied in multi-agent systems as a particular strategy
or action e.g. in game theory or social choice theory as we showed, in this article we
adopt a general position in regard to what is a manipulation in a multi-agent system
by considering the deﬁnition 2.1. This deﬁnition makes clear the distinction with other
related concepts such as e.g. coercion which is the instrumentalization of somebody by
making him seeing a threat (thus without concealment) (McCloskey, 1980), persuasion
which is the deliberate eﬀect of changing beliefs (O’Keefe, 2015), lying which is the
intention to induce a contrary beliefs from ours (Mahon, 2008), and so on. These
concepts have been studied and disambiguated in the ﬁeld of logic in multi-agent
systems. Thus, in the next section, we provide a survey about related works in logic
that are interested in deﬁning such notions and how these formalisms can help us in
deﬁning manipulation.

3. Formalizing manipulation

From a general point-of-view, modal logics allow us to explicitly describe notions of
intention, belief and knowledge that are fundamental to manipulations. Several logi-
cal approaches have already studied similar notions such as social inﬂuence (Bottazzi
& Troquard, 2015; Lorini & Sartor, 2016; Santos & Carmo, 1996), lying and decep-
tion (Sakama et al., 2015; Van Ditmarsch et al., 2012). In this section, since manipu-
lation is a deliberate instrumentalization with concealment, we survey related works
in literature about how to represent concealment (van der Hoek, Iliev, & Wooldridge,
2012) and deliberate eﬀects (Broersen, 2008). First, we present works related on mod-
eling of lies and dishonesty. In a second step, since manipulation is a deliberate eﬀect
to instrumentalize, we review logics that have been interested in representing inﬂuence
and deliberate eﬀects. Finally, we present works on modeling awareness.

3.1. Representing dishonesty, deception and lies

Those three related concepts has been modeled by (Bonnet, Leturc, Lorini, & Sartor,
2021; Sakama et al., 2015; Van Ditmarsch et al., 2012). All those approaches are based

9

of the fact that an agent i informs another agent j about something so that j believes
it while the agent i believes the opposite. For instance, Sakama et al. (2015) use modal
logic and introduces a modality of communication between two agents, a modality of
belief as well as a modality of intention to describe concepts such as lying, churning,
concealment or deception. Bonnet et al. (2021) deﬁne persuasion as a deliberate action
through which a persuader changes the beliefs of a persuadee, and deﬁne deception
as persuading the persuadee of something under the assumption that the persuader
believes that it is false. ﬁnally, Van Ditmarsch et al. (2012) uses dynamic doxastic
logics with a modality to describe the action of private advertisements that is used to
describe lying.

3.1.1. A theory of dishonesty

Sakama et al. (2015) deﬁne a logical theory of dishonesty in which they characterize
notions of lying, bullshitting, concealment of information, deception, and half-truth.
To formally describe these notions, they consider a formalism called BIC in which
they considers for any agent i, j ∈ N , modalities of beliefs Bi, intentions Ii and
communications, noted Ci,j, from an agent i to another agent j. While Mahon (2008)
ﬁrst deﬁnes lying as making another person believe a false statement with the intent
that the statement to be believed to be true by the other person, Sakama et al. (2015)
take up this deﬁnition and deﬁne a simple lie with the predicate:

SimpleLiei,j(ϕ)

(cid:52)
= Ci,jϕ ∧ Bi¬ϕ ∧ IiBjϕ

However, Mahon (2008) also considers that lying to another person can be deﬁned
as the intention to make the intention to make the addressee believe that the statement
is believed to be true by the speaker. Thus, Sakama et al. (2015) describe lying as:

Lie∗

i,j(ϕ)

(cid:52)
= SimpleLiei,j(ϕ) ∨ (Ci,jϕ ∧ Bi¬ϕ ∧ IiBjBiϕ)

To this notion of lying, Sakama et al. (2015) add the notion of lying by objective
when the agent i lying intends to make his addressee believe a proposition ϕ by
deduction. Here, the liar then lies about a statement that he does not believe σ, but
believes that the statement will lead the other person to believe ϕ. This notion is then
described by the predicate:

O − Lie∗

i,j(σ, ϕ)

(cid:52)
= IiBjϕ ∧ ¬BiBjϕ ∧ BiBj(σ ⇒ ϕ) ∧ Bi¬σ ∧ Ci,jσ

Other notions are characterized as “bullshitting”, which describes the action of
communicating information that is not the case whether the agent communicating i
believes ϕ and believes the opposite ¬ϕ, i.e. the predicate:

BSi,j(ϕ)

(cid:52)
= Ci,jϕ ∧ ¬Biϕ ∧ ¬Bi¬ϕ

They also characterize withholding information as the fact that an agent i intends

not to reveal information ϕ that i believes to be true, that is:

W Ii,j(ϕ)

(cid:52)
= ¬Ci,jϕ ∧ Biϕ ∧ Ii¬Bjϕ

10

Finally, the notion of half-truth consists in giving information that we believe to be
true in order to mislead the other person by playing on an error of reasoning in the
addressee. It is formally described by:

HTi,j(ϕ, ψ)

(cid:52)
= (Ci,jϕ ∧ Biϕ ∧ IiBjϕ) ∧ ¬BiBjψ

∧ BiBj(ϕ ⇒ ψ) ∧ Bi¬ψ ∧ ¬Ci,j¬ψ ∧ IiBjψ

The part of this predicate (Ci,jϕ ∧ Biϕ ∧ IiBjϕ) is called the intentional sincerity.
So, in their system, they show, for example, that lying about a proposition ϕ while
intending to be sincere is impossible and deduce the theorem (Ci,jϕ ∧ Biϕ ∧ IiBjϕ) ∧
LieB

i,j(ϕ) ⇒ ⊥.

3.1.2. A theory of persuasion and deception

Bonnet et al. (2021) model notions such as inﬂuence, persuasion, deception and their
logical relations. To do that they extend a propositional dynamic logic to a STIT
logic and express a ex post knowledge Kpost
which characterizes an agent’s knowledge
assuming that the agent has made his decision about which action to take, but might
still be uncertain about the decisions of others. Here, a deliberate STIT [{i}:dstit] is
deﬁned as seeing to it that something is true, which is not necessary true in the other
worlds in a current moment. There is also a temporal operator ‘next’ X deﬁned as the
applied joint action in the current world and a belief modality Bj. In their approach,
persuasion is deﬁned as a deliberate action through which an agent (persuader) changes
the beliefs of another agent’s (persuadee):

i

Persuades(i, j, ϕ)

(cid:52)
= Kpost
i

[{i}:dstit]XBjϕ

Based on this notion, they deﬁne deception as a persuasion in a proposition ϕ under

the assumption that the persuader believes that ϕ is false.

Deceives(i, j, ϕ)

(cid:52)
= Persuades(i, j, ϕ) ∧ BiX¬ϕ

Here, truthfully telling is simply captured by persuasion, while deception always in-
volves not telling the truth. This notion of deception is then reﬁned to express more
subtle notions, such as smooth-talking (persuading since the persuader is uncertain
whether ϕ is true or false) which is equivalent to Sakama et al. (2015)’s “bullshitting”.

PersuadesBySmoothTalking(i, j, ϕ)

(cid:52)
= Persuades(i, j, ϕ)

∧ ¬Kpost

i X¬ϕ ∧ ¬Kpost

i ¬X¬ϕ

Finally, Bonnet et al. (2021) distinguish benevolent, malevolent and reckless decep-
tion, which diﬀer in how persuading an agent j of something is good for j (or not). In
the malevolent form, the deceiver believes that believing ϕ will have bad consequences
for the deceived. On the contrary, in a benevolent deception the deceiver believes that
believing ϕ is good for the deceived. Finally, reckless deception consists for the deceiver
to not know whether that ϕ is good or bad for the deceived.

11

MalevolentDeception(i, j, ϕ)

BenevolentDeception(i, j, ϕ)

RecklessDeception(i, j, ϕ)

(cid:52)
= Deceives(i, j, ϕ) ∧ BiX(Bjϕ → badj)
(cid:52)
= Deceives(i, j, ϕ) ∧ BiX(Bjϕ → goodj)
(cid:52)
= Deceives(i, j, ϕ) ∧ ¬Kpost

i X(Bjϕ → goodj)

∧ ¬Kpost

i X(Bjϕ → badj)

3.1.3. A dynamic logic of lying

While Bonnet et al. (2021) and Sakama et al. (2015) consider predicates to express
lying, deception, or persuasion, another approach Van Ditmarsch et al. (2012) gets
rid of representing those notions through predicates. Instead, they consider lying as a
public announcement which is false, and they use a dynamic doxastic logic to describe
the eﬀects of lying through the semantics of the logical system. In this work, they
consider a language Lll generated by the following BNF:

ϕ ::= p|(ϕ1 ∧ ϕ2)|¬ϕ|(cid:62)|⊥|Biϕ|[‡ϕ1]ϕ2|[!ϕ1]ϕ2|[¡ϕ1]ϕ2

In this language, they consider a set of modal operators and public announcement

operators as:

• Biϕ means the agent i believes that ϕ is true,
• [!ϕ]ψ means that ψ is true after the public announcement of ϕ,
• [¡ϕ]ψ means that ψ is true after the lie ϕ,
• [‡ϕ]ψ means that ψ is true after the public announcement of ϕ but also true

after the lie ϕ.

Figure 1. Event-driven model of the logic of lying (Van Ditmarsch et al., 2012)

To interpret

these operators

they ﬁrst consider a doxastic model M =
(W, {Bi}i∈N , V ) with {Bi}i∈N a set of serial, transitive and euclidean relations. Sec-
ondly they deﬁne an action model Ap = (W α, {Bα
i }i∈N , I α, P α) with I α : W α → Lll
the precondition function and P α : W α → SubLll a function called postcondition func-
tion which assigns to each possible event a substitution which represents the eﬀects
of actions on variables. If A(Lll) = {p1, . . . , pn} is the set of propositional variables of
Lll, elements of SubLll are represented by:

{p1 (cid:55)→ σ1, . . . , pn (cid:55)→ σn|σ1, . . . , σn ∈ Lll}

The action model they use is described by Figure 1 which expresses the eﬀects of
actions, here public announcements. For instance the event 1 : p represents the public
announcement of p where p is true while 0 : ¬p represents the possible event when it
is a lie i.e. p is announced while p is false. Furthermore let us notice that p can be

12

substituted for any formula ϕ which means that public announcement are not necessary
related to atomic propositions. Then, to deﬁne the eﬀect of public announcement
on the beliefs of the agents, this is given by a standard product update deﬁned as
(M, U ) ⊗ (A, S) = ((W ⊗, {B⊗

i }i∈N , V ⊗), U ⊗) where U ⊆ W, S ⊆ W α and:

• W ⊗ = {(v, f ) ∈ W × W α : M, v |= I α(f )}
• ∀(v, f ) ∈ W ⊗, ∀i ∈ N , B⊗
• ∀(v, f ) ∈ W ⊗ : V ⊗(v, f ) = {p ∈ A(LB)|M, w |= P (s)(p)}
• U ⊗ := {(v, f )|v ∈ U, f ∈ S, (v, f ) ∈ W ⊗}

i (v, f ) = {(u, g) ∈ W ⊗ : u ∈ Bi(v), g ∈ Bα

i (f )}

Finally, the semantics of the operators of Lll is given by:

• M, w |= Biϕ iﬀ ∀v ∈ W : wBiv, M, v |= ϕ
• M, w |= [!ϕ]ψ iﬀ (M, {w}) ⊗ (Aϕ, {1}), (w, 1) |= ψ
• M, w |= [¡ϕ]ψ iﬀ (M, {w}) ⊗ (Aϕ, {0}), (w, 0) |= ψ
• M, w |= [‡ϕ]ψ iﬀ (M, {w}) ⊗ (Aϕ, {0, 1}), (w, 0) |= ψ

and (M, {w}) ⊗ (Aϕ, {0, 1}), (w, 1) |= ψ

This semantics then gives the axiomatic system summarized in Figure 2, the manip-
ulative announcement is then described as [‡ϕ]ψ and by Ax0, [‡ϕ]ψ ⇔ [!ϕ]ψ ∧ [¡ϕ]ψ.
The rule A1 describes that if a public announcement ϕ brings the consequence p, then
if ϕ is true, then necessarily p is true and vice versa. The formula [!ϕ]p ⇔ ϕ ⇒ p is
then a tautology of the system.

(cid:96) ϕ, for all PC theorems ϕ

(CP)
(Ax0) (cid:96) [‡ϕ]ψ ⇔ [!ϕ]ψ ∧ [¡ϕ]ψ
(cid:96) [!ϕ]p ⇔ ϕ ⇒ p
(A1)
(cid:96) [!ϕ]¬ψ ⇔ ϕ ⇒ ¬[!ϕ]ψ
(A2)
(cid:96) [!ϕ](ψ1 ∧ ψ2) ⇔ [!ϕ]ψ1 ∧ [!ϕ]ψ2
(A3)
(cid:96) [!ϕ]Biψ ⇔ ϕ ⇒ Bi[!ϕ]ψ
(A4)
(cid:96) [¡ϕ]p ⇔ ¬ϕ ⇒ p
(L1)
(cid:96) [¡ϕ]¬ψ ⇔ ¬ϕ ⇒ [¡ϕ]ψ
(L2)
(cid:96) [¡ϕ](ψ1 ∧ ψ2) ⇔ [¡ϕ]ψ1 ∧ [¡ϕ]ψ2
(L3)
(cid:96) [¡ϕ]Biψ ⇔ ¬ϕ ⇒ Bi[¡ϕ]ψ
(L4)

Figure 2. Simpliﬁed axiomatic system of Van Ditmarsch et al. (2012)

Let us notice that other works using dynamic logic to model lying or deceiving exist.
For instance, Sakama (2021) recently extends his previous work (Sakama et al., 2015)
and proposes to model deception with a doxastic dynamic semantics.

3.2. Representing the eﬀects of actions

As manipulation is a deliberate eﬀect in order to instrumentalize an agent, it is of
interest to reason on actions, their intended consequences, their side-eﬀects, and how
they can inﬂuence the other agents. Many formalisms exist. For instance, dynamic log-
ics (Harel, Kozen, & Tiuryn, 2001) and temporal logics (Alur, Henzinger, & Kupfer-
man, 2002) consider several action modalities where each action modality is associated
with a program and its outputs. Dynamic epistemic logics express the logical conse-
quences generated by public or private announcements of agents (Van Ditmarsch, Van
Der Hoek, & Kooi, 2007). Many other formalisms exist such as ﬂuent calculus. For a

13

detailed survey, the interested reader may refer to (Segerberg, Meyer, & Kracht, 2009).
Interestingly, (Giordano, Martelli, & Schwind, 2000) propose a formalism that catches
all ramiﬁcation eﬀects of actions i.e. all direct consequences and side-eﬀects of actions.
However such formalism introduces a distinct modality for each possible action, while
we saw in Table 1 that manipulation does not depend on particular actions or strate-
gies (e.g. lying, rumor propagating, emotional blackmailing) but rather on its results.
Thus, it is of interest to consider action logics which only represent abstract strategies
that lead to a state-of-aﬀair. Two approaches seem relevant: the STIT logics (Bal-
biani, Herzig, & Troquard, 2008; Belnap & Perloﬀ, 1988; Lorini & Sartor, 2016) and
the BIAT logics (P¨orn, 1977; Santos & Carmo, 1996; Troquard, 2014), which both
consider, in an abstract way, the fact of ensuring that something is done.

Both STIT and BIAT logics consider actions as the fruit of their consequences. This
level of abstraction is well-adapted to deﬁne manipulation. BIAT considers a modality
Ei which means that the agent i brings it about. Let us notice it is side-eﬀects free,
i.e. indirect consequences of actions are not considered as intended eﬀects. For its
part, STIT considers a modality [ST IT ]i which means that the agent i sees to it
that and catches all consequences of actions. Although these two approaches are often
confused, the main diﬀerence between these two formalisms lies in the semantics of
these modalities. STIT considers a S5 system1 whereas BIAT is a non normal system
based on neighborhood functions. Furthermore, STIT uses a notion of temporality
while BIAT does not.

3.2.1. Representing inﬂuence

In the literature about STIT, some approaches already deﬁned a notion of inﬂuence.
Here, inﬂuence consists in seeing to it that another agent will see to it that something
becomes true. For instance, Lorini and Sartor (2016) deﬁne the fact that agent i
inﬂuences agent j on ϕ if, and only if, agent i sees to it that in the future, agent j
rationally sees to it that ϕ, i.e.:

[inf l]i,jϕ

(cid:52)
= [stit]iX[rstit]jϕ

where [rstit] is a primitive modal operator which represents the current choice as a
rational choice. For its part, BIAT logics deﬁne inﬂuence similarly as the eﬀect of an
agent i to bring it about that another agent j brings about something. For instance,
Bottazzi and Troquard (2015) considers the following predicate to deﬁne inﬂuence
which is called interpersonal control :

[inf l]i,jϕ

(cid:52)
= Ei(Ejϕ ∧ ψ)

The modality Ei (resp. Ej) refers to a non-normal modality which means that agent
i (resp. agent j) brings it about something. The formula ψ represents any formula of the
language that does not contradict Ejϕ. This ψ is explicitly included in the deﬁnition
of the predicate of inﬂuence because of the semantics which does not allow us to have
the property of normal logics (cid:3)(ϕ ∧ ψ) ≡ (cid:3)ϕ ∧ (cid:3)ψ. If inﬂuence is deﬁned only as
EiEjϕ and if a formula Ei(Ejϕ ∧ ψ) is veriﬁed with ψ (cid:54)= (cid:62), then since we do not have
the property of normal logics, we could not be able to deduce the inﬂuence EiEjϕ

1A S5 system for a (cid:3) modality is a system where the axioms: (K) (cid:3)(ϕ ⇒ ψ) ⇒ ((cid:3)ϕ ⇒ (cid:3)ψ), (T ) (cid:3)ϕ ⇒ ϕ,
(4) ¬(cid:3)ϕ ⇒ (cid:3)¬(cid:3)ϕ and (5) (cid:3)ϕ ⇒ (cid:3)(cid:3)ϕ are considered.

14

from Ei(Ejϕ ∧ ψ).

3.2.2. Representing deliberate eﬀects

While STIT approaches deﬁne inﬂuence, they also deﬁne a notion of deliberate eﬀect.
Lorini and Sartor (2016) deﬁne deliberate eﬀect by considering that something is done
deliberately by another agent i if, and only if, i sees to it that something is true while
it is not necessarily the case, that is to say:

[dstit]iϕ

(cid:52)
= [stit]iϕ ∧ ¬(cid:3)ϕ

However, this deﬁnition is not without problems. Let us imagine a situation in
which one agent i deliberately causes a car crash to take advantage of car insurance.
But during this car crash, a person died. By following the formal deﬁnition of Lorini
and Sartor (2016)’s deliberate STIT, we would deduce that the agent i deliberately
sees to it that “the car is crashed” but also, all indirect consequences as “a person is
dead”. Consequently by following STIT reasoning and since it was not necessarily the
case (if the agent did not choose to cause this accident) that the person is dead, we
would also deduce that i deliberately sees to it that “the person is dead”. However
we claim the opposite. Even if the agent i deliberately caused this car accident, he
did not deliberately kill the victim. Furthermore a deliberate eﬀect must be known by
the agent. Indeed when we deliberately do or do not something, then we know what
we are doing. Because they use standard STIT, Lorini and Sartor (2016) do not and
cannot consider positive and negative introspection on knowledge. Let us notice that
Broersen (2008) integrates a knowledge modality into the STIT language and deﬁnes
a deliberate see to it such as:

[dxstit]iϕ

(cid:52)
= Ki[xstit]iϕ ∧ Ki¬(cid:3)Xϕ

Here, [xstit]iϕ denotes that in the future, agent i sees to it that ϕ. Broersen (2008)’s
deliberate STIT has the positive and negative introspection with knowledge. Further-
more it has also the side-eﬀect free property since a consequence may not be known
by the agent to consider it as a deliberate eﬀect. A third important property that
deliberate eﬀects has to be veriﬁed which is the conjunction of all deliberate eﬀects
forms a deliberate eﬀect. This property means that if agent i deliberately sees to it
that ϕ and also deliberate sees to it that ψ, then he deliberately sees to it that ϕ ∧ ψ;
and Broersen (2008)’s deliberate STIT has this property.

Concerning BIAT, as written previously, it explicitly deﬁnes a deliberate eﬀect

modality and it is side-eﬀects free.

3.3. Representing revelation, concealment and awareness

Lastly, we have seen that manipulation needs to conceal its eﬀects. In the literature,
this notion of concealment can be expressed either in terms of an agent’s knowledge, or
in terms of his level of awareness. In this section, we highlight some logical approaches
that have represented those notions.

15

3.3.1. A logic of revelation and concealment

To the best of our knowledge, only van der Hoek et al. (2012) proposed a logic for
representing revelation and concealment as a Propositional Dynamic Logic (PDL).
They considered particular actions for revelation and concealment, denoted (resp) by
r(p, i) and c(p, i). The formula [r(p, i)]ϕ means that after revealing the value of p to
an agent i, the formula ϕ is true, while [c(p, i)]ϕ means that after concealing the value
of p to an agent i, the formula ϕ is true. These modalities are described in a PDL
logical frame. They combined to action a standard S5 epistemic operator Ki with a
Kripke relationship.

Their formalism makes possible to express and deduce interesting valid formulas as
if a proposition p is true, then after revealing p to one agent i, then this agent will
know that p is true i.e.:

p ⇒ [r(p, i)]Kip

In the same way, this formalism provides other valid formulas which combine eﬀects
of actions on the knowledge of agents. For instance, they can express a validity as e.g.
if after doing an action α, the variable p is true, then if we reveal p to one agent i and
then do α, then i will know that p is true:

[α]p ⇒ [r(p, i); α]Kip

In their logical framework, they are able to express interesting validities related
to that action of concealment as e.g. after concealing to agent i the value of p it is
possible that after some execution of one action α, ϕ is true, is equivalent to, after
some execution of α and, after concealing to agent i the value of p, makes ϕ true, i.e.:

(cid:104)c(p, i)(cid:105)(cid:104)α(cid:105)ϕ ⇔ (cid:104)α(cid:105)(cid:104)c(p, i)(cid:105)ϕ

3.3.2. Representing awareness

Contrary to concealment, many works have taken an interest in formally representing
the semantics of being aware of (Hill, 2010; Modica & Rustichini, 1994; Schipper, 2014;
Van Ditmarsch, French, Vel´azquez-Quesada, & W´ang, 2018).

Fagin and Halpern (1987) consider Levesque’s logic on implicit and explicit knowl-
edge to model a logic of non-omniscience (Levesque, 1984). Modica and Rustichini
(1994) consider that an agent i ∈ N is aware of something, denoted Aiϕ, if, and only
if, that agent knows ϕ or it is not the case it knows ϕ and it knows that it is not the
case it knows ϕ, i.e. checks the predicate Aiϕ := Kiϕ ∨ (¬Kiϕ ∧ Ki¬Kiϕ) where Ki is
a knowledge modality. If Ki is associated with a modal system S5, then the previous
deﬁnition of consciousness becomes equivalent to Aiϕ := Kiϕ ∨ Ki¬Kiϕ.

While previous mentioned approaches use knowledge or belief operators semanti-
cally deﬁned by a Kripke relationship to deﬁne awareness, Schipper (2014) proposes
to model awareness semantically with a function Ai : W → 2L that maps from a
possible world, the set of formulas that agent i is aware of. It deﬁnes a modal lan-
guage L in which a modality Li refers to the implicit knowledge of an agent i, and a
modality Aiϕ expresses the awareness of an agent i on a proposition ϕ. The semantics
of this modality Ai is deﬁned with a function Ai : W → 2L. This function is called
Awareness Correspondence. Thus, an agent i is aware of a proposition ϕ if, and only
if, this formula ϕ belongs to a set of formulas given by this correspondence function.

16

Ai : W → 2L associates for a given world, all the formulas that a i agent is aware
(cid:52)
of. Knowledge is then deﬁned by the predicate Kiϕ
= Liϕ ∧ Aiϕ. In this formalism,
a model is a tuple, M = (W, {Ri}i∈N , {Ai}i∈N , V ) such that (W, {Ri}i∈N , V ) is a
Kripke frame where {Ri}i∈N is a set of equivalence relations associated to the seman-
tics of Li for each agent i ∈ N . To deﬁne the correspondence function Ai, it is then
necessary to use a function that returns the set of atomic propositions of a formula,
this function At is such that:

• At((cid:62)) = ∅
• At(p) = {p} if p is an atom of L
• At(¬ϕ) = At(ϕ)
• At(ϕ ∧ ψ) = At(ϕ) ∪ At(ψ)
• At(Kiϕ) = At(ϕ)
• At(Aiϕ) = At(ϕ)

So, for each agent i ∈ N and all possible worlds w ∈ W, the correspondence function

is such that:

(1) ϕ ∈ Ai(w) if, and only if, At(ϕ) ⊆ Ai(w)
(2) ∀v ∈ W : wRiv ⇒ Ai(w) = Ai(v)

Property 1 means that, for an agent i to be aware of a formula ϕ, it is necessary for
that agent to be aware of all the propositional atoms contained in a formula. Property
2 corresponds to the fact that an agent knows what it is aware of. Finally, a pattern is
deﬁned in a standard way. We have, for every agent i ∈ N and for each world w ∈ W,
the following semantics:

• M, w |= Liϕ iﬀ ∀v ∈ W, wRiv : M, v |= ϕ
• M, w |= Aiϕ iﬀ ϕ ∈ Ai(w)
• M, w |= Kiϕ iﬀ M, w |= Liϕ and M, w |= Aiϕ

This semantics then gives us the axiomatic system of the ﬁgure 3. An immediate
theorem of consciousness is that if an agent i knows that something is true then
necessarily this agent i is aware of that something. Indeed:

• (cid:96) Kiϕ ⇔ Liϕ ∧ Aiϕ
• (cid:96) Liϕ ∧ Aiϕ ⇒ Aiϕ
• (cid:96) Kiϕ ⇒ Aiϕ

Finally, all these works have been extended in Van Ditmarsch et al. (2018) where
they deﬁne a logic of speculative knowledge allowing to reason about the notion of non
awareness, based on the logic of implicit and explicit knowledge of Fagin and Halpern
(1987) and the logic of consciousness of Schipper (2014). This notion of speculative
knowledge is distinct from that of implicit knowledge and explicit knowledge. It trans-
lates that an agent has speculative knowledge of a proposition ϕ in a model M and a
world w if this formula is veriﬁed in all accessible worlds in all pointed models of the
framework that are Ai(w)-bisimilar2 to the world w.

2A bisimulation is a relation between two models in which related states have identical atomic information
and matching transition possibilities (Blackburn, De Rijke, & Venema, 2002).

17

(CP)
(KL)

(cid:96) ϕ, for all PC theorems ϕ
(cid:96) Kiϕ ⇔ Liϕ ∧ Aiϕ

(S5(Li)) (cid:96) ϕ, for all theorems ϕ of S5 associated with Li

(AS)
(AC)
(AKR)
(AR)
(ALR)
(UL)
(MP)
(Nec)

(cid:96) Aiϕ ⇔ Ai¬ϕ
(cid:96) Ai(ϕ ∧ ψ) ⇔ Aiϕ ∧ Aiψ
(cid:96) Aiϕ ⇔ AiKiϕ
(cid:96) Aiϕ ⇔ AiAiϕ
(cid:96) Aiϕ ⇔ AiLiϕ
(cid:96) ¬Aiϕ ⇔ Li¬Aiϕ
If (cid:96) ϕ ⇒ ψ and (cid:96) ϕ then (cid:96) ψ
If (cid:96) ϕ then (cid:96) Liϕ

Figure 3. Axiomatic system of the logic of awareness (Schipper, 2014)

4. A modal logic for manipulation

In this section, we propose a logic to represent the notion of manipulation as it has
been deﬁned in Section 2.1. Let us remark our goal is not to propose a deﬁnitive logic
but rather to provide the basic elements to express such deﬁnition and disambiguate
this concept.

To this end, we consider a logic with several modalities: deliberate eﬀects, conse-
quences of actions, belief and knowledge. One of the main element of this logic is
the deliberate eﬀect operator. Indeed, we require that this operator must have: (1)
negative and positive introspection; (2) side-eﬀect free; (3) the conjunction of all de-
liberate eﬀects forms a deliberate eﬀect. As written previously, STIT semantic catches
all (direct and indirect) consequences of actions while BIAT semantics catches the
deliberate eﬀects. Moreover, since BIAT is side-eﬀect free and makes it easy to express
positive and negative introspection and also the conjunction of all deliberate eﬀects
forms a deliberate eﬀect, we distinguish a modality of deliberate eﬀects (expressed
by a BIAT-like modality denoted Ed
in the sequel) from a modality that catches all
i
consequences of performed actions (expressed by a STIT-like modality denoted Ei in
the sequel). Thanks to these modalities, combined with knowledge and belief, we are
able to express instrumentalization and concealment. Furthermore distinguishing an
epistemic modal operator from a belief operator allows us to deﬁne diﬀerent levels of
concealment. Then, we chose to not introduce an awareness operator explicitly in the
language and prefer to keep the logic simple. Finally, we also do not want the modality
of future which increases the complexity of the model.

4.1. Language

Let P = {a, b, c, . . .} be a set of propositional letters, N be a ﬁnite set of agents with
two agents i, j ∈ N , and p ∈ P be a propositional variable. We deﬁne LKBE the
language with the following BNF grammar rule:

ϕ ::= p | ¬ϕ | (ϕ ∨ ϕ) | (ϕ ∧ ϕ) | (ϕ ⇒ ϕ) | Kiϕ | Biϕ | Eiϕ | Ed

i ϕ

The formula Eiϕ means that the actions of i lead to ϕ. So Ei represents the eﬀects of
i ϕ

actions which may have been deliberated or not such as side-eﬀects. The formula Ed

18

means3 that agent i deliberately brings it about that ϕ. This modality is semantically
represented with a neighborhood function which associates a set of possible worlds for
each deliberate eﬀect. Finally the formulas Kiϕ and Biϕ mean respectively that the
agent knows that ϕ, and the agent believes that ϕ. We note the dual operators as
following: (cid:104)Ki(cid:105)ϕ = ¬Ki¬ϕ, (cid:104)Bi(cid:105)ϕ = ¬Bi¬ϕ, (cid:104)Ei(cid:105)ϕ = ¬Ei¬ϕ and (cid:104)Ed

i (cid:105)ϕ = ¬Ed

i ¬ϕ.

4.2. Associated semantics

We consider the following logical frame:

C = (W, {Bi}i∈N , {Ki}i∈N , {Ei}i∈N , {E d

i }i∈N )

where W is a nonempty set of possible worlds, {Bi}i∈N , {Ki}i∈N , {Ei}i∈N are sets of
binary relationships, and {E d

i }i∈N is a set of neighborhood functions, i.e.:

∀i ∈ N , E d

i : W → 22W

The reasons why we consider neighborhood functions for the deliberate brings it
about semantics are twofold. Firstly, neighborhood semantics allow us to be free from
the necessitation since we do not want to express that the agent deliberately brings
it about a tautology. Secondly, the neighborhood functions translate semantically sets
of possible worlds that results from strategies deliberated by the agent. In this case,
each set of possible worlds corresponds to the deliberate eﬀects of those strategies.

We deﬁne a model as M = (W, {Bi}i∈N , {Ki}i∈N , {Ei}i∈N , {E d

i }i∈N , V ) with
V : P → 2W an interpretation function. For all w ∈ W, ϕ, ψ ∈ LKBE, and p ∈ P, we
inductively deﬁne M, w |= ϕ as:

(1) M, w |= (cid:62)
(2) M, w (cid:54)|= ⊥
(3) M, w |= p iﬀ w ∈ V (p)
(4) M, w |= ¬ϕ iﬀ M, w (cid:54)|= ϕ
(5) M, w |= ϕ ∨ ψ iﬀ M, w |= ϕ or M, w |= ψ
(6) M, w |= ϕ ∧ ψ iﬀ M, w |= ϕ and M, w |= ψ
(7) M, w |= ϕ ⇒ ψ iﬀ M, w |= ¬ϕ or M, w |= ψ
(8) M, w |= Biϕ iﬀ ∀v ∈ W, wBiv : M, v |= ϕ
(9) M, w |= Kiϕ iﬀ ∀v ∈ W, wKiv : M, v |= ϕ
(10) M, w |= Eiϕ iﬀ ∀v ∈ W, wEiv : M, v |= ϕ
i ϕ iﬀ ||ϕ|| ∈ E d
(11) M, w |= Ed

i (w) with ||ϕ|| := {v ∈ W : M, v |= ϕ}

Let us detail the diﬀerence between rule (10) and rule (11). We do not want to
express that an agent deliberately brings it about a tautology. Thus, since the rule
(11) is deﬁned on a neighborhood function, it allows Ed
i to be freed from necessitation,
while since the rule (10) characterizes a normal modality, the necessitation holds.

We also consider a dual notion of deliberate eﬀects, denoted (cid:104)Ed

i (cid:105), which translates
“it is possible that one agent deliberately brings it about something as he does not
deliberately brings it about the contrary”. Formally, we write M, w |= (cid:104)Ed
i (cid:105)ϕ if, and
only if, W \ ||ϕ|| (cid:54)∈ E d

i (w), with ||ϕ|| := {v ∈ W : M, v |= ϕ}.

Finally, let us remind that ϕ is valid in M (written M |= ϕ) if, and only if, for all
worlds w ∈ W, ϕ is satisﬁable in w, i.e. M, w |= ϕ is true. A formula ϕ is valid in a

3We also accept the expressions “ϕ is a deliberate eﬀect of agent i” or “agent i deliberately sees to it that ϕ”.

19

frame C (written |=C ϕ or C |= ϕ) if, and only if, for all models M built on C, M |= ϕ.
In this case ϕ is a tautology of C, written |=C ϕ.

4.2.1. Semantics for beliefs and knowledge

For the modalities of knowledge and belief, we conventionally constrain our frame C
so that, for any agent i ∈ N , Ki is reﬂexive, transitive and conﬂuent 4 and Bi is serial,
transitive and Euclidean. The constraints and relations between these two modalities
have already been well studied (Stalnaker, 2006). Thus, we ﬁrst consider that an agent
i believes what it knows, namely:

∀w ∈ W : Bi(w) ⊆ Ki(w)

(KB1)

If an agent believes something then it knows it believes it:

∀w, u, v ∈ W : wKiu ∧ uBiv ⇒ wBiv

(KB2)

In the same way, an agent knows what it does not believe:

∀w, u, v ∈ W : wKiu ∧ wBiv ⇒ uBiv

(KB3)

4.2.2. Semantics for the eﬀects of actions

It is commonly accepted to consider the eﬀects of action as an equivalence relation-
ships, such as in STIT. Thus, for any agent i ∈ N , Ei is a reﬂexive, transitive and
Euclidean relationship5. Indeed, when an agent implements one or more actions, if he
has carried them out, it means that this is the case and that the consequence ϕ is
true. The reﬂexivity, denoted (E1), expresses the fact that once the actions leading to
a certain ϕ consequence have been performed by an agent i, then that consequence ϕ
is necessarily true in the current world. This constraint (E1) gives the axiom T.

∀w ∈ W : wEiw (E1)

From this constraint, we immediately deduce that this relation Ei is also serial.
This translates that if an agent i ensures that one or several actions lead to a certain
consequence ϕ, it is not the case that this action or series of actions can lead to the
opposite in the current world. So we deduce in such a system the property D. The
relation Ei is also transitive since when the actions of agent i lead to ϕ, these actions
also lead to the fact that these actions are done properly, i.e.:

∀w, u, v ∈ W : wEiu ∧ uEiv ⇒ wEiv

(E2)

4A binary relation R on W is conﬂuent if, and only if, the following property is satisﬁed ∀w, u, v ∈ W, wRu ∧
wRv → ∃z ∈ W : uRz ∧ vRz. Here we do not consider a S5 system with negative introspection but a S4.2
system. A S4.2 system is a S4 system – a system with the axioms for a (cid:3) modality (K) (cid:3)(ϕ ⇒ ψ) ⇒ (cid:3)ϕ ⇒ (cid:3)ψ,
(T ) (cid:3)ϕ ⇒ ϕ, and (4) ¬(cid:3)ϕ ⇒ (cid:3)¬(cid:3)ϕ – with a 4.2 axiom, ie. ♦(cid:3)ϕ ⇒ (cid:3)♦ϕ. The main reason is that since we
would like to model also human agents’ reasoning, we cannot accept that humans know everything they do not
know. For more details, the interested reader may refer to Stalnaker (2006) who gave arguments to support
S4.2 rather than S5 for modeling knowledge.
5An equivalence relationship is by deﬁnition a reﬂexive, transitive and symmetrical relationship, but equiva-
lently we can consider any reﬂexive, transitive and Euclidean relationship.

20

Finally, if an agent i does not perform actions that lead to some consequences ϕ,
then agent i indirectly performs actions that lead to not realize the actions that lead
to ϕ. Thus the relation Ei is Euclidean, i.e.:

∀w, u, v ∈ W : wEiu ∧ wEiv ⇒ uEiv

(E3)

Let us notice that we do not consider positive and negative introspection with
knowledge because since Ei represents the eﬀects of actions, some eﬀects may not be
known by the agent i as side-eﬀects.

4.2.3. Semantic representation of deliberate eﬀects

While the eﬀects of actions are represented as an equivalence relationship, we represent
deliberate eﬀects as a neighborhood function. This semantic diﬀerence is justiﬁed
by the fact that when an agent deliberately brings it about something, the latter
considers as many sets of possible worlds as deliberate eﬀects which has been carried
out. Moreover, Kripke’s relations do not allow us to express the fact that an agent
cannot deliberately bring it about something that he always knows to be true, such as
tautologies. It is due to the principle of necessity which is valid in any Kripke frame.
Thus, the ﬁrst semantic diﬀerence with the Ei modality is that an agent i cannot
deliberately bring it about that a tautology to be true since he knows it is always true.
This constraint, denoted Ed
N ec, is semantically translated by the fact that the set of
all possible worlds cannot belong to any neighborhood, i.e.:

∀w ∈ W : W (cid:54)∈ E d

i (w)

(Ed

N ec)

Moreover, there is a logical link between the modality of deliberate eﬀects and
that of the eﬀects of actions that may or may not be deliberate. Indeed, if an agent
i deliberately brings it about some action, then this agent does these actions. It is
represented by the constraint EdE which is semantically translated by the fact that
all the possible worlds reachable by the relation Ei are always included in all possible
worlds sets of E d

i , i.e.:

∀w ∈ W : S ∈ E d

i (w) ⇒ Ei(w) ⊆ S (EdE)

When an agent i deliberately brings it about that a proposition ϕ to be true while
deliberately bringing it about that another proposition ψ to be true, then that agent
i deliberately brings it about that ϕ ∧ ψ to be true, i.e.:

∀w ∈ W : S ∈ E d

i (w) ∧ T ∈ E d

i (w) =⇒ S ∩ T ∈ E d

i (w)

(E⇒,∧)

However, we cannot consider the reciprocal of (E⇒,∧) because deliberate eﬀects
concern a whole and cannot be considered as the sum of its part. For example, when
somebody decides to eat a hazelnut cake, he does not decide to deliberately eat the
dough of the cake and eat the hazelnuts independently. Moreover, this reciprocal,
deﬁned by ∀w ∈ W : S ∩ T ∈ E d
i (w) and associated with
the theorem Ed
i ψ, cannot be considered for technical reasons.
Indeed, an immediate result is that such constraint is equivalent to ∀w ∈ W : S ∈
E d
i (w) ∧ S ⊆ T =⇒ T ∈ E d
i (w). Hence, if this reciprocal is considered, we would get
an inconsistent logical system due to the constraint (Ed
N ec).

i (w) =⇒ S ∈ E d

i (ϕ ∧ ψ) ⇒ Ed

i (w) ∧ T ∈ E d

i ϕ ∧ Ed

21

Finally, an essential characteristic of deliberate eﬀects is that it is introspective
to the knowledge of agents. An agent always knows what it is doing and what it is
not doing deliberately. Thus, the deliberate eﬀect modality has positive (Ed
KP ) and
negative introspection (Ed
KN ) with respect to the knowledge of the agent, i.e.:

∀w ∈ W : E d

i (w) ⊆

(cid:92)

E d
i (v)

(Ed

KP )

v∈W:wKiv

∀w, v ∈ W, ∀S ∈ 2W : S (cid:54)∈ E d

i (w) =⇒ (wKiv ⇒ S (cid:54)∈ E d

i (v))

(Ed

KN )

These constraints mean that when an agent i deliberately brings it about a conse-
quence, she knows what she is doing deliberately. The same is true when an agent i
does not deliberately bring it about that a consequence, then the agent i knows that
she did not do it deliberately. Furthermore, let us notice that (Ed
KN ) is equivalent to:

∀w ∈ W, ∀S ∈ 2W : S (cid:54)∈ E d

i (w) =⇒ S (cid:54)∈

(cid:91)

E d
i (v)

(Ed

KN )

v∈W:wKiv

Or simply by contraposition, (Ed

KN ) can be rewritten as:

∀w ∈ W, ∀S ∈ 2W :

(cid:91)

i (v) ⊆ E d
E d

i (w)

(Ed

KN )

v∈W:wKiv

Thus, we can deduce the following theorems, whose proofs are given in Ap-

pendix A.1:

Proposition 4.1. If (Ed
Kripke structure that the following property holds:

KN ) and (Ed

KP ) hold at the same time, then it implies on the

(Ed

KN ) + (Ed

KP )

∀w ∈ W : E d

i (w) =

(cid:92)

E d
i (v) =

(cid:91)

E d
i (v)

v∈W:wKiv

v∈W:wKiv

Proposition 4.2.

(1) If (Ed

KP ) holds and Ki is reﬂexive, then:

∀w ∈ W, E d

i (w) =

(cid:92)

E d
i (v)

v∈W:wKiv

(2) If (Ed

KN ) holds and Ki is reﬂexive, then:

∀w ∈ W, E d

i (w) =

(cid:91)

E d
i (v)

v∈W:wKiv

KP ) hold at the same time. Thus, we can say that (Ed

However considering for instance only the property (1) is not enough to verify that
KN ) and (Ed
(Ed
KN ) is stronger than
considering an equivalence between intersections. Indeed, (Ed
KN ) translates exactly
that if an agent does not deliberate something, then it cannot be the case for all
indistinguishable worlds by the epistemic relationship.

22

4.2.4. Illustration of semantic relations

Example 4.3 illustrates the fundamental diﬀerences between deliberate and non-
deliberate eﬀects. A deliberate eﬀect is characterized as a calculated choice of an agent
to achieve something, making the agent fully aware of the consequences, whereas a
non-deliberate eﬀect represents the set of all consequences of the actions of the agent
which may be deliberate or not. Thus, the agent does not necessarily have knowledge
of all these consequences.

Example 4.3. Suppose a situation in which there is a murderer i that deliberately
brings it about to kill a victim j. In order to represent this situation we consider three
propositional variables: p denotes that “the agent kills the victim by stabbing her”,
q denotes that “the agent gets arrested by the police”, and r denotes that “there is
no witness”. For this situation, there are several possible worlds, for example, agent i
kills the victim and does not get stopped by the police, the victim was already dead
before the agent stabs her, agent i is remorseful and does not kill the victim, or the
victim j wakes up and makes agent i run away, etc. Let us assume that a model M
describes all of these possible worlds. Obviously we could consider a large number of
possible worlds to describe this example, but for the sake of clarity, we consider only
a small number of possible worlds. Let us assume M is such that:

• W = {w, u, v, x, y, z, a}
• V (p) = {w, u, v}, V (q) = {v, y, z}, V (r) = {w, x, y, z, a}

The possible worlds are:

• w: “there is no witness, agent i kills the victim j and does not get arrested”
• u: “there is a witness and agent i kills the victim j but does not get arrested”
• v: “there is a witness and agent i kills the victim j and agent i gets arrested”
• x: “the victim was already dead, no witness, and i does not get arrested”
• y: “the victim was already dead, no witness, and agent i gets arrested”
• z: “the killer is remorseful, no witness, and does not kill the victim, but agent i

still gets arrested for attempted murder”

• a: “no murder”

In the possible world w, the agent i therefore has a deliberate eﬀect to kill the victim.
In addition, he also takes care that there is no witness. So the neighborhood function is
such that E d
i (w) = {{w, u, v}, {w, x, y, z, a}}. It represents each independent strategy
that agent i intended to implement in w:

• {w, u, v} represents the deliberate eﬀect by agent i to kill the victim;
• {w, x, y, z, a} represents the deliberate eﬀect by agent i to ensure that there is

no witness at the crime scene.

In the world w, agent i successfully manages to kill the victim without getting
caught, so Ei(w) = {w}. Furthermore in w, since agent i deliberately brings it about
that there were no witness, we infer that the agent knows that p and r are true. So
we have Ki(w) = {w}, the only possible world where p and r are true simultaneously.
The agent i cannot discern in w any other world than this one. Moreover in w, the
agent knows that the police does not arrest him.

Let us remark that in this model semantics constraints, e.g. ∀w ∈ W : S ∈ E d

i (w) ⇒
Ei(w) ⊆ S, are naturally satisﬁed and illustrate the fact that since agent i deliberately
brings it about in w to kill the victim, then this agent i deliberately brings it about

23

that the victim is killed. Furthermore, since ||p|| ∈ E d
i p, i.e.
agent i deliberately brings it about to kill the victim. Since the agent’s strategic choice
was to succeed in killing the victim, he set up a strategy to make p true.

i (w) we have M, w |= Ed

4.3. Associated axiomatic system

Given the constraints on our frame, the associated axiomatic system is given in Fig-
ure 4. Here, (cid:96) ϕ means that ϕ is a theorem. For all modalities (cid:3) ∈ {Ki, Bi, Ei, Ed
i },
we have the modus ponens (M P ), the substitution (SU B) and the rule of infer-
ence (RE), i.e. from (cid:96) ϕ ⇔ ψ, we infer (cid:96) (cid:3)ϕ ⇔ (cid:3)ψ. However, the rule of neces-
sitation (N EC) is only veriﬁed for normal modalities, i.e. for all (cid:3) ∈ {Ki, Bi, Ei},
from (cid:96) ϕ, we infer (cid:96) (cid:3)ϕ. Finally, we have duality (DU AL), i.e. for all ((cid:3), ♦) ∈
{(Bi, (cid:104)Bi(cid:105)), (Ki, (cid:104)Ki(cid:105)), (Ei, (cid:104)Ei(cid:105)), (Ed

i (cid:105))}, (cid:96) (cid:3)ϕ ⇔ ¬♦¬ϕ.

i , (cid:104)Ed

(PC)
(S4Ki)
(4.2Ki)

All tautologies of Propositional Calculus
All S4-axioms for Ki
(cid:96) (cid:104)Ki(cid:105)Kiϕ ⇒ Ki(cid:104)Ki(cid:105)ϕ

(KD45Bi) All KD45-axioms6 for Bi

(S5Ei)
(KiBi)
(4Ki,Bi)
(5Ki,Bi)
(Ed
i Ei)
)
(CEd
)
(¬NEd
)
(4Ki,Ed
)
(5Ki,Ed

i

i

i

i

All S5-axioms for Ei
(cid:96) Kiϕ ⇒ Biϕ
(cid:96) Biϕ ⇒ KiBiϕ
(cid:96) ¬Biϕ ⇒ Ki¬Biϕ
(cid:96) Ed
i ϕ ⇒ Eiϕ
i ϕ ∧ Ed
(cid:96) Ed
(cid:96) ¬Ed
i (cid:62)
i ϕ ⇒ KiEd
(cid:96) Ed
i ϕ
i ϕ ⇒ Ki¬Ed
(cid:96) ¬Ed

i ψ ⇒ Ed

i ϕ

i (ϕ ∧ ψ)

Figure 4. Axiomatic system KBE

From Figure 4, one may wonder if deliberate eﬀect modality Ed

i may be expressed
with the non-deliberate modality Ei and a combination of modalities Ki, Bi or another
modality expressing intention? It is not the case because, (1) as we consider a S4.2
system for knowledge, we do not have the negative introspection on KiEiϕ while we
want it; (2) BiEiϕ does not satisfy the axiom T while Ed
i satisﬁes it, which will be
shown in Section 4.6; (3) an intention modality Ii such has the one proposed by Sakama
et al. (2015) will satisfy the necessitation on IiEiϕ which is a problem.

4.4. Soundness

It is well known that the semantics of a normal modality of a S5 system that preserves
validity is an equivalence relation (Blackburn et al., 2002). Since the relation Ei is an
equivalence relation, the rules of S5 preserve the validity. Then a relation Ki which
is reﬂexive, transitive and conﬂuent is sound as it is a S4.2 system. Concerning the
inference rules between the modality Ki and Bi, Stalnaker (2006) showed they are valid
in our logical frame. Moreover, it is well known that a serial, transitive and Euclidean
relation preserves the validity of a KD45 system for the modality Bi. Thus, in this

6It corresponds to the axioms of the KD45-system for a (cid:3) modality, i.e. (K) (cid:3)(ϕ ⇒ ψ) ⇒ ((cid:3)ϕ ⇒ (cid:3)ψ), (D)
(cid:3)ϕ ⇒ ¬(cid:3)¬ϕ, (4) ¬(cid:3)ϕ ⇒ (cid:3)¬(cid:3)ϕ, and (5) (cid:3)ϕ ⇒ (cid:3)(cid:3)ϕ are considered.

24

section, we only focus on the non-normal properties associated with the neighborhood
semantics E d

i . The following properties are in Pacuit (2017):

(1) C |= ¬Ed
(2) C |= Ed

i (cid:62) iﬀ ∀w ∈ W : W (cid:54)∈ E d
i p ∧ Ed
i (p ∧ q) iﬀ:

i q ⇒ Ed

i (w)

∀w ∈ W : S ∈ E d

i (w) ∧ T ∈ E d

i (w) =⇒ S ∩ T ∈ E d

i (w)

Other properties are standard to prove by using contraposition. Consequently it is
straightforward to prove that our KBE system is sound. The complete proof is detailed
in Appendix A.2.

Theorem 4.4. The KBE system is sound.

4.5. KBE Completeness

In order to prove that our system is complete, we apply a Henkin-like proof method
by building a canonical model which relies on Maximal Consistent Sets (MCS) and a
notion of minimal canonical model for neighborhood semantics (Pacuit, 2017).

Theorem 4.5. The KBE system is complete.

The complete proof can be found in Appendix A.3. Moreover the KBE system has
the deduction theorem, is strongly complete and strongly sound (Blackburn et al., 2002;
Pacuit, 2017). For the interested reader, the proofs are given in Appendix A.4.

4.6. Deductible theorems

Let us remark that (D) and (T ) can be derived for Ed
i . It means that one agent i cannot
deliberately bring about something and its opposite, and that when an agent i deliber-
ately brings about ϕ, he makes ϕ to be true. In particular, it makes beliefs equivalent
to knowledge for the special case of the deliberate eﬀect modality. It means that an
agent cannot have false beliefs concerning the formulas he deliberately brings about.
It is given by the following theorem; the complete proofs are given in Appendix A.5.

Theorem 4.6.

)

i

i

)

(1) (cid:96) ¬Ed
(2) (cid:96) Ed
(3) (cid:96) KiEd
(4) (cid:96) Ki¬Ed
(5) (cid:96) ¬KiEd
(6) (cid:96) ¬Ki¬Ed
(7) (cid:96) BiEd
(8) (cid:96) Bi¬Ed
(9) (cid:96) ¬BiEd
(10) (cid:96) ¬Bi¬Ed

i ⊥ (DEd
i ϕ ⇒ ϕ (TEd
i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ ⇔ ¬Ed
i ϕ ⇔ Ed
i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ ⇔ ¬Ed
i ϕ ⇔ Ed

i ϕ
i ϕ
i ϕ

i ϕ
i ϕ
i ϕ

We can also show that any agent i, when it deliberately brings it about that another
agent j believes something, this agent i also brings it about that the agent j cannot
believe that this agent i can know the opposite. Such a theorem translates that when

25

an agent seeks to convey new beliefs, whether they are true or false in the case of lies,
that agent always brings it about that he is credible to the other agent.

Theorem 4.7.

(1) concealing contrary beliefs: (cid:96) Ed
(2) concealing knowledge: (cid:96) Ed

i Bjϕ ⇒ Ei¬BjKk¬ϕ

i ¬Bjϕ ⇒ Ei¬BjKkϕ

The complete proofs are given in Appendix A.5. Other interesting theorems can
also be deduced. Moreover, when an agent deliberately brings it about that another
agent believes something, then it cannot be the case that the agent deliberately brings
it about the other to believe that a third-party agent can know the opposite.

Theorem 4.8.

(1) An agent who deliberately inﬂuences the beliefs of an agent cannot have deliber-
ated to show that other agents, including himself, may hold the opposite, i.e.:

(cid:96) Ed

i Bjϕ ⇒ ¬Ed

i BjKk¬ϕ

(2) An agent who deliberately brings it about that another agent does not believe a
piece of information, cannot also deliberately bring it about that the agent knows
that a third-party agent holds the opposite, i.e.:

(cid:96) Ed

i ¬Bjϕ ⇒ ¬Ed

i BjKkϕ

As previously, the complete proofs are given in Appendix A.5. These theorems
tell us that when an agent i brings it about new beliefs in another agent j, they also
maintained consistency (i.e. by preventing j to know that a third party agent may know
the opposite as it is the case for i). Let us notice that (cid:96) Ed
i ¬Kjϕ ⇒ Ei¬KjKkϕ is also
a theorem by following the same method as in 4.2. Moreover, as the contraposition of
(cid:96) Kkϕ ⇒ Bkϕ is (cid:96) ¬Bkϕ ⇒ ¬Kkϕ and (cid:96) Ed
i ϕ, we deduce
two immediate corollaries to these theorems:

i ϕ ⇒ Eiϕ is (cid:96) ¬Eiϕ ⇒ ¬Ed

(1) (cid:96) Ed
(2) (cid:96) Ed

i Bjϕ ⇒ ¬Ed
i ¬Bjϕ ⇒ ¬Ed

i KjKk¬ϕ
i KjKkϕ

In the KBE system, we can also deduce the qui facit per alium facit per se principle,

i.e. “he who acts through another does the act himself”.

Theorem 4.9 (Qui facit per alium facit per se).

(cid:96) (Ed

i Ejϕ ∨ Ed

i Ed

j ϕ) ⇒ Eiϕ

This theorem means that an agent inﬂuencing another agent to act illegally also acts
illegally itself. Thus in a legal context, an inﬂuencer is also responsible for illegal acts
perpetrated by the inﬂuenced agent. Therefore, the inﬂuencer has some responsibility
in these acts committed by this principle.

26

5. Modeling manipulations

In this section we ﬁrst deﬁne formally what a manipulation is. Secondly we show
our logical framework can also model coercion, persuasion and some forms of decep-
tion, and thus is consistent with “manipulation is not exactly coercion, not precisely
persuasion, and not entirely similar to deception” (Handelman, 2009).

5.1. Diﬀerent kinds of manipulation

In terms of manipulation, a manipulator always intends to inﬂuence the intentions:
by pushing his victim to do something, or by preventing his victim from doing some-
thing. It is the instrumentalization involved in Deﬁnition 2.1. Moreover, the manip-
ulator always deliberately brings it about to conceal this instrumentalization. Thus,
we can characterize manipulation depending on (1) what the manipulator wanted the
victim to realize; (2) whether the victim deliberately brings it about to realize the
manipulator’s will; (3) how the manipulator intended to conceal. Hence, we consider
constructive manipulations to be those where the manipulator brings about his victim
to do something, and destructive manipulations when the manipulator aims at pre-
venting an agent from doing something. Since manipulation is a deliberate eﬀect of the
manipulator, we also need to distinguish between bringing about another agent to do
something in a deliberate way from doing it in an unintentional way. Thus, when the
manipulator deliberately brings about the manipulated agent to deliberately bringing
it about something, it relies on a strong instrumentalization. When the manipulator
deliberately brings about the manipulated agent to do something in general, it relies
on a soft instrumentalization. Finally we distinguish diﬀerent forms of manipulation
depending on whether the dissimulation is based on knowledge or beliefs: we call an
epistemic concealment when the manipulator aims at preventing the victim to know
his eﬀects, and a doxastic concealment when the manipulator aims at preventing the
victim from believing his intentions.

Tables 2 and 3 present diﬀerent ways of expressing instrumentalization and conceal-
ment in the case of constructive manipulations and the case of destructive manipula-
tions.

j ϕ)

Instrumentalization Concealment
Epistemic (Ed
Strong (Ed
Epistemic (Ed
Soft (Ed
Doxastic (Ed
Strong (Ed
Doxastic (Ed
Soft (Ed

i Ed
i Ejϕ)
i Ed
i Ejϕ)

j ϕ)

i ¬KjEd
i Ed
j ϕ)
i ¬KjEd
i Ejϕ)
i Ed
i ¬BjEd
j ϕ)
i ¬BjEd
i Ejϕ)

Table 2. Constructive forms of manipulation

Table 2 shows the diﬀerent components of a constructive manipulation. For exam-
ple, a strong instrumentalization is represented by the formula Ed
j ϕ. Literally, this
formula describes that the agent i employed a strategy leading the agent j deliberately
bringing it about the consequence ϕ. A soft instrumentalization can be represented
by the formula Ed
i Ejϕ. Finally, in the case of constructive manipulations, an epis-
temic concealment can be represented by the formula Ed
i Ejϕ and a doxastic
concealment by the formula Ed

i ¬KjEd

i Ed

i ¬BjEd

i Ejϕ.

Table 3 describes the diﬀerent components when a manipulation is destructive.
For example, in this case of destructive manipulations, soft instrumentalization is

27

j ϕ)

Instrumentalization Concealment
Epistemic (Ed
Strong (Ed
Epistemic (Ed
Soft (Ed
Doxastic (Ed
Strong (Ed
Doxastic (Ed
Soft (Ed

i ¬Ed
i ¬Ejϕ)
i ¬Ed
i ¬Ejϕ)

j ϕ)

i ¬KjEd
i ¬KjEd
i ¬BjEd
i ¬BjEd

i ¬Ed
j ϕ)
i ¬Ejϕ)
i ¬Ed
j ϕ)
i ¬Ejϕ)

Table 3. Destructive forms of manipulation

represented by the formula Ed
formula Ed
ﬁnally, a doxastic concealment is represented by the formula Ed

j ϕ, then an epistemic concealment by the formula Ed

i ¬Ejϕ, a strong manipulation is represented by the
j ϕ and

i ¬Ed

i ¬KjEd
i ¬Ed

i ¬Ed
j ϕ.

i ¬BjEd

Let us that notice that, for both constructive and destructive manipulations, an
agent i cannot manipulate another agent j to deliberately brings about ϕ while con-
cealing i deliberately brings j about bringing about ϕ as a side-eﬀect (and inversely).
This is due to the deﬁnition of manipulation we consider (see Deﬁnition 2.1): there is
a manipulation when the eﬀect of intrumentalization is the eﬀect which is concealed.
Thus, combining both a strong instrumentalization with the corresponding ”soft” epis-
temic (or doxastic) and the soft instrumentalization with the corresponding ”strong”
epistemic (or doxastic) does not make sense.

5.1.1. The set of formulas Σ

In the sequel, we combine these diﬀerent forms of instrumentalization and concealment
to deﬁne all the forms of manipulation that can be expressed in KBE. Since we use
i which does not have the theorem (cid:3)(ϕ ∧ ψ) ≡ (cid:3)ϕ ∧
a non-normal modality for Ed
(cid:3)ψ, we have to consider all other possible formulas that this agent may deliberately
bring about at the same time. Indeed, an agent can manipulate another one while
deliberately bringing about something else. However, without this theorem, we cannot
deduce manipulation alone in this situation. One way to deal with this problem is
to consider an explicit set of formulas on which we (as designers) allow the logic to
reason, and to use this set to deﬁne predicates for manipulation. However, this set
must be ﬁnite, otherwise the formulas that will characterize manipulation cannot be
well-formed.

Thus, we introduce a set of formulas Σ which is ﬁnite, closed, and which contains
P ∪ {(cid:62), ⊥}. We consider the closure as Blackburn et al. (2002): a set of formulas Σ
is said to be closed if, and only if, (1) if σ ∈ Σ and θ is a subformula of σ, then
θ ∈ Σ and (2) if σ ∈ Σ and σ is not of the form ¬θ, then ¬σ ∈ Σ. While Σ may
be arbitrarily instantiated, it makes sense to ground it on a action-eﬀect knowledge
base: Σ shall be the closed set of all subformulas of this knowledge base. In order
to manipulate the predicates that will use in the next sections a Σ-set, we introduce
to deﬁne a conjunctive Cartesian product between two sets of
a new operator
Γ := {σ ∧ γ : σ ∈ Σ, γ ∈ Γ}. This operator will allow us to rewrite
formulas, i.e. Σ
these predicates in order to highlight logical relations between related concepts, as for
instance between strong instrumentalization and the persuasion predicate.

(cid:55)
(cid:55)

5.1.2. Soft constructive manipulations

A soft constructive manipulation with epistemic concealment, denoted M CEKΣ
i,j(ϕ),
is when a manipulator deliberately brings the victim about doing something while

28

making sure that the victim does not know the deliberate eﬀects of the manipulator.
Here, ϕ ∈ Σ and must be consistent. A soft constructive manipulation with doxastic
concealment – denoted M CEBΣ
i,j(ϕ) below – is deﬁned similarly but, in this case, the
manipulator deliberately brings it about that the victim does not believe his deliberate
eﬀects. Formally, we deﬁne these manipulation forms such as:

M CEKΣ

i,j(ϕ)

M CEBΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ejϕ ∧ ¬KjEd

i Ejϕ ∧ ψ)

Ed

i (Ejϕ ∧ ¬BjEd

i Ejϕ ∧ ψ)

Let us notice that ψ represents all formulas from Σ which do not contradict Ejϕ ∧
i Ejϕ, then we immediately deduce
i ⊥.

i Ejϕ. Indeed, if ψ contradicts Ejϕ ∧ ¬KjEd
i ⊥. However it is necessarily false due to the theorem (cid:96) ¬Ed

¬KjEd
that Ed

5.1.3. Strong constructive manipulations

is denoted with
A strong constructive manipulation with epistemic concealment
M CEdKΣ
i,j(ϕ), and is when the manipulator brings the other agent about doing some-
thing in a deliberate way while making sure that the victim does not know the de-
liberate eﬀects of the manipulator. A strong constructive manipulation with doxastic
concealment – denoted M CEdBΣ
i,j(ϕ) below – is similar but, in this case, the manip-
ulator makes sure that the victim does not believe his eﬀects. Formally,

M CEdKΣ

i,j(ϕ)

M CEdBΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ed

j ϕ ∧ ¬KjEd

i Ed

j ϕ ∧ ψ)

Ed

i (Ed

j ϕ ∧ ¬BjEd

i Ed

j ϕ ∧ ψ)

Example 5.1. Let us illustrate this predicate with an example related to advertising.
An advertiser always intends to bring new customers about buying a product. These
intentions are not concealed and therefore we cannot speak of manipulation. On the
other hand, it becomes manipulation when the advertiser uses concealed sales tech-
niques such as, for example, the use of subliminal images. Thus, the advertiser does
not seek to conceal his intention to bring the customer about buying the product, but
to deliberately conceal the technique he uses to bring the customer about buying. If
the agent i is the advertiser, Ed
i represents his strategy of using subliminal images to
get the customer j to buy a product. The customer does not know that the advertiser
has used these images. Thus, if ϕ := ”the product is bought”, then this situation of
manipulation is fully described by the formula Ed

i (Ejϕ ∧ ¬KjEd

i Ejϕ).

5.1.4. Strong and soft destructive manipulations

As said in the introduction, another way to see manipulation is to consider that a
manipulator may deliberately prevent the victim from doing something. We call this

29

kind of manipulation a destructive manipulation. As previous, destructive manipula-
tion can be declined in soft and strong destructive manipulations with either epistemic,
or doxastic concealment. Formally,

M DEKΣ

i,j(ϕ)

M DEdKΣ

i,j(ϕ)

M DEBΣ

i,j(ϕ)

M DEdBΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (¬Ejϕ ∧ ¬KjEd

i ¬Ejϕ ∧ ψ)

Ed

i (¬Ed

j ϕ ∧ ¬KjEd

i ¬Ed

j ϕ ∧ ψ)

Ed

i (¬Ejϕ ∧ ¬BjEd

i ¬Ejϕ ∧ ψ)

Ed

i (¬Ed

j ϕ ∧ ¬BjEd

i ¬Ed

j ϕ ∧ ψ)

Example 5.2. An example of destructive manipulation is illustrated by the case of
eclipse attacks (Singh, Ngan, Druschel, & Wallach, 2006). These attacks consist in
isolating an agent in order to exclude it from a network. This type of manipulation is
captured by destructive manipulation. Indeed, the hacker makes sure at the moment
of the attack that the target node can no longer communicate with other nodes in
the network (i.e. Ed
i ¬Ejϕ with ϕ any communicable information) while making sure
that he does not know that he is at that moment under the instance of an attack (i.e.
Ed

i ¬KjEd

i ¬Ejϕ).

5.1.5. A general deﬁnition of manipulation

Finally, all these deﬁnitions can be merged in a general deﬁnition of manipulation:

M Σ

i,j(ϕ)

(cid:52)
=

(cid:95)

(cid:3)∈{B,K}

M CE(cid:3)Σ

i,j(ϕ) ∨ M CEd(cid:3)Σ

i,j(ϕ) ∨ M DE(cid:3)Σ

i,j(ϕ) ∨ M DEd(cid:3)Σ

i,j(ϕ)

5.2. Some properties of manipulation

In this section, we exhibit some properties of the above deﬁnitions.

5.2.1. Believing being inﬂuenced

Obvioulsy, if an agent is a victim of an epistemic (resp. doxastic) manipulation, he
cannot know (resp. believe) he is instrumentalized. However, an agent can believe he
is instrumentalized while being a victim of an epistemic manipulation. It means that
the victim may believe to be instrumentalized while being unable to prove it, i.e. it is
not the case the agent knows he is instrumentalized. Indeed, when a child cries to get
a new toy from his parents, the parents may believe the child deliberately puts himself
in this state but cannot be sure it is the case. It is given by the following theorem for
the soft epistemic constructive manipulation.

30

Theorem 5.3. (cid:54)|= M CEKΣ

i,j(ϕ) ∧ BjEd

i Ejϕ ⇒ ⊥

This property is obvious because there is no contradiction between ¬KjEd

i Ejϕ and
i Ejϕ. The same property holds for the other forms of manipulation with epistemic

BjEd
concealment, i.e. strong epistemic and destructive manipulation.

5.2.2. Knowing being inﬂuenced

Interestingly, an agent can be victim of a manipulation while knowing he is inﬂuenced.
In this case, the agent does not know (resp. believe) he is instrumentalized, i.e. the
manipulator deliberately brings the victim about bringing about something, but he can
know the manipulator inﬂuenced him. Indeed, the manipulation conceals the deliberate
intention of the the manipulator, but not the inﬂuence in itself. It is given by the
following theorem.

Theorem 5.4. (cid:54)|= M CEKΣ

i,j(ϕ) ∧ KjEiEjϕ ⇒ ⊥

This property is obvious as there is no contradiction between ¬KjEd

i Ejϕ and
KjEiEjϕ. The same property holds for the other forms of manipulation. Let us con-
sider the previous example: when the child cries to get a new toy from his parents, the
parents can know the cries inﬂuence them while not knowing the child deliberately
puts himself in this state to aﬀect them.

5.2.3. Knowing or believing the eﬀects of a manipulation

If an agent is strongly manipulated in a constructive way to bring himself about a
formula ϕ, he knows that ϕ, and cannot know or believe ¬ϕ. Indeed, while a manipu-
lation conceals the instrumentalization, it does not conceal its eﬀect, i.e. the fact that
the victim brings about ϕ.

Theorem 5.5.

(1) (cid:96) (M CEdKΣ
(2) (cid:96) (M CEdKΣ
(3) (cid:96) (M CEdKΣ

i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ ⊥
i,j(ϕ)) ∧ Bj¬ϕ ⇒ ⊥
i,j(ϕ)) ⇒ Kjϕ

The proofs are given in Appendix A.6. Let us notice that those properties do not

hold for the soft or destructive manipulations.

5.2.4. Interactions between deliberate and non-deliberate eﬀects

When the goal ϕ of a manipulation consists in bringing the victim about another
formula ϕ(cid:48), some form of manipulation may be reduced while some others allow us to
express particular situations depending if it is a soft or strong manipulation.

In the case of soft manipulation:

Theorem 5.6.

(1) (cid:96) M CEKΣ
(2) (cid:96) M CEKΣ
(3) (cid:96) M CEBΣ
(4) (cid:96) M CEBΣ

i,j(Ejϕ) ⇔ M CEKΣ
i,j(¬Ejϕ) ⇔ M DEKΣ
i,j(Ejϕ) ⇔ M CEBΣ
i,j(¬Ejϕ) ⇔ M DEBΣ

i,j(ϕ)

i,j(ϕ)

i,j(ϕ)

i,j(ϕ)

31

(5) (cid:96) M DEKΣ
(6) (cid:96) M DEKΣ
(7) (cid:96) M DEBΣ
(8) (cid:96) M DEBΣ

i,j(Ejϕ) ⇔ M DEKΣ
i,j(¬Ejϕ) ⇔ M CEKΣ
i,j(Ejϕ) ⇔ M DEBΣ
i,j(¬Ejϕ) ⇔ M CEBΣ

i,j(ϕ)
i,j(ϕ)

i,j(ϕ)
i,j(ϕ)

The previous properties obviously hold because we have |= EiEiϕ ≡ Eiϕ, |=
¬EiEiϕ ≡ ¬Eiϕ, and |= Ej¬Ejϕ ⇔ ¬Ejϕ i.e. |= ¬Ej¬Ejϕ ⇔ Ejϕ. Interestingly
such properties do not hold for deliberate eﬀects, i.e. when ϕ = Ed
j ϕ(cid:48). However, it
allows us to express manipulation where the goal is to let a victim obliges or forbids
herself by side-eﬀect to apply a given strategy, e.g. to make a mistake that obliges or
forbids herself to deliberately bring her about something. For instance for constructive
manipulation, such situations are expressed by:

• Ed
• Ed
• Ed
• Ed

i (EjEd
i (EjEd
i (Ej¬Ed
i (Ej¬Ed

j ϕ(cid:48) ∧ ¬KjEd
j ϕ(cid:48) ∧ ¬BjEd
j ϕ(cid:48) ∧ ¬KjEd
j ϕ(cid:48) ∧ ¬BjEd

i EjEd
i EjEd

j ϕ(cid:48))
j ϕ(cid:48))
i Ej¬Ed
i Ej¬Ed

j ϕ(cid:48))
j ϕ(cid:48))

In the case of strong manipulation, if we consider ϕ = Ejϕ(cid:48), we can express manipu-
lation where the goal is to instrumentalize a victim to make her to insure producing (or
not producing) something by side-eﬀects, e.g. to jeopardize (or insuring not to jeopar-
dize) another strategy. For instance for constructive manipulation, such situations are
expressed by:
i (Ed
i (Ed
i (Ed
i (Ed

i Ed
j Ejϕ(cid:48) ∧ ¬KjEd
j Ejϕ(cid:48) ∧ ¬BjEd
i Ed
j ¬Ejϕ(cid:48) ∧ ¬KjEd
j ¬Ejϕ(cid:48) ∧ ¬BjEd

j Ejϕ(cid:48))
j Ejϕ(cid:48))
i Ed
i Ed

• Ed
• Ed
• Ed
• Ed

j ¬Ejϕ(cid:48))
j ¬Ejϕ(cid:48))

Finally, we have the case where ϕ = Ed

j ϕ(cid:48). In this case, it correspond to manipulation
where the goal is to instrumentalize a victim in order she puts herself a situation where
she deliberately brings about something or deliberately forbid herself to bring about
something, e.g. pushing a drug-addict to attach himself in order to not be able to take
drug. For instance for constructive manipulation, such situations are expressed by:

• Ed
• Ed
• Ed
• Ed

i (Ed
i (Ed
i (Ed
i (Ed

j Ed
j Ed
j ¬Ed
j ¬Ed

j ϕ(cid:48))
j Ed
i Ed
j ϕ(cid:48) ∧ ¬KjEd
j Ed
i Ed
j ϕ(cid:48) ∧ ¬KjEd
j ϕ(cid:48))
j ¬Ed
i Ed
j ϕ(cid:48) ∧ ¬KjEd
j ¬Ed
i Ed
j ϕ(cid:48) ∧ ¬BjEd

j ϕ(cid:48))
j ϕ(cid:48))

5.2.5. Interactions between soft and strong manipulation

An agent can strongly manipulate another one while not softly manipulating the vic-
tim. Conversely, an agent can softly manipulate another one while not strongly ma-
nipulating the victim. Obviously, an agent can both softly and strongly manipulate
another one.

Theorem 5.7.

(1) (cid:54)|= ¬M CEKΣ
(2) (cid:54)|= M CEKΣ

i,j(ϕ) ∧ M CEdKΣ
i,j(ϕ) ∧ ¬M CEdKΣ

i,j(ϕ) ⇒ ⊥
i,j(ϕ) ⇒ ⊥

32

(3) (cid:54)|= M CEKΣ

i,j(ϕ) ∧ M CEdKΣ

i,j(ϕ) ⇒ ⊥

Those properties can be extended to the other forms of manipulation. While it
may be seen as counterintuitive, it expressed some particular situations. For instance,
if ¬M CEKΣ
i,j(ϕ) is true, then it means that the manipulator aims
at concealing the way he instrumentalized the victim, i.e. he brings the victim to
deliberately bring about something, while not concealing the fact that he brings the
victim about something (e.g. by side-eﬀects).

i,j(ϕ) ∧ M CEdKΣ

5.2.6. Manipulating oneself

As deﬁned in Section 2.2, manipulation consists in instrumentalizing another agent.
However, the KBE system only partially prevents an agent to manipulate himself as
shown by the following properties.

Theorem 5.8.

(1) (cid:96) Ed
(2) (cid:54)|= M CEKΣ

i Eiϕ ∧ Ed

i ¬KiEd

i Eiϕ ⇒ ⊥
i,i(ϕ) ⇒ ⊥ and (cid:54)|= M CEBΣ

i,i(ϕ) ⇒ ⊥

i ϕ ∧ Ed

i ϕ ⇔ ¬Ed

i (ϕ ∧ ψ) =⇒ Ed

Both properties can be extended to the other forms of manipulation. Property
(1) holds because of |= ¬KiEd
i ϕ while properties in (2) are due to
(cid:54)|= Ed
i ψ. Property (1) means that manipulating oneself by
independently deliberately bringing oneself about each part of the manipulation is
inconsistent. However, properties in (2) mean that an agent can manipulate himself
when the strategy of concealment is intrinsic to the strategy of instrumentalization. It
makes particularly sense for artiﬁcial agents, e.g. in the case where a hacker changes
the normal behavior of an artiﬁcial agent to delete or prevent log recording.

5.3. Other notions related to manipulation

We can also express related notions like coercion, persuasion and deception. We exhibit
some links between those notions and manipulation. As previously, the proofs are given
in Appendix A.6.

5.3.1. Coercion

The coercion is an inﬂuence of an agent over another agent by means of pressure
without any dissimulation. For instance, a robber pointing a gun at somebody so
as to get his wallet is not trying to manipulate the victim but he is inﬂuencing his
behavior. The robber deliberately ensures that the victim knows or believes that he
is under pressure (by pointing the gun). As manipulation, coercion can be expressed
in a constructive or a destructive form. Thus, coercion can be deﬁned formally with
several predicates, i.e. constructive epistemic coercion, constructive doxastic coercion,
destructive epistemic coercion and destructive doxastic coercion:

CKCoeΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ed

j ϕ ∧ KjEd

i Ed

j ϕ ∧ ψ)

33

CBCoeΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ed

j ϕ ∧ BjEd

i Ed

j ϕ ∧ ψ)

DKCoeΣ

i,j(ϕ)

DBCoeΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (¬Ed

j ϕ ∧ KjEd

i ¬Ed

j ϕ ∧ ψ)

Ed

i (¬Ed

j ϕ ∧ BjEd

i ¬Ed

j ϕ ∧ ψ)

Obviously, coercion is a particular case of strong instrumentalization. Let us notice
operator deﬁned in Section 5.1.1 in order to better
the following theorems use the
highlight some interesting properties. We recall the reader this operator is a conjunctive
Cartesian product between two sets of formulas.

(cid:55)

Theorem 5.9.

(1) (cid:96) CKCoeΣ

i,j(ϕ) ⇔

(2) (cid:96) CBCoeΣ

i,j(ϕ) ⇔

ψ∈Σ

ψ∈Σ

(cid:55)

(cid:55)

5.3.2. Persuasion

(cid:87)

i Ed

j ϕ}

{KjEd
(cid:87)

{BjEd

i Ed

j ϕ}

Ed

i (Ed

j ϕ ∧ ψ)

Ed

i (Ed

j ϕ ∧ ψ)

Persuasion consists in an agent making another one into believing something.

perΣ

i,j(ϕ)

(cid:52)
=

(cid:95)

ψ∈Σ

Ed

i (Bjϕ ∧ ψ)

Persuasion is view as a particular case of inﬂuence, i.e. an inﬂuence on the belief
state of the persuadee. Let us notice that, as the KBE system is not based on dynamic
logic, this notion of persuasion does not capture the case of belief revision. However, if
the persuadee is persuaded to deliberately bring about something, then the persuasion
is equivalent to strong instrumentalization. It is expressed by the following theorem.

Theorem 5.10.

(1) (cid:96) perΣ

i,j(¬Ed

Ed

i (¬Ed

j ϕ ∧ ψ)

(2) (cid:96) perΣ

i,j(Ed

Ed

i (Ed

j ϕ ∧ ψ)

j ϕ) ⇔ (cid:87)
j ϕ) ⇔ (cid:87)

ψ∈Σ

ψ∈Σ

When an agent persuades another one to deliberately bring about something while
ensuring that this agent knows or believes that he is persuaded, we can deduce a
coercion.

Theorem 5.11.

(1) (cid:96) CKCoeΣ

i,j(ϕ) ⇔ per

Σ
i,j

(cid:55)

{KjEd

i Ed

j ϕ}

(Ed

j ϕ)

34

(2) (cid:96) CBCoeΣ

(3) (cid:96) DKCoeΣ

(4) (cid:96) DBCoeΣ

(cid:55)

Σ
i,j(ϕ) ⇔ per
i,j
Σ
i,j(ϕ) ⇔ per
i,j
Σ
i,j(ϕ) ⇔ per
i,j

(cid:55)

{BjEd

i Ed

j ϕ}

{KjEd

i ¬Ed

j ϕ}

(cid:55)

{BjEd

i ¬Ed

j ϕ}

(Ed

j ϕ)
(¬Ed

(¬Ed

j ϕ)
j ϕ)

Interestingly, when an agent persuades another agent to bring about something
while concealing the persuader deliberate intention, we can deduce a strong manipu-
lation.

Theorem 5.12.

(1) (cid:96) per

(2) (cid:96) per

(3) (cid:96) per

(4) (cid:96) per

Σ
i,j
Σ
i,j
Σ
i,j
Σ
i,j

(cid:55)

(cid:55)

(cid:55)

(cid:55)

{¬KjEd

i Ed

j ϕ}

{¬BjEd

i Ed

j ϕ}

{¬KjEd

i ¬Ed

j ϕ}

{¬BjEd

i ¬Ed

j ϕ}

(Ed

(Ed

j ϕ) ⇔ M CEdKΣ
j ϕ) ⇔ M CEdBΣ
(¬Ed

i,j(ϕ)
i,j(ϕ)
j ϕ) ⇔ M DEdKΣ
j ϕ) ⇔ M DEdBΣ

(¬Ed

i,j(ϕ)
i,j(ϕ)

Let us notice the previous properties does not hold for soft manipulation.

5.3.3. Deception

Deception consists in an agent making another believing something while hiding it
some aspects linked to the newly believed statement. It may be half-truth, or deception
by omission (Sakama et al., 2015). Let us focus on source concealment (namely hiding
the deliberate eﬀects to make another agent into believing something) and credible lies
(namely hiding we believe the opposite of the statement we want the other agent to
believe). Interestingly, both cases can be deﬁned as a special case of persuasion.

Source concealment can represent agents that spread rumors. For instance, in the
case of stock exchange market, it happens that some agents spread rumors in order
to inﬂuence the others to buy or sell a product without they know that it is a part of
their strategy (Aggarwal & Wu, 2006). Thus, it can be characterized by the fact that
an agent makes sure to conceal – from an epistemic (resp. doxastic) point-of-view – his
deliberate eﬀects to make someone believes something. Thus, we can deﬁne epistemic
(resp. doxastic) source concealment as follows:

KSoCoΣ

i,j(ϕ)

BSoCoΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Bjϕ ∧ ¬KjEd

i Bjϕ ∧ ψ)

Ed

i (Bjϕ ∧ ¬BjEd

i Bjϕ ∧ ψ)

Mahon deﬁnes lying as “to make a believed-false statement (to another person) with
the intention that that statement be believed to be true (by the other person)” (Mahon,
2008). Thus, a statement is a lie if there is also a deliberate eﬀect to conceal the
intended eﬀects to lie, from an epistemic or a doxastic point-of-view. We call such a
lie an epistemic (reps. doxastic) credible lie:

35

KCrLieΣ

i,j(ϕ)

(cid:52)
= Bi¬ϕ ∧ (

(cid:95)

Ed

i (Bjϕ ∧ ¬KjBi¬ϕ ∧ ψ))

ψ∈Σ

BCrLieΣ

i,j(ϕ)

(cid:52)
= Bi¬ϕ ∧ (

(cid:95)

Ed

i (Bjϕ ∧ ¬BjBi¬ϕ ∧ ψ))

ψ∈Σ

One property of credible lie is that an agent cannot lie to another one in order
to make the victim believes he deliberately brings about something. Indeed, due to
Theorem 5.10(1), believing to deliberately bring about ϕ implies deliberately bringing
about ϕ, and the persuader would believe it while he should not. It is given by the
next theorem.

Theorem 5.13.

(1) (cid:96) KCrLieΣ
(2) (cid:96) BCrLieΣ
(3) (cid:96) KSoCoΣ
(4) (cid:96) BSoCoΣ
(5) (cid:96) KCrLieΣ
(6) (cid:96) BCrLieΣ

j ϕ) ⇒ ⊥
j ϕ) ⇒ ⊥
j ϕ) ⇔ M CEdKΣ
j ϕ) ⇔ M CEdBΣ

i,j(Ed
i,j(Ed
i,j(Ed
i,j(Ed
i,j(ϕ) ⇒ P erΣ
i,j(ϕ) ⇒ P erΣ

i,j

(cid:55)

i,j

i,j(ϕ)
i,j(ϕ)
{¬KjBi¬ϕ}

{¬BjBi¬ϕ}

(ϕ)

(cid:55)

(ϕ)

We can compare the persuasion and deception deﬁnitions we propose here to the
literature presented in Section 3.1. Firstly, we do not need to introduce explicit commu-
nication modality as Sakama et al. (2015) did. Here, the communication is expressed
(more precisely reduced) to a deliberate eﬀect of having an inﬂuence on the mental
state of another agent, e.g. making the agent believing something, or making him
bringing about something. Obviously, communication in a whole cannot be reduced
to just that, e.g. when an agent asks a question, or apologize, or publicly commit
himself to do something, etc. Our notion of persuasion is syntactically close to the
one proposed by Bonnet et al. (2021) – deliberately seeing to it that the persuadee
believes something – except we do not consider a temporal modality. Our notion of
deception is however diﬀerent as we explicitly consider concealment, which is not the
case in Bonnet et al. (2021). The same remark holds for lie when compared to the one
proposed by Sakama et al. (2015).

6. Application of KBE

The purpose of this section is to instantiate the KBE system in a situation where it
is possible for one agent to manipulate another.

6.1. The story

We consider an e-commerce website in which two agents perform a commercial trans-
action. Let i be the seller and j be the customer, and i says to j: “You can trust me on
the quality of the product. You will not ﬁnd a better product anywhere else. You are

36

Ki, Kj, Bi, Bj, Ei, Ej

w

a

Ki, Kj, Bi, Bj, Ei, Ej

Kj, Bj, Ej

Ki, Kj, Bi, Bj, Ei, Ej

v

Ej

Ej

u

Ki, Kj, Bi, Bj, Ei, Ej

Figure 5. Mental states of the agents

free to check information by yourself!”. Let us notice in the conversation when you use
terms such as you “are free to” may be related to a technique of manipulation in the
theory of free will compliance. Indeed, it has been observed by sociopsychologists that
the use of terms such as you are free to can strongly inﬂuence the choice of somebody
to which desired by a manipulator (Joule, Girandola, & Bernard, 2007).

6.2. Variables and possible worlds

To represent this situation, we consider two propositional variables p and q:

• p refers to “agent j trusts agent i on the product quality”;
• q refers to “agent j buys the product”.

For the sake of readability, we do not consider all possible scenarios such as agent
j does not buy the product but trusts i on the product quality. We represent the
possible scenarios we consider as a set of possible worlds W = {a, w, v, u} where:

• w: “i builds trust to get j to buy the product”;
• v: “i does not deliberately instrumentalize j to buy the product but j buys the

product and trusts i on the product quality”;

• u: “j buys the product without trust in i on the product quality and knows that

the agent i intended to make him buy the product”;

• a: “j does not buy the product and does not trust i on the product quality”.

6.3. Deﬁning the set Σ

Let us deﬁne the set Σ (see Section 5.1.1). Here, Σ = Cl(Γ) be a ﬁnite and closed set
of formulas where:

i p ⇒ Ed

i (Ed
Γ = {Ed
i Ejq ∧ Ed
Ed
j q ∧ Ed
i Ed
Ed
(cid:62), ⊥}

i Ejq),
i Ejq ⇒ Ed
i ¬KjEd
j q ⇒ Ed
i Ed
i KjEd

i (Ejq ∧ ¬KjEd
i Ed
j q ∧ KjEd
i (Ed

i Ejq),
j q),

Hence for example, the formula Ed

i p ⇒ Ed
i Ejq) allows us to reason about the sit-
uation described in the world w, i.e. the agent i deliberately builds trust in order to get

i (Ed

37

i (Ejq ∧ ¬KjEd

agent j to buy the product. As another example, the formula Ed
i Ejq ⇒
Ed
i Ejq) allows us to deduce a soft constructive manipulation if agent
i manipulates agent j. Finally, Ed
i Ed
j q) allows
agents to infer coercion if there is coercion in a world. Furthermore, as we consider
the closure of Γ, we also express all subformulas and their single negation7.

j q ∧ KjEd

i Ejq∧Ed

j q ⇒ Ed

i ¬KjEd

j q ∧ Ed

i KjEd

i (Ed

i Ed

i Ed

6.4. The KBE model

The valuation function V of the model describing this situation is given by V (p) =
{w, v} and V (q) = {w, u, v}. The accessibility relations are given in Figure 5 and they
are assumed to be:

(1) Ki(w) = {w}, Ki(v) = {v}, Ki(u) = {u}, Ki(a) = {a}
(2) Kj(w) = {w, v}, Kj(v) = {w, v}, Kj(u) = {u}, Kj(a) = {a}
(3) Bi(w) = {w}, Bi(v) = {v}, Bi(u) = {u}, Bi(a) = {a}
(4) Bj(w) = {w, v}, Bj(v) = {w, v}, Bj(u) = {u}, Bj(a) = {a}
(5) Ei(w) = {w}, Ei(v) = {v}, Ei(u) = {u}, Ei(a) = {a}
(6) Ej(w) = {w, u, v}, Ej(v) = {w, u, v}, Ej(u) = {w, u, v}, Ej(a) = {a}
(7) E d
i (w) = {{w, v}, {w, u, v}, {w, u, a}, {w, v, a}, {w}, {w, a}, {w, u}},
i (v) = {{v}, {w, v}}, E d
E d
j (w) = {{w, u, v}}, E d
(8) E d

i (a) = {{w, a}}
j (u) = {{w, u, v}}, E d

i (u) = {{u}, {w, u, v}}, E d

j (v) = {{w, u, v}}, E d

j (a) = {{w, a}}

Informally:

(1) describes the fact that the agent i knows agent j trusts him about the product
quality and knows that agent j knows he buys a product and trusts i about the
product quality, if it is the case.

(2) describes the agent j that buy the product while trusting the agent j does not

distinguish the worlds where he is instrumentalized and where he is not.

(3) and (4) describe that the agents believe what they know and vice versa, i.e.

Ki = Bi and Kj = Bj.

(5) means that in the world w, agent i ensures that p and q.
(6) says that agent j buys the product in {w, u, v} but does not necessarily trust i

on the product quality.

(7) means the agent i in w deliberately brings agent j about trusting him and he
deliberately brings it about if agent j trusts him, then agent j buys the product
while i makes sure to hide his strategy to get j to buy the product.

(8) means the agent j in {w, u, v} only intended to buy the product.

6.5. Deductions

We give now some deductions. We show according to the given KBE model that there
is a soft instrumentalization, a deliberate concealment in w, a possible manipulation
in w and a coercion in the world u.

6.5.1. Soft instrumentalization in w

Let us notice that in w, this model expresses that agent i has deliberately brought
j about buying the product by building trust. Indeed, we have ||Ed
i Ejq|| =

i p ⇒ Ed

7A set of formulas Σ is closed under single negation iﬀ if σ ∈ Σ and σ is not of the form ¬θ, then ¬σ ∈ Σ.

38

{w, u, a} and {w, u, a} ∈ E d
the theorem (cid:96) Ed
||p|| = {w, v} and {w, v} ∈ E d

i (w). So M, w |= Ed

i (Ed

i p ⇒ Ed

i ϕ ⇒ ϕ, we deduce that in w, we have M, w |= Ed

i Ejq). Thus, by applying
i p ⇒ Ed
i Ejq. But
i Ejq.

i (w), M, w |= Ed

i p. Therefore, we have M, w |= Ed

6.5.2. Deliberate concealment in w

In addition, we can notice that in w agent i also ensures to hide his strategy to get
j to buy the product. Indeed, we have in v that M, v |= ¬Ed
i Ejq, since ||Ejq|| =
{w, u, v} and {w, u, v} (cid:54)∈ E d
i (v). Thus, since agent j cannot discern between the worlds
w and v, we also deduce that M, w, v |= ¬KjEd
i Ejq. Moreover, we can notice that
||¬KjEd
i Ejq|| ∈
E d
i (w), we have M, w |= Ed
i Ejq. In conclusion, we have shown that M, w |=
Ed
i Ejq ∧ Ed
i ¬KjEd

i Ejq|| = {w, v, a}8 and {w, v, a} ∈ E d

i (w). Therefore, since ||¬KjEd

i ¬KjEd

i Ejq.

6.5.3. Possible manipulation in w
i ϕ ∧ Ed

i Ejq) and it is equivalent to M, w |= Ed

Now, by the tautology |= Ed
i (Ejq ∧
¬KjEd
i Ejq ∧ (cid:62)). So, we showed
that, in this situation, there is a possible world in which agent i manipulates the
agent j to make him buy the product by using a soft constructive manipulation with
epistemic concealment.

i (ϕ ∧ ψ), we deduce that M, w |= Ed

i (Ejq ∧ ¬KjEd

i ψ ⇒ Ed

Moreover, if we decompose the deliberate eﬀects of the agent i, E d

i (w) = {{w, v},
{w, u, v}, {w, u, a}, {w, v, a}, {w}, {w, a}, {w, u}}, we notice that agent i intended
to ensure p by considering the set ||p|| = {w, v}, and on the other hand to ensure q
by considering the set ||q|| = {w, u, v}. This agent also has the strategy to get the
other agent to buy the product with the set ||Ed
i p ⇒ Ed
i Ejq|| = {w, u, a}, and his
dissimulation strategy is represented by the set ||¬KjEd
i Ejq|| = {w, v, a}. Finally,
the sets {w}, {w, a}, {w, u} are given by the imposed constraint (CE) on the frame
to allow the tautology |= Ed
i (ϕ ∧ ψ). These sets of possible worlds
reﬂect the fact that when an agent sets up diﬀerent plans, this agent also considers all
combinations of all the diﬀerent plans as a possible plan. For example, since {w, a} =
{w, u, a} ∩ {w, v, a}, {w, a} is the combination of the respective plans ||Ed
i Ejq||
and ||¬KjEd

i ψ ⇒ Ed

i p ⇒ Ed

i ϕ ∧ Ed

i Ejq||.

6.5.4. Coercion in the world u

Finally let us notice that in the world u, agent i coerced agent j to push him to buy the
j q|| = {u}9 and that
product. Indeed, since we have ||Ed
j q ∧ KjEd
i Ed
j q|| ∩ ||KjEd
||Ed
j q)
and so M, u |= Ed
j q ∧ (cid:62)). Consequently, we just have proved that
M, u |= coeΣ

j q|| = {w, u, v} and ||KjEd
i (u), we deduce that M, u |= Ed
i Ed

j q|| = {u} ∈ E d
j q ∧ KjEd
i (Ed

i (Ed

i Ed

i Ed

i,j(q).

i Ej q and ∀x ∈ W : aKj x, M, x |= ¬Ed

8We explain why a ∈ ||¬Kj Ed
¬Ed
Secondly, notice that ||Ed
and so u (cid:54)∈ ||¬Kj Ed
i Ej q||.
9To make sure, just compute the set ||Ed
W, xKj z, M, z |= Ed
i Ed
j q is the world x = u.

i Ed

i Ej q|| and u (cid:54)∈ ||¬Kj Ed

i Ej q||. Firstly, notice that ||Ej q|| (cid:54)∈ E d

i Ej q|| = {w, u} and since ∀x ∈ W, uKj x, M, x |= Ed

i Ej q. Thus, M, a |= Kj ¬Ed

i Ej q, and so M, a |= ¬Kj Ed
i Ej q, we have M, u |= Kj Ed

i (a), and M, a |=
i Ej q.
i Ej q

j q|| = {w, u} and so the only possible world x such that ∀z ∈

39

7. Conclusion and future works

In this article, we provide a broad state-of-the-art about manipulation in social sci-
ence. We used this state-of-the-art to deﬁne manipulation as the deliberate eﬀect to
instrumentalize a victim while making sure to conceal that eﬀect. We proposed a log-
ical framework to reason about this notion. To this end, we deﬁned a new deliberate
BIAT modality for deliberate eﬀects. We then considered logical interactions between
knowledge, belief, deliberate eﬀects and consequences of actions and proved that our
system is strongly sound and complete. Furthermore we deduced several theorems such
as concealment of contrary beliefs and qui facit per alium facit per se principle. Fi-
nally we gave an explicit deﬁnition of what manipulation is, and we modeled coercion,
persuasion and deception diﬀerently such as highlighted by the literature.

In terms of perspectives, future works are twofold. Firstly, it may be of interest to
formalize deliberated intention in a deeper way. Indeed, KBE neither consider tem-
poral nor dynamic operators while they are necessary to express actions and their
consequences. Secondly, expressing more kind of manipulation is of interest. For in-
stance, it should be interesting to extend the framework with awareness so as to deﬁne
new manipulation forms with awareness concealment. As another example, extending
KBE with other mental state can be of interest to model manipulation strategies such
as presented in Table 1.

7.1. Extending KBE to awareness logics

When we deﬁned manipulation such as the deliberate eﬀect to instrumentalize an
agent while making sure to conceal that eﬀect, we deﬁned concealment as a lack of
knowledge or belief about the manipulator’s eﬀects. However, in many situations, a
manipulated agent is unaware that he or she has been manipulated. In section 3.3, we
have presented work on the representation of awareness. One perspective is to integrate
awareness into manipulation.

We could for instance consider a modality Ai to represent that agent i is aware of
something, as proposed in Schipper (2014). Let Σ be a set of formulas that is closed
and ﬁnite such as {(cid:62), ⊥} ⊆ Σ, ϕ ∈ Σ and Ai : W → 2Σ be the awareness function
associated with the modality Ai. We could then deﬁne new forms of manipulations
with absence of awareness. Thus, a soft constructive manipulation with absence of
awareness would be deﬁned as:

M CEAΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ejϕ ∧ ¬AjEd

i Ejϕ ∧ ψ)

A strong constructive manipulation with absence of awareness would be deﬁned as:

M CEdAΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (Ed

j ϕ ∧ ¬AjEd

i Ed

j ϕ ∧ ψ)

A soft destructive manipulation with absence of awareness would be deﬁned as:

M DEAΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (¬Ejϕ ∧ ¬AjEd

i ¬Ejϕ ∧ ψ)

40

A strong destructive manipulation with absence of awareness would be deﬁned as:

M DEdAΣ

i,j(ϕ)

(cid:95)

(cid:52)
=

ψ∈Σ

Ed

i (¬Ed

j ϕ ∧ ¬AjEd

i ¬Ed

j ϕ ∧ ψ)

Furthermore, note that in this case the function Ai is such that for any w ∈ W,
Ai(w) ⊆ Σ. That means that, in such a system, we assume agents are never aware of
formulas that are not in Σ.

7.2. Extending KBE with other mental states

We also could consider mental states other than awareness, in particular mental states
on which a manipulation strategy relies (see Table 1). Indeed, while our KBE system
can express strategies based on an agent’s beliefs and knowledge as with deception or
lying, we cannot express other forms of strategies when they are based on the agents’
desires, norms, or when they are based on trust in the sincerity that one agent gives
to another agent.

In a previous work, we propose a logic – called TB system – in which a modal-
ity T s
j,i expresses the fact that an agent i trusts the sincerity of an agent i about
something (Leturc & Bonnet, 2018). A perspective would consist in merging the KBE
system and the TB system. By merging them we would be able to deduce new theo-
rems such as if an agent j trusts the sincerity of another agent i about the fact that i
does not instrumentalize him, then it cannot be the case that agent j believes that i
can instrumentalize him. This theorem would be represented by the following formula:

(cid:96) T s

j,i¬Ed

i Ejϕ ⇒ ¬BjEd

i Ejϕ

We would then have new forms of manipulation whose concealment would be based
on trust between two agents. In the same way, it could be interesting to extend the
KBE system with notions of desires, norms or obligations so as to describe other kinds
of manipulation strategies presented in Table 1.

References

Abell, P. (1977). The many faces of power and liberty: Revealed preference, autonomy, and

teleological explanation. Sociology, 11 (1), 3–24.

Ackerman, F. N. (1995). The concept of manipulativeness. Philosophical Perspectives, 9 ,

335–340.

Aggarwal, R. K., & Wu, G. (2006). Stock market manipulations. The Journal of Business,

79 (4), 1915–1953.

A¨ımeur, E., & Sahnoune, Z. (2020). Privacy, trust, and manipulation in online relationships.

Journal of Technology in Human Services, 38 (2), 159-183.

Akopova, A. S. (2013). Linguistic manipulation: Deﬁnition and types. International Journal

of Cognitive Research in Science, Engineering and Education, 1 (2), 78–82.

Alur, R., Henzinger, T. A., & Kupferman, O. (2002). Alternating-time temporal logic. Journal

of the ACM , 49 (5), 672–713.

Balbiani, P., Herzig, A., & Troquard, N. (2008). Alternative axiomatics and complexity of

deliberative STIT theories. Journal of Philosophical Logic, 37 (4), 387–406.

Barnhill, A. (2014). What is manipulation. In C. Coons & M. Weber (Eds.), Manipulation:

Theory and practice (pp. 51–72). Oxford University Press.

41

Baron, M. (2003). Manipulativeness. Addresses of the American Philosophical Association,

77 (2), 37–54.

Belnap, N., & Perloﬀ, M. (1988). Seeing to it that: a canonical form for agentives. Theoria,

54 (3), 175–199.

Blackburn, P., De Rijke, M., & Venema, Y.

(2002). Modal logic: Graph. darst (Vol. 53).

Cambridge University Press.

Bonnet, G., Leturc, C., Lorini, E., & Sartor, G. (2021). Inﬂuencing choices by changing beliefs:
A logical theory of inﬂuence, persuasion, and deception. In S. Sarkadi, B. Wright, P. Mas-
ters, & M. P. (Eds.), Deceptive AI. DeceptECAI 2020, DeceptAI 2021. Communications in
Computer and Information Science (Vol. 1296, pp. 124–141). Springer.
Bottazzi, E., & Troquard, N. (2015). On help and interpersonal control.

In A. Herzig &
E. Lorini (Eds.), The cognitive foundations of group attitudes and social interaction (pp.
1–23). Springer.

Bowers, L. (2003). Manipulation: description, identiﬁcation and ambiguity. Journal of Psy-

chiatric and Mental Health Nursing, 10 (3), 323–328.

Broersen, J. (2008). A complete STIT logic for knowledge and action, and some of its ap-
plications. In International workshop on declarative agent languages and technologies (pp.
47–59).

Calo, R. (2013). Digital market manipulation. George Washington Law Review , 82 (4), 995–

1051.

Castelfranchi, C., & Falcone, R. (2010). Trust theory: A socio-cognitive and computational

model. John Wiley & Sons.

Cialdini, R. B. (2001). Harnessing the science of persuasion. Harvard Business Review , 79 (9),

72–81.

Cialdini, R. B. (2012). Inﬂuence and manipulation. First Editions.
Cohen, S. (2017). Manipulation and deception. Australasian Journal of Philosophy, 96 (3),

1–15.

de Saussure, L., & Schulz, P. J. (2005). Manipulation and ideologies in the twentieth century:

Discourse, language, mind. John Benjamins Publishing.

Ettinger, D., & Jehiel, P. (2010). A theory of deception. Microeconomics, 2 (1), 1–20.
Faden, R. R., & Beauchamp, T. L. (1986). A history and theory of informed consent. Oxford

University Press.

Fagin, R., & Halpern, J. Y.
Intelligence, 34 (1), 39–76.

(1987). Belief, awareness, and limited reasoning. Artiﬁcial

Festinger, L. (1962). A theory of cognitive dissonance (Vol. 2). Stanford University Press.
G¨ardenfors, P. (1976). Manipulation of social choice functions. Journal of Economic Theory,

13 (2), 217–228.

Gibbard, A. (1973). Manipulation of voting schemes: a general result. Econometrica, 41 (4),

587–601.

Giordano, L., Martelli, A., & Schwind, C. (2000). Ramiﬁcation and causality in a modal action

logic. Journal of Logic and Computation, 10 (5), 625–662.

Goodin, R. E. (1980). Manipulatory politics. Yale University Press.
Gunderson, J. G. (1984). Borderline personality disorder. SUNY Press.
Handelman, S. (2009). Thought manipulation: the use and abuse of psychological trickery.

Praeger.

Harel, D., Kozen, D., & Tiuryn, J. (2001). Dynamic logic. In Handbook of philosophical logic

(pp. 99–217). Springer.

Hill, B. (2010). Awareness dynamics. Journal of Philosophical Logic, 39 (2), 113–137.
Hoﬀman, K., Zage, D., & Nita-Rotaru, C. (2009). A survey of attack and defense techniques

for reputation systems. ACM Computing Surveys, 42 (1), 1–17.

Hoﬀman, K., Zage, D., & Nita-Rotaru, C. (2009). A survey of attack and defense techniques

for reputation systems. ACM Computing Surveys (CSUR), 42 (1), 1.

Josang, A., & Golbeck, J. (2009). Challenges for robust trust and reputation systems. In 5th

International workshop on security and trust management.

42

Joule, R.-V., Beauvois, J.-L., & Deschamps, J.-C. (2002). Concise handbook of manipulation

in honest people’s favour (french edition). Grenoble University Press.

Joule, R.-V., Girandola, F., & Bernard, F. (2007). How can people be induced to willingly
change their behavior? The path from persuasive communication to binding communication.
Social and Personality Psychology Compass, 1 (1), 493–505.

Kahneman, D. (2011). Thinking, fast and slow. Macmillan.
Kligman, M., & Culver, C. M. (1992). An analysis of interpersonal manipulation. Journal of

Medicine and Philosophy, 17 (2), 173–197.

Leturc, C., & Bonnet, G. (2018). A normal modal logic for trust in the sincerity. In 17th
International conference on autonomous agents and multiagent systems (pp. 175–183).
Leturc, C., & Bonnet, G. (2020). A deliberate BIAT logic for modeling manipulations. In 20th
International conference on autonomous agents and multiagent systems (pp. 699–707).
Levesque, H. J. (1984). A logic of implicit and explicit belief. In AAAI Conference on artiﬁcial

intelligence (pp. 198–202).

Lorini, E., & Sartor, G. (2016). A STIT logic for reasoning about social inﬂuence. Studia

Logica, 104 (4), 773–812.

Luhmann, N. (1979). Trust and power. Wiley.
Mahon, J. E. (2008). Two deﬁnitions of lying. International Journal of Applied Philosophy,

22 (2), 211–230.

Maillat, D., & Oswald, S. (2009). Deﬁning manipulative discourse: The pragmatics of cognitive

illusions. International Review of Pragmatics, 1 (2), 348–370.

Maoz, Z. (1990). Framing the national interest: The manipulation of foreign policy decisions

in group settings. World Politics, 43 (1), 77–110.

Masters, P., Smith, W., Sonenberg, L., & Kirley, M. (2021). Characterising deception in AI:
A survey. In S. Sarkadi, B. Wright, P. Masters, & M. P. (Eds.), Deceptive AI. DeceptECAI
2020, DeceptAI 2021. Communications in Computer and Information Science (Vol. 1296,
pp. 3–16). Springer.

McCloskey, H. J.

(1980). Coercion: its nature and signiﬁcance. The Southern Journal of

Philosophy, 18 (3), 335-351.

McGinn, C. (2014). Mindfucking: A critique of mental manipulation. Routledge.
Mills, C. (1995). Politics and manipulation. Social Theory and Practice, 21 (1), 97–112.
Mintzberg, H. (1987). The strategy concept I: Five Ps for strategy. California Management

Review , 30 (1), 11–24.

Mobasher, B., Burke, R., Bhaumik, R., & Sandvig, J. J. (2007). Attacks and remedies in

collaborative recommendation. IEEE Intelligent Systems, 22 (3), 56–63.

Modica, S., & Rustichini, A. (1994). Awareness and partitional information structures. Theory

and Decision, 37 (1), 107–124.

Noggle, R. (1996). Manipulative actions: a conceptual and moral analysis. American Philo-

sophical Quarterly, 33 (1), 43–55.

O’Keefe, D. J. (2015). Persuasion: Theory and research (third edition). Sage Publications.
Pacuit, E. (2017). Neighborhood semantics for modal logic. Springer.
Parkes, D. C., & Ungar, L. H. (2000). Preventing strategic manipulation in iterative auctions:
In AAAI Conference on artiﬁcial intelligence (pp.

Proxy agents and price-adjustment.
82–89).

P¨orn, I. (1977). Action theory and social science: Some formal models. Springer.
Poulin, R. (2010). Parasite manipulation of host behavior: an update and frequently asked

questions. Advances in the Study of Behavior , 41 , 151–186.

Raz, J. (1986). The morality of freedom. Clarendon Press.
Resnick, P., & Sami, R. (2008). Manipulation-resistant recommender systems through inﬂuence

limits. ACM SIGecom Exchanges, 7 (3), 10.

Rigotti, E.

(2005). Towards a typology of manipulative processes.

In L. de Saussure &
P. Schulz (Eds.), Manipulation and ideologies in the twentieth century: discourse, language,
mind (pp. 61–83). John Benjamins Publishing Company.

Robinson, M. S. (1985). Collusion and the choice of auction. RAND Journal of Economics,

43

16 (1), 141–145.

Rosenberg, M., & Pearlin, L. I. (1962). Power-orientations in the mental hospital. Human

Relations, 15 (4), 335–349.

Ruan, Y., & Durresi, A. (2016). A survey of trust management systems for online social
communities – trust modeling, trust inference and attacks. Knowledge-Based Systems, 106 ,
150–163.

Rudinow, J. (1978). Manipulation. Ethics, 88 (4), 338–347.
Saint Clair, H. R. (1966). Manipulation. Comprehensive Psychiatry, 7 (4), 248–258.
Sakama, C. (2021). Deception in epistemic causal logic. In S. Sarkadi, B. Wright, P. Mas-
ters, & M. P. (Eds.), Deceptive AI. DeceptECAI 2020, DeceptAI 2021. Communications in
Computer and Information Science (Vol. 1296, pp. 105–123). Springer.

Sakama, C., Caminada, M., & Herzig, A.
Journal of the IGPL, 23 (2), 259–294.

(2015). A formal account of dishonesty. Logic

Sanghvi, S., & Parkes, D.

(2004). Hard-to-manipulate VCG-based auctions (Tech. Rep.).

Division of Engineering and Applied Sciences: Harvard University.

Santos, F., & Carmo, J. (1996). Indirect action, inﬂuence and responsibility. In Deontic logic,

agency and normative systems (pp. 194–215). Springer.

Schipper, B. (2014). Awareness. In H. van Ditmarsch, J. Y. Halpern, W. van der Hoek, &

B. Kooi (Eds.), Handbook of epistemic logic (pp. 77–146). College Publications.

Segerberg, K., Meyer, J.-J., & Kracht, M. (2009). The logic of action. Stanford Library of

Philosophy.

Singh, A., Ngan, T.-W., Druschel, P., & Wallach, D.

(2006). Eclipse attacks on overlay
networks: Threats and defenses. In 25th International Conference on Computer Communi-
cations.

Sorlin, S. (2017). The pragmatics of manipulation: Exploiting im/politeness theories. Journal

of Pragmatics, 121 , 132–146.

Stalnaker, R. (2006). On logics of knowledge and belief. Philosophical Studies, 128 (1), 169–

199.

Strauss, N. (2006). The game. Canongate Books.
Sunstein, C. R. (2015). Fifty shades of manipulation. Journal of Marketing Behavior , 213 .
Todd, P. (2013). Manipulation. International Encyclopedia of Ethics.
Troquard, N. (2014). Reasoning about coalitional agency and ability in the logics of “bringing-

it-about”. Autonomous Agents and Multiagent Systems, 28 (3), 381–407.

Turner, J. A., Deyo, R. A., Loeser, J. D., Von Korﬀ, M., & Fordyce, W. E. (1994). The
importance of placebo eﬀects in pain treatment and research. Journal of the American
Medical Association, 271 (20), 1609–1614.

Vall´ee, T., & Bonnet, G. (2015). Using KL divergence for credibility assessment.

In 14th
International conference on autonomous agents and multiagent Systems (pp. 1797–1798).
Van Dijk, T. A. (2006). Discourse and manipulation. Discourse & Society, 17 (3), 359–383.
Van Ditmarsch, H., Van Der Hoek, W., & Kooi, B. (2007). Dynamic epistemic logic. Springer

Science & Business Media.

van der Hoek, W., Iliev, P., & Wooldridge, M. J. (2012). A logic of revelation and concealment.

In Aamas (pp. 1115–1122).

Van Ditmarsch, H., French, T., Vel´azquez-Quesada, F. R., & W´ang, Y. N. (2018). Implicit,

explicit and speculative knowledge. Artiﬁcial Intelligence, 256 , 35–67.

Van Ditmarsch, H., Van Eijck, J., Sietsma, F., & Wang, Y. (2012). On the logic of lying.
In J. van Eijck & R. Verbrugge (Eds.), Games, actions and social software (pp. 41–72).
Springer.

Wagner, A. R., & Arkin, R. C. (2009). Robot deception: recognizing when a robot should de-
ceive. In International symposium on computational intelligence in robotics and automation
(pp. 46–54).

Ware, A. (1981). The concept of manipulation: its relation to democracy and power. British

Journal of Political Science, 11 (2), 163–181.

Whiten, A., & Byrne, R. W. (1988). Tactical deception in primates. Behavioral and Brain

44

Sciences, 11 (2), 233–244.

Wilkinson, T. M. (2013). Nudging and manipulation. Political Studies, 61 (2), 341–355.
Wood, A. W. (2014). Coercion, manipulation, exploitation. In C. Coons & M. Weber (Eds.),

Manipulation: Theory and practice (pp. 17–50). Oxford University Press.

45

Appendix A. Soundness, completeness and theorems of KBE

In this appendix, we ﬁrstly prove some theorems on the KBE semantics constraints.
Then we demonstrate that the axiomatic system presented in Figure 4 is correct. Then,
we demonstrate that this axiomatic system is complete. We show that it veriﬁes the
deduction theorems and that it is strongly correct and strongly complete. Finally, we
give the proofs of the theorems with a Hilbert system.

A.1. Theorems on semantic constraints

Proposition 4.1. If (Ed
Kripke structure that the following property holds:

KN ) and (Ed

KP ) hold at the same time, then it implies on the

∀w ∈ W : E d

i (w) =

(cid:92)

E d
i (v) =

(cid:91)

E d
i (v)

v∈W:wKiv

v∈W:wKiv

(Ed

KN ) + (Ed

KP )

Proof. Let assume a frame C s.t. (Ed
obviously implies that:

KP ) and (Ed

KN ) hold. Let us remark that (Ed

KP )

∀w ∈ W : E d

i (w) ⊆

(cid:92)

E d
i (v) ⊆

(cid:91)

E d
i (v)

(Ed

KP )

v∈W:wKiv

v∈W:wKiv

Then, since for all sets E, F , (E ⊆ F ∧ ∀e, e (cid:54)∈ E ⇒ e (cid:54)∈ F ) ⇐⇒ E = F 10, and since
KN ) holds, we thus deduce:

(Ed

∀w ∈ W : E d

i (w) =

(cid:91)

E d
i (v)

v∈W:wKiv

Then, with (Ed

KP ) we prove the complete theorem :

∀w ∈ W :

(cid:91)

i (v) = E d
E d

i (w) ⊆

(cid:92)

E d
i (v)

v∈W:wKiv

v∈W:wKiv

(Ed

KN ) + (Ed

KP )

Consequently:

∀w ∈ W : E d

i (w) =

(cid:92)

E d
i (v) =

(cid:91)

E d
i (v)

v∈W:wKiv

v∈W:wKiv

Proposition 4.2.

(1) If (Ed

KP ) holds and Ki is reﬂexive, then:

∀w ∈ W, E d

i (w) =

(cid:92)

E d
i (v)

v∈W:wKiv

10It is an obvious theorem of the theory of set. Let E, F be two sets. (⇒) Let assume (E ⊆ F ∧ ∀e, e (cid:54)∈ E ⇒
e (cid:54)∈ F ). W have E ⊆ F and so, let us show that F ⊆ E. Let f ∈ F . Since ∀e, e (cid:54)∈ E ⇒ e (cid:54)∈ F is equivalent,
by contraposition, to ∀e, e ∈ F ⇒ e ∈ E, we deduce that f ∈ E. So E = F . (⇐) Let us assume E = F , thus
E ⊆ F and F ⊆ E. Thus ∀e, e ∈ F ⇒ e ∈ E and by contraposition, we deduce ∀e, e (cid:54)∈ E ⇒ e (cid:54)∈ F .

46

(2) If (Ed

KN ) holds and Ki is reﬂexive, then:

∀w ∈ W, E d

i (w) =

(cid:91)

E d
i (v)

v∈W:wKiv

Proof.

(1) Let assume a frame C s.t. (Ed

KP ) holds and Ki is reﬂexive, then:

∀w ∈ W, E d

i (w) ⊆

(cid:92)

i (v) ⊆ E d
E d

i (w)

Consequently, ∀w ∈ W, E d

i (w) =

v∈W:wKiv

(cid:84)
v∈W:wKiv

E d
i (v).

(2) Let assume a frame C s.t. (Ed

KN ) holds and Ki is reﬂexive, then:

∀w ∈ W,

(cid:91)

i (v) ⊆ E d
E d

i (w) ⊆

(cid:91)

E d
i (v)

v∈W:wKiv

v∈W:wKiv

Consequently, ∀w ∈ W, E d

i (w) =

(cid:83)
v∈W:wKiv

E d
i (v).

A.2. Soundness

This section aims to demonstrate the correctness of our KBE system. Thus, in the
sequel we consider any frame C = (W, {Bi}i∈N , {Ki}i∈N , {Ei}i∈N , {E d

i }i∈N ).

A.2.1. Normal modalities

It is well known that the semantics of a normal modality of a S5 system that preserves
validity is an equivalence relation Blackburn et al. (2002). Since the relation Ei is an
equivalence relation, the rules of S5 preserve the validity. Then a relation Ki which is
reﬂexive, transitive and conﬂuent is sound with a S4.2 system. Let us recall a proof
method to show that conﬂuence corresponds to the axiom 4.2.

Proposition A.1. Ki is conﬂuent if, and only if, C |= (cid:104)Ki(cid:105)Kip ⇒ Ki(cid:104)Ki(cid:105)ϕ

Proof. (⇒) Let us suppose a frame C (cid:54)|= (cid:104)Ki(cid:105)Kip ⇒ Ki(cid:104)Ki(cid:105)p, i.e. there exists a
model M on C and a world w ∈ W s.t. M, w |= (cid:104)Ki(cid:105)Kip ∧ ¬Ki(cid:104)Ki(cid:105)p. Thus, there
exists u ∈ W, wKiu and v ∈ W, wKiv such that M, u |= Kip and M, v |= ¬(cid:104)Ki(cid:105)p. So
for all z1 ∈ W, uKiz1, M, z1 |= p and for all z2 ∈ W, vKiz2, M, z2 |= ¬p. Therefore
z1 (cid:54)= z2 and Ki is not conﬂuent.

(⇐) By contraposition, let us suppose a frame C s.t. Ki is not conﬂuent i.e.

∃w, u, v ∈ W : wKiu ∧ wKiv∧ (cid:54) ∃z ∈ W : uKiz ∧ vKiz

Let us assume M on C s.t. M, w |= (cid:104)Ki(cid:105)Kip, V (p) = W \ Ki(u). Thus, M, u |= Ki¬p
i.e. M, u |= ¬(cid:104)Ki(cid:105)p. Since wKiu, we have M, w |= (cid:104)Ki(cid:105)¬(cid:104)Ki(cid:105)p i.e. M, w |= ¬Ki(cid:104)Ki(cid:105)p.

47

Consequently, we have proved, there exists M on C s.t. M, w |= (cid:104)Ki(cid:105)Kip ∧ ¬Ki(cid:104)Ki(cid:105)p
i.e. C (cid:54)|= (cid:104)Ki(cid:105)Kip ⇒ Ki(cid:104)Ki(cid:105)ϕ

Concerning the inference rules between the modality Ki and Bi, Stalnaker (2006)
showed they are valid in our logical frame. Moreover, it is well known that a serial,
transitive and Euclidean relation preserves the validity of a KD45 system for the
modality Bi.

A.2.2. Non standard properties

In this section, we focus on the non-standard properties associated with our neighbor-
hood semantics for the relation E d
i . Some of these properties may be found in Pacuit
(2017) but not all. Thus, in the interest of rigor, we demonstrate all non standard
properties in this section.

Firstly the axiom (C) is valid in KBE.

Proposition A.2.

C |= Ed

i ϕ ∧ Ed

i ψ ⇒ Ed

i (ϕ ∧ ψ)

if, and only if,

∀w ∈ W : S ∈ E d

i (w) ∧ T ∈ E d

i (w) =⇒ S ∩ T ∈ E d

i (w)

Proof. (⇒) By contraposition, let be a frame C such that : ∃w ∈ W : S ∈ E d
E d
i (w) ∧ S ∩ T (cid:54)∈ E d
V (q) = T . Thus, M, w |= Ed
However since S ∩ T (cid:54)∈ E d
M, w (cid:54)|= Ed

i (w). Let us assume M, w s.t. M, w |= Ed

i (w), we have ||p|| ∩ ||q|| (cid:54)∈ E d

i (w) and M, w |= Ed

i (w)∧T ∈
i q, V (p) = S and
i (w).
i (w) i.e.

i (w) and so ||p ∧ q|| (cid:54)∈ E d

i p i.e. ||p|| ∈ E d

i q i.e. ||p|| ∈ E d

i p ∧ Ed

(⇐) Let us assume that C (cid:54)|= Ed

i (p ∧ q), i.e. there exists a model M
i (p ∧ q). So ||p|| ∈ Ei(w)
i (w) i.e
i (w). Thus, we prove that there exists a world w ∈ W, S ∈ Ei(w) ∧ T ∈

and a world w ∈ W such that M, w |= Ed
and ||q|| ∈ Ei(w). Moreover, as M, w |= ¬Ed
||p|| ∩ ||q|| (cid:54)∈ E d
Ei(w) ∧ S ∩ T (cid:54)∈ Ei(w).

i (p ∧ q), we have ||p ∧ q|| (cid:54)∈ E d

i q ∧ ¬Ed

i q ⇒ Ed

i p ∧ Ed

i p ∧ Ed

i (p ∧ q).

The necessitation does not hold for the modality of deliberate eﬀects.

Proposition A.3.

C |= ¬Ed

i (cid:62)

if, and only if,

∀w ∈ W : W (cid:54)∈ E d

i (w)

Proof. Let us suppose a frame C |= ¬Ed
M, w |= ¬Ed

i (cid:62) if, and only if, ∀w ∈ W, ||(cid:62)|| (cid:54)∈ Ei(w) i.e. ∀w ∈ W, W (cid:54)∈ Ei(w).

i (cid:62). As ||(cid:62)|| = W, it follows ∀M, ∀w ∈ W :

The deliberate eﬀects has positive introspection with knowledge.

48

Proposition A.4.

C |= Ed

i p ⇒ KiEd
i p

if, and only if,

∀w ∈ W : E d

i (w) ⊆

(cid:92)

E d
i (v)

v∈W:wKiv

i (w) \ (cid:84)

i (v). First,

v∈W:wKiv E d

v∈W:wKiv E d

v∈W:wKiv E d

v∈W:wKiv E d

let us notice that necessary E d

i (v). Thus there exists X ∈ E d

Proof. (⇒) By contraposition,
i (w) (cid:54)⊆ (cid:84)
E d
∅ ⊆ (cid:84)
and X (cid:54)∈ (cid:84)
i (w) \ (cid:84)
E d
X (cid:54)∈ (cid:84)
v∈W:wKiv E d
Thus, M, w |= (cid:104)Ki(cid:105)¬Ed

let us assume a frame C such that ∃w ∈ W :
i (w) (cid:54)= ∅ since
i (w)
i (v). Second, let M be a model on C such that X = V (p) ∈
i p. Furthermore since
i p.
i p and so, C (cid:54)|= Ed
i p.
i p, i.e. there exists a model M and a world
i p. So, we have that ||p|| ∈ E d
i (w). Moreover,
i (v). So, we deduce

i (v)11 i.e. M, v |= ¬Ed
i p ⇒ KiEd

i (v), we have there exists v ∈ Ki(w), X (cid:54)∈ E d
i p. Consequently, M, w |= ¬KiEd

(⇐) Let us assume C (cid:54)|= Ed
w ∈ W such that M, w |= Ed
there exists v ∈ W such that: wKiv and M, v |= ¬Ed
that :

i (w), we have M, w |= Ed

i p ⇒ KiEd
i p ∧ ¬KiEd

i (v). As ||p|| ∈ E d

i (v) i.e. X ∈ E d

i p, i.e. ||p|| (cid:54)∈ E d

v∈W:wKiv E d

||p|| (cid:54)∈

(cid:92)

E d
i (v)

v∈W:wKiv

Consequently, we have proved that:

∃w ∈ W : E d

i (w) (cid:54)⊆

(cid:92)

E d
i (v)

v∈W:wKiv

The deliberate eﬀects has negative introspection with knowledge.

Proposition A.5.

C |= ¬Ed

i p ⇒ Ki¬Ed
i p

if, and only if,

∀w, v ∈ W, ∀S ∈ 2W : S (cid:54)∈ E d

i (w) =⇒ (wKiv ⇒ S (cid:54)∈ E d

i (v))

Proof. (⇒) By contraposition, let us assume a frame C such that :

∃w, v ∈ W, ∃S ∈ 2W : S (cid:54)∈ E d

i (w) ∧ wKiv ∧ S ∈ E d

i (v)

Let us deﬁne a model M on C s.t. V (p) = S. As ||p|| (cid:54)∈ E d
M, w |= ¬Ed

i (v), we have M, v |= Ed

i p. As ||p|| ∈ E d

i (w), we directly have
i p. Furthermore, since wKiv,

11X ∈ (cid:84)

v∈W:wKiv E d

i (v) iﬀ ∀v ∈ Ki(w), X ∈ E d

i (v). Thus, X (cid:54)∈ (cid:84)

v∈W:wKiv E d

i (v) iﬀ ∃v ∈ Ki(w), X (cid:54)∈ E d

i (v)

49

i p i.e. M, w |= ¬Ki¬Ed

we deduce that M, w |= (cid:104)Ki(cid:105)Ed
¬Ed
i p ∧ ¬Ki¬Ed
and so C (cid:54)|= ¬Ed

i p. We have proved that there exists a model M (cid:54)|= ¬Ed
i p ⇒ Ki¬Ed

i p.
(⇐) Let us suppose by contraposition C (cid:54)|= ¬Ed
model M and a world w ∈ W such that M, w |= ¬Ed
i p ∧ ¬Ki¬Ed
Moreover, there exists v ∈ W such that wKiv and M, v |= Ed
Consequently, for S = ||p||, we can conclude that:

i p ⇒ Ki¬Ed

i p, i.e. there exists a
i p. So ||p|| (cid:54)∈ E d
i (w).
i p, i.e ||p|| ∈ E d
i (v).

i p. Consequently, M, w |=
i p ⇒ Ki¬Ed
i p

∃w, v ∈ W, ∃S ∈ 2W : S (cid:54)∈ E d

i (w) ∧ wKiv ∧ S ∈ E d

i (v)

There is logical link between deliberate eﬀects and eﬀects of actions.

Proposition A.6.

C |= Ed

i p ⇒ Eip

if, and only if,

∀w ∈ W, ∀S ∈ 2W : S ∈ E d

i (w) =⇒ Ei(w) ⊆ S

i (w) and so M, w |= Ed

Proof. (⇒) By contraposition, let us suppose a frame C such that : ∃w ∈ W, ∃S ∈
2W : S ∈ E d
i (w) ∧ Ei(w) (cid:54)⊆ S. Let us consider a model M on C s.t. V (p) = S. So,
we have, ||p|| ∈ E d
i p. Furthermore, as Ei(w) (cid:54)⊆ S, there exists
v ∈ Ei(w) \ S, and so M, v |= ¬p (since S = ||p||). We deduce that since wEiv we have
M, w |= (cid:104)Ei(cid:105)¬p i.e. M, w |= ¬Eip. We have M, w |= Ed
i p ∧ ¬Eip. Consequently, we
can conclude that there exists M satisfying the constraint of the frame C such that
M (cid:54)|= Ed

i p ⇒ Eip.
i p ⇒ KiEd
(⇐) Let us suppose C (cid:54)|= Ed
i p, i.e. there exists a model M and a world
w ∈ W such that M, w |= Ed
i p ∧ ¬Eip. So ||p|| ∈ E d
i (w) and there exists v ∈ W s.t.
wEiv and M, v |= ¬p. By deﬁnition, we have v (cid:54)∈ ||p||. Consequently, for S = ||p||, we
prove that ∃(w, S) ∈ W × 2W : S ∈ E d

i p ⇒ Eip, and so C (cid:54)|= Ed

i (w) ∧ Ei(w) (cid:54)⊆ S.

A.2.3. Soundness properties

In this section, we give the complete proof of soundness.

Theorem 4.4. The KBE system is sound.

Proof. In order to show soundness, we have to show that substitution, modus ponens,
necessitation, (RE) and (DUAL) preserve the validity for all modalities.

(1) Let us prove that substitution preserves validity. Let ϕ ∈ LKBE be a formula
and pa1, . . . , pan ∈ P be propositional atoms that are contained in ϕ. We deﬁne θ =
ϕ(ψ1/pa1, . . ., ψn/pan) the obtained formula after an uniform substitution on ϕ and
ψ1, . . . , ψn ∈ LKBE formulas. We want to prove that if ϕ is valid in C, then θ is
also valid in C. By contraposition let us assume that C (cid:54)|= θ. So there exists a model
M = (C, h) and a world w ∈ W such that: M, w (cid:54)|= θ. Let us build a model for ϕ,
M(cid:48) = (C, h(cid:48)) such that:

• ∀j ∈ N : 1 ≥ j ≥ n, M, w |= ψj =⇒ w ∈ h(cid:48)(paj )

50

• ∀j ∈ N : 1 ≥ j ≥ n, M, w (cid:54)|= ψj =⇒ w /∈ h(cid:48)(paj )
• ∀p ∈ P : ∀j ∈ N : p (cid:54)= paj , w /∈ h(cid:48)(p)12

Since M, w (cid:54)|= θ, we have that the combination of ψj invalidate formula θ in M, w.
Since for all ψj we associate an atom paj language with the same truth value as the
formula as ψj. The combination of paj invalidate the formula ϕ in M(cid:48), w. Thus, we
have M(cid:48), w (cid:54)|= ϕ. It has therefore been well proven by contraposition that substitution
preserves validity, i.e. if ϕ is valid in C then its substitution ψ is also valid in C.

(2) Let us prove that modus ponens preserves validity. Let us suppose C |= ϕ and
C |= (ϕ ⇒ ψ). So for all models M and for all worlds w, we have M, w |= ϕ and
M, w |= ϕ ⇒ ψ, i.e. M, w |= ϕ ∧ (¬ϕ ∨ ψ), i.e M, w |= (ϕ ∧ ¬ϕ) ∨ (ϕ ∧ ψ), so
M, w |= (ϕ ∧ ψ), i.e. M, w |= ϕ and M, w |= ψ. So M, w |= ψ. Therefore it has been
proven that for all models M and for all worlds w, ψ is valid, i.e. C |= ψ.

(3) Let us prove that necessitation preserves validity for all

((cid:3), R) ∈
{(Bi, Bi), (Ki, Ki), (Ei, Ei)}. Let ϕ be a tautology, so for all models M and ∀v ∈
W, M, v |= ϕ. So ∀w, v ∈ W, wRv : M, v |= ϕ, i.e. ∀w ∈ W, M, w |= (cid:3)ϕ. We prove
that if C |= ϕ, then C |= (cid:3)ϕ. Consequently, necessitation preserves validity.

(4) Let us prove that the rule (RE) preserves validity for Ed
i

i.e.:

If |= ϕ ⇔ ψ then |= Ed

i ϕ ⇔ Ed

i ψ

Let us assume |= ϕ ⇔ ψ. We have |= Ed

i ϕ if, and only if, for all (M, w), M, w |= Ed

i.e. for all (M, w), ||ϕ||M ∈ E d
|= ϕ ⇔ ψ, we have for all (M(cid:48), w(cid:48)), ||ϕ||M(cid:48) = ||ψ||M(cid:48)) iﬀ |= Ed
prove that if |= ϕ ⇔ ψ then |= Ed

i (w) if, and only if, for all (M, w), ||ψ||M ∈ E d

i ψ i.e. (RE) preserves validity.

i ϕ ⇔ Ed

i ϕ
i (w) (since
i ψ. Consequently, we

(5) Let us prove that the rule (DUAL) preserves validity for Ed
i

i.e.:

|= Ed

i ϕ ⇔ ¬(cid:104)Ed

i (cid:105)¬ϕ

For all models M and for all worlds w ∈ W such that M, w |= Ed

i ϕ. We just have
to notice that ||ϕ||M = W \ (W \ ||ϕ||M) and ||¬ϕ||M = W \ ||ϕ||M. Then, we have
M, w |= Ed
i (w) iﬀ W \ (W \ ||ϕ||M) ∈ E d
i (cid:105)¬ϕ iﬀ
M, w |= ¬(cid:104)Ed

i (cid:105)¬ϕ. Consequently (DUAL) preserves validity.

i (w) iﬀ M, w (cid:54)|= (cid:104)Ed

i ϕ iﬀ ||ϕ||M ∈ E d

A.3. Completeness

In this section we prove the completeness of the logic KBE by using maximal consistent
sets. Firstly, we deﬁne maximal consistent sets for KBE. Secondly, we give the proof
of the completeness.

A.3.1. Deﬁnition of a deductible system

We recall in this section the notion of deductible system which is used in this article
to prove later the strongly completeness.

12Since p is not an atom involved in the substitution, regardless if w /∈ h(cid:48)(p) or w ∈ h(cid:48)(p), it will not aﬀect the
demonstration. We are just making sure we have got the right model here.

51

A.3.2. Deduction theorems

We talk about KBE-deductibility when a formula ϕ can be deduced from a set Σ of
formulas.

Deﬁnition A.7 (KBE-deductibility). Let Σ be a set formulas in KBE and ϕ be a
formula. We say that ϕ is a KBE-deduction from Σ and we write Σ (cid:96) ϕ if, and only if:

(1) If Σ = ∅, then (cid:96) ϕ ;
(2) Otherwise ∃ψ1, . . . , ψn ∈ Σ with n ∈ N∗ and (cid:96) ψ1 ∧ . . . ∧ ψn ⇒ ϕ.

If Σ (cid:96) ϕ is veriﬁed, then ϕ is KBE-deductible.

The KBE-deductibility has various fundamental properties such as reﬂexivity, tran-

sitivity, and left weakening.

Proposition A.8. Let Σ and Γ be two sets of formulas in KBE. It holds:

(1) Reﬂexivity holds i.e. if ϕ ∈ Σ, then Σ (cid:96) ϕ
(2) Transitivity holds i.e. if Σ (cid:96) ϕ and {ϕ} (cid:96) ψ, then Σ (cid:96) ψ
(3) Left weakening holds i.e. if Σ (cid:96) ϕ and Σ ⊆ Γ, then Γ (cid:96) ϕ

Proof. Let Σ and Γ be two non-empty sets of formulas in KBE.

(1) If ϕ ∈ Σ, then since (cid:96) ϕ ⇒ ϕ, by deﬁnition of KBE-deductibility, we have Σ (cid:96) ϕ.
(2) If Σ (cid:96) ϕ and {ϕ} (cid:96) ψ, then there exists ψ1, . . . , ψn ∈ Σ with n ∈ N∗ such that:

(cid:94)

(cid:96) (

ψk) ⇒ ϕ

k∈{1,...,n}

Furthermore since {ϕ} (cid:96) ψ, by deﬁnition we have (cid:96) ϕ ⇒ ψ. Thus, we deduce:

(cid:94)

(cid:96) (

ψk) ⇒ ψ

k∈{1,...,n}

Consequently, we prove that Σ (cid:96) ψ.

(3) If Σ (cid:96) ϕ and Σ ⊆ Γ, then there exists ψ1, . . . , ψn ∈ Σ with n ∈ N∗ such that:

(cid:94)

(cid:96) (

ψk) ⇒ ϕ

k∈{1,...,n}

Since ψ1, . . . , ψn ∈ Σ and Σ ⊆ Γ, we have ψ1, . . . , ψn ∈ Γ. Thus, we prove that
Γ (cid:96) ϕ.

We prove now the deduction theorem of KBE. We ﬁrst recall the deﬁnition of a

model of a set of formula.

Deﬁnition A.9. Let Σ be a set of formulas and ϕ be a formula. Σ semantically entails
ϕ, written Σ |= ϕ if, and only if, for all models M of Σ (i.e. ∀ψ ∈ Σ, M |= ψ), M |= ϕ.

Theorem A.10 (Deduction theorems).

52

If Γ is a set of formulas in KBE, ϕ and ψ be two formulas of KBE, then:

(1) Γ ∪ {ψ} (cid:96) ϕ if, and only if, Γ (cid:96) ψ ⇒ ϕ

If Γ is a set of formulas in KBE, ϕ and ψ be two formulas of KBE, then:

(2) Γ ∪ {ψ} |= ϕ if, and only if, Γ |= ψ ⇒ ϕ

Proof. Let Γ ⊆ LKBE be a set of formulas, ϕ and ψ be two formulas of LKBE.

(⇒) Let us assume that Γ ∪ {ψ} (cid:96) ϕ. By deﬁnition of the KBE-deductibility, we

have that there exists Σ = {ψ1, . . . , ψn}, Σ ⊆ Γ ∪ {ψ} such that:

(cid:94)

(cid:96)

ψi ⇒ ϕ

i∈{1,...,n}

We have two cases to consider ψ ∈ Σ and when ψ (cid:54)∈ Σ.

(
k∈{1,...,n}\{i}
(cid:96)

(cid:86)

(1) If ψ ∈ Σ, then there exists i ∈ {1, . . . , n} such that ψ = ψi. So (cid:96)
ψk) ∧ ψ ⇒ ϕ by commutativity and by associativity of ∧. Then,

(cid:86)

ψk ⇒ (ψ ⇒ ϕ). However for all k ∈ {1, . . . , n} \ {i}, ψk ∈ Σ and

k∈{1,...,n}\{i}

so ψk ∈ Γ by inclusion. Consequently, we prove that Γ (cid:96) ψ ⇒ ϕ.

(2) If ψ (cid:54)∈ Σ, then for all i ∈ {1, . . . , n}, ψi (cid:54)= ψ. We have

(cid:94)

(cid:96)

ψk ⇒ ϕ

k∈{1,...,n}

Or since (cid:96) ϕ ⇒ (ψ ⇒ ϕ) is a PC axiom, we immediately deduce:

(cid:94)

(cid:96)

k∈{1,...,n}

ψk ⇒ (ψ ⇒ ϕ)

Consequently, since for all k ∈ {1, . . . , n}, ψk ∈ Σ and so ψk ∈ Γ by inclusion.
Thus, Γ (cid:96) ψ ⇒ ϕ.

(⇐) Let us assume that Γ (cid:96) ψ ⇒ ϕ. So there exists Σ = {ψ1, . . . , ψn}, Σ ⊆ Γ such

that:

Thus,

(cid:94)

(cid:96)

i∈{1,...,n}

ψi ⇒ (ψ ⇒ ϕ)

(cid:94)

(cid:96)

i∈{1,...,n}

ψi ∧ ψ ⇒ ϕ

is a theorem. So we deduce that Σ ∪ {ψ} (cid:96) ϕ. But since Σ ⊆ Γ, by left weakening, we
immediately deduce that Γ ∪ {ψ} (cid:96) ϕ.

The semantic version (2) of the deduction theorem immediately follows:

53

Γ |= ψ ⇒ ϕ iﬀ ( ∀M :

if M |= Γ, then M |= ψ ⇒ ϕ) iﬀ ∀M : M |= Γ ⇒ (ψ ⇒ ϕ)
iﬀ ∀M : M |= ¬Γ ∨ ¬ψ ∨ ϕ iﬀ ∀M : M |= ¬(Γ ∧ ψ) ∨ ϕ iﬀ ∀M : M |= (Γ ∧ ψ) ⇒ ϕ iﬀ
(∀M :

if M |= Γ ∪ {ψ}, then M |= ϕ) iﬀ Γ ∪ {ψ} |= ϕ.

A.3.3. Maximal KBE-consistent sets

First of all let us recall some well-known results about maximal consistent sets. A set
of formulas Σ is inconsistent if, and only if, ∃ψ1, . . . , ψn ∈ Σ :(cid:96) ¬ (cid:86)n
i=1 ψi. A set of
formulas Σ is consistent iﬀ Σ is not inconsistent. A set of formulas Γ is a maximal
consistent iﬀ (cid:64)Γ(cid:48) : Γ (cid:40) Γ(cid:48), Γ(cid:48) consistent. It leads us to the well-known Lindenbaum’s
lemma: for all consistent sets of formulas Γ , there exists a set of formulas Γ(cid:48) s.t Γ ⊆ Γ(cid:48)
and Γ(cid:48) is a maximal consistent set (MCS). Let us consider a MCS Γ and ϕ, ψ ∈ LKBE
two formulas:

(1) MCS1: Γ (cid:96) ϕ =⇒ ϕ ∈ Γ
(2) MCS2: (ϕ ∈ Γ ∨ ¬ϕ ∈ Γ) ∧ ¬(ϕ ∈ Γ ∧ ¬ϕ ∈ Γ)
(3) MCS3: (ϕ ∨ ψ ∈ Γ) ⇐⇒ ϕ ∈ Γ or ψ ∈ Γ
(4) MCS3’: (ϕ ∧ ψ ∈ Γ) ⇐⇒ ϕ ∈ Γ and ψ ∈ Γ
(5) MCS4: [(ϕ ⇒ ψ ∈ Γ) ∧ (ϕ ∈ Γ)] =⇒ ψ ∈ Γ
(6) MCS5: (cid:96) ϕ iﬀ ∀Γ is a MCS , ϕ ∈ Γ

A.3.4. Canonical models

In order to prove that our system is complete, we are doing a Henkin-like proof. Thus,
we need to deﬁne the canonical model for our non normal system Pacuit (2017).

Deﬁnition A.11. A model Mc = (W c, {Bc
i }i∈N , {E c
is the canonical model for KBE if, and only if Mc is such that:

i }i∈N , {Kc

i }i∈N , {E dc

i }i∈N , V c)

• W c is a non-empty set of worlds where each world is a MCS,
• For all (Rc, (cid:3)) ∈ {(Bc

i , Bi), (Kc

i , Ki), (E c

i , Ei)}i∈N :

∀i ∈ N , ∀w, v ∈ W : wRcv if, and only if, (cid:3)ϕ ∈ w ⇒ ϕ ∈ v

• {E dc

i }i∈N is a set of neighborhood functions such that:

∀i ∈ N , ∀w ∈ W c : E dc

i (w) := {|ϕ| : Ed

i ϕ ∈ w} with |ϕ| := {w|w ∈ W c ∧ ϕ ∈ w}

• V c : P → 2W is an interpretation function such that ∀p ∈ P, w ∈ V c(p) if, and

only if, p ∈ w, i.e.:

∀p ∈ P, V c(p) = |p| with |p| := {w|w ∈ W c ∧ p ∈ w}

The part E dc

i of the canonical model for KBE corresponds to the notion of minimal
canonical model for neighborhood semantics described in Pacuit (2017). In the sequel,
we use the following notations, for all i ∈ N , w ∈ W c:

• K∗
• B∗
• E ∗

i (w) := {ϕ|Kiϕ ∈ w}
i (w) := {ϕ|Biϕ ∈ w}
i (w) := {ϕ|Eiϕ ∈ w}

54

A.3.5. Truth lemma

Let Mc = (W c, {Bc
model for KBE.

i }i∈N , {Kc

i }i∈N , {E c

i }i∈N , {E dc

i }i∈N , V c) be a minimal canonical

Lemma A.12. Let i, j ∈ N and ϕ ∈ LKBE be a formula,

(1) ∀w ∈ W c : ¬Kiϕ ∈ w ⇒ K∗
(2) ∀w ∈ W c : ¬Biϕ ∈ w ⇒ B∗
(3) ∀w ∈ W c : ¬Eiϕ ∈ w ⇒ E ∗

i (w) ∪ {¬ϕ} is KBE-consistent
i (w) ∪ {¬ϕ} is KBE-consistent
i (w) ∪ {¬ϕ} is KBE-consistent

i }, (cid:3) ∈ {Ki, Bi, Ei} and ϕ ∈ LKBE be
Proof. Let w ∈ W c, i, j ∈ N , R ∈ {Kc
i , Bc
a formula. Let us assume by contraposition that R∗(w) ∪ {¬ϕ} is KBE-inconsistent.
There exists n ∈ N and ψ1, . . . , ψn ∈ R∗(w) such that:

k=1

k=1 ψk ⇒ ϕ

(cid:3)ψk ∧ ¬(cid:3)ϕ)

k=1 ψk ∧ ¬ϕ)
k=1 ψk ∨ ¬¬ϕ

k=1 ψk ⇒ ϕ)
k=1 ψk ⇒ (cid:3)ϕ)
(cid:3)ψk ⇒ (cid:3)ϕ)

(1) (cid:96) ¬((cid:86)n
(2) (cid:96) ¬ (cid:86)n
(3) (cid:96) (cid:86)n
(4) (cid:96) (cid:3)((cid:86)n
(5) (cid:96) ((cid:3) (cid:86)n
(6) (cid:96) ((cid:86)n
k=1
(7) (cid:96) ¬((cid:86)n
So {(cid:3)ψ1, . . . , (cid:3)ψn, ¬(cid:3)ϕ} is KBE-inconsistent. However ∀k ∈ {1, . . . , n}, ψk ∈
R∗(w) if, and only if, (cid:3)ψk ∈ w and w is a maximal KBE-consistent set.
Thus, (cid:86)n
(cid:3)ψk ∈ w (MCS3’) and so {(cid:3)ψ1, . . . , (cid:3)ψn} is KBE-consistent. But
{(cid:3)ψ1, . . . , (cid:3)ψn} ∪ {¬(cid:3)ϕ} is KBE-inconsistent. So ¬(cid:3)ϕ cannot belong to the set
of maximal KBE-consistent formulas w. Indeed by reductio ad absurdum,
if we
have ¬(cid:3)ϕ ∈ w, we would also have that (cid:86)n
(cid:3)ψk ∧ ¬(cid:3)ϕ ∈ w (by MCS3’),
and {(cid:3)ψ1, . . . , (cid:3)ψn, ¬(cid:3)ϕ} would be KBE-consistent, which is a contradiction. Thus,
¬(cid:3)ϕ /∈ w. Consequently we prove that if ¬(cid:3)ϕ ∈ w, then R∗(w) ∪ {¬ϕ} is KBE-
consistent.

k=1

k=1

Lemma A.13. Let i, j ∈ N and ϕ, ψ ∈ LKBE be a formula,

(1) |ϕ ∧ ψ| = |ϕ| ∩ |ψ|
(2) |¬ϕ| = W c \ |ϕ|
(3) |ϕ ∨ ψ| = |ϕ| ∪ |ψ|
(4) |ϕ| ⊆ |ψ| iﬀ (cid:96) ϕ ⇒ ψ
(5) |ϕ| = |ψ| iﬀ (cid:96) ϕ ⇔ ψ

Proof. See Pacuit (2017).

Lemma A.14. Let w ∈ W c, ϕ, ψ ∈ LKBE.

If |ϕ| = |ψ| and |ϕ| ∈ E dc

i (w) then Ed

i ψ ∈ w

Proof. See Pacuit (2017).

We need a second lemma to demonstrate the completeness of our system. This
lemma shows that any valid formula of the canonical model is a formula of a maximal
KBE-consistent set corresponding to a world in which it is veriﬁed and reciprocally.

The following proofs are based on the degree of formulas. We recall the basic notion

of a degree of a formula.

55

Deﬁnition A.15. We deﬁne deg : LKBE → N the degree function iﬀ for all ϕ, ψ ∈
LKBE:

(1) ∀p ∈ P, deg(p) = 0
(2) deg(¬ϕ) = deg(ϕ) + 1
(3) ∀(cid:3) ∈ {Ki, Bi, Ei, Ed
(4) deg(ϕ ∧ ψ) = max{deg(ϕ), deg(ψ)} + 1
(5) deg(ϕ ∨ ψ) = max{deg(ϕ), deg(ψ)} + 1
(6) deg(ϕ ⇒ ψ) = max{deg(¬ϕ), deg(ψ)} + 1
We say that the degree of a formula ϕ is n ∈ N∗ iﬀ deg(ϕ) = n.

i }, deg((cid:3)ϕ) = deg(ϕ) + 1

Lemma A.16. Let ϕ ∈ LKBE be a formula, for all w ∈ W c :

Mc, w |= ϕ if, and only if, ϕ ∈ w

Proof. Let us reason by recurrence on the degree of a formula.

(Initialization) If ϕ ∈ LKBE is a formula such that deg(ϕ) = 0, i.e. there exists
p ∈ P, ϕ = p. By deﬁnition of a canonical model we have ∀w ∈ W c, w ∈ V (p) if, and
only if, p ∈ w.

(Heredity) Let us assume for all formulas ϕ ∈ LKBE and n ∈ N∗ such that deg(ϕ) <

n, we have for all w ∈ W c, Mc, w |= ϕ if, and only if, ϕ ∈ w.

Let ψ, θ ∈ LKBE such that max(deg(ψ), deg(θ)) = n − 1. So we have for all worlds
w ∈ W c, Mc, w |= ψ iﬀ ψ ∈ w and Mc, w |= θ iﬀ θ ∈ w. Furthermore we have
Mc, w |= ¬ψ iﬀ Mc, w (cid:50) ψ iﬀ ψ /∈ w. Then Mc, w |= ψ ∧ θ iﬀ Mc, w |= ψ and
Mc, w |= θ iﬀ ψ ∈ w and θ ∈ w iﬀ ψ ∧ θ ∈ w (MCS3’). Then Mc, w |= ψ ∨ θ
iﬀ Mc, w |= ψ or Mc, w |= θ iﬀ ψ ∈ w or θ ∈ w iﬀ ψ ∨ θ ∈ w (MCS3). Finally
Mc, w |= ψ ⇒ θ iﬀ Mc, w |= ¬ψ or Mc, w |= θ iﬀ ψ /∈ w or θ ∈ w iﬀ ψ ⇒ θ ∈ w.

Let us consider (R, (cid:3)) ∈ {(Bi, Bi), (Ki, Ki), (Ei, Ei)} and a world w ∈ W c. Let us

show that the equivalence for normal modalities by double implication.

(⇒) Let us assume by contraposition that (cid:3)ψ /∈ w and since w is a maximal KBE-
consistent set, we have ¬(cid:3)ψ ∈ w. By the previous lemma, we have R∗(w) ∪ {¬ψ} is
KBE-consistent and so, by the Lindenbaum’s lemma, there exists v ∈ W c : R∗(w) ∪
{¬ψ} ⊆ v and v is maximal KBE-consistent set. So we have ¬ψ ∈ v and, by deﬁnition
of Rc, we have wRcv. Furthermore, we have ψ /∈ v and, by induction hypothesis
W c, v (cid:50) ψ. So since there exists v ∈ W c : wRcv : v |= ¬ψ, we have Mc, w |= ¬(cid:3)ψ, i.e.
Mc, w (cid:50) (cid:3)ψ.

(⇐) By contraposition, let us assume that Mc, w (cid:50) (cid:3)ψ, i.e. Mc, w |= ¬(cid:3)ψ. So
there exists v ∈ W : wRcv, Mc, v |= ¬ψ. So Mc, v (cid:50) ϕ and by induction hypothesis,
we have ϕ /∈ v. However, since ϕ /∈ v, by deﬁnition of Rc, we have (cid:3)ϕ /∈ w.

Let us now show that equivalence is also veriﬁed when the formula is of the form
i ϕ and such that deg(ϕ) = n. Let us assume that Mc, w |= Ed
Ed
i ϕ. In other words, this
is equivalent to {v|v ∈ W c ∧Mc, v |= ϕ} ∈ E dc
i (w). Applying the induction hypothesis,
we therefore have by equivalence that {v|v ∈ W c ∧ ϕ ∈ v} ∈ E dc
i (w)
with |ϕ| := {v|v ∈ W c ∧ ϕ ∈ v}. Finally, by deﬁnition of the canonical model, this is
equivalent to Ed

i (w), i.e. |ϕ| ∈ E dc

i ϕ ∈ w.

(Conclusion) So we have shown by recurrence that:

∀ϕ ∈ LKBE, ∀w ∈ W c : Mc, w |= ϕ if, and only if, ϕ ∈ w

56

Now that the link between validity and KBE-consistent maximum sets has been
demonstrated, we can prove the link between our canonical model and the proven
formulas in our axiomatic system.

Lemma A.17 (Truth lemma). Let ϕ ∈ LKBE be a formula and w ∈ W c,

Mc, w |= ϕ if, and only if, (cid:96) ϕ

Proof. Let ϕ ∈ LKBE be a formula and w ∈ W c. We have Mc, w |= ϕ iﬀ (by
lemma A.16) ϕ ∈ w iﬀ (by MCS5) (cid:96) ϕ.

A.3.6. Canonical model properties

Let us prove that the canonical model preserves the semantic constraints of KBE. Let
Mc = (W c, {Bc

i }i∈N , V c) be the canonical model.

i }i∈N , {E dc

i }i∈N , {Kc

i }i∈N , {E c

Lemma A.18. The canonical model Mc is a KBE model i.e. the following properties
for the canonical model hold:

i (w) ⊆ (cid:84)

i (w) ∧ Y ∈ E dc

(1) ∀w ∈ W c : X ∈ E dc
(2) ∀w ∈ W c : E dc
v∈W:wKc
(3) ∀w, v ∈ W c, ∀X ∈ 2W : X (cid:54)∈ E dc
(4) ∀w ∈ W c : W c (cid:54)∈ E dc
(5) ∀w ∈ W : X ∈ E dc
(6) Mc respects the constraints for Ki, Bi and Ei

i (w) =⇒ X ∩ Y ∈ E dc
i v E dc
i (w) =⇒ (wKc

i (w) =⇒ (Ei(w) ⊆ X)

i (w)

i (v)

i (w)

i v ⇒ X (cid:54)∈ E dc

i (v))

Proof. (1) Let us ﬁrst show that:

∀w ∈ W c : X ∈ E dc

i (w) ∧ Y ∈ E dc

i (w) =⇒ X ∩ Y ∈ E dc

i (w)

i (w) and Y ∈ E dc

Let w ∈ W c, X ∈ E c

i (w). Then, by deﬁnition, we have Ed
i ψ ∈ w. However (cid:96) Ed

model, there exists ϕ, ψ ∈ LKBE such that X = |ϕ| and Y = |ψ|. Thus, |ϕ| ∈ E dc
and |ψ| ∈ E dc
by MCS3’ we have Ed
MCS5 Ed
i ϕ ∧ Ed
|ϕ ∧ ψ| ∈ E dc
X ∩ Y ∈ E dc

i (w). By deﬁnition of the minimal canonical
i (w)
i ψ ∈ w. Furthermore
i (ϕ ∧ ψ). Thus, by
i (ϕ ∧ ψ) ∈ w. So
i (w). However |ϕ ∧ ψ| = |ϕ| ∩ |ψ| = X ∩ Y . Consequently, we prove that
i (w).
(2) Let us show that:

i (ϕ ∧ ψ) ∈ w and by MCS4, we deduce that Ed

i ϕ ∈ w and Ed
i ϕ ∧ Ed

i ψ ⇒ Ed

i ψ ⇒ Ed

i ϕ ∧ Ed

∀w ∈ W c : E dc

i (w) ⊆

(cid:92)

E dc
i (v)

v∈W:wKc
i v

Let w ∈ W c and X ∈ E dc

i (w). By deﬁnition of E dc
i

i ϕ ⇒ KiEd

i ϕ and, by MCS5, we deduce that Ed

, there exists ϕ ∈ LKBE, X = |ϕ|.
i ϕ ⇒
i ϕ ∈ w. Thus, by deﬁnition of the canonical model, we
i (v),
i (v), i.e.

i ϕ ∈ v, which means that |ϕ| ∈ E dc

i v : X ∈ E dc

i ϕ. So Ed

i v : Mc, v |= Ed

i (v). Consequently, we prove that ∀v ∈ W c, wKc

i ϕ ∈ w. However, (cid:96) Ed
i ϕ ∈ w and, by MCS4, KiEd

So Ed
KiEd
have for all v ∈ W c, wKc
i.e. X ∈ E dc
X ∈ (cid:84)

i v E dc

i (v).

v∈W:wKc

57

(3) Let us show that:

∀w, v ∈ W c, ∀X ∈ 2W : X (cid:54)∈ E dc

i (w) =⇒ (wKc

i v ⇒ X (cid:54)∈ E dc

i (v))

Let w, v ∈ W c s.t. wKc

i v and X (cid:54)∈ E dc

i (w). By deﬁnition of E dc

i (w), there is no ϕ ∈ LKBE such that X = |ϕ| and Ed

since X (cid:54)∈ E dc
means that for all ϕ ∈ LKBE, X = |ϕ| ⇒ Ed
ϕ ∈ LKBE, X = |ϕ| ⇒ ¬Ed

i (w) = {|ϕ| : Ed

i ϕ ∈ w},
i ϕ ∈ w. So, this
i ϕ (cid:54)∈ w, and by MCS2, we have for all

i ϕ ∈ w. Thus, there are two possible cases:
i ϕ ∈ w. However, (cid:96) ¬Ed
i ϕ ∈ w then, by MCS4, Ki¬Ed

i ϕ ⇒ Ki¬Ed

i u, ¬Ed

i ϕ ∈ u. Finally, ∀u ∈ W c s.t. wKc

i u, |ϕ| (cid:54)∈ E dc

i ϕ ⇒ Ki¬Ed
i ϕ
i ϕ ∈ w. Thus,
i (u), and

• If X is of the form X = |ϕ|, then ¬Ed

and, by MCS5, ¬Ed
∀u ∈ W c s.t. wKc
thus X (cid:54)∈ E dc

i (v).

• If X cannot be written as X = |ϕ|, then by using the deﬁnition of the minimal
i ϕ ∈ w}, we deduce that ∀u ∈ W c : X (cid:54)∈

i (w) = {|ϕ| : Ed

canonical model, i.e. E dc
E dc
i (u). So X (cid:54)∈ E dc

i (v).

Consequently, we prove that:

∀w, v ∈ W c, ∀X ∈ 2W : X (cid:54)∈ E dc

i (w) =⇒ (wKc

i v ⇒ X (cid:54)∈ E dc

i (v))

(4) Let us show that:

∀w ∈ W c : W c (cid:54)∈ E dc

i (w)

Let w ∈ W c. We have (cid:96) ¬Ed

i (cid:62) and, by MCS5, we have ¬Ei(cid:62) ∈ w, i.e. |(cid:62)| (cid:54)∈ E dc

i (w).

However, since |(cid:62)| = W c, we deduce that W c (cid:54)∈ E dc

i (w).

(5) Let us show that:

∀w ∈ W : X ∈ E dc

i (w) =⇒ (Ei(w) ⊆ X)

Let w ∈ W c and X ∈ E dc

i (w). By deﬁnition of E dc

i (w) = {|ϕ| : Eiϕ ∈ w}, there
i ϕ ⇒ Eiϕ and, by
i ϕ ⇒ Eiϕ ∈ w, then, by MCS4, we have Eiϕ ∈ w, i.e. Mc, w |= Eiϕ and so
i (w), u ∈ |ϕ|.
i (w) =⇒

i (w), Mc, u |= ϕ. But since X = |ϕ|, then we have ∀u ∈ E c
i (w), then v ∈ |ϕ| i.e. v ∈ X. So we prove that ∀w ∈ W : X ∈ E dc

exists ϕ ∈ LKBE s.t. X = |ϕ|. So, Ed
MCS5, Ed
∀u ∈ W c : u ∈ E c
Thus, if v ∈ E c
(Ei(w) ⊆ X).

i ϕ ∈ w. However, (cid:96) Ed

(6) The other canonical properties are easy to show and standard for Ki, Bi and Ei

(see Blackburn et al. (2002)).

A.3.7. Completeness proof

In this section, we give the complete proof of completeness.

Theorem 4.5. The KBE system is complete.

Proof. (Completeness) By deﬁnition, we have that for all valid formulas ϕ in the
frame C, ϕ is valid in all models M on C. Thus, since the canonical model is a KBE
model from Lemma A.18, ϕ is also valid in the canonical model Mc. So, from the

58

Lemma A.17, we have (cid:96) ϕ. Consequently, we have proved that the KBE system is
complete.

A.4. Strong properties of KBE

We prove here the strong soundness and strong completeness of KBE.

A.4.1. Strong soundness

In the following, we demonstrate the strong correction of KBE. The strong correction
is an almost immediate consequence of the correction and the semantic weakening that
we demonstrate in the proof of the theorem.

Theorem A.19 (Strongly soundness of KBE). Let Γ be a set of formulas of KBE,
ϕ be a theorem of KBE, we have that the system KBE is strongly sound, i.e. if Γ (cid:96)
ϕ then Γ |= ϕ.

Proof. Let Γ be a set of formulas of KBE, ϕ be a formula of KBE. Let us assume
that Γ (cid:96) ϕ, so there exists ψ1, . . . , ψn ∈ Γ such that (cid:96) ψ1 ∧ . . . ∧ ψn ⇒ ϕ. Thus, by
soundness we have |= ψ1 ∧ . . . ∧ ψn ⇒ ϕ i.e. |= ¬ψ1 ∨ . . . ∨ ¬ψn ∨ ϕ. So:

|= ¬ψ1 ∨ . . . ∨ ¬ψn ∨ ¬

θ ∨ ϕ

(cid:94)

θ∈Γ

Thus, by applying the rule of De Morgan, we have:

|= ¬

(cid:94)

θ ∨ ϕ

θ∈Γ∪{ψ1,...,ψn}

However since {ψ1, . . . , ψn} ⊆ Γ, we have Γ ∪ {ψ1, . . . , ψn} = Γ and so (semantic
weakening):

|= ¬

(cid:94)

θ∈Γ

θ ∨ ϕ

Consequently, we have ∀M, if M |= Γ, then M |= ϕ. Thus, we prove that Γ |= ϕ.

A.4.2. Strong completeness

The KBE system is strongly complete. In order to demonstrate the strong completeness
of the system, we need the following lemma A.20.

Lemma A.20. For all KBE-consistent sets Γ of formulas, there exists a world w ∈ W c
in the canonical model Mc such that Mc, w |= Γ, i.e. ∀ϕ ∈ Γ : Mc, w |= ϕ.

i )i∈N , (Bc

Proof. Let Mc = (W c, (Kc
i )i∈N , (E c
i )i∈N , V c) be the canonical
model. Let Γ be a KBE-consistent set of formulas. By applying the lemma of Lin-
denbaum, there exists a maximal consistent set of formulas Γ(cid:48) such that Γ ⊆ Γ(cid:48) and
Γ(cid:48) ∈ W c. Let w = Γ(cid:48) denotes the possible world in W c. We have ∀ϕ ∈ Γ(cid:48) : Mc, Γ(cid:48) |= ϕ,
and so ∀ϕ ∈ Γ : Mc, Γ |= ϕ i.e. ∀ϕ ∈ Γ : Mc, w |= ϕ. Thus, we have proved that for

i )i∈N , (E dc

59

all KBE-consistent sets Γ, there exists a world w ∈ W c satisfying all formulas of Γ in
the canonical model Mc.

Finally we give the proof of the strong completeness of KBE.

Theorem A.21 (Strong completeness of KBE). Let ϕ ∈ LKBE be a formula and for
all sets Γ ⊆ LKBE of formulas, we have that the system KBE is strongly complete i.e.
if Γ |= ϕ, then Γ (cid:96) ϕ.

Proof. By contraposition, let Γ ⊆ LKBE be a set of formulas such that Γ (cid:54)(cid:96) ϕ, we
have that Γ ∪ {¬ϕ} is a KBE-consistent set. Indeed, by absurdity, if we have Γ ∪ {¬ϕ}
is KBE-inconsistent, then we would have that there exists ψ1, . . . , ψn ∈ Γ such that
(cid:96) ¬(ψ1 ∧ . . . ∧ ψn ∧ ¬ϕ), and so we would also have (cid:96) (ψ1 ∧ . . . ∧ ψn) ⇒ ϕ. However
by deduction theorem, we would deduce that Γ ∪ {ψ1, . . . , ψn} (cid:96) ϕ, i.e. Γ (cid:96) ϕ, which
contradicts the hypothesis Γ (cid:54)(cid:96) ϕ. Thus, by lemma A.20, there exists a model M (the
canonical model) and a world w such that M, w |= Γ ∪ {¬ϕ}, i.e. M, w |= Γ and
M, w |= ¬ϕ. Consequently we have proved that there exists a model M such that
M, Γ (cid:54)|= ϕ.

A.5. Theorems of KBE

In Section 4.6, we gave theorems that can be deduced with KBE such as the property
D, T, concealing contrary beliefs or knowledge and the qui facit per alium facit per se
principle. In this section we give complete Hilbert-style proof of these theorems.

Theorem 4.6 (Statements 1 and 2).

(1) (cid:96) ¬Ed
(2) (cid:96) Ed

i ⊥ (DEd
i ϕ ⇒ ϕ (TEd

)

i

i

)

Proof.

i ⊥ ⇒ Ei⊥
i ⊥ ⇒ Ei⊥) ⇒ (¬Ei⊥ ⇒ ¬Ed

i ⊥)

(1)

(2)

i ⊥

(a) (cid:96) Ed
(b) (cid:96) (Ed
(c) (cid:96) ¬Ei⊥ ⇒ ¬Ed
(d) (cid:96) ¬Ei⊥
(e) (cid:96) ¬Ed
i ⊥
(a) (cid:96) Ed
(b) (cid:96) Eiϕ ⇒ ϕ
(c) (cid:96) Ed
(d) (cid:96) (Ed
(e) (cid:96) Ed

i ϕ ⇒ Eiϕ

i ϕ ⇒ Eiϕ ⇒ ϕ
i ϕ ⇒ Eiϕ ⇒ ϕ) ⇒ ((Ed
i ϕ ⇒ ϕ

i ϕ ⇒ Eiϕ) ⇒ (Ed

i ϕ ⇒ ϕ))

[Ax. (Ed
i Ei)]
[Contra. on (a)]
[MP (a), (b)]
[Ax. (DEi)]
[MP (d), (c)]
[Ax. (Ed
i Ei)]
[Ax. (TEi)]
[Aug. (b)]
[Syll. (c)]
[MP (c) (a) (d)]

Theorem 4.6 (Statements 3 to 10).

(3) (cid:96) KiEd
(4) (cid:96) Ki¬Ed
(5) (cid:96) ¬KiEd
(6) (cid:96) ¬Ki¬Ed
(7) (cid:96) ¬Bi¬Ed
(8) (cid:96) Bi¬Ed

i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ
i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ

60

(9) (cid:96) BiEd
(10) (cid:96) ¬BiEd

i ϕ ⇔ Ed
i ϕ
i ϕ ⇔ ¬Ed

i ϕ

Proof.

(3)

(4)

(5)
(6)
(7)

(8)
(9)

(10)

(cid:96) KiEd
i ϕ ⇒ Ed
i ϕ
(cid:96) Ed
i ϕ ⇒ KiEd
i ϕ
i ϕ ⇔ Ed
i ϕ
(cid:96) Ki¬Ed
i ϕ ⇒ ¬Ed
i ϕ
(cid:96) ¬Ed
i ϕ ⇒ Ki¬Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ
i ϕ ⇔ ¬Ed
i ϕ
i ϕ ⇔ Ed
i ϕ

(a) (⇒)
(b) (⇐)
(c) (cid:96) KiEd
(a) (⇒)
(b) (⇐)
(c) (cid:96) Ki¬Ed
(a) (cid:96) ¬KiEd
(a) (cid:96) ¬Ki¬Ed
(a) (⇒) (cid:96) ¬Bi¬Ed
(b) (⇒) (cid:96) ¬Bi¬Ed
(c) (⇒) (cid:96) ¬Bi¬Ed
(d) (⇒) (cid:96) (¬Bi¬Ed
i ϕ ⇒ Ed

i ϕ ⇒ ¬Ki¬Ed
i ϕ ⇒ Ed
i ϕ ⇒ ¬Bi¬Ed
i ϕ ⇒ ¬Bi¬Ed
i ϕ))
i ϕ ⇒ Ed
i ϕ
i ϕ ⇒ BiEd

i ϕ ⇒ KiEd

i ϕ

i ϕ

i ϕ

i ϕ

(¬Bi¬Ed
(e) (⇒) (cid:96) ¬Bi¬Ed
(f) (⇐) (cid:96) Ed
(g) (⇐) (cid:96) KiEd
(h) (⇐) (cid:96) Ed
(i) (⇐) (cid:96) (Ed
[Syll. (h)]
(j) (⇐) (cid:96) Ed
(k) (⇐) (cid:96) BiEd
(l) (⇐) (cid:96) Ed
(m) (⇐) (cid:96) (Ed
(Ed
(n) (⇐) (cid:96) Ed
(o) (cid:96) Ed
(a) (cid:96) ¬Ed
(a) (⇒) (cid:96) BiEd
(b) (⇒) (cid:96) BiEd
(c) (⇐) (cid:96) Ed
(d) (cid:96) Ed
(a) (cid:96) ¬Ed

i ϕ ⇒ BiEd

i ϕ ⇔ ¬Bi¬Ed
i ϕ ⇔ Bi¬Ed

i ϕ
i ϕ
i ϕ ⇒ ¬Bi¬Ed
i ϕ ⇒ Ed
i ϕ ⇒ BiEd
i ϕ ⇔ BiEd
i ϕ
i ϕ ⇔ ¬BiEd

i ϕ
i ϕ

i ϕ

i ϕ

i ϕ ⇒ Ed

i ϕ
i ϕ ⇒ Ed

i ϕ) ⇒ ((¬Bi¬Ed

i ϕ ⇒ ¬Bi¬Ed

i ϕ ⇒ KiEd
i ϕ ⇒ KiEd

i ϕ ⇒ BiEd
i ϕ
i ϕ) ⇒ (Ed
i ϕ ⇒ BiEd

i ϕ ⇒ KiEd

i ϕ) ⇒ (Ed

i ϕ ⇒ BiEd

i ϕ

i ϕ ⇒ ¬Bi¬Ed

i ϕ
i ϕ ⇒ BiEd

i ϕ ⇒ KiEd
i ϕ ⇒ BiEd
i ϕ ⇒ KiEd
i ϕ ⇒ ¬Bi¬Ed
i ϕ) ⇒ (Ed
i ϕ ⇒ ¬Bi¬Ed
i ϕ

i ϕ)

i ϕ ⇒ ¬Bi¬Ed

i ϕ

i ϕ ⇒ ¬Bi¬Ed

i ϕ) ⇒ (Ed

i

i

[Ax. (4Ki,Ed

[Ax. (5Ki,Ed

[Ax. (TKi)]
)]
[Def. (⇔)]
[Ax. (TKi)]
)]
[Def. (⇔)]
[Contrap. (1.c)]
[Contrap. (2.c)]
[Contrap. (KiBi)]
[RE (3.a) in (a)]
[Aug. (b)]
i ϕ) ⇒
[Syll. (c)]
[MP (c) (a) (b)]
)]
[Ax. (4Ki,Ed
[Ax. (KiBj)]
[Aug. (g)]
i ϕ)

i ϕ ⇒ BiEd

i

i ϕ ⇒ KiEd

[MP (h) (i) (g)]
[Ax. (DBi)]
[Aug. (k)]
i ϕ) ⇒
[Syll. (l)]
[MP (l) (f) (j) (m)]
[Def. (⇔)]
[Contrap. (5.o)]
[Ax. (DBi)]
[RE (5.o)]
[Th. (5.j)]
[Def. (⇔)]
[Contrap. (7.d)]

Theorem 4.7.

(1) (cid:96) Ed
(2) (cid:96) Ed

i Bjϕ ⇒ Ei¬BjKk¬ϕ
i ¬Bjϕ ⇒ Ei¬BjKkϕ

Proof. Here is the proof of (1).

(1) (cid:96) Bjϕ ∧ BjKk¬ϕ ⇒ Bjϕ
(2) (cid:96) Bj(Kk¬ϕ ⇒ ¬ϕ)
(3) (cid:96) Bj(Kk¬ϕ ⇒ ¬ϕ) ⇒ (BjKk¬ϕ ⇒ Bj¬ϕ)
(4) (cid:96) BjKk¬ϕ ⇒ Bj¬ϕ
(5) (cid:96) Bj¬ϕ ⇒ ¬Bjϕ

[Left Elim. ∧]
[Nec. Bj on (TKk)]
[Ax. (K)]
[MP (2), (3)]
[Ax. (D)]

61

(6) (cid:96) BjKk¬ϕ ⇒ Bj¬ϕ ⇒ ¬Bjϕ
[Aug. (5)]
(7) (cid:96) (BjKk¬ϕ ⇒ Bj¬ϕ ⇒ ¬Bjϕ) ⇒ ((BjKk¬ϕ ⇒ Bj¬ϕ) ⇒ (BjKk¬ϕ ⇒ ¬Bjϕ))

[Syll. (6)]

BjKk¬ϕ))

(Bjϕ ∧ BjKk¬ϕ ⇒ ¬Bjϕ)))

[MP (6),(4),(7)]
(8) (cid:96) BjKk¬ϕ ⇒ ¬Bjϕ
[Aug. (8)]
(9) (cid:96) Bjϕ ∧ BjKk¬ϕ ⇒ (BjKk¬ϕ ⇒ ¬Bjϕ)
(10) (cid:96) Bjϕ ∧ BjKk¬ϕ ⇒ BjKk¬ϕ
[Right Elim. (∧) ]
(11) (cid:96) (Bjϕ ∧ BjKk¬ϕ ⇒ (BjKk¬ϕ ⇒ ¬Bjϕ)) ⇒ ((Bjϕ ∧ BjKk¬ϕ ⇒ BjKk¬ϕ) ⇒
[Syll. (9)]
(12) (cid:96) Bjϕ ∧ BjKk¬ϕ ⇒ ¬Bjϕ
[MP (9),(10),(11)]
(13) (cid:96) ((Bjϕ ∧ BjKk¬ϕ ⇒ Bjϕ)) ⇒ ((Bjϕ ∧ BjKk¬ϕ ⇒ ¬Bjϕ) ⇒ ¬(Bjϕ ∧
[Reductio ad absurdum]
[MP (1), (12), (13)]
[De Morgan Th. (14)]
[MP (14), (15)]
[Nec. (16)]
[Ax. (K)]
[MP (17), (18)]
[Ax. (Ed
i Ei)]
[Aug. (20)]
i Bjϕ ⇒
[Syll. (21)]
i Ei)]

(14) (cid:96) ¬(Bjϕ ∧ BjKk¬ϕ)
(15) (cid:96) ¬(Bjϕ ∧ BjKk¬ϕ) ≡ (Bjϕ ⇒ ¬BjKk¬ϕ)
(16) (cid:96) Bjϕ ⇒ ¬BjKk¬ϕ
(17) (cid:96) Ei(Bjϕ ⇒ ¬BjKk¬ϕ)
(18) (cid:96) Ei(Bjϕ ⇒ ¬BjKk¬ϕ) ⇒ (EiBjϕ ⇒ Ei¬BjKk¬ϕ)
(19) (cid:96) EiBjϕ ⇒ Ei¬BjKk¬ϕ
(20) (cid:96) Ed
(21) (cid:96) Ed
(22) (cid:96) (Ed

i Bjϕ ⇒ EiBjϕ
i Bjϕ ⇒ EiBjϕ ⇒ Ei¬BjKk¬ϕ
i Bjϕ ⇒ EiBjϕ ⇒ Ei¬BjKk¬ϕ) ⇒ ((Ed

i Bjϕ ⇒ EiBjϕ) ⇒ (Ed

i Bjϕ ⇒ Ei¬BjKk¬ϕ

Ei¬BjKk¬ϕ))

(23) (cid:96) Ed

[Ax. (Ed

Here is the proof of (2).

(1) (cid:96) Kkϕ ⇒ ϕ
(2) (cid:96) Bj(Kkϕ ⇒ ϕ)
(3) (cid:96) Bj(Kkϕ ⇒ ϕ) ⇒ BjKkϕ ⇒ Bjϕ
(4) (cid:96) BjKkϕ ⇒ Bjϕ
(5) (cid:96) (BjKkϕ ⇒ Bjϕ) ⇒ ¬Bjϕ ⇒ ¬BjKkϕ
(6) (cid:96) ¬Bjϕ ⇒ ¬BjKkϕ
(7) (cid:96) Ei(¬Bjϕ ⇒ ¬BjKkϕ)
(8) (cid:96) Ei(¬Bjϕ ⇒ ¬BjKkϕ) ⇒ Ei¬Bjϕ ⇒ Ei¬BjKkϕ
(9) (cid:96) Ei¬Bjϕ ⇒ Ei¬BjKkϕ
(10) (cid:96) Ed
(11) (cid:96) Ed
(12) (cid:96) (Ed

i ¬Bjϕ ⇒ Ei¬Bjϕ
i ¬Bjϕ ⇒ Ei¬Bjϕ ⇒ Ei¬BjKkϕ
i ¬Bjϕ ⇒ Ei¬Bjϕ ⇒ Ei¬BjKkϕ) ⇒ (Ed

Ei¬BjKkϕ

(13) (cid:96) Ed

i ¬Bjϕ ⇒ Ei¬BjKkϕ

[Ax. (T)]
[Nec (1)]
[Ax. (KBj )]
[MP (2) (3)]
[Contrap. (4)]
[MP (4) (5)]
[Nec (6)]
[Ax. (KEi)]
[MP (7) (8)]
[Ax. (Ed
i Ei)]
[Aug. (9)]
i ¬Bjϕ ⇒
[Syll. (11)]
[MP (11) (10) (12)]

i ¬Bjϕ ⇒ Ei¬Bjϕ) ⇒ Ed

Theorem 4.8.

(1) (cid:96) Ed
(2) (cid:96) Ed

i Bjϕ ⇒ ¬Ed
i ¬Bjϕ ⇒ ¬Ed

i BjKk¬ϕ
i BjKkϕ

Proof.

Here is the proof of (1).

(1) (cid:96) Ei¬BjKk¬ϕ ⇒ ¬EiBjKk¬ϕ
(2) (cid:96) ¬EiBjKk¬ϕ ⇒ ¬Ed
i BjKk¬ϕ

[Contrap. Ax. (EiEd

[Ax. (D)]
i )]

62

(3) (cid:96) Ed
(4) (cid:96) (Ed
Ed
(5) (cid:96) Ed

i Bjϕ ⇒ ¬EiBjKk¬ϕ ⇒ ¬Ed
i Bjϕ ⇒ ¬EiBjKk¬ϕ ⇒ ¬Ed

i Bjϕ ⇒ ¬Ed

i BjKk¬ϕ

i Bjϕ ⇒ ¬Ed

i BjKk¬ϕ

i BjKk¬ϕ

i BjKk¬ϕ) ⇒ (Ed

[Aug. (2)]
i Bjϕ ⇒ ¬EiBjKk¬ϕ) ⇒
[Syll. (3)]
[MP (3) (Syll. ((Thm 4.7.1)-(1)))) (4)]

Here is the proof of (2).

(1) (cid:96) Ei¬BjKkϕ ⇒ ¬EiBjKkϕ
(2) (cid:96) ¬EiBjKkϕ ⇒ ¬Ed
i BjKkϕ
(3) (cid:96) Ed
(4) (cid:96) (Ed
Ed
(5) (cid:96) Ed

i ¬Bjϕ ⇒ Ei¬BjKkϕ ⇒ ¬Ed
i ¬Bjϕ ⇒ Ei¬BjKkϕ ⇒ ¬Ed

i ¬Bjϕ ⇒ ¬Ed

i ¬Bjϕ ⇒ ¬Ed

i BjKkϕ

i BjKkϕ

i BjKkϕ

i BjKkϕ) ⇒ (Ed

[Contrap. (Ed

[Ax. (DEi)]
i Ei)]
[Aug. (2)]
i ¬Bjϕ ⇒ Ei¬BjKkϕ) ⇒
[Syll. (3)]
[MP (3) (Thm 4.7.2) (4)]

The next theorem is the qui facit per alium facit per se principle.

Theorem 4.9 (Qui facit per alium facit per se).

(cid:96) (Ed

i Ejϕ ∨ Ed

i Ed

j ϕ) ⇒ Eiϕ

Proof.
Left part:

i Ejϕ ⇒ EiEjϕ

(1) (cid:96) Ed
(2) (cid:96) Ejϕ ⇒ ϕ
(3) (cid:96) Ei(Ejϕ ⇒ ϕ)
(4) (cid:96) Ei(Ejϕ ⇒ ϕ) ⇒ EiEjϕ ⇒ Eiϕ
(5) (cid:96) EiEjϕ ⇒ Eiϕ
(6) (cid:96) (Ed
(7) (cid:96) Ed

i Ejϕ ⇒ EiEjϕ ⇒ Eiϕ) ⇒ (Ed
i Ejϕ ⇒ Eiϕ

i Ejϕ ⇒ EiEjϕ) ⇒ Ed

j ϕ ⇒ EiEd
j ϕ
j ϕ ⇒ Ejϕ)
j ϕ ⇒ Ejϕ) ⇒ EiEd
j ϕ ⇒ EiEjϕ
j ϕ ⇒ EiEd
j ϕ ⇒ EiEd

j ϕ ⇒ EiEjϕ

j ϕ ⇒ EiEjϕ

j ϕ ⇒ EiEjϕ
j ϕ ⇒ EiEjϕ ⇒ Eiϕ
j ϕ ⇒ EiEjϕ ⇒ Eiϕ) ⇒ (Ed
j ϕ ⇒ Eiϕ

Right part:
(1) (cid:96) Ed
i Ed
(2) (cid:96) Ei(Ed
(3) (cid:96) Ei(Ed
(4) (cid:96) EiEd
i Ed
(5) (cid:96) Ed
i Ed
(6) (cid:96) (Ed
[Syll. (5)]
i Ed
i Ed
i Ed
i Ed
Conclusion:

(7) (cid:96) Ed
(8) (cid:96) Ed
(9) (cid:96) (Ed
(10) (cid:96) Ed

(1) (cid:96) (Ed
(∨)]
(2) (cid:96) ((Ed
((Ed

j ϕ ⇒ EiEjϕ) ⇒ (Ed

i Ed

j ϕ ⇒ EiEd

j ϕ) ⇒ Ed

i Ed

i Ed

j ϕ ⇒ EiEjϕ) ⇒ Ed

i Ed

i Ejϕ ∨ Ed

i Ed

j ϕ) ⇒ ((Ed

i Ejϕ ⇒ Eiϕ) ⇒ (Ed

i Ed

j ϕ ⇒ Eiϕ) ⇒ Eiϕ))

[Elim.

i Ejϕ ∨ Ed
i Ed

i Ejϕ ∨ Ed

j ϕ) ⇒ ((Ed

i Ed
j ϕ) ⇒ (Ed

i Ejϕ ⇒ Eiϕ) ⇒ (Ed

i Ejϕ ⇒ Eiϕ)) ⇒ (Ed

i Ed
i Ejϕ ∨ Ed

j ϕ ⇒ Eiϕ) ⇒ Eiϕ)) ⇒
j ϕ) ⇒ (Ed
j ϕ ⇒

i Ed

i Ed

63

[Ax. (Ed

i Ei)]
[Ax. (T)]
[Nec (Ei)]
[Ax. (K)]
[MP (3) (4)]
i Ejϕ ⇒ Eiϕ [Syll. (5)]
[MP (4) (1) (6)]

[Ax. (Ed
[Nec (Ax. (Ed

i Ei)]
i Ei))]
[Ax. (K)]
[MP (2) (3)]
[Aug. (4)]
j ϕ ⇒ EiEjϕ

[MP (5) (1) (6)]
[Aug. (Ax. (4Ei))]
j ϕ ⇒ Eiϕ [Syll. (8)]
[MP (8) (7) (9)]

Eiϕ) ⇒ Eiϕ

(3) (cid:96) (Ed
(4) (cid:96) ((Ed
(Ed
i Ed
(5) (Ed
i Ejϕ ∨ Ed

i Ejϕ ∨ Ed
i Ed
j ϕ) ⇒ (Ed
i Ed
i Ejϕ ∨ Ed
i Ed
j ϕ) ⇒ (Ed
j ϕ ⇒ Eiϕ)) ⇒ (Ed
i Ed
j ϕ) ⇒ Eiϕ

j ϕ ⇒ Eiϕ) ⇒ Eiϕ
i Ed
i Ejϕ ∨ Ed

j ϕ ⇒ Eiϕ) ⇒ Eiϕ) ⇒ ((Ed
i Ed

j ϕ) ⇒ Eiϕ

[MP (3) (Aug. ((cid:96) Ed

[Syll. (1)]
)) (2)]
[MP (1) (Aug. (TEd
i Ed
j ϕ) ⇒
[Syll. (3)]
j ϕ ⇒ Eiϕ)) (4)]

i Ejϕ ∨ Ed

i Ed

i

A.6. Properties of manipulation, coercion, persuasion and deception

In Sections 5.2 and 5.3, we provide theorems for manipulation and the related notions,
i.e. coercion, perusasion and deception. In this section we give the proofs of these
theorems. In some cases, the Hilbert proofs need several steps of obvious syllogisms
and rewritings that make the proofs diﬃcult to read. In those cases and for ease of
reading, we allow ourselves to denote those steps by “. . .”.

Theorem 5.5.

(1) (cid:96) (M CEdKΣ
(2) (cid:96) (M CEdKΣ
(3) (cid:96) (M CEdKΣ

i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ ⊥
i,j(ϕ)) ∧ Bj¬ϕ ⇒ ⊥
i,j(ϕ)) ⇒ Kjϕ

Proof.

(1)

(a) (cid:96) (M CEdKΣ
(b) (cid:96) Kj¬ϕ ⇒ ¬ϕ
(c) (cid:96) (M CEdKΣ
(d) (cid:96) (M CEdKΣ
((M CEdKΣ
M CEdBΣ
(e) (cid:96) ((M CEdKΣ
(f) (cid:96) ((M CEdKΣ
M CEdBΣ
i,j(ϕ))

(g) . . .
(h) (cid:96) ((M CEdKΣ

¬BjEd

i Ed

j ϕ))

(Ed

j ϕ ⇒ ϕ

(i) . . .
(j) (cid:96) ((Ed
(k) (cid:96) Ed
(l) (cid:96) ((M CEdKΣ
j ϕ ∧ ¬BjEd
(m) (cid:96) (((M CEdKΣ
j ϕ ∧ ¬BjEd

(Ed
M CEdBΣ
(((M CEdKΣ
(n) (cid:96) ((M CEdKΣ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ)) ∧ Kj¬ϕ ⇒ ¬ϕ)
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ Kj¬ϕ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ (Kj¬ϕ ⇒ ¬ϕ)

i,j(ϕ)) ∧ Kj¬ϕ ⇒ Kj¬ϕ) ⇒ (((M CEdKΣ

[Right elim. (∧)]
[Ax. (T)]
[Aug. (b)]
i,j(ϕ)) ∧ Kj¬ϕ ⇒ (Kj¬ϕ ⇒ ¬ϕ)) ⇒
i,j(ϕ) ∨
[Syll. (c)]
[MP (c),(a),(d)]
i,j(ϕ) ∨
[Left elim. (∧)]

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ (M CEdKΣ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ¬ϕ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ))) ⇒ ((Ed

j ϕ ∧ ¬KjEd

j ϕ ∧ ¬KjEd

i Ed

j ϕ) ∨ (Ed

j ϕ ∧ ¬BjEd

i Ed

j ϕ)) ⇒ Ed

j ϕ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ((Ed

j ϕ ∧ ¬KjEd

i,j(ϕ) ∨ M CEdBΣ
j ϕ)) ⇒ Ed
i Ed
j ϕ ⇒ ϕ
i,j(ϕ) ∨ M CEdBΣ
j ϕ)) ⇒ Ed
i Ed

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ((Ed

j ϕ ∧ ¬KjEd
j ϕ ⇒ ϕ) ⇒ (((M CEdKΣ
i Ed
j ϕ) ∨ (Ed

j ϕ ∧ ¬BjEd

j ϕ ∧ ¬KjEd

i Ed

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ((Ed
i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ (Ed
i,j(ϕ)) ∧ Kj¬ϕ) ⇒ (Ed

j ϕ ⇒ ϕ))
j ϕ ⇒ ϕ)

i Ed
j ϕ) ∨ (Ed
j ϕ ∧
[CBR13 Th. (T)]

[Elim. (∧) (∨) ]
[Ax. (T)]
i Ed
j ϕ) ∨
[Aug. (k)(×2)]
i Ed
j ϕ) ∨
i,j(ϕ) ∨
j ϕ))) ⇒
[Syll. (l)]
[MP

13We apply here the Case-Based Reasoning i.e. the elimination of the disjunction.

64

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ (Ed

i,j(ϕ))∧Kj¬ϕ) ⇒ Ed

(l),(f),(m)]
(o) (cid:96) (((M CEdKΣ
((((M CEdKΣ
M CEdBΣ
(p) (cid:96) (((M CEdKΣ
(q) (cid:96) (((M CEdKΣ
M CEdBΣ
¬Kj¬ϕ))

i,j(ϕ)∨M CEdBΣ
i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ϕ))
i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ)∨M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ϕ)
i,j(ϕ))∧Kj¬ϕ) ⇒ ¬ϕ) ⇒ ((((M CEdKΣ

i,j(ϕ)) ∧ Kj¬ϕ) ⇒ ϕ)) ⇒ (¬(M CEdKΣ

(r) (cid:96) (¬(M CEdKΣ
(s) (cid:96) (¬(M CEdKΣ

i,j(ϕ) ∨ M CEdBΣ
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∨ ¬Kj¬ϕ)

M CEdBΣ
(t) (cid:96) (M CEdKΣ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ ⊥)
i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Kj¬ϕ ⇒ ⊥

i,j(ϕ)) ∨ ¬Kj¬ϕ) ⇔ ((M CEdKΣ

j ϕ) ⇒ (((M CEdKΣ

j ϕ ⇒ ϕ)) ⇒
i,j(ϕ)∨
[Syll. (n)]
[MP (l),(e),(m)]
i,j(ϕ)∨
i,j(ϕ)) ∨
[Reductio ad absurdum]
[MP (e),(p),(q)]
i,j(ϕ) ∨
[Th. ((cid:96) ϕ ⇔ (¬ϕ ⇒ ⊥))]
[MP (r),(s)]

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ∧ Bj¬ϕ ⇒ Bj¬ϕ

[Right elim. (∧)]

j ϕ ∧ ¬KjEd

i Ed

j ϕ) ∨ (Ed

j ϕ ∧ ¬BjEd

i Ed

j ϕ)) ∧ Bj¬ϕ ⇒ Ed

j ϕ [Left elim.

(2)

(3)

j ϕ ⇒ KjEd
j ϕ)
i Ed
j ϕ ∧ ¬KjEd

j ϕ ⇒ BjEd

j ϕ

(a) (cid:96) (M CEdKΣ
(b) . . .
(c) (cid:96) ((Ed
(∧) ]

(d) . . .
(e) (cid:96) (Ed
(f) (cid:96) ((Ed
(e)]
(g) (cid:96) KjEd
(h) . . .
(i) (cid:96) Bj(Ed
(j) (cid:96) Bj(Ed
(k) (cid:96) BjEd
(l) . . .
(m) (cid:96) ((Ed

j ϕ ⇒ ϕ)
j ϕ ⇒ ϕ) ⇒ (BjEd
j ϕ ⇒ Bjϕ

j ϕ ⇒ Bjϕ)

j ϕ ∧ ¬KjEd

i Ed

j ϕ) ∨ (Ed

BjEd

j ϕ ⇒ Bjϕ
(n) (cid:96) (M CEdKΣ

(m))]

i,j(ϕ) ∨ M CEdBΣ

(o) . . .
(p) (cid:96) Bjϕ ⇒ (Bj¬ϕ ⇒ (Bjϕ ∧ Bj¬ϕ))
(q) (cid:96) (M CEdKΣ
Bj¬ϕ)))
(r) (cid:96) (M CEdKΣ
(Syll. (q)) ]
(s) (cid:96) (M CEdKΣ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ) ∨ M CEdBΣ

((cid:96) Bjϕ ∧ Bj¬ϕ ⇔ ⊥)]

j ϕ) ∨ (Ed

j ϕ ∧ ¬BjEd

i Ed

j ϕ)) ⇒ (Ed

j ϕ ⇒ KjEd

j ϕ)

[Ax. (5Kj,Ed

)]
[Aug.

j

[Ax. (KjBj)]

[Nec (Bj) on (TEd

j

)]
[Ax. (K)]
[MP (i), (j)]

i Ed

j ϕ)) ⇒ Ed

j ϕ ∧ ¬BjEd

j ϕ ⇒
[Aug. (k)]
i,j(ϕ)) ∧ Bj¬ϕ ⇒ Bjϕ [MP (c) . . . (m) (Syll.

j ϕ ⇒ KjEd

[Intro. (∧)]
i,j(ϕ)) ∧ Bj¬ϕ ⇒ (Bjϕ ⇒ (Bj¬ϕ ⇒ (Bjϕ ∧
[Aug. (p)]
[MP (n) (a)

i,j(ϕ)) ∧ Bj¬ϕ ⇒ (Bjϕ ∧ Bj¬ϕ)

i,j(ϕ)) ∧ Bj¬ϕ ⇒ ⊥

[RE (r)

i (Ed

(a) (cid:96) (Ed
(Ed
(b) (cid:96) (Ed

j ϕ ∧ ¬BjEd

j ϕ∧¬KjEd
j ϕ))
i Ed

i Ed
j ϕ ∧ ¬KjEd

(Elim. (∨))]

j ϕ ⇒ KjEd

(c) (cid:96) Ed
(d) . . .
(e) (cid:96) (M CEdKΣ

i Ed

j ϕ)∨Ed

i (Ed

j ϕ∧¬BjEd

i Ed

j ϕ)) ⇒ ((Ed

j ϕ) ∨ (Ed

j ϕ ∧ ¬BjEd

i Ed

j ϕ)) ⇒ Ed

j ϕ

j ϕ∧¬KjEd

i Ed
[Th. (TEd

j ϕ)∨
)]
[MP (Elim. (∧))

i

j ϕ ⇒ Kjϕ [Aug. (MP (Th. (TEd

i

i,j(ϕ) ∨ M CEdBΣ

i,j(ϕ)) ⇒ Kjϕ

))(Nec Ki + Ax. (KKi)))]

[MP (...) Syll. (c)]

65

Theorem 5.6.

i,j(ϕ)

i,j(ϕ)

(1) (cid:96) M CEKΣ
(2) (cid:96) M CEKΣ
(3) (cid:96) M CEBΣ
(4) (cid:96) M CEBΣ
(5) (cid:96) M DEKΣ
(6) (cid:96) M DEKΣ
(7) (cid:96) M DEBΣ
(8) (cid:96) M DEBΣ

i,j(Ejϕ) ⇔ M CEKΣ
i,j(¬Ejϕ) ⇔ M DEKΣ
i,j(Ejϕ) ⇔ M CEBΣ
i,j(¬Ejϕ) ⇔ M DEBΣ
i,j(Ejϕ) ⇔ M DEKΣ
i,j(¬Ejϕ) ⇔ M CEKΣ
i,j(Ejϕ) ⇔ M DEBΣ
i,j(¬Ejϕ) ⇔ M CEBΣ

i,j(ϕ)
i,j(ϕ)
i,j(ϕ)

i,j(ϕ)
i,j(ϕ)

i,j(ϕ)

Proof. All those theorems are obvious to show by using (RE) and considering the
following theorems (cid:96) EiEiϕ ⇔ Eiϕ for (1) and (3), (cid:96) Ej¬Ejϕ ⇔ ¬Ejϕ for (2) and
(4), (cid:96) ¬EiEiϕ ⇔ ¬Eiϕ for (5) and (7), (cid:96) ¬Ej¬Ejϕ ⇔ Ejϕ for (6) and (8).

Theorem 5.7.

(1) (cid:54)|= ¬M CEKΣ
(2) (cid:54)|= M CEKΣ
(3) (cid:54)|= M CEKΣ

i,j(ϕ) ∧ M CEdKΣ
i,j(ϕ) ∧ ¬M CEdKΣ
i,j(ϕ) ∧ M CEdKΣ

i,j(ϕ) ⇒ ⊥
i,j(ϕ) ⇒ ⊥

i,j(ϕ) ⇒ ⊥

Proof. For both theorems, we will use the same model base, modulo a set of sets
of possible worlds X ⊆ 2W . Let M = (cid:104)W, {Bi}, {Ki}, {Ei}, {E d
i }, V (cid:105) be a KBE model,
and Σ be any ﬁnite and closed set of formulas that contains {(cid:62), ⊥} ∪ {p} and such
that:

• W = {w, x, y, z}
• Ki = {(w, w), (x, x), (y, y), (z, z)} = Bi = Ei = Kj = Bj = Ej
• E d
• E d
• V (p) = {w, y, z}

i = {(w, X), (x, {{x}}), (y, {{w, y}}), (z, {{z}})}
j = {(w, {{w, y, z}}), (x, {{x}}), (y, {{w, y, z}}), (z, {{z}})}

(0) if X = {{w}}, X = {{w, z}} or X = {{w}, {w, z}}, then we have:

j p|| = {w, y}
i Ejp|| = {w, x, z}
i Ed
j p|| = {w, x, z}

• ||Ejp|| = {w, y, z} and ||Ed
i Ejp|| = {y} and ||¬Ed
• ||Ed
j p|| = {y} and ||¬Ed
i Ed
• ||Ed
i Ejp|| = {w, x, z} ⊆ ||¬KjEd
• ||Kj¬Ed
j p|| = {w, x, z} ⊆ ||¬KjEd
i Ed
• ||Kj¬Ed
• ||Ed
j p|| = ||Ed
j p ∧ ¬KjEd
• ||Ejp ∧ ¬KjEd

i Ejp|| = {w, x, z}
i Ed
j p|| = {w, x, z}
i Ed
i Ed
j p|| ∩ ||¬KjEd
j p|| = {w},
i Ejp|| = ||Ejp|| ∩ ||¬KjEd
i Ejp|| = {w, z},
i,j(ϕ) ∧ M CEdKΣ
i,j(ϕ)
i Ed
j p ∧ ¬KjEd
j p)
i,j(ϕ) ∧ ¬M CEdKΣ
i,j(ϕ)
j p ∧ ¬KjEd
i Ed
j p)
i,j(ϕ) ∧ M CEdKΣ
j p ∧ ¬KjEd
j p)

i Ejp) ∧ ¬Ed

i Ejp) ∧ Ed

i (Ejp ∧ ¬KjEd

i (Ed

i Ed

(2) if X = {{w, z}}, then M, w |= M CEKΣ

since M, w |= Ed

i (Ed
(3) if X = {{w}, {w, z}}, then M, w |= M CEKΣ
i (Ed

i (Ejp ∧ ¬KjEd

i (Ejp ∧ ¬KjEd

since M, w |= Ed

i Ejp) ∧ Ed

(1) if X = {{w}}, then M, w |= ¬M CEKΣ

since M, w |= ¬Ed

i,j(ϕ)

Let us notice that it is possible to describe with this model the fact that the agent i

66

(a) (cid:96) Ed
(b) (cid:96) Ed
(c) . . .
(d) (cid:96) Ed

does not softly or strongly manipulate the agent j if X = {{w, x}}. We would have
M, w |= ¬M CEKΣ
i,j(ϕ) ∧ ¬M CEdKΣ
i Ejp) ∧
¬Ed
i Ed

i,j(ϕ) since M, w |= ¬Ed

i (Ejp ∧ ¬KjEd

j p ∧ ¬KjEd

i (Ed

j p).

Theorem 5.8.

(1) (cid:96) Ed
(2) (cid:54)|= M CEKΣ

i Eiϕ ∧ Ed

i ¬KiEd

i Eiϕ ⇒ ⊥
i,i(ϕ) ⇒ ⊥ and (cid:54)|= M CEBΣ

i,i(ϕ) ⇒ ⊥

Proof.

(1)

i Eiϕ ∧ Ed
i Eiϕ ∧ Ed

i ¬KiEd
i ¬KiEd

i Eiϕ ⇒ KiEd
i Eiϕ ⇒ ¬KiEd

i Eiϕ

i Eiϕ

[Left Elim. (∧) + Ax. (5Ki,Ed
[Right Elim. (∧) + Th. (TEd

i

i

)]
)]

i Eiϕ ∧ Ed
(2) Let M = (cid:104)W, {Bi}, {Ki}, {Ei}, {E d

i ¬KiEd

i Eiϕ ⇒ (KiEd

i Eiϕ ∧ ¬KiEd

i Eiϕ ⇔ ⊥)

[Conclusion]

i }, V (cid:105) be a KBE model, and Σ be any ﬁnite

and closed set of formulas that contains {(cid:62), ⊥} ∪ {p} and such that:

• W = {w, x, y}
• Ki = {(w, w), (x, x), (y, y)} = Bi = Ei
• E d
• V (p) = {w, y}

i = {(w, {{w}}), (x, {{x}}), (y, {{w, y}})}

We have:

• ||Eip|| = {w, y}
• ||¬KiEd
• ||Eip ∧ ¬KiEd

i Eip|| = ||¬Ed

i Eip|| = {z ∈ W : ||Eip|| (cid:54)∈ E d
i Eip|| = {w}

i Eip|| = ||Eip|| ∩ ||¬KiEd
i Eip|| ∈ E d

i (z)} = {w, x}

Thus, since ||Eip ∧ ¬KiEd
KBE-model M and w ∈ W s.t. M, w |= Ed
since |= Ed
of ∨ i.e. |= ϕ ⇒ (ϕ ∨ ψ), we prove the manipulation, i.e. M, w |= M CEKΣ
We notice that with this KBE model, we prove also (cid:54)|= M CEBΣ
i,i(ϕ) ⇒ ⊥.

i (w), we have proved that there exists a
i Eip). Furthermore,
i Eip ∧ (cid:62)) and by introduction
i,i(ϕ).

i (Eip ∧ ¬KiEd

i (Eip ∧ ¬KiEd

i (Eip ∧ ¬KiEd

i Eip) ⇔ Ed

Theorem 5.9.

(1) (cid:96) CKCoeΣ

i,j(ϕ) ⇔

(2) (cid:96) CBCoeΣ

i,j(ϕ) ⇔

(cid:87)

ψ∈Σ

(cid:55)

{KjEd
(cid:87)

i Ed

j ϕ}

ψ∈Σ

{BjEd

i Ed

j ϕ}

Ed

i (Ed

j ϕ ∧ ψ)

Ed

i (Ed

j ϕ ∧ ψ)

(cid:55)
Proof. By rewriting CKCoeΣ
i,j(ϕ) and Σ, we have for (1):

(cid:96) CKCoeΣ

i,j(ϕ) ⇔

(cid:95)

ψ∈Σ

Ed

i (Ed

j ϕ ∧ KjEd

i Ed

j ϕ ∧ ψ) ⇔

(cid:95)

Ed

i (Ed

j ϕ ∧ ψ)

ψ∈Σ

(cid:55)

{KjEd

i Ed

j ϕ}

The same methodology holds for (2).

Theorem 5.10.

(1) (cid:96) perΣ

i,j(¬Ed

j ϕ) ⇔ (cid:87)

ψ∈Σ

Ed

i (¬Ed

j ϕ ∧ ψ)

67

(2) (cid:96) perΣ

i,j(Ed

j ϕ) ⇔ (cid:87)

ψ∈Σ

Ed

i (Ed

j ϕ ∧ ψ)

Proof. Let us recall Theorem 4.6 says (cid:96) Bj¬Ed
Thus, we have:

j ϕ ⇔ ¬Ed

j ϕ and (cid:96) BjEd

j ϕ ⇔ Ed

j ϕ.

(1) (cid:96) perΣ

i,j(¬Ed

ψ∈Σ Ed

i (Bj¬Ed

Ed

i (¬Ed

j ϕ ∧ ψ)

(2) (cid:96) perΣ

i,j(Ed

ψ∈Σ Ed

i (BjEd

i (Ed

j ϕ ∧ ψ)

j ϕ) ⇔ (cid:87)
j ϕ) ⇔ (cid:87)

j ϕ ∧ ψ) ⇔ (cid:87)
ψ∈Σ
Ed

j ϕ ∧ ψ) ⇔ (cid:87)

ψ∈Σ

Theorem 5.11.

(1) (cid:96) CKCoeΣ

(2) (cid:96) CBCoeΣ

(3) (cid:96) DKCoeΣ

(4) (cid:96) DBCoeΣ

(cid:55)

(cid:55)

Σ
i,j(ϕ) ⇔ per
i,j
Σ
i,j(ϕ) ⇔ per
i,j
Σ
i,j(ϕ) ⇔ per
i,j
Σ
i,j(ϕ) ⇔ per
i,j

(cid:55)

{KjEd

i Ed

j ϕ}

{BjEd

i Ed

j ϕ}

{KjEd

i ¬Ed

j ϕ}

(cid:55)

{BjEd

i ¬Ed

j ϕ}

(Ed

(Ed

j ϕ)
j ϕ)
(¬Ed

(¬Ed

j ϕ)
j ϕ)

Proof. By rewriting CKCoeΣ

i,j(ϕ) and Σ, we have for (1):

(cid:96) CKCoeΣ

i,j(ϕ) ⇔

(cid:95)

ψ∈Σ

Ed

i (Ed

j ϕ ∧ KjEd

i Ed

j ϕ ∧ ψ) ⇔

(cid:95)

Ed

i (Ed

j ϕ ∧ ψ) ⇔ per

Σ
i,j

(cid:55)

ψ∈Σ

(cid:55)

{KjEd

i Ed

j ϕ}

The same methodology holds for (2), (3) and (4).

Theorem 5.12.

{KjEd

i Ed

j ϕ}

(Ed

j ϕ)

(1) (cid:96) per

(2) (cid:96) per

(3) (cid:96) per

(4) (cid:96) per

Σ
i,j
Σ
i,j
Σ
i,j
Σ
i,j

(cid:55)

(cid:55)

(cid:55)

(cid:55)

{¬KjEd

i Ed

j ϕ}

{¬BjEd

i Ed

j ϕ}

{¬KjEd

i ¬Ed

j ϕ}

{¬BjEd

i ¬Ed

j ϕ}

(Ed

(Ed

j ϕ) ⇔ M CEdKΣ
j ϕ) ⇔ M CEdBΣ
(¬Ed

i,j(ϕ)
i,j(ϕ)
j ϕ) ⇔ M DEdKΣ
j ϕ) ⇔ M DEdBΣ

(¬Ed

i,j(ϕ)
i,j(ϕ)

Proof. By rewriting M CEdKΣ

i,j(ϕ) and Σ, we have for (1):

(cid:96) per

Σ
i,j

(cid:55)

(cid:95)

ψ∈Σ

(cid:55)

{¬KjEd

i Ed

j ϕ}

{¬KjEd

i Ed

j ϕ}

(Ed

j ϕ) ⇔

(cid:95)

Ed

i (BjEd

j ϕ ∧ ψ) ⇔

ψ∈Σ

(cid:55)

{¬KjEd

i Ed

j ϕ}

Ed

i (Ed

j ϕ ∧ ψ) ⇔

Ed

i (Ed

j ϕ ∧ ¬KjEd

i Ed

j ϕ ∧ ψ) ⇔ M CEdKΣ

i,j(ϕ)

(cid:95)

ψ∈Σ

The same methodology holds for (2), (3) and (4).

Theorem 5.13.

68

(1) (cid:96) KCrLieΣ
(2) (cid:96) BCrLieΣ
(3) (cid:96) KSoCoΣ
(4) (cid:96) BSoCoΣ
(5) (cid:96) KCrLieΣ
(6) (cid:96) BCrLieΣ

j ϕ) ⇒ ⊥
j ϕ) ⇒ ⊥
j ϕ) ⇔ M CEdKΣ
j ϕ) ⇔ M CEdBΣ

i,j(Ed
i,j(Ed
i,j(Ed
i,j(Ed
i,j(ϕ) ⇒ P erΣ
i,j(ϕ) ⇒ P erΣ

i,j

(cid:55)

i,j

i,j(ϕ)
i,j(ϕ)
{¬KjBi¬ϕ}

{¬BjBi¬ϕ}

(ϕ)

(cid:55)

(ϕ)

Proof.

(1)

(a) (cid:96) Bi¬Ed

j ϕ ∧ Ed

i (BjEd

j ϕ ∧ ¬KjBi¬ϕ) ⇒ Bi¬Ed

j ϕ ∧ Ed

i (Ed

j ϕ ∧ ¬KjBi¬ϕ)

[RE on Th. ((cid:96) BjEd
j ϕ ∧ Ed

j ϕ ⇔ Ed

j ϕ)]
j ϕ ∧ ¬KjBi¬ϕ) ⇔ Bi¬Ed

i (Ed

(b) Bi¬Ed

j ϕ ∧ BiEd

i (Ed

j ϕ ∧ ¬KjBi¬ϕ) [RE

on Th. ((cid:96) BiEd

i ϕ ⇔ Ed
i (Ed

i ϕ)]

(c) (cid:96) Bi¬Ed

j ϕ ∧ BiEd

j ϕ ∧ ¬KjBi¬ϕ) ⇒ Bi¬Ed

j ϕ ∧ BiEd

j ϕ [Right elim. (∧)

+ Th. (TEd

i

) + Nec. Bi + MP on (K)]

(d) (cid:96) Bi¬Ed
(e) Bi¬Ed

j ϕ ∧ BiEd

j ϕ ⇔ Bi⊥

j ϕ ∧ Ed

i (BjEd

j ϕ ∧ ¬KjBi¬ϕ) ⇒ ⊥

(2) The same methodology as (1) holds for this property.

(3) By rewriting M CEdKΣ

i,j(ϕ) and Σ, we have:

(cid:96) KSoCoΣ

i,j(Ed

j ϕ) ⇔

Ed

i (BjEd

j ϕ ∧ ¬KjEd

i BjEd

j ϕ ∧ ψ) ⇔

(cid:95)

ψ∈Σ

Ed

i (Ed

j ϕ ∧ ¬KjEd

i Ed

j ϕ ∧ ψ) ⇔ M CEdKΣ

i,j(ϕ)

(cid:95)

ψ∈Σ

(4) The same methodology as (3) holds for this property.

i,j(ϕ) ⇒ ((cid:87)
i (Bjϕ ∧ ¬KjBi¬ϕ ∧ ψ)) ⇔ P erΣ

ψ∈Σ Ed

i (Bjϕ ∧ ¬KjBi¬ϕ ∧ ψ))

i,j

[Right Elim. (∧)]

{¬KjBi¬ϕ}

(ϕ)

(cid:55)

[Def.

(5)

(a) (cid:96) KCrLieΣ
(b) (cid:96) ((cid:87)
ψ∈Σ Ed
(P erΣ
i,j
(c) (cid:96) KCrLieΣ

(cid:55)

{¬KjBi¬ϕ}

(ϕ))]
i,j(ϕ) ⇒ P erΣ

i,j

{¬KjBi¬ϕ}

(ϕ)

(cid:55)

[RE (b) in (a)]

(6) The same methodology as (5) holds for (6).

69

