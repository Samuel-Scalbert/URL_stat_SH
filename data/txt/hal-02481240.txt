Semantics of negative sequential patterns
Thomas Guyet, Philippe Besnard

To cite this version:

Thomas Guyet, Philippe Besnard. Semantics of negative sequential patterns. 24 th European Confer-
ence on Artificial Intelligence (ECAI 2020), European Association for Artificial Intelligence (EurAI);
Spanish AI Society (AEPIA); University of Santiago de Compostela (CiTIUS), Aug 2020, Santiago de
Compostela, Spain. pp.1-7. ￿hal-02481240v2￿

HAL Id: hal-02481240

https://inria.hal.science/hal-02481240v2

Submitted on 18 Feb 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Semantics of negative sequential patterns

Philippe Besnard 1 and Guyet Thomas 2

Abstract.
In the ﬁeld of pattern mining, a negative sequential pat-
tern is speciﬁed by means of a sequence consisting of events to occur
and of other events, called negative events, to be absent. For instance,
containment of the pattern ha ¬b ci arises with an occurrence of a and
a subsequent occurrence of c but no occurrence of b in between.

This article is to shed light on the ambiguity of such a seemingly
intuitive notation and we identify eight possible semantics for the
containment relation between a pattern and a sequence. These se-
mantics are illustrated and formally studied, in particular we propose
dominance and equivalence relations between them. Also we prove
that support is anti-monotonic for some of these semantics. Some of
the results are discussed with the aim of developing algorithms to
extract eﬃciently frequent negative patterns.

1 Introduction

In many application domains such as predictive maintenance or mar-
keting, decision makers are interested in discovering speciﬁc events
that trigger or are correlated to undesirable events. Sequential pattern
mining [11] is a technique that extracts such hidden rules from logs.
Often, the presence but also the absence of a speciﬁc action or
event partly explains the occurrence of an undesirable situation [4].
For example in predictive maintenance, if some maintenance oper-
ations have not been performed, e.g. damaged parts have not been
replaced, then a fault is likely to occur in a short delay whereas if
these operations were performed in time the fault would not occur. In
marketing, if a marketplace customer has not received special oﬀers
or coupons for a long time then s/he has a high probability of churn-
ing whereas if s/he were provided with such oﬀers s/he should re-
main loyal to her/his marketplace. Mining speciﬁc events to discover
a context under which they occur, or do not occur, may provide inter-
esting information. It is called actionable information as it serves to
determine what action should be performed to avoid the undesirable
situation, i.e. fault in monitored systems, churn in marketing, . . .

Figure 1. On the left, a synthetic dataset of six sequences. On the right, a
set of rules with their support and accuracy in the dataset.

s1
s2
s3
s4
s5
s6

ha c ei
ha b c ei
ha b c ei
ha c di
ha c di
ha c di

Rule

support

accuracy

ha ci =⇒ e
ha ci =⇒ d
ha ¬b ci =⇒ e
ha ¬b ci =⇒ d

3
3
1
3

1/2
1/2
1/4
3/4

1 CNRS / IRIT, France, email: besnard@irit.fr
2 Institut Agro / IRISA UMR6074, France, email: thomas.guyet@irisa.fr

Standard sequential pattern mining algorithms [11] extract se-
quential patterns that frequently occur in the logs. A sequential pat-
tern is a sequence of events. For example, the sequential pattern
ha c di is read as “a occurs and then c occurs and ﬁnally d occurs”.
In practice, a pattern is frequent if its number of occurrences exceeds
a user-deﬁned threshold. If ha c di occurs in most cases where ha ci
occurs, then the sequential rule ha ci =⇒ d (read as “if a occurs and
c occurs later, then d occurs afterwards”) is useful to predict occur-
rences of d. The premise of a rule speciﬁes what actually occurred
frequently, but does not inform about what did not happen in these
examples. Negative sequential patterns are sequential patterns that
also specify non-occurring events. Intuitively, the syntax of a simple
negative sequential pattern is as follows: ha ¬b ci. This pattern is read
as “a occurs and then c occurs, but b does not occur in between”. A
negative sequential pattern can also be the premise of a rule.

We illustrate the interest of negative sequential patterns via the
dataset of sequences in Figure 1. The rightmost table gives the sup-
port (number of sequences containing both premise and conclusion)
and the accuracy (ratio of the support with the support of the premise
only) of some rules. The sequential patterns ha c di and ha c ei occur
thrice each. Rules ha ci ⇒ d and ha ci ⇒ e obtained from positive
sequential patterns have low accuracy, they are not really interesting.
Let sp = ha b c ?i be a new sequence with an event to predict. The
two rules above predict e or d with the same likelihood.

Modeling the absence of event b in patterns appears to be mean-
ingful to describe the dataset. Indeed, rule ha ¬b ci ⇒ d occurs in
half of the sequences and has an accuracy of 3/4 (whereas the accuracy
of the rule without ¬b is only 1/2). When it comes to predicting occur-
rences of d, the absence of b is meaningful. These new rules predict
event e with a likelihood of 3/4 for sp. In a medical context, a, b and
c may be drug administration while d and e some medical events,
respectively, patient declared cured and patient suﬀering complica-
tions. The situation that is illustrated by our synthetic dataset is the
case of adverse drugs reaction. Being exposed to drug b while being
treated by drugs a and c leads to complications. Mining positive pat-
terns in a medical database would miss such adverse drug reaction.

Mining frequent negative sequential patterns is of utmost interest
to discover actionable rules taking into account absent events. In [10],
pattern mining is viewed as the computation of a theory T h(L, D, C)
= {ψ ∈ L | C(ψ, D)}. Given a pattern language L, some constraints
C and a database D, a pattern mining algorithm enumerates the el-
ements of the language that fulﬁll the constraints within the data.
In the case of frequent pattern mining, C is the minimal support con-
straint. The success of pattern mining techniques comes from an anti-
monotonicity property of some support measures [1]. Intuitively, if a
pattern p is not frequent, no pattern “larger” than p is frequent. Pat-
tern mining algorithms prune the search space whenever an unfre-
quent pattern is found. The “is larger than” relation induces a partial
order on the set of patterns, L. For a support measure that is anti-

• we provide three partial orders for which some containment rela-

tions induce anti-monotonic support measures.

D =

monotonic on this structure, the frequent pattern mining trick can be
used to eﬃciently prune the search space. Ideally, this structure is a
lattice, in which case the above strategy is complete and correct.

As to frequent negative sequential pattern mining, L is the set of
negative sequential patterns, D is a dataset of sequences and C is the
constraint of minimal frequency. Few approaches [3, 5, 7, 8, 9, 14,
15] proposed algorithms to extract such patterns and none of them
proposed an algorithm based on an anti-monotonic support measure.
The questions we address in this article are:

1. what is a proper support measure for negative sequential patterns?
2.

is there a support measure enjoying anti-monotonicity?

The support measure is strongly related to the containment rela-
tion that determines whether a pattern occurs in a sequence or not.
In the case of negative sequential patterns, the apparently intuitive
notion of absent event appears to be intricate and the negation syntax
(the ¬ symbol) used in the literature is hiding diﬀerent semantics. In
logic, it is accepted knowledge that there is more than one kind of
negation [13]. For instance, in classical reasoning ¬p means that p
is false while in stable reasoning ¬p means that p cannot be proved
[2].

The objective of this article is not to propose a new pattern mining
algorithm for negative sequential patterns but to establish formal re-
sults on containment relations that can serve as a basis to design such
algorithms. The main contributions of our work are as follows:

• we deﬁne eight possible semantics for the containment relation of

negative sequential patterns,

• we establish dominance and equivalence relations between con-

tainment relations,

2 Negative sequential patterns

Throughout this article, [n] = {1, . . . , n} denotes the set of the ﬁrst
n positive integers. Let I be the set of items (alphabet). An itemset
A = {a1 a2 · · · am} ⊆ I is a ﬁnite set of items. The length of A,
denoted |A|, is m. A sequence s is of the form s = hs1 s2 · · · sni
where each si is an itemset.

Deﬁnition 1 (Negative sequential patterns (NSP)). A negative se-
quential pattern p = hp1 ¬q1 p2 ¬q2 · · · pn−1 ¬qn−1 pni is a ﬁnite
sequence where pi ∈ 2I \ {∅} for all i ∈ [n] and qi ∈ 2I for all
i ∈ [n − 1].

The length of p, denoted |p| is the number of its non empty itemsets

(negative or positive).

p+ = hp1 . . . pni is called the positive part of the NSP.

We denote by N the set of negative sequential patterns.
It can be noticed that Deﬁnition 1 introduces syntactic limitations
on negative sequential patterns that are commonly encountered in the
state of the art [12]:

• a pattern can neither start or ﬁnish by a negative itemset,
• a pattern cannot have two successive negative itemsets.

Example 1 (Negative sequential pattern). This example illustrates
the notations introduced in Deﬁnition 1. Consider I = {a, b, c, d}
and p = ha ¬(bc) (ad) d ¬(ab) di. Let p1 = {a}, p2 = {ad}, p3 = {d},
p4 = {d} and q1 = {bc}, q2 = ∅, q3 = {ab}. The length of p is |p| = 6
and p+ = ha (ad) d di.

3 Semantics of negative sequential patterns

The semantics of negative sequential patterns relies upon negative
containment: a sequence s supports pattern p (or p matches the se-
quence s) iﬀ s contains a sub-sequence s′ such that every positive
itemset of p is included in some itemset of s′ in the same order and
for any negative itemset ¬qi of p, qi is not included in any itemset
occurring in the sub-sequence of s′ located between the occurrence
of the positive itemset preceding ¬qi in p and the occurrence of the
positive itemset following ¬qi in p.

Deﬁnition 2 (Non inclusion). We introduce two relations comparing
two itemsets P ∈ 2I \ {∅} and I ∈ 2I:

• partial non inclusion: P *G I ⇔ ∃e ∈ P, e < I
• total non inclusion: P *D I ⇔ ∀e ∈ P, e < I

Partial non-inclusion means that P \ I is non-empty while total non-
inclusion means that P and I are disjoint. By convention, ∅ *D I and
∅ *G I for all I ⊆ I.

In the sequel we will denote the general form of itemset non-

inclusion by the symbol *∗, meaning either *G or *D.

Intuitively, partial non-inclusion identiﬁes the itemset P with a dis-
junction of negative constraints, i.e. at least one of the items (of P)
has to be absent from I, and total non-inclusion consider the itemset
P as a conjunction of negative constraints: all items (of P) have to be
absent from I.

Choosing one non-inclusion interpretation or the other has con-
sequences on extracted patterns as well as on pattern search. Let us
illustrate this with the following dataset of sequences:

s1 = h(bc) f ai
s2 = h(bc) (c f ) ai
s3 = h(bc) (d f ) ai
s4 = h(bc) (e f ) ai
s5 = h(bc) (cde f ) ai






.






Table 1 compares the support of patterns under the two semantics of
itemset non-inclusion. Since the positive part of p2 is in s2, p2 occurs
in the sequence iﬀ (cd) *∗ (c f ). As for total non-inclusion, it is false
that (cd) *D (c f ) because c occurs in (c f ), and thus p2 does not
occur in s2. As for partial non-inclusion, it is true that (cd) *G (c f ),
because d does not occur in (c f ), and thus p2 occurs in s2.

Lemma 1. 3 Let P, I ⊆ I be two itemsets:

P *D I =⇒ P *G I

(1)

Table 1. Lists of sequences in D supported by negative patterns ( pi)i=1..4
under the total and partial non-inclusion relations. Each pattern has the form
hb ¬qi ai where qi are itemsets such that qi ⊂ qi+1.

partial
non-inclusion
*G

total
non-inclusion
*D

p1 = hb ¬c ai
p2 = hb ¬(cd) ai
p3 = hb ¬(cde) ai
p4 = hb ¬(cdeg) ai

{s1, s3, s4}
{s1, s2, s3, s4}
{s1, s2, s3, s4}
{s1, s2, s3, s4, s5}

{s1, s3, s4}
{s1, s4}
{s1}
{s1}

Now, we formulate the notions of sub-sequence, non-inclusion and

absence by means of the concept of embedding.

3 All proofs can be found in the appendix of this article.

2

Deﬁnition 3 (Positive pattern embedding). Let s = hs1 . . . sni be
a sequence and p = hp1 . . . pmi be a (positive) sequential pattern.
A tuple e = (ei)i∈[m] ∈ [n]m is an embedding of pattern p in sequence
s iﬀ ∀i ∈ [m], pi ⊆ sei and ei < ei+1 for all i ∈ [m − 1].

Another point that determines the semantics of negative contain-
ment concerns the multiple occurrences of some pattern in a se-
quence: should at least one or should all occurrences of the pattern
positive part in the sequence satisfy the non-inclusion constraints?

Deﬁnition 4 (Strict and soft embeddings of negative patterns). Let
s = hs1 . . . sni be a sequence and p = hp1 ¬q1 . . . ¬qm−1 pmi be a
negative sequential pattern.

An increasing4 tuple e = (ei)i∈[m] ∈ [n]m is a -embedding (read:

soft-embedding) of pattern p in sequence s iﬀ:

• pi ⊆ sei for all i ∈ [m]
• qi *∗ s j, ∀ j ∈ [ei + 1, ei+1 − 1] for all i ∈ [m − 1]

An increasing4 tuple e = (ei)i∈[m] ∈ [n]m is a -embedding (read:

strict-embedding) of pattern p in sequence s iﬀ:

• pi ⊆ sei for all i ∈ [m]
• qi *∗

j∈[ei+1,ei+1−1] s j for all i ∈ [m − 1]

S

Intuitively, the constraint of a negative itemset qi is checked on the
sequence’s itemsets at positions in interval [ei + 1, ei+1 − 1], i.e. be-
tween occurrences of the two positive itemsets surrounding the neg-
ative itemset in the pattern. A soft embedding considers individually
each of the sequence’s itemsets of [ei + 1, ei+1 − 1] while a strict em-
bedding consider them as a whole.

Example 2 (Itemset absence semantics). Let p = ha ¬(bc) di be a
pattern and consider four sequences as follows:

Sequence

*D *D *G *G

s1 = ha c b e di
s2 = ha (bc) e di
s3 = ha b e di
s4 = ha e di

✓

✓

✓
✓

✓

✓
✓

The reader can notice that each sequence contains a unique occur-
rence of p+ = ha di, the positive part of pattern p. Considering soft-
embedding and partial non-inclusion (*∗:=*G), p occurs in s1, s3
and s4 but not in s2. Considering strict-embedding and partial non-
inclusion, p occurs in s3 and s4. Indeed, items b and c occur between
occurrences of a and d in s1 and s2. Considering total non-inclusion
(*∗:=*D) and either type of embeddings, the absence of an itemset
is satisﬁed if any of its items is absent. Hence, p occurs only in s4.

Lemma 2. If e is a -embedding, then e is a -embedding, regardless
of whether *∗ is *G or *D.

Lemma 3. In the case that *∗ is *D, e is a -embedding iﬀ e is a
-embedding

Lemma 4. Let p = hp1 ¬q1 . . . ¬qn−1 pni ∈ N such that |qi| ≤ 1 for
all i ∈ [n − 1], then e is a -embedding iﬀ e is a -embedding.

Lemma 4 shows that in the simple case of patterns where all neg-
ative itemsets are singleton sets, the notions of strict and soft embed-
dings coincide.

Deﬁnition 5 (Negative pattern occurrence). Let s be a sequence and
p be a negative sequential pattern with p+ the positive part of p.
For *∗∈ {*D, *G} and ∈ { , },

• p (cid:22)∗ s denotes that pattern p occurs in sequence s iﬀ there ex-
ists at least one -embedding of p in s considering the *∗ non-
inclusion.

• p ⊑∗ s denotes that pattern p occurs in sequence s iﬀ for each em-
bedding e of p+ in s, e is also a -embedding of p in s considering
the *∗ non-inclusion, and there exists at least one embedding e of
p+.

Deﬁnition 5 permits to capture two semantics for negative sequen-
tial patterns depending on the occurrences of the positive part: p ⊑∗ s
states that a negative pattern p occurs in a sequence s iﬀ there exists
at least one occurrence of the positive part of pattern p in sequence s
and every such occurrence satisﬁes the negative constraints; p (cid:22)∗ s
states that p occurs in a sequence s iﬀ there exists at least one occur-
rence of the positive part of pattern p in sequence s and at least one
of these occurrences satisﬁes the negative constraints.

Example 3 (Strong vs weak occurrence semantics). Let p =
ha b ¬c di be a pattern, s1 = ha b e di and s2 = ha b c a d e b di
be two sequences. Thus, p+ = ha b di occurs once in s1 hence there
is no diﬀerence for occurrences of p in s1 under the two semantics.
However, p+ occurs four times in s2 through embeddings (1, 2, 5),
(1, 2, 8), (1, 7, 8) and (4, 7, 8). The ﬁrst two occurrences do not sat-
isfy the negative constraint (¬c) but the last two occurrences do. Un-
der the weak occurrence semantics, pattern p occurs in sequence s2
whereas it fails to do so under the strong occurrence semantics.

Lemma 6. Let p be an NSP and s a sequence. For
*∗∈ {*D, *G},

p ⊑∗ s =⇒ p (cid:22)∗ s

∈ { , } and

(2)

Lemma 7. Let p be an NSP and s a sequence. For ∈ { , },

p (cid:22)D s =⇒ p (cid:22)G s
p ⊑D s =⇒ p ⊑G s

In this section, we have exhibited several semantics that can be
associated to negative patterns. This leads to eight diﬀerent types
of pattern occurrences. We take Θ to denote the set of containment
relations:

Θ =

(cid:22)D, (cid:22)D, (cid:22)G, (cid:22)G, ⊑D, ⊑D, ⊑G, ⊑G
n

o

These containment relations allow to disambiguate the semantics
of negative pattern containment encountered in the literature. Next,
Section 4 investigates possible equivalent containment relations in Θ.

4 Dominance and equivalence between

containment relations

Lemma 5. Let p ∈ N, if e is an embedding of p in some sequence s,
then e is an embedding of p+ in s.

4 By an increasing tuple e, we mean a tuple such that ei < ei+1 (in particular,

repetitions are not allowed).

Deﬁnition 6 (Dominance). For θ, θ′ ∈ Θ, θ dominates θ′, denoted
θ 1 θ′, iﬀ pθs =⇒ pθ′ s for all p ∈ N and all sequence s.

We denote by θ 61 θ′ iﬀ θ 1 θ′ is false, that is, there is some couple

(p, s) such that pθs but not pθ′ s.

3

The idea behind dominance between two containment relations θ
and θ′ is related to the sequences in which a pattern occurs. By deﬁni-
tion, if θ 1 θ′ then a pattern p ∈ N occurs in a sequence s according
to the θ′ containment relation whenever p occurs in s according to the
θ containment relation. In the context of pattern mining, this is useful
to design algorithms exploiting properties of a dominating contain-
ment relation in order to extract eﬃciently the patterns according to
dominated containment relations.

Lemma 8. The dominance relation 1 is a pre-order.

Deﬁnition 7 (Equivalent containment relations). For θ, θ′ ∈ Θ, θ is
equivalent to θ′, denoted θ ∼ θ′ iﬀ θ 1 θ′ and θ′ 1 θ.

Lemma 9. ∼ is an equivalence relation on Θ.

Two equivalent containment relations have equivalent semantics,
in the following sense: the sets of sequences in which a given pattern
occurs are the same and, reciprocally, the sets of negative patterns
that occur in a sequence are the same when considering these two
containment relations.

We now study the dominance relations that hold between the ele-

ments of Θ.

Proposition 1. The following dominance statements between con-
tainment relations hold:

⊑∗ 1 (cid:22)∗
(cid:22)∗ 1 (cid:22)∗ and ⊑∗ 1 ⊑∗
(cid:22)D 1 (cid:22)D and ⊑D 1 ⊑D

(cid:22)D 1 (cid:22)G and ⊑D 1 ⊑G

and the following non-dominance statements hold:

(cid:22)G 61 (cid:22)D and ⊑G 61 ⊑D
(cid:22)∗ 61 ⊑∗
(cid:22)G 61 (cid:22)G and ⊑G 61 ⊑G

(cid:22)G 61 ⊑G

⊑G 61 (cid:22)G
(cid:22)∗ 61 ⊑∗′
(cid:22)D 61 ⊑G

⊑G 61 (cid:22)D

(3)

(4)

(5)

(6)

(7)

(8)

(9)

(10)

(11)

(12)

(13)

(14)

classes become:
. Figure
2 illustrates the dominance relation on the quotient set Θ/∼ in this
speciﬁc case.

(cid:22)D, (cid:22)D
n

⊑D, ⊑D

(cid:22)G, (cid:22)G

⊑G, ⊑G

and

o

o

o

n

n

n

o

,

,

Figure 2. Dominance between containment relations. The labels for edges
refer to the corresponding equations in Proposition 1. Dominance goes from
top to bottom i.e. ⊑D as well as ⊑D dominate all other containment relations.
⊑D ∼ ⊑D

(3)

(6)

(cid:22)D ∼ (cid:22)D

(6)

⊑G

(3)

(4)

⊑G

(3)

(cid:22)G

(4)

(cid:22)G

Figure 3. Dominance between containment relations for the case that, in
negative sequential patterns, negative itemsets are restricted to be singleton
sets. The labels for edges again refer to the equations given in Proposition 1.
⊑D ∼ ⊑D

(3)

(6)

(cid:22)D ∼ (cid:22)D

⊑G ∼ ⊑G

(6)

(3)

(cid:22)G ∼ (cid:22)G

where *∗∈

*D, *G

and ∈ { , }.

5 Anti-monotonicity

n

o

Proposition 1 gathers results from Section 3. Each line expresses
several relationships between pairs of containment relations. Equa-
tions 4-6 are dominance statements deduced from Lemmas 2, 3, 6
and 7. Equations 7-9 state the absence of dominance for which we
can exhibit counterexamples. In addition, many other dominance and
non dominance relationships can be deduced from Proposition 1 us-
ing transitivity of dominance (Lemma 8). Table 2 summarizes them.
An interesting result in Proposition 1 is that there are two pairs of
containment relations,
, whose two members
and
are equivalent. In fact, there are six equivalence classes of contain-
(cid:22)D, (cid:22)D
(cid:22)G
(cid:22)G
ment relations:
. Figure
2 illustrates the dominance relation on the quotient set Θ/∼.
o

(cid:17)
⊑D, ⊑D
n

⊑D, ⊑D

(cid:22)D, (cid:22)D

(cid:16)
⊑G

(cid:16)
,
o

and

,
o

⊑G

(cid:17)
,

n

o

n

o

o

n

n

n

,

We can ﬁnally point out that Lemma 4 adds a dominance relation-
ship for the case that, in negative sequential patterns, negative item-
sets are restricted to be singleton sets. In this case, the equivalence

4

It is now time to check whether there are containment relations that
enjoy interesting properties. In our initial context of mining frequent
negative sequential patterns, we investigate anti-monotonicity prop-
erties.

According to Wang et al. [12], “the downward property (. . . ) does
not hold in negative sequential analysis”. The “downward property”
denotes the anti-monotonicity property. We will see that this asser-
tion is actually false with some semantics.

Anti-monotonicity makes sense only with a partial order on the set
of NSPs. We ﬁrst introduce diﬀerent possible partial orders and then
we introduce anti-monotonicity.

In the remaining of the section, non-inclusion of itemsets is total
non-inclusion, *D. Thus, we can count on the anti-monotonicity of
non-inclusion of itemsets: q ⊆ q′ =⇒ ∀p ∈ I, (q′ *D p ⇒ q *D
p) for all itemsets q, q′.

Table 2. Dominance. 1 (resp. −) means that the semantics at the left of the row dominates (resp. does not dominate) the semantics at the top of the column.

⊑G

·

−

−

−

1

−

1

−

(cid:22)G

1

·

−

−

1

1

1

1

⊑G

(cid:22)G

⊑D

(cid:22)D

⊑D

(cid:22)D

1

−

·

−

1

−

1

−

1

1

1

·

1

1

1

1

−

−

−

−

·

−

1

−

−

−

−

−

1

·

1

1

−

−

−

−

1

−

·

−

−

−

−

−

1

1

1

·

⊑G

(cid:22)G

⊑G

(cid:22)G

⊑D

(cid:22)D

⊑D

(cid:22)D

5.1 Partial orders

5.2 Anti-monotonicity

Deﬁnition 8 introduces three relations between negative sequential
patterns that are partial orders (see Proposition 2).

Let us ﬁrst deﬁne the anti-monotonicity property of a containment
relation θ ∈ Θ considering a strict partial order ⋉ ∈ {⊳, ⊳· , ⊳+ }.

Deﬁnition 8 (NSP relations). Consider two NSPs p = hp1
¬q1 p2 ¬q2
· · ·
k′−1 ¬q′
p′
By deﬁnition, p ⊳· p′ iﬀ k ≤ k′ and there exists an increasing4

· · · pk−1 ¬qk−1 pki and p′ = hp′
k′ i.

k′−1 p′

1 ¬q′

2 ¬q′

1 p′

2

tuple (ui)i∈[k] ∈ [k′]k and:

1. ∀i ∈ [k], pi ⊆ p′
ui
2. ∀i ∈ [k − 1], qi ⊆
3. k = k′ =⇒ ∃ j ∈ [k], p j , p′

j∈[ui,ui+1−1] q′

j

S

j or ∃ j ∈ [k − 1], q j , q′

j

by deﬁnition, p ⊳ p′ iﬀ k ≤ k′ and:

1. ∀i ∈ [k], pi ⊆ p′
i
2. ∀i ∈ [k − 1], qi ⊆ q′
i
3. k = k′ =⇒ pk , p′

k or ∃ j ∈ [k − 1] s.t. q j , q′

j

and, by deﬁnition, p ⊳+ p′ iﬀ k = k′ and:

1. ∀i ∈ [k], pi = p′
i
2. ∀i ∈ [k − 1], qi ⊆ q′
i
3. ∃ j ∈ [k − 1] s.t. q j , q′
j

The ⊳· relation can be seen as the “classical” inclusion relation
between sequential patterns [11]. An NSP p is less speciﬁc than p′
iﬀ p+ is a subsequence of p′+ and negative constraints are satisﬁed.
The main diﬀerence with ⊳ is that ⊳· permits to insert new positive
itemsets in the middle of the sequence while ⊳ permits only insertion
of new positive itemsets at the end.5,6 Nonetheless, it is still possible
to insert items to the positive itemsets. The ⊳+ does not even permit
such diﬀerences: for two NSPs to be comparable via ⊳+ , they must
have the same positive itemsets.

Lemma 10. For p, p′ ∈ N,

p ⊳+ p′ =⇒ p ⊳ p′ =⇒ p ⊳· p′

(15)

Proposition 2 (Strict partial orders). ⊳· , ⊳ and ⊳+ are partial orders
on N.

We can notice that the third conditions in Deﬁnition 8 enforce the
relations to be irreﬂexive. Removing these conditions enables to de-
ﬁne non-strict partial orders.

5 In sequential pattern mining, it is called a backward-extension of the pat-

terns.

6 We remind that, by Deﬁnition 1, pi , ∅ and that we never have two succes-

sive negative itemsets in an NSP.

Deﬁnition 9 (Anti-monotonicity on (N, ⋉)). Let θ ∈ Θ be a con-
tainment relation, θ is anti-monotonic on (N, ⋉) iﬀ for all p, p′ ∈ N
and all sequences s:

p ⋉ p′ =⇒ (p′θs =⇒ pθs)

First of all, we provide an example showing that none of the con-
tainment relations is anti-monotonic on (N, ⊳· ). Let p = hb ¬c ai,
p′ = hb ¬c d ai and s = hb e d c ai. Then, we have p ⊳· p′.7 Nonethe-
less, for each θ ∈ Θ, p′θs but it is false that pθs.

In fact, the presence of the item d in the sequence changes the
scope for checking the absence of c. This example is similar to the
one used by Zheng et al. [15] to state that anti-monotonic property
does not hold for negative sequential patterns. Nonetheless, the anti-
monotonicity property holds in case the partial order prevents from
changing the scope for absent items.

Proposition 3. (cid:22)D and (cid:22)D are anti-monotonic on (N, ⊳).

Proposition 3 shows that using the ⊳ partial order causes anti-
monotonicity to hold for containment with weak-occurrence. It is
not the case with strong-occurrence, though. Let us give a coun-
terexample illustrating what can happen with strong-occurrence. Let
p = ha ¬b ci, p′ = ha ¬b c di and s = ha c d a b ci. Then, we have
p ⊳ p′.8 Nonetheless, p′ ⊑D s holds but it is false that p ⊑D s. In
fact, without the presence of the item d in the pattern, there are three
possible embeddings of p in s. For ⊑D each embedding must satisfy
the negation of b, which is not the case, but for (cid:22)D it is suﬃcient to
have only one embedding satisfying negations.

The previous example illustrates the problem when extending the
pattern with additional itemsets. The same issue is encountered with
the following example considering patterns of equal length while one
pattern has an extended itemset. Let p = ha ¬b ci, p′ = ha ¬b (cd)i
and s = ha (cd) a b ci. Then, we have p ⊳ p′. Nonetheless, p′ ⊑D s
holds but it is false that p ⊑D s.

Proposition 4. (cid:22)D, (cid:22)D, ⊑D and ⊑D are anti-monotonic on (N, ⊳+ ).

We remind that this section was restricted to the case of total non-
inclusion (*D) but the results also hold when *D is replaced by *G
except that we must reverse the inclusion relations for negatives in
j∈[ui,ui+1−1] q′
i ⊆ qi for ⊳
the partial orders (that is,
and ⊳+ ).

j ⊂ qi for ⊳· and q′

S

7 In this case, we do not have p ⊳ p′ nor p ⊳+ p′
8 In this case, we also have p ⊳· p′ (see Lemma 10) but not p ⊳+ p′

5

6 Application to pattern mining

7 A proposal to disambiguate syntax of negative

The deﬁnitions of pattern support, frequent pattern and pattern min-
ing derive naturally from the notion of occurrence of a negative se-
quential pattern, no matter the choices for embedding (soft or strict),
non-inclusion (partial or total) and occurrences (weak or strong).
However, these choices about the semantics of NSPs impact directly
the number of frequent patterns (under the same minimal threshold
constraint) and also computation time. The stronger the negative con-
straints, the fewer the number of sequences containing a pattern, and
the lesser the number of frequent patterns.

Deﬁnition 10 (Pattern supports). Let D = {si}i∈[n] be a dataset of
sequences and p be an NSP. The support of p in D, denoted supp−
θD(p), is the number of sequences of D in which p occurs according
to the θ ∈ Θ containment relation.

When there is no ambiguity on the dataset of sequences, supp−

θD(p) is denoted supp−θ(p).

Clearly, if a containment relation θ is dominated by another con-
tainment relation θ′, then the support of the pattern evaluated with θ
is lower than the support of the pattern evaluated with θ′. The next
proposition ensues from Proposition 1.

Proposition 5. For p ∈ N,

supp− ⊑∗ (p) ≤ supp− (cid:22)∗ (p)

supp− ⊑∗ (p) ≤ supp− ⊑∗ (p)
supp− (cid:22)∗ (p) ≤ supp− (cid:22)∗ (p)

supp− ⊑D (p) ≤ supp− ⊑D (p)
supp− (cid:22)D (p) ≤ supp− (cid:22)D (p)

supp− ⊑D (p) ≤ supp− ⊑G (p)
supp− (cid:22)D (p) ≤ supp− (cid:22)G (p)

(16)

(17)

(18)

(19)

In addition, the following anti-monotonicity properties of support

measures ensue from Propositions 3 and 4.

Proposition 6. For p, p′ ∈ N,

p ⊳ p′ =⇒ supp− (cid:22)D (p′) ≤ supp− (cid:22)D (p)

(20)

p ⊳+ p′ =⇒

supp− ⊑D (p′) ≤ supp− ⊑D (p)
supp− (cid:22)D (p′) ≤ supp− (cid:22)D (p)

(

(21)

There are two practical ways to exploit these results to implement
eﬃcient frequent NSP mining algorithms. On the one hand, the re-
sults from Proposition 6 can be directly used to implement algo-
rithms with eﬃcient and correct strategies to prune the search space.9
For (cid:22)D containment relation, Equation 20 exploits the ⊳ partial or-
der to early prune a priori unfrequent patterns. For ⊑D containment
relation, the ⊳+ partial order must be used to ensure the correctness of
the algorithm (Equation 21). Unfortunately, ⊳+ is less interesting than
⊳ because there are fewer pairs of comparable patterns. On the other
hand, the support evaluated with (cid:22)D is an upper bound for the sup-
port of ⊑D (Equation 16). Thus, it is possible also to prune patterns
accessible with the partial order ⊳ without losing the correctness of
the pruning strategy.

sequential patterns

The ¬ symbol is overloaded in the literature about negative sequen-
tial pattern mining. Our intuition was that the diﬀerent approaches
[3, 7, 8, 9, 15] do not extract the same set of patterns because of
slightly diﬀerent deﬁnition of negative patterns. Our framework deals
with the need to deﬁne an unambiguous containment relation be-
tween a negative sequential pattern p and a sequence s that informs
the user about:

• how multiple occurrences of the positive part of p are handled,
• how negative itemsets are handled (type of embedding and type of

non-inclusion relation).

We separate these two dimensions of our deﬁnition of a containment
relation because the second refers to single itemsets, while the ﬁrst
refers to the whole pattern.

Thanks to our framework, we are able to assign a containment
relation to each approach from the literature. The approaches based
on eNSP [3, 7] are based on the containment relation ⊑D, PNSP [9]
uses the relation (cid:22)G, and NegPSpan [8] and NegGSP [15] deal with
the equivalent relations (cid:22)D and (cid:22)D.

This conﬁrms our initial intuition: the diﬀerent approaches do not
use the same containment relations and thus they do not aim at ex-
tracting the same set of patterns. Moreover, it is worth noticing that
these four approaches explore a large range of the possible con-
tainment relations. eNSP exploits the strong notion of occurrence
while the other approaches exploit the weak notion. All but PNSP
approaches are based on total non-inclusion. Strict-embedding ( ) is
generally preferred to soft-embedding ( ). eNSP (⊑D) made the most
restrictive choice by using the containment relation that dominates
all the others. On the opposite, the two least restrictive choices ((cid:22)G
and ⊑G) have not been explored, presumably due to their obvious
lack of suitable properties for pattern mining.

Finally, it is worth comparing negative sequential patterns with
some formulas in Linear Temporal Logic on ﬁnite traces (LTLf) [6].
The question is to ﬁnd speciﬁc LTLf formulas capturing our contain-
ment relations between any two patterns p and s. Then, it is inter-
esting to notice that containment relations based on soft-embedding
have simple counterparts in the language of LTLf. Indeed, the soft-
embedding constraint imposes each successive itemset of a sequence
to not contain some negated items. The strict-embedding constraint,
which requires to evaluate a union of items, does not ﬁt well to the
linearity of LTLf formulas.

8 Conclusions and perspectives

In this article, we investigated formal properties of the semantics of
negation in sequential patterns to answer our two main questions.

1. What is a proper support measure for negative sequential pat-
terns? We gave eight possible semantics and as many support
measures. We can conclude that there is not a single way to eval-
uate the support of an NSP.

2. Is there a support measure enjoying anti-monotonicity? We run
counter the state of the art by proposing three partial orders for
which anti-monotonicity holds although only for some semantics
of negative sequential pattern mining.

9 Completeness and non-redundancy of algorithms are out of the scope of this

article.

The combination of partial order ⊳ and containment relation (cid:22)D
appears to be a good candidate for developping a complete, correct

6

[2] Pedro Cabalar, David Pearce, and Agust´ın Valverde, ‘Stable reasoning’,
Journal of Applied Non-Classical Logics, 27(3-4), 238–254, (2017).
[3] Longbing Cao, Xiangjun Dong, and Zhigang Zheng, ‘e-NSP: Eﬃcient
negative sequential pattern mining’, Artiﬁcial Intelligence, 235, 156–
182, (2016).

[4] Longbing Cao, Philip S. Yu, and Vipin Kumar, ‘Nonoccurring behavior
analytics: A new area’, Intelligent Systems, 30(6), 4–11, (2015).
[5] Yen-Liang Chen, Mei-Ching Chiang, and Ming-Tat Ko, ‘Discovering
time-interval sequential patterns in sequence databases’, Expert System
with Applications, 25(3), 343–354, (2003).

[6] Giuseppe De Giacomo and Moshe Y Vardi, ‘Linear temporal logic and
linear dynamic logic on ﬁnite traces’, in Proceedings of the Interna-
tional Joint Conference on Artiﬁcial Intelligence (IJCAI), (2013).
[7] Yongshun Gong, Tiantian Xu, Xiangjun Dong, and Guohua Lv, ‘e-
NSPFI: Eﬃcient mining negative sequential pattern from both frequent
and infrequent positive sequential patterns’, Int. Journal of Pattern
Recognition and Artiﬁcial Intelligence, 31(02), 1750002, (2017).
[8] Thomas Guyet and Ren´e Quiniou, ‘NegPSpan: eﬃcient extraction of
negative sequential patterns with embedding constraints’, Data Mining
and Knowledge Discovery, 34(2), 563–609, (2020).

[9] Sue-Chen Hsueh, Ming-Yen Lin, and Chien-Liang Chen, ‘Mining neg-
ative sequential patterns for e-commerce recommendations’, in Proc. of
Asia-Paciﬁc Services Computing Conference, pp. 1213–1218, (2008).

[10] Tomasz Imielinski and Heikki Mannila, ‘A database perspective on
knowledge discovery’, Communications of the ACM, 39(11), 58–64,
(1996).

[11] Carl H. Mooney and John F. Roddick, ‘Sequential pattern mining –
approaches and algorithms’, ACM Computing Survey, 45(2), 1–39,
(2013).

[12] Wei Wang and Longbing Cao, ‘Negative sequence analysis: A review’,

ACM Computing Survey, 52(2), 32:1–32:39, (2019).

[13] Heinrich Wansing, Negation, chapter 18, 415–436, John Wiley & Sons,

Ltd, 2017.

[14] Tiantian Xu, Xiangjun Dong, Jianliang Xu, and Yongshun Gong, ‘E-
msNSP: Eﬃcient negative sequential patterns mining based on multiple
minimum supports’, Int. Journal of Pattern Recognition and Artiﬁcial
Intelligence, 31(02), 1750003, (2017).

[15] Zhigang Zheng, Yanchang Zhao, Ziye Zuo, and Longbing Cao,
‘Negative-GSP: An eﬃcient method for mining negative sequential pat-
terns’, in Proc. of the Australasian Data Mining Conference, pp. 63–67,
(2009).

and non-redundant negative sequential pattern mining algorithm [8].
One advantage of an approach based on an anti-monotonic support
measure is the beneﬁt from decades of research in pattern mining so
as to extend the mining of NSP to the mining of closed NSP or the
mining of NSP with maxgap or maxspan constraints.

Nonetheless, no semantics is “more correct” or relevant than an-
other one. It depends on the notion to be captured. Our objective is
to give the opportunity to make an educated choice. It is especially
important with NSP as the choice of a mining algorithm is not only
a matter of computational eﬃciency, but also a matter of semantics.
In view of Deﬁnition 4 and Lemma 3, three possibilities arise
for evaluating a negative itemset (syntactically distinguished be-
low by writing a negative itemset ¬(a1, . . . , ali ) or ¬{a1, . . . , ali } or
¬|a1, . . . , ali |) as follows:

¬(a1, . . . , ali ) is evaluated as

{a1, . . . , ali } *G s j, ∀ j ∈ [ei + 1, ei+1 − 1] for all i ∈ [m − 1]

Intuitively, you check that, in between sei (i.e., a match for pi)
and sei+1 (i.e., a match for pi+1), none of these s j include all of
a1, . . . , ali .

¬{a1, . . . , ali } is evaluated as

{a1, . . . , ali } *G

j∈[ei+1,ei+1−1] s j for all i ∈ [m − 1]

S

Intuitively, you check that there exists some item in a1, . . . , ali that
does not occur at all in between sei (i.e., a match for pi) and sei+1
(i.e., a match for pi+1).

¬|a1, . . . , ali | is evaluated as

{a1, . . . , ali } *D

j∈[ei+1,ei+1−1] s j for all i ∈ [m − 1]

Intuitively, you check that every item in a1, . . . , ali fails to occur in
between sei (i.e. , a match for pi) and sei+1 (i.e., a match for pi+1).

S

This opens the way for a syntax of negative sequential patterns that
is even more expressive. Indeed, it enables to mix diﬀerent types of
negation within a pattern. For instance, we can specify patterns such
as ha ¬|bc| f ¬{ac} bi (intuitively: none of b and c occur between a
and f ; also, either a or c (or both) does not occur at all between f
and b).

The ﬁrst perspective of this work is to evaluate the proposed nota-
tions on a panel of real users. A preliminary survey concluded on a
lack of any dominant interpretation of the ¬ symbol. We would like
to conﬁrm this preliminary result on a larger panel and to evaluate the
beneﬁt of having a dedicated syntax for each containment relation.

Our second perspective is to extend our theoretical results from
the pattern recognition perspective. Matching sequential patterns in
sequences is a fundamental issue in monitoring of discrete event sys-
tems, in genetic data analysis, in text analysis, etc. Adding negations
to sequential patterns increases the expressivity of the pattern lan-
guage. It raises questions about space and time complexity of the
recognition and/or enumeration of negative sequential patterns: are
the diﬀerent containment relations equally hard to evaluate in se-
quences?

REFERENCES

[1] Rakesh Agrawal and Ramakrishnan Srikant, ‘Fast Algorithms for Min-
ing Association Rules in Large Databases’, in Proceedings of the Inter-
national Conference on Very Large Data Bases (VLDB), pp. 487–499,
(1994).

7

Proofs

Proof of Lemma 1. Let P, I ⊆ I s.t. P *D I. If P = ∅, by deﬁnition,
P *G I. Otherwise, because P is not empty, then there exists e ∈ P
s.t. e < I, i.e. P *G I.

Proof of Lemma 2. Let e = (ei)i∈[m] ∈ [n]m be a -embedding of a
NSP p = hp1 ¬q1 . . . ¬qm−1 pmi in a sequence s = hs1 . . . sni.
For all positive itemsets pi, the deﬁnition of
-embedding matches
-embedding. For a negative itemset qi, let us start with
the one for
*G:=*∗. By deﬁnition 4, qi *G
j∈[ei+1,ei+1−1] s j, and by Deﬁnition
2, ∃α ∈ qi, α <
j∈[ei+1,ei+1−1] s j. And then, ∃α ∈ qi, ∀ j ∈ [ei +
S
1, ei+1 − 1], α < s j. That is ∀ j ∈ [ei + 1, ei+1 − 1], ∃α ∈ qi, α < s j.
This shows ∀ j ∈ [ei + 1, ei+1 − 1], qi *G s j ( -embedding deﬁnition).
It remains *D:=*∗. By deﬁnition 4, qi *D
j∈[ei+1,ei+1−1] s j, and by
Deﬁnition 2, ∀α ∈ pi, α <
j∈[ei+1,ei+1−1] s j. And then, ∀α ∈ qi, ∀ j ∈
[ei +1, ei+1 −1], α < s j. That is ∀ j ∈ [ei +1, ei+1 −1], ∀α ∈ qi, α < s j.
This shows ∀ j ∈ [ei + 1, ei+1 − 1], qi *∗ s j.

S

S

S

Proof of Lemma 3. Let s = hs1 . . . sni be a sequence and p =
hp1 ¬q1 . . . ¬qm−1 pmi be a negative sequential pattern. Lemma 2
shows that -embedding implies -embedding. It remains the implica-
tion to the left. Let e = (ei)i∈[m] ∈ [n]m be a -embedding of pattern p
in sequence s. Then, the deﬁnition matches the one for -embedding
for positives, pi. For negatives, qi, then ∀ j ∈ [ei+1, ei+1−1], qi *D s j,
i.e. ∀ j ∈ [ei+1, ei+1−1], ∀α ∈ qi, α < s j and then ∀α ∈ qi, ∀ j ∈ [ei +
1, ei+1 − 1], α < s j. It thus implies that ∀α ∈ qi, α <
j∈[ei+1,ei+1−1] s j,
i.e. by deﬁnition, qi *D

j∈[ei+1,ei+1−1] s j.

S

S

Proof of Lemma 4. Let s = hs1 . . . sni be a sequence and p =
hp1 ¬q1 . . . ¬qm−1 pmi be a NSP s.t. ∀i, |qi| ≤ 1. Due to Lemma 3, we
only need to deal with the case that *∗ is *G. Let e = (ei)i∈[m] ∈ [n]m
be a -embedding of p in s then, by deﬁnition, 1) pi ⊆ sei for all
j ∈ [ei + 1, ei+1 − 1]. In case
i ∈ [m] and 2) qi *G s j for all
|qi| = 0, there is no constraint. In case |qi| = 1, then 2) becomes
qi < s j for all j ∈ [ei + 1, ei+1 − 1]. Hence, qi <
j∈[ei+1,ei+1−1] s j
j∈[ei+1,ei+1−1] s j. As a consequence e is a -embedding of
i.e. qi *G
p.

S

S

Proof of Lemma 5. Let s = hs1 . . . sni be a sequence and p =
hp1 ¬q1
. . . ¬qm−1 pmi ∈ N be a pattern. By deﬁnition 4, if
e = (ei)i∈[m] ∈ [n]m is an embedding of pattern p in sequence s then
∀i ∈ [m]: pi ⊆ sei because pi is positive. The condition ei < ei+1
in Deﬁnition 3 immediately follows from the requirement in Deﬁni-
tion 4 that e be increasing with no repetition. It ensues that e is an
embedding of the positive pattern p+.

Proof of Lemma 6. Let s = hs1 . . . sni be a sequence and p =
hp1 ¬q1 . . . ¬qm−1 pmi ∈ N be a pattern s.t. p ⊑∗ s. Then, there
exists e an embedding of p+ in s and, by deﬁnition, it is also an em-
bedding of p in s. This means that p (cid:22)∗ s.

Proof of Lemma 7. Let s = hs1 . . . sni be a sequence and p =
hp1 ¬q1 . . . ¬qm−1 pmi ∈ N be a pattern.

We start by considering relations between semantics at the embed-

ding level, and then we will conclude at the pattern level.

Let’s ﬁrst assume that

is . Consider a ( , D)-embedding e =
(ei)i∈[m] of pattern p in sequence s. Hence, ∀i ∈ [m], pi ⊆ sei and
∀i ∈ [m − 1], ∀ j ∈ [ei + 1, ei+1 − 1], qi *D s j. According to eq. 1, we
have qi *G s j. It ensues that e is a ( , (cid:22))-embedding.

Let’s now assume that

is . Let e = (ei)i∈[m] be a ( , D)-embedding
of pattern p in sequence s. Hence, ∀i ∈ [m], pi ⊆ sei and ∀i ∈ [m − 1],
j∈[ei+1,ei+1−1] s j ⊆ I, hence ∀i ∈
qi *D

j∈[ei+1,ei+1−1] s j. In addition

S

S

8

[m − 1], qi *G
an ( , (cid:22))-embedding.

S

j∈[ei+1,ei+1−1] s j according to eq. 1. It ensues that e is

Let’s come back to the pattern level. Consider p JD s, in the two
cases (J∈ {(cid:22), ⊑}). In the ﬁrst case the existing ( , D)-embedding is a
( , G)-embedding, and in the second case, all ( , D)-embeddings are
( , G)-embeddings. Therefore, we have that p JG s.

Proof of Lemma 8. A pre-order is a reﬂexive, transitive binary re-
lation. The reﬂexivity of the relation comes with Deﬁnition 6. Let
θ, θ′, θ′′ ∈ Θ be three dominance relations s.t. θ 1 θ′ and θ′ 1 θ′′.
Then, for all p ∈ N and sequence s: pθs =⇒ pθ′ s and pθ′ s =⇒
pθ′′ s. Hence, we have, pθs =⇒ pθ′′ s, i.e. θ 1 θ′′.

Proof of Lemma 9. Let θ, θ′ ∈ Θ, by reﬂexivity of 1 we have that ∼
is reﬂexive. By deﬁnition (θ 1 θ′ ∧ θ′ 1 θ), ∼ is symmetric. And ,
∼ is also transitive. Let θ, θ′, θ′′ ∈ Θ be three dominance relations s.t.
θ ∼ θ′ and θ′ ∼ θ′′ then, θ 1 θ′, θ′ 1 θ′′, θ′ 1 θ and θ′′ 1 θ′. Hence,
by transitivity of 1, θ 1 θ′′ and θ′′ 1 θ, θ ∼ θ′′.

Proof of Proposition 1. Let p ∈ N and s a sequence.

According to Lemma 6, p ⊑∗ s =⇒ p (cid:22)∗ s. Thus we obtain

Equality 3 by Deﬁnition 6.

According to Lemma 7, p JD s =⇒ p JG s. Thus we obtain

Equality 6 by Deﬁnition 6.

According to Lemma 2, a -embedding is a -embedding whatever
the itemset non-inclusion operator. Then, we get p (cid:22)∗ s =⇒ p (cid:22)∗
s. Lemma 2 holds for any -embedding, hence p ⊑∗ s =⇒ p ⊑∗ s.
All this gives p J∗ s =⇒ p J∗ s (Equality 4).

In addition, Lemma 3 shows that a -embedding is a -embedding
(and vice-versa) in case of total itemset non-inclusion. Then, we can
conclude that p JD s =⇒ p JD s (Equality 5).

Let now gives some counterexamples for known non-dominance
relationships. For each non-dominance relation, θ 61 θ′, we provide
counterexamples for some θ, θ′ ∈ Θ, i.e. a pattern p and a sequence s
such that pθs but not pθ′ s.

• Equation (7): θ = (G,

, J), θ′ = (D,

, J): Let p = ha ¬(bc) di,

s = ha b di, then pθs but not pθ′ s.

• Equation (8): θ = (∗,

, (cid:22)), θ′ = (∗,

, ⊑): Let p = ha ¬b ci, s =

ha c b ci, then pθs but not pθ′ s.

• Equation (9): θ = (G,

, J), θ′ = (G,

, J): Let p = ha ¬(bc) di,

s = ha b c di, then pθs but not pθ′ s.

, (cid:22)), θ′ = (G,

• Equation (10): θ = (G,

, ⊑): Let p = ha ¬(bc) di,
s = ha b d c di, then pθs but not pθ′ s. The strict embedding works
for one embedding of the positive partner, but there is a positive
partner embedding for which even the soft-embedding.

• Equation (11): θ = (G,

, ⊑), θ′ = (G,

, (cid:22)): Let p = ha ¬(bc) di,

s = ha b c di, then pθs but not pθ′ s.

• Equation (12): θ = (∗,

, (cid:22)), θ′ = (∗′,
, ⊑): Let p = ha ¬b ci,
s = ha c b ci, then pθs but not pθ′ s. Redundant with (8) when
∗′ = ∗.

• Equation (13): θ = (D,

, (cid:22)), θ′ = (G,

, ⊑): Let p = ha ¬b ci,

s = ha c b ci, then pθs but not pθ′ s.

• Equation (14): θ = (G,

, ⊑), θ′ = (D,

, (cid:22)): Let p = ha ¬(bc) di,

s = ha b di, then pθs but not pθ′ s.

Proof of Lemma 10. We start with the implication p ⊳+ p′ =⇒ p ⊳
p′. Let p, p′ ∈ N s.t. p ⊳+ p′. By deﬁnition, k = k′ and 1. ∀i ∈
[k], pi = p′
i , 2. ∀i ∈ [k − 1], qi ⊆ q′
i and 3. ∃ j ∈ [k − 1] s.t. qi , q′
i.
A particular case of 1. is that ∀i ∈ [k], pi ⊆ p′
i . In addition, the third

condition of ⊳ is obtained easily from 3. by adding a disjunctive
condition. Hence, p ⊳ p′.

We now prove the second implication: p ⊳ p′ =⇒ p ⊳· p′. Let
p, p′ ∈ N s.t. p ⊳ p′. Let’s now deﬁne the sequence ui such that
ui = i for all i ∈ [k]. By construction, we have that ui < ui+1, for all
i ∈ [k − 1] (see the increasingness requirement in the deﬁnition of ⊳· ).
In addition, by deﬁnition of ⊳, we have that ∀i ∈ [k], pi ⊆ p′
i = p′
ui ,
and ∀i ∈ [k − 1], qi ⊆ q′
j∈[i,(i+1)−1] q′
j. Assuming
k = k′, then pk , p′
k or ∃ j ∈ [k − 1] s.t. q j , q′
k the third
condition of ⊳· is satisﬁed (with j = k). Otherwise, it is also satisﬁed
with the j of the deﬁnition of ⊳.

j. If pk , p′

j∈[ui,ui+1−1] q′

i =

j =

S

S

Note that the proof of the results of Table 2 in the article is given

at the end of this supplementary material.

Proof of Proposition 2. We ﬁrst remind that ⊳· is a strict partial order
iﬀ the three following conditions hold:

1. ∀p ∈ N, not p ⊳· p (irreﬂexive),
2. ∀p, p′, p′′ ∈ N, p ⊳· p′ and p′ ⊳· p′′ =⇒ p ⊳· p′′ (transitivity),
3. ∀p, p′ ∈ N, p ⊳· p′ =⇒ not p′ ⊳· p (antisymmetry)

By Lemma 10, if ⊳· is irreﬂexive and antisymmetric then so are ⊳
and ⊳+ . Hence, we only show that ⊳· is a strict partial order and then
show transitivity for ⊳ and ⊳+ .

We now prove that ⊳· is a strict partial order.

S

j∈[ui,ui+1−1]

Irreﬂexivity. Let’s assume that ∃p ∈ N s.t. p ⊳· p. Then, identity is
the only possibility for u, i.e. ui = i, for all i ∈ [k]. Then, the third
condition implies that ∃ j ∈ [k − 1] s.t. q j , q j or p j , p j, which is
absurd. Then ⊳· is irreﬂexive.
Transitivity. Let p, p′, p′′ ∈ N s.t. p ⊳· p′ and p′ ⊳· p′′. We de-
note by (ui)i ∈ [k′]k and (vi)i ∈ [k′′]k′
the respective mapping, and
we deﬁne (wi)i ∈ [k′′][k] such that wi = vui for all i ∈ [k]. Then,
j∈[ui,ui+1−1] q′
= p′′
⊆ p′′
for all i ∈ [k], pi ⊆ p′
j =
wi ; qi ⊆
vui
ui
l . The union of the q′′
l∈[v j,v j+1−1] q′′
in the intervals
S
l
[v j, v j+1 − 1] for j ∈ [ui, ui+1 − 1] can be sum up as an union on
S
the interval [vui , v(ui+1−1)+1 − 1] = [vui , vui+1 − 1] = [wi, wi+1 − 1] be-
cause intervals are contiguous. Then, qi ⊆
j . Finally, if
k = k′′, then k = k′′ = k′ and then it exists j ∈ [k], s.t. p j , p′
j ⊆ p′′
S
j
or q j , q′
j or q j , q′′
j . As a consequence, we
have p ⊳· p′′.
Antisymmetry. Let p, p′ ∈ N s.t. p ⊳· p′. Then, if k < k′ we can not
have p′ ⊳· p. Assuming that k = k′ (and thus ui = i for all i ∈ [k]),
we have that there exists j ∈ [k] s.t. p j , p′
j or q j , q′
j. If p j , p′
j
then, according to 1. p j   p′
j ⊆ p j fails. If q j , q′
j, then,
according to 2. q j  
j. Thus, it is not possible to
have q′
j ⊆ q j =
j∈[ui,ui+1 −1] q j. As a consequence, we can not have
p′ ⊳· p.

j, hence p′
j = q′

j . Thus, p j , p′′

j∈[wi,wi+1 −1] q′′

j∈[ui,ui+1−1] q′

j ⊆ q′′

S

We now turn to ⊳.
Transitivity. Let p, p′, p′′ ∈ N s.t. p ⊳ p′ and p′ ⊳ p′′. Then, for
all i ∈ [k], pi ⊆ p′
i ⊆ q′′
i
(k ≤ k′ ≤ k′′). Finally, if k = k′′, then k = k′′ = k′. Assuming that
k and p′
k then pk = p′′
pk = p′
k or
p′
k , then ∃ j ∈ [k − 1] s.t. q j , q′
, p′′
j , and hence q j , q′′
j .
k
Then, we have that p ⊳ p′′. We ﬁnish with ⊳+ .

k′′ . Assuming that pk , p′
j or q′

i and for all i ∈ [k − 1], qi ⊆ q′

k = p′′

i ⊆ p′′

j , q′′

i = p′′

i and for all i ∈ [k − 1], qi ⊆ q′

Transitivity. Let p, p′, p′′ ∈ N s.t. p ⊳+ p′ and p′ ⊳+ p′′. Then, for
i ⊆ q′′
i (k = k′ =
i for all i ∈ [k−1]. In fact,
i = q′′
i for all i ∈ [k − 1]
i . But having all these further equalities is not

all i ∈ [k], pi = p′
k′′). Finally, it is not possible to have qi = q′′
these equalities would entail qi = q′
i and q′
because qi ⊆ q′
i ⊆ q′′
possible according to 3. Therefore, we have that p ⊳+ p′′.

S

Proof of Proposition 3. We start this proof by a small result about
the anti-monotonicity of *D. Let P, Q ∈ I be two itemsets s.t. P ⊆ Q,
and I ∈ I another itemset. Then, Q *D I =⇒ P *D I. In fact,
Q *D I implies that for all e ∈ Q, e < I, and because P ⊆ Q, we also
have that e ∈ P, e < I.

hp′

m′−1 p′

1 . . . ¬q′

∈ N and p′ =

i ⊆ sei , ∀i ∈ [m′] and q′

. . . ¬qm−1 pmi
m′ i ∈ N be two NSPs s.t. p ⊳ p′.

Let p = hp1 ¬q1
1 ¬q′
We ﬁrst show that an ( , D)-embedding of p′ in a sequence s, de-
noted e = (ei)i∈[m′], induces an ( , D)-embedding of p. By Deﬁnition
4, we have p′
i *D s j, for all j ∈ [ei +1, ei+1 −1]
and for all i ∈ [m′ − 1].
On the other hand, p ⊳ p′ implies that pi ⊆ p′
i for all i ∈ [m]. Then,
because m ≤ m′ (p ⊳ p′), we have that pi ⊆ sei for all i ∈ [m]. In
addition, p ⊳ p′ also implies that qi ⊆ q′
i for all i ∈ [m − 1] and thus,
by anti-monotonicity of *D (and q′
i *D s j), we have qi *D s j for all
j ∈ [ei + 1, ei+1 − 1] and for all i ∈ [m − 1]. In conclusion, we have
that e = (ei)i∈[m] is an ( , D)-embedding of p.

i ⊆ sei , ∀i ∈ [m′] and q′

We now show that an ( , D)-embedding of p′ in a sequence s, de-
noted e = (ei)i∈[m′], induces an ( , D)-embedding of p. By Deﬁnition
4, we have p′
j∈[ei+1,ei+1−1] s j, for all
i ∈ [m′ − 1].
However, p ⊳ p′ implies that pi ⊆ p′
i for all i ∈ [m]. Then, because
m ≤ m′ (p ⊳ p′), we have that pi ⊆ sei for all i ∈ [m]. In addition,
p⊳ p′ also implies that qi ⊆ q′
i for all i ∈ [m−1], by anti-monotonicity
j∈[ei+1,ei+1−1] s j, for all i ∈ [m′ − 1]. In con-
of *D, we have q′
clusion, we have that e = (ei)i∈[m] is an ( , D)-embedding of p.

i *D

i *D

S

S

Proof of Proposition 4. Let p = hp1 ¬q1 . . . ¬qk−1 pki ∈ N and
k′ i ∈ N be two NSP s.t. p ⊳+ p′. Thus, we
p′ = hp′
have that k = k′.

1 . . . ¬q′

k′−1 p′

1 ¬q′

Similarly to the proof of Proposition 3, we can show that any
( , D)-embedding of p′ in s induces an ( , D)-embedding of p in s.
This enables to conclude that (cid:22)D is anti-monotonic on (N, ⊳+ ).

The anti-monotonicity of ⊑D requires that each embedding of p+
in s satisﬁes the negations. Let us assume that p′ ⊑D s, then there
exists an embedding (ei)i∈[k] of p′. (ei)i∈[k] is also an embedding of
p′+ (Lemma 5). According to 1. in Deﬁnition 8 and because k = k′,
p′+ = p+, and then (ei)i∈[k] is an embedding of p+ in s. Thus, we have
shown that there is at least one embedding of p+ in s. If ⊑D is not
anti-monotonic, then there exists an embedding (ei)i∈[k] of p+ such
that for some j ∈ [k] and l ∈ [e j + 1, e j+1 − 1], it is false that q j *D sl
(∃α ∈ q j, α < sl). According to 2. in Deﬁnition 8, q j ⊆ q′
j, and thus
j *D sl. However, (ei)i∈[k] is also an embedding of p′+.
it is false q′
Since p′ ⊑D s, it follows that q′
j *D sl. There is a contradiction, thus
⊑D is anti-monotonic.

The anti-monotonicity of ⊑D requires that each embedding of p+
in s satisﬁes the negations. Let us assume that p′ ⊑D s, then there
exists an embedding (ei)i∈[k] of p′. (ei)i∈[k] is also an embedding of
p′+ (Lemma 5). According to 1. in Deﬁnition 8, and because k = k′,
p′+ = p+, and then (ei)i∈[k] is an embedding of p+ in s. Thus, we have
shown that there is at least one embedding of p+ in s. If ⊑D is not anti-
monotonic, then there exists an embedding (ei)i∈[k] of p+ such that for
some j ∈ [k], it is false that q j *D
l∈[e j+1,e j+1−1] sl. According to 2.
in Deﬁnition 8, q j ⊆ q′
j, and thus it is false q′
l∈[e j+1,e j+1−1] sl.
Nonetheless, (ei)i∈[k] is also an embedding of p′+. And p′ ⊑D s, it
implies that q′
l∈[e j+1,e j+1−1] sl. There is a contradiction, thus ⊑D
j *D
is anti-monotonic.

j *D

S

S

S

Proof of Proposition 5. Let θ, θ′ ∈ Θ, then θ 1 θ′ =⇒ suppθ(p) ≤
suppθ′ (p) for all p ∈ N (by Deﬁnition 6 of the dominance relation).
Thus, Proposition 5 comes immediately with Proposition 1.

9

Proof of Proposition 6. Let p, p′ ∈ N be two negative sequential
patterns such that p ⊳ p′. According to Proposition 3, p′ (cid:22)D s =⇒
p (cid:22)D s for all s. Thus, suppD,

,(cid:22)(p′) ≤ suppD,

,(cid:22)(p).

If p ⊳+ p′. According to Proposition 4, p′ JD s =⇒ p JD s for

all s. Thus, suppD,

,J(p′) ≤ suppD,

,J(p).

9 Additional dominance results

Table 3 below illustrates the dominance and non-dominance relations
that are given in Proposition 1. In this section, we use transitivity of
the dominance relation to complete the table.

9.1 Transitive dominance relation

Let θ 1 θ′ and θ′ 1 θ′′ then, by transitivity, we have θ′ 1 θ′′

• θ = (D,

, ⊑), θ′ = (G,

, ⊑) and θ′′ = (G,

, ⊑). θ 1 θ′ is obtained

by (5) and θ′ 1 θ′′ is obtained by (7).

• ...

In Table 3, we deduce that the x cell is 1 when we have the fol-
lowing scheme (or symmetrical schemes): a square with a diagonal
of 1 and a diagonal with x and a cell in the diagonal of the matrix.

1 . . .
...
·

x
...
. . . 1

Table 4 illustrates the dominance that can be deduced from the
Proposition 1. Table 5 contains additional dominance relations de-
duced by second order transitivity.

9.2 Transitive non-dominance relation

Lemma 11. Let θ, θ′ and θ′′ s.t. θ 1 θ′ and θ 61 θ′′ then θ′ 61 θ′′

Proof. By absurd, suppose θ′ 1 θ′′ thus, by transitivity, θ 1 θ′′ that
is not possible.

In Table 3, we deduce that the x cell is 61 when we have the fol-
lowing scheme (or symmetrical schemes): a square with a diagonal
of 1 and x; and a diagonal with 61 and a cell in the diagonal of the
matrix.

1 . . .
...
·

. . .

61
...
x

Table 6 illustrates the non dominance relations that can be deduced

from previously deduced dominance and non-dominance.

10

Table 3. Dominance relations from Proposition 1. 1 (resp. 61) in the Table means that the semantic at the left of the row dominates (resp. does not dominate)
the semantic at the top of the column. The indices are corresponding equation numbers in Proposition 1.

(G,

, ⊑)

(G,

, (cid:22))

(G,

, ⊑)

(G,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

·
61(8)
61(9)

1
(6)
61(13)

1(3)
·
61(12)
61(9)

1

(6)

(G,
(G,
(G,
(G,
(D,
(D,
(D,
(D,

, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))

1(4)
61(10)
·
61(8)

1(6)
61(14)

1(4)
1(3)
·

1

(6)

61(7)
61(13)

·
61(8)
1(5)

61(15)
61(7)

1(3)
·

1

(5)

61(7)

1(4)

·
61(8)

61(7)

1(4)
1(3)
·

Table 4. Dominance relations added by transitivity (with indices). The indices denote the coordinates (row-columns) which is the diagonally opposite relation
in the ”transitive-square” (see description in the text). 1 (resp. −) in the Table means that the semantics at the left of the row dominates (resp. does not dominate)
the semantics at the top of the column.

(G,

, ⊑)

(G,

, (cid:22))

(G,

, ⊑)

(G,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(G,
(G,
(G,
(G,
(D,
(D,
(D,
(D,

, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))

·
−
−

1
−
15−5

1
·
−
−
11−1
1

16−6

1
−
·
−
11−1

1
−

13−3
1
1
·

12−2
13−3
1

−
−

·
−
1

−
−

1
·
18−8
1

−

1

·
−

−
17−7
1
1
·

Table 5. Dominance relations added by second-order transitivity (with indices). The indices denote the coordinates (row-columns) which is the diagonally
opposite relation in the ”transitive-square” (see description in the text). 1 (resp. −) in the Table means that the semantics at the left of the row dominates (resp.
does not dominate) the semantics at the top of the column.

(G,

, ⊑)

(G,

, (cid:22))

(G,

, ⊑)

(G,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(G,
(G,
(G,
(G,
(D,
(D,
(D,
(D,

, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))

·
−
−

1
−
1

1
·
−
−
1
1
15−5
1

1
−
·
−
1

1
−

1
1
1
·
16−6
1
1
1

−
−

·
−
1

−
−

1
·
1
1

−

1

·
−

−
1
1
1
·

Table 6. Non-dominance relations added by transitivity. The indices denote the coordinates (row-columns) which is the diagonally opposite relation in the
”transitive-square” (see description in the text). 1 (resp. −) in the Table means that the semantics at the left of the row dominates (resp. does not dominate) the
semantics at the top of the column.

(G,

, ⊑)

(G,

, (cid:22))

(G,

, ⊑)

(G,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(D,

, ⊑)

(D,

, (cid:22))

(G,
(G,
(G,
(G,
(D,
(D,
(D,
(D,

, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))
, ⊑)
, (cid:22))

·
−
−
−1−2
1
−
1
−6−8

1
·
−
−
1
1
1
1

1
−
·
−
1
−8−6
1
−

−
−
−1−3
−1−4
·
−
1
−6−8

−
−
−6−2
−6−8
1
·
1
1

−7−5
−7−6
−
−8−4
1
−8−6
·
−

−8−6
−8−6
−8−2
−
1
1
1
·

1
1
1
·
1
1
1
1

11

