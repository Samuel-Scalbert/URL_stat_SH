Evaluating Top-k Queries with Inconsistency Degrees
Ousmane Issa, Angela Bonifati, Farouk Toumani

To cite this version:

Ousmane Issa, Angela Bonifati, Farouk Toumani.
Evaluating Top-k Queries with Inconsis-
tency Degrees. Proceedings of the VLDB Endowment (PVLDB), 2020, 13 (12), pp.2146-2158.
￿10.14778/3407790.3407815￿. ￿hal-02898931￿

HAL Id: hal-02898931

https://hal.science/hal-02898931

Submitted on 14 Jul 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Evaluating Top-k Queries with Inconsistency Degrees

Ousmane Issa
University Clermont Auvergne
ousmane.issa@uca.fr

Angela Bonifati
Lyon 1 University
angela.bonifati@univ-
lyon1.fr

Farouk Toumani
University Clermont Auvergne
farouk.toumani@uca.fr

ABSTRACT
We study the problem of augmenting relational tuples with
inconsistency awareness and tackling top-k queries under a
set of denial constraints (DCs). We deﬁne a notion of in-
consistent tuples with respect to a set of DCs and deﬁne
two measures of inconsistency degrees, which consider sin-
gle and multiple violations of constraints. In order to com-
pute these measures, we leverage two models of provenance,
namely why-provenance and provenance polynomials. We
investigate top-k queries that allow to rank the answer tu-
ples by their inconsistency degrees. Since one of our mea-
sure is monotonic and the other non-monotonic, we design
an integrated top-k algorithm to compute the top-k results
of a query w.r.t. both inconsistency measures. By means of
an extensive experimental study, we gauge the eﬀectiveness
of inconsistency-aware query answering and the eﬃciency of
our algorithm with respect to a baseline, where query results
are fully computed and ranked afterwards.

PVLDB Reference Format:Ousmane Issa, Angela Bonifati,
Evaluating Top-k Queries with Inconsis-
Farouk Toumani.
tency Degrees..
xxxx-yyyy, 2020. DOI:
https://doi.org/10.14778/3407790.3407815

PVLDB, 13(11):

1.

INTRODUCTION

Assessing the quality of raw data is crucial in numerous
data management tasks, spanning from traditional querying
and data integration to cutting-edge in-database analytical
and inference/ML processes. Throughout these processes,
the quality of the output as well as the trustworthiness of
the results might be tremendously aﬀected by the quality of
the input tuples [29].

Past work on data curation for relational tuples has
mainly addressed the problem of detecting and repairing
the violations with respect to a set of constraints [39]. Con-
sistent query answering has also been considered as a mean
to reconcile several possible repairs of the original data [11].
However, little or no attention has been paid to leave the
database instances intact and quantifying their degrees of
inconsistency at diﬀerent levels of granularity (tuple, sets of

licensed under

This work is
the Creative Commons Attribution-
NonCommercial-NoDerivatives 4.0 International License. To view a copy
of this license, visit http://creativecommons.org/licenses/by-nc-nd/4.0/. For
any use beyond those covered by this license, obtain permission by emailing
info@vldb.org. Copyright is held by the owner/author(s). Publication rights
licensed to the VLDB Endowment.
Proceedings of the VLDB Endowment, Vol. 13, No. 11
ISSN 2150-8097.
DOI: https://doi.org/10.14778/3407790.3407815

1

tuples, entire relations) as we do in this paper for the ﬁrst
time. Such a characterization enables the users of a DBMS
to quantify the level of trust that they shall expect from the
data that they query and manipulate.

In our work, we are interested in augmenting relational in-
stances with novel inconsistency measures that can also be
propagated to query results. To this end, we focus on top-k
rank join queries over an inconsistent relational database in
the presence of a set of Denial Constraints (DCs) [17]. The
inconsistency degree of an answer tuple of a given query is
determined by relying on provenance-based information of
the input tuples. We ﬁrst leverage why-provenance in or-
der to identify the inconsistent base tuples of a relational
instance with respect to a set of DCs. Then, we rely on
provenance polynomials [26] in order to propagate the anno-
tations of inconsistencies from the base tuples to the answer
tuples of Conjunctive Queries (CQs). Building upon the
computed annotations, we deﬁne two measures of inconsis-
tency degrees, which consider single and multiple violations
of constraints. Since one of our measures is a monotone
function and the other a non-monotone function, we design
an integrated top-k algorithm to rank the top-k results of a
query w.r.t. the above inconsistency measures.
We envision several applications of our

framework:
Inconsistency-conscious queries for analytical tasks, as we
expect that our framework enables inconsistency quantiﬁ-
cation in querying and analytical tasks within data science
pipelines. Our annotations are not merely numbers as they
also convey provenance-based information about the vio-
lated constraints, the latter being ready for user consump-
tion in data science tasks.

External annotations for data cleaning pipelines, as our
approach can also ease the tasks of data cleaning tools
such as OpenReﬁne, Wrangler and Tableau by injecting into
them the external information of inconsistency indicators
and putting upfront the resulting ranking prior to cleaning
and curation.

Approximation schemes for integrity constraints that have
been employed recently in order to guarantee a polynomial
number of samples required by recent probabilistic inference
approaches for data cleaning [38]. We believe that an alter-
native to constraint approximation would be to build sam-
ples based on the top-k number of constraints leading to the
most consistent (the least consistent, respectively) tuples.

Combined ranking since our quality-informed ranking and
query evaluation can be combined with other ranking crite-
ria, such as for instance user preferences in recommender
systems and novel unfairness and discrimination detection

in marketplaces and search sites [3].

In this paper, we make the following main contributions:
(1) We design novel measures of inconsistency degrees of
answer tuples for CQs over an inconsistent database in the
presence of a set of DCs.
(2) We leverage why-provenance in order to identify the in-
consistent tuples of a given database w.r.t. a set of DCs.
Then, we exploit provenance polynomials to propagate the
inconsistency degree of base tuples to the answer tuples of
CQs, which is to the best of our knowledge a novel and quite
promising usage of provenance. Both provenance techniques
considered here are PTIME-computable in data complexity
thus guaranteeing that our augmentation of relational in-
stances with inconsistency measures remains tractable.
(3) We study the problem of top-k rank queries with re-
spect to a given measure of inconsistency degree. We con-
sider monotonic and non-monotonic measures and we design
an integrated top-k ranking algorithm that is applicable to
both. We show that the algorithm is space eﬃcient (i.e.,
in O(|I| + k) instead of O(Q(I)), where I is a database
instance). As a side contribution, we prove that our algo-
rithm is optimal w.r.t. a new notion of optimality tailored to
generic scoring functions (monotonic and non-monotonic).
(4) We deploy our framework with real-world and synthetic
datasets equipped with DCs. We gauge the low overhead
due to the generation of inconsistency degrees as well as the
bearable runtimes of our top-k ranking algorithm with vari-
ous query sets. Our experimental study shows the feasibility
of inconsistency-aware query answering with top-k ranking,
with the latter outperforming by up to 28 times the baseline
solution.

The paper is organized as follows: Section 2 introduces
a motivating example; Section 3 and Section 4 present the
state of the art and the background notions, respectively;
Section 5 introduces the inconsistency measures; Section 6
describes our novel top-k algorithm along with its properties.
Section 7 illustrates our experimental study while Section 8
concludes the paper and pinpoints future directions.

2. MOTIVATING EXAMPLE

Consider a relational instance I as depicted in Figure 1
consisting of three relations D, V and S contaning informa-
tion about the diagnoses, vaccinations and surgical interven-
tions of patients. Hence, in each of the relations D, V and
S, the ﬁrst column represents the patient identiﬁer PID, the
second column is the disease identiﬁer RefID and the third
column is the Date of a given event 1.

The denial constraint C1 imposes to have any diagnosis
for a patient’s disease before surgery for the same disease
concerning that patient. The constraint C2 establishes that
a patient cannot be diagnosed a given disease for which
he/she has been administered a vaccine on a previous date.
The constraint C3 requires that a patient cannot undergo
surgery and vaccination on the same date. Figure 1 also
shows a conjunctive query Qex extracting pairs of diseases
for which the same patient underwent surgery and was ad-
ministered a vaccine.

Observe that the instance I does not satisfy the set of
Indeed, the constraint C1

denial constraint {C1, C2, C3}.

1For ease of exposition and to avoid clutter, the relations
have the same schema. Our approach is applicable to re-
lations with arbitrary schemas as also shown in our experi-
mental study.

2

is violated both by the pairs of tuples (t2, t3) and (t2, t4)
while the constraint C2 is violated by the tuples (t2, t7) and
the constraint C3 is violated by the tuples (t4, t7). Hence,
the inconsistent base tuples of I w.r.t.
the set of denial
constraint {C1, C2, C3} are: t2, t3, t4, t7.
Quantifying the inconsistency degrees of query an-
swers. Evaluating the query Qex over the inconsistent
database I, under the bag answer semantics, returns the
answers reported in the ﬁrst column of Table 1. The second
column of Table 1 shows the base tuples of I that contribute
to each answer. One can observe that the tuple (cid:104)d4, d4(cid:105) is a
consistent answer since it is computed using consistent base
tuples. This is, however, not the case for (cid:104)d2, d2(cid:105), which can
be derived in three possible ways, either using the base tu-
ples {t2, t3, t7} or {t2, t4, t7} or {t2, t6, t7}. Notice that
all the above derivations use inconsistent base tuples.

In this paper, we consider two alternatives for quantify-
ing the inconsistency degree of query answers. The ﬁrst
approach quantiﬁes the inconsistency degree of an answer t
by counting the number of constraints violated by the base
tuples that contribute to t. The third column of Table 1
shows the constraints violated by the base tuples that con-
tribute to each answer. For example, in line 1 of Table 1,
the computation of the answer (cid:104)d2, d2(cid:105) from the base tu-
ples {t2, t3, t7} leads to the violation of the constraints C1
(violated by t2 and t3), C2 (violated by t2 and t7) and C3
(violated by t7). As a consequence, the inconsistency degree
of the answer (cid:104)d2, d2(cid:105) when it is computed from the base tu-
ples {t2, t3, t7} is equal to 3 (i.e., 3 constraints are violated
by the base tuples that contribute to this answer).

A second approach to quantify the inconsistency degree
of an answer amounts to counting the number of violations
of the constraints per each base tuple. The fourth column
of Table 1 shows the constraints violated by the base tu-
ples while reporting how many times the same violation oc-
curred (indicated by the exponent of the constraints). For
instance, in the ﬁrst row of Table 1, the computation of the
answer (cid:104)d2, d2(cid:105) from the base tuples {t2, t3, t7} leads to the
violation of the constraint C1 twice (violated by t2 and by
t3), the violation of C2 two times (violated by t2 and t7)
and the violation of C3 one time (violated by t7). Hence,
the corresponding inconsistency degree of (cid:104)d2, d2(cid:105) is equal
to 5 (i.e., 5 violations of the constraints by base tuples).

In this paper, we focus on a constraint-based approach to
quantify inconsistency degrees of query answers under bag
semantics. As Table 1 (fourth column) shows, the annota-
tions of the base tuples are the richest and the most informa-
tive ones since they consider the violations in terms of the
constraints and their occurrences. In particular, we consider
two alternative measures: (i) counting the number of con-
straints violated by the base tuples contributing to a given
answer (called in the sequel, single occurrence quantiﬁca-
tion), and (ii) summing up the exponents of the constraints
violated by base tuples contributing to a an answer (called
in the sequel, multiple occurrence quantiﬁcation).
Inconsistency-aware query processing. With the in-
consistency measures at hand, we are interested in top-k
query processing while taking into account the inconsistency
degrees of query answers. This problem can be framed in
the general context of top-k rank queries where the inconsis-
tency measures are used as scoring functions that can be ex-
ploited to rank the answers of queries. In particular, given a
query Q, top-k ranking aims at computing the subset of Q’s

Diagnosis(D)
Date
2
4

RefD
d4
d2

PID
02
01

t1
t2

Surgery(S)
Date
RefD
1
d2
3
d2
4
d4
5
d2

PID
01
01
02
01

t3
t4
t5
t6

Vaccination(V)
Date
3
3

RefD
d2
d4

PID
01
02

t7
t8

Set of denial constraints(DCs)

Constraint Id
C1
C2
C3

Denial Constraint
← D(x, y, z) ∧ S(x, y, u) ∧ z > u
← D(x, y, z) ∧ V (x, y, u) ∧ z > u
← S(x, y, z) ∧ V (x, v, z)

Query(Qex)
Qex(y, u) ← D(x, y, z) ∧ S(x, y, z1) ∧ V (x, u, v)

Figure 1: A hospital database hdb with a set of denial constraints (DCs) and a query Qex.

Answers

Contrib. tuples

(cid:104)d2, d2(cid:105)
(cid:104)d2, d2(cid:105)
(cid:104)d2, d2(cid:105)
(cid:104)d4, d4(cid:105)

{t2, t3, t7}
{t2, t4, t7}
{t2, t6, t7}
{t1, t5, t8}

Violated
Constr.
C1 × C2 × C3
C1 × C2 × C3
C1 × C2 × C3
1

# Constr.
Violations
C2
1 × C2
C2
1 × C2
1 × C2
C2
1

2 × C3
2 × C2
3
2 × C3

Table 1: Annotated answers of query Qex

answers with the top k scores, where the scores correspond
to the inconsistency degrees of the tuples. Continuing with
our example, the top-2 answers of the query Qex over the
database I are: (cid:104)d4, d4(cid:105), (cid:104)d2, d2(cid:105), with respective inconsis-
tency degrees 0 and 3 with single occurrence quantiﬁcation),
or, respectively, inconsistency degrees 0 and 5 with multi oc-
currence quantiﬁcation, respectively. In the remainder, we
will see that both augmenting the instances with inconsis-
tency measures and enabling top-k queries on them are far
from being trivial and need special treatment.

3. RELATED WORK
Consistent Query Answering and Repairs. Central to
data quality is data consistency that has been extensively
investigated in the past. Starting from the pioneering work
of [5], there has been a wealth of research on the problem of
consistent query answering in inconsistent databases [7, 39,
36, 23, 8]. Most of the existing works make a distinction be-
tween consistent and inconsistent answers based on the no-
tion of a database repair (see [11, 10] for a survey). A repair
is a database instance obtained by applying some minimal
changes on the initial database instance in order to make
it compliant with a given set of integrity constraints. Usu-
ally, there exist several possible repairs of a given database
and for such a reason, following the certain answers seman-
tics, consistent answers to a given query are deﬁned as being
the intersection of the query answers on all possible repairs
of the initial database instance. The problem of consistent
query answering has been investigated in several settings
depending on: (i) the deﬁnition of repairs, where a repair is
deﬁned in terms of the sets of inserted and/or deleted tuples
[11, 10, 34, 13], or updates [39, 32, 6] and (ii) the considered
integrity constraints and the query language. The latter has
been studied for a variety of queries and constraints such as
ﬁrst-order queries and binary universal constraints or sin-
gle functional dependencies [5], union of conjunctive queries
and key and inclusion dependencies [14], ﬁrst-order queries
and denial constraints [16], to mention a few.

Recent approaches study a counting variant of consistent
query answering [36], i.e., counting how many repairs satisfy
a given query q. The work in [36] establishes a dichotomy
for the #- CERTAINTY(q) problem, where q is a boolean
conjunctive query possibly with self-joins and with single-
attribute primary-key (PK) constraints. Our work is agnos-
tic to the repairing semantics and computation of repairs
and only leverages constraint violations.

3

Quantifying Inconsistency in KBs.
Reasoning in
Knowledge Bases (KBs) in the presence of inconsistency is
also widely studied in the AI community, where it has been
shown that an arbitrary consequent can be entailed from an
inconsistent set of premises (see the survey by Lang et al.
[33]). Similarly, the role of inconsistency tolerance in KBs
has been introduced in [9]. They are more concerned about
the co-existence of consistency and inconsistency as sepa-
rate axioms when doing reasoning in KBs rather than using
inconsistency measures to yield inconsistency-aware query
answering, as we do in our work.

Another line of research deals with the deﬁnition of in-
consistency measures in Knowledge Bases (KBs) [20, 24].
Numerous measures of inconsistency in KBs have been pro-
posed based on various paradigms such as information the-
ory [35], possibility theory [19] or quasi-classical logic [24],
to mention a few. The ultimate goal is, however, to provide
measures to quantify the inconsistency of a KBs in order, for
example, to allow comparison of full KBs based on their in-
consistency degrees. Extensions of such an approach to the
database ﬁeld has been recently investigated in [10] where
inconsistency measures based on various classes of repair se-
mantics are studied. However, their notion of inconsistency
measures (despite the name) relies on restoring the consis-
tency of a database, thus on the class of repairs admitted by
the database. As such, it is quite diﬀerent from our notion
of inconsistency.
Top-k Query Processing. Top-k query processing algo-
rithms address the eﬃcient computation of the ﬁrst top-k
answers of selection [22], join [27, 30, 31] and aggregate
queries [15]. There exists a vast literature on top-k join
query processing, see [28] for a survey. However, a basic as-
sumption of several previous papers on this topic is that the
scoring function f used to aggregate the scores of the under-
lying tuples is a monotonic function [15, 28, 30, 31]. Non-
monotonic scoring functions have been considered in [40]
for top-k query processing, while assuming that attribute
values are indexed by tree-structured indexes (e.g., B-tree,
R-tree). However, none of the existing top-k ranking al-
gorithms would be optimal to handle both monotonic and
non-monotonic functions. Additionally, our novel top-k al-
gorithm is tailored for inconsistency measures and leverages
a suitable cost model for them. Our algorithm is thus generic
and designed in a way that it incorporates both monotonic
and non-monotonic inconsistency measures.

Analytical studies of the performance of existing top-k
join algorithms have been conducted mostly for the class
of algorithms, introduced initially in [22], that use a sorted
data access strategy, i.e., the input relations are scanned se-
quentially in base score order [30, 31]. Such a framework,
which imposes a sequential data access strategy, is not suit-
able for non-monotonic functions. This motivated our work
on a new notion of optimality based on: (i) a more general
class of algorithms, called Semi-Blind Algorithms (SBA),

M (P )
V ar(M )
W (M )
DC
Υ
Γ
V C(I, DC, t)
IΥ
IΥ(Ri)
Qk,α
ind(R)
label(B)

Set of monomials of a polynomial P
Set of variables of a monomial M
weight of a monomial M
Set of denial constraints
Set of constraints identifiers
Set of tuple identifiers
Set of constraints violated by a tuple t
a Υ-instance obtained from I
A K-relation of IΥ
top-k query w.r.t. measure α
Index associated with R
Label of a bucket B of an index

Table 2: Summary of the notation used in the paper.

that alleviate the assumptions on the permitted data access
strategies, and (ii) a new cost model that enable to deal
with nondeterministic choices due to the assumption that
SBA algorithms do not exploit any speciﬁc knowledge on
join attributes. Using this framework, we show the optimal-
ity of our algorithm w.r.t. the SBA class.

4. PRELIMINARIES

We introduce some basic notions used throughout the
paper. Table 2 summarizes the notation. We consider
S = {R1, . . . , Rn} as a database schema with Ri(i ∈ [1, n])
a predicate and with arity(Ri) denoting the arity of Ri. We
consider D, I as the domain and a database instance over
S and D, respectively. Let Γ be an inﬁnite set of identiﬁers
distinct from the domain D. We denote by id a function
that associates to each tuple t ∈ I(Ri) an unique idenﬁer
id(t) from the set Γ.
Conjunctive Queries (CQ). A CQ is in form Q(u) ←
R1(u1), ..., Rn(un),where each Ri is a relation symbol in S
and Q is a relation symbol in the output schema, u is a tuple
of either distinguished variables or constants and each ui is
a tuple of either variables or constants having the same arity
as Ri. The set of variable in a query Q is denoted V ars(Q).
Denial Constraints. A denial constraint is of the form:
← R1(u1) ∧ ... ∧ Rn(un) ∧ φ where the Ri(ui) are deﬁned
as previously and φ is a conjunction of comparison atoms of
the form x op y, where x, y are either constants or variables
and op ∈ {=, (cid:54)=, ≤, <, >, ≥} is a built-in operator. Let C
be a denial constraint, Cid is an unique identiﬁer of C. We
denote Υ the set of the identiﬁers of the denial constraints.
Monomials and Polynomials. A (non null) monomial M
over N and a ﬁnite set of variables X is deﬁned by M = a ×
xm1
n with a, m1, ..., mn ∈ N∗ (i.e., non zero positive
1 ×...×xmn
integers) and x1, ..., xn ∈ X . Let M = a × xm1
1 × ... × xmn
be a monomial. We denote by V ar(M ) = {x1, . . . , xn} the
set of variables that appear in the monomial M . The weight
of a variable xi ∈ V ar(M ) w.r.t a monomial M , denoted by
W (M, xi), is equal to mi, the exponent of the variable xi
in M . The weight of a non null monomial M , denoted by
W (M ), is deﬁned as the sum of the weights of its variables,
i.e.: W (M ) = (cid:80)
W (M, x). A polynomial P over N

n

x∈V ar(M )

and a ﬁnite set of variables X is a ﬁnite sum of monomials
over X . We denote M (P ) the set of monomials of P .
Provenance Semirings. We recall the provenance semir-
ings framework, introduced in [26] as a unifying framework
able to capture a wide range of provenance models at diﬀer-
ent levels of granularity [26, 25, 21].
K-relations. A commutative semiring is an algebraic struc-
ture (K, ⊕, ⊗, 0, 1), where 0 and 1 are two constants in K
and K is a set equipped with two binary operations ⊕ (sum)

and ⊗ (product) such that (K, ⊕, 0) and (K, ⊗, 1) are com-
mutative monoids2 with identities 0 and 1 respectively, ⊗ is
distributive over ⊕ and 0 ⊗ a = a ⊗ 0 = 0 holds ∀a ∈ K.
An n-ary K-relation is a function R : Dn → K such that
its support, deﬁned by supp(R) def= {t : t ∈ Dn, R(t) (cid:54)= 0},
is ﬁnite. Let R be an n-ary K-relation and let t ∈ Dn, the
value R(t) ∈ K assigned to the tuple t by the K-relation R
is called the annotation of t in R. Note that R(t) = 0 means
that t is ”out of” R [26]. A K-instance is a mapping from
relations symbols in a database schema S to K-relations
(i.e, a ﬁnite set of K-relations over S). If J is a K-instance
over a database schema S and Ri ∈ S is a relation symbol
in S, we denote by J (Ri) the K-relation corresponding to
the value of Ri in J .
Conjunctive queries on K-instances. Let Q(u) ←
R1(u1), ..., Rn(un), be a conjunctive query and let J be a K-
instance over the same schema than Q, with (K, ⊕, ⊗, 0, 1)
a semiring. A valuation of Q over a domain D is a
function v : V ars(Q) → D, extended to be the iden-
tity on constants. The result of executing a query Q
over a K-instance J , using the semiring (K, ⊕, ⊗, 0, 1),
is the K-relation Q(J ) deﬁned as follows: Q(J ) def=
{ (v(u), Πn

i=1Ri(v(ui))) | v is a valuation over V ars(Q)}.

The K-relation Q(J ) associates to each tuple t = v(u),
which is in the answer of the query Q over the K-instance
J , an annotation Πn
i=1Ri(v(ui))) obtained from the prod-
uct, using the ⊗ operator, of the annotations Ri(v(ui)) of
the base tuples contributing to t. Since there could exist
diﬀerent ways to compute the same answer t, the com-
plete annotation of t is obtained by summing the alter-
native ways (i.e., the various valuations) to derive a tu-
ple t using the ⊕ operator. Consequently, the provenance
of an answer t of Q over a K-instance J is given by:
Q(J )(t) = (cid:80)

i=1Ri(v(ui))).

Πn

v s.t v(u)=t

Example 1. Consider the K-instance hdbΥ in Figure 2
with K = N[Υ], the set of polynomials with variables from Υ
and coeﬃcients in N. The annotation of the tuple (cid:104)01, d2, 1(cid:105)
of relation S is given by: hdbΥ(S)((cid:104)01, d2, 1(cid:105)) = C1. Evalu-
ation of Qex over hdbΥ uses (N[Υ], +, ×, 0, 1) semiring and,
for example, leads to an answer (cid:104)d2, d2(cid:105) annotated as fol-
lows: Qex(hdbΥ)((cid:104)d2, d2(cid:105)) = C 2
2 C3.

2 C3 + C 2

3 + C 2

2 C 2

1 C 2

1 C 2

1 C 2

5. QUANTIFYING INCONSISTENCY
DEGREES OF QUERY ANSWERS

In this section, we focus on the problem of quantifying
the inconsistency degree of query answers. Let I be an in-
stance over a database schema S, let DC be a set of denial
constraints over S and let Υ be the set of identiﬁers of the
constraints in DC. We proceed in three steps:
(i) Identifying inconsistent base tuples. We ﬁrst start by
identifying the inconsistent tuples of an instance I over S
w.r.t a set of denials constraints DC. To achieve this task,
we turn each constraint C ∈ DC into a conjunctive query
QCid and, by exploiting why-provenance, we consider the
lineage of QCid as the set of tuples of I that violates the
constraint C. As a consequence, we are able to deﬁne a
function V C(I, DC, t) that associates to each tuple t ∈ I,
the set of constraints violated by t;

2i.e., ⊕ (resp. ⊗) is associative and commutative and 0
(resp. 1) is its neutral element.

4

(ii) Annotating the initial database instance. Using the set
V C(I, DC, t), we convert the instance I into a Υ-instance,
denoted I Υ, obtained by annotating each tuple in I by a
monomial with variables from Υ. The variables record the
constraints violated by the annotated tuple.
(iii) Deﬁning inconsistency degrees of query answers. Given
a query Q over the instance I, we use the provenance semir-
ings to annotate the query answers. The latter provenance
is the most informative form of provenance annotation [25]
and hence is exploited in our setting in order to deﬁne two
inconsistency degrees for query answers.

We shall detail in the sequel the proposed approach.

5.1

Identifying inconsistency degrees of base
tuples

Let I and DC be respectively an instance and a set of
DCs over S. We ﬁrst convert each constraint C of DC of the
form: ← R1(u1)∧...∧Rn(un)∧φ into a boolean conjunctive
query with arithmetic comparisons QCid deﬁned as follows:
QCid () ← R1(u1) ∧ ... ∧ Rn(un) ∧ φ

Example 2. The set DC of denial constraints depicted
in Figure 1 are converted into the following boolean queries:

QC1 () ← D(x, y, z) ∧ S(x, y, u) ∧ z > u
QC2 () ← D(x, y, z) ∧ V (x, y, u) ∧ z > u
QC3 () ← S(x, y, z) ∧ V (x, v, z)

It is easy to verify that an instance I violates the set of
denial constraints DC iﬀ the boolean UCQ query QDC ≡
QCid evaluates to true over I (i.e., at least one of the

(cid:87)
C∈DC
conjunctive queries QCid , for C ∈ DC, returns true when
evaluated over I). The base tuples of I which are inconsis-
tent w.r.t. DC are exactly those tuples of I that contribute
to the computation of the empty answer <> (i.e., true) for
query QDC when evaluated over I.
In particular, a base
tuple t of I violates a constraint C ∈ DC iﬀ t contributes
to the derivation of the answer true when the query QCid is
evaluated over I.

We shall use below the why-provenance [12] to compute
the inconsistent base tuples while keeping track of the con-
straints violated by each inconsistent tuple.
Indeed, the
why-provenance of an answer t in a query output is made of
the set of all contributing input tuples [12].

We ﬁrst formulate the why-provenance in the provenance
semirings framework as proposed in [26]. Let P(Γ) be the
powerset of the set of tuple identiﬁers Γ. Consider the fol-
lowing provenance semiring: (P(Γ) ∪ {⊥}, +, ., ⊥, ∅), where:
∀S, T ∈ P(Γ) ∪ {⊥}, we have ⊥ + S = S + ⊥ = S, ⊥.S =
S.⊥ = ⊥ and S +T = S.T = S ∪T if S (cid:54)=⊥ and T (cid:54)= ⊥. This
semiring consists of the powerset of Γ augmented with the
distinguished element ⊥ and equipped with the set union (∪)
operation which is used both as addition and multiplication.
The distinguished element ⊥ is the neutral element of the
addition and the annihilating element of the multiplication.
In order to compute the why-provenance, we convert the
instance I over the schema S into a K-instance, denoted by
I LP , with K = P(Γ) ∪ {⊥}. The K-instance I LP is deﬁned
below.

Definition 1

(K-instances). Let I be an instance
over a database schema S and let DC be a set of denial
constraints over S. Let K = P(Γ) ∪ {⊥}. The K-instance

I LP is constructed as follows: ∀Ri ∈ S a corresponding K-
relation is created in I LP . A K-relation I LP (Ri) ∈ I LP
is populated as follows:

(cid:26) I LP (Ri)(t) = {id(t)} if t ∈ I(Ri)

I LP (Ri)(t) = ⊥

otherwise

Example 3. Figure 2 shows the provenance database
hdbLP obtained from the hospital database hdb of our moti-
vating example by annotating each tuple t ∈ hdb with a sin-
gleton set {id(t)} (column lprov) containing the tuple iden-
tiﬁer of t.

Using the provenance semirings (P(Γ) ∪ {⊥}, +, ., ⊥, ∅),
we deﬁne below the function V C that associates with each
base tuple t of I the set of constraints violated by t.

Definition 2

(Violated constraints). Given

set

an instance I and a set of denial constraints DC,
of DC vi-
the
constraints
olated by a tuple
follows:
t
I is deﬁned as
V C(I, DC, t) = {Cid ∈ Υ | t ∈ QCid (I LP )(<>)}

V C(I, DC, t)

of
∈

Example 4. Consider the boolean conjunctive queries
QC1 , QC2 and QC3 of Example 2. Hence, the lineage of the
output true of each query gives the set of tuples that violate
the corresponding constraint:
QC1 (I LP )((cid:104)(cid:105)) = {t2, t3, t4}, QC2 (I LP )((cid:104)(cid:105)) = {t2, t7}
QC3 (I LP )((cid:104)(cid:105)) = {t4, t7}

These lineages enable us to compute the set of constraints
violated by each tuple t, given by the function V C(I, DC, t1).
For example, we have V C(I, DC, t1) = ∅, (i.e., t1 is
a consistent tuple) while V C(I, DC, t2) = {C1, C2} and
V C(I, DC, t3) = {C1}.

Note that, even if why-provenance computes richer anno-
tations [12], we choose to not keep the information about
combinations of tuples that cause a violation. Hence, our
approach is currently agnostic to the inconsistency reasons.

5.2 Annotating the database instance

In the next section, we will show how to use the prove-
nance polynomials to deﬁne the inconsistency degrees of
query answers.
In order to obtain that, we ﬁrst need to
convert the instance I into a N[Υ]-instance, denoted I Υ.
As shown in the following deﬁnition, an instance I Υ is de-
rived from I by tagging each tuple t ∈ I with a monomial
with variables in Υ.

Definition 3

(I Υ instance). Let I be an instance
over a database schema S and let DC be a set of denial
constraints over S. Let K = N[Υ]. The K-instance I Υ is
constructed as follows: ∀Ri ∈ S a corresponding K-relation
is created in I Υ. A K-relation I Υ(Ri) ∈ I Υ is populated
as follows:

I Υ(Ri)(t) =

(cid:40) 0

(cid:81)
Cid∈Υ

if t /∈ I Υ(Ri)
otherwise

C l
id

with l = 1 if Cid ∈ V C(I, DC, t) or l = 0 otherwise.

Hence, an annotation I Υ(Ri)(t) of a tuple t is equal to
1 if the base tuple t is consistent (i.e., V C(I, DC, t) = ∅),
otherwise it is equal to a monomial expression that uses as
variables the identiﬁers of the constraints violated by t (i.e.,
the elements of V C(I, DC, t)).

5

Diagnosis(D)

PID
02
01

RefD
d4
d2

Date
2
4

lprov
{t1}
{t2}

prov
1
C1C2

Surgery(S)

PID
01
01
02
01

RefD
d2
d2
d4
d2

Date
1
3
4
5

lprov
{t3}
{t4}
{t5}
{t6}

prov
C1
C1C3
1
1

PID
01
02

V accination(V )
lprov
{t7}
{t8}

Date
3
3

RefD
d2
d4

prov
C2C3
1

Figure 2: The K-instances hdbLP (without prov column) and hdbΥ (without lprov column).

Example 5. Continuing with our example, the hdbΥ in-
stance obtained from the hospital database hdb is depicted
in Figure 2. We illustrate below the computation of the an-
notations of the tuples t1 (a consistent tuple) and t2 (an
inconsistent tuple). From the previous example, we have
V C(I, DC, t1) = ∅ and hence the annotation of t1 is com-
puted as follows: hdbΥ(Ri)(t1) = (cid:81)
id = 1. For the

C 0

Cid∈Υ

tuple t2, we have V C(I, DC, t2) = {C1, C2} and hence:
hdbΥ(Ri)(t1) = C 1

3 = C1C2.

1 × C 1

2 × C 0

In the sequel, we assume that the relations of an anno-
tated instance I Υ are augmented with an attribute prov
that stores the annotations of the base tuples. As an exam-
ple, Figure 2 shows the annotated relations of the instance
hdbΥ together with their respective prov columns.

5.3 Computing inconsistency degrees of query

answers

Given a query Q, we evaluate Q over the N[Υ]-instance
I Υ and use the provenance polynomials semiring in order
to annotate each answer t of Q. The computed anno-
tations, expressed as polynomials with variables from the
set Υ of constraint, are fairly informative as they allow to
fully record how the constraints are violated by base tu-
ples that contribute to each answer. Such annotations are
hence exploited to compute the various inconsistency mea-
sures needed for query answers.

Example 6. Continuing with the example, evaluating the
query Qex over hdbΥ and computing its polynomial prove-
nance leads to the following annotated answers:
Qex(hdbΥ)((cid:104)d2, d2(cid:105)) = C 2
3 + C 2
Qex(hdbΥ)((cid:104)d4, d4(cid:105)) = 1.

2 C3 + C 2

1 C 2

2 C 2

1 C 2

1 C 2

2 C3

1 C 2

The monomial C 2

2 C3 that appears in the annotation of
the answer (cid:104)d2, d2(cid:105) of Qex encodes the fact that this answer
can be computed from inconsistent base tuples that lead to
the violation of the constraints C1 and C2 twice and to the
violation of the constraint C3 once.

Hence, the polynomial expression Q(I Υ)(t) fully records
the inconsistency of an output t in terms of violations of
constraints and therefore can be used to quantify the incon-
sistency degrees of a query outputs. Consider a polynomial
P = Q(I Υ)(t) of an output t of a given query Q. Each
monomial M from P gives an alternative way to derive the
output t. In the sequel, we consider bag semantics of query
answers. Although our approach is extensible to set seman-
tics of query answers, we do not discuss this further in the
paper.

Under bag semantics, each query answer will be annotated
with a monomial corresponding to the unique derivation of
the considered answer.

Two diﬀerent measures can be deﬁned in order to quan-
tify the inconsistency degree of an answer t depending on
how one deals with multiple occurrences of the same vari-
able in monomials. This situation occurs when a constraint

6

is violated by more than one base tuple that contribute to
an answer t. We deﬁne two possible quantiﬁcations to deal
with this issue: single occurrence quantiﬁcation, in which
a variable that appears in a monomial is counted exactly
once, and multi-occurrence quantiﬁcation, where the exact
number of occurrences of a variable in a monomial is taken
into account when quantifying the inconsistency degree of
a given answer. As a consequence, we obtain two diﬀer-
ent inconsistency measures: the CBM (Constraint-based,
Bag semantics, Multiple occurrence) measure and the CBS
(Constraint-based, Bag semantics, Single occurrence) mea-
sure.

Definition 4

(Inconsistency measures). Let I, Q
and DC be deﬁned as previously. Let M = Q(I Υ)(t) be
the monomial annotating an output t of Q. We deﬁne in-
def
consistency measures of t as: CBM (t, Q, I, DC)
= W (M )
def
= |V ar(M )|

and CBS(t, Q, I, DC)

It follows that a single occurrence quantiﬁcation of a
monomial M amounts to counting the number of distinct
variables that occur in M while a multi occurrence seman-
tics sums the total number of occurrence of each variable in
M (given by the weight W (M ) of M ).

Example 7. Consider the annotation
Qex(hdbΥ)((cid:104)d2, d2(cid:105)) = C 2

1 C 2
(cid:123)(cid:122)
M1

2 C3
(cid:125)

+ C 2
(cid:124)

2 C 2
1 C 2
3
(cid:123)(cid:122)
(cid:125)
M2

+ C 2
(cid:124)

1 C 2
(cid:123)(cid:122)
M3

2 C3
(cid:125)

.

(cid:124)

This annotation conveys the information about the violated
constraints by each of the three possible ways to derive the
output (cid:104)d2, d2(cid:105) as an answer to the query Qex. Under bag
semantics, each derivation corresponds to a distinct answer
annotated by a single monomial. This means that the an-
swer (cid:104)d2, d2(cid:105) is output three times leading to three answers,
a1 = a2 = a3 = (cid:104)d2, d2(cid:105), each of which annotated, respec-
tively, whith one of the monomials M1, M2 and M3. The
inconsistency degrees of these three answers can then be com-
puted as follows: CBS(ai, Q, I, DC) = 3, for i ∈ [1, 3],
and CBM (a1, Q, I, DC) = CBM (a3, Q, I, DC) = 5 and
CBM (a2, Q, I, DC) = 6.

While our approach is orthogonal to that of CQA in general
(as explained in Section 3), our notion of consistency is much
stronger than the notion of consistent answers in CQA as
stated by the following lemma.

Lemma 1. Let I, Q, DC be deﬁned as previously. ∀t ∈

Q(I) we have:
CBM (t, Q, I, DC) = CBS(t, Q, I, DC) = 0 ⇒ t is a CQA.

Lemma 6 is trivial to prove as any answer that has incon-
sistency degree equal to 0 is computed from tuples that do
not violate any constraint. As these tuples do not involve
any violation, they belong to all the repairs of database re-
gardless of the repair semantics. Clearly, the set of CQA
can be larger by including the tuples that involve violations
and leveraging a given repair semantics. More diﬀerences
between CQA and our method are addressed in Section 7.

6.

INCONSISTENCY-AWARE RANKING
In this section, we study top-k ranking of inconsistency-
awre tuples as deﬁned above. To this end, we leverage the
introduced inconsistency measures. We consider as input an
annotated instance I Υ, where each base tuple t of a relation
R is annotated with the monomial I Υ(R)(t) (c.f. Deﬁnition
3). Let α be either CBM or CBS, the main idea is to use α
as a scoring function over the results of a query Q where the
score of an output t of Q is given by CBM (t, Q, I, DC) =
W (M ) (respectively, CBS(t, Q, I, DC) = |V ar(M )|), with
M = Q(I Υ)(t). The goal is then to rank the answer tuples
while taking into account the inconsistency degrees of the
base tuples contributing to the answers. The fundamental
computation problem is then to be able to eﬃciently enu-
merate (part of) query answers in a speciﬁc order w.r.t. their
inconsistency degrees. We focus on one particular instance
of this problem where the goal is to return the query results
with the top k scores, hereafter called inconsistency-aware
top-k ranking.

Definition 5

(Top-k queries). Let I, Q and DC be
respectively a database instance, a conjunctive query and a
set of denial constraints over the same instance. Let k be
an integer, let α ∈ {CBM, CBS}. The top-k query answers
of a query Q using the inconsistency measure α, denoted by
Qk,α(I), is deﬁned as follows:
(i) Qk,α(I) ⊆ Q(I),
(ii) |Qk,α(I)| = M in(k, |Q(I)|), and
(iii) ∀(t1, t2) ∈ Qk,α(I) × (Q(I) \ Qk,,α(I)), we have:
α(t1, Q, I, DC) ≤ α(t2, Q, I, DC)

Condition (i) and (ii) ensure that a top-k query Qk,α(I)
computes at most k answers of Q(I) while condition (iii)
ensures that the computed answers are the best answers in
Q(I) w.r.t.
the inconsistency measure α. The following
example illustrates a top-k query over our running example.

Example 8. Assume k = 1 and α = CBM . Continuing
with the database hdb and the query Qex as in Figure 1, we
have: Qk,α

ex (hdb) = {(cid:104)d4, d4(cid:105)}.

A naive approach to solve a top-k query Qk,α(I), with α
being one of our inconsistency measures, would be to entirely
compute and sort, w.r.t. α, the set Q(I) and then ﬁlter
out the k best answers. Such a naive approach is clearly
suboptimal in particular when k (cid:28) |Q(I)|.

The problem of computing Qk,α(I) answers falls in the
general setting of rank join problems [28]. Performance of
rank join algorithms have been deeply studied in the case
of monotonic scoring functions [28, 31] while very few works
deal with nonmonotoninc functions.

Let us ﬁrst recall the monotonicity property. Let f be
a scoring function. The function f is monotonic w.r.t. an
operator ◦ iﬀ: f(x) ≤ f(y) ∧ f(z) ≤ f(v) ⇒ f(x ◦ z) ≤ f(y ◦ v),
∀x, y, z, v. Otherwise, f is said to be non-monotonic w.r.t.
◦.

The following lemma says that inconsistency degrees
based on multi occurrence quantiﬁcation are monotonic
w.r.t. the join operator ((cid:46)(cid:47)) while the inconsistency mea-
sures based on the single occurrence quantiﬁcation are non-
monotonic w.r.t. (cid:46)(cid:47).

Lemma 2. A scoring function that associates to each tu-
ple t a score computed using CBM (respectively, using
CBS) is monotonic (respectively, non-monotonic) w.r.t. (cid:46)(cid:47).

We present in the next section an integrated algorithm
to handle both monotonic and non-monotonic inconsistency
measures in the case of bag semantics and we prove the
optimality of the algorithm.

6.1 The TopINC algorithm

In this section, we present our top-k ranking algorithm,
called TopINC, for top-k queries under both inconsistency
measures CBM and CBS. A general idea behind exist-
ing rank jon algorithms [28] is to process the tuples of the
relations involved in a given query in a speciﬁc order by
considering at each step the most promising tuples at ﬁrst.
However, when the scoring function is not monotonic with
respect to the join operator, which is the case for CBS due
to single-occurrences, it is not straightforward to identify
the order in which tuples should be processed.

The core intuition of our top-k ranking algorithm consists
of using an index based on the inconsistency measures to
access the most promising tuples at each step of query pro-
cessing. More precisely, we build for each relation R, an
associated index, denoted ind(R), whose nodes are labeled
by a subset of the constraints. More precisely, each node
B of Ind(R) is labeled with label(B) ⊆ DC. A node B
stores the set of tuples’s ids of R, denoted B(R), that vi-
olate exactly the set of constraints label(B), i.e., the set
B(R) = {t ∈ R | V C(I, DC, t) = B}. We call B a bucket of
the index Ind(R) and the set B(R) the bucket content.

Example 9. In our example, the buckets of the index are
labeled with subsets of the constraints DC = {C1, C2, C3}.
For instance, a bucket B0, with label(B0) = ∅, will store
the consistent tuples B0(D) = {t1}, B0(S) = {t5, t6} and
B0(V ) = {t8} of the relations D, S and V . The labels of the
buckets and the content of the buckets are given below.
B7

B1 B2 B3

B6

B4

B5

{C1} {C2} {C3} {C1, C2} {C1, C3} {C2, C3} {C1, C2

B
label(B)

B0
∅

{t1}
B(D)
B(S) {t5, t6} {t3}
{t8}
B(V )

∅

∅

∅
∅
∅

∅
∅
∅

{t2}
∅
∅

∅
{t4}
∅

, C3}
∅
∅
∅

∅
∅
{t7}

Each index ind(R) is deﬁned as an ordered list of the
nodes containing fragments of R, where nodes are ordered
with respect to the cardinality set of their labels, i.e., B ≤ B(cid:48)
iﬀ |label(B)| ≤ |label(B(cid:48))|.

Example 10. The following indexes are associated with
the relations D, S and V of our example database: Ind(D)
= [B0, B4], Ind(V ) = [B0, B6] and Ind(S) = [B0, B1, B5].

We now describe the pseudocode of the Algorithm in de-
tail. Let Q be a query Q(u) ← R1(u1), . . . , Rm(um).
In
order process the query Qk,α, with α ∈ {CBS, CBM }, the
algoritm TopINC (c.f., Algorithm 1) takes as input:
the
query Qk,α, the indexes ind(Ri), with i ∈ [1, m], one for
each input relation and the set V iolC of the violated con-
straints obtained by unioning the labels of all the buckets in
the indexes. The algoritm uses as many temporary buﬀers
HRi, i ∈ [1, m] as the number of indexes. Each temporary
buﬀer contains the bucket contents. In addition, the algo-
rithm uses a vector jB of size m storing the ids of the buckets
that need to be joined during the course of the algorithm.
The algorithm TopINC follows a level-wise sequencing of the
iterations, where each level denotes the inconsistency degree
of the answers computed at this level (c.f., lines 3-7 of algo-
rithm 1). Level 0 means that consistent tuples are processed

7

while the subsequent level l indicates the number of con-
strainst that are considered for the violated tuples. When
processing a given level l, the algorithm resets the variable
curV Set, used to keep track of the violated constraints while
exploring the input relations at level l, and makes a recur-
sive call to the IterateJoin procedure (line 6). For each level
l, the IterateJoin procedure (Algorithm 2) explores the input
relations sequentially from R1 to Rn (lines 11 to 14). For
each input relation Rp, IterateJoin uses the index ind(Rp) to
identify the buckets of Rp that are worthwhile to consider
for the join (i.e., the buckets to be loaded in jB[p]), i.e.,
those buckets whose label size’s is less than l (line 5). The
relevant bucket ids of input relations are loaded in the jB
buﬀer (line 13 of algorithm 2) and when Rp is the last input
relation (i.e., p = m) (line 15) a join is performed between
the buﬀers of jB (lines 17-20 of the algorithm 2) in order to
compute the answers with inconsistency degree equal to the
current level l. Note that the variable curV Set will contain
duplicate occurrences if α = CBM (line 10) and single oc-
currences if α = CBS (line 7). It enables us to keep track of
the current level of inconsistency while exploring the inputs.
When intermediate inputs are explored, the IterateJoin al-
gorithm ensures that |curV Set| does not exceed the current
inconsistency level l (line 5 and line 11). When the last in-
put is processed, a join is performed between the buckets in
jB only if |curV Set| = l (line 15) which ensures that the
computed answers have l as inconsistency degree.

Algorithm 1: TopINC

Input : ViolC: set of violated constraints

Qk,α : a top-k query over R1, . . . , Rm with

α ∈ {CBM, CBS}

ind(R1), . . . , ind(Rm) : indexes of the input
relations

Output: Res: k best answers w.r.t. α
Data structures: HR1, . . . , HRm: input buﬀers;
jB : an array of size m begin
Res=[] be an empty list ;
/* Contr. violated by current answer
level:=0 ;
while l ≤ |V iolC| ∧ Res.size < k do

curVSet := ∅ ;
IterateJoin(1, level, curVSet) ;
level:= level + 1 ;

return Res

1

2

3

4

5

6

7

8

*/

ex

Example 11. We assume that the input relations are
processed in this order: D, S and V . We illustrate the pro-
cessing of query Q2,CBS
(I) by TopINC. Figure 3 exempliﬁes
the iterations of the algorithm. The gray cells, in each step,
denote the newly read tuples in that step. The ﬁnal result
(Level 3) is reported at the bottom of the Figure 3. Starting
from level 0, the selected buckets are jB = [B0, B0, B0], thus
leading to join the contents of these buckets only at the very
beginning. The contents of HV (B0), HS(B0) and HD(B0)
are shown in Figure 3. The ﬁrst answer corresponding to
the join of the above buﬀers is found (i.e, res = [(cid:104)d4, d4(cid:105)]).
The TopINC continues to read in selected buckets in jB. It
then tries to read in B0 of V but no additional tuples, then
it moves to read in B0 of V . Next, the tuple (cid:104)02, d2, 5(cid:105) is
loaded in HV (B0) but no additional answer is found. As
there is no additional answers (because k=2) and all tuples
are read in selected buckets, TopINC jumps to the next level,
i.e, the level 1. At this level, the ﬁrst selected buckets are
jB = [B0, B1, B0], thus leading to read the only one tuple

jB
D S V
B0 B0 B0

HD

Key
B0

Tuples
(cid:104)02, d4, 2(cid:105)

jB
D S V
B0 B1 B0

HD

Key
B0

Tuples
(cid:104)02, d4, 2(cid:105)

jB
D S V
B4 B1 B6

HD

Key
B0
B4

Tuples
(cid:104)02, d4, 2(cid:105)
(cid:104)01, d2, 4(cid:105)

Level 0
HS

Key

B0

Tuples
(cid:104)02, d4, 4(cid:105)
(cid:104)02, d2, 5(cid:105)

Level 1
HS

Key

B0

B1

Tuples
(cid:104)02, d4, 4(cid:105)
(cid:104)02, d2, 5(cid:105)
(cid:104)01, d2, 1(cid:105)

Level 3
HS

Key

B0

B1
B5

Tuples
(cid:104)02, d4, 4(cid:105)
(cid:104)02, d2, 5(cid:105)
(cid:104)01, d2, 1(cid:105)
(cid:104)01, d4, 3(cid:105)

HV

Key
B0

Tuples
(cid:104)02, d4, 3(cid:105)

Res
(cid:104)d4, d4(cid:105)

HV

Key
B0

Tuples
(cid:104)02, d4, 3(cid:105)

Res
(cid:104)d4, d4(cid:105)

HV

Key
B0
B6

Tuples
(cid:104)02, d4, 3(cid:105)
(cid:104)01, d2, 3(cid:105)

Res
(cid:104)d4, d4(cid:105)
(cid:104)d2, d2(cid:105)

Figure 3: Illustraive example of TopINC

Algorithm 2: IterateJoin

Input: p, level, curVSet

1 begin
2

/* Index of input relation p
Let idx := ind(Rp);
i:=1 ;
while i ≤ idx.size ∧ |label(idx[i])| ≤ level do

*/

*/

*/

*/

*/

if α = CBS then

curV Set := curV Set ∪ label(idx[i])

else

/* (cid:100) stands for bag union
curV Set := curV Set (cid:100) label(idx[i])

/* Case input Rp is not the last
if p < m ∧ |curV Set| <= level then

jB[p]:=idx[i];
IterateJoin(p + 1, level, curV Set);;

if p = m ∧ |curV Set| = level then

jB[p]:=idx[i];
/* Compute the join from jB
ans := HR1(jB[1]) (cid:46)(cid:47) . . . (cid:46)(cid:47) HRm(jB[m]) ;
/* Add the results to Res up to k
Res.add(ans) ;
if Res.size = k then

EXIT;

i := i + 1;

3

4

5

6

7

8

9

10

11

12

13

14

15

16

17

18

19

20

21

22

23

of bucket B1 of relation V into HV (B1). But no additional
answer is found and no others buckets in level 1 can be se-
lected bringing TopINC to level 2. Finally, TopINC processes
level 2 and then level 3 as shown in Figure 3 and halts when
it reaches |res| = 2.

The following two lemmas state the correctness and the

worst case complexity of TopINC, respectively.

Lemma 3. Let α ∈ {CBM, CBS}. The algorithm Top-

INC computes correctly Qk,α(I).

Lemma 4. Let Q(X) ← R1(X1), . . . , Rm(Xm) be a con-
junctive query, let s = |X| and let k be an integer. A query
Qk,α is evaluated by the TopINC in time O(nm) and in space
O(|I| + k × s).

Unsurprisingly, and like most of state of the art top-k join
algorithms that do not use speciﬁc knowledge related to the
join attributes (e.g., see [28, 31]), the worst case time com-
plexity of TopINC is in O(|I|m), with m the number of input
relations in Q. Interestingly, the previous lemma also pro-
vides a tighter upper bound regarding the space complexity.
This lemma is a consequence of the level-wise approach fol-
lowed by TopINC which ensures that query answers are com-
puted in the ascending order of their inconsistency degree.
Hence, TopINC strictly computes the answers that belong

8

to the output (and the algorithm stops when k answers are
computed). All the proofs are reported in appendix section.
Optimality of TopINC. As discussed in Section 3, the pres-
ence of the non-monotonic function CBS prevents us from
exploiting the existing frameworks [30, 31] to analyze the
performance of TopINC. We deﬁne hereafter a new class of
algorithms, called Semi-Blind Algorithms (SBA), which in-
cludes the algorithms that exploit only the prov column (i.e.,
the scoring function) without imposing any predeﬁned data
access strategy3. We show that in this general class, and
modulo non deterministic choices, TopINC is optimal w.r.t.
the number of tuples read from the inputs.

We start by deﬁning the family of SBA algorithms as fol-
lows. We deﬁne SA as a database schema where each table
R has a set of attributes A. Let I1 and I2 be two relational
instances over SA, we deﬁne equivalent instances under at-
tributes A: I1 ≡A I2 iﬀ ∀R ∈ SA, πA(I1(R)) = πA(I2(R))
with πA(R) the projection over table R on attributes A.

Let Q(X) ← R1(X1), . . . , Rn(Xm) and I be respectively a
conjunctive query and an instance over schema S{prov}. Let
AL be an algorithm that allows to compute the answers of
Qk,α(I), with α ∈ {CBS, CBM }. A join test J of AL when
processing Qk,α over an instance I has the following form
J = t1 (cid:46)(cid:47) . . . (cid:46)(cid:47) tm where ti ∈ I(Ri) with i ∈ [1, m]. A score
of a join test is deﬁned as follows: α(J) = α(t1 (cid:46)(cid:47) . . . (cid:46)(cid:47)
tm). We deﬁne jP ath(AL, Q, I) as the sequence of joins
test performed by the algorithm AL when evaluating Qk,α
over I. The intuition is that jP ath(AL, Q, I) enables to
capture the behavior of the algorithm AL when it evaluates
Qk,α over I. Formally, jP ath(AL, Q, I) = [J1, ..., Jn], where
m, with ti
1 (cid:46)(cid:47) . . . (cid:46)(cid:47) ti
Ji = ti
j ∈ I(Rj) and j ∈ [1, m]. We
deﬁne label(Ji) def= (cid:0)πprov(ti
m)(cid:1). We are now
1), . . . , πprov(ti
ready to give the formal deﬁnition of the class of Semi-Blind
Algorithms (SBA), the algorithms that use only information
from the prov column when processing inconsistency-aware
queries.

Definition 6

(SBA algorithms). Let Qk,α be a top-
k query, let I1, I2 be two instances, and let AL be an al-
gorithm such that:
n2 ] and
jP ath(AL, Q, I1) = [J1, ..., Jn1 ]. The algorithm AL belongs
to the class SBA iﬀ:
I1 ≡{prov}
[1, max(n1, n2)]

I2 ⇒ label(Ji) = label(J (cid:48)

jP ath(AL, Q, I2) = [J (cid:48)

for i ∈

1, ..., J (cid:48)

i),

According to this deﬁnition, an algorithm AL ∈ SBA will
have a similar behavior when evaluating a query Qk,α over
diﬀerent instances that are equivalent under prov, i.e., AL
will explore the same sequence of join tests but may stop
earlier or later depending on the success or failure of the
join tests. The outcome of this latter test is related to the
content of the join attributes of each speciﬁc input instance
and remains independent from the prov column. As one
can easily notice, TopINC belongs to SBA. Indeed, it only
relies on the information given by the prov column without
exploiting any auxiliary information. A natural metric to
measure the performance of an algorithm AL is to compute
the number of tuples of the input relations accessed by AL,
denoted cost(Al, Q, I).

Let J = t1 (cid:46)(cid:47) . . . (cid:46)(cid:47) tm, we denote by tuple(J) =
{t1, . . . , tm} the set of tuples involved in a join test J. Con-
sider an algorithm AL with jP ath(AL, Q, I1) = [J1, ..., Jn1 ].
3Note that the popular family of top-k algorithms using
sorted data access [22, 28, 30] is a strict subset of SBA.

|

the cost of AL is given by:

tuple(Ji)|. The following lemma states that there ex-

Then,
n
(cid:83)
i=1
ists no algorithm in the class SBA that is optimal w.r.t.
the cost metric deﬁned above.

cost(Al, Q, I) =

Lemma 5. Let Qk,α be a top-k query.

Then, we
have: ∀Al1 ∈ SBA, ∃Al2 ∈ SBA and an instance
I such that, cost(Al1, I, Q) > cost(Al2, I, Q).

The intuition behind the above lemma 10 is that the SBA
algorithms need to make a non-deterministic choice among
the join tests that have equivalent score. We illustrate this
case by relying on a corner case of an instance ˆI contain-
ing exclusively consistent tuples. Consider a query Q over
n inputs R1, . . . Rn such that |Q(ˆI)| = 1. Consider now the
evaluation of the query Q1,CBS by SBA algorithms. Since
all the join tests among the tuples of the input relations will
have the same score, an SBA algorithm needs to make a non-
deterministic choice among the elements of R1 × . . . × Rn
to decide in which order the join tests will be performed.
Hence, the best algorithm Al would luckily pick the right
tuples in the ﬁrst round of choice which leads to an op-
timal cost: cost(Al, ˆI, Q) = n. The worst-case algorithm
Al(cid:48) might end up with the least good cost after exploring
the entire cartesian product of the inputs, which leads to
cost(Al, ˆI, Q) =
|Ri| (i.e., the algorithms Al(cid:48) needs to

n
(cid:80)
i=1

read the entire inputs). Consequently, we argue that it is not
worthwhile to distinguish between SBA algorithms w.r.t. to
the order of exploring join tests with equivalent score (since
this is a non-deterministic choice). We formalize this notion
using regions, deﬁned as maximal subsequences of join tests
with equivalent score, and we deﬁne a new metric based
on the number of regions explored by the algorithm. The
region-based cost enables us to get ride of lucky choices when
comparing the performances of SBA algorithms.

Below, we deﬁne

the notion of a region.

Let
jP ath(AL, Q, I) = [J1, ..., Jn]. A region of jP ath(AL, Q, I)
is a maximal subsequence of jP ath(AL, Q, I) made of
inconsistency degree. More for-
join tests with equal
is a region of
mally, a sequence [J1, ..., Jn], with l ≤ p,
jP ath(AL, Q, I) = [J1, ..., Jn]
(i)
α(Ji) = α(Jj), ∀i, j ∈ [l, p], and (ii) α(Jl−1) (cid:54)= α(Jl)
and α(Jp+1) (cid:54)= α(Jp). We deﬁne Regs(Al, Q, I) to be
the set of regions of jP ath(AL, Q, I). We deﬁne the cost
model cost∇(Al, Q, I) as the number of regions explored
by the algorithm Al during processing of query Q over I:
cost∇(Al, Q, I) = |Regs(Al, Q, I)|.

iﬀ l, p ∈ [1, n], and:

The introduced cost model cost∇(Al, Q, I) conveniently
prevents an algorithm to compute an answer that can be
dropped after to the top-k answers, thus avoiding more use-
less I/O operations, as proved in the following theorem.

Theorem 1. For any instance I and any top-k con-
cost∇(TopINC, Q, I) ≤

junctive query Qk,α, we have:
cost∇(AL, Q, I), ∀AL ∈ SBA.

Notice that the TopINC algorithm is only sensitive to
the class of queries and unsensitive to the class of con-
straints, the latter being hardcoded in the inconsistency an-
notations. TopINC and Theorem 2 are established for con-
junctive queries, which are by deﬁnition monotonic queries
for which a partial output can be computed starting
(i.e.

9

Dataset

Syn

#Rel

#Tup

Hospital
T ax
Synthetic
P stock

(cid:37)
(cid:37)
(cid:88)
(cid:37)

1
1
5
1

114919
99999
1012524
244992

#Equal
3
1
6
1

#Cons

#(In-)equal
39
49
9
9

#atom

Inc(%)

2
2
[1, 3]
[1, 2]

100
100
89.34
18.62

Table 3: Datasets used in our empirical evaluation.

Query
1 s
214ms
41 ms
31ms
57 ms
23 ms
97 ms
518ms
61 ms
231ms
472ms
3 s
1 s
938ms

Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9
Q10
Q11
Q12
Q13
Q14

CBM CBS
119 s
22 s
2 s
3 ms
31ms
546ms
903s
6 s
83ms
12ms
7 s

#Answers
2891897
560 161
114 919
50
625
99 999
100 777
488 505
303
582
505 046
14831052 5 mn
2 mn
7384207
9 s
287 242

59 s
11 s
2 s
2 ms
19ms
546ms
558ms
4 s
80ms
12ms
4 s
2 mn
1 mn
3 s

Across all tuples in the query output
(a)

CBM
41 µs
39 µs
17 µs
60 µs
49 µs
5 µs
9 µs
12 µs
273µs
20 µs
13 µs
20 µs
16 µs
31 µs

Q1
Q2
Q3
Q4
Q5
Q6
Q7
Q8
Q9
Q10
Q11
Q12
Q13
Q14

CBS
20 µs
19 µs
17 µs
40 µs
30 µs
5 µs
5 µs
8 µs
264µs
20 µs
7 µs
8 µs
8 µs
10 µs

One tuple at a time
(b)

(a) Tax

(b) Hospital

(c) Synthetic

(d) Pstock

Figure 4: Transformation of an instance into a N[Υ]-instance

from a partial input). Non-monotonic queries (such as ag-
gregate queries and queries with negation) are not covered
by our algorithm and are far from being trivial due to the
non-monotonic nature of the CBS scoring function.

7. EMPIRICAL EVALUATION

Our experimental assessment has been carried out with
two main objectives in mind.
In the ﬁrst part, we aimed
at measuring the time required to transform a database in-
stance into a N[Υ]-instance. The latter transformation is
considered as the pre-processing time for our approach. In
second part, we empirically evaluate the TopINC algorithm
to perform top-k query answering. We have implemented
our framework in PostgreSQL 10 by leveragingPLSQL and
JDK 11. All the experiments have been executed on a DELL
Core i7 2.5 GHz laptop with 16 GB RAM running Linux
OS. The datasets used in our study are summarized in Ta-
ble 3. As real-life datasets, we employed the Hospital, Tax
and Pstock datasets from [17] as they are the only datasets
in the literature that are equipped with denial constraints.
In addition, we generated our own synthetic datasets and
companion denial constraints.

In Table 3, the column Inc denotes the percentage of in-
consistency per relation, whereas #Tup and #Rel denote
the number of tuples and relations in the dataset, respec-
tively. Finally, #Cons indicates the number of denial con-
straints per dataset. The column #atom gives interval of
number of atoms for the constraints of a given dataset. The
column Syn indicates the type of dataset (synthetic or not).
All the queries used are described as follows: Q1 to Q5 are
on the Hospital dataset and they contain one join; Q6 to
Q9 are on the Tax dataset and they contain one join; Q10
to Q14 are on the synthetic dataset; Q10, Q11 have a join
across three tables, Q12, Q13 have a join across four tables
and Q14 has a join across ﬁve tables.

Table 3 shows the constraints in each dataset. Columns
#Equal and #(In-)equal provide the number of constraints
that use exclusively equality predicates and those using a
mixture of predicates from {≤, ≥, (cid:54)=, <, >, =}, respectively.
As one can notice, the latter are in greater number.
Runtimes of the instance transformation. In this Sec-
tion, we measure the runtimes of the transformation of a
database instance into a N[Υ]-instance. Figure 4 shows
the runtimes for each dataset while varying the number of
constraints. We can observe that the runtimes of the K-
instance transformation linearly scale with the number of
constraints for all datasets. They range between tens and
thousands of seconds, depending on the dataset. We ob-

Figure 5: CBS and CBM computation overhead.

•

Baseline(500×500)

(cid:7)

TopInc(500×500)

(cid:74)

Baseline(1000×1000)

×

TopInc(1000×1000)

Figure 6: TopINC vs. Baseline (α = CBS)

served the highest runtimes only with one dataset (Tax),
which has ﬁfty denial constraints and took approximately
1h to transform 100000 tuples. Such a transformation is
part of the pre-processing and only done one time for the
annotated instances, thus it remains quite reasonable. One
can also notice that there is a huge gap between runtimes
of transformation of Tax (Figure 4.a) and Hospital (Figure
4.b) despite the fact that these two datasets have similar
characteristics. The observed gap is due to the fact that
the constraints in the dataset Tax are more sophisticated
than the constraints in the dataset Hospital (i.e., with larger
built-in atoms).
Overhead of inconsistency measures on query execu-
tion. In order to gauge the overhead of running a query Q
with inconsistency degrees, we have employed our 14 queries
and measured the overhead per each tuple in the answer
(Table 5.a) as well as the total overhead for the complete
output of the query (Table 5.b). The obtained results are
reported in Table 5. The greater is the size of the output of
a query the larger is the overhead of query execution with
inconsistency degrees. The columns query and #answers in
Table 5.a are the total query runtime of the original query
on an inconsistency-free database instance and the size of
query answer, respectively. Depending to the size of output
of the queries, the overhead ranges between 2ms and 6m,
respectively for queries Q4 and Q12. (respectively, yellow
and red cells in Table 5.a). The diﬀerence can be explained
by looking at the size of the answer set of Q4 and Q1 that
are 50 tuples and 15M tuples, respectively. These overhead
are, however, not trustworthy to understand the overhead
of our approach, since they concern the entire output set
of queries, whereas our algorithms returns the top-k results
tuple by tuple. Thus, one should look at the overhead per
tuple in Table 5.b. We can observe that the overheads per
tuple are reasonable in all cases, and range between 5 mi-
croseconds and 293 microseconds (yellow and red cells in
Table 5.b).
TopINC Performance vs. baseline. We have imple-
mented a baseline algorithm leveraging PostgreSQL, where
all answers of a query are computed beforehand and then
sorted (ORDER BY) and ﬁltered (LIMIT k). Figure 7

10

4030201050Number of Constraints05001000150020002500300035004000Runtime(s)30201042Number of Constraints050100150200250300Runtime(s)51015Number of Constraints020406080100Runtime(s)3610Number of Constraints0.00.51.01.52.02.53.03.5Runtime(s)0.10.20.40.6#answers (x10^6)101101103105Runtime (ms)K=20 and DC = 10 0.10.20.40.6#answers (x10^6)100101102103104Runtime (ms)K=20 and DC = 20 0.10.20.40.6#answers (x10^6)100101102103104Runtime (ms)K=20 and DC = 30 shows the performance of TopINC (with k varying from 10 to
300) as opposed to the aforementioned baseline algorithm.
We have chosen ﬁve queries as representatives of diﬀerent
datasets and join sizes ranging from one join (Q1,Q2, Q8)
and three joins (Q11) to ﬁve joins (Q14). The algorithm
TopINC (blue bar) can be up to 28 times faster than the
baseline approach as shown in Figure 7.a. There is only one
query, i.e. the most complex query Q14, for which TopInc
has lower performance compared to the baseline, starting
from a value of k ≥ 200. The reason for that is the fact that
TopInc for higher values of k and higher number of joins
in the query will inspect more buckets and try to perform
more joins that will likely produce no answers. Further-
more, notice that in all these experiments the baseline turns
to have advantageous with respect to TopInc, as it leverages
the query planning of Postgres and opportunistically picks
the most eﬃcient join algorithm. Despite these advantages,
our approach is still superior in terms of performance in the
majority of the cases.
In Figure 7, from 7.f to 7.j, we
measure the memory consumption of our approach for the
same queries. We observe that TopINC always consumes less
memory than the baseline.

We also ran another experiment on synthetic datasets to
study the impact of other parameters on the performance of
TopINC. The results are reported in Figure 6. Precisely, we
wanted to study the dependency of TopINC on the following
parameters: the number of answers to be returned (k), the
number of violated constraints (DC), the size of search space
formed by DC (i.e, the number of subsets of constraints vi-
olated by base tuples) and the exact size of output of Q (i.e,
|Q(I)|). In these results, we focused on a relatively simple
query Q containing a join between two synthetic relations
(of size 1000 each one) and we kept constant the value of k
(equal to 20). We ran this experiment with varying num-
ber of denial constraints DC from 10 to 30, respectively in
Figures 6.a, 6.b and 6.c. In each of these plots, we vary the
selectivities of Q and the size of the search space of the algo-
rithm. One can see that TopINC outperforms the baseline in
all cases and is particularly advantageous with larger query
outputs and smaller search space.. The underlying reason is
that the greater is the output size of the query, the larger is
the probability to ﬁnd answers within the ﬁrst combinations
scanned within the search space.

Qualitative evaluation. We have designed an experi-
ment devoted to show the utility of our inconsistency mea-
sures on real-world inconsistent data. We chose two real-life
datasets, namely Adult, used in [1, 37] and containing census
data, along with and Food Inspection [2] including informa-
tion about inspections of food establishments in Chicago.
The features of the two datasets are shown in Table 4.a.
Table 4.b reports the the constraints of Adult, namely A1
and A2, that have been derived using Holoclean [38]. While
A1 indicates that men who have ‘married’ as marital status
are husbands, A2 expresses the dual constraint for women.In
addition, we handcrafted a third constraint A3 establishing
that adults who are not in a family should not have ‘married’
as marital status. This third constraint allows to capture
violated tuples that overlap with the tuples violated by the
two former constraints. We also built meaningful denial con-
straints for the second dataset as shown in Table 4.c. The
constraint F1 (respectively, F2) states that a licence num-
ber, which is a unique number assigned to an establishment,
uniquely identiﬁes the legal name of the establishment (re-

Dataset
Adult
Food Inspection

Table
Adult
Inspection

#tuples
48842
204896

Attributes
11
17

(a) Characteristics of Adult and Food Inspection.
A1:← Adult(A,MS,Re,S,...)∧ S=‘Female’ ∧ Re=‘Husband’
A2:← Adult(A,MS,Re,S,...) ∧ S=‘Male’ ∧ Re=‘Wife’
A3:← Adult(A,MS,Re,S,...) ∧ Re=‘Husband’ ∧

MS=‘Marr-civ-sp.’

(b) Constraints on Adult.
F1: ← Inspection(I1,F T1, V1, Re1, L1, . . .) ∧ L1 = L2 ∧

Inspection(I2,F T2, V2, Re2, L2, ...) ∧ N1 (cid:54)= N2

F2: ← Inspection(I1,F T1, V1, R1, L1, ...) ∧

Inspection(I2,F T2, V2, R2, L2, ...) ∧ L1 = L2 ∧
R1 (cid:54)= R2

F3: ← Inspection(I1,F T1, V1, R1, L1, D1, ...) ∧
Inspection(I2,F T2, V2, R2, L2, D2, ...) ∧
IT1 =(cid:48)
D2 < D1

consultation(cid:48) ∧ IT2

(cid:54)=(cid:48)

consultation(cid:48) ∧

(c) Constraints on Food Inspection.
AQ1: SELECT * FROM adult a1, adult a2 WHERE a1.sex = ’Male’
AND a2.sex = ’Female’AND a1.country = a2.country AND
a1.income = a2.income

FQ1: Select

like

From

where

t2.license

inspection

inspection

t1,
(t1.results = ’Fail’

t3
’%food
t1.license=t2.license
(cid:54)= ’Fail’

inspection
t2,
or
t1.violations
contact %’)
and
t1.license=t3.license
and
t2.inspection type =
’Canvass’
and
and t3.inspection date
t1.inspection date<t3.inspection date
<t2.inspection date and t1.zip >= 60666 and t2.zip > 60655
and t3.zip > 60655

t3.inspection type=’Complaint’

and
and

t2.results

non-food

and

and

(d) Queries on Adult and Food Inspection.

Table 4: Real-world datasets with their denial constraints.

spectively, its risk category). The constraint F3 states that
if a given establishment has been inspected for ‘consultation’
at a date d, one cannot expect to have an inspection of a
diﬀerent type prior to d for the same establishment. This is
because the attribute Inspection type takes the value ‘con-
sultation’ when the inspection “is done at the request of the
owner prior to the opening of the establishment.”

Viol.
Const.
∅
F1
F2
F3
F2F1
F3F1
F3F2
F3F2F1 439

#Viol.
F.Insp.
191K
7715
360
2366
1977
181
2

#Viol.
Viol.
Adult
Const.
48K
∅
A1
7
A2
5
A3
23
A1A2
0
A1A2
0
A2A3
0
A1A2A3 0

(a) Data Inconsistency.

Annot.

CBS CBM #Ans
0
1
1
1
1
2
2
2

276M ∅
0
99K A1
1
28K A2
1
13K A3
1
A2
23
2
3
A1A2
10
2
A1A3
32
2
A2A3
2
6
(b) Distrib.
of AQ1 Answ.

CBS CBM #Ans Annot.
A1, A3
32
2
A2, A3
6
2
A1, A2
10
2
A2
23
1
3
A1
29
1

2
2
2
2
1

(c) Top-100 AQ1 Answ.

CBS CBM
0
0
1
(e) Comparison with CQA.

Ans.
(cid:104)1141505(cid:105)
(cid:104)1042895(cid:105)
(cid:104)34183(cid:105)

0
0
3

CBS
0
1
2
1
1
1
2
3
3

CBM
0
3
6
1
2
3
4
8
9

#Ans
6239
495
17
6
16
3
72
135
36

1

2 F 3

Annot.
∅
F 3
1
F 3
F3
F 2
3
F 3
3
F3F 3
1
3 F 3
F 2
1 F 3
F 3

2 F 3
3 F 3
2
(d) Distrib. of FQ1 Answ.

1

Table 5: Results of the qualitative study.
We report in Table 4.d the considered queries for the two
datasets. The query AQ1 on Adult ﬁnds all couples of male
and female living in the same country and earning the same
income. The query FQ1 on Food Inspection retrieves the li-
censes of establishments in a speciﬁc area that were subject
to three inspections: the ﬁrst one having either a failing in-
spection or a violation related to “food and non-food contact

11

(a) Q1

(b) Q11

(c) Q2

(d) Q8

(e) Q14

(f) Q1

(g) Q11

(h) Q2

(i) Q8

(j)Q14

Figure 7: TopINC performance vs baseline (α = CBS). (a)-(e) Runtime, (f)-(j) Memory footprint

surface”, followed by an inspection issued as a response to
a complaint and then a non-failing normal inspection.

Table 5.a. shows the violations of constraint for the two
datasets. We can notice that there are diﬀerent kinds of
tuples returned by AQ1 as illustrated in Table 5.b. The
majority of the results (276M tuples) are consistent, thus
both CBS and CBM are equal to 0, while the remaining
answers exhibit 1 or 2 as inconsistency degrees. Most of the
inconsistent tuples violate one constraint at a time (in the
order A3, A1 and A2) while the rest of the tuples violate two
constraints. For this dataset, in the majority of the cases
a constraint is violated at most once and hence CBS and
CBM measures are not discriminating, except for the 23
answers where violations occur twice (5th line of Table 5.b).
These tuples are captured when running TopINC for top-100
tuples starting from the most inconsistent ones as illustrated
in Table 5.c. Note that, while CBM does not distinguish
between the 71 most inconsistent answers of AQ1 (answers
with CBM = 2 corresponding to the ﬁrst four rows of Table
5.c), the CBS measure provides a diﬀerent ranking for the
23 answers of the 4th row of this Table.

We show in Table 5.d the inconsistency degrees of the
answers when evaluating query FQ1 on the second dataset.
Note that for this query the CBS degrees vary from 0 up
to 3 while the CBM degrees range from 0 up to 9. We ob-
serve now that many answers are not distinguishable under
CBS while they exhibit a wider range of CBM degrees (e.g.,
CBM varies from 1 to 3 for answers having CBS = 1). This
again shows that CBS and CBM provide the user with two
diﬀerent types of information, both being useful to carry
out the ranking. Furthermore, by looking at the tuples that
contribute to the last row of Table 5.d (CBM = 9) violat-
ing the three consraints F1, F 2 and F3 in tandem, we made
an interesting discovery. These violations (and also those
corresponding to CBM = 8) are all related to the same er-
roneous license numbers (all set to 0 in the corresponding
tuples).

Finally, we show by means of examples the remarkable dif-
ference between our approach and CQA4. Note that as we
already pinpointed in Section 3, these are complementary
approaches. Table 5.e shows three CQA-consistent answers
for query F Q1. First, we note that all our consistent answers
(i.e., with CBS = CBM = 0) are also CQA-consistent as

4We consider repair by deletion and symmetric set diﬀerence
as measure of minimality [5].

12

stated in Lemma 1. The converse is not true as it can be
observed in Table 5.e where the answer (cid:104)34183(cid:105) is CQA-
consistent but not consistent in our framework (with CBS
and CBM (cid:54)= 0). On another note, we can notice that the
CQA approach does not distinguish between the three CQA-
consistent answers of Table 5.e. In particular, the informa-
tion that the CQA-consistent answer (cid:104)34183(cid:105) is computed
using inconsistent base tuples (violation of F1) is not con-
veyed by CQA.

8. CONCLUSION AND OUTLOOK

We have presented a novel framework for inconsistency-
aware query answering leveraging two diﬀerent measures of
inconsistency. We have grounded the computation of incon-
sistency degrees in why-provenance annotations and we have
designed a novel top-k rank algorithm suitable for the above
measures while proving its optimality.

As future work, we plan to investigate the extension of our
approach to other classes of constraints and queries, such as
universal constraints and aggregate queries. Techniques de-
veloped in the literature e.g. [18] for tracing lineage of ﬁrst
order queries could be employed to extend our approach
to the upper class of constraints beyond DCs (e.g., univer-
sal constraints). However, in the presence of negation, the
connection between provenance and inconsistency degrees
of base tuples remains unclear and raises intriguing research
questions. On the other hand, while recent literature, e.g.,
[4], provides foundations to study the computation of in-
consistency measures for aggregate queries using polynomial
provenance, the problem of eﬃciently computing top-k ag-
gregate queries in presence of non-monotonic scoring func-
tions such as CBS remains open and unsolved up to date.
Handling updates of tuples or denial constraints in our
framework is also in our research agenda. One has to re-
sort to classical incremental view maintenance mechanisms.
However, handling constraint modiﬁcations without fully re-
computing both the constraint-based annotations and the
TopINC’s index, remains an open challenge.

9. ACKNOWLEDGEMENTS
Our research is supported by the French National Agency
(ANR) through the grant nr. 18-CE23-0002 QualiHealth.

1050100150200250300K29212215218Runtime (ms)TopIncBaseline1050100150200250300K2729211213Runtime (ms)TopIncBaseline1050100150200250300K29212215Runtime (ms)TopIncBaseline1050100150200250300K28210212214Runtime (ms)TopIncBaseline1050100150200250300K212214Runtime (ms)TopIncBaseline1050100150200250300K05101520Memory (Mo)TopIncBaseline1050100150200250300K0102030Memory (Mo)TopIncBaseline1050100150200250300K05101520Memory (Mo)TopIncBaseline1050100150200250300K02468Memory (Mo)TopIncBaseline1050100150200250300K02040Memory (Mo)TopIncBaseline10. REFERENCES

[1] Adult dataset. https://github.com/HoloClean/

holoclean/blob/master/testdata/AdultFull.csv.

[2] Food inspection dataset. https://data.

cityofchicago.org/Health-Human-Services/
Food-Inspections/4ijn-s7e5.

[3] S. Amer-Yahia, S. Elbassuoni, A. Ghizzawi, R. M.
Borromeo, E. Hoareau, and P. Mulhem. Fairness in
online jobs: A case study on taskrabbit and google. In
EDBT 2020, pages 510–521, 2020.

[4] Y. Amsterdamer, D. Deutch, and V. Tannen.

Provenance for aggregate queries. In ACM PODS
2011, page 153–164, 2011.

[5] M. Arenas, L. Bertossi, and J. Chomicki. Consistent
query answers in inconsistent databases. In ACM
PODS 1999, pages 68–79, 1999.

[6] A. Arioua and A. Bonifati. User-guided repairing of
inconsistent knowledge bases. In EDBT 2018, pages
133–144, 2018.

[7] L. Bertossi. Database Repairing and Consistent Query

Answering. Morgan & Claypool, 2011.

[8] L. Bertossi. Database repairs and consistent query

answering: Origins and further developments. In ACM
PODS 2019, page 48–58, New York, NY, USA, 2019.
Association for Computing Machinery.

[9] L. Bertossi, A. Hunter, and T. Schaub. Introduction

to inconsistency tolerance. In Inconsistency Tolerance,
volume LNCS 3300, pages 1–14, 2005.

[10] L. E. Bertossi. Repair-based degrees of database

inconsistency: Computation and complexity. CoRR,
abs/1809.10286, 2018.

[11] L. E. Bertossi and J. Chomicki. Query answering in

inconsistent databases. In R. v. d. M. J. Chomicki and
G. Saake, editors, In Logics for Emerging Applications
of Databases, 2013.

[12] P. Buneman, S. Khanna, and W. C. Tan. Why and

where: A characterization of data provenance. In
ICDT 2001, 2001.

[13] M. Calautti, M. Console, and A. Pieris. Counting
database repairs under primary keys revisited. In
ACM PODS 2019, page 104–118, New York, NY,
USA, 2019. Association for Computing Machinery.
[14] A. Cal`ı, D. Lembo, and R. Rosati. On the decidability

and complexity of query answering over inconsistent
and incomplete databases. In ACM PODS 2003, pages
260–271, 2003.

[15] L. Chengkai, C.-C. C. Kevin, and I. Ihab F.

Supporting ad-hoc ranking aggregates. In ACM
SIGMOD 2006, 2006.

[16] J. Chomicki, J. Marcinkowski, and S. Staworko.

Computing consistent query answers using conﬂict
hypergraphs. In CIKM 2004, pages 417–426, 2004.
[17] X. Chu, I. F. Ilyas, and P. Papotti. Discovering denial
constraints. PVLDB, 6(13):1498–1509, Aug. 2013.
[18] Y. Cui, J. Widom, and J. L. Wiener. Tracing the

lineage of view data in a warehousing environment.
ACM TODS, 25(2):179–227, 2000.

[19] J. L. D Dubois and H. Prade. Possibilistic logic. In

Handbook of Logic in Artiﬁcial Intelligence and Logic
Programming, pages 439–513. Oxford University Press.

[20] H. Decker and D. Martinenghi. Modeling, measuring

13

and monitoring the quality of information. In ER 2009
Workshops. ACM, 2009.

[21] D. Deutch, T. Milo, S. Roy, and V. Tannen. Circuits
for datalog provenance. In ICDT 2014, 03 2014.

[22] R. Fagin, A. Lotem, and M. Naor. Optimal

aggregation algorithms for middleware. In ACM
PODS 2001, page 102–113, New York, NY, USA,
2001. ACM.

[23] F. Geerts, F. Pijcke, and J. Wijsen. First-order

under-approximations of consistent query answers.
Int. J. Approx. Reasoning, 83(C):337–355, Apr. 2017.

[24] J. Grant and A. Hunter. Measuring inconsistency in

knowledgebases. Journal of Intelligent Information
Systems, 2005.

[25] T. J. Green. Containment of conjunctive queries on
annotated relations. In ICDT, pages 296–309. ACM,
2009.

[26] T. J. Green, G. Karvounarakis, and V. Tannen.

Provenance semirings. In ACM PODS 2007, pages
31–40. ACM, 2007.

[27] I. F. Ilyas, W. G. Aref, and A. K. Elmagarmid.

Supporting top-k join queries in relational databases.
The VLDB Journal, 13(3):207–221, Sept. 2004.
[28] I. F. Ilyas, G. Beskales, and M. A. Soliman. A survey
of top-k query processing techniques in relational
database systems. ACM Computing Surveys (CSUR).

[29] I. F. Ilyas and X. Chu. Data Cleaning. ACM, 2019.
[30] N. P. Karl Schnaitter. Evaluating rank joins with

optimal cost. In ACM PODS 2008, pages 43–52, 2008.

[31] N. P. Karl Schnaitter. Optimal algorithms for

evaluating rank joins in database systems. ACM
TODS, 2010.

[32] S. Kolahi and L. V. S. Lakshmanan. On

approximating optimum repairs for functional
dependency violations. In ICDT 2009, pages 53–62,
2009.

[33] J. Lang and P. Marquis. Reasoning under

inconsistency: A forgetting-based approach. Artif.
Intell., 174(12-13):799–823, 2010.

[34] E. Livshits and B. Kimelfeld. Counting and

enumerating (preferred) database repairs. In ACM
PODS 2017, page 289–301, New York, NY, USA,
2017. Association for Computing Machinery.
[35] E. L. Lozinskii. Information and evidence in logic

systems. Journal of Experimental and Theo- retical
Artiﬁcial Intelligence, pages 163–193.

[36] D. Maslowski and J. Wijsen. A dichotomy in the

complexity of counting database repairs. Journal of
Computer and System Sciences, 2013.

[37] J. Rammelaere and F. Geerts. Explaining repaired

data with cfds. PVLDB, 11(11):1387–1399, July 2018.

[38] T. Rekatsinas, X. Chu, I. F. Ilyas, and C. R´e.

Holoclean: Holistic data repairs with probabilistic
inference. PVLDB, 10(11):1190–1201, 2017.

[39] J. Wijsen. Database repairing using updates. ACM

TODS, 2005.

[40] D. Xin, J. Han, and K. C.-C. Chang. Progressive and
selective merge: computing top-k with ad-hoc ranking
functions. In ACM SIGMOD 2007, pages 103–114,
2007.

11. APPENDIX

Lemma 6. Let I, Q, DC be deﬁned as previously. ∀t ∈

Q(I) we have:
CBM (t, Q, I, DC) = CBS(t, Q, I, DC) = 0 ⇒ t is a CQA.
Proof. Given an instance I, a query Q and a set of
denial constraint DC. An answer t of Q over I such that
CBM (t, Q, I, DC) = CBS(t, Q, I, DC) = 0 is a CQA be-
cause all the tuples used to compute it do not involve in any
violation of constraints DC. So, trivially any king of answer
as t is CQA under any semantic of repair.

Lemma 7. A scoring function that associates to each tu-
ple t a score computed using CBM (respectively, using
CBS) is monotonic (respectively, non-monotonic) w.r.t. (cid:46)(cid:47).
Proof. Recall that in the context of bag semantics, the
scoring functions CBM and CBS are applied over mono-
mials. Let M1, . . . , Mm be monomials corresponding, re-
spectively, to the annotations of m base tuples t1, . . . , tm
in an N[Υ]-instance I Υ. Let t = t1 (cid:46)(cid:47) . . . (cid:46)(cid:47) tm be an
answer to the quey Q over I Υ. The annotation of t using
provenance polynomials semiring is given by the monomial
Q(I Υ)(t) = M1 × . . . × Mm. The monotonicity of CBM
is derived from the following property of the weight func-
tion W (i.e, the sum of powers of variables in a mono-
mial): W (Q(I Υ)(t)) = W (M1 × . . . × Mm) = W (M1) +
. . . + W (Mm). This makes W monotonic w.r.t. the product
(i.e., ×) which implies that CBM is monotonic w.r.t. (cid:46)(cid:47).
We show the non-monotonicity of CBS by counterexample.
Assume I Υ(t1) = C1C2, I Υ(t2) = C1C2C3, I Υ(t3) = C3C4
and I Υ(t4) = C1C2C3. So, Q(I Υ)(t(cid:48)) = C1C2C3C4 and
Q(I Υ)(t”) = C 2
3 . We have V ar(I Υ(t1)) = 2 ≤
V ar(I Υ(t2)) = 3 and V ar(I Υ(t3)) = 2 ≤ V ar(I Υ(t4)) = 3
but V ar(Q(I Υ)(t(cid:48))) = 4 > V ar(Q(I Υ)(t”)) = 3. We can
conclude that CBS is a non-monotonic function.

1 C 2

2 C 2

Lemma 8. Let α ∈ {CBM, CBS}. The algorithm Top-

INC computes correctly Qk,α(I).

Proof. The TopINC algorihtm proceeds one level at a
time. It starts from inconsistency degree 0 to upper incon-
sistency degrees. At each inconsistency degree d ﬁxed, it
looks for all the joins of buckets (from join relations) where
the union of their labels has cardinality d; the join is only
performed among the tuples within the buckets found. It
stops processing when k answers are found otherwise Top-
INC continues to look for the remaining joins of buckets for
the same inconsistency degree d; if there exists no other join
of buckets that leads to inconsistency degree d, the TopINC
moves forward to inconsistent degree d + 1. Hence, this pro-
cessing ensures that the K answers output by TopINC are
correct.

Lemma 9. Let Q(X) ← R1(X1), . . . , Rm(Xm) be a con-
junctive query, let s = |X| and let k be an integer. A query
Qk,α is evaluated by the TopINC in time O(nm) and in space
O(|I| + k × s).

Proof. This lemma is a consequence of the level-wise ap-
proach followed by TopINC which ensures that query answers
are computed in the ascending order of their inconsistency
degree. Hence, TopINC strictly computes the answers that
belong to the output (and the algorithm stops when k an-
swers are computed).

Lemma 10. Let Qk,α be a top-k query.

Then, we
have: ∀Al1 ∈ SBA, ∃Al2 ∈ SBA and an instance
I such that, cost(Al1, I, Q) > cost(Al2, I, Q).

Proof. W.l.o.g, assume that m = 2 (i.e., Q is a join
between two relations R1 and R2). Take two integers l >
1, p > 1 such that k ≤ l ∗ p. We build an instance I1 as
follows:

• The relation I1(R1) contains two subsets of tuples
l with
1, . . . , tp
p
j ), ∀i, j ∈ [1, p]. We take

(the l-tuples and the p-tuples): l tuples tl
πprov(tl
with πprov(tp
πprov(tp

j), ∀i, j ∈ [1, l] and p tuples tp

i ) = πprov(tp
1).

i) = πprov(tl

1) (cid:54)= πprov(tl

1, . . . , tl

• The relation I1(R2) contains two subsets of tuples
l with
1 , . . . , t(cid:48)p
p

(the l-tuples and the p-tuples): l tuples t(cid:48)l
πprov(tp
with πprov(tl

i )∀i ∈ [1, l] and p tuples t(cid:48)p

1) = πprov(t(cid:48)l

1) = πprov(t(cid:48)p

i ), ∀i ∈ [1, p].

1 , . . . , t(cid:48)l

they satisfy
The prov values are choosed such that
1)) <
the following condition:
min(α(πprov(tl
1) × πprov(tl
1)). Con-
sider an algorithm Al1 ∈ SBA with jP ath(Al1, Q, I) =
[J1, ..., Jn1 ]. We exhibit the following cases regarding the
ﬁrst test join J1:

1) × πprov(tp
1) × πprov(tp

α(πprov(tl
1), α(πprov(tp

• Case when J1 = tp

1 (cid:46)(cid:47) tl

1 (cid:46)(cid:47) tp

2 or J1 = tp

2 (i.e., Al1
starts reading a p-tuple from R1). We construct an in-
stance I2 such that I2 ≡prov I1 and all the answers of
Q over I2 are exactly those answers obtained by joining
l-tuples of I2(R1) with p-tuples from I2(R2), i.e., any
other join test between tuples of I2(R1) and tuples of
I2(R2) will evaluate to false. Clearly, Al1 is not optimal
to evaluate Qk,α over I2 because Al1 starts to process
join test that does not lead to any output answer as
a result of the fact that label(jP ath(Al1, Q, I2)[1]) =
label(J1) (since I2 ≡prov I1) and hence Al1 reads at
least one useless tuple (the p-tuple tp
1 which, by con-
truction of I2, do not contribute to any answer). It is
easy to see that a round robbin algorithm that alter-
nate reading l-tuples from R1 and p-tuples from R2 and
performing join tests between the tuples loaded in the
memory is optimal. Indeed, to maximize the generated
answers for a given cost s (i.e., reading s base tuples),
the best strategie is to read (cid:100)s/2(cid:101) base l-tuples from
R1 and (cid:98)s/2(cid:99) base p-tuples from R2 (or inversely)5,
which enables to compute the maximal number of
(cid:100)s/2(cid:101) × (cid:98)s/2(cid:99) answers. The behavior of such an al-
1, . . . , J (cid:48)
gorithm Al2 is given by jP ath(Al2, Q, I) = [J (cid:48)
k]
p,
p, J (cid:48)
with J (cid:48)
l (cid:46)(cid:47) t(cid:48)
3 = t1
2 = t2
2
J (cid:48)
l (cid:46)(cid:47) t(cid:48)
l (cid:46)(cid:47) t(cid:48)
4 = t2
2
1
Since, Al2 reads the minimal number of base tu-
ples to compute k answers from I2 and Al1 reads
at least one useless base tuple, we can conclude that
cost(Al1, I2, Q) > cost(Al2, I2, Q).

l (cid:46)(cid:47) t(cid:48)
1
p, J (cid:48)
5 = t3

l (cid:46)(cid:47) t(cid:48)
1
6 = t3

1 = t1
l (cid:46)(cid:47) t(cid:48)
2

p, J (cid:48)

p . . .

p, J (cid:48)

1 (cid:46)(cid:47) tl

• Case when J1 = tl

2 or J1 = tl

2 (i.e., Al1
starts reading an l tuple from R1). This case is the
dual of the ﬁrst one and can be proved following the
same reasoning while inverting the roles of p-tuples and
l-tuples when building I2 and Al2.

1 (cid:46)(cid:47) tP

5This is because the optimum of the function f (x) = sx−x2,
for a constant s, is given by x = s/2.

14

Theorem 2. For any instance I and any top-k con-
cost∇(TopINC, Q, I) ≤

junctive query Qk,α, we have:
cost∇(AL, Q, I), ∀AL ∈ SBA.

Proof. Let Qk,α, with α ∈ {CBM, CBS}, be a top-
k query over an instance I. Assume that there ex-
ists an algorithm AL ∈ SBA that outputs Qk,α(I) with
cost∇(AL, Q, I) < cost∇(TopINC, Q, I). The intuition be-
hind our proof is that if TopINC explores a region Z that is
not explored by AL then AL is not correct (i.e., it do not
correctly compute the top-k answers). Note that, when Top-
INC starts performing join tests with inconsistency degree
d, it fully explores the region (i.e., performs all the possible
join tests with inconsistency degree d) before moving to an-
other region. In addition, TopINC processes the regions se-
quencially in increasing order of their inconsistency degrees
(i.e, starting from region of inconsistency degree 0 to upper
degrees of inconsistency). Let Z be the region having the
biggest inconsistency degree, noted dz, among the regions
explored by AL. Two cases occur: (i) either AL has exhaus-
tively explored all the regions with inconsistency degree < dz
and in this case cost∇(AL, Q, I) ≥ cost∇(TopINC, Q, I) (be-
cause TopINC will also explore the same regions or a subset
of them), or (ii) AL skips some regions with inconsistency
degree < dz. In this case, one can prove that AL is incor-
rect. Indeed, since AL ∈ SBA, one can build an instance
I (cid:48) ≡prov I such that AL outputs incorrect answers when it
evaluates Qk,α over I (cid:48).

15

