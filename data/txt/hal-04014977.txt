Unsupervised Fine-grained Hate Speech Target
Community Detection and Characterisation on Social
Media
Anaïs Ollagnier, Elena Cabrio, Serena Villata

To cite this version:

Anaïs Ollagnier, Elena Cabrio, Serena Villata. Unsupervised Fine-grained Hate Speech Target Com-
munity Detection and Characterisation on Social Media. Social Network Analysis and Mining, 2023,
￿10.1007/s13278-023-01061-4￿. ￿hal-04014977￿

HAL Id: hal-04014977

https://hal.science/hal-04014977

Submitted on 5 Mar 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech
Target Community Detection and
Characterisation on Social Media

Ana¨ıs Ollagnier1*, Elena Cabrio1 and Serena Villata1

1*Universit´e Cˆote d’Azur, Inria, CNRS, I3S, Polytech’Nice-Sophia,
930 route des Colles, Sophia Antipolis, 06903, France.

*Corresponding author(s). E-mail(s): ollagnier@i3s.unice.fr;
Contributing authors: elena.cabrio@inria.fr;
serena.villata@inria.fr;

Abstract

Recent studies have highlighted the importance to reach a ﬁne-grained
online hate speech characterisation to better understand how hate is
conveyed, especially on social media. A key element in this scenario is
the identiﬁcation and characterisation of the hate speech target commu-
nity, e.g., national, ethnic, religious minorities. In this paper, we propose
a full pipeline relying on unsupervised methods to distinguish speciﬁc
hate speech manifestations, i.e., targeted (group of) victim(s) and the
protected characteristics (target-types) discriminated. Our contribution
is threefold: (1) we leverage multiple data views to contrast diﬀerent
abusive behaviours; (2) we explore the use of clustering techniques to
perform ﬁne-grained hate speech target community detection, and (3) we
address an in-depth content analysis of the generated hate speech target
communities. Relying on multiple data views derived from multilingual
pre-trained language models (i.e., multilingual BERT and multilingual
Universal Sentence Encoder) and the Multi-view Spectral Clustering
(MvSC) algorithm, the 69 experiments performed on the Multilingual
Hate Speech dataset (MLMA) of tweets show that most of the conﬁgura-
tions of the proposed pipeline signiﬁcantly outperforms state-of-the-art
clustering algorithms on French and English. Our experiments conﬁrm
the ability of the proposed approach to capture complex hate speech phe-
nomena (i.e., intersections between victim-groups, target-types or both).

1

Springer Nature 2021 LATEX template

2

Unsupervised Fine-grained Hate Speech Target Community Detection

Keywords: Fine-grained hate speech target detection, Community detection,
Multi-view clustering, Sentence embedding, Social media

1 Introduction

By empowering the freedom of expression and individual voices, social media
platforms such as Twitter and Facebook, and community forums have witnessed
an exponential growth, becoming an integral part of our daily lives. Whilst these
online spaces have facilitated the communication and exchange of ideas and
points of view, they have also opened the door to the proliferation of content
that can be degrading, abusive, or otherwise harmful to people. An important
and elusive form of such language is hateful speech, i.e., content that mocks
or discriminates against a person or group based on speciﬁc characteristics
such as colour, ethnicity, gender, sexual orientation, nationality, religion, or
other characteristics [1, 2]. Over the last decade, the preoccupation for the
use of electronic means of communication as a tool to convey hate, racist
and xenophobic contents tremendously increased [3], and a large number of
computational methods involving Natural Language Processing (NLP) and
Machine Learning (ML) have been proposed for automated online hate speech
detection, e.g., [4–6]. Most of the prior works have mainly considered the task as
a binary classiﬁcation problem seeking to distinguish hate and non-hate speech.
However, recent works have highlighted the importance to consider the diﬀerent
hate speech facets (e.g., nature of the target, hate directness, hostility type) in
order to better understand how hate is conveyed online [7–9]. On this purpose,
a high number of resources and benchmark corpora aiming at evaluating the
ability of automated methods to capture ﬁne-grained hate speech phenomena
(i.e., multi-level annotation accounting for diﬀerent hate speech facets) were
developed. The following examples extracted from the multilingual hate speech
dataset (MLMA) [10] illustrate a multi-level annotation scheme. Here, we
only detail the (group of) victim(s) targeted and the protected characteristics
discriminated (e.g., references to racial or sexist stereotypes).

1. ‘@user @user go back shithole country grab pussy’ – targets: immigrants,

protected characteristic: ethnic origin

2. ‘@user @user another disgusting lying feminazi.’ – targets: women, protected

characteristic: gender

3. ‘@url steve guy fucking retard.’ – targets: special needs, protected charac-

teristic: disability

Besides the eﬀorts made to develop methods enabling to distinguish ﬁne-
grained hate speech phenomena from each other, often only a speciﬁc facet is
dealt with [11]. However, hate speech is a complex and multi-faceted notion
relying on interconnected phenomena at stake. Despite existing works addressing
the task from an intersectional perspective [12], the issue of understanding the
multiple complex facets of hate speech phenomena is still an open challenge.

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

3

In addition, an important challenge when dealing with social media is to
provide robust solutions enabling to cope with the fast and often unpredictable
evolution of social media data. This evolution involves both the language
level (i.e., neologisms and slang words) or content (i.e., expression of opinions
in reaction to societal issues). However, most of existing approaches rely on
supervised algorithms which suﬀer from well-known limitations including the
lack of annotated data and the need to regularly update them in order to
account for such continuous evolution of this kind of content. Such ﬁndings
raise questioning about the ability of a such strategy to eﬃciently address alone
the task of hate speech detection.

To undertake these issues, the research objectives of this paper are the
following: (1) to encode harmful content to unveil key features aiming at
contrasting diﬀerent kinds of abusive behaviours; (2) to address the task of
ﬁne-grained hate speech target community detection adopting an unsupervised
technique; and (3) to assess the ability of the proposed pipeline to establish
partitioning reﬂecting complex hate speech phenomena.

To achieve these goals, we investigate the use of multiple data views (i.e.,
data structures) holding diﬀerent properties to obtain meaningful hate speech
representations. To do that, we exploit two well-known multilingual pre-trained
language models: mBERT (multilingual BERT) [13] and mUSE (multilingual
Universal Sentence Encoder) [14], from which syntactic, semantic and rela-
tionship information is derived. Then, the task of hate speech detection is
transposed into a clustering problem allowing to beneﬁt from unsupervised
approaches, which do not need annotated corpora to be trained. Leveraging
the last advances in clustering, we investigate the use of Multi-view Clustering
(MvC), especially the Multi-view Spectral Clustering (MvSC) algorithm, in
order to exploit complementary and consensual information across the multiple
data views of a diﬀerent nature (i.e., feature and graph spaces). To investi-
gate the ability of the proposed pipeline to address challenges in the ﬁeld (i.e.,
detecting ﬁne-grained hate speech phenomena), we conduct experiments on a
curated version of the French and the English of the MLMA dataset which
only includes hostile tweets. We assessed the performances focusing on the
target and group labels (hereinafter referred respectively to as target-type /
victim-groups). Partitioning is evaluated regarding whether aggregated hate
content correspond to existing hate speech target communities in the MLMA
dataset, i.e., clusters containing content with the same target-type / victim-
group labels. Conducted experiments show that the simultaneous clustering
of multiple data views improves the clustering performance when compared
to state-of-the-art clustering methods (k-means, k-medoids and spectral clus-
tering) based on a single feature set on both languages. Furthermore, we also
provide a study of the most frequent n-grams extracted from the generated
clusters. The goal is to observe the ability of the proposed pipeline to generate
semantic spaces reﬂecting hate speech manifestations used to oﬀend a speciﬁc
victim-group given a protected characteristic. In other words, we seek to iden-
tify whether the generated clusters may unveil an underlying structure of the

Springer Nature 2021 LATEX template

4

Unsupervised Fine-grained Hate Speech Target Community Detection

data similar to those provided by the MLMA multi-aspect hate speech analysis
or - on the contrary - it is enabled to uncover diﬀerent properties. From this
study, we analyse the properties resulting from the automatic identiﬁcation
of ﬁne-grained hate speech target communities with the purpose of providing
key informational insights aiming at improving the design of machine learning
tools dedicated to capture online hateful content.

In summary, the contributions of our paper are summarised as follows:
• Leveraging syntactic/semantic and relationship information to enrich hate

content representations;

• Exploring the use of clustering techniques as a mean to address the task of

ﬁne-grained hate speech detection;

• Assessing the ability of the proposed pipeline to address the task through an
in-depth content analysis of the generated hate speech target communities.

The paper is organised as follows: Section 2 discusses the related literature
on hate speech detection, on community detection in social media and on the
multi-view data clustering. Section 3 describes the multilingual hate speech
dataset used in this study. Section 4 presents the proposed clustering method
and discusses the methodological choices. The experimental procedure is
described in Section 5. Section 6 details the experimental setting and report
on the obtained results. Finally, Section 7 presents the study about the charac-
terisation of the diﬀerent types of hate speech used to target communities.
Conclusions end the paper, drawing directions for future work.

NOTE: This paper contains examples of language which may be oﬀensive

to some readers. They do not represent the views of the authors.

2 Related Work

The following sections provide a panorama of existing works aiming at auto-
matically identifying abusive behaviours. In particular, we focus on a review of
datasets and approaches developed to address this task.

2.1 Hate Speech Datasets.

From 2016 onward, a high number of resources and benchmark corpora for
many diﬀerent languages were developed. As hate speech is a complex and
multi-faceted notion, the scientiﬁc community tackles this issue by developing
various semantic frameworks aiming at identifying diﬀerent topical focus
such as speciﬁc targets (groups targeted), nuances of hate speech (abusive,
toxic, dangerous, oﬀensive or aggressive language) or rhetoric devices (slurs,
obscenity, oﬀences or sarcasm). Several surveys describe the current state of
the ﬁeld providing a structured overview of existing datasets [7, 11, 15]. Most
of available datasets come from Twitter and rely on a binary scheme: two
mutually-exclusive values to mark the presence or absence of hate speech such
as those introduced in [16], [17] and, [18]. Some datasets relies on multi-level

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

5

annotation, with ﬁner-grained schemes accounting for diﬀerent phenomena.
Recently, [19] adopt a three-layer binary annotation for hate speech, aggres-
siveness and nature of the target (individual or group), while [10] provides a
ﬁne-grained annotation of tweets about both victim-groups and target-types,
hate directness (whether the text is direct or indirect), hostility type and
annotator’s sentiment. With the purpose to facilitate access to information, the
platform hatespeechdata.com 1 catalogues datasets annotated for hate speech,
online abuse, and oﬀensive language aiming at training natural language
processing systems.

Several corpora have been developed with the purpose of organising open
shared tasks at NLP-related conferences including TRAC2 (Workshop on
Trolling, Aggression and Cyberbullying at LREC 2018 & 2020), EVALITA
2020 Tasks3 (automatic misogyny identiﬁcation & hate speech detection) and
SemEval 2019 Tasks 5 (HatEval [19], multilingual detection of hate speech
against immigrants and women in Twitter) & 6 (OﬀensEval [20], identifying
and categorising oﬀensive language in social media) at NAACL HLT 2019, as
well as Hate Speech and Oﬀensive Content Identiﬁcation in Indo-European
Languages (HASOC 2019 & 2020 4), among others.

2.2 Hate Speech Detection Methods.

Most of the prior works have mainly considered the task of hate speech
detection as a supervised document classiﬁcation problem. Following the
taxonomy introduced in [2], existing methods can be divided into two main
categories: classical ML methods and deep learning methods.
Classical ML methods require as input feature vectors derived from text
representation techniques. Text representation consists of converting textual
content into machine-readable format using a collection of meaningful features.
While this task has been widely investigated by the NLP community, it is still
an ongoing challenge as it involves addressing complex semantic phenomena
such as ﬁgurative language and idiosyncratic style. As a part of hate speech
detection models, this task is mainly addressed using two main text mining
encoding techniques: surface features and linguistic-based features. Word
and character n-grams are currently the prominent shallow lexical features,
and also the most successful ones [21, 22]. In [23], character 4-grams features
outperforms other surface feature representations in distinguish between
profanity and hate comments. Concerning linguistic-based features, Part of
Speech (PoS) tagging and dependency parsing obtain the best performances
by providing a deeper understanding of hateful content [21, 22, 24]. Features
derived from sentiment analysis, usually used as auxiliary features, are also
considered as powerful linguistic cues. The use of sentiment polarity or

1https://hatespeechdata.com/ Date of access: 2nd November 2021.
2https://sites.google.com/view/trac2/home Date of access: 2nd November 2021.
3http://www.evalita.it/ Date of access: 2nd November 2021.
4https://hasocﬁre.github.io/hasoc/2020/index.html Date of access: 24th February 2023.

Springer Nature 2021 LATEX template

6

Unsupervised Fine-grained Hate Speech Target Community Detection

emotion tone prove eﬀective in tasks on aggression identiﬁcation and threat
detection [25]. Recently, the use of clustering techniques, especially Brown
clustering, show promising results in representing positive and negative
sentiment data to enrich oﬀensive comment representations [26]. Once feature
vectors are generated given a text representation strategy, they are consumed
by supervised algorithms. Several surveys report the use of diﬀerent algorithms
including Support Vector Machines (SVM), Naive Bayes, Logistic Regression,
and Random Forest [2, 21, 24]. Among these, SVM is still one of the most
popular algorithms to address shared tasks on hate speech detection [27–29].

Deep learning based methods consists of applying neuronal networks to
automatically learn multi-layers of abstract features from raw data. Here, inputs
can be simply the raw text data, or take various forms of feature encoding,
including any of those used in the classic methods. Prior works based on
neuronal networks exploit the network structure either to design classiﬁcation
models or to build language models. In the context of hate speech classiﬁcation,
Convolutional Neural Network (CNN), Recurrent Neural Network (RNN) and,
Long Short-Term Memory network (LSTM) have shown to perform better than
classic ML methods [2]. Hybrid methods combining neuronal networks have also
been proposed and shown promising performances outperforming state-of-the-
art methods on a large collection of public hate speech datasets [4]. In parallel,
pre-trained word representations signiﬁcantly advanced the state of the art in
various NLP tasks including shared tasks on hate speech detection [30]. Besides
traditional neuronal network models, transformer-based language models like
Bidirectional Encoder Representations from Transformers (BERT) [13] achieve
also state-of-the-art performance. In the SemEval 2019 shared task: Oﬀens-
Eval [31], most of the top-ranked models relies on BERT models. Recent works
address the topic bias issue and introduced ﬁne-tuned Transformer neuronal
network architectures achieving state-of-the-art performance in the task of
abusive language detection in English [32, 33].

From the literature review, we highlight that the task of hate speech
detection is mainly considered as a supervised classiﬁcation problem. However,
dealing with social media content means to cope with dynamic data. Moreover,
recent studies report the proliferation of code words for communities aiming at
countering moderation tools [34], while [35] highlight the diﬃculties in tracking
all racial and minority insults due to the constant evolution of social phenomena
and language. Applying supervised methods raise concerns also about the
long-term robustness of such systems dealing with evolving social media data.
Unsupervised approaches are mainly used in the literature to obtain richer
text representations including deep learning to generate embeddings [36] or
LDA and Brown Clustering to provide auxiliary features [26, 37]. Concerning
this point, clustering techniques, especially community detection algorithms,
constitutes a key tool for the analysis of complex networks by enabling the
study of mesoscopic structures that are often associated with organisational
and functional characteristics of the underlying networks. In the context of

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

7

social media, the analysis of such networks presents valuable resources from
which it is possible to gain insights into the social phenomena and processes [38].
For instance, outcomes from analysing the community structure of networks
have led to a wide range of intelligent services and applications in the ﬁelds of
opinion mining [39], marketing activities [40] and data-driven decision making
[41], among others. Often addressed to reveal communities from user-to-user
interaction (e.g., mentions, follows), it has also been performed considering
only the textual content allowing to uncover cohesive groups or clusters based
on semantic knowledge [42]. Using clustering techniques allow to overcome
aforementioned limitations by providing a scalable, adaptive and robust solution
to deal with social data. As hate speech is a complex and multi-faceted notion,
we investigate the use of multi-view clustering to handle data views holding
diﬀerent properties to leverage richer data information. Introduced in [43], the
core idea behind Multi-view Clustering is to leverage eﬀectively the diversity and
the complementary of multi-view data to improve the clustering performance.
Typically, each of these data views provides a diﬀerent perspective of a given
set of entities. The term “multi-view clustering” refers to algorithms that
can utilise multiple feature spaces to describe distinct points of view of a
phenomenon [43, 44]. Recently, several important related surveys about MvC
have been published to summarise the theories, methodologies, taxonomies
and applications of the existing MvC approaches [45–47]. As a part of this
work, we rely on the MVSC-CEV (multi-view spectral clustering by common
eigenvectors) algorithm introduced in [48] which allows the use of an arbitrary
number of input views, possibly of a diﬀerent nature (feature or graph space)
and with diﬀerent dimensions. To the best of our knowledge, this is the ﬁrst
approach based on multi-view clustering applied to the problem of hate speech
detection.

3 The MLMA dataset and its extension

The multilingual hate speech dataset (MLMA) [10] provides a ﬁne-grained
annotation of 5.647 English tweets, 4.014 French tweets, and 3.353 Arabic
tweets. Five facets characterising hate speech are labelled, including the direct-
ness of the speech (directness), the hostility type (sentiment), the protected
characteristic discriminated (target-type), the group of victims (victim-group),
and the annotator’s sentiment (annotator sentiment).

In this paper, we focus on the French and the English portions of the
dataset and on the facets related to the target-type and victim-group labels.
More precisely, the target-type denotes whether the tweet insults or discrimi-
nates against people based on their origin, religious aﬃliation, gender, sexual
orientation, special needs or other. In total, 16 common victim-group have been
identiﬁed denoting whether the tweet is aimed at women, people of African
descent, Hispanics, gay people, Asians, Arabs, immigrants in general, refugees;
people of diﬀerent religious aﬃliations such as Hindu, Christian, Jewish peo-
ple, and Muslims; or diﬀerent political ideologies as socialists, and others. The

Springer Nature 2021 LATEX template

8

Unsupervised Fine-grained Hate Speech Target Community Detection

individual covers hate directed towards one individual, which cannot be gen-
eralised. Both target-type and victim-group referring to other correspond to
utterances which do not ﬁt with MLMA facets’ annotation guidelines. In the
dataset, 49 hate speech target communities are identiﬁed in French and 70 in
English (i.e., combining target-type victim-group labels).

Table 1: Distribution of hate speech target communities in the French and
English corpora.

FR

EN

Target

Group

no. of Tweets Group

no. of Tweets

origin

other

religion

sexOrient

disability

gender

Total

other
indian/hindu
africanDesc
arabs
individual
leftWing
asians
immigrants
specNeeds
-
-
-
individual
other
leftWing
immigrants
muslims
jews
-
-
-
-
specNeeds
individual
-
women
-
-
-

619
324
298
289
276
103
87
84
61
-
-
-
556
442
280
20
71
56
-
-
-
-
83
80
-
22
-
-
3.701

other
specNeeds
individual
women
refugees
immigrants
leftWing
hispanics
africanDesc
muslims
indian/hindu
asians
other
women
specNeeds
individual
-
-
other
gay
individual
specNeeds
specNeeds
other
women
women
other
specNeeds
-

814
378
301
162
128
123
101
96
81
75
67
61
507
145
120
55
-
-
133
111
98
67
944
58
55
474
55
50
5.209

A serious skewed distribution of the hate speech target communities is
observed in each corpus, with 69.3% of hate speech target communities in
French below the average imbalance ratio (i.e., the average proportion of the
number of instances in the majority community to the number of instances in
the minority ones) and 72.8% in English. Most of the studies on the behaviour
of machine learning applications have shown a signiﬁcant loss of performance
facing imbalanced datasets [49]. As one of the purposes of this study is to

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

9

Fig. 1: Distribution of the target-type facet in both French and English corpora.

evaluate the ability of the proposed pipeline to identify automatically ﬁne-
grained hate speech phenomena relying on the MLMA labels, the corpora
are ﬁltered to alleviate the bias towards the majority communities. Only
communities getting an imbalance ratio above 20 for the French corpus and 15
for the English one are considered in this study. In addition, as we focus on
hostile tweets conveying abusive or threatening speech only tweets labelled as
abusive, hateful, oﬀensive, disrespectful or fearful are considered. The resulting
datasets (hereinafter referred respectively to as the FR hate speech target
community corpus and the EN hate speech target community corpus) comprise
3.701 and 5.209 tweets divided respectively into 16 and 26 hate speech target
communities, as reported in Table 1.

From this Table, we can observe that English tweets tend to target people
with special needs and women over the diﬀerent target-type facets, while
French tweets are more oﬀensive towards the victim-group individual. Figure 1
illustrates the global distribution of target-types on both languages. From this
ﬁgure, we can observe a ﬂagrant diﬀerence between the protected characteristics
discriminated according to each language. In detail, tweets discriminating or
insulting against people based on their origin is the highest accounted target-
type. Concerning the other target-type facets, disparities are more important
according to the language. Whilst the target-type sexual orientation is among
one of the main protected characteristics discriminated in English (7.85% in
total considering the whole English tweets), in French it is pruned due to a
low number of samples. The same phenomenon is observed on the target-type
religion which is pruned in English while it represents 3.4% of the hateful
content in the French corpus. In English, disability is the second most frequent
target-type followed by other and gender. In French, the second most populate
target-type facet is other followed by disability and religion. Table 2 presents
a sample of hateful tweets with the corresponding annotations extracted from
the MLMA dataset.

0500100015002000originotherreligionsexOrientdisabilitygenderFR05001000150020002500ENSpringer Nature 2021 LATEX template

10

Unsupervised Fine-grained Hate Speech Target Community Detection

Table 2: Annotation examples in the MLMA dataset.

smh women r retarder @url

quel mongol ! jsuis sur c un rebeu

Target type: disability
Victim group: women

Target type: origin
Victim group: specNeeds
Translation: what a retard ! I’m sure it’s
a raghead

(a) English.

(b) French.

Fig. 2: Multi-view clustering workﬂow from Twitter data.

4 A Framework for Fine-grained Hate Speech

Target Community Detection

This section describes the proposed pipeline for the task of ﬁne-grained hate
speech target community detection. As visualised in Figure 2, it consists of
three main steps including the network construction, the data views extraction
and the target community detection.

4.1 Network Construction

Twitter data are noisy and unstructured, and include linguistic errors and
idiosyncratic style. Handling such content implies using adapted cleaning
processes to fully leverage data content and extract relevant information.
Several works have proposed speciﬁc preprocessing pipelines showing signiﬁcant
improvements in model performances [50, 51]. As a part of the proposed
work, we have implemented the benchmark preprocessing framework presented
in [6] aiming at dealing with heterogeneous hate speech datasets extracted
from various social media. In short, the applied cleaning process consists of
performing data normalisation including hashtags (i.e., split into single words),
emojis (i.e., replaced by their textual description), user mentions and URLs
(i.e., replaced by canonical forms: username and url), and next, tokenises and
lemmatises the textual content.

Twitter data contentNetwork constructionLanguage modeling-mBERT dim: 768-mUSE dim: 512Network projection-cosine similarityNetwork filtering-threshold: 0.80 Feature set [n x dim]Affinity matrix [n x n]Affinity matrix [n x n]Graph 1Graph 2Graph 3Community detectionData viewsextractionFusion graphSpringer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

11

Table 3: Description of the Pre-trained language models.

Name

Architecture

Training data

mBERT [13]

12-layer, 768-hidden, 12-heads

mUSE [14]

6-layer, 512-hidden, 8-heads

Trained on uncased texts in the top 102
languages with the largest Wikipedias.
Originally trained on mined question-
answer pairs, SNLI data, translated
SNLI data and parallel corpora over
16 languages. Here, we use the V2
extended to 50+ languages.

After data cleaning and normalisation, the step consists of encoding the hate
speech target community corpora to obtain node-like structures. As pre-trained
language models have become a popular method achieving state-of-the-art
results in a wide range of NLP tasks, especially as a part of feature con-
struction methods [52, 53], we decide to exploit two well-known multilingual
pre-trained language models to generate sentence vector-based features. From
empirical studies we conducted on the hate speech target community corpora,
mBERT (multilingual BERT) and mUSE (multilingual Universal Sentence
Encoder) achieved better performances. These two pre-trained language mod-
els - evaluated against XLM-RoBERTa and Quora distilbert multilingual on
the community detection task using k-means and spectral clustering with a
single feature set - are used to generate sentence embeddings for each tweet.
Table 3 provides a brief overview of both pre-trained models describing the
encoder architecture and the training dataset. In detail, mBERT relies on the
transformer model BERT [13] (Bidirectional Encoder Representations from
Transformers) and is pre-trained on a large corpus of multilingual data. More
precisely, it is pre-trained with two objectives: Masked Language Modelling
(MLM, 15% of tokens are masked and BERT is trained to predict them from
context) and Next Sentence Prediction (NSP, it is trained to predict if a chosen
next sentence was probable or not given the ﬁrst sentence). Concerning mUSE,
it relies on the USE [54] (Universal Sentence Encoder) architecture and is
originally pre-trained on Wikipedia, web news, web question-answer pages and
discussion forums and augmented with the Stanford Natural Language Infer-
ence (SNLI) corpus translated to 15 languages. From a multi-task dual-encoder
model, this transformer constructs sentence embeddings based on cross-lingual
representation learning that combines methods for multi-task learning of mono-
lingual sentence representations. Here, the pre-trained mBERT model used is
publicly available on HuggingFace5. In order to generate sentence embeddings,
we perform a mean pooling of the model outputs. Conversely, the mUSE model
used in this study, also released by HuggingFace6, allows to generate directly
sentence embeddings.

5https://huggingface.co/mBERT-base-multilingual-uncased Date of access: 5th October 2021.
6https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2 Date of

access: 5th October 2021.

Springer Nature 2021 LATEX template

12

Unsupervised Fine-grained Hate Speech Target Community Detection

Once the feature sets are built, the next step is the network construction,
which consists of reshaping the data into node-like structures. To identify tweet
pairs sharing key textual features, we use the cosine similarity measure. Widely
used to determine similarities between vectors [55], this similarity measure has
the advantage to allow comparisons between inputs with diﬀerent lengths.

Figure 3 shows samples of sentence similarity scores obtained from the corre-
sponding aﬃnity matrix of each pre-trained language model. As illustrated, the
inner representation of the languages learnt by each pre-trained model results
in aﬃnity matrices conveying diﬀerent sources of rich semantic information.
From the aﬃnity matrices, a network (graph) is generated in which individual
tweets are the nodes, and similar tweets are grouped together. As a result we
obtain a weighted and undirected graph G. Edges have positive weights, and
the graph topology is described by the aﬃnity matrix W , where the generic
element Wuv = Wvu > 0 if there is a weighted edge between nodes u and v,
while Wuv = Wvu = 0 otherwise. However, keeping the full information about
the network may be problematic. A network with a high edge density may be
intractable by traditional tools of network analysis. It may especially pose a
serious obstacle for graph clustering techniques [56]. To overcome this issue
and considering the weighted character of the edges in the proposed approach,
we perform information reduction using a simple weight thresholding method.
Weight thresholding removes all edges with weight lower than a threshold value.
This means that the resulting graph ˜G has a thresholded weight matrix ˜W ,
whose generic element ˜Wuv = ˜Wvu = Wuv if Wuv ≥ θ and ˜Wuv = ˜Wvu = 0
otherwise. The thresholded graph ˜G is therefore a subgraph of G with the same
number of nodes. Concerning the connectivity of this subgraph, as there are so
many ways to express hatred some users’ utterances obtain similarity scores
below the deﬁned threshold. However, these tweets constitute relevant informa-
tional segments which can allow to better capture how hate is spread online. In
addition, the lack of connectivity in a graph can impact its analysis leading to
decrease the quality of the partitioning. To bridge isolated nodes towards the
main connected components, we connect them to their closest neighbours (i.e.,
nodes getting the highest similarity scores). From empirical studies we con-
ducted on the hate speech target community corpora, the weight threshold used
throughout the paper is set to 0.8 when referring to the thresholded graphs.

4.2 Data views Construction

The MvSC algorithm maximises clustering quality considering the diversity
and complementary of diﬀerent data views. In this regard, one of the main
contributions of this work is to derive diﬀerent views holding speciﬁc properties
to unveil a more robust network partitioning. Here, data views of diﬀerent
nature are considered including feature sets (syntactic/semantic information)
and aﬃnity matrices (relationship information) resulting from the network
construction step. Data views used in this work are detailed below:

- Feature sets (syntactic/semantic information)

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

13

Fig. 3: Sentence similarity scores using embeddings from mBERT (left) and
mUSE (right).

– mBERT view (mBERT). This view refers to the sentence embedding repre-
sentations encoded using the pre-trained mBERT model. As a result, we
get feature sets of 5.209 data points in English and 3.701 in French with
an embedding size of 768.

– mUSE view (mUSE). This view consists of the sentence vector-based features
generated from the pre-trained mUSE model. Resulting feature sets are
composed of 5.209 data points in English and 3.701 in French with an
embedding size of 512.

- Aﬃnity matrices (relationship information)

– Projection view (mBERT-PRO & mUSE-PRO). These views consist of aﬃnity
matrices resulting from the cosine similarity computed respectively on the
mBERT view for mBERT-PRO and on the mUSE view for mUSE-PRO.

– Network view (mBERT-NET & mUSE-NET). These views refer to aﬃnity matri-
ces relying on the thresholded subgraphs (Section 4.1). The mBERT-NET
and mUSE-NET views are respectively built from the corresponding original
view, namely the mBERT view and the mUSE view.

While the feature sets capture relations, similarities and semantic relation-
ships between sentences, the graph spaces contain information about nodes
(i.e., tweets) connectedness (i.e., whether pairs of nodes are adjacent or not
in a graph and the nature of their connection). The deriving views obtained
from diﬀerent language models – relying on diﬀerent encoding strategies and
exhibiting diﬀerent properties – is beneﬁcial to accurately describe the textual
data we analyse. In the following section, we describe how these views are
consumed by the MvSC algorithm.

4.3 Community Detection

Relying on a MvSC algorithm, the ﬁnal module of the proposed pipeline aims
at identifying communities. In the proposed approach, target communities refer

Springer Nature 2021 LATEX template

14

Unsupervised Fine-grained Hate Speech Target Community Detection

to the diﬀerent hate speech targets introduced in Section 3. In order to unveil
mesoscopic structures among tweets related to the expected communities, this
step relies on the MVSC-CEV [48]. The main structural diﬀerence between
prevailing multi-view clustering methods and MVSC-CEV lies in the step
where the information from the multiple views is collapsed into a single view to
produce the ﬁnal clustering assignment. Roughly speaking, multi-view clustering
methods consider as input data views and obtain an aﬃnity matrix for each
view. Then, a projection of each aﬃnity matrix is computed into a space suitable
for clustering, to produce a consensus partition. As a part of the MVSC-CEV
algorithm, it clusters all views separately. Then, it takes the obtained clustering
assignments and loops back to the data projection step in order to improve the
projections with the clustering information previously obtained.

Formally, the algorithm considers as input a set of D data views V =
{V1, V2, . . . , VD} of the data with n samples each. For each data view VD ∈ V ,
a similarity matrix is computed using the Gaussian similarity function resulting
in a set of similarity matrices S = {S1, S2, . . . , SD}. In turn, for each SD ∈ S
its corresponding Laplacian matrix LD is generated, where LD ∈ L and L
corresponds to the set of computed Laplacian matrices. The set of Laplacian
matrices L is passed to the S-CPC algorithm [57] along with k desired number
of clusters in order to compute their common eigenvectors. As a result, a matrix
X is obtained, where the k largest eigenvectors of the Laplacian matrices
LD ∈ L are the ﬁrst eigenvectors x(i)
D . Finally, k-means
is applied to the matrix Y producing the partitioning of the input data samples
common to the D input views, where Y is the result of the normalisation of
the matrix X. Therefore, it is a co-training approach, since it uses the results
of one iteration to further improve the results of the ﬁnal clustering. Figure 4
presents a visualisation of the best partitioning (cf. Section 6) resulting from
the proposed pipeline applied to the FR hate speech target community corpus.
In this example, the consensus partition is obtained computing eigenvectors
common to the mUSE view and the following aﬃnity matrices: mBERT-PRO,
mUSE-PRO and mUSE-NET. As a result, we obtain a graph composed of 3.701
nodes and 16.945 edges. Each colour refers to one of the 16 ground-truth
(labels already used in the MLMA dataset) ﬁne-grained hate speech target
communities of the French corpus.

1 of each submatrix L(i)

5 Experimental setting

In this section, we ﬁrstly describe the reference methods evaluated in this study,
and secondly, we introduce the evaluation metrics used to assess the quality of
the clustering produced by each method. Finally, we detail the procedure of
hypothesis testing used to perform signiﬁcance tests.

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

15

Fig. 4: Hate speech target community network relying on a 2-views conﬁgura-
tion (the mBERT view and the mUSE view). The network is obtained from the
FR hate speech target community corpus and it is composed of 16 node com-
munities. Each node colouring corresponds to an hate speech target community.
Individual nodes represent the tweets and are linked to each other considering
their semantic similarity.

5.1 Reference methods

To evaluate the advantages of mixing multiple data views, we compare the
MvSC clustering algorithm against three well-known clustering techniques: k-
means [58], k-medoids [59] and spectral clustering [60]. All these state-of-the
art clustering techniques are based on the Scikit-learn implementation. As k-
means only allows feature sets as input, here k-medoids is used to evaluate the
performances of the proposed single-view conﬁgurations relying on similarity
matrices. Conversely, the spectral clustering algorithm allows inputs of a
diﬀerent nature (feature or graph space). Both k-means and k-medoids use
default parameters. Concerning spectral clustering, the aﬃnity parameter for
the feature spaces is set to ‘nearest neighbors’ (construct the aﬃnity matrix by
computing a graph of nearest neighbours) and for the similarity matrices it is
set to ‘precomputed nearest neighbors’ (interpret precomputed distances and
construct a binary aﬃnity matrix from the n neighbors nearest neighbours of
each instance). As all the clustering methods analysed and compared require
to deﬁne a number of desired clusters, the number deﬁned for the French and

Springer Nature 2021 LATEX template

16

Unsupervised Fine-grained Hate Speech Target Community Detection

the English datasets is respectively 16 and 26 clusters, numbers corresponding
to their ground-truth hate speech target communities.

5.2 Performance assessment

Following the methodology described in [61], the quality of the clustering
methods is evaluated using clustering purity, clustering Adjusted Rand Index
(ARI) and the Normalised Mutual Information (NMI) metric. Brieﬂy, purity is
the ratio of the summation of how many maximum points of each algorithmic
cluster c ∈ k match with a considered gold set cluster g ∈ t and the total
number of points in data, such as:

purity(ck, gt) =

(cid:80)k

i=1 maxt
j=1(ci ∩ gj)
N

(1)

the higher the purity the better the clustering outcome is. The maximum purity
value is 1.0. The Rand Index calculates a similarity between two clusterings
(i.e, sets of clusters), by looking at each peer of individuals and counting those
that are or are not in the same cluster, depending on whether you are in actual
or predicted clustering:

RI = (a + b)/(nC2)

(2)

where a is the number of times a pair of elements belongs to the same cluster
across two clustering methods, b is for those that belong to diﬀerence clusters
across two clustering methods, and nC2 is the number of unordered pairs in a
set of n elements. As such, the RI does not guarantee that random assignment
will produce a value close to 0. This is why this raw index is ‘adjusted to
account for chance’, which gives the ARI score:

ARI =

RI − Expected RI
max(RI) − Expected RI

(3)

The ARI, which is symmetrical, measures the similarity and the consensus
of two assignments, ignoring permutations and normalising against what would
have happened by chance. The NMI, built on the Shannon entropy of informa-
tion theory, tries to quantify the amount of shared information between two
clusterings C and T . Formally:

M I(C, T ) =

r
(cid:88)

k
(cid:88)

i=1

j=1

pij log

(cid:18) pij

(cid:19)

pCi · pTj

(4)

It measures the dependence between the observed joint probability pij of C
and T , and the expected joint probability pCi · pTj under the independence
assumption. When C and T are independent then pij = pCi · pTj , and thus
M I(C, T ) = 0. In other words, M I(C, T ) can be thought of as the informational

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

17

‘overlap’ between C and T , or how much we learn about C from knowing T
(and about T from knowing C). In order to normalise the M I value, the NMI
of C and T is deﬁned as follows:

(cid:115)

N M I(C, T ) =

M I(C, T )
H(C)

·

M I(C, T )
H(T )

=

M I(C, T )
(cid:112)H(C) · H(T )

(5)

where H(.) corresponds to the computation of the Shannon entropy. All these
indices lie in the range [0, 1], and values tending towards unity indicate a perfect
correlation between the partitions. In our experiments we use the Scikit-learn
implementation of the ARI and NMI while the purity is implemented following
the instructions reported in [61].

5.3 Statistical tests

For all the analysed and compared stochastic clustering methods in this study,
a total of 31 independent executions for each dataset were performed. For each
clustering method and evaluation metric, we carried out statistical tests from
all the executions to determine the signiﬁcance of the reported performances.
To deﬁne the appropriate procedure of hypothesis testing, we checked the
normality assumption using the Shapiro-Wilk test [62] and the homogeneity of
variance through the Levene’s test [63]. As a result, and for both assumptions,
we rejected the null hypotheses indicating that the residuals are not normally
distributed and that their variability is statistically insigniﬁcant. Therefore, we
use the Wilcoxon signed ranks test [64] to compare every pair of approaches
on each dataset and across all datasets. Furthermore, we use the Friedman
test [65] to compare multiple clustering methods on each dataset or across all
datasets. In the case where the latter test reveals signiﬁcant diﬀerences between
the results, a post hoc Nemenyi test [66] is performed to establish a hierarchy
between the approaches. In all tests, we assume the signiﬁcance level α = 0.05.
From these tests, we expect to assess evidences concerning the plausibility of
the following hypotheses:

1. Question: Considering each evaluation metric individually, are the perfor-

mances observed on each model equal?
• Null Hypothesis (H0) — Models achieve similar performances.
• Alternative Hypothesis (HA) — Some models perform better considering

the evaluation metrics.

2. Question: Considering all evaluation metrics, are there models they do

globally perform better?
• Null Hypothesis (H0) — Proposed models achieve similar performances

considering all the evaluation metrics.

• Alternative Hypothesis (HA) — Some models provide global better

performances.

Springer Nature 2021 LATEX template

18

Unsupervised Fine-grained Hate Speech Target Community Detection

Both hypotheses are claimed on each dataset and also across all the datasets.
Outcomes of these hypotheses allow to observe whether the combination of
certain methods and view conﬁgurations perform better depending on the
language and the tested evaluation metrics, or not.

6 Results

This section investigates the ability of the MVSC-CEV algorithm to generate
high-quality clustering solutions on both the FR hate speech target commu-
nity corpus and the EN hate speech target community corpus by varying the
combination of the data views introduced in Section 4.2. Experiments were
conducted on an Intel i7-4600U CPU @ 2.10 GHz with 32GB of RAM, using
single-threaded processes. Table 4 summarises the results achieved by the two
baseline clustering techniques and the top-3 models relying on MVSC-CEV. In
total 69 experiments were conducted, all the results are reported in Appendix A
Table A1.

English/French corpus performance – Concerning the English corpus, most
of the conﬁgurations relying on the MVSC-CEV algorithm outperforms the base-
line clustering techniques, except the {mBERT/mUSE/mUSE-PRO} conﬁguration
w.r.t. the ARI score. Concerning each evaluation metric, the post hoc Nemenyi
test, allowing to evaluate the consistency of the ranking of each model through-
out all the iterations, ranks the {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}
and {mBERT-PRO/mUSE-PRO/mBERT-NET} conﬁgurations respectively at the
ﬁrst and the second position. Considering all the metrics, the post
hoc Nemenyi test establishes that {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}
outperforms other models followed by {mBERT-PRO/mUSE-PRO/mBERT-NET}
and {mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}. In French, the major-
ity of the data view conﬁgurations combined to the MVSC-CEV algo-
rithm achieves good performances as well as the baseline clustering
techniques relying on the feature set and the projection aﬃnity matrix
derived from mUSE. The post hoc Nemenyi
test allows to establish
that {mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET} outperforms the other mod-
els w.r.t. the purity score, {mBERT-PRO/mUSE-PRO} regarding the ARI score
and {SC view mUSE} w.r.t. the NMI score. Considering all the metrics,
the post hoc Nemenyi test establishes that {mUSE/mBERT-PRO/mUSE-PRO}
outperforms the other models followed by {mBERT-PRO/mUSE-PRO} and
{mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}.

Overall evaluation – Table 5 shows the top-5 models obtained from the
post hoc Nemenyi test performed on each evaluation metric considering both
corpora. The latter test allows to reject the null hypothesis formulated in
Question 1 (cf. Section 5.3). Indeed, the resulting hierarchy conﬁrms that
some models achieve better performances regarding the tested evaluation met-
rics. In detail, {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} outperforms the other
methods on both the purity score and the NMI score. This ﬁnding highlights

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

19

d
e
t
r
o
p
e
r

e
r
a

s
n
u
r

t
n
e
d
n
e
p
e
d
n

i

1
3
m
o
r
f

n
o
i
t
a
i
v
e
d

d
r
a
d
n
a
t
s

d
n
a

n
a
e
m
e
h
T

.
I

M
N
d
n
a

I

R
A

,
y
t
i
r
u
p

.
t
.
r
.
w
s
t
l
u
s
e
r

d
e
l
i
a
t
e
D

:

4

e
l
b
a
T

e
h
t

e
l
i
h
w

d
l
o
b

n
i

e
r
a

c
i
r
t
e
m
h
c
a
e

r
o
f

d
e
t
r
o
p
e
r

s
e
u
l
a
v

t
s
e
b

e
h
t

t
s
e
t

i
y
n
e
m
e
N

c
o
h

t
s
o
p

e
h
t

o
t

g
n

i

d
r
o
c
c
A

.
e
g
a
u
g
n
a
l

h
c
a
e

r
o
f

.
e
g
a
u
g
n
a
l

h
c
a
e

r
o
f

s
c
i
r
t
e
m
e
h
t

l
l
a

g
n

i
r
e
d

i
s
n
o
c

s
l
e
d
o
m

t
s
e
b

e
h
t

o
t

r
e
f
e
r

s
w
o
r

d
e
t
h
g
i
l
h
g
i
h

I

M
N

3
0
0
.
0
±
1
2
1
.
0

9
0
0
.
0
±
3
1
1
.
0

7
0
0
.
0
±
6
2
0
.
0

3
0
0
.
0
±
9
2
2
.
0

3
1
0
.
0
±
7
9
1
.
0

9
0
0
.
0
±
2
3
0
.
0

0
0
0
.
0
±
8
7
1
.
0

1
0
0
.
0
±
2
8
1
.
0

0
0
0
.
0
±
8
1
1
.
0

0
0
0
.
0
±
7
3
2
.
0

3
0
0
.
0
±
1
3
2
.
0

0
0
0
.
0
±
6
6
1
.
0

I

M
N

2
0
0
.
0
±
7
2
2
.
0

2
0
0
.
0
±
7
2
2
.
0

2
0
0
.
0
±
2
2
2
.
0

2
0
0
.
0
±
7
2
2
.
0

3
0
0
.
0
±
6
1
2
.
0

1
0
0
.
0
±
1
3
2
.
0

2
0
0
.
0
±
8
0
2
.
0

2
0
0
.
0
±
1
2
2
.
0

R
F

I

R
A

3
0
0
.
0
±
9
3
0
.
0

7
0
0
.
0
±
0
4
0
.
0

0
0
0
.
0
±
0
0
0
.
0

7
0
0
.
0
±
3
9
0
.
0

1
1
0
.
0
±
1
9
0
.
0

1
0
0
.
0
±
0
0
0
.
0

0
0
0
.
0
±
1
7
0
.
0

1
0
0
.
0
±
5
6
0
.
0

0
0
0
.
0
±
1
1
0
.
0

0
0
0
.
0
±
1
0
1
.
0

1
0
0
.
0
±
3
0
1
.
0

0
0
0
.
0
±
1
3
0
.
0

I

R
A

4
0
0
.
0
±
7
0
1
.
0

1
0
0
.
0
±
0
1
1
.
0

4
0
0
.
0
±
4
0
1
.
0

3
0
0
.
0
±
9
0
1
.
0

1
0
0
.
0
±
8
8
0
.
0

5
0
0
.
0
±
9
9
0
.
0

1
0
0
.
0
±
8
8
0
.
0

3
0
0
.
0
±
3
9
0
.
0

g
n
i
r
e
t
s
u
l
c

l
a
r
t
c
e
p
S
&
s
n
a
e
M
K

-

y
t
i
r
u
P

I

M
N

3
0
0
.
0
±
8
5
2
.
0

0
1
0
.
0
±
4
5
2
.
0

5
0
0
.
0
±
7
7
1
.
0

4
0
0
.
0
±
8
4
3
.
0

4
1
0
.
0
±
4
2
3
.
0

7
0
0
.
0
±
3
8
1
.
0

0
0
0
.
0
±
6
0
3
.
0

1
0
0
.
0
±
0
0
3
.
0

0
0
0
.
0
±
7
3
2
.
0

0
0
0
.
0
±
9
3
3
.
0

2
0
0
.
0
±
2
4
3
.
0

0
0
0
.
0
±
1
9
2
.
0

y
t
i
r
u
P

2
0
0
.
0
±
0
6
3
.
0

2
0
0
.
0
±
2
6
3
.
0

1
0
0
.
0
±
2
6
3
.
0

3
0
0
.
0
±
4
6
3
.
0

5
0
0
.
0
±
3
4
3
.
0

1
0
0
.
0
±
7
6
3
.
0

3
0
0
.
0
±
3
4
3
.
0

3
0
0
.
0
±
0
5
3
.
0

C
S
V
M

8
0
0
.
0
±
8
2
1
.
0

8
0
0
.
0
±
9
3
1
.
0

1
1
0
.
0
±
5
4
0
.
0

4
0
0
.
0
±
9
5
2
.
0

1
1
0
.
0
±
8
1
2
.
0

9
0
0
.
0
±
3
3
0
.
0

4
0
0
.
0
±
4
3
2
.
0

0
0
0
.
0
±
8
3
2
.
0

0
0
0
.
0
±
1
5
1
.
0

0
0
0
.
0
±
2
4
2
.
0

0
0
0
.
0
±
4
3
2
.
0

0
0
0
.
0
±
1
3
1
.
0

I

M
N

3
0
0
.
0
±
3
6
2
.
0

2
0
0
.
0
±
7
6
2
.
0

2
0
0
.
0
±
7
4
2
.
0

3
0
0
.
0
±
8
6
2
.
0

3
0
0
.
0
±
3
7
2
.
0

1
0
0
.
0
±
6
7
2
.
0

4
0
0
.
0
±
0
7
2
.
0

2
0
0
.
0
±
1
7
2
.
0

N
E

I

R
A

5
0
0
.
0
±
3
5
0
.
0

7
0
0
.
0
±
5
4
0
.
0

4
0
0
.
0
±
2
0
0
.
0

6
0
0
.
0
±
6
9
0
.
0

0
1
0
.
0
±
8
8
0
.
0

2
0
0
.
0
±
1
0
0
.
0

9
0
0
.
0
±
6
0
1
.
0

0
0
0
.
0
±
4
9
0
.
0

0
0
0
.
0
±
3
1
0
.
0

1
0
0
.
0
±
0
9
0
.
0

0
0
0
.
0
±
1
0
1
.
0

0
0
0
.
0
±
4
0
0
.
0

I

R
A

3
0
0
.
0
±
8
9
0
.
0

3
0
0
.
0
±
1
0
1
.
0

4
0
0
.
0
±
5
8
0
.
0

4
0
0
.
0
±
1
0
1
.
0

5
0
0
.
0
±
8
0
1
.
0

5
0
0
.
0
±
8
0
1
.
0

6
0
0
.
0
±
6
0
1
.
0

5
0
0
.
0
±
5
0
1
.
0

y
t
i
r
u
P

6
0
0
.
0
±
6
8
2
.
0

7
0
0
.
0
±
9
9
2
.
0

4
0
0
.
0
±
1
9
1
.
0

7
0
0
.
0
±
2
7
3
.
0

2
1
0
.
0
±
6
3
3
.
0

3
0
0
.
0
±
7
8
1
.
0

3
0
0
.
0
±
2
5
3
.
0

0
0
0
.
0
±
7
4
3
.
0

0
0
0
.
0
±
1
5
2
.
0

0
0
0
.
0
±
4
4
3
.
0

0
0
0
.
0
±
5
4
3
.
0

0
0
0
.
0
±
2
3
2
.
0

y
t
i
r
u
P

3
0
0
.
0
±
2
8
3
.
0

2
0
0
.
0
±
5
8
3
.
0

2
0
0
.
0
±
0
6
3
.
0

3
0
0
.
0
±
4
8
3
.
0

4
0
0
.
0
±
1
9
3
.
0

2
0
0
.
0
±
0
9
3
.
0

4
0
0
.
0
±
3
8
3
.
0

3
0
0
.
0
±
0
8
3
.
0

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
O
R
P
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

.
s
g
ﬁ
n
o
c

w
e
i
v
-
e
l
g
n
i
S

}
O
R
P
-
T
R
E
B
m

}
T
E
N
-
T
R
E
B
m

}
O
R
P
-
E
S
U
m

}
T
E
N
-
E
S
U
m

}
E
S
U
m

}
T
R
E
B
m

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

}
O
R
P
-
T
R
E
B
m

}
T
E
N
-
T
R
E
B
m

}
O
R
P
-
E
S
U
m

}
T
E
N
-
E
S
U
m

}
E
S
U
m

}
T
R
E
B
m

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

M
K
{

M
K
{

M
K
{

M
K
{

M
K
{

M
K
{

C
S
{

C
S
{

C
S
{

C
S
{

C
S
{

C
S
{

.
s
g
ﬁ
n
o
c

w
e
i
v

-
i
t
l
u
M

Springer Nature 2021 LATEX template

20

Unsupervised Fine-grained Hate Speech Target Community Detection

h
t
o
b

g
n
i
r
e
d
i
s
n
o
c

c
i
r
t
e
m
n
o
i
t
a
u

l
a
v
e

h
c
a
e

n
o

d
e
m
r
o
f
r
e
p

t
s
e
t

i
y
n
e
m
e
N
c
o
h

t
s
o
p

e
h
t

m
o
r
f

g
n
i
t
l
u
s
e
r

g
n
i
k
n
a
r

e
g
a
r
e
v
a

’
s
l
e
d
o
M

:

5

.
g
i
F

.
a
r
o
p
r
o
c

1234567891011121314151617181920{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}{mUSE/mBERT-PRO/mUSE-PRO}{mBERT-PRO/mUSE-PRO}{mUSE/mBERT-PRO}{mBERT-PRO/mUSE-PRO/mBERT-NET}{mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{KM view mUSE}{mBERT/mUSE/mUSE-PRO}{SC view mUSE-PRO}{SC view mUSE}{SC view mBERT}{KM view mUSE-PRO}{SC view mBERT-PRO}{KM view mBERT}{KM view mBERT-PRO}{SC view mUSE-NET}{SC view mBERT-NET}{KM view mBERT-NET}{KM view mUSE-NET}CDSpringer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

21

Table 5: Top-5 models w.r.t. the post hoc Nemenyi test performed on each
evaluation metric considering both corpora. Figure A1 in Appendix A details
the whole hierarchies obtained for each metric.

Rank

1
2
3
4
5

Evaluation Metrics

Purity

ARI

NMI

{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {mBERT-PRO/mUSE-PRO}
{mBERT-PRO/mUSE-PRO}
{mUSE/mBERT-PRO/mUSE-PRO}
{mUSE/mBERT-PRO}
{mBERT-PRO/mUSE-PRO/mBERT-NET}

{mUSE/mBERT-PRO/mUSE-PRO}
{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} {SC view mUSE}
{SC view mUSE-PRO}
{mUSE/mBERT-PRO}

{mBERT-PRO/mUSE-PRO}
{KM view mUSE}

{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}
{mUSE/mBERT-PRO/mUSE-PRO}

the ability of this conﬁguration to generate homogeneous clusters (i.e. each
cluster gathers tweets belonging for the most part to the same ground-truth
community) and to maximise mutual information (i.e. uncertainties of depen-
dencies between clusters and labels is decreased). Concerning the ARI score,
{mBERT-PRO/mUSE-PRO} achieves the best performances providing the most sim-
ilar partitioning in comparison to the ground-truth communities considering the
frequency of occurrence of agreements over the total pairs. In short, most of the
top-ranked models rely on the MVSC-CEV algorithm except the fourth-ranked
model of the ARI score and both the third and the ﬁfth-ranked models of the
NMI. Figure 5 allows to visualise the hierarchy among the models according to
post hoc Nemenyi test performed on each evaluation metric considering both
corpora. From the latter test we can reject the null hypothesis formulated in
Question 2 (cf. Section 5.3). Indeed, {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}
outperforms all the other models reaching the best balance considering all
the evaluation metrics on both languages. {mUSE/mBERT-PRO/mUSE-PRO} and
{mBERT-PRO/mUSE-PRO} are respectively ranked at the second and the third
position. From these ﬁndings, we can conﬁrm that using data views of a diﬀer-
ent nature is beneﬁcial in this context to improve the clustering performance
considering all the tested aspects. Additionally, we can also observe that encap-
sulating the complementary information of diﬀerent language representations
unveil relevant data properties improving partitioning. Moreover, the consis-
tency of the occurrence of aﬃnity matrices in top-ranked models, especially the
ones derived from the network projection, allows to establish that these aﬃnity
matrices exhibit relevant properties describing accurately data connections.
Furthermore, the majority of the conﬁgurations relying on data views based on
mUSE achieves better performances considering both the baseline clustering
methods and the MVSC-CEV algorithm.

To sum up, the majority of the models relying on the MVSC-CEV algorithm
achieves the best results on both languages and tested evaluation metrics. We
can observe a consistency of the performances on each metric highlighting the
portability of the proposed pipeline across other languages. In addition, the
purity and the NMI score achieve the highest results witnessing the ability
of this pipeline to also generate homogeneous clusters and to decrease the
uncertainty among clusters. Considering results reported in Appendix A, we
can notice that aﬃnity matrices (relationship information) derived from the

Springer Nature 2021 LATEX template

22

Unsupervised Fine-grained Hate Speech Target Community Detection

network projection appear to be a rich source of information as they are
a part of most of the top-ranked models. In addition, despite the fact that
{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} provides the best balance considering
both languages and metrics, performances vary throughout the conﬁgurations.
For instance, to get the best ARI {mBERT-PRO/mUSE-PRO} has to be preferred
in French and {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} in English.

7 Hate speech target community

Characterisation

the

best

each

explore

identiﬁed

balance model

In this section, we explore the partitioning resulting from the proposed pipeline.
Our goal here is not to perform an error analysis as in standard supervised
approaches, but more to identify whether the properties emerging from the
generated clusters correspond to the facets used in the MLMA multi-aspect
hate speech analysis, i.e., our gold-standard corpus.
language, we

For
resulting
namely
from the
{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}. The methodology consists of observ-
ing the ground-truth communities’ behaviours within the generated clusters
in terms of scatteredness and equivocality. To disambiguate, in this study
scatteredness refers to the level of dispersion of the communities and equivocal-
ity attempts to qualify the ability of each community to federate their own
cluster(s). From these two aspects, we investigate the ability of victim-group
and target-type to provide salient properties allowing to generate fully-ﬂedged
communities corresponding to the MLMA labels. To establish these two
aspects, we consider the most frequent ground-truth hate speech target
community label within each cluster as the cluster-head. Next, the content of
each cluster is analysed using n-gram co-occurrence statistics.

partitioning
Section

in

6,

Figure 6 describes the behaviours of the communities observed in the
partitioning obtained from the EN hate speech target community corpus. Con-
sidering the equivocality, 7 ground-truth communities federate their own
cluster(s). Among them 4 are the heads of one cluster including other other, sex-
ual orientation other, origin refugees and sexual orientation individual while
the others are the heads of multiple clusters. origin other reaches the high-
est number of clusters by being the head of 10 diﬀerent clusters representing
38.4% of the total number of clusters. The second and the third communities
obtaining the highest degree of equivocality are disability special needs and
gender women representing respectively 30.7% and 15.3% of clusters’ heads.
Considering the scatteredness, we can observe that some communities being
cluster-heads are also assimilated to other clusters. For instance, other other
and origin refugees are above 70% of scatteredness. Entries composing both of
these two clusters occur frequently in clusters having origin other and disabil-
ity special needs as head. From the mixing of these ground-truth communities,
new communities emerge characterising how the hate is expressed towards a
victim-group or the diﬀerent ways of linguistically discriminate a target-type or

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

23

Fig. 6: Scatteredness and equivocality of the ground-truth communities in the
EN hate speech target community corpus.

both. For instance, clusters mixing entries from the ground-truth communities
origin refugees and origin other gather tweets using terms such as ‘go back
country’ or ‘shithole countries’. These segments are frequently associated with
the victim-group refugees but their usage is also extended to discriminate and
insult more globally people based on their origin. From the generated commu-
nities mixing other other and origin other salient patterns emerge combining
vocabularies used to oﬀend people based on their origin or political views such as
‘radical leftist’, ‘leftist terrorist’ or ‘conspiracy terrorist’. In parallel, 19 ground-
truth communities are fully assimilated into the generated clusters regarding
various degrees of scatteredness. Among them, origin women reaches 100% of
scatteredness showing that tweets composing this ground-truth community
are also scattered throughout all the clusters. Entries from this ground-truth
community occur frequently within clusters being federated by the commu-
nity gender women. Studying these combinations highlighted salient properties
(identiﬁed as a part of two diﬀerent clusters) characterising hate speech expresses
towards women such as ‘fucking cunt’ and ‘little cunt’ in the ﬁrst cluster and
‘absolute twat’ and ‘fucking twat’ in the second one. other special needs, ori-
gin special needs and origin individual are highly dispersed with a degree of
scatteredness above 70%. Considering both of these aspects, we can observe that
the cluster-head sexual orientation individual is the less equivocal and scat-
tered ground-truth community. Indeed, this community assimilates only entries
belonging to its community or from gender women and disability special needs.
Combined to gender women the cluster having sexual orientation individual as
head highlights properties related to the women group and hate speeches based
on the vocabulary used to discriminate or insult people based on their sexual
orientation including ‘faggot bitch’ and ‘suck dick’. origin african descent and

0510152025303540equivocality (%)2030405060708090100scatteredness (%)other_special_needsgender_womenother_othersexual_orientation_gayorigin_otherdisability_special_needsgender_otherorigin_immigrantsorigin_womensexual_orientation_special_needsorigin_hispanicsdisability_otherorigin_special_needssexual_orientation_otherorigin_refugeesother_individualorigin_indian/hinduorigin_asiansorigin_muslimsorigin_african_descentgender_special_needsorigin_individualorigin_left_wing_peopleother_womensexual_orientation_individualdisability_womenSpringer Nature 2021 LATEX template

24

Unsupervised Fine-grained Hate Speech Target Community Detection

origin asians are the ground-truth communities obtaining the lowest degrees
of scatteredness with respectively 23.0% and 26.9%. Both of them occur only
in the clusters having origin other and disability special needs as head. From
the generated clusters assimilating the ground-truth community origin asians,
diﬀerent oﬀensive speeches emerge based on slurs such as ‘screeches high’ and
‘ching chang’ when combined to origin other and ’proceeds squint’ and ‘ching
chong’ when mixed to disability special needs’ entries. Figure 7 allows to better
visualise the mixing of communities’ semantic spaces within the generated clus-
ters. As previously reported, we can observe that both vocabularies related to
the target disability and the group specNeeds are used in oﬀensive comments
targeting women. Other prominent mixing can be noticed including the com-
munity disability special needs whose the vocabulary is based on common slurs
and demeaning expressions widely used to discriminate and insult the other
communities.

Fig. 7: Visualisation of the mixing of the communities within the generated
clusters for the EN hate speech target community corpus. The bigger the nodes,
the bigger the communities occur as a cluster-head in the generated partition.
Nodes refer to ground-truth communities and edges link towards communities
occurring in the given cluster-head.

Figure 8 describes the behaviours of the communities observed in the parti-
tioning obtained from the FR hate speech target community corpus. Considering
the equivocality, 9 ground-truth communities federate their own cluster(s).

other_otherorigin_otherother_individualorigin_african_descentorigin_indian/hinduorigin_individualorigin_arabsdisability_individualorigin_asiansdisability_special_needsorigin_special_needsorigin_left_wing_peoplereligion_muslimsother_left_wing_peopleorigin_immigrantsreligion_jewsSpringer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

25

Fig. 8: Dispersion and equivocality of the communities in the FR hate speech
target community corpus.

Among them 5 are the head of one cluster including origin immigrants, ori-
gin arabs, origin african descent, religion muslims and religion jews while the
others are the head of multiple clusters. other individual reaches the high-
est number of clusters being the head of 4 diﬀerent clusters representing
25.0% of the total number of clusters. The second community obtaining the
highest degree of equivocality is other other representing respectively 18.7%
of cluster-heads. Considering the scatteredness, we can observe that some
communities being cluster-heads are also assimilated to other clusters. For
instance, origin african descent and origin other are above 70% of scattered-
ness. Entries composing both of these two clusters occur frequently in clusters
having other individual and other other as head. ‘les renois’ (EN: niggers) and
‘attard´e mentaux’ (EN: retarded) are the most frequent patterns extracted
from the cluster mixing origin african descent and other individual while ‘cet
attard´e’ (EN: this retarded) and ‘@user mongol’ (EN: @user mogolian) are
the most redundant ones in the generated cluster combining other other and
other individual. These ﬁndings highlight that both ground-truth communities
use frequently a vocabulary based on common slurs and demeaning expressions
use to target individuals belonging to the other individual community. In paral-
lel, 7 ground-truth communities are fully assimilated into the generated clusters
regarding various degrees of scatteredness. Among them, origin individual,
origin left wing people and origin indian/hindu reach 100% of scatteredness
showing that tweets composing these ground-truth communities are also scat-
tered throughout all the clusters. origin asians and origin special needs are
also highly dispersed with a degree of scatteredness above 80%. Considering
both of these aspects, we can observe that the cluster-head religion muslims
and religion jews are the less equivocal and scattered ground-truth community.
Indeed, these communities assimilate only entries belonging to their commu-
nities or from origin arabs for religion muslims and from religion muslims for

0510152025303540equivocality (%)20406080100scatteredness (%)origin_individualorigin_left_wing_peopleorigin_otherorigin_immigrantsorigin_arabsother_individualorigin_indian/hindudisability_individualother_left_wing_peopleother_otherorigin_african_descentreligion_muslimsdisability_special_needsorigin_asiansreligion_jewsorigin_special_needsSpringer Nature 2021 LATEX template

26

Unsupervised Fine-grained Hate Speech Target Community Detection

Fig. 9: Visualisation of the mixing of the communities within the generated
clusters for the FR hate speech target community corpus. The bigger the nodes,
the bigger the communities occur as a cluster-head in the generated partition.
Nodes refer to ground-truth communities and edges link towards communities
occurring in the given cluster-head.

religion jews. From these clusters, we can observe common slurs speciﬁc to
each religion. For instance, ‘danger de l’islam’ (EN: danger of Islam) and
‘source du terrorisme’ (EN: source of terrorism) for the cluster correspond-
ing to the ground-truth community religion muslims and ‘sale juif’ (EN: kike)
and ‘antis´emitisme et complotiste’ (EN: antisemitism and conspiracy) for the
cluster corresponding to the ground-truth community religion jews. From the
visualisation of the mixing of the communities’ semantic spaces presented in
Figure 9, we can observe that both vocabularies related to the communities
origin immigrants and other left wing people are used to convey hate against
people based on their origin. Other prominent mixing can be noticed including
the community other individual targeting individuals using vocabularies and
slurs related to the target disability and the group special needs.

Whilst data are highly imbalanced, explaining the assimilation of some
ground-truth communities in favor of the multiplication of others, applying the
proposed pipeline has unveiled new insights improving the understanding on
how hate is conveyed. From this study, we can conﬁrm the relevance of the
MLMA facets to unveil sub-semantic spaces reﬂecting the nature of oﬀensive
comments expressed towards the deﬁned attributes. However, from the observed

other_otherorigin_otherother_individualorigin_african_descentorigin_indian/hinduorigin_individualorigin_arabsdisability_individualorigin_asiansdisability_special_needsorigin_special_needsorigin_left_wing_peoplereligion_muslimsother_left_wing_peopleorigin_immigrantsreligion_jewsSpringer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

27

behaviours of the ground-truth communities within the generated clusters we
notice diﬃculties to discriminate among victim-groups and target-types. Indeed
vocabularies related to victim-groups, target-types or both can hold speciﬁc
properties allowing to discriminate between each other or conversely they can
share common properties leading to increase the bias. Communities resulting
from the partitioning rely on two kinds of phenomenons: clusters assimilat-
ing ground-truth communities relying on vocabularies mostly composed of
common slurs and demeaning expressions or clusters mixing facets based on
complementary vocabularies. For instance, the target-type disability and the
victim-group specNeeds composed of oﬀensive messages targeting people with
special needs constitute a fully-ﬂedged sub-semantic space speciﬁc to these
attributes. However, this vocabulary is mostly composed of slurs and demean-
ing expressions used to discriminate or insult victim-groups, target-types or
both such as the target-type origin in both languages and more particularly
the victim-group arabs in French (e.g.: ‘@user c’est pas `a toi que je parle gros
mongol. t’as pris le melon sale arabe’, (EN: ‘@user I am not talking to you
retard. you are big-headed raghead’)) and the community gender women in
English (e.g.: ‘smh women really retarded @url’). Concerning the complementar-
ity between sub-semantic spaces, we have observed bridges built between some
spaces leading to a precise characterisation of the type of hate speech expressed
frequently towards victim-groups, target-types or both. For instance, clusters
have emerged in English combining vocabularies from the community sex-
ual orientation special needs and gender women (e.g.: ‘keep your mouth shut
you retard bitch’ ) or other left wing people and religion muslims in French
(e.g.: ‘@user ferme ta gueule islamo gauchiste’, (EN: ‘shut the fuck up you
libtard’)). In addition, we have also observed that communities based on victim-
groups, target-types or both referring to other (i.e., the facets gathering tweets
which do not correspond to the speciﬁc target-types / victim-groups deﬁned
by MLMA) federate multiple clusters in both languages. This ﬁnding allows
to establish that from these facets either new ones emerged allowing to cap-
ture other target-types / victim-groups or a ﬁner-grained target community
taxonomy exists based on subdivisions of the given ground-truth communities.

8 Conclusion

In this paper, we have presented a complete pipeline addressing the task of ﬁne-
grained hate speech target community detection adopting a clustering approach.
Leveraging the last advances in clustering, the proposed pipeline is based on the
MVSC-CEV algorithm which performs a simultaneous clustering of multiple
data views resulting in a consensus partition of the data. We have explored the
use of diﬀerent language modelling resources to derive diﬀerent types of data
views exhibiting diﬀerent properties (i.e., syntactic/semantic and relationship
information). In total 69 experiments were conducted, both on the FR hate
speech target community corpus and on the EN hate speech target community
corpus, evaluated against state-of-the-art clustering techniques. As a result, we

Springer Nature 2021 LATEX template

28

Unsupervised Fine-grained Hate Speech Target Community Detection

showed that the majority of the models relying on the MVSC-CEV algorithm
achieves the best results on both languages and on the tested evaluation
metrics. More particularly, the {mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET} model
outperforms all the other models reaching the best balance considering all the
evaluation metrics on both languages. Besides that, through the use of clustering
techniques we enabled the study of mesoscopic structures of the data to unveil
insights on how the hate is conveyed against target communities through the
textual messages. Our results on the MLMA ground-truth communities showed
the ability of the proposed pipeline to generate clusters corresponding to sub-
semantic spaces reﬂecting the nature of oﬀensive comments related to the
deﬁned facets. Although the generated clusters do not correspond exactly to
the MLMA communities, they unveil new information allowing to investigate
hate speech properties related to speciﬁc victim-groups, target-types or both.
To conclude, this study has proven the possibility to transpose the task of
ﬁne-grained hate speech detection into a clustering problem by its ability to
address current challenges in the ﬁeld, i.e., capturing complex hate speech
phenomena using unsupervised methods which are more appropriate to deal
with social data. An API allowing to test the diﬀerent view conﬁgurations on
both languages is available online7.

The ﬁndings resulting from the conducted study open also multiple research
directions: ﬁrst, developing improved clustering-oriented solutions to address
this task and, (2) leveraging communities to derive auxiliary features aiming
at supporting downstream tasks (e.g., classiﬁcation and misogyny detection).
More generally, we hope our eﬀorts based on unsupervised learning clustering
techniques will pave the road to achieving an unsupervised pipeline estimating
optimal cluster number. Expectations from automating this step include to
establish whether the MLMA multi-aspect analysis reﬂects all the facets allowing
to describe accurately hate speech phenomena on social media. In future work,
we intend to evaluate the proposed pipeline on the task of ﬁne-grained hate
speech detection by including non-hostile tweets in order to establish its ability
to deal with real-world data.

Acknowledgments. This work is supported by the French government,
through the 3IA Cˆote d’Azur Investments in the Future project managed by
the National Research Agency (ANR) with the reference number ANR-19-
P3IA-0002 and the EFELIA Cˆote d’Azur project ANR-22-CMAS-0004.

Appendix A Experiments

7http://134.59.134.227/demo/index.html Date of access: 19th November 2021.

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

29

e
r
a

s
n
u
r

t
n
e
d
n
e
p
e
d
n
i

1
3
m
o
r
f

n
o
i
t
a
i
v
e
d

d
r
a
d
n
a
t
s

d
n
a

n
a
e
m
e
h
T

.
I

M
N

d
n
a

I

R
A

,
y
t
i
r
u
P

.
t
.
r
.
w

s
t
l

u
s
e
r

d
e
l
i
a
t
e
D

:

1
A

e
l
b
a
T

e
l
i
h
w
d
l
o
b

n
i

e
r
a

c
i
r
t
e
m
h
c
a
e

r
o
f

d
e
t
r
o
p
e
r

s
e
u
l
a
v

t
s
e
b

e
h
t

t
s
e
t

i
y
n
e
m
e
N
c
o
h

t
s
o
p

e
h
t

o
t

g
n
i
d
r
o
c
c
A

.
e
g
a
u
g
n
a
l

h
c
a
e

r
o
f

d
e
t
r
o
p
e
r

.
e
g
a
u
g
n
a
l

h
c
a
e

r
o
f

s
c
i
r
t
e
m
e
h
t

l
l
a

g
n

i
r
e
d

i
s
n
o
c

s
l
e
d
o
m

t
s
e
b

e
h
t

o
t

r
e
f
e
r

s
w
o
r

d
e
t
h
g
i
l
h
g
i
h

e
h
t

g
n
i
r
e
t
s
u
l
c

l
a
r
t
c
e
p
S
&
s
n
a
e
M
K

-

R
F

N
E

3
0
0
.
0
±
1
2
1
.
0

9
0
0
.
0
±
3
1
1
.
0

7
0
0
.
0
±
6
2
0
.
0

3
0
0
.
0
±
9
2
2
.
0

3
1
0
.
0
±
7
9
1
.
0

9
0
0
.
0
±
2
3
0
.
0

0
0
0
.
0
±
8
7
1
.
0

1
0
0
.
0
±
2
8
1
.
0

0
0
0
.
0
±
8
1
1
.
0

0
0
0
.
0
±
7
3
2
.
0

3
0
0
.
0
±
1
3
2
.
0

0
0
0
.
0
±
6
6
1
.
0

3
0
0
.
0
±
9
3
0
.
0

7
0
0
.
0
±
0
4
0
.
0

0
0
0
.
0
±
0
0
0
.
0

7
0
0
.
0
±
3
9
0
.
0

1
1
0
.
0
±
1
9
0
.
0

1
0
0
.
0
±
0
0
0
.
0

0
0
0
.
0
±
1
7
0
.
0

1
0
0
.
0
±
5
6
0
.
0

0
0
0
.
0
±
1
1
0
.
0

0
0
0
.
0
±
1
0
1
.
0

1
0
0
.
0
±
3
0
1
.
0

0
0
0
.
0
±
1
3
0
.
0

3
0
0
.
0
±
8
5
2
.
0

0
1
0
.
0
±
4
5
2
.
0

5
0
0
.
0
±
7
7
1
.
0

4
0
0
.
0
±
8
4
3
.
0

4
1
0
.
0
±
4
2
3
.
0

7
0
0
.
0
±
3
8
1
.
0

0
0
0
.
0
±
6
0
3
.
0

1
0
0
.
0
±
0
0
3
.
0

0
0
0
.
0
±
7
3
2
.
0

0
0
0
.
0
±
9
3
3
.
0

2
0
0
.
0
±
2
4
3
.
0

0
0
0
.
0
±
1
9
2
.
0

8
0
0
.
0
±
8
2
1
.
0

8
0
0
.
0
±
9
3
1
.
0

1
1
0
.
0
±
5
4
0
.
0

4
0
0
.
0
±
9
5
2
.
0

1
1
0
.
0
±
8
1
2
.
0

9
0
0
.
0
±
3
3
0
.
0

4
0
0
.
0
±
4
3
2
.
0

0
0
0
.
0
±
8
3
2
.
0

0
0
0
.
0
±
1
5
1
.
0

0
0
0
.
0
±
2
4
2
.
0

0
0
0
.
0
±
4
3
2
.
0

0
0
0
.
0
±
1
3
1
.
0

1
0
0
.
0
±
7
1
2
.
0

2
0
0
.
0
±
5
5
1
.
0

0
0
0
.
0
±
7
1
2
.
0

3
0
0
.
0
±
9
1
1
.
0

3
0
0
.
0
±
1
5
1
.
0

2
0
0
.
0
±
7
2
2
.
0

1
0
0
.
0
±
8
1
2
.
0

2
0
0
.
0
±
0
1
2
.
0

2
0
0
.
0
±
9
1
2
.
0

2
0
0
.
0
±
7
2
2
.
0

1
0
0
.
0
±
8
3
1
.
0

2
0
0
.
0
±
7
5
1
.
0

1
0
0
.
0
±
7
0
2
.
0

1
0
0
.
0
±
5
1
2
.
0

3
0
0
.
0
±
1
4
1
.
0

2
0
0
.
0
±
5
0
2
.
0

2
0
0
.
0
±
2
2
2
.
0

1
0
0
.
0
±
8
9
1
.
0

2
0
0
.
0
±
4
1
2
.
0

2
0
0
.
0
±
8
1
2
.
0

4
0
0
.
0
±
4
3
1
.
0

2
0
0
.
0
±
4
6
1
.
0

2
0
0
.
0
±
9
9
1
.
0

I

M
N

1
0
0
.
0
±
4
9
0
.
0

1
0
0
.
0
±
9
6
0
.
0

2
0
0
.
0
±
3
9
0
.
0

1
0
0
.
0
±
7
3
0
.
0

2
0
0
.
0
±
6
5
0
.
0

4
0
0
.
0
±
7
0
1
.
0

5
0
0
.
0
±
3
0
1
.
0

2
0
0
.
0
±
6
8
0
.
0

3
0
0
.
0
±
2
9
0
.
0

I

R
A

1
0
0
.
0
±
0
1
1
.
0

1
0
0
.
0
±
8
4
0
.
0

2
0
0
.
0
±
8
5
0
.
0

1
0
0
.
0
±
4
8
0
.
0

2
0
0
.
0
±
2
8
0
.
0

1
0
0
.
0
±
6
1
0
.
0

3
0
0
.
0
±
4
9
0
.
0

4
0
0
.
0
±
4
0
1
.
0

1
0
0
.
0
±
3
8
0
.
0

2
0
0
.
0
±
6
8
0
.
0

5
0
0
.
0
±
8
9
0
.
0

2
0
0
.
0
±
7
4
0
.
0

1
0
0
.
0
±
3
6
0
.
0

1
0
0
.
0
±
3
8
0
.
0

C
S
V
M

2
0
0
.
0
±
7
4
3
.
0

3
0
0
.
0
±
2
0
3
.
0

1
0
0
.
0
±
3
5
3
.
0

3
0
0
.
0
±
0
6
2
.
0

4
0
0
.
0
±
0
9
2
.
0

2
0
0
.
0
±
0
6
3
.
0

1
0
0
.
0
±
8
5
3
.
0

1
0
0
.
0
±
1
4
3
.
0

3
0
0
.
0
±
4
4
3
.
0

2
0
0
.
0
±
2
6
3
.
0

2
0
0
.
0
±
1
8
2
.
0

2
0
0
.
0
±
0
0
3
.
0

2
0
0
.
0
±
9
3
3
.
0

4
0
0
.
0
±
2
4
3
.
0

2
0
0
.
0
±
9
5
2
.
0

2
0
0
.
0
±
5
4
3
.
0

1
0
0
.
0
±
2
6
3
.
0

2
0
0
.
0
±
7
3
3
.
0

2
0
0
.
0
±
9
3
3
.
0

2
0
0
.
0
±
0
6
3
.
0

6
0
0
.
0
±
4
7
2
.
0

1
0
0
.
0
±
5
0
3
.
0

5
0
0
.
0
±
8
3
3
.
0

y
t
i
r
u
P

2
0
0
.
0
±
8
3
2
.
0

3
0
0
.
0
±
1
8
1
.
0

3
0
0
.
0
±
5
4
2
.
0

1
0
0
.
0
±
7
8
0
.
0

1
0
0
.
0
±
7
7
0
.
0

3
0
0
.
0
±
3
6
2
.
0

3
0
0
.
0
±
3
4
2
.
0

3
0
0
.
0
±
0
5
2
.
0

3
0
0
.
0
±
6
4
2
.
0

2
0
0
.
0
±
7
6
2
.
0

4
0
0
.
0
±
9
9
1
.
0

5
0
0
.
0
±
6
0
2
.
0

3
0
0
.
0
±
3
5
2
.
0

3
0
0
.
0
±
5
4
2
.
0

2
0
0
.
0
±
7
3
1
.
0

2
0
0
.
0
±
6
5
2
.
0

2
0
0
.
0
±
7
4
2
.
0

2
0
0
.
0
±
3
4
2
.
0

2
0
0
.
0
±
6
4
2
.
0

1
0
0
.
0
±
0
6
2
.
0

3
0
0
.
0
±
9
7
1
.
0

3
0
0
.
0
±
3
7
1
.
0

2
0
0
.
0
±
7
4
2
.
0

I

M
N

5
0
0
.
0
±
3
5
0
.
0

7
0
0
.
0
±
5
4
0
.
0

4
0
0
.
0
±
2
0
0
.
0

6
0
0
.
0
±
6
9
0
.
0

0
1
0
.
0
±
8
8
0
.
0

2
0
0
.
0
±
1
0
0
.
0

9
0
0
.
0
±
6
0
1
.
0

0
0
0
.
0
±
4
9
0
.
0

0
0
0
.
0
±
3
1
0
.
0

1
0
0
.
0
±
0
9
0
.
0

0
0
0
.
0
±
1
0
1
.
0

0
0
0
.
0
±
4
0
0
.
0

3
0
0
.
0
±
0
8
0
.
0

3
0
0
.
0
±
5
6
0
.
0

2
0
0
.
0
±
4
8
0
.
0

0
0
0
.
0
±
2
1
0
.
0

3
0
0
.
0
±
9
0
0
.
0

3
0
0
.
0
±
8
9
0
.
0

3
0
0
.
0
±
7
8
0
.
0

3
0
0
.
0
±
0
9
0
.
0

5
0
0
.
0
±
8
8
0
.
0

3
0
0
.
0
±
1
0
1
.
0

4
0
0
.
0
±
8
7
0
.
0

6
0
0
.
0
±
0
8
0
.
0

4
0
0
.
0
±
2
9
0
.
0

5
0
0
.
0
±
7
8
0
.
0

1
0
0
.
0
±
6
1
0
.
0

2
0
0
.
0
±
2
9
0
.
0

4
0
0
.
0
±
5
8
0
.
0

5
0
0
.
0
±
9
8
0
.
0

4
0
0
.
0
±
4
9
0
.
0

2
0
0
.
0
±
4
9
0
.
0

4
0
0
.
0
±
5
6
0
.
0

4
0
0
.
0
±
9
6
0
.
0

4
0
0
.
0
±
1
9
0
.
0

I

R
A

6
0
0
.
0
±
6
8
2
.
0

7
0
0
.
0
±
9
9
2
.
0

4
0
0
.
0
±
1
9
1
.
0

7
0
0
.
0
±
2
7
3
.
0

2
1
0
.
0
±
6
3
3
.
0

3
0
0
.
0
±
7
8
1
.
0

3
0
0
.
0
±
2
5
3
.
0

0
0
0
.
0
±
7
4
3
.
0

0
0
0
.
0
±
1
5
2
.
0

0
0
0
.
0
±
4
4
3
.
0

0
0
0
.
0
±
5
4
3
.
0

0
0
0
.
0
±
2
3
2
.
0

4
0
0
.
0
±
8
4
3
.
0

4
0
0
.
0
±
0
2
3
.
0

3
0
0
.
0
±
7
5
3
.
0

2
0
0
.
0
±
6
2
2
.
0

3
0
0
.
0
±
3
3
2
.
0

3
0
0
.
0
±
2
8
3
.
0

3
0
0
.
0
±
1
6
3
.
0

4
0
0
.
0
±
1
6
3
.
0

3
0
0
.
0
±
9
5
3
.
0

2
0
0
.
0
±
5
8
3
.
0

6
0
0
.
0
±
5
3
3
.
0

6
0
0
.
0
±
5
4
3
.
0

3
0
0
.
0
±
2
6
3
.
0

3
0
0
.
0
±
8
5
3
.
0

3
0
0
.
0
±
1
5
2
.
0

2
0
0
.
0
±
1
7
3
.
0

2
0
0
.
0
±
0
6
3
.
0

3
0
0
.
0
±
0
6
3
.
0

4
0
0
.
0
±
0
6
3
.
0

3
0
0
.
0
±
3
7
3
.
0

4
0
0
.
0
±
7
2
3
.
0

3
0
0
.
0
±
4
1
3
.
0

2
0
0
.
0
±
7
6
3
.
0

y
t
i
r
u
P

I

M
N

I

R
A

y
t
i
r
u
P

I

M
N

I

R
A

y
t
i
r
u
P

.
s
g
ﬁ
n
o
c

w
e
i
v
-
e
l
g
n
i
S

}
O
R
P
-
T
R
E
B
m

}
T
E
N
-
T
R
E
B
m

}
O
R
P
-
E
S
U
m

}
T
E
N
-
E
S
U
m

}
E
S
U
m

}
T
R
E
B
m

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

}
O
R
P
-
T
R
E
B
m

}
T
E
N
-
T
R
E
B
m

}
O
R
P
-
E
S
U
m

}
T
E
N
-
E
S
U
m

}
E
S
U
m

}
T
R
E
B
m

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

w
e
i
v

M
K
{

M
K
{

M
K
{

M
K
{

M
K
{

M
K
{

C
S
{

C
S
{

C
S
{

C
S
{

C
S
{

C
S
{

.
s
g
ﬁ
n
o
c

w
e
i
v

-
i
t
l
u
M

}
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
T
R
E
B
m
{

}
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
R
E
B
m
{

}
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
E
S
U
m
{

}
O
R
P
-
E
S
U
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
{

}
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
T
R
E
B
m
{

Springer Nature 2021 LATEX template

30

Unsupervised Fine-grained Hate Speech Target Community Detection

2
0
0
.
0
±
8
0
2
.
0

5
0
0
.
0
±
6
3
1
.
0

2
0
0
.
0
±
7
2
2
.
0

2
0
0
.
0
±
3
1
2
.
0

3
0
0
.
0
±
6
2
2
.
0

2
0
0
.
0
±
0
2
2
.
0

0
0
0
.
0
±
8
1
2
.
0

1
0
0
.
0
±
6
1
2
.
0

3
0
0
.
0
±
6
1
2
.
0

4
0
0
.
0
±
0
2
2
.
0

3
0
0
.
0
±
7
4
1
.
0

2
0
0
.
0
±
1
1
2
.
0

1
0
0
.
0
±
5
2
2
.
0

3
0
0
.
0
±
8
9
1
.
0

3
0
0
.
0
±
7
0
2
.
0

1
0
0
.
0
±
2
1
2
.
0

4
0
0
.
0
±
4
1
2
.
0

2
0
0
.
0
±
6
9
1
.
0

1
0
0
.
0
±
4
9
1
.
0

3
0
0
.
0
±
4
0
2
.
0

3
0
0
.
0
±
6
4
1
.
0

3
0
0
.
0
±
2
0
2
.
0

2
0
0
.
0
±
1
2
2
.
0

1
0
0
.
0
±
1
3
2
.
0

2
0
0
.
0
±
6
0
2
.
0

2
0
0
.
0
±
7
1
2
.
0

2
0
0
.
0
±
8
0
2
.
0

2
0
0
.
0
±
8
1
2
.
0

1
0
0
.
0
±
5
2
2
.
0

1
0
0
.
0
±
4
9
1
.
0

1
0
0
.
0
±
3
1
2
.
0

2
0
0
.
0
±
7
9
1
.
0

2
0
0
.
0
±
1
2
2
.
0

2
0
0
.
0
±
8
1
2
.
0

3
0
0
.
0
±
4
8
0
.
0

2
0
0
.
0
±
6
4
0
.
0

3
0
0
.
0
±
9
0
1
.
0

2
0
0
.
0
±
9
8
0
.
0

2
0
0
.
0
±
5
9
0
.
0

5
0
0
.
0
±
6
9
0
.
0

5
0
0
.
0
±
0
0
1
.
0

2
0
0
.
0
±
0
9
0
.
0

1
0
0
.
0
±
8
8
0
.
0

1
0
0
.
0
±
2
9
0
.
0

1
0
0
.
0
±
0
5
0
.
0

1
0
0
.
0
±
8
8
0
.
0

4
0
0
.
0
±
9
9
0
.
0

1
0
0
.
0
±
5
8
0
.
0

1
0
0
.
0
±
6
8
0
.
0

1
0
0
.
0
±
7
8
0
.
0

2
0
0
.
0
±
0
9
0
.
0

1
0
0
.
0
±
1
8
0
.
0

1
0
0
.
0
±
1
8
0
.
0

1
0
0
.
0
±
2
8
0
.
0

1
0
0
.
0
±
3
5
0
.
0

2
0
0
.
0
±
1
8
0
.
0

5
0
0
.
0
±
5
9
0
.
0

5
0
0
.
0
±
9
9
0
.
0

2
0
0
.
0
±
6
8
0
.
0

1
0
0
.
0
±
3
9
0
.
0

1
0
0
.
0
±
8
8
0
.
0

3
0
0
.
0
±
3
9
0
.
0

1
0
0
.
0
±
4
9
0
.
0

2
0
0
.
0
±
8
7
0
.
0

2
0
0
.
0
±
9
8
0
.
0

1
0
0
.
0
±
1
8
0
.
0

3
0
0
.
0
±
3
9
0
.
0

1
0
0
.
0
±
0
9
0
.
0

4
0
0
.
0
±
0
4
3
.
0

4
0
0
.
0
±
1
7
2
.
0

3
0
0
.
0
±
4
6
3
.
0

4
0
0
.
0
±
1
5
3
.
0

3
0
0
.
0
±
7
5
3
.
0

3
0
0
.
0
±
9
5
3
.
0

1
0
0
.
0
±
5
5
3
.
0

3
0
0
.
0
±
0
4
3
.
0

5
0
0
.
0
±
3
4
3
.
0

5
0
0
.
0
±
1
5
3
.
0

4
0
0
.
0
±
5
8
2
.
0

5
0
0
.
0
±
4
4
3
.
0

1
0
0
.
0
±
1
6
3
.
0

3
0
0
.
0
±
1
4
3
.
0

5
0
0
.
0
±
3
4
3
.
0

4
0
0
.
0
±
5
4
3
.
0

4
0
0
.
0
±
8
4
3
.
0

2
0
0
.
0
±
8
2
3
.
0

2
0
0
.
0
±
5
3
3
.
0

3
0
0
.
0
±
7
3
3
.
0

4
0
0
.
0
±
8
8
2
.
0

4
0
0
.
0
±
0
3
3
.
0

3
0
0
.
0
±
8
4
3
.
0

2
0
0
.
0
±
6
4
2
.
0

1
0
0
.
0
±
9
9
0
.
0

3
0
0
.
0
±
8
6
2
.
0

3
0
0
.
0
±
3
6
2
.
0

3
0
0
.
0
±
7
6
2
.
0

2
0
0
.
0
±
0
5
2
.
0

3
0
0
.
0
±
9
4
2
.
0

4
0
0
.
0
±
7
4
2
.
0

3
0
0
.
0
±
3
7
2
.
0

3
0
0
.
0
±
8
6
2
.
0

3
0
0
.
0
±
3
4
2
.
0

3
0
0
.
0
±
2
9
1
.
0

2
0
0
.
0
±
2
6
2
.
0

3
0
0
.
0
±
5
5
2
.
0

2
0
0
.
0
±
3
5
2
.
0

2
0
0
.
0
±
6
4
2
.
0

1
0
0
.
0
±
2
5
2
.
0

2
0
0
.
0
±
4
4
2
.
0

2
0
0
.
0
±
8
4
2
.
0

3
0
0
.
0
±
7
5
2
.
0

3
0
0
.
0
±
6
7
1
.
0

2
0
0
.
0
±
8
4
2
.
0

3
0
0
.
0
±
5
6
2
.
0

1
0
0
.
0
±
7
6
3
.
0

1
0
0
.
0
±
6
7
2
.
0

5
0
0
.
0
±
3
3
3
.
0

4
0
0
.
0
±
9
4
3
.
0

3
0
0
.
0
±
3
4
3
.
0

2
0
0
.
0
±
5
5
3
.
0

3
0
0
.
0
±
5
5
3
.
0

2
0
0
.
0
±
9
2
3
.
0

2
0
0
.
0
±
3
4
3
.
0

3
0
0
.
0
±
2
3
3
.
0

3
0
0
.
0
±
0
5
3
.
0

4
0
0
.
0
±
8
4
3
.
0

4
0
0
.
0
±
6
6
2
.
0

4
0
0
.
0
±
1
5
2
.
0

4
0
0
.
0
±
0
7
2
.
0

2
0
0
.
0
±
0
6
2
.
0

2
0
0
.
0
±
2
6
2
.
0

2
0
0
.
0
±
7
5
2
.
0

2
0
0
.
0
±
9
4
2
.
0

2
0
0
.
0
±
4
5
2
.
0

2
0
0
.
0
±
1
7
2
.
0

5
0
0
.
0
±
1
6
2
.
0

5
0
0
.
0
±
2
9
0
.
0

0
0
0
.
0
±
1
1
0
.
0

4
0
0
.
0
±
1
0
1
.
0

4
0
0
.
0
±
9
9
0
.
0

5
0
0
.
0
±
1
0
1
.
0

3
0
0
.
0
±
8
8
0
.
0

6
0
0
.
0
±
8
8
0
.
0

4
0
0
.
0
±
8
8
0
.
0

5
0
0
.
0
±
8
0
1
.
0

4
0
0
.
0
±
3
0
1
.
0

3
0
0
.
0
±
7
8
0
.
0

3
0
0
.
0
±
3
7
0
.
0

4
0
0
.
0
±
6
9
0
.
0

4
0
0
.
0
±
4
9
0
.
0

5
0
0
.
0
±
7
9
0
.
0

3
0
0
.
0
±
0
9
0
.
0

4
0
0
.
0
±
1
9
0
.
0

5
0
0
.
0
±
4
9
0
.
0

3
0
0
.
0
±
9
8
0
.
0

4
0
0
.
0
±
7
9
0
.
0

5
0
0
.
0
±
9
6
0
.
0

4
0
0
.
0
±
4
9
0
.
0

5
0
0
.
0
±
9
9
0
.
0

5
0
0
.
0
±
8
0
1
.
0

5
0
0
.
0
±
0
0
1
.
0

5
0
0
.
0
±
9
8
0
.
0

6
0
0
.
0
±
6
0
1
.
0

4
0
0
.
0
±
4
9
0
.
0

5
0
0
.
0
±
8
9
0
.
0

4
0
0
.
0
±
7
9
0
.
0

3
0
0
.
0
±
0
9
0
.
0

4
0
0
.
0
±
7
9
0
.
0

5
0
0
.
0
±
5
0
1
.
0

4
0
0
.
0
±
8
9
0
.
0

4
0
0
.
0
±
3
6
3
.
0

1
0
0
.
0
±
8
3
2
.
0

3
0
0
.
0
±
4
8
3
.
0

4
0
0
.
0
±
8
7
3
.
0

4
0
0
.
0
±
0
8
3
.
0

4
0
0
.
0
±
2
6
3
.
0

4
0
0
.
0
±
0
6
3
.
0

4
0
0
.
0
±
2
6
3
.
0

4
0
0
.
0
±
1
9
3
.
0

5
0
0
.
0
±
0
8
3
.
0

3
0
0
.
0
±
1
6
3
.
0

5
0
0
.
0
±
1
3
3
.
0

2
0
0
.
0
±
2
7
3
.
0

4
0
0
.
0
±
9
6
3
.
0

4
0
0
.
0
±
2
6
3
.
0

2
0
0
.
0
±
0
6
3
.
0

3
0
0
.
0
±
6
6
3
.
0

3
0
0
.
0
±
3
6
3
.
0

4
0
0
.
0
±
3
6
3
.
0

6
0
0
.
0
±
8
6
3
.
0

4
0
0
.
0
±
4
2
3
.
0

3
0
0
.
0
±
6
6
3
.
0

2
0
0
.
0
±
9
7
3
.
0

2
0
0
.
0
±
0
9
3
.
0

5
0
0
.
0
±
9
7
3
.
0

5
0
0
.
0
±
2
6
3
.
0

4
0
0
.
0
±
3
8
3
.
0

3
0
0
.
0
±
4
7
3
.
0

3
0
0
.
0
±
4
7
3
.
0

5
0
0
.
0
±
9
6
3
.
0

3
0
0
.
0
±
4
6
3
.
0

3
0
0
.
0
±
6
6
3
.
0

3
0
0
.
0
±
0
8
3
.
0

5
0
0
.
0
±
1
7
3
.
0

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
{

}
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
T
R
E
B
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
E
S
U
m
/
T
R
E
B
m
{

}
T
E
N
-
E
S
U
m
/
T
E
N
-
T
R
E
B
m
/
O
R
P
-
E
S
U
m
/
O
R
P
-
T
R
E
B
m
{

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

31

(a) purity

(b) ARI

(c) NMI
Fig. A1: The diﬀerent hierarchies obtained from models’ average ranking for
each evaluation metric using the post hoc Nemenyi test

1234567891011121314151617181920{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}{mBERT-PRO/mUSE-PRO}{mUSE/mBERT-PRO/mUSE-PRO}{mUSE/mBERT-PRO}{mBERT-PRO/mUSE-PRO/mBERT-NET}{mBERT/mUSE/mUSE-PRO}{mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{KM view mUSE}{SC view mUSE-PRO}{SC view mBERT}{SC view mUSE}{KM view mUSE-PRO}{SC view mBERT-PRO}{KM view mBERT-PRO}{KM view mBERT}{SC view mUSE-NET}{SC view mBERT-NET}{KM view mBERT-NET}{KM view mUSE-NET}CD1234567891011121314151617181920{mBERT-PRO/mUSE-PRO}{mUSE/mBERT-PRO/mUSE-PRO}{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}{SC view mUSE-PRO}{mUSE/mBERT-PRO}{mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{KM view mUSE}{mBERT/mUSE/mUSE-PRO}{SC view mBERT}{SC view mUSE}{KM view mUSE-PRO}{SC view mBERT-PRO}{KM view mBERT}{KM view mBERT-PRO}{SC view mBERT-NET}{SC view mUSE-NET}{KM view mBERT-NET}{KM view mUSE-NET}CD1234567891011121314151617181920{mUSE/mBERT-PRO/mUSE-PRO/mUSE-NET}{mUSE/mBERT-PRO/mUSE-PRO}{SC view mUSE}{mBERT-PRO/mUSE-PRO}{KM view mUSE}{mUSE/mBERT-PRO}{mUSE/mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET}{mBERT-PRO/mUSE-PRO/mBERT-NET/mUSE-NET}{SC view mUSE-PRO}{mBERT/mUSE/mUSE-PRO}{SC view mBERT-PRO}{KM view mUSE-PRO}{SC view mBERT}{SC view mBERT-NET}{SC view mUSE-NET}{KM view mBERT}{KM view mBERT-PRO}{KM view mBERT-NET}{KM view mUSE-NET}CDSpringer Nature 2021 LATEX template

32

Unsupervised Fine-grained Hate Speech Target Community Detection

References

[1] Nockleby, J.T.: Hate speech. Encyclopedia of the American Constitution

2nd ed., 1277–1279 (2000)

[2] Zhang, Z., Luo, L.: Hate speech detection: A solved problem? the chal-
lenging case of long tail on twitter. Semantic Web 10(5), 925–945 (2019).
https://doi.org/10.3233/SW-180338

[3] Blaya, C.: Cyberhate: A review and content analysis of intervention strate-
gies. Aggression and Violent Behavior 45, 163–172 (2019). https://doi.org/
10.1016/j.avb.2018.05.006. Bullying and cyberbullying: Protective factors
and eﬀective interventions

[4] Zhang, Z., Robinson, D., Tepper, J.A.: Detecting hate speech on twitter
using a convolution-gru based deep neural network. In: Gangemi, A.,
Navigli, R., Vidal, M., Hitzler, P., Troncy, R., Hollink, L., Tordai, A., Alam,
M. (eds.) The Semantic Web - 15th International Conference, ESWC 2018,
Proceedings. Lecture Notes in Computer Science, vol. 10843, pp. 745–
760. Springer, Heraklion, Crete, Greece (2018). https://doi.org/10.1007/
978-3-319-93417-4 48. https://doi.org/10.1007/978-3-319-93417-4 48

[5] Liu, P., Li, W., Zou, L.: NULI at semeval-2019 task 6: Transfer learning for
oﬀensive language detection using bidirectional transformers. In: May, J.,
Shutova, E., Herbelot, A., Zhu, X., Apidianaki, M., Mohammad, S.M. (eds.)
Proceedings of the 13th International Workshop on Semantic Evaluation,
SemEval@NAACL-HLT 2019, pp. 87–91. Association for Computational
Linguistics, Minneapolis, MN, USA (2019). https://doi.org/10.18653/v1/
s19-2011. https://doi.org/10.18653/v1/s19-2011

[6] Corazza, M., Menini, S., Cabrio, E., Tonelli, S., Villata, S.: A multilingual
evaluation for online hate speech detection. ACM Trans. Internet Techn.
20(2), 10–11022 (2020). https://doi.org/10.1145/3377323

[7] Fortuna, P., Nunes, S.: A survey on automatic detection of hate speech
in text. ACM Comput. Surv. 51(4), 85–18530 (2018). https://doi.org/10.
1145/3232676

[8] Mossie, Z., Wang, J.: Vulnerable community identiﬁcation using hate
speech detection on social media. Inf. Process. Manag. 57(3), 102087
(2020). https://doi.org/10.1016/j.ipm.2019.102087

[9] Chiril, P., Pamungkas, E.W., Benamara, F., Moriceau, V., Patti, V.:
Emotionally informed hate speech detection: A multi-target perspec-
tive. Cogn. Comput. 14(1), 322–352 (2022). https://doi.org/10.1007/
s12559-021-09862-5

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

33

[10] Ousidhoum, N., Lin, Z., Zhang, H., Song, Y., Yeung, D.: Multilingual and
multi-aspect hate speech analysis. In: Inui, K., Jiang, J., Ng, V., Wan, X.
(eds.) Proceedings of the 2019 Conference on Empirical Methods in Natural
Language Processing and the 9th International Joint Conference on Natural
Language Processing, EMNLP-IJCNLP 2019, pp. 4674–4683. Association
for Computational Linguistics, Hong Kong, China (2019). https://doi.org/
10.18653/v1/D19-1474. https://doi.org/10.18653/v1/D19-1474

[11] Poletto, F., Basile, V., Sanguinetti, M., Bosco, C., Patti, V.: Resources
and benchmark corpora for hate speech detection: a systematic review.
Lang. Resour. Evaluation 55(2), 477–523 (2021). https://doi.org/10.1007/
s10579-020-09502-8

[12] Fortuna, P., da Silva, J.R., Wanner, L., Nunes, S., et al.: A hierarchically-
labeled portuguese hate speech dataset. In: Proceedings of the Third
Workshop on Abusive Language Online, pp. 94–104 (2019)

[13] Devlin, J., Chang, M.-W., Lee, K., Toutanova, K.: BERT: pre-training
of deep bidirectional transformers for language understanding. In: Pro-
ceedings of the 2019 Conference of the North American Chapter of the
Association for Computational Linguistics: Human Language Technolo-
gies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume
1 (Long and Short Papers), pp. 4171–4186 (2019). https://aclweb.org/
anthology/papers/N/N19/N19-1423/

[14] Yang, Y., Cer, D., Ahmad, A., Guo, M., Law, J., Constant, N., ´Abrego,
G.H., Yuan, S., Tar, C., Sung, Y., Strope, B., Kurzweil, R.: Multilingual
universal sentence encoder for semantic retrieval. In: Celikyilmaz, A., Wen,
T. (eds.) Proceedings of the 58th Annual Meeting of the Association
for Computational Linguistics: System Demonstrations, ACL 2020, pp.
87–94. Association for Computational Linguistics, Online (2020). https:
//doi.org/10.18653/v1/2020.acl-demos.12. https://doi.org/10.18653/v1/
2020.acl-demos.12

[15] Vidgen, B., Derczynski, L.: Directions in abusive language training data,
a systematic review: Garbage in, garbage out. PLOS ONE 15(12), 1–32
(2021). https://doi.org/10.1371/journal.pone.0243300

[16] Bohra, A., Vijay, D., Singh, V., Akhtar, S.S., Shrivastava, M.: A dataset
of hindi-english code-mixed social media text for hate speech detection.
In: Nissim, M., Patti, V., Plank, B., Wagner, C. (eds.) Proceedings of
the Second Workshop on Computational Modeling of People’s Opinions,
Personality, and Emotions in Social Media, PEOPLES@NAACL-HTL
2018, pp. 36–41. Association for Computational Linguistics, New Orleans,
Louisiana, USA (2018). https://doi.org/10.18653/v1/w18-1105. https://
doi.org/10.18653/v1/w18-1105

Springer Nature 2021 LATEX template

34

Unsupervised Fine-grained Hate Speech Target Community Detection

[17] Poletto, F., Basile, V., Bosco, C., Patti, V., Stranisci, M.: Annotating hate
speech: Three schemes at comparison. In: Bernardi, R., Navigli, R., Semer-
aro, G. (eds.) Proceedings of the Sixth Italian Conference on Computational
Linguistics. CEUR Workshop Proceedings, vol. 2481. CEUR-WS.org, Bari,
Italy (2019). http://ceur-ws.org/Vol-2481/paper56.pdf

[18] Nascimento, G., Carvalho, F., da Cunha, A.M., Viana, C.R., Guedes,
G.P.: Hate speech detection using brazilian imageboards. In: dos Santos,
J.A.F., Muchaluat-Saade, D.C. (eds.) Proceedings of the 25th Brazillian
Symposium on Multimedia and the Web, WebMedia 2019, pp. 325–328.
ACM, Rio de Janeiro, Brazil (2019). https://doi.org/10.1145/3323503.
3360619. https://doi.org/10.1145/3323503.3360619

[19] Basile, V., Bosco, C., Fersini, E., Nozza, D., Patti, V., Pardo, F.M.R.,
Rosso, P., Sanguinetti, M.: Semeval-2019 task 5: Multilingual detection
of hate speech against immigrants and women in twitter. In: May, J.,
Shutova, E., Herbelot, A., Zhu, X., Apidianaki, M., Mohammad, S.M. (eds.)
Proceedings of the 13th International Workshop on Semantic Evaluation,
SemEval@NAACL-HLT 2019, pp. 54–63. Association for Computational
Linguistics, Minneapolis, MN, USA (2019). https://doi.org/10.18653/v1/
s19-2007. https://doi.org/10.18653/v1/s19-2007

[20] Zampieri, M., Malmasi, S., Nakov, P., Rosenthal, S., Farra, N., Kumar,
R.: Semeval-2019 task 6: Identifying and categorizing oﬀensive language
in social media (oﬀenseval). In: May, J., Shutova, E., Herbelot, A., Zhu,
X., Apidianaki, M., Mohammad, S.M. (eds.) Proceedings of the 13th
International Workshop on Semantic Evaluation, pp. 75–86. Association
for Computational Linguistics, Minneapolis, MN, USA (2019). https://
doi.org/10.18653/v1/s19-2010. https://doi.org/10.18653/v1/s19-2010

[21] Alrehili, A.: Automatic hate speech detection on social media: A brief
survey. In: 16th IEEE/ACS International Conference on Computer Systems
and Applications, AICCSA, pp. 1–6. IEEE Computer Society, Abu Dhabi,
UAE (2019). https://doi.org/10.1109/AICCSA47632.2019.9035228. https:
//doi.org/10.1109/AICCSA47632.2019.9035228

[22] Themeli, C., Giannakopoulos, G., Pittaras, N.: A study of text rep-
resentations in hate speech detection. CoRR abs/2102.04521 (2021)
https://arxiv.org/abs/2102.04521

[23] Malmasi, S., Zampieri, M.: Challenges in discriminating profanity from
hate speech. J. Exp. Theor. Artif. Intell. 30(2), 187–202 (2018). https:
//doi.org/10.1080/0952813X.2017.1409284

[24] MacAvaney, S., Yao, H.-R., Yang, E., Russell, K., Goharian, N., Frieder,
O.: Hate speech detection: Challenges and solutions. PLOS ONE 14(8),
1–16 (2019). https://doi.org/10.1371/journal.pone.0221152

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

35

[25] Vigna, F.D., Cimino, A., Dell’Orletta, F., Petrocchi, M., Tesconi, M.:
Hate me, hate me not: Hate speech detection on facebook. In: Armando,
A., Baldoni, R., Focardi, R. (eds.) Proceedings of the First Italian
Conference on Cybersecurity (ITASEC17). CEUR Workshop Proceed-
ings, vol. 1816, pp. 86–95. CEUR-WS.org, Venice, Italy (2017). http:
//ceur-ws.org/Vol-1816/paper-09.pdf

[26] Tian, Z., K¨ubler, S.: Oﬀensive language detection using brown clustering.
In: Calzolari, N., B´echet, F., Blache, P., Choukri, K., Cieri, C., Declerck,
T., Goggi, S., Isahara, H., Maegaard, B., Mariani, J., Mazo, H., Moreno,
A., Odijk, J., Piperidis, S. (eds.) Proceedings of The 12th Language
Resources and Evaluation Conference, LREC 2020, Marseille, France, May
11-16, 2020, pp. 5079–5087. European Language Resources Association,
??? (2020). https://aclanthology.org/2020.lrec-1.625/

[27] Davidson, T., Warmsley, D., Macy, M.W., Weber, I.: Automated hate
speech detection and the problem of oﬀensive language. In: Proceedings of
the Eleventh International Conference on Web and Social Media, ICWSM
2017, Montr´eal, Qu´ebec, Canada, May 15-18, 2017., pp. 512–515 (2017)

[28] Vogel, I., Meghana, M.: Proﬁling hate speech spreaders on twitter: SVM
vs. bi-lstm. In: Faggioli, G., Ferro, N., Joly, A., Maistro, M., Piroi, F.
(eds.) Proceedings of the Working Notes of CLEF 2021 - Conference
and Labs of the Evaluation Forum. CEUR Workshop Proceedings, vol.
2936, pp. 2193–2200. CEUR-WS.org, Bucharest, Romania (2021). http:
//ceur-ws.org/Vol-2936/paper-196.pdf

[29] Asogwa, D.C., Chukwuneke, C.I., Ngene, C.C., Anigbogu, G.N.:
Hate speech classiﬁcation using SVM and naive BAYES. CoRR
abs/2204.07057 (2022) https://arxiv.org/abs/2204.07057. https://doi.
org/10.48550/arXiv.2204.07057

[30] Kumar, R., Ojha, A.K., Malmasi, S., Zampieri, M.: Benchmarking aggres-
sion identiﬁcation in social media. In: Kumar, R., Ojha, A.K., Zampieri,
M., Malmasi, S. (eds.) Proceedings of the First Workshop on Trolling,
Aggression and Cyberbullying, TRAC@COLING 2018, pp. 1–11. Associa-
tion for Computational Linguistics, Santa Fe, New Mexico, USA (2018).
https://aclanthology.org/W18-4401/

[31] Indurthi, V., Syed, B., Shrivastava, M., Gupta, M., Varma, V.: Fermi
at SemEval-2019 task 6: Identifying and categorizing oﬀensive language
in social media using sentence embeddings. In: Proceedings of the 13th
International Workshop on Semantic Evaluation, pp. 611–616. Association
for Computational Linguistics, Minneapolis, Minnesota, USA (2019). https:
//doi.org/10.18653/v1/S19-2109. https://aclanthology.org/S19-2109

Springer Nature 2021 LATEX template

36

Unsupervised Fine-grained Hate Speech Target Community Detection

[32] Koufakou, A., Pamungkas, E.W., Basile, V., Patti, V.: HurtBERT: Incor-
porating lexical features with BERT for the detection of abusive language.
In: Proceedings of the Fourth Workshop on Online Abuse and Harms, pp.
34–43. Association for Computational Linguistics, Online (2020). https://
doi.org/10.18653/v1/2020.alw-1.5. https://aclanthology.org/2020.alw-1.5

[33] Caselli, T., Basile, V., Mitrovic, J., Granitzer, M.: Hatebert: Retraining
BERT for abusive language detection in english. CoRR abs/2010.12472
(2020) https://arxiv.org/abs/2010.12472

[34] Magu, R., Luo, J.: Determining code words in euphemistic hate speech
using word embedding networks. In: Proceedings of the 2nd Workshop on
Abusive Language Online (ALW2), pp. 93–100. Association for Computa-
tional Linguistics, Brussels, Belgium (2018). https://doi.org/10.18653/v1/
W18-5112. https://aclanthology.org/W18-5112

[35] Nobata, C., Tetreault, J.R., Thomas, A., Mehdad, Y., Chang, Y.: Abusive
language detection in online user content. In: Proceedings of the 25th
International Conference on World Wide Web, WWW 2016, Montreal,
Canada, April 11 - 15, 2016, pp. 145–153 (2016)

[36] Jain, M., Goel, P., Singla, P., Tehlan, R.: Comparison of various word
embeddings for hate-speech detection. In: Khanna, A., Gupta, D.,
P´olkowski, Z., Bhattacharyya, S., Castillo, O. (eds.) Data Analytics and
Management, pp. 251–265. Springer, Singapore (2021)

[37] Schmidt, A., Wiegand, M.: A survey on hate speech detection using
natural language processing. In: Proceedings of the Fifth International
Workshop on Natural Language Processing for Social Media, pp. 1–10.
Association for Computational Linguistics, Valencia, Spain (2017). https:
//doi.org/10.18653/v1/W17-1101. https://aclanthology.org/W17-1101

[38] Meena, P., Pawar, M., Pandey, A.: A survey on community detection algo-
rithm and its applications. Turkish Journal of Computer and Mathematics
Education (TURCOMAT) 12(6), 4807–4815 (2021)

[39] Mohamed, M.M.: Clustering halal food consumers: A twitter sentiment
analysis. International Journal of Market Research 61(3), 320–337 (2019)
https://arxiv.org/abs/https://doi.org/10.1177/1470785318771451. https:
//doi.org/10.1177/1470785318771451

[40] Wang, A., Gao, X.: Multifunctional product marketing using social media
based on the variable-scale clustering. Tehniˇcki vjesnik 26(1), 193–200
(2019)

[41] Kingston, C., Nurse, J.R.C., Agraﬁotis, I., Milich, A.: Using semantic
clustering to support situation awareness on twitter: the case of world

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

37

views. Hum. centric Comput. Inf. Sci. 8, 22 (2018). https://doi.org/10.
1186/s13673-018-0145-6

[42] Curiskis, S.A., Drake, B., Osborn, T.R., Kennedy, P.J.: An evaluation of
document clustering and topic modelling in two online social networks:
Twitter and reddit. Inf. Process. Manag. 57(2), 102034 (2020). https:
//doi.org/10.1016/j.ipm.2019.04.002

[43] Bickel, S., Scheﬀer, T.: Multi-view clustering. In: Proceedings of the 4th
IEEE International Conference on Data Mining (ICDM 2004), pp. 19–26.
IEEE Computer Society, Brighton, UK (2004). https://doi.org/10.1109/
ICDM.2004.10095. https://doi.org/10.1109/ICDM.2004.10095

[44] de A.T. de Carvalho, F., Lechevallier, Y., Despeyroux, T., de Melo,
F.M.: In: Guillet, F., Pinaud, B., Venturini, G., Zighed, D.A. (eds.)
Multi-view Clustering on Relational Data, pp. 37–51. Springer, Cham
(2014). https://doi.org/10.1007/978-3-319-02999-3 3. https://doi.org/10.
1007/978-3-319-02999-3 3

[45] Chao, G., Sun, S., Bi, J.: A survey on multi-view clustering. CoRR

abs/1712.06246 (2017) https://arxiv.org/abs/1712.06246

[46] Yang, Y., Wang, H.: Multi-view clustering: A survey. Big Data Min. Anal.
1(2), 83–107 (2018). https://doi.org/10.26599/BDMA.2018.9020003

[47] Fu, L., Lin, P., Vasilakos, A.V., Wang, S.: An overview of recent multi-
view clustering. Neurocomputing 402, 148–161 (2020). https://doi.org/10.
1016/j.neucom.2020.02.104

[48] Kanaan-Izquierdo, S., Ziyatdinov, A., Perera-Lluna, A.: Multiview and mul-
tifeature spectral clustering using common eigenvectors. Pattern Recognit.
Lett. 102, 30–36 (2018). https://doi.org/10.1016/j.patrec.2017.12.011

[49] Rout, N., Mishra, D., Mallick, M.K.: Handling imbalanced data: A survey.
In: Reddy, M.S., Viswanath, K., K.M., S.P. (eds.) International Proceedings
on Advances in Soft Computing, Intelligent Systems and Applications, pp.
431–443. Springer, Singapore (2018)

[50] Ram´ırez-Gallego, S., Krawczyk, B., Garc´ıa, S., Wozniak, M., Herrera,
F.: A survey on data preprocessing for data stream mining: Current
status and future directions. Neurocomputing 239, 39–57 (2017). https:
//doi.org/10.1016/j.neucom.2017.01.078

[51] Pradha, S., Halgamuge, M.N., Vinh, N.T.Q.: Eﬀective text data prepro-
cessing technique for sentiment analysis in social media data. In: 11th
International Conference on Knowledge and Systems Engineering, KSE
2019, Da Nang, Vietnam, October 24-26, 2019, pp. 1–8. IEEE, ??? (2019).

Springer Nature 2021 LATEX template

38

Unsupervised Fine-grained Hate Speech Target Community Detection

https://doi.org/10.1109/KSE.2019.8919368. https://doi.org/10.1109/KSE.
2019.8919368

[52] Ollagnier, A., Williams, H.T.P.: Sequential transfer learning for event
detection and key sentence extraction. In: Wani, M.A., Luo, F., Li, X.A.,
Dou, D., Bonchi, F. (eds.) 19th IEEE International Conference on Machine
Learning and Applications, ICMLA 2020, pp. 1023–1027. IEEE, Miami,
FL, USA (2020). https://doi.org/10.1109/ICMLA51294.2020.00166. https:
//doi.org/10.1109/ICMLA51294.2020.00166

[53] Qiu, X., Sun, T., Xu, Y., Shao, Y., Dai, N., Huang, X.: Pre-trained models
for natural language processing: A survey. CoRR abs/2003.08271 (2020)
https://arxiv.org/abs/2003.08271

[54] Cer, D., Yang, Y., Kong, S., Hua, N., Limtiaco, N., John, R.S., Constant,
N., Guajardo-Cespedes, M., Yuan, S., Tar, C., Sung, Y., Strope, B.,
Kurzweil, R.: Universal sentence encoder. CoRR abs/1803.11175 (2018)
https://arxiv.org/abs/1803.11175

[55] Vijaymeena, M., Kavitha, K.: A survey on similarity measures in text
mining. Machine Learning and Applications: An International Journal
3(2), 19–28 (2016)

[56] Fortunato, S.: Community detection in graphs. Physics Reports 486(3),

75–174 (2010). https://doi.org/10.1016/j.physrep.2009.11.002

[57] Trendaﬁlov, N.T.: Stepwise estimation of common principal components.
Comput. Stat. Data Anal. 54(12), 3446–3457 (2010). https://doi.org/10.
1016/j.csda.2010.03.010

[58] MacQueen, J., et al.: Some methods for classiﬁcation and analysis of
multivariate observations. In: Proceedings of the Fifth Berkeley Symposium
on Mathematical Statistics and Probability, vol. 1, pp. 281–297 (1967).
Oakland, CA, USA

[59] Park, H., Jun, C.: A simple and fast algorithm for k-medoids clustering.
Expert Syst. Appl. 36(2), 3336–3341 (2009). https://doi.org/10.1016/j.
eswa.2008.01.039

[60] Ng, A.Y., Jordan, M.I., Weiss, Y.: On spectral clustering: Analysis and an
algorithm. In: Dietterich, T.G., Becker, S., Ghahramani, Z. (eds.) Advances
in Neural Information Processing Systems 14 [Neural Information Process-
ing Systems: Natural and Synthetic, NIPS 2001, pp. 849–856. MIT Press,
Vancouver, British Columbia, Canada (2001). https://proceedings.neurips.
cc/paper/2001/hash/801272ee79cfde7fa5960571fee36b9b-Abstract.html

[61] Manning, C., Raghavan, P., Sch¨utze, H.: Introduction to information

Springer Nature 2021 LATEX template

Unsupervised Fine-grained Hate Speech Target Community Detection

39

retrieval. Journal of the American Society for Information Science and
Technology 1, 496 (2008)

[62] Shapiro, S.S., Wilk, M.B.: An analysis of variance test for normality

(complete samples). Biometrika 52(3/4), 591–611 (1965)

[63] Levene, H.: Robust tests for equality of variances. Stanford University

Press, 278–292 (1960)

[64] Wilcoxon, F.: In: Kotz, S., Johnson, N.L. (eds.) Individual Compar-
isons by Ranking Methods, pp. 196–202. Springer, New York, NY (1992).
https://doi.org/10.1007/978-1-4612-4380-9 16. https://doi.org/10.1007/
978-1-4612-4380-9 16

[65] Milton, F.: The use of ranks to avoid the assumption of normality implicit
in the analysis of variance. Journal of the American Statistical Association
32(200), 675–701 (1937) https://arxiv.org/abs/https://www.tandfonline.
com/doi/pdf/10.1080/01621459.1937.10503522. https://doi.org/10.1080/
01621459.1937.10503522

[66] Nemenyi, P.: Distribution-free Multiple Comparisons. Princeton University,

??? (1963). https://books.google.fr/books?id=nhDMtgAACAAJ

