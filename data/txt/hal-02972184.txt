A Multilingual Evaluation for Online Hate Speech
Detection
Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, Serena Villata

To cite this version:

Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, Serena Villata. A Multilingual Eval-
uation for Online Hate Speech Detection. ACM Transactions on Internet Technology, 2020, 20 (2),
pp.1-22. ￿10.1145/3377323￿. ￿hal-02972184￿

HAL Id: hal-02972184

https://hal.science/hal-02972184

Submitted on 20 Oct 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

A Multilingual Evaluation for Online Hate
Speech Detection

Michele Corazza, Universit`a di Bologna, Bologna, Italy
Stefano Menini, Fondazione Bruno Kessler, Trento, Italy
Elena Cabrio, Universit´e Cˆote d’Azur, Inria, CNRS, I3S, France
Sara Tonelli, Fondazione Bruno Kessler, Trento, Italy
Serena Villata, Universit´e Cˆote d’Azur, Inria, CNRS, I3S, France

Abstract

The increasing popularity of social media platforms like Twitter and
Facebook has led to a rise in the presence of hate and aggressive speech on
these platforms. Despite the number of approaches recently proposed in
the Natural Language Processing research area for detecting these forms
of abusive language, the issue of identifying hate speech at scale is still an
unsolved problem. In this paper, we propose a robust neural architecture
which is shown to perform in a satisfactory way across diﬀerent languages,
namely English, Italian and German. We address an extensive analysis of
the obtained experimental results over the three languages to gain a better
understanding of the contribution of the diﬀerent components employed
in the system, both from the architecture point of view (i.e., Long Short
Term Memory, Gated Recurrent Unit, and bidirectional Long Short Term
Memory) and from the feature selection point of view (i.e., ngrams, social
network speciﬁc features, emotion lexica, emojis, word embeddings). To
address such in-depth analysis, we use three freely available datasets for
hate speech detection on social media on English, Italian and German.

1

Introduction

The use of social media platforms such as Twitter, Facebook and Instagram
has enormously increased the number of online social interactions, connecting
billions of users, favouring the exchange of opinions and giving visibility to ideas
that would otherwise be ignored by traditional media. However, this has led
also to an increase of attacks targeting speciﬁc groups of users based on their
religion, ethnicity or social status, and individuals often struggle to deal with
the consequences of such oﬀenses.

This problem aﬀects not only the victims of online abuse, but also stake-
holders such as governments and social media platforms. For example, Face-
book, Twitter, YouTube and Microsoft have recently signed a code of conduct1,

1http://ec.europa.eu/justice/fundamental-rights/files/hate_speech_code_of_

1

proposed by the European Union, pledging to review the majority of valid no-
tiﬁcations for removal of illegal hate speech in less than 24 hours.

Within the Natural Language Processing (NLP) community, there have been
several eﬀorts to deal with the problem of online hate speech detection, since the
computational analysis of language can be used to quickly identify oﬀenses and
ease the removal of abusive messages. Several workshops [61, 27] and evaluation
campaigns [26, 12, 66, 7, 68] have been recently organised to discuss existing
approaches to hate speech detection, propose shared tasks and foster the devel-
opment of benchmarks for system evaluation. These have led to the creation
of a number of datasets for hate speech detection in diﬀerent languages, that
have been shared within the NLP research community. Recent advances in deep
learning approaches to text classiﬁcation have then been applied also to deal
with this task, achieving for some languages state-of-the-art results [17, 29, 31].
These systems are usually tailored to deal with social media texts by apply-
ing pre-processing, using domain-speciﬁc embeddings, adding textual features,
etc. Given the number of conﬁgurations and external resources that have been
used by systems for hate speech detection, it is rather diﬃcult to understand
what makes a classiﬁer robust for the task, and to identify recommendations on
how to pre-process data, what kind of embeddings should be used, etc. This
is indeed the main contribution of the current paper: after identifying a deep
learning architecture that is rather stable and well-performing across diﬀerent
languages, we evaluate the endowments of several components that are usually
employed in the task, namely the type of embeddings, the use of additional
features (text-based or emotion-based), the role of hashtag normalisation and
that of emojis. We perform our comparative evaluation on English, Italian and
German, focusing on freely available Twitter datasets for hate speech detec-
tion. Our goal is to identify a set of recommendations to develop hate speech
detection systems, possibly going beyond language-speciﬁc diﬀerences.

The article is organised as follows: in Section 2 we present past work related
In Section 3, we describe the neural architecture
to hate speech detection.
adopted in our experiments, while in Section 4 we present both the datasets used
to train and test our classiﬁer, and the external resources fed to the system. In
Section 5, the experimental setup is presented, with details on the pre-processing
step and the selection of hyperparameters. Finally, Section 6 reports on the
evaluation results and discusses suggestions for the development of robust hate
speech detection systems. In Section 7, we summarise our ﬁndings.

NOTE : This paper contains examples of language which may be oﬀensive

to some readers. They do not represent the views of the authors.

conduct_en.pdf

2

2 Related work

2.1 Hate speech detection on English data

Given the well-acknowledged rise in the presence of toxic and abusive speech
on social media platforms like Twitter and Facebook, an increasing number of
approaches has been proposed to detect such a kind of messages in English. Au-
tomated systems for the detection of abusive language range from supervised
machine learning models built using a combination of manually crafted features
such as n-grams [67], syntactic features [47], and linguistic features [23], to more
recent neural networks that take word or character sequences from comments
and learn abusive patterns without the need for explicit feature engineering.
The recent trend of using neural network-based approaches has been particu-
larly evident for English, since several training datasets are available for this
language, enabling more data-hungry approaches.
Indeed, organisers of the
2019 Semeval task on Oﬀensive Language Identiﬁcation [68] report that 70% of
the participants adopt a deep learning approach. However, also simpler classi-
ﬁcation systems using logistic regression have been successfully applied to the
task [62, 22]. Among the neural network-based approaches, diﬀerent algorithms
have been presented, such as Convolutional Neural Network using pre-trained
word2vec embeddings [69], bi-LSTM with attention mechanism [1] and bidi-
rectional Gated Recurrent Unit network [40]. More recently, also the combina-
tion of diﬀerent neural newtorks, capturing both the message content and the
Twitter account metadata, has been proposed [29]. In a comparative study
of various learning models on the Hate and Abusive Speech on Twitter dataset
built by Founta et al. [30], Lee et al. [40] show that, in the classiﬁcation of tweets
as “normal”, “spam”, “hateful” and “abusive” a bidirectional Gated Recurrent
Unit network trained on word-level features is the most accurate model.
In-
stead, in the binary task of oﬀensive language detection, Liu et al. [41] achieve
the best performance at Semeval 2019 by ﬁne-tuning a bidirectional encoder
representation from transformer [24].

In this paper, we propose a robust neural classiﬁer for the hate speech binary
classiﬁcation task which is performing well across diﬀerent languages (English,
Italian and German), and we study the impact of each feature and component
on the results across these languages. Our recurrent neural architecture shares
some elements with the above approaches, namely the use of a Long Short Term
Memory and a Gated Recurrent Unit. Embeddings, textual and social network
speciﬁc features are employed. As in [38], we do not use metadata related to the
social media accounts. The obtained results are compared in a more detailed
way in Section 6.

2.2 Hate speech detection on languages diﬀerent from En-

glish

While most approaches to hate speech detection have been proposed for En-
glish, other systems have been developed to deal with the task in German,

3

Italian and Spanish, thanks to recent shared tasks. The 2018 GermEval Shared
Task on the Identiﬁcation of Oﬀensive Language 2 deals with the detection of of-
fensive comments from a set of German tweets. The tweets have to be classiﬁed
into the two classes oﬀense and other, where the oﬀense class covers abusive
language, insults, as well as profane statements. Diﬀerent classiﬁers are used
by the participants, ranging from traditional feature-based supervised learning
(i.e., SVMs for the top performing system TUWienKBS [48]) to the more re-
cent deep learning methods. Most top performing systems in both shared tasks
employed deep learning (e.g., spMMMP [60], uhhLT [63], SaarOﬀDe [25], Inri-
aFBK [19]). For example, SaarOﬀDe employs Recurrent Neural Networks and
Convolutional Neural Networks produced top scores, while other systems (e.g.,
spMMMP, uhhLT) employ transfer learning. The usage of ensemble classiﬁca-
tion seems to often improve the classiﬁcation approaches (e.g., Potsdam [54],
RuG [5], SaarOﬀDe, TUWienKBS, UdSW [64]). Concerning the features, sev-
eral systems include a combination of word embeddings, character n-grams and
some forms of (task-speciﬁc) lexicon. Both the HaUA and the UdSW systems
report that high performance scores can be achieved with a classiﬁer solely
relying on a lexicon.

In 2018, the ﬁrst Hate Speech Detection (HaSpeeDe) task for Italian has been
organized at EVALITA-20183. The task consists in automatically annotating
messages from Twitter and Facebook, with a boolean value indicating the pres-
ence (or not) of hate speech. Similar to Germeval 2018 submissions, also in this
case the participating systems adopt a wide range of approaches, including bi-
LSTM [39], SVM [53], ensemble classiﬁers [52, 4], RNN [28], CNN and GRU
[60]. The authors of the best-performing system, ItaliaNLP [17], experiment
with three diﬀerent classiﬁcation models: one based on linear SVM, another
one based on a 1-layer BiLSTM and a newly-introduced one based on a 2-layer
BiLSTM which exploits multi-task learning with additional data from the 2016
SENTIPOLC task4.

Concerning Spanish, the IberEval 2018 edition5 has proposed the Aggres-
siveness Detection task [13] applied to Mexican Spanish, aiming at providing
a classiﬁcation of aggressive / non-aggressive tweets. A variety of systems is
proposed, exploiting content-based (bag of words, word n-grams, term vectors,
dictionary words, slang words) and stylistic-based features (frequencies, punc-
tuation, POS, Twitter speciﬁc elements). Most of the systems rely on neural
networks (CNN, LSTM and others). The top ranked team was INGEOTEC [32]:
the system is based on MicroT, a text classiﬁcation approach supported by a
lexicon-based model that takes into account the presence of aggressive and af-
fective words, and a model based on the Fasttext representation of texts. More
recently, a task for the detection of hate speech against immigrants and women
on Twitter has been organised at Semeval 2019 [7], providing an English and

2https://www.oeaw.ac.at/fileadmin/subsites/academiaecorpora/PDF/GermEval2018_

Proceedings.pdf

3http://www.evalita.it/2018
4http://www.di.unito.it/~tutreeb/sentipolc-evalita16/index.html
5https://sites.google.com/view/ibereval-2018

4

si

xe

xi

RNN

yi

si−1

xn

⊕

x1

⊕
. . .

Figure 1: The modular neural architecture

Spanish dataset annotated according to the same guidelines. While for both
languages a number of neural network approaches has been proposed, the best
systems for hateful content detection still rely on SVM and embedding-based
features [37, 50, 2].

Looking at the descriptions of the systems participating in the above tasks,
as well as at most recent hate speech detection classiﬁers for English, we ob-
serve that deep learning approaches usually share a number of features, such
as word embeddings, the use of emotion or sentiment lexica, as well as speciﬁc
pre-processing steps. Many exploit also other features related to the tweets
(e.g. message length, punctuation marks, etc.). Nevertheless, more emphasis is
usually put on the architecture, and no insight is given into the role played by
variants of the above features and by the selected pre-processing strategy. Also,
no attempt to understand diﬀerences across diﬀerent languages has been made.
This motivates the experiments presented in the remainder of this paper.

3 Classiﬁcation framework

Since our goal is to compare the eﬀect of various features, word embeddings and
pre-processing techniques on hate speech detection, we use a modular neural
architecture for binary classiﬁcation that is able to support both word-level and
message-level features. The components are chosen to support the processing
of social-media speciﬁc language. The neural architecture and the features are
detailed in the following subsections.

3.1 Modular Neural Architecture

We use a modular neural architecture (see Figure 1) in Keras [15]. The ar-
chitecture that constitutes the base for all the diﬀerent models uses a single
feed-forward hidden layer of 100 neurons, with a ReLu activation and a single
output with a sigmoid activation. The loss used to train the model is binary
cross-entropy. We choose this particular architecture because we used it to par-
ticipate to two shared tasks for hate speech detection, EVALITA HaSpeeDe
2018 [18] for Italian and Germeval 2018 [19] for German, and it proved to be

5

eﬀective and robust for both languages, also across diﬀerent social media plat-
forms [20]. In particular, in our original submissions the same architecture was
ranked fourth in the Twitter EVALITA subtask (−1.56 F1 compared to the ﬁrst
ranked) and seventh in the Germeval coarse-grained classiﬁcation task (−2.52
F1 from the top-ranked one).

The architecture is built to support both word-level (i.e. embeddings) and
tweet-level features. In particular, we use a recurrent layer to learn an encoding
(xn in the Figure) derived from word embeddings, obtained as the output of
the recurrent layer at the last timestep. This encoding gets then concatenated
with the other selected features, obtaining a vector of tweet-level features.

Since the models derived from using diﬀerent features are diﬀerent both in
terms of number of parameters and in terms of layers, we decided to keep the
size of the hidden layer ﬁxed. This allows us to compare diﬀerent features, as
the latent representation learned by the hidden layer that is ultimately used
to classify the tweets has the same size regardless of the number and kind of
features.

More formally, given an input represented as the set of features X = {xj|xj ∈
Xm}, where XM is the set of all features supported by a model M (see Section
3.2) and s is the sum of the dimensions of all the features, we compute a function:

M (X) = s(WoH(X) + bo) Wo ∈ R1×100 H(X) ∈ R100

bo ∈ R1

s(X) = (σ(x1), . . . , σ(xn)) x ∈ Rn

σ(x) =

1
1 + e−x

where Wo and bo are the learned weights for the output layer and σ(x) is the
sigmoid activation function (note that in all the models we used n = 1 as we
only have one binary output), and:

H(X) = g(WhC(X) + bh) Wh ∈ R100×s C(X) ∈ Rs

bh ∈ R100

g(X) = (f (x1), . . . , f (xn)) x ∈ Rn
f (x) = max(0, x) x ∈ R

where H(X) represents the application of a hidden layer of size 100 and learned
weights Wh and bh and g(x) is the ReLU activation function. Additionally:

C(X) =

(cid:77)

R(xi)

xi∈X
where (cid:76) denotes the concatenation of all vectors along their axes. For example,
if we have a set of vectors X = [x1, x2, x3], then:

Finally:

xi ∈ Ra+b+c x1 ∈ Ra, x2 ∈ Rb, x3 ∈ Rc

(cid:77)

xi∈X

R(x) =

(cid:40)

x
RN N (x)

if x is a tweet-level feature
if x is a word-level feature

6

where RNN is the function returning the output by a recurrent layer at the last
timestep.

3.2 Features

In our experiments, we use the following features, with the goal of evaluating
their impact on a hate speech detection model:

• Word Embeddings (xe in Figure 1): multiple word embeddings from
various sources have been tested (for a full description of the diﬀerent
embeddings see Section 4.2). We evaluate in particular the contribution
of word embeddings extracted from social media data, therefore belong-
ing to the speciﬁc domain of our classiﬁcation task, compared with the
performance obtained using generic embedding spaces, like Fasttext [11],
which are widely used across diﬀerent NLP tasks because of their good
coverage.

• Emoji embeddings: emojis are a peculiar element of social media texts.
They are often used to emphasize or reverse the literal meaning of a short
message, for example in ironic or sarcastic tweets [36]. It is therefore very
important for hate speech detection to understand which is the best way
to represent them and to include them in the embedding space. We com-
i) we
pare diﬀerent ways to embed emoji information in our classiﬁer:
use embedding spaces created from social media data, where each emoji
is also represented through a word embedding, or ii) in case of generic
embedding spaces, where emojis are not present, we include emoji em-
beddings through the alignment of diﬀerent spaces following the approach
presented in [58], or iii) in order to cope with the low coverage of emojis,
they are replaced by their description in plain text as suggested in [56].

• Ngrams: unigrams (x1 in Figure 1) and bigrams derived from the tweets
are also included as features. We ﬁrst tokenize and lemmatize the tweets
by using Spacy [35], then normalize the tweet-level ngram occurrence vec-
tor by using tf-idf. Our intuition is that these features should capture
lexical similarities between training and test data, therefore they should
be predictive when training and test set deal with the same type of of-
fenses. Higher-level ngrams are not considered, as we expect them to be
very sparse especially in social media, where tweets do not follow standard
writing conventions.

• Social-network speciﬁc features: The character limit imposed by some
social media platforms like Twitter aﬀects the style in which messages are
written: function words tend to be skipped, texts are very concise while
punctuation and uppercase words are used to convey eﬀective messages
despite their brevity. Therefore, all these linguistic indicators can be used
to identify the presence of hateful messages. We consider in particular the
number of hashtags and mentions, the number of exclamation and ques-
tion marks, the number of emojis, the number of words that are written

7

in uppercase at the tweet-level. These features are then normalized by
subtracting their mean and dividing them by their standard deviation.

• Emotion lexica: several emotion lexica have been (manually or automat-
ically) created and used in classiﬁcation tasks to represent the emotional
content of a message [45, 44, 9, 59]. While the importance of emotion infor-
mation to hate speech detection may seem evident [3], it is also true that an
embedding space which is large and representative enough of the domain
may make additional emotion features redundant. We therefore evaluate
the contribution of emotion information using two freely available, multi-
lingual emotion lexica, namely EmoLex and Hurtlex. Emolex [45, 44] is a
large list of English words and their associations with eight basic emotions
(anger, fear, anticipation, trust, surprise, sadness, joy, and disgust) and
two sentiments (negative and positive), manually annotated with Ama-
zon’s Mechanical Turk. The creators of the lexicon have additionally
made available a multilingual version of the resource, that was created
by translating each word with Google translate in 2017. We therefore use
the German and Italian translations as well as the English one. Using
EmoLex, we extract two sentiment-related features and eight emotion-
related features for each tweet by summing all the sentiment and emotion
scores assigned to the words in a tweet and normalizing them by using
tf-idf. The second resource, i.e., Hurtlex [9], is a multilingual lexicon of
hate words created starting from the Italian hate lexicon developed by
the linguist Tullio De Mauro, organized in 17 categories. It has been ex-
panded through the link to available synset-based computational lexical
resources such as MultiWordNet [51] and Babelnet [46], and evolved in
a multilingual perspective by semi-automatic translation and expert an-
notation. Since Hurtlex may contain the same word multiple times with
diﬀerent Part-of-Speech tags, we performed a union operation over the
categories in order to represent all the categories that a word can belong
to, independently of the POS. Using HurtLex, we assign with the same
strategy a score for negative stereotypes, one for hate words and slurs and
one for other insults to each tweet.

4 Data and linguistic resources

In the following, we present the datasets used to train and test our system for
English, Italian and German and their annotations (Section 4.1). Then, we
describe the word embeddings (Section 4.2) we have used in our experiments.

4.1 Datasets

English We use the dataset described in [62], containing 16k English tweets
manually annotated for hate speech. More precisely, 1,924 are annotated as
containing racism, 3,082 as containing sexism, while 10,884 tweets are annotated
as not containing oﬀensive language. We merge the sexist and racist tweets in

8

a single class, so that 5,006 tweets are considered as positive instances of hate
speech, as in Example 1.

1. Annotation: hateful.

Since 1/3 of all #Islam believes that people who leave the religion should
be murdered where are the moderate Muslim.

Italian We use the Twitter dataset released for the HaSpeeDe (Hate Speech
Detection) shared task organized at Evalita 2018, the evaluation campaign for
NLP and speech processing tools for Italian6. This dataset includes a total
amount of 4,000 tweets [12], comprising for each tweet the respective annotation,
as can be seen in Example 2. The two classes considered in the annotation are
“hateful post” or “not”.

2. Annotation: hateful.

altro che profughi? sono zavorre e tutti uomini (EN: Are they really
refugees? they are ballast and all men).

German We use the dataset distributed for the shared task on the Identiﬁca-
tion of Oﬀensive Language organized at Germeval 2018, a workshop in a series
of shared tasks on German processing7. The dataset provided for task 1, where
oﬀensive comments are to be detected from a set of German tweets (binary
classiﬁcation), consists of 5,009 German tweets manually annotated at the mes-
sage level [66] with the labels “oﬀense” (abusive language, insults, and profane
statements) and “other” (i.e. not oﬀensive). More speciﬁcally, 1,688 messages
are tagged as “oﬀense” (see Example 3), while 3,321 messages as “other”.

3. Annotation: Oﬀense.

@Ralf Stegner Oman Ralle..dich mag ja immer noch keiner. Du willst
das die Hetze gegen dich aufhort? Geh in Rente und verzichte auf die
1/2deiner Pension (EN: @Ralf Stegner Oman Ralle... still, nobody likes
you. You want to stop hate against you? Retire and give up half of your
pension).

Table 1 summarizes the main statistics on the datasets. The reported val-
ues show that, although the datasets have diﬀerent sizes, the distribution be-
tween positive and negative examples is similar. We also manually investigated
data samples and the annotation schemes of the English, German and Italian
datasets. Although the developers of the English and the Italian corpus focus on
hate speech, while the Germeval organisers claim to target oﬀensive language,
the kind of messages they annotate as belonging to their respective ‘positive’
class largely overlap. The targets are diﬀerent, i.e. the Italian messages focus on
immigrants, Muslim and Roma, the English ones on sexist and racial oﬀenses,
while the German one has no speciﬁc targets, and includes both oﬀensive mes-
sags towards groups and towards individuals. However, the types of oﬀenses,

6http://www.di.unito.it/~tutreeb/haspeede-evalita18
7https://www.oeaw.ac.at/ac/konvens2018/workshop/

9

Dataset # hate speech/oﬀensive (%) # other (%) # total
16,000
English
4,000
Italian
5,009
German

10,884 (68%)
2,704 (68%)
3,321 (66%)

5,006 (32%)
1,296 (32%)
1,688 (34%)

Table 1: Statistics on the datasets

both explicit and implicit, including sarcastic messages, rhetorical questions and
false claims based on prejudices make them in our view comparable. The only
diﬀerence is the set of messages labeled as ‘Profanity’ and included among the
‘Oﬀensive’ ones in the German dataset, which covers slurs without a speciﬁc
target. However, they account only for 1.4% messages in this training set.

4.2 Word Embeddings

In our experiments we test several embeddings, with the goal to compare generic
with social media-speciﬁc ones.
In order to have a high coverage of emojis,
we also experiment with aligned embedding spaces obtained by aligning the
English, Italian and German ones. Another element we take into account is the
access to the binary Fasttext model that originates the embedding space. When
using that binary model, it is possible to greatly mitigate the problem of out-of-
vocabulary words, since the system is able to provide an embedding for unknown
words by using subword unit information [42]. The binary model is often made
available together with the standard model when pre-trained embeddings are
released. When available, we always use this version. The tested embeddings,
summarised in Table 2, are the following:

• Fasttext embeddings for German and Italian: we use embedding
spaces obtained directly from the Fasttext website8 for German and Ital-
ian.
In particular, we use the Italian and German embeddings trained
on Common Crawl and Wikipedia [33] with size 300. A binary Fasttext
model is also available and was therefore used;

• English Fasttext Crawl embeddings: English embeddings trained by
Fasttext9 on Common Crawl, with an embedding size of 300. A binary
Fasttext model is provided;

• English Fasttext News embeddings: English embeddings trained on
Wikipedia 2017 using subword information, UMBC web base corpus and
statmt.org and released by Fasttext 10, with an embedding size of 300.
The available binary Fasttext model was used;

• Italian Twitter embeddings: we trained Fasttext embeddings from a
sample of Italian tweets [8], with embedding size of 300. We used the
binary version of the model;

8https://fasttext.cc/docs/en/crawl-vectors.html
9https://fasttext.cc/docs/en/english-vectors.html
10https://fasttext.cc/docs/en/english-vectors.html

10

• German Twitter embeddings: trained by Spinning Bytes11 from a
sample of German tweets [16]. We used the model with embeddings of
size 300. A binary Fasttext model was not provided, we therefore used
the word-based version;

• English Twitter embeddings: English Fasttext embeddings from Spin-
ning Bytes12, trained on an English Twitter sample [16] with an embed-
ding size of 200. Since a binary Fasttext model was not provided, we used
the word-based version;

• Aligned embeddings: since Fasttext embeddings for Italian and Ger-
man do not contain emojis, we extend them by aligning them with an
English embedding space containing emojis [6], following the alignment
approach presented in [57]. All embeddings and the resulting aligned
spaces have a size of 300.

EMBEDDINGS

LANGUAGE ALGORITHM SIZE

Fasttext En CCrawl

Fasttext En News

Twitter English

Fasttext It CCrawl & Wiki

Twitter Italian

Fasttext De CCrawl & Wiki

Twitter German

Aligned

EN

EN

EN

IT

IT

DE

DE

EN,IT,DE

Fasttext

Fasttext

Fasttext

Fasttext

Fasttext

Fasttext

Fasttext

Fasttext

300

300

200

300

300

300

300

300

FASTTEXT
BINARY MODEL
YES

YES

NO

YES

YES

YES

NO

NO

Table 2: Overview of the diﬀerent embeddings used in our experiments

In summary, we were able to use a binary model for all the oﬃcial Fasttext
monolingual datasets and the Italian Twitter embeddings that we trained. For
the remaining embedding spaces, we only had access to a dictionary-like struc-
ture, that contains the embedding for each word in the vocabulary.

5 Experiments

In this section, we detail the setup of our experiments,
including the pre-
processing step, the selection of hyperparameters and the combination of fea-
tures and conﬁgurations tested for each language.

5.1 Preprocessing

Since hashtags, user mentions, links to external media and emojis are common
in social media interactions, it is necessary to carefully preprocess the data,

11https://www.spinningbytes.com/resources/wordembeddings/
12https://www.spinningbytes.com/resources/wordembeddings/

11

in order to normalize the text as much as possible while retaining all relevant
semantic information. For this reason, we ﬁrst replace URLs with the word
“url” and “@” user mentions with “username” by using regular expressions.
Since hashtags often provide important semantic content, we wanted to test
how splitting them into single words would impact on the performance of the
classiﬁer. To this end, we use the Ekphrasis tool [10] to do hashtag splitting
and evaluate the classiﬁer performance with and without splitting. Since the
aforementioned tool only supports English, it has been adapted to Italian and
German by using language-speciﬁc Google ngrams.13

Another pre-processing step we evaluate in our experiments is the description
of emojis in plain text, that proved to beneﬁt tweet classiﬁcation [56] but was
evaluated so far only on English. In order to map each emoji with a description,
we ﬁrst retrieve an emoji list using the dedicated Python library14 and replace
each emoji with its English description according to the website of the Unicode
consortium15. We then translate the descriptions using Google Translate and
ﬁx any mistakes by hand.
In this way we create a list of emojis with the
corresponding transcription in three languages (available at https://github.
com/dhfbk/emoji-transcriptions).

5.2 Hyperparameters

In order to keep our setting robust across languages, we base our model on a
conﬁguration that performed consistently well on all subtasks of Evalita hate
speech detection [18], both on Facebook and on Twitter data, even if it was not
the best performing conﬁguration on the single tasks. In particular, our model
uses no dropout and no batch normalization on the outputs of the hidden layer.
Instead, a dropout on the recurrent units of the recurrent layers is used. We
select a batch size of 32 for training and a size of 200 for the output (and hidden
states) of the recurrent layers. We also test the impact of diﬀerent recurrent
layers, namely long short-memory (LSTM) [34], gated recurrent unit (GRU)
[14] and bidirectional LSTM (BiLSTM) [55].

5.3 Settings

In our experiments, we perform a series of tests on the aforementioned modular
neural model, concerning the following aspects:

• For each language, we test the corresponding embeddings presented in

Section 4.2.

• We test all possible combination of features: embeddings, unigrams, bi-

grams, social features, EmoLex and Hurtlex.

13http://storage.googleapis.com/books/ngrams/books/datasetsv2.html
14https://github.com/carpedm20/emoji
15https://www.unicode.org/emoji/charts/full-emoji-list.html

12

• We test three possible recurrent layers, namely LSTM, GRU and Bidirec-

tional LSTM.

• We train models with and without hashtag splitting.

• We test models that replace emojis with their description and models that
do not. For Italian and German Fasttext embeddings that do not contain
emojis, we also test the model performance after using emoji embeddings
resulting from alignment with an English embedding space (see details in
Section 4.2)

Overall, we compare 1,800 possible conﬁgurations for English, 1,080 for Ital-
ian and 1,224 for German. The diﬀerence is due to the availability of more
embedding spaces for English, which increase the amount of possible settings
and feature combinations to be tested.

Concerning the dataset splits into training and test instances, for the English
dataset - since no standardized split is provided - we randomly selected 60% of
the dataset for training, 20% for validation and 20% for testing. Since we want
our experiments to be reproducible, we use the train test split function from
scikit-learn [49] to shuﬄe and split the dataset 60%/40%. The remaining 40%
was then split in half to obtain the validation and test set, respectively. We use
42 as a seed value for the random number generator used for shuﬄing.

The German dataset was already randomly split by the GermEval task or-
ganizers into training and test set, containing 5,009 and 3,532 messages respec-
tively. For our experiments we keep the same split as proposed in the chal-
lenge, but we use 20% of the training set as validation set, obtained by invoking
train test split from scikit learn with 42 as seed. Similarly, the Italian dataset
was randomly split by the HaSpeeDe task organizers into training and test set
of 3,000 and 1,000 messages respectively. Again, in our experiments we keep
the same split as proposed in the challenge, but we used 20% of the training set
as validation set applying the same function as for the German dataset.

For each language, the validation test is used to evaluate the classiﬁer per-
formance over 20 training epochs and select the best performing model in terms
of macro averaged F1 score. The selected model is then used to evaluate per-
formance on the test set.

6 Evaluation

In this section, we report a selection of the most relevant results from the pool
of settings described in Section 5.3. In particular, the ﬁrst row of Table 3, 4
and 5 reports the best run over all the conﬁgurations tested for English, Italian
and German respectively, while the other rows show how the best performance
changes when modifying one parameter at a time. We also provide an evaluation
of the eﬀectiveness of diﬀerent conﬁgurations by comparing the three languages
after downsampling the training sets. As comparison we provide a baseline
obtained running a SVM (linear kernel) with a bag of word approach using
tf-idf as weight.

13

6.1 Multilingual evaluation on the complete datasets

For English, the best result (0.823 F1) is obtained using an LSTM network
and the Fasttext embeddings trained on Common Crawl. Table 3 shows how
adding or removing single features from the best conﬁguration aﬀects the result:
adding unigram and bigram-based features to the classiﬁer leads to the largest
drop in performance, while changing other features the impact is lower. This
conﬁrms the ﬁndings in [62], in which character n-grams outperform word n-
grams in the classiﬁcation of racial, sexist and not-oﬀensive tweets. Overall we
ﬁnd that, although the best result is obtained using an LSTM network, replacing
LSTM with Bi-LSTM keeping the same features achieves similar results, with
a diﬀerence of F1 of 0.1-0.2% F1. This shows that having both forward and
backward information when dealing with tweets is probably not needed because
of the limited length of the messages. The use of hashtag normalization to split
the hashtags into words improves the system performance in every conﬁguration,
increasing the coverage of the embeddings. Overall, the coverage of Fasttext
embeddings trained on CommonCrawl is suﬃcient to deal with Twitter data,
therefore adding speciﬁc embeddings or pre-processing them is not necessary.
Also, the SVM baseline suﬀers from lower recall compared to the best neural
conﬁguration, especially when dealing with the hate category, that has less
training instances.

14

1
F

R

P

1
F

G
V
A

G
V
A

G
V
A

E
T
A
H

O
N
1
F

E
T
A
H

.

H
S
A
H

T
I
L
P
S

3
2
8
.
0

5
2
8
.
0

0
2
8
.
0

2
1
8
.
0

4
1
8
.
0

1
1
8
.
0

1
2
8
.
0

1
2
8
.
0

1
2
8
.
0

0
2
8
.
0

3
2
8
.
0

7
1
8
.
0

9
1
8
.
0

5
1
8
.
0

3
2
8
.
0

8
1
8
.
0

7
1
8
.
0

0
2
8
.
0

4
1
8
.
0

0
1
8
.
0

8
1
8
.
0

2
1
8
.
0

9
0
8
.
0

6
1
8
.
0

0
0
8
.
0

0
9
7
.
0

5
1
8
.
0

1
9
7
.
0

7
8
7
.
0

6
9
7
.
0

4
8
7
.
0

3
7
7
.
0

0
0
8
.
0

8
7
7
.
0

3
6
7
.
0

8
0
8
.
0

0
6
7
.
0

5
4
7
.
0

6
5
7
.
0

7
5
7
.
0

1
5
7
.
0

1
5
7
.
0

4
4
7
.
0

2
4
7
.
0

9
1
7
.
0

1
1
7
.
0

4
9
6
.
0

2
8
6
.
0

5
8
8
.
0

9
7
8
.
0

6
8
8
.
0

3
8
8
.
0

7
8
8
.
0

5
8
8
.
0

4
8
8
.
0

3
8
8
.
0

1
8
8
.
0

1
7
8
.
0

3
7
8
.
0

5
7
8
.
0

S
E
Y

O
N

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

K
R
O
W
T
E
N

I
J
O
M
E

S
N
O
I
T
O
M
E

L
A
I
C
O
S

S
T
A
E
F
T
X
E
T

.

D
E
B
M
E

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

.
r
c
s
n
a
r
t

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

X
E
L
O
M
E

X
E
L
O
M
E

X
E
L
T
R
U
H

O
N

O
N

O
N

O
N

O
N

O
N

O
N

S
E
Y

S
E
Y

O
N

O
N

X
E
L
T
R
U
H

S
E
Y

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

l

w
a
r
C
C
t
x
e
t
t
s
a
F

O
N

O
N

O
N

O
N

O
N

O
N

i

i

b
+
n
u
+
b
m
e

l

w
a
r
C
C
t
x
e
t
t
s
a
F

i

n
u
+
b
m
e

l

w
a
r
C
C
t
x
e
t
t
s
a
F

i

b
+
b
m
e

l

w
a
r
C
C
t
x
e
t
t
s
a
F

e
n

i
l
e
s
a
b
M
V
S

f
o

g
n
i
s
s
e
c
o
r
p

c
ﬁ
i
c
e
p
s

o
n

t
a
h
t

s
n
a
e
m

’

O
N

‘

=

I
J
O
M
E

.
)

G
V
A

o
r
c
a
M

(

a
t
a
d

h
s
i
l
g
n
E

n
o

n
o
i
t
a
r
u
g
ﬁ
n
o
c

g
n
i
m
r
o
f
r
e
p

t
s
e
B

:
3

e
l
b
a
T

d
e
i
l
p
p
a

s
a
w

i
j
o
m
e

15

For Italian, the best result (0.805 F1) is obtained with a conﬁguration us-
ing a LSTM network and the word embeddings we trained on a large corpus of
Italian tweets. In Table 4 we show to what extent the diﬀerent features aﬀect
the performance obtained with the best conﬁguration. On Italian, diﬀerently
from English and German, the use of unigrams in addition to word embeddings
is beneﬁcial to the classiﬁer performance. The best result is obtained using the
emoji transcription, but their impact is not signiﬁcant (0.805 F1 using them
vs. 0.804 not using them). The same trend can be found also with diﬀerent
conﬁgurations not reported in the table. Considering all runs with all conﬁg-
urations, the use of embeddings trained on the same domain of the dataset
(Italian Tweets) always leads to better results compared with the use of more
generic embeddings as the ones from Fasttext (trained on Common Crawl and
Wikipedia). Almost all the best performing conﬁgurations take advantage of
the use of hashtag splitting. BiLSTM performs generally worse than LSTM.
Like in the English evaluation, the SVM baseline achieves a remarkably lower
performance on the hate class, and shows recall issues.

16

1
F

R

P

1
F

G
V
A

G
V
A

G
V
A

E
T
A
H

O
N
1
F

E
T
A
H

.

H
S
A
H

T
I
L
P
S

K
R
O
W
T
E
N

I
J
O
M
E

S
N
O
I
T
O
M
E

L
A
I
C
O
S

S
T
A
E
F
T
X
E
T

.

D
E
B
M
E

5
0
8
.
0

6
0
8
.
0

3
0
8
.
0

5
0
8
.
0

6
0
8
.
0

3
0
8
.
0

4
0
8
.
0

5
0
8
.
0

2
0
8
.
0

7
9
7
.
0

0
0
8
.
0

5
9
7
.
0

4
9
7
.
0

0
0
8
.
0

9
8
7
.
0

3
9
7
.
0

6
9
7
.
0

0
9
7
.
0

1
9
7
.
0

2
9
7
.
0

0
9
7
.
0

8
8
7
.
0

4
9
7
.
0

4
8
7
.
0

9
7
7
.
0

5
7
7
.
0

5
8
7
.
0

4
7
7
.
0

8
5
7
.
0

9
0
8
.
0

0
6
7
.
0

7
4
7
.
0

3
8
7
.
0

8
6
7
.
0

1
7
7
.
0

6
6
7
.
0

4
2
7
.
0

7
0
7
.
0

1
8
7
.
0

6
3
7
.
0

7
3
7
.
0

6
3
7
.
0

8
2
7
.
0

7
2
7
.
0

3
2
7
.
0

8
1
7
.
0

9
1
7
.
0

7
9
6
.
0

6
7
6
.
0

0
6
6
.
0

0
9
6
.
0

3
9
5
.
0

7
6
8
.
0

2
7
8
.
0

1
7
8
.
0

7
6
8
.
0

1
6
8
.
0

3
6
8
.
0

4
6
8
.
0

8
5
8
.
0

2
6
8
.
0

2
7
8
.
0

0
6
8
.
0

7
4
8
.
0

5
5
8
.
0

S
E
Y

S
E
Y

S
E
Y

S
E
Y

O
N

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

S
E
Y

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

m

t
s
l

n
o
i
t
p
i
r
c
s
n
a
r
t

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

O
N

O
N

O
N

n
o
i
t
p
i
r
c
s
n
a
r
t

X
E
L
T
R
U
H

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

n
o
i
t
p
i
r
c
s
n
a
r
t

X
E
L
T
R
U
H

n
o
i
t
p
i
r
c
s
n
a
r
t

X
E
L
O
M
E

n
o
i
t
p
i
r
c
s
n
a
r
t

X
E
L
O
M
E

n
o
i
t
p
i
r
c
s
n
a
r
t

i

s
g
n
d
d
e
b
m
e

n
o
i
t
p
i
r
c
s
n
a
r
t

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

O
N

O
N

O
N

O
N

S
E
Y

O
N

O
N

O
N

S
E
Y

S
E
Y

O
N

O
N

O
N

O
N

O
N

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

n
u
+
b
m
e

i

b
+
b
m
e

b
m
e

i

i

b
+
n
u
+
b
m
e

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

r
e
t
t
i
w
T

d
e
n
g
i
l
a

r
e
t
t
i
w
T

r
e
t
t
i
w
T

e
n

i
l
e
s
a
b
M
V
S

.
)

G
V
A
o
r
c
a
M

(

a
t
a
d

n
a
i
l
a
t
I

n
o

n
o
i
t
a
r
u
g
ﬁ
n
o
c

i

g
n
m
r
o
f
r
e
p

t
s
e
B

:
4

e
l

b
a
T

17

Table 5 reports the results obtained on German data. The best result is
achieved with a GRU network, using the standard Fasttext embeddings (trained
on Common Crawl and Wikipedia). Similar to English, adopting unigrams and
bigrams as feature leads to a decrease in performance (0.05 points F1). Con-
sidering all the experiments run on German data, the results conﬁrm that also
for this language emoji transcriptions perform better than the emoji vectors
obtained through multilingual alignment, but for the best conﬁguration no spe-
ciﬁc emoji processing is needed. Hashtag splitting, which is included in the
best performing conﬁguration for English and Italian, is instead not beneﬁcial
to German tweet classiﬁcation. Our intuition is that, since German is rich in
compound words, Ekphrasis hashtag normalization approach based on Google
n-grams tends to split terms also when it is not needed. Although social and
emotion features are not used in the best output, they appear to help in most
of the other conﬁgurations. Also for this language, the SVM baseline achieves
a lower recall and less accurate classiﬁcation on the hate speech class than the
neural model.

18

1
F

R

P

1
F

G
V
A

G
V
A

G
V
A

E
T
A
H

O
N
1
F

E
T
A
H

.

H
S
A
H

T
I
L
P
S

K
R
O
W
T
E
N

I
J
O
M
E

S
N
O
I
T
O
M
E

L
A
I
C
O
S

S
T
A
E
F
T
X
E
T

.

D
E
B
M
E

8
5
7
.
0

2
6
7
.
0

4
5
7
.
0

1
4
7
.
0

0
3
7
.
0

5
6
7
.
0

1
4
7
.
0

2
3
7
.
0

8
5
7
.
0

4
4
7
.
0

8
3
7
.
0

2
5
7
.
0

3
5
7
.
0

1
5
7
.
0

5
5
7
.
0

4
5
7
.
0

1
5
7
.
0

9
5
7
.
0

7
4
7
.
0

1
4
7
.
0

5
5
7
.
0

8
4
7
.
0

0
4
7
.
0

0
6
7
.
0

8
4
7
.
0

9
3
7
.
0

4
6
7
.
0

6
0
7
.
0

3
0
7
.
0

0
1
7
.
0

6
0
7
.
0

7
9
6
.
0

6
2
7
.
0

2
0
7
.
0

4
9
6
.
0

2
2
7
.
0

1
9
5
.
0

7
9
5
.
0

2
9
6
.
0

6
8
6
.
0

0
4
6
.
0

4
4
6
.
0

2
5
6
.
0

1
7
6
.
0

1
7
6
.
0

7
5
6
.
0

5
5
6
.
0

4
5
6
.
0

6
0
6
.
0

0
9
5
.
0

6
8
5
.
0

4
7
3
.
0

9
2
8
.
0

3
4
8
.
0

9
3
8
.
0

5
3
8
.
0

4
3
8
.
0

6
3
8
.
0

6
3
8
.
0

0
4
8
.
0

3
4
8
.
0

6
0
8
.
0

1
2
8
.
0

9
1
8
.
0

7
0
8
.
0

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

S
E
Y

O
N

U
R
G

U
R
G

O
N

O
N

U
R
G

n
o
i
t
p
i
r
c
s
n
a
r
t

i

s
g
n
d
d
e
b
m
e

O
N

O
N

O
N

O
N

U
R
G

U
R
G

U
R
G

U
R
G

U
R
G

U
R
G

U
R
G

U
R
G

U
R
G

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

X
E
L
T
R
U
H

O
N

X
E
L
O
M
E

X
E
L
O
M
E

X
E
L
T
R
U
H

O
N

O
N

O
N

O
N

O
N

O
N

O
N

S
E
Y

S
E
Y

S
E
Y

O
N

O
N

O
N

O
N

O
N

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

b
m
e

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

d
e
n
g
i
l
a

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

t
x
e
t
t
s
a
F

i

i

b
+
n
u
+
b
m
e

t
x
e
t
t
s
a
F

i

n
u
+
b
m
e

t
x
e
t
t
s
a
F

i

b
+
b
m
e

t
x
e
t
t
s
a
F

e
n

i
l
e
s
a
b
M
V
S

.
)

G
V
A
o
r
c
a
M

(

a
t
a
d

n
a
m
r
e
G
n
o

n
o
i
t
a
r
u
g
ﬁ
n
o
c

i

g
n
m
r
o
f
r
e
p

t
s
e
B

:
5

e
l
b
a
T

19

Beside the aforementioned experiments, we perform an additional evalua-
tion using a character-based RNN. Indeed, character-based representations have
been recently used in several NLP tasks including abusive language detection
[43] with promising results thanks to their ability to eﬀectively handle rare and
unseen words. We use the best performing systems for the three languages, re-
placing word-based RNN with a character-based one. In order to learn a dense
representation for characters, we used a learned embedding layer with size 10.
The results of this set of experiments are reported in Table 6, and show that us-
ing a character-based RNN the performance of the system drops signiﬁcantly in
all three languages compared to word-based RNNs, probably because Fasttext
embeddings already account for subword information. We therefore decided not
to perform further tests with this conﬁguration.

20

1
F

R

P

1
F

G
V
A

G
V
A

G
V
A

E
T
A
H

O
N
1
F

E
T
A
H

.

H
S
A
H

T
I
L
P
S

5
5
6
.
0

5
4
6
.
0

7
9
6
.
0

2
9
6
.
0

7
7
6
.
0

3
6
7
.
0

1
9
4
.
0

4
2
5
.
0

5
5
5
.
0

9
8
4
.
0

0
4
5
.
0

2
1
2
.
0

1
2
8
.
0

5
4
8
.
0

1
7
7
.
0

S
E
Y

S
E
Y

O
N

K
R
O
W
T
E
N

I
J
O
M
E

S
N
O
I
T
O
M
E

L
A
I
C
O
S

S
T
A
E
F
T
X
E
T

G
N
A
L

m

t
s
l

m

t
s
l

U
R
G

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

O
N

O
N

O
N

O
N

O
N

O
N

O
N

i

n
u
+
r
a
h
c

r
a
h
c

r
a
h
c

N
E

T

I

E
D

.
s
e
g
a
u
g
n
a
l

e
e
r
h
t

e
h
t

r
o
f

s
n
o
i
t
a
r
u
g
ﬁ
n
o
c

t
s
e
b

e
h
t

g
n

i
s
u
N
N
R
d
e
s
a
b

r
e
t
c
a
r
a
h
c

f
o

s
t
l
u
s
e
R

:
6

e
l
b
a
T

21

Language

Emoji

AVG F1 Max F1

Standard deviation F1 Number of runs

EN

EN

EN

IT

IT

IT

DE

DE

DE

NO

YES

Transcription

NO

YES

Transcription

NO

YES

Transcription

0.796

0.797

0.796

0.764

0.761

0.763

0.684

0.678

0.682

0.823

0.821

0.821

0.804

0.798

0.805

0.758

0.745

0.754

0.034

0.009

0.034

0.021

0.016

0.021

0.034

0.028

0.034

612

576

612

468

144

468

468

288

468

Table 7: Mean and Standard deviation of macro averaged F1 scores without any
speciﬁc processing of emojis (‘NO’), using emojis obtained through alignment
(‘YES’) and transcribing them (‘TRANSCRIPTION’)

6.2 Contribution of social and emotion information

In order to better understand the contribution of speciﬁc features or pre-processing
steps on all the system runs, we present a comparative evaluation of the clas-
siﬁer performance with or without emoji transcription (in Figure 2) and with
or without social and emotion features (Figure 3). This analysis is done with
the goal of focusing not only on the best performing conﬁguration, but also on
general trends that could not be included in the previous tables. In particular,
we plot the distribution of runs achieving diﬀerent macro average F1 scores.

(a) English (total: 1800 runs)

(b) Italian (total: 1080 runs)

(c) German (total: 1224 runs)

Figure 2: Results distribution with and without emoji transcription and using
aligned emoji embeddings over the three languages.

Figure 2 shows that transcribing emojis yields the best performance for
English but not for the two other languages. Nevertheless, this distinction is
not clear-cut, since no clear trend can be associated with this feature. More
details on the diﬀerent conﬁgurations are shown in Table 7, conﬁrming the
above ﬁndings. Figure 3 analyses in a similar way the contribution of social
network speciﬁc features (i.e. tweet length, punctuation marks, uppercase, etc.)
and emotion features (i.e. based on EmoLex and Hurtlex). It shows that, while

22

Language

Social & emotion features Mean F1 Max F1

Standard Deviation F1 Number of Runs

EN

EN

IT

IT

DE

DE

NO

YES

NO

YES

NO

YES

0.794

0.797

0.763

0.763

0.680

0.682

0.823

0.821

0.805

0.805

0.758

0.754

0.011

0.010

0.020

0.021

0.035

0.033

300

1500

180

900

204

1020

Table 8: Mean and Standard deviation of macro averaged F1 scores with and
without social and emotion features

for English and Italian the best results are obtained without these two groups of
features, other runs achieving on average a slightly lower performance make use
of this information. For German, the improvement due to social and emotion
features appears to be more consistent, even if it does not apply to all runs.
Also, the averaged results summarised in Table 8 conﬁrm that, like for emojis,
the diﬀerences are not clear-cut.

(a) English (total: 1800 runs)

(b) Italian (total: 1080 runs)

(c) German (total: 1224 runs)

Figure 3: Results distribution with and without social network and emotion
features over the three languages.

Comparing the results across the three languages, we summarize the main

ﬁndings from the evaluation as follows:

• Using subword information has a positive impact on our task, since it can
deal with the high language variability and creativity in the social media
domain as well as with typos.

• Creating speciﬁc embeddings that cover well the domain of interest is
beneﬁcial to the task performance. If possible, a large amount of Twitter
data should be collected to create embeddings when dealing with online
hate speech classiﬁcation. If not, pretrained Fasttext embeddings trained
on CommonCrawl or similar are recommended, provided that it is possible
to access the binary model

23

• If the above domain-speciﬁc embeddings are available, where emojis are
also present, our experiments show that it is not needed to pre-process
emojis in speciﬁc ways (e.g. transcribe, add emoji embeddings through
alignment)

• Hashtag normalization is useful to classify hate speech in English and
Italian, but current approaches to hashtag splitting may not perform well
on languages that are rich in compounds like German, which in turn may
aﬀect classiﬁcation

• Using domain-speciﬁc embeddings with a good coverage make emotion
lexica redundant in our experiments. The fact that such lexica may be
manually or semi-automatically created does not play a major role in
classiﬁcation performance

• Given the limited length of tweets, LSTM yielded better results than BiL-

STM

6.3 Multilingual evaluation on downsampled datasets

We perform an additional set of experiments to investigate to what extent the
size of the dataset aﬀects the results. Therefore, we downsample both the Ger-
man and the English datasets to match the size of the Italian Twitter dataset,
the smallest one. In order to improve our ability to compare the results, we
use the same distribution of labels (hate speech, non hate speech) as the Italian
dataset for the two downsampled ones. We then replicate some of the best per-
forming conﬁgurations presented in the previous tables, and report the results
in Table 9. As expected, reducing the training data both for English and for
German leads to a drop in performance (from 0.823 F1 to 0.782 for English,
from 0.758 F1 to 0.713 for German). On all the runs, the classiﬁer achieves a
lower performance on German than on the other two languages, while the results
on Italian and English are comparable. Our experiments suggest that German
is more challenging to classify, partly because of inherent characteristics of the
language (for example the presence of compound words that makes hashtag
splitting ineﬀective), partly because of the way in which the Germeval dataset
was built. Namely, the organisers report that they sampled the data starting
from speciﬁc users and avoiding keyword-based queries, so to obtain the highest
possible variability in the oﬀensive language. They also manually checked and
enriched the data so to cover all the political spectrum in their oﬀenses, and
avoid user overlaps between training and test data. This led to the creation of
a very challenging dataset, where lexical overlap between training and test data
is limited (therefore unigram and bigram features do not work well) and where
hate speech is not associated with speciﬁc topics or keywords.

24

n
a
m
r
e
G
d
n
a

n
a
i
l
a
t
I

,
h
s
i
l
g
n
E
n

i

e
z
i
s

e
l
b
a
r
a
p
m
o
c

f
o

s
t
e
s

a
t
a
d

n
o

n
o
i
t
a
u

l
a
v
e

e
c
n
a
m
r
o
f
r
e
P

:
9

e
l
b
a
T

1
F

R

P

1
F

G
V
A

G
V
A

G
V
A

E
T
A
H

O
N
1
F

E
T
A
H

G
N
A
L

.

H
S
A
H

T
I
L
P
S

K
R
O
W
T
E
N

I
J
O
M
E

S
N
O
I
T
O
M
E

L
A
I
C
O
S

S
T
A
E
F
T
X
E
T

.

D
E
B
M
E

5
6
7
.
0

9
6
7
.
0

3
6
7
.
0

1
0
8
.
0

1
1
8
.
0

4
9
7
.
0

0
0
7
.
0

0
9
6
.
0

6
2
7
.
0

0
7
7
.
0

0
8
7
.
0

3
6
7
.
0

3
9
7
.
0

6
9
7
.
0

9
8
7
.
0

9
8
6
.
0

0
8
6
.
0

2
1
7
.
0

3
7
7
.
0

3
8
7
.
0

7
6
7
.
0

3
8
7
.
0

5
8
7
.
0

0
8
7
.
0

3
1
7
.
0

3
0
7
.
0

6
3
7
.
0

5
8
7
.
0

2
9
7
.
0

0
8
7
.
0

7
6
7
.
0

6
6
7
.
0

7
6
7
.
0

8
1
7
.
0

0
1
7
.
0

2
3
7
.
0

2
8
7
.
0

1
9
7
.
0

6
7
7
.
0

0
6
7
.
0

7
6
7
.
0

5
5
7
.
0

3
1
7
.
0

2
0
7
.
0

1
4
7
.
0

3
8
6
.
0

9
3
7
.
0

8
7
5
.
0

6
9
6
.
0

3
2
7
.
0

3
6
5
.
0

1
0
7
.
0

8
0
7
.
0

8
9
5
.
0

3
1
7
.
0

4
8
6
.
0

1
1
6
.
0

1
1
7
.
0

3
8
6
.
0

6
9
5
.
0

7
4
8
.
0

3
6
8
.
0

2
2
8
.
0

4
4
8
.
0

2
6
8
.
0

4
1
8
.
0

6
4
8
.
0

7
5
8
.
0

7
2
8
.
0

7
5
8
.
0

9
4
8
.
0

4
2
8
.
0

3
5
8
.
0

7
3
8
.
0

0
3
8
.
0

N
E

T
I

E
D

N
E

T
I

E
D

N
E

T
I

E
D

N
E

T
I

E
D

N
E

T
I

E
D

S
E
Y

M
T
S
L

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

O
N

i
n
u
+
b
m
e

t
x
e
t
t
s
a
F

S
E
Y

M
T
S
L

O
N

O
N

O
N

i
n
u
+
b
m
e

t
x
e
t
t
s
a
F

O
N

U
R
G

O
N

O
N

O
N

b
m
e

t
x
e
t
t
s
a
F

S
E
Y

M
T
S
L

n
o
i
t
p
i
r
c
s
n
a
r
t

O
N

O
N

b
m
e

t
x
e
t
t
s
a
F

S
E
Y

M
T
S
L

O
N

O
N

O
N

b
m
e

t
x
e
t
t
s
a
F

25

While our main goal is not to develop a system achieving state-of-the-art
results, it is interesting to compare our performance with the best systems
dealing with hate speech detection. For Italian and German our approach can
be easily compared to other existing classiﬁers using the same training and test
split, since we relied on the oﬃcial data released in two shared tasks. These
results, however, were obtained in the context of the shared task, therefore the
authors could not use information about the test set performance as we did.
The comparison is still interesting, but it should be noted that we are reporting
the best results on the test set, not on the development set.

On Italian, we observe that our best system conﬁguration achieves state-of-
the-art results (F1 0.805). The best performing system in the EVALITA shared
task [17] reached 0.800 F1 on the development set using an SVM-based classiﬁer
with rich linguistic features, while the best score obtained on the test set (0.799
F1) was yielded by a two-layer BiLSTM in a multi-task learning setting. Sim-
ilar to our best setting, they also use embeddings extracted from social media
data, and observe that using sentiment-based lexica does not increase system
performance.

On German, the best performing system participating in Germeval [66]
achieved 0.768 F1 [48] and was a stacked ensemble system that combined max-
imum entropy and random forest classiﬁers and relied on ﬁve groups of fea-
tures. However, the system performance in 10-fold cross-validation using only
the training set reached 0.817 F1. Our best conﬁguration on the task test set
yields 0.758 F1 with a much simpler architecture, using only Fasttext and no
other features except for word embeddings.

As for English, it is more diﬃcult to draw a similar comparison because
the dataset we use [62] was originally annotated with three classes (i.e. racism,
sexism and none), thus most systems using the same data perform multiclass
classiﬁcation. Besides, they are run using ten-fold cross-validation like in the
original paper [62]. One of the few attempts to distinguish between hate and
non-hate speech on the same English data is described in [38], where the authors
present a classiﬁer combining word-based CNN and character-based CNN. They
report 0.734 F1 on the binary task in ten-fold cross-validation. Other works
using the same data set for three-class classiﬁcation report much higher results
(0.783 F1 in [31] using CNN, 0.86 F1 in [38] using a multi-layer perceptron).
Interestingly, as shown in [38], multi-class classiﬁcation seems generally easier
than the binary one on this speciﬁc data set, since sexist and racist tweets
present lexical-based discriminating features that are easy to capture.

6.4 Qualitative evaluation

In our experiments we tested more that 1,000 conﬁgurations for each language,
and it is therefore diﬃcult to manually evaluate and compare the results, since
each conﬁguration may make speciﬁc mistakes and the distribution of false posi-
tives and negatives on the test split would change. In order to gain some insights
into the speciﬁcity of each language and dataset, however, we focus on the out-
put of the best performing conﬁguration for each language, and we manually

26

check the wrongly classiﬁed instances. In most of the cases, it is not possible to
assign a category to the mistakes done by the classiﬁer, since the false negative
tweets are clearly hateful and the false positive ones are unambiguously non-
hateful. These cases are prevalent in all the datasets, so they are independent
from the language and also from the dataset size. The opaque mechanisms with
which deep learning classiﬁers assign labels make it diﬃcult to explain why these
apparently trivial cases were misclassiﬁed, but we plan to exploit information
conveyed by attention mechanisms to shed light into this issue [21].

Among the broad mistake categories found across the inspected datasets,
there are some cases of implicit abuse. Such messages do not contain abusive
words but rather convey their oﬀensive nature through sarcasm, jokes, the usage
of negative stereotypes or supposedly objective statements implying some form
of oﬀense.

We report few examples of false negatives for the hate speech class below:

4. It’s not about any speciﬁc individuals, but about an ideology that will always

produce terrorists.

5. Molti ancora non vedono, ma quando attraversano un parco, se popolato
da immigrati, si tengono stretta la borsa. (EN: Many do not see it, but
when they cross a park populated with immigrants they hold their bag
close).

6. Schau doch Pornos wenn du mehr Redeanteil von Frauen h¨oren willst

(EN: Watch porn if you want to hear more women talk).

We also observe that sentences with a complex syntactic structure, contain-
ing for example more than one negation, or questions, are frequent both among
the false positives and the false negatives (see Sentence 7, which was wrongly
classiﬁed as ‘Not hate’). The same happens for tweets that contain anaphoric
elements that hint at mentions probably present in previous messages, and for
tweets which require some form of world knowledge to be understood. In some
cases, a link to external media contributed to the hateful meaning of a tweet,
as in Sentence 8. However, since we remove urls in the pre-processing step this
information was not exploited for classiﬁcation.

7. No. You have proven your ignorance here to anyone who isn’t as dumb as

you. It’s there for all to see but you don’t know it..

8. A quanto pare, il corano si pu`o usare anche per questo. Ma pare non
funzioni molto bene..... http: // t. co/ DcOSHfmfxK (EN: It seems that
Quran can be used also for this. But apparently it does not work very
well...http://t.co/DcOSHfmfxK).

Among false positives, the inspected examples conﬁrm the remarks in [65]
concerning the English dataset, and we observe a similar behaviour also for
Italian tweets: since these datasets were collected starting from keywords con-
cerning potential hate targets such as women, Roma and Muslims and then

27

extended with not oﬀensive tweets, classiﬁers tend to associate target mentions
to hate speech, even if such messages are not oﬀensive. This phenomenon is
less evident on the German data, which indeed was created in a diﬀerent way,
starting from a list of users. Two examples of false positive are reported below.
In (9) the message is probably classiﬁed as hateful because of the mention of
‘Jewish’. In (10) it may depend on the mention of ‘migration’.

9. Fine by me. I had ﬁve Jewish friends in college. None ever went to a

Synagogue.

10. l’immigrazione `e un problema x tutti! Ma servono iniziative non comuni-
cati (EN: Migration is a problem for everybody! But we need initiatives,
not press releases).

Finally, we noted few mistakes in the gold standard annotation of the test

sets, which were correctly classiﬁed by our system.

7 Conclusions

Targeting the hate speech detection task in social media messages, in this paper
we have ﬁrst identiﬁed a recurrent neural architecture that is rather stable and
well-performing across diﬀerent languages (i.e., English, German and Italian),
and then we have evaluated the contribution of several components that are
usually employed in the task, namely the type of embeddings, the use of addi-
tional features (text-based or emotion-based), the role of hashtag normalisation
and that of emojis. Our comparative evaluation has been carried out on En-
glish, Italian and German available Twitter datasets for hate speech detection
(annotated as either containing hate speech/oﬀensive language or not). More
precisely, in our detailed study we have compared 1,800 possible conﬁgurations
for English, 1,080 for Italian and 1,224 for German. This allowed us to propose
a set of ﬁndings, listed in Section 6, that could guide researchers in the design of
hate speech detection systems, especially for languages diﬀerent from English.
To be exhaustive, we have also performed an additional set of experiments to
investigate to what extent the size of the dataset aﬀects the results.

8 Acknowledgements

Part of this work was funded by the CREEP project16, a Digital Wellbeing
Activity supported by EIT Digital in 2018 and 2019. This research was also
supported by the HATEMETER project17 within the EU Rights, Equality and
Citizenship Programme 2014-2020, and by the ANR-19-P3IA-0002 - 3IA Cˆote
d’Azur - Nice - Interdisciplinary Institute for Artiﬁcial Intelligence.

16http://creep-project.eu/
17http://hatemeter.eu/

28

References

[1] Sweta Agrawal and Amit Awekar. Deep learning for detecting cyberbul-
lying across multiple social media platforms. In Gabriella Pasi, Benjamin
Piwowarski, Leif Azzopardi, and Allan Hanbury, editors, Advances in In-
formation Retrieval - 40th European Conference on IR Research, ECIR
2018, Grenoble, France, March 26-29, 2018, Proceedings, volume 10772 of
Lecture Notes in Computer Science, pages 141–153. Springer, 2018.

[2] Luis Enrique Argota Vega, Jorge Carlos Reyes-Maga˜na, Helena G´omez-
Adorno, and Gemma Bel-Enguix. MineriaUNAM at SemEval-2019 task 5:
Detecting hate speech in twitter using multiple features in a combinatorial
framework. In Proceedings of the 13th International Workshop on Seman-
tic Evaluation, pages 447–452, Minneapolis, Minnesota, USA, June 2019.
Association for Computational Linguistics.

[3] Pinar Arslan, Michele Corazza, Elena Cabrio, and Serena Villata. Over-
whelmed by Negative Emotions? Maybe You Are Being Cyber-bullied! In
SAC 2019 - The 34th ACM/SIGAPP Symposium On Applied Computing,
Limassol, Cyprus, April 2019.

[4] Xiaoyu Bai, Flavio Merenda, Claudia Zaghi, Tommaso Caselli, and Malvina
Nissim. Rug @ EVALITA 2018: Hate speech detection in italian social me-
dia. In Proceedings of the Sixth Evaluation Campaign of Natural Language
Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018)
co-located with the Fifth Italian Conference on Computational Linguistics
(CLiC-it 2018), Turin, Italy., 2018.

[5] Xiaoyu Bai, Flavio Merenda, Claudia Zaghi, Tommaso Caselli, and Malv-
ina Nissim. Rug at germeval: Detecting oﬀensive speech in german social
media. In Proceedings of GermEval 2018, 14th Conference on Natural Lan-
guage Processing (KONVENS 2018), 2018.

[6] Francesco Barbieri, Francesco Ronzano, and Horacio Saggion. What does
this emoji mean? a vector space skip-gram model for twitter emojis. In
Language Resources and Evaluation conference, LREC, Portoroz, Slovenia,
May 2016.

[7] Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana
Patti, Francisco Manuel Rangel Pardo, Paolo Rosso, and Manuela San-
guinetti. SemEval-2019 task 5: Multilingual detection of hate speech
against immigrants and women in twitter. In Proceedings of the 13th In-
ternational Workshop on Semantic Evaluation, pages 54–63, Minneapolis,
Minnesota, USA, June 2019. Association for Computational Linguistics.

[8] Valerio Basile and Malvina Nissim. Sentiment analysis on italian tweets.
In Proceedings of the 4th Workshop on Computational Approaches to Sub-
jectivity, Sentiment and Social Media Analysis, pages 100–107, Atlanta,
2013.

29

[9] Elisa Bassignana, Valerio Basile, and Viviana Patti. Hurtlex: A multilin-
gual lexicon of words to hurt. In 5th Italian Conference on Computational
Linguistics, CLiC-it 2018, volume 2253, pages 1–6. CEUR-WS, 2018.

[10] Christos Baziotis, Nikos Pelekis, and Christos Doulkeridis. DataStories at
SemEval-2017 Task 4: Deep LSTM with Attention for Message-level and
Topic-based Sentiment Analysis. In Proceedings of the 11th International
Workshop on Semantic Evaluation (SemEval-2017), pages 747–754, Van-
couver, Canada, August 2017. Association for Computational Linguistics.

[11] Piotr Bojanowski, Edouard Grave, Armand Joulin, and Tomas Mikolov.
Enriching word vectors with subword information. Transactions of the
Association for Computational Linguistics, 5:135–146, 2017.

[12] Cristina Bosco, Felice Dell’Orletta, Fabio Poletto, Manuela Sanguinetti,
and Maurizio Tesconi. Overview of the EVALITA 2018 hate speech detec-
tion task. In Proceedings of the Sixth Evaluation Campaign of Natural Lan-
guage Processing and Speech Tools for Italian. Final Workshop (EVALITA
2018) co-located with the Fifth Italian Conference on Computational Lin-
guistics (CLiC-it 2018), Turin, Italy., 2018.

[13] Miguel ´Angel ´Alvarez Carmona, Estefan´ıa Guzm´an-Falc´on, Manuel
Montes-y-G´omez, Hugo Jair Escalante, Luis Villase˜nor Pineda, Ver´onica
Reyes-Meza, and Antonio Rico Sulayes. Overview of MEX-A3T at ibereval
2018: Authorship and aggressiveness analysis in mexican spanish tweets.
In Proceedings of the Third Workshop on Evaluation of Human Language
Technologies for Iberian Languages (IberEval 2018) co-located with 34th
Conference of the Spanish Society for Natural Language Processing (SE-
PLN 2018), Sevilla, Spain, September 18th, 2018., pages 74–96, 2018.

[14] Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bah-
danau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. Learning
phrase representations using rnn encoder–decoder for statistical machine
translation. In Proceedings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages 1724–1734. Association
for Computational Linguistics, 2014.

[15] Fran¸cois Chollet et al. Keras. https://github.com/fchollet/keras,

2015.

[16] Mark Cieliebak, Jan Milan Deriu, Dominic Egger, and Fatih Uzdilli. A
twitter corpus and benchmark resources for german sentiment analysis.
In 5th International Workshop on Natural Language Processing for Social
Media, Boston, MA, USA, pages 45–51. Association for Computational
Linguistics, 2017.

[17] Andrea Cimino, Lorenzo De Mattei, and Felice Dell’Orletta. Multi-task
learning in deep neural networks at EVALITA 2018.
In Proceedings of
the Sixth Evaluation Campaign of Natural Language Processing and Speech

30

Tools for Italian. Final Workshop (EVALITA 2018) co-located with the
Fifth Italian Conference on Computational Linguistics (CLiC-it 2018),
Turin, Italy., 2018.

[18] Michele Corazza, Stefano Menini, Pinar Arslan, Rachele Sprugnoli, Elena
Cabrio, Sara Tonelli, and Serena Villata. Comparing diﬀerent supervised
approaches to hate speech detection. In Proceedings of the Sixth Evaluation
Campaign of Natural Language Processing and Speech Tools for Italian. Fi-
nal Workshop (EVALITA 2018) co-located with the Fifth Italian Conference
on Computational Linguistics (CLiC-it 2018), Turin, Italy., 2018.

[19] Michele Corazza, Stefano Menini, Pinar Arslan, Rachele Sprugnoli, Elena
Cabrio, Sara Tonelli, and Serena Villata. Inriafbk at germeval 2018: Iden-
tifying oﬀensive tweets using recurrent neural networks. In GermEval 2018
Workshop, 2018.

[20] Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, and Serena
Villata. Cross-platform evaluation for italian hate speech detection.
In
Proceedings of the Sixth Italian Conference on Computational Linguistics,
Bari, Italy, November 13-15, 2019, 2019.

[21] Michele Corazza, Stefano Menini, Elena Cabrio, Sara Tonelli, and Serena
Villata. Inriafbk drawing attention to oﬀensive language at germeval2019.
In Proceedings of the 15th Conference on Natural Language Processing,
KONVENS 2019, Erlangen, Germany, October 9-11, 2019, 2019.

[22] Thomas Davidson, Dana Warmsley, Michael W. Macy, and Ingmar Weber.
Automated hate speech detection and the problem of oﬀensive language.
In Proceedings of the Eleventh International Conference on Web and Social
Media, ICWSM 2017, Montr´eal, Qu´ebec, Canada, May 15-18, 2017., pages
512–515, 2017.

[23] Liangjie Hong Brian D Davison April Kontostathis Lynne Edwards
Dawei Yin, Zhenzhen Xue. Detection of harassment on web 2.0. In Pro-
ceedings of the Content Analysis in the Web, pages 1–7, 2009.

[24] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova.
BERT: pre-training of deep bidirectional transformers for language under-
standing.
In Proceedings of the 2019 Conference of the North American
Chapter of the Association for Computational Linguistics: Human Lan-
guage Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7,
2019, Volume 1 (Long and Short Papers), pages 4171–4186, 2019.

[25] Polina Stadnikova Dietrich Klakow Dominik Stammbach, Azin Zahraei.
Oﬀensive language detection with neural networks for germeval task 2018.
In Proceedings of GermEval 2018, 14th Conference on Natural Language
Processing (KONVENS 2018), 2018.

31

[26] Elisabetta Fersini, Paolo Rosso, and Maria Anzovino. Overview of the task
on automatic misogyny identiﬁcation at ibereval 2018. In IberEval@SEPLN,
volume 2150 of CEUR Workshop Proceedings, pages 214–228. CEUR-
WS.org, 2018.

[27] Darja Fiˇser, Ruihong Huang, Vinodkumar Prabhakaran, Rob Voigt, Zeerak
Waseem, and Jacqueline Wernimont. Proceedings of the 2nd workshop on
abusive language online (alw2).
In Proceedings of the 2nd Workshop on
Abusive Language Online (ALW2). Association for Computational Linguis-
tics, 2018.

[28] Paula Fortuna, Ilaria Bonavita, and S´ergio Nunes. Merging datasets for
hate speech classiﬁcation in italian. In Proceedings of the Sixth Evaluation
Campaign of Natural Language Processing and Speech Tools for Italian.
Final Workshop (EVALITA 2018) co-located with the Fifth Italian Confer-
ence on Computational Linguistics (CLiC-it 2018), Turin, Italy, December
12-13, 2018., 2018.

[29] Antigoni-Maria Founta, Despoina Chatzakou, Nicolas Kourtellis, Jeremy
Blackburn, Athena Vakali, and Ilias Leontiadis. A uniﬁed deep learning
architecture for abuse detection. CoRR, abs/1802.00385, 2018.

[30] Antigoni-Maria Founta, Constantinos Djouvas, Despoina Chatzakou, Ilias
Leontiadis, Jeremy Blackburn, Gianluca Stringhini, Athena Vakali, Michael
Sirivianos, and Nicolas Kourtellis. Large scale crowdsourcing and charac-
terization of twitter abusive behavior.
In Proceedings of the Twelfth In-
ternational Conference on Web and Social Media, ICWSM 2018, Stanford,
California, USA, June 25-28, 2018., pages 491–500, 2018.

[31] Bj¨orn Gamb¨ack and Utpal Kumar Sikdar. Using convolutional neural net-
works to classify hate-speech.
In Proceedings of the First Workshop on
Abusive Language Online, pages 85–90. Association for Computational Lin-
guistics, 2017.

[32] Mario Graﬀ, Sabino Miranda-Jim´enez, Eric Sadit Tellez, Daniela
Moctezuma, Vladimir Salgado, Jos´e Ortiz-Bejar, and Claudia N. S´anchez.
INGEOTEC at MEX-A3T: author proﬁling and aggressiveness analysis
in twitter using µtc and evomsa.
In Proceedings of the Third Workshop
on Evaluation of Human Language Technologies for Iberian Languages
(IberEval 2018) co-located with 34th Conference of the Spanish Society
for Natural Language Processing (SEPLN 2018), Sevilla, Spain, September
18th, 2018., pages 128–133, 2018.

[33] Edouard Grave, Piotr Bojanowski, Prakhar Gupta, Armand Joulin, and
In Proceed-
Tomas Mikolov. Learning word vectors for 157 languages.
ings of the International Conference on Language Resources and Evaluation
(LREC 2018), 2018.

32

[34] Sepp Hochreiter and J¨urgen Schmidhuber. Long short-term memory. Neu-

ral Comput., 9(8):1735–1780, November 1997.

[35] Matthew Honnibal and Ines Montani. spacy 2: Natural language under-
standing with bloom embeddings, convolutional neural networks and incre-
mental parsing. To appear, 2017.

[36] Tianran Hu, Han Guo, Hao Sun, Thuy-vy Thi Nguyen, and Jiebo Luo.
Spice up your chat: The intentions and sentiment eﬀects of using emojis.
In Proceedings of the Eleventh International Conference on Web and Social
Media, ICWSM 2017, Montr´eal, Qu´ebec, Canada, pages 102–111, 2017.

[37] Vijayasaradhi

Indurthi, Bakhtiyar Syed, Manish Shrivastava, Nikhil
Chakravartula, Manish Gupta, and Vasudeva Varma. FERMI at SemEval-
2019 task 5: Using sentence embeddings to identify hate speech against
immigrants and women in twitter. In Proceedings of the 13th International
Workshop on Semantic Evaluation, pages 70–74, Minneapolis, Minnesota,
USA, June 2019. Association for Computational Linguistics.

[38] Rohan Kshirsagar, Tyrus Cukuvac, Kathy McKeown, and Susan McGregor.
Predictive embeddings for hate speech detection on twitter. In Proceedings
of the 2nd Workshop on Abusive Language Online (ALW2), pages 26–32.
Association for Computational Linguistics, 2018.

[39] Gretel Liz De la Pe˜na Sarrac´en, Reynaldo Gil Pons, Carlos Enrique Mu˜niz-
Cuza, and Paolo Rosso. Hate speech detection using attention-based
LSTM. In Proceedings of the Sixth Evaluation Campaign of Natural Lan-
guage Processing and Speech Tools for Italian. Final Workshop (EVALITA
2018) co-located with the Fifth Italian Conference on Computational Lin-
guistics (CLiC-it 2018), Turin, Italy., 2018.

[40] Younghun Lee, Seunghyun Yoon, and Kyomin Jung. Comparative studies
of detecting abusive language on twitter. CoRR, abs/1808.10245, 2018.

[41] Ping Liu, Wen Li, and Liang Zou. NULI at SemEval-2019 task 6: Transfer
learning for oﬀensive language detection using bidirectional transformers.
In Proceedings of the 13th International Workshop on Semantic Evaluation,
pages 87–91, Minneapolis, Minnesota, USA, June 2019. Association for
Computational Linguistics.

[42] Tomas Mikolov, Edouard Grave, Piotr Bojanowski, Christian Puhrsch, and
Armand Joulin. Advances in pre-training distributed word representations.
In Proceedings of the International Conference on Language Resources and
Evaluation (LREC 2018), 2018.

[43] Pushkar Mishra, Helen Yannakoudakis, and Ekaterina Shutova. Neural
character-based composition models for abuse detection. In Proceedings of
the 2nd Workshop on Abusive Language Online (ALW2), pages 1–10, Brus-
sels, Belgium, October 2018. Association for Computational Linguistics.

33

[44] Saif M Mohammad and Peter D Turney. Emotions evoked by common
words and phrases: Using mechanical turk to create an emotion lexicon.
In Proceedings of the NAACL HLT 2010 workshop on computational ap-
proaches to analysis and generation of emotion in text, pages 26–34. Asso-
ciation for Computational Linguistics, 2010.

[45] Saif M Mohammad and Peter D Turney. Crowdsourcing a word–emotion
association lexicon. Computational Intelligence, 29(3):436–465, 2013.

[46] Roberto Navigli and Simone Paolo Ponzetto. Babelnet: The automatic
construction, evaluation and application of a wide-coverage multilingual
semantic network. Artiﬁcial Intelligence, 193:217 – 250, 2012.

[47] Chikashi Nobata, Joel R. Tetreault, Achint Thomas, Yashar Mehdad, and
Yi Chang. Abusive language detection in online user content. In Proceedings
of the 25th International Conference on World Wide Web, WWW 2016,
Montreal, Canada, April 11 - 15, 2016, pages 145–153, 2016.

[48] Joaquin Padilla Montani and Peter Sch¨uller. Tuwienkbs at germeval 2018:
German abusive tweet detection. In Proceedings of GermEval 2018, 14th
Conference on Natural Language Processing (KONVENS 2018), 09 2018.

[49] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,
M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. Scikit-
learn: Machine learning in Python. Journal of Machine Learning Research,
12:2825–2830, 2011.

[50] Juan Manuel P´erez and Franco M. Luque. Atalaya at SemEval 2019 task 5:
Robust embeddings for tweet classiﬁcation. In Proceedings of the 13th In-
ternational Workshop on Semantic Evaluation, pages 64–69, Minneapolis,
Minnesota, USA, June 2019. Association for Computational Linguistics.

[51] Emanuele Pianta, Luisa Bentivogli, and Christian Girardi. Multiwordnet:
developing an aligned multilingual database. In Proceedings of the First
International Conference on Global WordNet, January 2002.

[52] Marco Polignano and Pierpaolo Basile. Hansel: Italian hate speech de-
tection through ensemble learning and deep neural networks. In Proceed-
ings of the Sixth Evaluation Campaign of Natural Language Processing and
Speech Tools for Italian. Final Workshop (EVALITA 2018) co-located with
the Fifth Italian Conference on Computational Linguistics (CLiC-it 2018),
Turin, Italy., 2018.

[53] Valentino Santucci, Stefania Spina, Alfredo Milani, Giulio Biondi, and
Gabriele Di Bari. Detecting hate speech for italian language in social me-
dia. In Proceedings of the Sixth Evaluation Campaign of Natural Language
Processing and Speech Tools for Italian. Final Workshop (EVALITA 2018)
co-located with the Fifth Italian Conference on Computational Linguistics
(CLiC-it 2018), Turin, Italy., 2018.

34

[54] Tatjana Scheﬄer, Erik Haegert, Santichai Pornavalaia, and Mino Lee Sasse.
Feature explorations for hate speech classiﬁcation. In Proceedings of Ger-
mEval 2018, 14th Conference on Natural Language Processing (KONVENS
2018), 2018.

[55] Mike Schuster, Kuldip K. Paliwal, and A. General. Bidirectional recurrent

neural networks. IEEE Transactions on Signal Processing, 1997.

[56] Abhishek Singh, Eduardo Blanco, and Wei Jin. Incorporating emoji de-
scriptions improves tweet classiﬁcation. In Proceedings of the Annual Con-
ference of the North American Chapter of the Association for Computa-
tional Linguistics (NAACL), 2019.

[57] Samuel L. Smith, David H. P. Turban, Steven Hamblin, and Nils Y. Ham-
merla. Oﬄine bilingual word vectors, orthogonal transformations and the
inverted softmax. CoRR, abs/1702.03859, 2017.

[58] Samuel L. Smith, David H.P. Turban, Steven Hamblin, and Nils Y. Ham-
merla. Oﬄine bilingual word vectors, orthogonal transformations and the
inverted softmax. 2017.

[59] Jacopo Staiano and Marco Guerini. Depeche mood: a lexicon for emotion
analysis from crowd annotated news. In Proceedings of the 52nd Annual
Meeting of the Association for Computational Linguistics (Volume 2: Short
Papers), volume 2, pages 427–433, 2014.

[60] Dirk von Grunigen, Ralf Grubenmann, Fernando Benites, Pius Von
spmmmp at germeval 2018 shared task:
Daniken, and Mark Cieliebak.
Classiﬁcation of oﬀensive content in tweets using convolutional neural net-
works and gated recurrent units. In Proceedings of GermEval 2018, 14th
Conference on Natural Language Processing (KONVENS 2018), 2018.

[61] Zeerak Waseem, Wendy Hui Kyong Chung, Dirk Hovy, and Joel Tetreault.
Proceedings of the ﬁrst workshop on abusive language online. In Proceed-
ings of the First Workshop on Abusive Language Online. Association for
Computational Linguistics, 2017.

[62] Zeerak Waseem and Dirk Hovy. Hateful symbols or hateful people? predic-
tive features for hate speech detection on twitter. In SRW@HLT-NAACL,
2016.

[63] Gregor Wiedeman, Eugen Ruppert, Raghav Jindal, and Chris Biemann.
Transfer learning from lda to bilstm-cnn for oﬀensive language detection
in twitter. In Proceedings of GermEval 2018, 14th Conference on Natural
Language Processing (KONVENS 2018), 2018.

[64] Michael Wiegand, Anastasija Amann, Tatiana Anikina, Aikaterini
Azoidou, Anastasia Borisenkov, Kirstin Kolmorgen, Insa Kroger, and
Christine Schafer. Saarland university’s participation in the germeval task

35

In
2018 (udsw) – examining diﬀerent types of classiﬁers and features.
Proceedings of GermEval 2018, 14th Conference on Natural Language Pro-
cessing (KONVENS 2018), 2018.

[65] Michael Wiegand, Josef Ruppenhofer, and Thomas Kleinbauer. Detection
of Abusive Language: the Problem of Biased Datasets. In Proceedings of
the 2019 Conference of the North American Chapter of the Association
for Computational Linguistics: Human Language Technologies, Volume 1
(Long and Short Papers), pages 602–608, Minneapolis, Minnesota, June
2019. Association for Computational Linguistics.

[66] Michael Wiegand, Melanie Siegel, and Josef Ruppenhofer. Overview of
the germeval 2018 shared task on the identiﬁcation of oﬀensive language.
In Proceedings of GermEval 2018, 14th Conference on Natural Language
Processing (KONVENS 2018), 2018.

[67] Ellery Wulczyn, Nithum Thain, and Lucas Dixon. Ex machina: Personal
attacks seen at scale. In Proceedings of the 26th International Conference
on World Wide Web, WWW 2017, Perth, Australia, April 3-7, 2017, pages
1391–1399, 2017.

[68] Marcos Zampieri, Shervin Malmasi, Preslav Nakov, Sara Rosenthal, Noura
Identifying and cate-
Farra, and Ritesh Kumar. SemEval-2019 task 6:
gorizing oﬀensive language in social media (OﬀensEval).
In Proceedings
of the 13th International Workshop on Semantic Evaluation, pages 75–86,
Minneapolis, Minnesota, USA, June 2019. Association for Computational
Linguistics.

[69] Robinson D. Zhang, Z. and J. Tepper. Detecting hate speech on twit-
ter using a convolution-gru based deep neural network. In ESWC 2018:
The semantic web Conference Proceedings, pages 745–760. Springer Ver-
lag, 2018.

36

