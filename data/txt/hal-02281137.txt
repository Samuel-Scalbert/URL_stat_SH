Comparing Automated Methods to Detect Explicit
Content in Song Lyrics
Michael Fell, Elena Cabrio, Michele Corazza, Fabien Gandon

To cite this version:

Michael Fell, Elena Cabrio, Michele Corazza, Fabien Gandon. Comparing Automated Methods to
Detect Explicit Content in Song Lyrics. RANLP 2019 - Recent Advances in Natural Language Pro-
cessing, Sep 2019, Varna, Bulgaria. ￿hal-02281137￿

HAL Id: hal-02281137

https://hal.science/hal-02281137

Submitted on 8 Sep 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Comparing Automated Methods to Detect Explicit Content in Song Lyrics

Michael Fell, Elena Cabrio, Michele Corazza, Fabien Gandon
Universit´e Cˆote d’Azur, CNRS, Inria, I3S, France
{firstname.lastname}@inria.fr

Abstract

The Parental Advisory Label (PAL) is a warn-
ing label that is placed on audio recordings in
recognition of profanity or inappropriate ref-
erences, with the intention of alerting parents
of material potentially unsuitable for children.
Since 2015, digital providers – such as iTunes,
Spotify, Amazon Music and Deezer – also fol-
low PAL guidelines and tag such tracks as “ex-
plicit”. Nowadays, such labelling is carried
out mainly manually on voluntary basis, with
the drawbacks of being time consuming and
therefore costly, error prone and partly a sub-
jective task. In this paper, we compare auto-
mated methods ranging from dictionary-based
lookup to state-of-the-art deep neural networks
to automatically detect explicit contents in En-
glish lyrics. We show that more complex mod-
els perform only slightly better on this task,
and relying on a qualitative analysis of the
data, we discuss the inherent hardness and sub-
jectivity of the task.

1

Introduction

All content is not always appropriate for all ages
and music is no exception. Content industries have
been actively searching for means to help adults
determine what is and is not appropriate for chil-
dren.
In USA, in 1985, the Recording Industry
Association of America (RIAA) introduced the
Parental Advisory label (PAL) in order to alert par-
ents of content unsuitable for children because of
profanity or inappropriate references1. PAL is “a
notice to consumers that recordings identiﬁed by
this mark may contain strong language or depic-
tions of violence, sex or substance abuse”2 and
that parental discretion is advised.
In UK, the
British Phonographic Industry (BPI) adds to this

1Parental Advisory https://en.wikipedia.org/

wiki/Parental_Advisory

2RIAA

PAL

https://www.riaa.com/

resources-learning/pal-standards/

list “racist, homophobic, misogynistic or other dis-
criminatory language or behavior; or dangerous or
criminal behavior”3.

In the case of a song, the explicit logo is applied
when the lyrics or content of a song matches one
of these criteria, raising the problem of detecting
and labelling explicit songs in a scalable way.

Within the Natural Language Processing (NLP)
community, there have been several efforts to deal
with the problem of online abusive language de-
tection, since the computational analysis of lan-
guage can be used to quickly identify offenses
and ease the removal of abusive messages. Sev-
eral workshops (Park and Fung, 2017; Fiˇser et al.,
2018) and evaluation campaigns (Fersini et al.,
2018; Bosco et al., 2018; Wiegand et al., 2018)
have been recently organized to discuss existing
approaches to abusive language detection, propose
shared tasks and foster the development of bench-
marks for system evaluation. These have led to the
creation of a number of datasets for abusive lan-
guage detection in different languages, that have
been shared within the NLP research community.
The SemEval 2019 tasks HatEval (Basile et al.,
2019) and OffensEval (Zampieri et al., 2019) have
aimed at the multilingual detection of hate speech
against women or immigrants and the categoriza-
tion of hate speech, respectively.

In this direction, and given the similarity with
the abusive language detection task, this paper ad-
dresses the problem of explicit content detection in
song lyrics as a binary classiﬁcation task: a song
can be labelled either as explicit or clean (=not ex-
plicit). To this end, we ﬁrst compare a range of
classiﬁcation methods for the task of explicit lyrics
detection, from dictionary lookup to deep neural
networks. We then attempt the comparison to the

3BPI Parent Advisory https://www.bpi.co.uk/
media/1047/parental-advisory-guidelines.
pdf

available related works and shed light on the inher-
ent hardness and subjectivity of the task at hand.

The paper is organized as follows: in Section 2
we survey the state of the art in explicit lyrics de-
tection. In Sections 3 and 4 we introduce the clas-
siﬁcation methods we apply, and the comparative
experimentation. Conclusions end the paper.

NOTE: This paper contains examples of lan-
guage which may be offensive to some readers.
They do not represent the views of the authors.

2 Related Work

Only a few works on the problem of explicit lyrics
detection exist. (Bergelid, 2018) consider a dataset
of English lyrics (see Table 1, B18) to which they
apply classical machine learning algorithms such
as Support Vector Machine (SVM) and Random
Forest (RF). As features they extract either (i) tf-
idf weighted bag-of-word (BOW) representations
of each song text or (ii) represent the lyrics with
paragraph vectors (Le and Mikolov, 2014). The
explicit labels are obtained from Soundtrack Your
Brand 4. They ﬁnd the RF with tf-idf BOW to per-
form best, especially in combination with a ran-
dom undersampling strategy to the highly imbal-
anced dataset. They also experiment with adding
lyrics metadata to the feature set, such as the artist
name, the release year, the music energy level, and
the valence/positiveness of a song. This results in
marginal improvements for some of their models.
(Chin et al., 2018) apply explicit lyrics detec-
tion to Korean song texts. They also use tf-idf
weighted BOW as lyrics representation and aggre-
gate multiple decision trees via boosting and bag-
ging to classify the lyrics for explicit content. On
their corpus (see Figure 1, C18) they report 78%
F1 using the bagging method. Note, that bagging
with decision trees is similar to the Random Forest
method used by (Bergelid, 2018).
Interestingly,
they also report a baseline for dictionary lookup,
i.e. given a profanity dictionary the song text is
classiﬁed as explicit if and only if one of its words
occurs in the profanity dictionary. With such a
baseline they obtain 61% F1.

More recently, (Kim and Mun, 2019) proposed
a method to create explicit words dictionaries au-
tomatically by weighting a vocabulary according
to all words’ frequencies in the explicit class vs.
the clean class, accordingly. For instance the word
“fuck” is typical for explicit lyrics and atypical

for clean lyrics. They compare different methods
to generate such a lexicon. The achieved perfor-
mances using solely dictionary lookup range from
49% F1 for a man-made dictionary to 75.6% F1
when using relative class frequencies. Note, that
the latter performance is achieved with a dictio-
nary of only 25 words. They work with a corpus
of Korean lyrics (see Figure 1, K19). Unlike pre-
vious work, they apply a recursive neural network,
resulting in 76.6% F1, slightly higher than the sim-
ple dictionary lookup. They ﬁnd performance to
increase to 78.1% when combining the vector rep-
resentation of the RNN with a one-hot vector indi-
cating for each profane word from the dictionary if
the lyric contains it. They argue to use the RNN to
ﬁnd such cases where the expliciteness arises from
the context and not from a dictionary check. How-
ever, no examples of ﬁnding this phenomenon are
presented.

3 Methods for Explicit Lyrics Detection

In this work, we compare a range of classiﬁcation
methods for the task of explicit lyrics detection.
Common to all methods is that they classify a full
song into one of two mutually exclusive classes -
explicit or clean (=not explicit). This means, the
decision if a song text is explicit is taken glob-
ally. We assess the performance of different clas-
siﬁcation methods ranging from simple dictionary
lookup / lexicon checking to general purpose deep
learning language understanding models. We try
to identify contextual effects by applying a method
that outputs the “importance” for each word (see
Section 3.4).

3.1 Dictionary-Based Methods

The most straightforward way to implement an
automated explicit content detection method, is
checking against a dictionary of explicit words.
The dictionary can be man-made or automatically
created from example explicit and clean lyrics.
Then, a classiﬁer uses this dictionary to predict the
class of an unseen song text.

3.1.1 Dictionary Creation

It is possible to use handcrafted dictionaries such
as Noswearing 5. Performance using an automat-
ically created lexicon has previously been shown
(Kim and Mun, 2019) to improve over the manu-
ally created dictionary. We therefore consider only

4https://www.soundtrackyourbrand.com

5https://www.noswearing.com/

the case of the machine-made dictionary in this
work. We generate a dictionary of words that are
indicative of explicit lyrics. We deﬁne the impor-
tance I of a word w for explicit lyrics by the fre-
quency f (w, ex) of w in explicit lyrics compared
to its frequency f (w, cl) in clean lyrics:

I(w) = f (w, ex)/f (w, cl)

We ﬁlter out unique and too common words and
restrict the number of terms to 1,000 to avoid over-
reliance on terms that are very corpus speciﬁc.
The dictionary Dn of the n words most impor-
tant for explicit lyrics, is now straightforwardly
deﬁned as containing the n words with the high-
est I score.

3.1.2 Dictionary Lookup
Given a dictionary Dn, this method simply checks
if a song text S contains any of the explicit terms
deﬁned in Dn. Then, S is classiﬁed as explicit iff
it contains at least one explicit term from Dn.

3.1.3 Dictionary Regression
This method uses BOW made from Dn as the
feature set of a classiﬁer. We used a logistic re-
gression, but RF or SVM have been used alike in
(Bergelid, 2018).

3.2 Tf-idf BOW Regression

Similar to the Dictionary Regression, but
the
BOW contains the whole vocabulary of a train-
ing sample instead of only the explicit terms. The
word features are weighted with the well-known
tf-idf weighting scheme.

3.3 Transformer Language Model

Recently,
approaches based on self-attention
(Vaswani et al., 2017) have been proposed and
have proven effective for natural language under-
standing tasks. These models are structured as an
encoder-decoder, and they are trained on unsuper-
vised tasks (such as masked language modelling)
in order to learn dense representations of sentences
or documents. These models differ from more tra-
ditional recurrent neural networks in different as-
pects.
In particular, while recurrent models can
process sequences (in NLP, typically word embed-
dings) in order, transformers use a joint model of
the right and left context of each word in order
to encode an entire sequence or document. Ad-
ditionally, transformers are typically less compu-
tationally expensive than recurrent models, espe-
cially when trained on a GPU accelerator.

One of the most successful transformer-based
models proposed in the last few years is BERT
(Devlin et al., 2018). This model is composed of
multiple transformers connected by residual con-
nections. Pre-trained models are provided by the
authors, and they are used in our work to perform
explicit language detection in lyrics, without re-
training the full model.

3.4 Textual Deconvolution Saliency

We use the Textual Deconvolution Saliency (TDS)
model of (Vanni et al., 2018), which is a Convolu-
tional Neural Network (CNN) for text classiﬁca-
tion. It is a simple model containing an embedding
layer for word representations, a convolutional
layer with max pooling and two fully connected
layers. The interesting part about this model is that
they manage to reverse the convolution. Given the
learned feature map (the output of the convolution
before max pooling) of the CNN, they upsample it
to obtain a 3-dimensional sample with dimensions
(#words, embedding size, #ﬁlters). The TDS for
each word is now deﬁned as the sum along the
embedding axes of the output of the deconvolu-
tion. The TDS represents the importance of each
word of the input with respect to the learned fea-
ture maps. We use this model with the goal to ﬁnd
local explanations for the global decision of the
classiﬁcation as explicit or clean. Such explana-
tions can arise from contexts or phrases that the
model assigns a high importance.

4 Experimental Setting and Evaluation

We compare the different methods as introduced
in the previous section to the task of explicit lyrics
detection. We attempt a comparison to the related
work as well, although due to different datasets
comparing the reported scores directly is problem-
atic. We ﬁnally analyze the classiﬁcation qualita-
tively with examples, and demonstrate the intrin-
sic hardness and subjectivity of the explicit lyrics
detection task.
Abbreviations used: to refer to related works in
Table 1 and 3, we use the following abbrevia-
tions. B18 stands for (Bergelid, 2018), C18 is
(Chin et al., 2018), K19 means (Kim and Mun,
2019), while Ours is this work.

4.1 Dataset

The WASABI database (Meseguer-Brocal et al.,
2017) contains song-wise labels for explicit lyrics,

total
Work
25,441
B18
27,695
C18
K19
70,077
WAS 179,391

explicit
3,310
1,024
7,468
17,808

ratio
language
13.0% English
3.7%
Korean
10.7% Korean
English
9.9%

Table 1: Overview of our dataset WAS (# songs) and
comparison to the related works.

such as explicit, unknown, no advice available, or
clean (=not explicit). These labels are provided by
the music streaming service Deezer 6. We selected
a subset of English song texts from the corpus
which are tagged as either explicit or clean. We
ﬁltered out duplicate lyrics and such that contain
less than 10 tokens. Finally, our dataset (WAS)
comprises of 179k lyrics, with a ratio of explicit
lyrics of 9.9%. The details and comparison with
related works datasets are depicted in Table 1.

For training any of the models described in the
previous section, we once randomly split the data
into training-development-test sets with the com-
mon 60%-20%-20% ratio. We tuned the hyperpa-
rameters of the different classiﬁcation algorithms
on the development set to then test with the best
performing parameters on the test set. As evalua-
tion metrics we use precision (P), recall (R), and
f-score (F1). Unless stated otherwise, the scores
are macro-averaged over the two possible classes.

4.2 Hyperparameters

For the dictionary-based methods, we found the
ideal dictionary size to be 32 words for the lookup
and 128 words for the regression. The Tf-idf BOW
regression performed best when the full vocab-
ulary of unigrams and bigrams was used. We
used the sklearn implementation of logistic regres-
sion with the class weighting scheme ’balanced’
to account for the class imbalance in the dataset.
We used TDS with max sequence length 512 and
dropout probability 50%. As is the default with
TDS, corpus-speciﬁc word vectors were trained
using Word2Vec (Mikolov et al., 2013) with di-
mensionality 128. The BERT model comes pre-
trained and no further pre-training was performed.
We used the smaller of the two published mod-
els. BERT then was ﬁnetuned to our task using
max sequence length 256 and batch size 16, other-
wise default parameters for text classiﬁcation task
learning.

6https://www.deezer.com

4.3 Results

Overall, the results of the different classiﬁcation
methods we tried are all close to each other. The
simple dictionary lookup with 32 words performs
comparably to the deep neural network with 110M
parameters (BERT base model). As baseline, we
include the majority class classiﬁer that always
predicts the clean class. Furthermore, all related
works show similar tendencies of performance on
their respective datasets. The results of all the dif-
ferent methods we applied are depicted in Table 2
and described in the following.

The majority class classiﬁer delivers a perfor-
mance of 47.4% F1, which is the only outlier in the
sense that this is far below any other model. The
dictionary lookup with a vocabulary of the 32 most
indicative explicit words obtains a balanced per-
formance as precision and recall are close to each
other, the overall performance is 77.3% F1. The
dictionary regression performs somewhat better in
terms of f-score (78.5% F1), achieving this with
the highest overall recall of 81.5%, but it has lower
precision. The tf-idf BOW regression performs
very similarly to the dictionary regression. This
proves that a limited number of words inﬂuences
the overall performance of the models, and that
they do not need to consider the whole vocabulary,
just the most offensive words. The increased vo-
cabulary of 929k unigrams and bigrams is gigan-
tic compared to the explicit words dictionary (32
words). As most of these n-grams may be noise to
the classiﬁer, this could explain the slight decrease
in performance over the dictionary regression. Fi-
nally, the neural-network-based methods behave
a bit differently:
the BERT language model is
clearly better in precision (84.4%) over all other
models - the second best is TDS with 81.2%.
However, BERT performs the worst in recall with
only 73.7%. The overall performance of BERT is
average with 77.7% F1. Finally, TDS performs
best in terms of 79.6% F1. We tested if TDS out-
performing BERT was due to TDS using domain-
speciﬁc word vectors trained on our corpus (BERT
is trained on books and Wikipedia). This was
not the case as TDS performed almost identically,
when using generic word vectors (GloVe, 200d):
80.4% P, 78.7% R, 79.5% F1.

A closer look at the classiﬁcation performance
shows that the F1 scores for the minority class (ex-
plicit lyrics) is highest with TDS (63%) and lowest
with the dictionary lookup (58.9%). The majority

Model
Majority Class
Dictionary Lookup
Dictionary Regression
Tf-idf BOW Regression
TDS Deconvolution
BERT Language Model

P
45.0
78.3
76.2
75.6
81.2
84.4

R
50.0
76.4
81.5
81.2
78.2
73.7

F1
47.4
77.3
78.5
78.0
79.6
77.7

Table 2: Performances of our different models on the
WAS dataset. Values in percent.

Dictionary Lookup

Work Model
Ours Dictionary Lookup
Ours Dictionary Regression
C18 Man-made Dictionary
K19 Man-made Dictionary
K19
Ours Tf-idf BOW Regression
Tf-idf BOW
C18
Tf-idf BOW+
C18
Tf-idf BOW
B18
B18
Tf-idf BOW+
Ours TDS Deconvolution
Ours BERT Language Model
K19
K19

HAN
HAN + Dictionary

F1
77.3
78.5
61.0
49.0
75.6
78.0
78.0
80.0
67.5
82.6
79.6
77.7
76.7
78.1

Table 3: Performances of dictionary-based methods
(top),
tf-idf BOW models (middle) and deep mod-
els (below). Note that different works use different
datasets. Ours always uses the WAS dataset. Values
in percent.

class (clean lyrics) on the other hand is best de-
tected by BERT (96.3% F1) and worst with the
tf-idf BOW (95.1% F1).

We attempt a comparison of the different ap-
proaches used in the different related works as
well as ours. While the scores achieved (see Ta-
ble 3) are not strictly comparable, we can see clear
tendencies. According to K19, a man-made dic-
tionary is inferior to an automatically generated
one. This is supported by the man-made lexicon
in C18 performing subpar to their tf-idf BOW. An
appropriate lexicon of explicit terms, on the other
hand, can compete with a tf-idf BOW model, as
we showed with both the dictionary lookup and the
regression performance. This is further supported
by the generated dictionary of K19 which com-
petes with the deep HAN model. Optimizations
to the standard tf-idf BOW models are marked
with the + sign. Restricting the POS tags to

more likely ones found in explicit terms (C18) im-
proves performance slighly. Using random under-
sampling to ﬁght the imbalanced class problem
(B18) increases performance drastically, however
makes the problem somewhat different from the
imbalanced problem. The ﬁnal takeaway is that
deep models do not necessarily outperform shal-
low models. Neither HAN, TDS, nor BERT de-
liver much higher scores than the dictionary-based
or the BOW method.

4.4 Qualitative Analysis

In this section we analyze examples of explicit
content lyrics and point to the inherent hardness
and subjectivity in classifying and even labelling
such data.

4.4.1 Explicitness in Context?

The highest difference in model performance we
measured between the deep TDS model (79.6%
F1) and the dictionary lookup (77.3% F1). We
analyzed why the TDS method performed better
than the dictionary lookup by inspecting those ex-
amples that (i) were explicit, (ii) were tagged as
clean by the dictionary lookup, and (iii) were de-
tected as explicit by TDS with high conﬁdence. 7
From the 13 examples analyzed, we found three
main phenomena: (1) Four texts contained explicit
terms that were not contained in the dictionary
of explicit terms. Words such as f**kin’, moth-
erf**kers were too rare to be included in the gen-
erated lexicon and other words like fucking, cunt,
cum, shit were not uniquely contained in explicit
lyrics. The reason why this is the case can be
traced back to problems in the annotations or the
fact that these words are relatively frequently used
in lyrics. (2) Five texts whose explicitness arises
in context rather than on a word level. Exam-
ples with violent context found were “organization
with horns of satan performs the ancient rituals” or
“bombin on mc’s, crushin crews with ease”. There
were also instances of sexual content such as “give
it to him down in the parking lot in the backseat, in
the backseat of the car”. Note that the words {give,
it, to, him} in isolation do not belong to an explicit
terms list and the sexuality arises from the context.
Similarly in “(turn the lights on) so i can see that
ass work”. Also here, putting “ass” in an explicit
terms dictionary is tempting but may not be ideal,

7The last layer of TDS outputs probabilities for the input
text being explicit or clean. We looked at examples where the
explicit class was predicted with at least 80% probability.

as its meaning is not necessarily explicit. (3) Four
texts appeared to have been mislabelled since no
explicitness could be found. We found for three
of them that the album the song is contained in is
tagged as explicit. In cases as these, inheriting the
label from the album is wrong, but it seems this is
exactly what had happened here. In one Raggae
lyric, in particular, we found no explicit content,
so we suspect the song was mislabelled.

Since we found some annotation to be problem-
atic, we will discuss difﬁculties that arise from an-
notating explicitness in lyrics.

4.4.2 How Hard is this Task?

As stated in the introduction, the explicit label is
voluntary and we will argue that it is also some-
what subjective in its nature. There are lyrics
which are not tagged as explicit although they have
profanity in them. Consider for example the song
Bitch by Meredith Brooks. While it already con-
tains profanity in the title, it does not carry the
explicit label and one can argue that in the con-
text of the song, the term “bitch” is used as a con-
trastive term and to raise attention to the struggle
the songwriter sees in her life, torn between po-
tentially conﬂicting expectations of society (“I’m
a little bit of everything - All rolled into one - I’m
a bitch, I’m a lover - I’m a child, I’m a mother -
I’m a sinner, I’m a saint - I do not feel ashamed”).
Another example is Check Your Head by
Buckcherry where it says “Ooh and you still bitch
about your payments” where “bitch” is used as a
verb and one can argue that the acceptance in this
verb form is higher than in the noun form. A sim-
ilar case where the part of speech inﬂuences the
perceived level of profanity is Hail Hail Rock ’n’
Roll by Discipline. It contains the line “the band
starts to play loud as fuck”.

We encounter a different kind of problem when
dealing with substance abuse or other drug-related
content.
It is evident that the legal status of the
substances mentioned plays a major role in how
such content is labelled. This is further com-
plicated by the fact that legislation about sub-
stances can vary wildly between different coun-
tries. The labels applied to this content are not
culture-invariant, and furthermore changes in the
societal view can lead to labels that are not rele-
vant anymore. This, like other examples, shows
why the labels applied to lyrics are subject to
change in different cultures and time periods.

Another aspect that is very sensitive to time pe-

riods and cultures comes from words themselves:
an inoffensive word can become offensive in slang
or common language. One such example can
be found in Johnny Cash’s The Christmas Guest:
“When the cock was crowing the night away - The
Lord appeared in a dream to me”. Here, cock
means male chicken, as opposed to the offensive
meaning that is now arguably more common.

We ﬁnally want to raise attention to the problem
of genre confounding. We found that the genre
Hip Hop contributed by far the most to all ex-
plicit lyrics - 33% of all Hip Hop lyrics. Since
only about 5% of the whole corpus are tagged
as Hip Hop, this genre is highly overrepresented.
This raises the question in how far our task is con-
founded with genre classiﬁcation. When inspect-
ing the explicit terms dictionaries we have created,
we clearly see that genre bias reﬂected. The dic-
tionary of 32 terms that we used for the dictio-
nary lookup method consists approximately half
of terms that are quite speciﬁc to the Rap genre,
such as glock, gat, clip (gun-related), thug, beef,
gangsta, pimp, blunt (crime and drugs). Finally,
the terms holla, homie, and rapper are arguably
no causes for explicit lyrics, but highly correlated
with explicit content lyrics. Biasing an explicit
lyrics detection model away from genres is an in-
teresting future direction of work.

5 Conclusion

Classifying song lyrics as explicit or clean is an
inherently hard task to accomplish since what is
considered offensive strongly depends on cultural
aspects that can change over time. We showed
that shallow models solely based on a dictionary
of profane words achieve a performance compara-
ble to deep neural networks. We argued that even
the hand-labelling is highly subjective, making it
problematic to automatically detect if a song text
should be tagged as explicit or clean.

We propose as a possible simpliﬁcation and ob-
jectiﬁcation to study the local detection of explicit
content.
If we present an authority a report on
found trigger words, found contextual sexual con-
tent, and alike, they can come to their own subjec-
tive conclusion about the ﬁnal label of the text.

Acknowledgement

This work is partly funded by the French Research
National Agency (ANR) under
the WASABI
project (contract ANR-16-CE23-0017-01).

Million Song Database Project with Audio and Cul-
tural Metadata plus WebAudio enhanced Client Ap-
In Web Audio Conference 2017 – Col-
plications.
laborative Audio #WAC2017, London, United King-
dom. Queen Mary University of London.

Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-
Efﬁcient estimation of word
arXiv preprint

frey Dean. 2013.
representations in vector space.
arXiv:1301.3781.

Ji Ho Park and Pascale Fung. 2017. One-step and two-
step classiﬁcation for abusive language detection on
In Proceedings of the First Workshop on
twitter.
Abusive Language Online, pages 41–45. Association
for Computational Linguistics.

Laurent Vanni, M´elanie Ducoffe, Carlos Aguilar, Fred-
eric Precioso, and Damon Mayaffre. 2018. Textual
deconvolution saliency (tds): a deep tool box for lin-
guistic analysis. In Proceedings of the 56th Annual
Meeting of the Association for Computational Lin-
guistics (Volume 1: Long Papers), pages 548–557.

Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob
Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz
Kaiser, and Illia Polosukhin. 2017. Attention is all
you need. In I. Guyon, U. V. Luxburg, S. Bengio,
H. Wallach, R. Fergus, S. Vishwanathan, and R. Gar-
nett, editors, Advances in Neural Information Pro-
cessing Systems 30, pages 5998–6008. Curran As-
sociates, Inc.

Michael Wiegand, Melanie Siegel, and Josef Ruppen-
hofer. 2018. Overview of the germeval 2018 shared
task on the identiﬁcation of offensive language. In
Proceedings of GermEval 2018, 14th Conference on
Natural Language Processing (KONVENS 2018).

Marcos Zampieri, Shervin Malmasi, Preslav Nakov,
Sara Rosenthal, Noura Farra, and Ritesh Kumar.
2019. Semeval-2019 task 6: Identifying and cate-
gorizing offensive language in social media (offen-
seval). CoRR, abs/1903.08983.

References

Valerio Basile, Cristina Bosco, Elisabetta Fersini, Deb-
ora Nozza, Viviana Patti, Francisco Manuel Rangel
Pardo, Paolo Rosso, and Manuela Sanguinetti. 2019.
Semeval-2019 task 5: Multilingual detection of hate
speech against immigrants and women in twitter. In
Proceedings of the 13th International Workshop on
Semantic Evaluation, pages 54–63.

Linn Bergelid. 2018. Classiﬁcation of explicit music

content using lyrics and music metadata.

Cristina Bosco, Felice Dell’Orletta, Fabio Poletto,
Manuela Sanguinetti, and Maurizio Tesconi. 2018.
Overview of the EVALITA 2018 hate speech de-
In Proceedings of the Sixth Evalua-
tection task.
tion Campaign of Natural Language Processing and
Speech Tools for Italian. Final Workshop (EVALITA
2018) co-located with the Fifth Italian Conference
on Computational Linguistics (CLiC-it 2018), Turin,
Italy.

Hyojin Chin, Jayong Kim, Yoonjong Kim, Jinseop
Shin, and Mun Y Yi. 2018. Explicit content de-
tection in music lyrics using machine learning.
In
2018 IEEE International Conference on Big Data
and Smart Computing (BigComp), pages 517–521.
IEEE.

Jacob Devlin, Ming-Wei Chang, Kenton Lee, and
Kristina Toutanova. 2018. Bert: Pre-training of deep
bidirectional transformers for language understand-
ing. arXiv preprint arXiv:1810.04805.

Elisabetta Fersini, Paolo Rosso, and Maria An-
Overview of the task on auto-
zovino. 2018.
In
matic misogyny identiﬁcation at ibereval 2018.
IberEval@SEPLN, volume 2150 of CEUR Work-
shop Proceedings, pages 214–228. CEUR-WS.org.

Darja Fiˇser, Ruihong Huang, Vinodkumar Prab-
hakaran, Rob Voigt, Zeerak Waseem, and Jacqueline
Wernimont. 2018. Proceedings of the 2nd workshop
on abusive language online (alw2). In Proceedings
of the 2nd Workshop on Abusive Language Online
(ALW2). Association for Computational Linguistics.

Jayong Kim and Y Yi Mun. 2019. A hybrid modeling
approach for an automated lyrics-rating system for
In European Conference on Informa-
adolescents.
tion Retrieval, pages 779–786. Springer.

Quoc Le and Tomas Mikolov. 2014. Distributed repre-
sentations of sentences and documents. In Interna-
tional conference on machine learning, pages 1188–
1196.

Gabriel Meseguer-Brocal, Geoffroy Peeters, Guil-
laume Pellerin, Michel Buffa, Elena Cabrio, Cather-
ine Faron Zucker, Alain Giboin, Isabelle Mirbel, Ro-
main Hennequin, Manuel Moussallam, Francesco
Piccoli, and Thomas Fillon. 2017. WASABI: a Two

