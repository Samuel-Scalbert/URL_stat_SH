An In-depth Analysis of Implicit and Subtle Hate
Speech Messages
Nicolás Benjamín Ocampo, Ekaterina Sviridova, Elena Cabrio, Serena Villata

To cite this version:

Nicolás Benjamín Ocampo, Ekaterina Sviridova, Elena Cabrio, Serena Villata. An In-depth Analysis
of Implicit and Subtle Hate Speech Messages. EACL 2023 - 17th Conference of the European Chap-
ter of the Association for Computational Linguistics, May 2023, Dubrovnik, France. pp.1997-2013,
￿10.18653/v1/2023.eacl-main.147￿. ￿hal-04214094￿

HAL Id: hal-04214094

https://hal.science/hal-04214094

Submitted on 21 Sep 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

1997
Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics, pages 1997–2013
May 2-6, 2023 ©2023 Association for Computational Linguistics

AnIn-depthAnalysisofImplicitandSubtleHateSpeechMessagesNicolasOcampo,EkaterinaSviridova,ElenaCabrioandSerenaVillataUniversiteCôted’Azur,CNRS,Inria,I3S,Francenicolas-benjamin.ocampo@etu.univ-cotedazur.fr,ekaterina.sviridova@inria.frelena.cabrio@univ-cotedazur.fr,villata@i3s.unice.frAbstractTheresearchcarriedoutsofarindetectingabu-sivecontentinsocialmediahasprimarilyfo-cusedonovertformsofhatespeech.Whileexplicithatespeech(HS)ismoreeasilyidenti-fiablebyrecognizinghatefulwords,messagescontaininglinguisticallysubtleandimplicitformsofHS(ascircumlocution,metaphorsandsarcasm)constitutearealchallengeforauto-maticsystems.Whilethesneakyandtrickynatureofsubtlemessagesmightbeperceivedaslesshurtfulwithrespecttothesamecontentexpressedclearly,suchabuseisatleastasharm-fulasovertabuse.Inthispaper,wefirstprovideanin-depthandsystematicanalysisof7stan-dardbenchmarksforHSdetection,relyingonafine-grainedandlinguistically-groundeddefini-tionofimplicitandsubtlemessages.Then,weexperimentwithstate-of-the-artneuralnetworkarchitecturesontwosupervisedtasks,namelyimplicitHSandsubtleHSmessageclassifica-tion.Weshowthatwhilesuchmodelsperformsatisfactoryonexplicitmessages,theyfailtodetectimplicitandsubtlecontent,highlight-ingthefactthatHSdetectionisnotasolvedproblemanddeservesfurtherinvestigation.1IntroductionTherisingmassofcommunicationthroughsocialmediafurtherexacerbatesharmfulconsequencesofonlinehatespeech.Asaresult,socialmediahavefacedmountingpressurefromcivilrightsgroupsdemandingtorampuptheirenforcementofanti-hatespeechpolicies,sothattomonitorandlimitthiskindofcontent.Inthelatestyears,numer-ousmethodshavebeendevelopedtoautomaticallyidentifythistypeofutterancesexpressinghatefulorabusivecontentonsocialmediausingNaturalLan-guageProcessingmethods.Avarietyofdatasetshavealsobeenbuilt,exemplifyingvariousmani-festationsofthisharmfulcontent(Polettoetal.,2021).However,mostoftheresearchcarriedoutsofaronthistopichasfocusedonovertformsofhatespeech.Explicithatespeechismoreeasilyidentifiablebyrecognizingaclearlyhatefulwordorphrase.Onlyrecently,afewworks(Hartvigsenetal.,2022;Wiegandetal.,2022,2021a;ElSheriefetal.,2021;Jurgensetal.,2019;Waseemetal.,2017)havestartedtofocusonimplicitness,wherecircumlocution,metaphor,orstereotypesareusedtointentionallyconveyhatredtowardsaparticulargroup.Inthosemessages,hatefulnesscanbecap-turedonlybyunderstandingtheirglobalmeaning,aswellascontextualinformation.Inthispaper,wecarryoutanin-depthanaly-sisofimplicitHSinstandardbenchmarksforHSdetection.Additionally,wedefinethenotionofSubtleHSthatputsforwardhatefulmeaningselu-sivelyrelyingonhumanperceptionandthroughtheuseofcomplexsyntacticstructures.Inourstudy,wecollectmessagesfrom7availabledatasetsforHSdetectionthatcoverdifferenttopicsandareextractedfromdifferentsocialmediaplatforms,andweenrichthemwiththefollowingthree-layerannotation:HS/nonHS,Explicit/ImplicitandSub-tle/NonSubtle.Wealsoprovideafine-grainedan-notationforimplicitHSmessageswith18implicitpropertiessuchasirony,exaggeration,metaphor,andrhetoricalquestion,amongothers.ThenewlycreatedresourcenamedISHate(ImplicitandSubtleHatespeech)providesarichandvariegatebench-markforpushingforwardresearchonimplicitandsubtlehatefulmessages,andconstitutesachalleng-ingtest-bedtoevaluatecomputationalapproaches.1Additionally,weevaluateSOTAandcompetitivebaselineclassifierstodetectbothimplicitandsub-tleHSinISHate,showingthatcurrentmethodsfailtoeffectivelydetectimplicitandsubtleHSmes-sagesduetotheirpeculiarnature.NOTE:Thispapercontainsexamplesoflanguagewhichmaybeoffensivetosomereaders.Theydo1Theannotatedcorpora,andtheaccompanyingannotationguidelinesandsoftwarecanbefoundathttps://github.com/benjaminocampo/ISHate1998

notrepresenttheviewsoftheauthors.2RelatedWorkInthelatestyears,therehasbeensignificantre-searchonabusivelanguageandhatespeechde-tectionusingNaturalLanguageProcessing(NLP)methods(e.g.,Xuetal.(2012);Dadvaretal.(2013);Polettoetal.(2021);Bohraetal.(2018);Corazzaetal.(2020);Zampierietal.(2019a);Casellietal.(2020,2021)).AfewworksfocusonsubtypesofHS,suchasWarnerandHirschberg(2012)thattacklestherecognitionofantisemitism,orWaseemandHovy(2016);Badjatiyaetal.(2017);GambäckandSikdar(2017)thatinvesti-gatepredictivefeaturestoidentifyHSintheformofracismandsexism.Inthiscontext,severalchal-lengesandsharedtaskshavealsobeenorganizedovertheyears,thatmadedatasetsandresourcesformultiplelanguagesavailable(forasurvey,seePolettoetal.(2021)).Researchstudiescarriedoutsofarhavemostlyfocusedonovertformsofhatespeech,whileveryfewworksaddresstheissueofimplicitandsubtleHS(ElSheriefetal.,2021).However,severalworksshowawarenessoftheproblem.Forinstance,WarnerandHirschberg(2012)andXuetal.(2012)discusssystems’limi-tationsinidentifyingHSmessageswhichaream-biguous,havepatternsofemotionalspeechorlackcontext.ZhangandLuo(2018)andCorazzaetal.(2020)highlightthecomplexityofrecognizinghatefulmessageswhenthemeaningisconveyedthroughsarcasm,stereotypes,complexsyntacticstructure,ornon-explicitlexicalpatterns.Amongthefewstudiesthatattemptedtoaddresstheissuesofimplicitandsubtledetection,Casellietal.(2020)definesasharedtasktodetectim-plicitandexplicitabusivemessagesfromAbusEval,areannotateddatasetbasedonOLID/OffensEval(Zampierietal.,2019a).Benikovaetal.(2018)paraphrasesGermanHStweetsobtainingimplicitandexplicitmessagestostudyclassificationmeth-ods.Dadvaretal.(2013)showshowtakingusercontextimprovescyberbullyingdetectionwithnei-therexplicitprofanitiesnorapparentneutralemo-tions.Jurgensetal.(2019)andWaseemetal.(2017)explainwhyexplicitness,implicitness,andsubtletyaretypologiesofabusivenessandencour-ageresearcherstodevelopproactivetechnologiesinthisarea.ElSheriefetal.(2021)introducesataxonomyofimplicithatespeechandabenchmarkcorpuswithfine-grainedlabelsforeachmessage.Hartvigsenetal.(2022)proposesalarge-scaleap-proachtoautomaticallygeneratebenignandim-plicitHSstatementsthroughthelanguagemodelGPT3.Wiegandetal.(2021a,2022)proposesre-sourcestotackleimplicitlyabusivecomparisonsandabusiveremarks,whicharetwosubtypesofimplicitness.Wiegandetal.(2021b)explainsthekeyissuesintheimplicitabusedetection,aswellaspossiblefuturedirectionstoexplore.EventhoughthesestudiessetthebasistoexploreandmodeltheissueofimplicitHS,thereisstilllargeroomforimprovement,bothintermsofcreatingadequateresourcestoinvestigatetheseaspectsandintermsofcomputationalapproachestoaddressthem.3HS,ImplicitnessandSubtletyHateSpeechisdefinedasadirectattackagainstpeople–ratherthanconceptsorinstitutions–basedonprotectedcharacteristics(PC):race,eth-nicity,nationalorigin,disability,religiousaffili-ation,caste,sexualorientation,sex,genderiden-tity,andseveredisease(Meta,2022).Weencom-passintheconceptrefugees,migrants,immigrants,asylumseekersfromthemostsevereattacks,andoccupationswhentheyarereferencedalongwithPC,thoughcommentaryandcriticismofimmi-grationpoliciesareexcludedfromHS.Followingthisdefinition,HSdiffersfromrelatedconceptsmainlysinceitisspecificallyorientedtogroupsofpeoplewithPCasthemaintarget(Polettoetal.,2021).Inthefollowing,weprovideclearandopera-tionaldefinitionsofexplicit,implicitandsubtleHS.ReportedexamplesareextractedfromtheWhiteSupremacyForum(WSF)(deGibertetal.,2018)andtheCONAN(Chungetal.,2019)datasets,de-scribedinSection4.3.1ExplicitHateSpeechExplicitHSisunambiguousinitspotentialtobeabusive/hateful,suchaslanguagecontainingracialorhomophobicslurs.ExplicitHSuseswordswhoseliteraldefinition(takenfromthedictionary)ishateful(ElSheriefetal.,2021;Waseemetal.,2017;Casellietal.,2020),asinExample1.1.Negrosaresodumb.(WSF)3.2ImplicitHateSpeechAccordingtothedefinitionsofElSheriefetal.(2021),implicitHSdoesnotimmediatelydenoteabuse/hate.Implicitnessgoesbeyondword-relatedmeaning,implyingfigurativelanguageusesuch1999

asirony,sarcasm,etc.(ElSheriefetal.,2021;Benikovaetal.,2018),generallyhidingtherealmeaning,makingitmoredifficulttograspandunderminingthecollectionofhatefulmessages(Hartvigsenetal.,2022;Waseemetal.,2017).Therefore,wedealwithfigurativemeaningin-tendedbytheauthorratherthanliteralmeaningofwordsthatmaybeextractedfromdictionaries.Inourextensivestudyonhatespeechdatasets,weidentified18typicalpropertiesofimplicitnessrelyingonlinguisticsfeatures(listedinTable2).Amongthemostsignificantoneswehaveirony(Frendaetal.,2022),sarcasm(Potamiasetal.,2020),blackhumor,metaphor(Choietal.,2021;Gaoetal.,2018),exaggeration(Troianoetal.,2018),rhetoricalquestion,sentiment(Lietal.,2021),inference,lackofcontext(Dadvaretal.,2013),andlackofextralinguisticknowledge.MostoftheimplicitHSmessagescontaincombinationsofseveralproperties,asin:2.GlobalJewrydidnotwantBrexitandaredoingeverythingtheycantosabotageit.(CO-NAN)Example2illustratesaninterlacementofironyandexaggeration.GlobalJewryrepresentsawordplaymixingGlobalJuryandJewsaddinghumorouscontenttotheperceptionofJewishpeopleasana-tion,whiledoingeverythingishyperbolicpointingoutthatJewishareextremelyoccupiedbyBrexit.ThewholemessageisironicalasitemphasizesthatIsraelhasitsowninterestinothercountry’saffairs.3.Ialso,unfortuantely,spent7-8thgradeina95%monkeyhouse(WSF)InExample3thereisanoverlapofirony,ex-aggeration,andmetaphor(underlined).95%looksmorelikeanexaggerationthanafact,whilemonkeyhousereferstothegroupofstudentsandinthemetaphorduetotheirskincolortheyarecomparedwithmonkeys.4.AreyousurethatIslamisapeacefulreligion?(CONAN)Example4interlacesrhetoricalquestion,infer-ence,andsentiment.TherhetoricalquestiondoubtsaboutthepeacefulnessofIslam,expressingatthesametimetheauthor’stakeonit.Aswellasthat,wemayreadnegativeinferencebetweenthelines.3.3SubtleHateSpeechSubtleHateSpeechconcernshatefulmessagesthataresodelicateorelusiveastobedifficulttoan-alyzeordescribe,andthatdependonanindirectmethodtodeliverthemeaning(Merriam-Webster,2022).However,literalmeanings(Rolandetal.,1968;Bertrand,1905)areofprimeimportanceinsubtlemessagesbycontrasttoimplicitmessageswherewegobeyondliteralmeanings(Waseemetal.,2017).Althoughimplicitnessandsubtletydifferalotatthispoint,westillrelyonlanguageusers’perception(Grice,1967,1989;KortaandPerry,2020)tounderstandimplicitandsubtlemes-sages(Benikovaetal.,2018).Despitethechal-lengesincharacterizinghumanperceptionschemat-ically,inourstudy,theuseofelementssuchasnegationswithpositiveclauses,conditionals,con-nectors,unrelatedconstructions,wordorder,andcircumlocutioncangreatlyaffectthesubtletyofamessage.CasesofHSthatconveythemean-ingdirectlyandstraightforwardlyarenon-subtle.AssubtletyisevenlessstudiedthanimplicitnessinthedomainofHS(Breitfelleretal.,2019),andonlyconsideredasarelatedconceptofimplicitnessinpreviousworks(Jurgensetal.,2019;ElSheriefetal.,2021;Hartvigsenetal.,2022),weanalyzetheirinterrelation,particularlywhetheroneoftheseconceptsisanumbrellatermfortheother.First,westudywhetherexplicitHScanconveythemeaninginasubtleway,toacceptorrejecttheideathatimplicitnessisageneraltermforsubtlety.Ascanbeseenfromtheexamplebelow,amessagecanbeexplicitandsubtleatthesametime:5.Asabritmyknowledgeofamericanlawissomewhatlackingbuteveniknowthatthisholdergroidhascommittedtreason(WSF)Example5isexplicitasitliterallyconveyshatefulmeaningswiththeexpressionholdergroid,butitissubtleastheintendedhatefulmeaningisdisguisedbythefirstandsecondunderlinedconstructions,pushingouttheattentionfromtheexplicithatefulexpression.Ontheotherside,weinvestigatewhethersubtletyisanumbrellaconceptforimplicitness(whetherallimplicitmessagesaresubtlebyde-fault).Thefollowingexampleshowsanimplicitnon-subtleHSmessage:6.I’meitherinNorthFloridaorNigeriasome-timesican’ttellthedifference.(WSF)2000

Accordingtothedefinitionsofexplicitnessandimplicitness,thismessageisnotexplicitsinceitdoesnotcontainanyhatefulwords,thus,itdoesnotdirectlyconveyhatefulmeaning.However,itishatefuldespitebeingmoreelaborated,asitin-cludescertainfiguresofspeechthattriggerhatefulmeaning.TheunderlinedexpressioninExample6representsantithesis,whilethemessageitselfisironical.Thismessagealsolackscontextualinfor-mationandextralinguisticknowledge.Althoughbeingimplicit,thismessageisnotsubtleasthemeaningisdeliveredplainlywithoutanydelusionordelicacy.Basedontheseconsiderations,wecon-siderimplicitnessandsubtletyastwoseparatecon-cepts.Toillustratethedifferencebetweenimplicitnon-subtlemessagespresentedaboveandimplicitsubtlecases,considerthefollowingexample:7.IthinkitisabitlatetothinktolookafterthesaetyandthefutureofwhitepeopleinSouth-frica.(WSF)WelabelitasimplicitHSasitdoesnotexpresshatefulmeaningexplicitlyviaoffensivewordsanditisironic.Itisalsosubtleasitstartswithanintroductoryconstructionthatmakesthemessagemoresophisticatedandaddsextraweighttoit.Ascanbeexpected,itisalsopossibletofindnon-hatefulsubtleorimplicitsentences(suchasironicorsentimentaltexts).However,ourworkfocusesonexploringimplicitnessandsubtletyinthecontextofhatespeechonly,thereforethosemoregeneralcasesarenotinvestigated.4TheISHateDatasetRelyingonthefine-graineddefinitionsofHSpro-videdintheprevioussection(explicit,implicitandsubtleHS),wecollectandenrich7availablestan-darddatasetsforHSdetection.Asaresult,wecreatethefirstbenchmarkforimplicitandsubtleHSdetectiononsocialmediamessagesextractedfromdifferentsources.4.1DataCollectionNearlyallavailableresourcesofuser-generatedHScontentareretrievedwithakeyword-basedap-proach,andmainlyrelyingonalistofwordswithnegativepolarity(Polettoetal.,2021).However,withthisstrategyitispossibletoextractmainlyexplicitHSexpressions(asintheAbusEvaldataset,Casellietal.(2020)).GiventhatourstudyfocusesonimplicitandsubtleHS,weprefertoexploreresourcescollectedfromcommunitiesofusersthatarepotentiallypronetohatespeech,orresourcesmanuallycreatedusingasystematicapproach.Inthefollowing,welisttheconsideredresources:WhiteSupremacyForumDataset(WSF)(deGib-ertetal.,2018),thatcontainsHSmessagesfromStormfront,scrapedfromthemostinfluentialwhitesupremacistforumontheWeb.Thedatabaseisar-rangedinsub-forumsandconversationthreads.HatEval(Basileetal.,2019),whichisamongthemostwell-knownbenchmarkforHSdetection.Acombinedapproachisappliedtocollecthatefulandmisogynoustweetsbymonitoringpotentialvictimsofhateaccounts,downloadingthehistoryofidentifiedhaters,andfilteringTwitterstreamswithbothneutralandderogatorykeywords.ImplicitHateCorpus(IHC)(ElSheriefetal.,2021),annotatedwithexplicitHS,implicitHS,andnon-HSlabelsobtainedfromonlinehategroupsonTwitter.TheauthorsfocusedoneightideologicalclustersofU.S.,asBlackSeparatists,WhiteNa-tionalistandNeo-Nazi.FromthisdatasetweonlyextractedmessageslabeledasimplicitHS,asitisoneofourtargetcategories.ToxiGen(Hartvigsenetal.,2022),adatasetwithbenignandimplicittoxicmessagesagainstminor-itygroups.ToxiGenismachine-generatedthroughtheGPT3languagemodelandpromptprogram-ming.SimilarlytoIHC,weonlyextractedmes-sageswhichwereautomaticallylabeledasimplicitHSandhuman-validatedastoxicbytheauthors.Wedidnotconsiderunfinishedgeneratedsentenceswhichmakeapartofimplicitmessages.YouTubeVideoCommentsDataset(YouTube)(Hammer,2017),thatconsistsofYouTubecom-mentspostedundervideosrelatedtoreligionandpolitics.Differentlyfromtheotherresources,themessagesareannotatedas“violent”or“clean”.CONAN(Chungetal.,2019),adatasetofHSmes-sagesandcounter-narratives(CN)pairsforCNgen-eration.TwonativeEnglishspeakerswereaskedtowrite50prototypicalshorttexts,whichNGOcouldlaterusetowritetheirhatetextsandcounter-narratives.WebelievethatmessagesforwhichaCNcanbeprovidedmightbericherinimplicitcon-tentsinceaslur-basedexplicitHSmessagemightproduceverypoorargumentativeCN.Multi-TargetCONAN(MCONAN)(Fantonetal.,2021),adatasetofEnglishHS/CNpairscompris-ingseveralhatetargets.ItiscollectedusingaHuman-in-the-Loopapproach.Agenerativelan-2001

guagemodelisrefinediterativelybyusingdatafromthepreviousloopstogeneratenewsamplesthatNGOsexpertsreview.Beforestartingtheannotationprocesswiththefine-grainedannotations(Explicit,ImplicitandSubtleHS),wehadtomakesurethatthedefinitionofHSoriginallyusedtoannotatesuchresourcesisconsistentwithours.Inthefirstannotationround,wecheckedthemessagesoriginallyannotatedasHS,anddiscardedthefewonesthatdidnotcorre-spondtothedefinitionofHSreportedinSection3.FortheYouTubedataset,wealsoaddedtheHSlabels.WhileallthemessagesannotatedasHSaredirectedtoPC,itshouldbenotedthatthetop-icsdistributionandthewritingqualitymightbedifferent,giventheheterogeneityoftheselectedresources.HSmessagesmostlytargetIslamism,Judaism,misogyny,multi-culturalism,racism,im-migration,andrefugees.Regardingtimecreation,WSFismadefromthreadspostedbetween2002and2017,ToxiGen’sLMwastrainedwithmes-sagesfrom2016to2019,Hatevalconsistsofmes-sagesof2018,theYouTubecommentswerecol-lectedin2017,whiletheIHCcontainstweetsfromU.S.ideologicalclustersfrom2015to2017.4.2AnnotationProcedureFollowingtheannotationschemedescribedinSec-tion3,fourgraduate-levelannotatorswithlinguis-ticsandcomputationallinguisticscompetencescar-riedoutapilotannotationstudyonasampleof100messagesextractedfromeachoftheabovementionedresourcestoconvergetonon-ambiguousannotationstrategies.WecalculatetheInterAn-notatorAgreement(IAA)onthissample,result-inginCohen’sκ=0.793(Cohen,1960)fortheim-plicitlayer(binaryannotationExplicit/Implicit)and0.730forthesubtletylayer(binaryannotationSubtle/Non-Subtle).WealsocomputetheIAAcon-sideringbothlayerssimultaneously,thatis,consid-eringonelayerof4classes(Implicit,Explicit,Sub-tle,Non-Subtle),obtainingaCohen’sκof0.734.Inthereconciliationphase,wenoticethatmostofthedisagreementsareduetotheinterlacementofsubtletyandimplicitness.Forthatreason,wealsocalculateanorderedweighteddisagreementusingKrippendorff’sαtopenalizelesswhentheanno-tatorsagreeatleastononeofthelayers(ArtsteinandPoesio,2008).TheKrippendorff’sαis0.757.Despitethecomplexityoftheannotationtask,ob-tainedresultsareconsideredasstrongagreementinatwo-annotatorssetting.Therestofthean-notationshasthenbeencarriedoutbytwooftheannotatorsmentionedabove,whichwereprovidedwiththefinalversionoftheannotationguidelines(containingthedefinitionsofthetargetclasses,i.e.,subtletyandimplicitness,andadiscussionaboutborderlinecases),togetherwithasetoflabeledexamples.Finally,theimplicitpropertiesannotationsareaddedontopofthemessageslabeledasimplicitasanadditionalannotationlayertohighlight18linguisticfeaturesthatimplicitlyconveyhatefulmeaning.Forthislayer,annotationsarecarriedoutbyoneexpertlinguist.4.3DataStatisticsTable1showsstatisticsofthefinaldataset,report-ingonthenumberofannotatedHSmessagesforeachresourceandforthethreeannotationlayers.TheISHatecollectionconsistsofatotalof29116messages,where11247areHS(furtherannotatedwiththeExplicit/ImplicitandSubtle/Non-subtlelabels).Forcomputationalpurposes,weprovideadatasetsplitinthreesubsets,i.e.,train(70%),validation(15%),andtest(15%)sets.Eachofthepartitionrespectsthedistributionofalltheanno-tationlayersusingstratifiedsplitting.Ascanbeseen,classesareunbalanced,eachresourceprovid-ingonlyareducednumberofimplicitandsubtlemessages-asexpected.NotethatCONANandMCONANdonotcontainNon-HSmessages,be-causetheirmainobjectiveisCNgeneration.AsforIHCandToxiGen,weonlylookthroughprevi-ouslyannotatedimplicitHSmessagesdisregardingnonhatefulones.NotealsothatToxiGenclaimedtocontainonlyimplicitadversarialmessages,butaccordingtoourdefinitionsandannotationguide-linesmanymessagesareconsideredasexplicitandnon-subtlebyourannotators.Table2showsthefulldistributionoftheim-plicitpropertiesrelativetotheimplicitmessagesinISHate.Asitcanbeseen,Inference(58%),Con-text(48%),Sentiment(45%),Exaggeration(28%)andIrony(22%),arethemostfrequentproper-tiesofimplicitHSmessages,whereasEuphemism(4%),Circumlocution(3%),Metonymy(0.4%)andSynecdoche(0.08%)aretheleastrecurrent.Notethatoneimplicitmessagecanbelabeledwithmorethanoneproperty.2002

TrainDevTestCONANHatEvalIHCMCONANToxiGenWSFYoutubeLabel#%#%#%Non-HS12508.6142680.6142681.6140742100093421106ExplicitHS7007.3441501.3441501.344324310731733441839871747ImplicitHS866.042186.043186.04381110300295170173109Non-HS12508.6142680.6142681.6140742100093421106Non-Subtle7691.3771648.3771648.3773933191614359534810181828Subtle182.00939.00939.0091226344514228Table1:Statisticsontheannotateddataset(resourcesandlabeldistributionsforthetwotasks)ImplicitHSImplicitProperties#%Inference72958.885Context60248.627Sentiment56945.961Exaggeration35928.998Irony27522.213Extralinguisticknowledge19315.590Blackhumor14411.632Rhetoricalquestion13410.824Visualsigns1229.855Humiliation1159.289Antithesis977.835Metaphor937.512Sarcasm856.866Fallacy745.977Euphemism564.523Circumlocution413.312Metonymy60.485Synecdoche10.081Table2:Statisticsonimplicitpropertiesdistribution.4.4DataAugmentationToovercometheproblemoftheunbalanceddataset,weproposeoversamplinganddataaugmentation(DA)methodsfortheminorityclassesusingad-versarialmethodsandgenerativemodelsfollowing(Mayeretal.,2020;WeiandZou,2019),andtheGPT2languagemodel(Radfordetal.,2019).ReplaceNamedEntities(RNE).Itreplacesanamedentity(PER,LOC,ORG,andMISC)intheinputsentence.AcandidateNEinasentenceisreplacedbyanotheroneaccordingtoapreviouslycollectedlistofNEs(Mayeretal.,2020).Then,themostsimilarNEisselectedbyusingpre-trainedFastTextembeddings(Bojanowskietal.,2016).Inourusecase,wenoticethatthenumberofNEsPER,LOC,andORGareveryfewcomparedtoMISC.ThismightbeduetothefactthatHSmes-sagesinourcollectionmostlytargetgroupsandnotindividuals.However,expressionslikemuslims,jews,orblacksarepresentintheMISCcategoryandreplaced,asinExample8.Asitcanbeno-ticed,theexpressionpreservesitsmeaning,thatis,theuseoftherhetoricalquestiontoconveythatMuslimsarenotconsideredasapartofsociety.8.Original:HaveMuslimsevermadeacontri-butiontooursociety?(CONAN)Augmented:HaveMoslemArabsevermadeacontributiontooursociety?ReplaceScalarAdverbs(RSA).Itreplacesem-phasisingadverbslikeconsiderablyorlargely,withanotherscalaradverbthatmightincreaseorde-creasetheemphasisofanadjective/verb.9.Original:Idoliketheoutfittheydressedthesimianin;helookssoregal(WSF)Augmented:Idoliketheoutfittheydressedthesimianin;helooksincrediblyregalExample9isanotherimplicitracistHSmessagethatusesironybycombiningsimian,dressed,andregal.RSAreplacesthescalaradverb,slightlyincreasingtheemphasisofregalinthesentence.AddAdverbstoVerbs(AAV).Itaddsmodifierstoverbstoaccentuatethem.Inthiscase,weusespeculativeadverbslikecertainly,likely,clearly.10.Original:Iwishwelivedinaworldinwhichonlymencouldbedoctors,lawyers,firemen,andteachers.(MCONAN)Augmented:Iwishwelivedinaworldinwhichonlymencouldplausiblybedoctors,lawyers,firemen,andteachers.InExample10,themeaningismadeelusivebytheuseoftheexpressionIwishwelived,theadditionofplausiblyaltersthepossibilityoftheverb“tobe”,butkeepsthemisogynymeaning.ReplaceAdjectives(RA).Itreplacesadjectiveswiththeirsynonyms,asin:11.Original:IfyoulookatanAlaskanmala-muteandatimberwolfthataretwodifferentspecies,theylookalotmorealikethansayaCongoleseandaSwede.(WSF)Augmented:IfyoulookatanAlaskanmala-muteandatimberwolfthataretwounlikespecies,theylookalotmorealikethansayaCongoleseandaSwede.2003

ReplaceIn-DomainExpressions(RI).Itreplacesalistofmanually-craftedexpressionsoftenusedinHSmessages(notcapturedbytheRNE)withothersemanticallysimilarexpressions,asinExample12.Heretheword“migrants”isreplacedby“foreign-ers”withoutaddinghatefulconnotations.Itwouldhavebeendifferenttoreplaceitwithaliens,whichisaderogatorytermtorefertomigrants.12.Original:migrantsareenteringtheu.s.justtoobtainwelfareandotherbenefits.(MCO-NAN)Augmented:foreignersareenteringtheu.s.justtoobtainwelfareandotherbenefits.EasyDataAugmentation(EDA).Givenaninputsentence,EDArandomly:i)replacesanon-stopwordexpressionwithasynonymusingWordnet;ii)insertsasynonymofanon-stopwordinarandomposition;iii)choosestwowordsofthesentenceandswapstheirpositions;iv)removeseachwordinthesentencewithacertainprobability.Onlyoneofthefouroperationsatatimeisappliedtoasentence.13.Original:Alotofwhitewomenaretryingtocreatedangerbydrawingtheseotherpeopleintoourcountries.(WSF)Augmented:Alotofourwomenaretryingtocreatedangerbydrawingtheseotherpeopleintowhitecountries.Aparameterαexpressingthepercentofthewordstobechangedinasentenceisspecified(inoursetting,α=0.1asinWeiandZou(2019)).BackTranslation.Ittranslatesaninputmessageintoadifferentlanguagetotranslateitbackintotheoriginallanguage.WeusethetranslationfromEn-glishtoRussianfollowing(ElSheriefetal.,2021).14.Original:Asanation,weareindesperateneedforanimmigrationtimeoutandazerotolerancepolicyforthosehereillegally.(WSF)Augmented:Asanation,wedesperatelyneedanimmigrationtime-outandazero-tolerancepolicyforthosehereillegally.GenerativeModels(GM).Wefine-tuneautore-gressivegenerativelanguagemodelswithinstancesfromourminorityclasses,i.e.,explicitsubtle,im-plicitnon-subtle,andimplicitsubtlemessages.Todoso,weprefixthislabelonthetextasaprompt.Then,languagemodelsareaskedtogeneratemes-sagesstartingwithoneofourfine-tunedprompts,asinExample15.WeuseGPT2(Radfordetal.,2019)asalanguagemodel,fine-tunedfor4epochsusinglearningrateof3e-5,andbatchsizeof32.Additionally,weimplementahuman-in-the-loopapproachrevisingthegeneratedexamplesandre-annotatingthemincasetheoriginallabelisno-moreappropriateforthemessage.15.Input:ExplicitSubtleHS:Augmented:ExplicitSubtleHS:Intheend,itcomesdowntowhatwomenwantfromaman...Iftheywanttoplaywithwhores,theycanstayathomeandhavebabies...ExceptforGMandBT,thesamestrategyisappliedtoaugmentationmethodstoproducenewmessages.Preprocessing(e.g.,Parts-of-Speechtag-gingandNamedEntitiesRecognition)iscarriedoutusingFlair(Akbiketal.,2019)andNLTK(BirdandLoper,2004)models,andallowstorecognizepossiblecandidatephrasestoperformareplace-ment/addition.Then,acandidatephraseisper-turbedbyanotheroneaccordingtoalistofadverbs,NEs,oradjectivesbasedondomaindata.WerelyonFastTextandWordNetSynsetstomaintainthesemanticsoftheaugmentedsentenceswithrespecttotheoriginalone.Thenumberofcandidatestoperformareplacement/additionandthenumberofreplacement/additionspercandidateareprovidedasparameterstothesemethods.5EvaluationToshowthatimplicitandsubtleHSdetectionisstillaverychallengingtask,weevaluateasetofstate-of-the-artmodelsforHSdetectionontheISHatedataset.Weproposetwo3-labelclassifi-cationtasks:•TaskA(Non-HS/ExplicitHS/ImplicitHS)•TaskB(Non-HS/Non-SubtleHS/SubtleHS)Tothisgoal,weconsiderthefollowingmodels:UniversalSentenceEncoder(USE)+SVM(In-durthietal.,2019).First-rankedmodelontheHatE-valbenchmark(Basileetal.,2019).TheUSE(Ceretal.,2018)isasentenceembeddingthatencodestextintohighdimensionalvectorsof512dimen-sions,trainedonlargedatasourcestoprovideanencodingmethodthatworksforvariousNLPtasks.AnSVMclassifierwithRBFkernelanddefaultparametersisthenusedforclassification.2004

DeBERTaV3(hate_speech18).SOTAmodelontheWSFdataset(deGibertetal.,2018).Forclassi-fication,adefaultHuggingFaceimplementationofaone-layerFeedForwardnetworkisusedontopofDeBERTa(Heetal.,2021a,b),atransformer-basedmodel.Themodelislaterfine-tunedfor4epochs(learningrateof2e-5,batchsizeof32).BERT(Devlinetal.,2018).WeusethislanguagemodeltoencodetextsequencesandclassifythembyaddingaFeed-forwardneuralnetworkontop.HateBERT.Are-trainedBERTmodelusingover1millionpostsfrombannedcommunitiesonReddit(Casellietal.,2021)andthenfine-tunedonourdataset.HateBERTobtainedverypromisingresultsinthebenchmarksHatEval,OffensEval(Zampierietal.,2019b),andAbusEval(Casellietal.,2020).Asforpreprocessing,wereplacelongnon-spacecharacterchainsforonlyoneoccurrence,anddeletedigits,specialsymbols,andURLs.5.1ResultsTable3reportsontheresultsofthedifferentmod-elsonthetwotasks.Onbothtasks,allmodelsshowsatisfactoryperformanceswhendetectingovertformsofHS(ExplicitHSandNon-SubtleHSclasses),withDeBERTaoutperformingtheothermodels.TheresultsobtainedbyallmodelsfortheImplicitHSandSubtleHSclassesaremuchlower,andcomparabletothoseobtainedbyElSheriefetal.(2021)(F1-score=.586)ontheimplicitclass.Asafollow-upexperiment,weapplytheover-samplingtechniques(Section4)ontheminorityclassesoftasksAandBuntilbalancingthemwithrespecttotheExplicitHSandNon-SubtleHScat-egories.Theoversamplingisperformedonthetrainingsetonly.Thetestsetistheoneoftheorigi-naldataset,andisthereforeunbalancedinordertoevaluatethesystemonrealclassdistributionandtoavoidinformationleakagefromtraintotestthroughaugmentationmethods.Tables4aand4bshowthenumberofadditionalgeneratedimplicit/subtlemes-sagesandtheresultanttrainingsetdistributionperaugmentationmethod,respectively.Amongalltestedmodels,onlyHateBERTsig-nificantlyimprovesitsperformancefordetect-ingimplicitmessagescombiningallaugmenteddata(ALL)(seeTable3).Wealsohighlightthatbacktranslation(BT)bettercontributestotheperformanceontheimplicithateclassforBERT,DeBERTa,andUSE+SVM2.Performances2ThetablereportingtheobtainedresultsbyallmodelsonsurprisinglyincreaseforthesubtleclasswithUSE+SVM+BTshowingthatback-translatedmes-sagesprovidediversitybyrephrasingsubtleex-ampleswithoutalteringtheirmeaning.DatageneratedwithsimpleraugmentationmethodsasBERT+RNEandDeBERTa+RIalsoshowslightim-provementsforsubtlety.However,performancesdecreaseontheimplicitclasswhenapplyingdataaugmentationstrategiesGMandGM+Revised,andonlyslightlyimproveonthesubtleclass.5.2ErrorAnalysisTogaininsightsintothemodels’behaviours,wemanuallyanalysetheclassificationerrorsofthebestperformingapproaches,i.e.,HateBERT+ALLandUSE+SVM+BTforbothtasksAandB.FortheNon-HS/Explicit/Implicitclassification,itisharderforHateBERT+ALLtodifferentiateimplicitmessagesratherthanexplicitones.Figure1inAp-pendixAshowstheresultantembeddingthrought-SNE(vanderMaatenandHinton,2008)approx-imationofallimplicitmessagesofthetestset,andtwosamplesoftheothertwoclasses,show-inghowHateBERT+ALLiscapableofseparatingthespaceinthreedifferentblobsforclassification(Figure1a),embeddingwellthehuman-annotatedExplicitHSandNon-HSclasses(Figure1b),butbadlyencodingimplicitannotatedmessages(in-stancesspreadovertheexplicitandnon-hatefulblobs).WealsoconsideredtheF1-scoresofthe(Non-HSvsImplicitHS)and(Non-HSvsExplicitHS)classes,asifwehadbinarylabels,obtainingan(F1-score=0.670)and(F1-score=0.850)onthetargetcategoriesrespectively,showingthatimplicitcasesarehardertodetectthanexplicitones.Amongmisclassifiedexamples,wecanfindmes-sageswherethePCarenotexplicitlynamed(Exam-ple16).Contextualknowledgeisneededtheretograspthatthetargetofthemessageisblackpeople.16.Icanpicturehimasthatbabymonkeyonthe’savetherainforestcomercialorwhateverAdditionally,fromthemisclassifiedmessagesweextractthemostfrequentimplicitpropertiesnotcapturedbytheclassifier3.TheyconcernInference(53%),Context(41%),Sentiment(40%),Exagger-ation(24%),Extralinguisticknowledge(24%).ForSubtle/NonSubtlemessageclassification,wealsoplottedtheUSEembeddingforthebestdifferenttypesofaugmenteddataisintheAppendix.3ThefulltablecanbefoundintheAppendix.2005

TaskATaskBPRF1PRF1PRF1PRF1PRF1PRF1ModelNon-HSExplicitHSImplicitHSNon-HSNon-SubtleHSSubtleHSUSE+SVM.888.866.877.766.803.784.399.382.390.891.868.879.783.832.807.667.103.178BERT.903.893.898.81.833.821.394.371.382.902.891.897.819.846.832.250.103.145HateBERT.904.89.897.811.849.829.447.382.412.903.890.897.814.850.831.143.026.043DeBERTa.927.899.913.825.880.851.467.419.442.920.893.906.823.877.849.375.077.128HateBERT+ALL.903.896.899.827.827.827.502.559.529.903.881.892.816.844.830.391.462.424BERT+BT.909.887.898.824.826.825.459.608.523.898.900.899.839.832.835.304.359.329DeBERTa+BT.919.885.902.830.857.844.428.543.479.920.897.908.835.876.855.385.256.308USE+SVM+BT.897.856.876.782.787.785.403.645.496.892.868.880.789.831.809.739.436.548BERT+RNE.897.897.897.807.829.818.455.349.395.899.895.897.826.839.833.400.256.312DeBERTa+RI.922.894.908.821.878.849.460.398.427.910.894.902.828.860.843.364.205.262HateBERT+GM.901.898.899.824.827.825.414.425.419.899.898.899.831.834.832.250.231.240HateBERT+GM+R..905.891.898.816.835.826.408.419.414.894.898.896.826.826.826.192.128.154Table3:ObtainedresultsontasksAandB.Aug.methodRSAAAVRNERIRAEDABTGMGM+RevisedALLLabelImplicitHS6848703282881746769357482008223957SubtleHS31923136480210172291217920020410685(a)Numberofadditionalimplicit/subtlemessagesgeneratedbyeachaugmentationmethod.Aug.methodORIGRSAAAVRNERIRAEDABTGMGM+RevisedALLLabelNon-HS.614.459.456.59.590.600.458.592.608.611.282ExplicitHS.344.257.256.33.331.336.257.332.340.342.158ImplicitHS.042.283.288.08.079.064.286.076.052.046.560Non-HS.614.531.532.600.607.609.537.608.608.608.403Non-SubtleHS.377.326.327.369.374.374.330.374.374.374.248SubtleHS.009.143.141.032.019.017.133.018.019.019.350(b)Trainsetdistribution(%)peraugmentationmethod(ORIGcorrespondstotheoriginaltraindistribution).Table4:Statisticsonthetrainsetwithdataaugmentation.modelonthistask(Figure2inAppendixA).How-ever,itcanbeseenthatUSE+SVM+BTcouldnotdifferentiatecorrectlyonthesubtlenotiondespiteoftheresultsreportedinTable6b.Example17isnotpredictedassubtle.Itshowshowthewordordermayinfluenceourunderstanding.Atafirstglance,theparthowstupidtheJewsseemstohaveadifferentmeaningfromwhatthephraseactuallyconveysifwereaditentirely.Wemayalsonoticeacircumlocutioninthesecondpartofthemessage.17.Iaminsultedbyhowstupidthejewsthinkweareuntiliseewhattheyseebyreadingthepostsamongstoursocalled,‘‘awakenedbrethren.6ConclusionsInthispaper,wehavepresentedISHate,thefirstbenchmarkdatasetannotatedwithbothimplicitandsubtleHSlabels,whichrepresentsachallengingtest-bedtoevaluatecomputationalapproaches.Wealsoprovideafine-grainedannotationforimplicitHSmessageswith18implicitpropertieswhichrepresenttherelevantfeaturesthatHSclassifiersshouldpossesstoimproveimplicitHSdetection.Ithasbeencreatedenriching7existingdatasetsforHSdetectionoverdifferenttopicsandfromdif-ferentsocialmedia.WehaveshownthatcurrentSOTAmodelsfailtoproperlydetectimplicitandsubtleHSmessagesaspeculiarfeaturesconnectedtoSentiment,Inference,ContextandIrony,aswellascomplexsyntacticstructure,cannotbeproperlyunderstood.Wealsoinvestigateddataaugmenta-tionstrategiestoincreasethenumberofinstancesfortheminorityclasses.Weshowthat-whiletheycannotbetheultimatesolutiontothelackofim-plicitandsubtleexamples-theystillplayaroleinimprovingthesystems’performances,inlinewithElSheriefetal.(2021).Asforfuturework,weplantoproposealternativelarge-scalemethodstocollectimplicitandsubtlemessagesbytargeting“hateful”users,manualcreation(Wiegandetal.,2021a,2022)orrefininghuman-in-the-loopgener-ativemethodsasin(Hartvigsenetal.,2022).Also,wewillinvestigatefeaturesmodelingimplicitprop-erties(Wallaceetal.,2014;Troianoetal.,2018;FrendaandPatti,2019)andnewmodelarchitec-turesforHSdetection(Nejadgholietal.,2022).2006

LimitationsThemainlimitationofthispaperliesintheintrinsicdifficultytoprovideacleardefinitionofthenotionsofImplicitHSandSubtleHS(giventhelimitednumberofdefinitionsavailableintheliteratureforthesenotions),and,asaconsequence,tobuildan-notatedresources.EnhancingtheISHatedatasetwithnewinstancesrequiresfutureannotatorstobeexpertsincomputationallinguisticstrainedonourannotationguidelinesthroughpilotannotationstokeepthesamelevelofagreement.Thisrestrictscrowdsourcing-likeoptions,makingtheresourcebuildingprocessmoreexpensive.Moreover,thecomplexityofthemessagesandoftheconsideredcategoriesmakestheprocesstime-consuming(i.e.,atrainedannotatorrequires30sec.forexplicitmes-sagesand1.30min.forimplicit/subtlemessagesonaverage).Evenoptingforgenerativeandsyntheticdataaugmentationapproaches,theystillrequirehuman-in-the-loopinterventionandhighcompu-tationalresourcestogenerateImplicit/SubtleHSmessagesonabigscale.EthicsStatementThispapercontainsexamplesofHSfromexistinglinguisticresourcesforHSdetectionandwhichdonotreflecttheauthors’opinions.WhileourpurposeistopreventandcuratesocialmediaresourcesfromHS,thereleaseofthisdatasetmightstillposeapotentialmisusecase.However,westillconsiderthateffectiveclassifiersforthistaskarenecessarytotackleimplicitandsubtleon-linehateonscaleandpreventthespreadingofthisharmfulcontentonline.Ourworkaimsatmakingasteptowardsthatobjectiveandencouragesthescientificcommunitytoinvestigatetheseaspects.AcknowledgementsThisworkhasbeensupportedbytheFrenchgov-ernment,throughthe3IACôted’AzurInvestmentsintheFutureprojectmanagedbytheNationalRe-searchAgency(ANR)withthereferencenumberANR-19-P3IA-0002.ReferencesAlanAkbik,TanjaBergmann,DuncanBlythe,KashifRasul,StefanSchweter,andRolandVollgraf.2019.FLAIR:Aneasy-to-useframeworkforstate-of-the-artNLP.InNAACL2019,2019AnnualConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics(Demonstrations),pages54–59.RonArtsteinandMassimoPoesio.2008.Surveyarticle:Inter-coderagreementforcomputationallinguistics.ComputationalLinguistics,34(4):555–596.PinkeshBadjatiya,ShashankGupta,ManishGupta,andVasudevaVarma.2017.Deeplearningforhatespeechdetectionintweets.CoRR,abs/1706.00188.ValerioBasile,CristinaBosco,ElisabettaFersini,DeboraNozza,VivianaPatti,FranciscoManuelRangelPardo,PaoloRosso,andManuelaSanguinetti.2019.SemEval-2019Task5:MultilingualDetectionofHateSpeechAgainstImmigrantsandWomeninTwitter.InProceedingsofthe13thInternationalWorkshoponSemanticEvaluation,pages54–63,Min-neapolis,Minnesota,USA.AssociationforCompu-tationalLinguistics.DarinaBenikova,MichaelWojatzki,andTorstenZesch.2018.WhatDoesThisImply?ExaminingtheIm-pactofImplicitnessonthePerceptionofHateSpeech.InLanguageTechnologiesfortheChallengesoftheDigitalAge,pages171–179,Cham.SpringerInterna-tionalPublishing.RussellBertrand.1905.Ondenoting.Mind,56(14):479–493.StevenBirdandEdwardLoper.2004.NLTK:Thenatu-rallanguagetoolkit.InProceedingsoftheACLIn-teractivePosterandDemonstrationSessions,pages214–217,Barcelona,Spain.AssociationforCompu-tationalLinguistics.AdityaBohra,DeepanshuVijay,VinaySingh,SyedSar-farazAkhtar,andManishShrivastava.2018.AdatasetofHindi-Englishcode-mixedsocialmediatextforhatespeechdetection.InProceedingsoftheSecondWorkshoponComputationalModelingofPeople’sOpinions,Personality,andEmotionsinSocialMedia,pages36–41,NewOrleans,Louisiana,USA.AssociationforComputationalLinguistics.PiotrBojanowski,EdouardGrave,ArmandJoulin,andTomásMikolov.2016.Enrichingwordvectorswithsubwordinformation.CoRR,abs/1607.04606.LukeBreitfeller,EmilyAhn,DavidJurgens,andYuliaTsvetkov.2019.FindingMicroaggressionsintheWild:ACaseforLocatingElusivePhenomenainSo-cialMediaPosts.InProceedingsofthe2019Confer-enceonEmpiricalMethodsinNaturalLanguagePro-cessingandthe9thInternationalJointConferenceonNaturalLanguageProcessing(EMNLP-IJCNLP),pages1664–1674,HongKong,China.AssociationforComputationalLinguistics.MiguelCasasGómez.2009.Towardsanewapproachtothelinguisticdefinitionofeuphemism.LanguageSciences,31(6):725–739.2007

TommasoCaselli,ValerioBasile,JelenaMitrovi´c,andMichaelGranitzer.2021.HateBERT:RetrainingBERTforabusivelanguagedetectioninEnglish.InProceedingsofthe5thWorkshoponOnlineAbuseandHarms(WOAH2021),pages17–25,Online.As-sociationforComputationalLinguistics.TommasoCaselli,ValerioBasile,JelenaMitrovi´c,IngaKartoziya,andMichaelGranitzer.2020.IFeelOf-fended,Don’tBeAbusive!Implicit/ExplicitMes-sagesinOffensiveandAbusiveLanguage.InPro-ceedingsofthe12thLanguageResourcesandEvalua-tionConference,pages6193–6202,Marseille,France.EuropeanLanguageResourcesAssociation.DanielCer,YinfeiYang,Sheng-yiKong,NanHua,NicoleLimtiaco,RhomniSt.John,NoahCon-stant,MarioGuajardo-Cespedes,SteveYuan,ChrisTar,Yun-HsuanSung,BrianStrope,andRayKurzweil.2018.Universalsentenceencoder.CoRR,abs/1803.11175.MinjinChoi,SunkyungLee,EunseongChoi,HeesooPark,JunhyukLee,DongwonLee,andJongwukLee.2021.MelBERT:MetaphorDetectionviaContex-tualizedLateInteractionusingMetaphoricalIden-tificationTheories.Number:arXiv:2104.13615arXiv:2104.13615[cs].Yi-LingChung,ElizavetaKuzmenko,SerraSinemTekiroglu,andMarcoGuerini.2019.CONAN-COunterNArrativesthroughnichesourcing:amul-tilingualdatasetofresponsestofightonlinehatespeech.InProceedingsofthe57thAnnualMeet-ingoftheAssociationforComputationalLinguistics,pages2819–2829,Florence,Italy.AssociationforComputationalLinguistics.JacobCohen.1960.Acoefficientofagreementfornominalscales.EducationalandPsychologicalMea-surement,20(1):37–46.MicheleCorazza,StefanoMenini,ElenaCabrio,SaraTonelli,andSerenaVillata.2020.Amultilingualevaluationforonlinehatespeechdetection.ACMTrans.InternetTechnol.,20(2).MaralDadvar,DolfTrieschnigg,RoelandOrdelman,andFranciskadeJong.2013.Improvingcyberbul-lyingdetectionwithusercontext.InProceedingsofthe35thEuropeanConferenceonAdvancesinInfor-mationRetrieval,ECIR’13,page693–696,Berlin,Heidelberg.Springer-Verlag.OnadeGibert,NaiaraPerez,AitorGarcía-Pablos,andMontseCuadros.2018.HateSpeechDatasetfromaWhiteSupremacyForum.arXiv:1809.04444[cs].ArXiv:1809.04444.JacobDevlin,Ming-WeiChang,KentonLee,andKristinaToutanova.2018.BERT:pre-trainingofdeepbidirectionaltransformersforlanguageunder-standing.CoRR,abs/1810.04805.CollinsDictionary.2022.Collinsdictionary.MaiElSherief,CalebZiems,DavidMuchlinski,Vaish-naviAnupindi,JordynSeybolt,MunmunDeChoud-hury,andDiyiYang.2021.Latenthatred:Abench-markforunderstandingimplicithatespeech.InPro-ceedingsofthe2021ConferenceonEmpiricalMeth-odsinNaturalLanguageProcessing,pages345–363,OnlineandPuntaCana,DominicanRepublic.Asso-ciationforComputationalLinguistics.MargheritaFanton,HelenaBonaldi,SerraSinemTekiro˘glu,andMarcoGuerini.2021.Human-in-the-LoopforDataCollection:aMulti-TargetCounterNarrativeDatasettoFightOnlineHateSpeech.InProceedingsofthe59thAnnualMeetingoftheAsso-ciationforComputationalLinguistics.AssociationforComputationalLinguistics.JaneFrank.1990.Youcallthatarhetoricalquestion?:Formsandfunctionsofrhetoricalquestionsincon-versation.JournalofPragmatics,14(5):723–738.SimonaFrenda,AlessandraTeresaCignarella,Vale-rioBasile,CristinaBosco,VivianaPatti,andPaoloRosso.2022.Theunbearablehurtfulnessofsarcasm.ExpertSyst.Appl.,193(C).SimonaFrendaandVivianaPatti.2019.ComputationalModelsforIronyDetectioninThreeSpanishVariants.page13.BjörnGambäckandUtpalKumarSikdar.2017.Usingconvolutionalneuralnetworkstoclassifyhate-speech.InProceedingsoftheFirstWorkshoponAbusiveLan-guageOnline,pages85–90,Vancouver,BC,Canada.AssociationforComputationalLinguistics.GeGao,EunsolChoi,YejinChoi,andLukeZettle-moyer.2018.NeuralMetaphorDetectioninContext.InProceedingsofthe2018ConferenceonEmpiri-calMethodsinNaturalLanguageProcessing,pages607–613,Brussels,Belgium.AssociationforCom-putationalLinguistics.HerbertPaulGrice.1967.Logicandconversation.InPaulGrice,editor,StudiesintheWayofWords,pages41–58.HarvardUniversityPress.HerbertPaulGrice.1989.StudiesintheWayofWords.Cambridge:HarvardUniversityPress.HugoLewiHammer.2017.AutomaticDetectionofHatefulCommentsinOnlineDiscussion.InIndus-trialNetworksandIntelligentSystems,pages164–173,Cham.SpringerInternationalPublishing.ThomasHartvigsen,SaadiaGabriel,HamidPalangi,MaartenSap,DipankarRay,andEceKamar.2022.ToxiGen:ALarge-ScaleMachine-GeneratedDatasetforAdversarialandImplicitHateSpeechDetection.PengchengHe,JianfengGao,andWeizhuChen.2021a.Debertav3:Improvingdebertausingelectra-stylepre-trainingwithgradient-disentangledembeddingshar-ing.2008

PengchengHe,XiaodongLiu,JianfengGao,andWeizhuChen.2021b.Deberta:Decoding-enhancedbertwithdisentangledattention.InInternationalConferenceonLearningRepresentations.VijayasaradhiIndurthi,BakhtiyarSyed,ManishShri-vastava,NikhilChakravartula,ManishGupta,andVasudevaVarma.2019.FERMIatSemEval-2019task5:UsingsentenceembeddingstoidentifyhatespeechagainstimmigrantsandwomeninTwitter.InProceedingsofthe13thInternationalWorkshoponSemanticEvaluation,pages70–74,Minneapo-lis,Minnesota,USA.AssociationforComputationalLinguistics.DavidJurgens,LibbyHemphill,andEshwarChan-drasekharan.2019.Ajustandcomprehensivestrat-egyforusingNLPtoaddressonlineabuse.InPro-ceedingsofthe57thAnnualMeetingoftheAsso-ciationforComputationalLinguistics,pages3658–3666,Florence,Italy.AssociationforComputationalLinguistics.KepaKortaandJohnPerry.2020.Pragmatics.InEd-wardN.Zalta,editor,TheStanfordEncyclopediaofPhilosophy,Spring2020edition.MetaphysicsRe-searchLab,StanfordUniversity.ZhengyanLi,YichengZou,ChongZhang,QiZhang,andZhongyuWei.2021.Learningimplicitsentimentinaspect-basedsentimentanalysiswithsupervisedcontrastivepre-training.InProceedingsofthe2021ConferenceonEmpiricalMethodsinNaturalLan-guageProcessing,pages246–256,OnlineandPuntaCana,DominicanRepublic.AssociationforCompu-tationalLinguistics.TobiasMayer,SantiagoMarro,ElenaCabrio,andSer-enaVillata.2020.Generatingadversarialexamplesfortopic-dependentargumentclassification.InCom-putationalModelsofArgument-ProceedingsofCOMMA2020,Perugia,Italy,September4-11,2020,volume326ofFrontiersinArtificialIntelligenceandApplications,pages33–44.IOSPress.Merriam-Webster.2022.Dictionary.Meta.2022.Facebook:Hatespeechpolicies.IsarNejadgholi,KathleenFraser,andSvetlanaKir-itchenko.2022.Improvinggeneralizabilityinim-plicitlyabusivelanguagedetectionwithconceptac-tivationvectors.InProceedingsofthe60thAnnualMeetingoftheAssociationforComputationalLin-guistics(Volume1:LongPapers),pages5517–5529,Dublin,Ireland.AssociationforComputationalLin-guistics.FabioPoletto,ValerioBasile,ManuelaSanguinetti,CristinaBosco,andVivianaPatti.2021.Resourcesandbenchmarkcorporaforhatespeechdetection:asystematicreview.LanguageResourcesandEvalua-tion,55(2):477–523.RolandosAlexandrosPotamias,GeorgiosSiolas,andAndreasGeorgiosStafylopatis.2020.Atransformer-basedapproachtoironyandsarcasmdetection.NeuralComputingandApplications,32(23):17309–17320.AlecRadford,JeffWu,RewonChild,DavidLuan,DarioAmodei,andIlyaSutskever.2019.Languagemodelsareunsupervisedmultitasklearners.BarthesRoland,LaversAnnette,andSmithColin.1968.Elementsofsemiology/RolandBarthes;translatedfromtheFrenchbyAnnetteLaversandColinSmith,1stamericaned.edition.HillandWangNewYork.EnricaTroiano,CarloStrapparava,GözdeÖzbal,andSerraSinemTekiro˘glu.2018.Acomputationalex-plorationofexaggeration.InProceedingsofthe2018ConferenceonEmpiricalMethodsinNaturalLanguageProcessing,pages3296–3304,Brussels,Belgium.AssociationforComputationalLinguistics.LaurensvanderMaatenandGeoffreyHinton.2008.Visualizingdatausingt-sne.JournalofMachineLearningResearch,9(86):2579–2605.ByronC.Wallace,DoKookChoe,LauraKertz,andEugeneCharniak.2014.Humansrequirecontexttoinferironicintent(socomputersprobablydo,too).InProceedingsofthe52ndAnnualMeetingoftheAssociationforComputationalLinguistics(Volume2:ShortPapers),pages512–516,Baltimore,Maryland.AssociationforComputationalLinguistics.WilliamWarnerandJuliaHirschberg.2012.Detectinghatespeechontheworldwideweb.InProceedingsoftheSecondWorkshoponLanguageinSocialMe-dia,pages19–26,Montréal,Canada.AssociationforComputationalLinguistics.ZeerakWaseem,ThomasDavidson,DanaWarmsley,andIngmarWeber.2017.Understandingabuse:Atypologyofabusivelanguagedetectionsubtasks.InProceedingsoftheFirstWorkshoponAbusiveLan-guageOnline,pages78–84,Vancouver,BC,Canada.AssociationforComputationalLinguistics.ZeerakWaseemandDirkHovy.2016.Hatefulsymbolsorhatefulpeople?predictivefeaturesforhatespeechdetectiononTwitter.InProceedingsoftheNAACLStudentResearchWorkshop,pages88–93,SanDiego,California.AssociationforComputationalLinguis-tics.JasonWeiandKaiZou.2019.EDA:EasyDataAugmentationTechniquesforBoostingPerformanceonTextClassificationTasks.TechnicalReportarXiv:1901.11196,arXiv.ArXiv:1901.11196[cs]type:article.MichaelWiegand,ElisabethEder,andJosefRuppen-hofer.2022.IdentifyingImplicitlyAbusiveRe-marksaboutIdentityGroupsusingaLinguisticallyInformedApproach.InProceedingsofthe2022ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:Human2009

LanguageTechnologies,pages5600–5612,Seattle,UnitedStates.AssociationforComputationalLin-guistics.MichaelWiegand,MajaGeulig,andJosefRuppen-hofer.2021a.Implicitlyabusivecomparisons–anewdatasetandlinguisticanalysis.InProceedingsofthe16thConferenceoftheEuropeanChapteroftheAsso-ciationforComputationalLinguistics:MainVolume,pages358–368,Online.AssociationforComputa-tionalLinguistics.MichaelWiegand,JosefRuppenhofer,andElisabethEder.2021b.Implicitlyabusivelanguage–whatdoesitactuallylooklikeandwhyarewenotget-tingthere?InProceedingsofthe2021ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,pages576–587,Online.AssociationforComputationalLinguistics.UlrikeWillinger,AndreasHergovich,MichaelaSchmoeger,MatthiasDeckert,SusanneStoettner,IrisBunda,AndreaWitting,MelanieSeidler,ReinhildeMoser,StefanieKacena,DavidJaeckle,BenjaminLoader,ChristianMueller,andEduardAuff.2017.Cognitiveandemotionaldemandsofblackhumourprocessing:theroleofintelligence,aggressivenessandmood.Cogn.Process.,18(2):159–167.Jun-MingXu,Kwang-SungJun,XiaojinZhu,andAmyBellmore.2012.Learningfrombullyingtracesinsocialmedia.InProceedingsofthe2012ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,pages656–666,Montréal,Canada.As-sociationforComputationalLinguistics.MarcosZampieri,ShervinMalmasi,PreslavNakov,SaraRosenthal,NouraFarra,andRiteshKumar.2019a.Predictingthetypeandtargetofoffensivepostsinsocialmedia.InProceedingsofthe2019ConferenceoftheNorthAmericanChapteroftheAssociationforComputationalLinguistics:HumanLanguageTechnologies,Volume1(LongandShortPapers),pages1415–1420,Minneapolis,Minnesota.AssociationforComputationalLinguistics.MarcosZampieri,ShervinMalmasi,PreslavNakov,SaraRosenthal,NouraFarra,andRiteshKumar.2019b.Semeval-2019task6:Identifyingandcatego-rizingoffensivelanguageinsocialmedia(offenseval).InProceedingsofthe13thInternationalWorkshoponSemanticEvaluation,pages75–86.ZiqiZhangandLeiLuo.2018.Hatespeechdetection:Asolvedproblem?thechallengingcaseoflongtailontwitter.CoRR,abs/1803.03662.2010

APerformanceDetailsinDataAugmentationInspiredbytherankedoneaugmentationstrategyinElSheriefetal.(2021),i.e.,aback-translationapproach,wealsotestSOTAmodelsonourdataset,ISHate,withtheaugmentationtechniquesde-scribedinSection4.4.EachmodelistrainedwiththeoriginallycollecteddatadescribedinSection4.3andadditionaldataobtainedfromoneaugmen-tationstrategy.Attheend,wealsoevaluateeachmodelusingonlynon-augmentedtestdata.Tables6aand6bshowtheexperiments’resultsontasksAandB.WefurtheranalysetheerrorscommittedbythebestperformingmodelontaskA.WetookfromTable6aHateBERT+ALLandthethirdannota-tionlayerdescribedinSections3and4toidentifywhicharethemostfrequentimplicitpropertiesontaskAmiss-classifiedmessages.Table5showshowInference,Context,Sentiment,Exaggeration,andExtralinguisticknowledgearethemostrecur-rentnotcaptureddevices.ImplicitHSImplicitProperty#%Inference4453.659Context3441.463Sentiment3340.244Exaggeration2328.049Extralinguisticknowledge2024.390Irony1720.732Blackhumor1214.634Visualsigns1113.415Metaphor910.976Rhetoricalquestion89.756Antithesis67.317Humiliation56.098Sarcasm56.098Circumlocution44.878Fallacy44.878Euphemism33.659Table5:ImplicitpropertiesofthemessagesthatarenotcapturedbyHateBERT+ALL.Wealsoanalysedtheembeddingsofourbest-performingmodelsintasksAandB(Hate-BERT+ALLandUSE+SVM+BT,respectively)throught-SNE(vanderMaatenandHinton,2008).Figures1and2showthetextembeddingsforsen-tencesofthetestset,labeledbybothclassifiersandannotators,fortheimplicitandsubtletasks.(a)Embeddingusingpredictedannotations.(b)Embeddingusingmanualannotations.Figure1:EmbeddingofHateBERT+ALLinthetestsetoftaskA(a)Embeddingusingpredictedannotations.(b)Embeddingusingmanualannotations.Figure2:EmbeddingofUSE+SVM+BTinthetestsetoftaskB2011

TaskANon-HSExplicitHSImplicitHSUSE+SVMPRF1PRF1PRF1RSA.887.875.881.768.830.798.515.285.367AAV.888.875.881.764.825.793.491.280.356RNE.887.867.877.770.802.786.386.382.384RI.888.865.876.769.803.786.371.371.371RA.888.867.877.768.803.785.398.387.392EDA.892.862.877.780.797.789.339.441.383BT.897.856.876.782.787.785.403.645.496GM.887.862.874.771.794.782.352.409.378GM+Revised.887.863.875.769.803.786.385.403.394ALL.889.879.884.796.809.803.421.430.426BERTPRF1PRF1PRF1RSA.894.899.896.805.835.819.487.301.372AAV.896.896.896.820.817.819.387.398.393RNE.897.897.897.807.829.818.455.349.395RI.909.897.903.812.850.831.458.376.413RA.894.905.899.822.825.823.473.382.423EDA.900.894.897.807.836.821.416.333.370BT.909.887.898.824.826.825.459.608.523GM.898.901.900.824.821.823.409.398.403GM+Revised.905.892.899.811.839.825.451.419.435ALL.902.894.898.816.817.816.488.543.514DeBERTaV3PRF1PRF1PRF1RSA.912.893.902.803.877.838.441.242.312AAV.916.904.910.832.858.845.431.403.417RNE.922.883.902.807.880.842.430.382.405RI.922.894.908.821.878.849.460.398.427RA.909.914.911.841.859.850.482.360.412EDA.907.899.903.813.859.835.460.312.372BT.919.885.902.830.857.844.428.543.479GM.913.899.906.839.843.841.399.468.431GM+Revised.918.893.905.819.873.845.425.366.393ALL.924.887.905.814.867.840.456.478.467HateBERTPRF1PRF1PRF1RSA.895.895.895.814.830.822.452.382.414AAV.899.900.899.819.825.822.428.398.412RNE.904.891.897.815.850.832.415.355.383RI.902.894.898.808.845.826.408.312.354RA.895.904.900.830.823.826.459.419.438EDA.890.901.895.808.820.814.454.317.373BT.910.880.895.820.823.822.378.543.446GM.901.898.899.824.827.825.414.425.419GM+Revised.905.891.898.816.835.826.408.419.414ALL.903.896.899.827.827.827.502.559.529(a)ResultsofSOTAmodelsusingdataaugmentationontaskA.Non-HSNon-SubtleHSSubtleHSUSE+SVMPRF1PRF1PRF1RSA.891.871.881.787.832.809.800.103.182AAV.891.871.881.786.831.808.571.103.174RNE.891.868.879.783.831.806.571.103.174RI.891.868.879.782.832.806.750.077.140RA.891.868.879.783.832.806.800.103.182EDA.892.870.881.788.828.807.263.128.172BT.892.868.880.789.831.809.739.436.548GM.891.867.879.786.827.806.269.179.215GM+Revised.892.866.879.785.826.805.286.205.239ALL.888.874.881.797.818.807.263.256.260BERTPRF1PRF1PRF1RSA.894.911.902.840.828.834.200.051.082AAV.898.896.897.824.836.830.300.154.203RNE.899.895.897.826.839.833.400.256.312RI.899.889.894.819.840.830.240.154.188RA.906.893.900.823.850.836.190.103.133EDA.902.885.893.813.845.829.143.077.100BT.898.900.899.839.832.835.304.359.329GM.899.899.899.836.839.837.194.154.171GM+Revised.903.893.898.826.843.835.206.179.192ALL.904.883.893.813.845.829.385.385.385DeBERTaV3PRF1PRF1PRF1RSA.922.894.908.826.879.852.333.103.157AAV.910.907.908.841.858.849.267.103.148RNE.923.893.907.829.881.854.261.154.194RI.910.894.902.828.860.843.364.205.262RA.923.884.903.815.883.848.188.077.109EDA.924.888.905.819.882.850.188.077.109BT.920.897.908.835.876.855.385.256.308GM.911.910.911.847.860.854.316.154.207GM+Revised.911.902.907.837.856.846.267.205.232ALL.926.881.903.817.877.846.306.385.341HateBERTPRF1PRF1PRF1RSA.900.893.896.823.841.832.273.154.197AAV.901.894.897.823.842.832.292.179.222RNE.897.894.896.823.836.829.167.103.127RI.906.886.896.812.852.832.176.077.107RA.897.892.895.816.836.826.077.026.038EDA.902.890.896.819.845.832.217.128.161BT.909.883.896.820.848.834.207.308.247GM.899.898.899.831.834.832.250.231.240GM+Revised.894.898.896.826.826.826.192.128.154ALL.903.881.892.816.844.830.391.462.424(b)ResultsofSOTAmodelsusingdataaugmentationontaskB.Table6:ObtainedresultsontasksAandBbyallmodelsanddifferenttypesofaugmenteddata.2012

BImplicitPropertiesInthefollowingpart,weprovidealistofimplicitpropertieswiththeirdefinitions.Alltheexamplesillustratingimplicitpropertiesareusedinimplicithatefulmessagesandtheirdescriptionsarepre-sentedintheannotationguidelines.Antithesis–therhetoricalcontrastofideasthroughparallelarrangementsofwords,clauses,orsentences(asin"action,notwords"or"theypromisedfreedomandprovidedslavery")(Merriam-Webster,2022)Blackhumor–humormarkedbytheuseofusu-allymorbid,ironic,grotesquelycomicepisodes;humortreatingsinistersubjectslikedeath,disease,deformity,handicaporwarfarewithbitteramuse-ment(Willingeretal.,2017)Circumlocution–theuseofanunnecessarilylargenumberofwordstoexpressanidea(Merriam-Webster,2022)Context–thepartsofadiscoursethatsurroundawordorpassageandcanthrowlightonitsmeaning(Dadvaretal.,2013)Euphemism–thesubstitutionofanagreeableorinoffensiveexpressionforonethatmaysuggestsomethingunpleasant(CasasGómez,2009)Exaggeration(hyperbole)–anactorinstanceofexaggeratingsomething:overstatementofthetruth(Troianoetal.,2018)Extralinguisticknowledge–anyknowledgethatexistsoutsideknowledgeofthelanguage.Inotherwords,itreferstoknowledgethatanauthororarecipientofamessagemaypossessaboutthemessageitselforabouttheworld,butwhichisnotexpressedbyanylinguisticmeans.Fallacy–afalseormistakenidea;anoftenplausibleargumentusingfalseorinvalidinference(Merriam-Webster,2022)Humiliation–theembarrassmentandshameapersonfeelswhensomeonemakesthemappearstupidorwhentheymakeamistakeinpublic(Dic-tionary,2022)Inference–somethingthatisinferred.Thepremisesandconclusionofaprocessofinferring(Merriam-Webster,2022)Irony–theuseofwordstoexpresssomethingotherthanandespeciallytheoppositeoftheliteralmeaning;incongruitybetweentheactualresultofasequenceofeventsandthenormalorexpectedresult(Potamiasetal.,2020)Metaphor–afigureofspeechinwhichawordorphraseliterallydenotingonekindofobjectorideaisusedinplaceofanothertosuggestalikenessoranalogybetweenthem(Choietal.,2021;Gaoetal.,2018)Metonymy–afigureofspeechconsistingoftheuseofthenameofonethingforthatofanotherofwhichitisanattributeorwithwhichitisassociated(suchas"crown"in"landsbelongingtothecrown")(Merriam-Webster,2022)Rhetoricalquestion–aquestionnotintendedtorequireananswer,usedmainlyfordramaticeffect(Frank,1990)Sarcasm–amodeofsatiricalwitdependingonitseffectonbitter,caustic,andoftenironiclan-guageusuallydirectedagainstanindividual.Sar-casmdiffersfromironywithonedistinctcharacter-istic:negativity.Sarcasmismostlywittymockeryhavinganegativeconnotationwhereasironydoesnotrepresentnegativity(Potamiasetal.,2020)Sentiment–anattitude,thought,orjudgmentpromptedbyfeeling;theemotionalsignificanceofapassageorexpressionasdistinguishedfromitsverbalcontext(Lietal.,2021)Synecdoche–afigureofspeechbywhichapartisputforthewhole,thewholeforapart,thespeciesforthegenus,thegenusforthespecies,orthenameofthematerialforthethingmade(Merriam-Webster,2022)Visualsigns–punctuationmarks,quotes,anduseofuppercasethatplayaroleofsupportinhatemessages.CAnnotationToolInterfaceFigure3ademonstratesascreenshotoftheanno-tationinterfaceoftheLabelStudiotoolusedforthelabelingprocess.Accordingtotheannotationschemerepresentedbythreeannotationlayers(dis-cussedinSection3andSubsection4.2)LabelStu-diohasthreeconsecutiveannotationsteps.Thefirststepconsistsinimplicitnesswiththreechoices:Im-plicitHS,ExplicitHS,Undecided,keepinginmindthatthetoolallowstofilterNon-Hateoutbeforestartingthelabelingprocess.ThefirstchoiceofImplicitHSorExplicitHSbringsintheappearanceofthesecondstepofsubtletywiththreechoices:Subtle,Non-Subtle,Undecided.ThisstepdoesnotappearwithanUndecidedchoiceatthepreviousstep.Aswellasthat,thechoiceofImplicitHStrig-gerstheappearanceofthethirdstepwhichconsistsofimplicitpropertiesbeingcharacteristicofonlyimplicitmessages.Figure3bshowstheshapeoftheresultantdatasetafterannotation.2013

(a)Annotationtoolinterface.(b)SampleoftheISHatedatasetaftertheannotationprocess.Figure3:LabelStudiointerfacetoenhancethe7HSdatasetsdescribedinSection4withthreenewadditionalannotationlayers:implicit_layer(ExplicitHS/ImplicitHS),subtlety_layer(Non-SubtleHS/SubtleHS),andimplicit_props_layer(Antithesis/Blackhumor/Context/etc.).Theannotationlayerhateful_layer(Non-HS/HS)consistsofthealreadyprovidedlabelsofeachHScorpus,withtheexceptionoftheYoutubedatasetwherewere-annotatedit.