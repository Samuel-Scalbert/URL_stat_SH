A Tale of Two Laws of Semantic Change: Predicting
Synonym Changes with Distributional Semantic Models
Bastien Liétard, Mikaela Keller, Pascal Denis

To cite this version:

Bastien Liétard, Mikaela Keller, Pascal Denis. A Tale of Two Laws of Semantic Change: Predicting
Synonym Changes with Distributional Semantic Models. The 12th Joint Conference on Lexical and
Computational Semantics, Association for Computational Linguistics, Jul 2023, Toronto, Canada.
￿hal-04126662￿

HAL Id: hal-04126662

https://inria.hal.science/hal-04126662

Submitted on 13 Jun 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

A Tale of Two Laws of Semantic Change:
Predicting Synonym Changes with Distributional Semantic Models

Bastien Liétard and Mikaela Keller and Pascal Denis
Univ. Lille, Inria, CNRS, Centrale Lille, UMR 9189 - CRIStAL, F-59000 Lille, France
first_name.last_name@inria.fr

Abstract

Lexical Semantic Change is the study of how
the meaning of words evolves through time.
Another related question is whether and how
lexical relations over pairs of words, such as
synonymy, change over time. There are cur-
rently two competing, apparently opposite hy-
potheses in the historical linguistic literature
regarding how synonymous words evolve: the
Law of Differentiation (LD) argues that syn-
onyms tend to take on different meanings over
time, whereas the Law of Parallel Change
(LPC) claims that synonyms tend to undergo
the same semantic change and therefore remain
synonyms. So far, there has been little research
using distributional models to assess to what ex-
tent these laws apply on historical corpora. In
this work, we take a first step toward detecting
whether LD or LPC operates for given word
pairs. After recasting the problem into a more
tractable task, we combine two linguistic re-
sources to propose the first complete evaluation
framework on this problem and provide empiri-
cal evidence in favor of a dominance of LD. We
then propose various computational approaches
to the problem using Distributional Semantic
Models and grounded in recent literature on
Lexical Semantic Change detection. Our best
approaches achieve a balanced accuracy above
0.6 on our dataset. We discuss challenges still
faced by these approaches, such as polysemy
or the potential confusion between synonymy
and hypernymy.

1

Introduction

Recent years have seen a surge to model lexical
semantic change (LSC) with computational ap-
proaches based on Distributional Semantic Mod-
els (DSMs) (Tahmasebi et al., 2021). While most
research in this area has concentrated on develop-
ing approaches for automatically detecting LSC
for individual words, as in the dedicated SemEval
2020 shared task (Schlechtweg et al., 2020), there
has also been some work on validating or even

proposing laws of semantic changes through new
DSM-based approaches (Dubossarsky et al., 2015;
Hamilton et al., 2016; Dubossarsky et al., 2017).
Ultimately, this line of work is very promising as
it can provide direct contributions to the field of
historical linguistics.

In this paper, we consider two laws of semantic
change that are very prominent in historical lin-
guistics, but that have to date given rise to very
little computational modeling studies. Specifically,
the Law of Differentiation (LD), originally due to
Bréal (1897, chapter 2), posits that synonymous
words tend to take on different meanings over time;
or one of them will simply disappear.1 The same
idea is also discussed in more recent work, such
as Clark (1993). As an example, the verbs spread
and broadcast used to be synonyms (especially in
farming), but now the latter is only used in the
sense of transmit, by means of radio, television
or internet. The verbs plead and beseech are syn-
onyms, but beseech is no longer used nowadays
compared to plead. By contrast, the Law of Par-
allel Change (LPC),2 inspired from the work of
Stern (1921), claims that two synonyms tend to
undergo the same semantic change and therefore
remain synonyms. As an illustration, Stern (1921,
chapter 3 and 4) describes the change of swiftly
and its synonyms from the sense of rapidly to the
stronger sense of immediately. Lehrer (1985) also
observes a parallel change affecting animal terms
which acquire a metaphorical sense.

These two laws are interesting under several as-
pects. Firstly, these laws go beyond the problem of
detecting semantic change in individual words, as
they concern the question of whether a lexical rela-
tionship between words, in this case synonymy, is
preserved or not through time. Secondly, these laws
make very strong, seemingly opposite, predictions

1To cite Bréal (1897): “[S]ynonyms do not exist for long:

either they differ, or one of the two terms disappears.”

2Name coined by Xu and Kemp (2015).

on how synonyms evolve: either their meanings di-
verge (under LD) or they remain close (under LPC).
It is likely that both of these laws might be at work,
but they possibly apply to different word classes,
correspond to different linguistic or extra-linguistic
factors, or operate at different time scales. A large-
scale study, fueled by computational methods over
large quantities of texts, would be amenable to sta-
tistical analyses addressing these questions. In this
work, we focus on predicting the persistence (or
disappearance) of synonymy through time, as a first
step toward more complete analyses.

Prima facie, DSMs appear to provide a natural
resource for constructing a computational approach
for assessing the importance of these laws, as they
inherently –through the distributional hypothesis–
capture a notion of semantic proximity, which
can be used as a proxy for synonymy. Follow-
ing this idea, Xu and Kemp (2015) propose the
first DSM-based method for predicting how syn-
onymous word pairs of English evolve over time
(specifically, from 1890 to 1990). This research
decisively concludes that there is "evidence against
the Law of Differentiation and in favor of the Law
of Parallel Change" for adjectives, nouns and verbs
alike (i.e., the three considered POS). However,
this pioneering work suffers from some limitations
that cast some doubts on this conclusion. First
off, the predictions made by their approach are not
checked against a ground truth, thus lacks a proper
evaluation. Second, the approach is strongly biased
against LD, as only pairs in which both words have
changed are considered, excluding pairs in which
differentiation may occur (e.g. in spread/broadcast,
only the latter word changed in meaning).

This paper addresses these shortcomings by in-
troducing a more rigorous evaluation framework
for testing these two laws and evaluating compu-
tational approaches. We build a dataset of English
synonyms that was obtained by combining lexical
resources for two time stamps (1890 and 1990) that
records, for a given list of synonym pairs at time
1890, whether these pairs are still synonymous or
not in 1990. The analysis of this dataset reveals
that, contra Xu and Kemp (2015) and though using
the same initial synonym set, synonymous words
show a strong tendency to differentiate in meaning
over time. With some variation across POS, we
found that between 55 and 80% of synonyms in
1890 are no longer synonyms in 1990.

Moreover, we propose several new computa-

tional approaches3, grounded in more recent DSMs,
for automatically predicting whether synonymous
words diverge or remain close in meaning over
time, which we recast as a binary classification
problem. Inspired by Xu & Kemp (2015), our first
approach is unsupervised and tracks pairwise syn-
chronic distances over time, computed over SGNS-
based vector representations. Our second approach
is supervised and integrates additional variables
into a logistic regression model. This latter model
achieves a balanced accuracy above 0.6 over the
proposed dataset.

2 Related Work

Data-driven methods to detect LSC have gained
popularity in the recent years (Tahmasebi et al.,
2021), using increasingly powerful and expressive
word representations, ranging from the simple co-
occurrence word vectors (Sagi et al., 2012) to static
word embeddings (Schlechtweg et al., 2019) and
transformer-based contextualized word represen-
tations (Kutuzov et al., 2022; Fourrier and Mon-
tariol, 2022). This line of research lead to the de-
velopment of shared tasks (Zamora-Reina et al.,
2022; Schlechtweg et al., 2020; Rodina and Kutu-
zov, 2020). Most often, these tasks concern the
evolution of individual words, in effect focusing on
absolute semantic change (of words individually).
In this paper, we take a different stand, considering
the problem of relative change in meaning among
pairs of words, specifically focusing on synonym
pairs.

Previous work on word pairs are rare in the
current LSC research landscape. A first excep-
tion is (Turney and Mohammad, 2019), who also
study the evolution of synonyms. They propose
a dataset to track how usage frequency of words
evolve over time within a sets of synonyms, as well
as a new task: namely, to predict whether the dom-
inant (most frequent) word of a synonyms set will
change or not. This task is actually complementary
to the one we address in this work. While Tur-
ney and Mohammad (2019) assume the stability
of most synonym pairs between 1800 and 2000,
and rather investigate the dynamic inside sets of
synonymous words across time, we question this
alleged stability and attempt to track whether these
words remain synonymous at all in this time period.

3The code used to run experiments

in this pa-
per can be found at https://github.com/blietard/
synonyms-semchange

Another distinctive motivation of our work is
in the empirical, large-scale evaluation of two pro-
posed laws of semantic change, originating from
historical linguistics. Previous work investigating
laws of semantic change with DSMs include Du-
bossarsky et al. (2015) and Hamilton et al. (2016),
who measured semantic change of words between
1800 and 2000 and attempted to draw statistical
laws of semantic change from their observations.
Later, Dubossarsky et al. (2017) contrasted these
observations and showed that even if these effects
may be real, it may be to a lesser extent.

The closest work to the current research is the
study of Xu and Kemp (2015), as they already fo-
cus on the two laws of Differentiation (LD) and
Parallel Change (LPC). Their main motivation was
to automatically measure, using DSMs, which of
the two laws was predominant between 1890 and
1999. To study which of the two laws actually oper-
ates, they focus on word pairs that (i) are synonyms
in the 1890s and (ii) where both words changed sig-
nificantly in meaning between 1890 and the 1990s.
First, they represent words as probability distri-
butions of direct contexts, using normalized co-
occurrence count vectors. Then, they measure the
(synchronic) semantic proximity of words by com-
puting the Jensen-Shannon Divergence between
the corresponding distributions. Semantic change
in a word is quantified by comparing its semantic
space neighborhoods in the 1890s and in the 1990s.
Finally, for every selected synonymous pair, they
pick a control word pair that has a smaller diver-
gence in the 1890s than the associated synonyms.
At a later time in the 1990s, if the divergence for
the synonyms is larger than that for the control pair,
they decide these synonyms have undergone LD,
otherwise they predict LPC. Ultimately, they found
that most pairs (around 60%) have undergone LPC,
which would be the dominant law.

The pioneering work of Xu and Kemp (2015)
faces a number of shortcomings. First, their re-
striction to synonymous pairs in which both words
changed mechanically excludes certain cases of
LD (i.e., where one one word has changed), thus
introducing an artificial bias against LD. Moreover,
they often select near-synonyms as controls (e.g.
instructive and interesting) because they constrain
control pairs to be closer in divergence in the 1890s
than the associated synonym pairs. Furthermore,
and more importantly, Xu and Kemp (2015) did
not compare their predictions to any ground-truth

and there is no evaluation of the reliability of their
method. Finally, their choice of word representa-
tions is not among the State-of-the-Art for static
methods.

In this paper, we consider all synonymous pairs,
thus avoiding the bias against LD. We propose
different approaches that we compare to Xu and
Kemp (2015)’s control pairs, and we provide results
obtained with more recent distributional semantic
models. Most importantly, we propose a complete
evaluation framework to benchmark the different
methods, something missing in this prior work.

3 Problem Statement

Our overarching goal is to develop new compu-
tational approaches that are able to automatically
predict which pairs of synonymous words under-
went LD or LPC. These predictions could be used
as a first step towards providing a more refined and
statistically meaningful analysis of the two laws.
An important milestone towards developing such
an approach is to compare it to some ground truth.
Otherwise, there is no way to assess whether statis-
tics obtained for LD or LPC are indeed reliable, a
problem faced by Xu and Kemp (2015).

Unfortunately, there is no existing large-scale
resource that records instances of LD/LPC, beyond
a handful of examples found in research papers
and textbooks in historical linguistics. What exists
however are historical lists of synonyms, which
we can compare to obtain some form of ground
truth. This forces us to consider a slightly differ-
ent methodological framework, focusing on a more
constrained prediction task, namely to detect pairs
of synonyms at time T 1 that have remained syn-
onymous or that are no longer synonymous at time
T 2(> T 1).

3.1 Formalization
Let us denote W (T ) the set of words (or vocabulary)
for a given language (say English) at time T . As
language evolves through time, vocabularies at two
times T 1 and T 2 need not have the exact same
extensions: e.g., a word w in W (T 1) might not
be in W (T 2) (i.e., w has disappeared). Making a
simplistic, idealized assumption, let C be a mostly
atemporal and exhaustive discrete set of concepts,
and denote M (T )
w ⊂ C the meaning of word w at
time T . The definition of M (T )
as a set allows
homonymy and/or polysemy to be accounted for.
Given these notations, we have that u ∈ W (T )

w

v

and M (T )

u ∩ M (T )

and v ∈ W (T ) are synonyms at a time T if
M (T )
̸= ∅. We understand that the study
of LD / LPC implies to track (i) the change of
M (T )
over time, (ii) the evolution of
u
v
M (T )
u ∩ M (T )
and (iii) the very persistence of both
words in vocabularies W (T ) between T 1 and T 2.
Discussion about formalizing LD and LPC under
those conditions can be found in appendix A.1.

v

3.2 Task Formulation: Tracking Synonyms

Change

The presented formulation, though very idealized,
should make it clear that the development of a com-
putational system that attempts to directly predict
LD and LPC, and even the construction of an eval-
uation benchmark for evaluating such a system, are
very challenging tasks. First, the initial synonym
set selection presupposes, not only that one has
access to a list of synonyms at T 1 and T 2, but
also that one can reliably predict LSC in one of
the two words from T 1 to T 2; unfortunately, LSC
is still an open problem for current NLP models.
Second, one typically does not have meaning inven-
tories or automatic systems (e.g. WSD systems) for
mapping words to their meanings at different time
stamps. Finally, even tracking the disappearance
of words through time is not trivial, as it ideally
requires full dictionaries at different time stamps.
Given these limitations, we suggest to narrow
down our target problem to the task of predicting,
for a given pair of synonymous words (u, v) at T 1,
whether (u, v) are still synonymous or not at T 2.
Stated a little more formally, we are concerned with
the following binary classification problem:
f :S (T 1) → {"Syn", "Diff"}
(cid:40)

(u, v) (cid:55)→ f ((u, v)) =

"Syn" if (u, v) ∈ S (T 2)
"Diff" otherwise

where S (T ) is a set of synonymous word pairs
at time T , "Syn" indicates that words (u, v) that
were synonymous at T 1 remain synonymous at T 2,
while "Diff" signals that they are no longer synony-
mous at T 2. This simpler problem leads to a more
operational evaluation procedure, which does not
require access to M (T ∗)
, but only to
lists of synonyms S (T 1) and S (T 2). See Section 4
for presentation of such procedure. It should be
clear that predicting which synonym pairs remain
("Syn") or cease to be synymoms ("Diff"), will
provide some information about LPC and LD, al-
though the mapping between the two problems is

and M (T ∗)

u

v

not one-to-one. Even if “Diff” covers pretty well
LD, a pair that is still synonymous at T 2 could
either be a case of LPC (their shared meaning
changed the same way for both words) or a pair
of words that simply have not changed in mean-
ing at all (or at least that their shared meaning is
unchanged).

Now turning to designing a computational sys-
tem that detects "Syn" vs. "Diff", a natural question
that emerges is whether current DSMs, commonly
used for detecting LSC in individual words, are
able to capture synonym changes. More specif-
ically, our main hypothesis will be that one can
reliably track the evolution of synonymous pairs
through their word vector representations at T 1 and
T 2.

This approach will be instantiated into different
unsupervised and supervised models in Section 5.

4 Evaluation Dataset

This section presents a dataset designed to track the
evolution of English synonymous word pairs be-
tween two time stamps T 1 and T 2, with T 2 > T 1.
Specifically, the two time periods considered are
the 1890’s decade (T 1) and the 1990’s decade (T 2).
For extracting synonymous pairs in the 1890’s
(noted S (T 1)), we use Fernald’s English Synonyms
and Antonyms (Fernald, 1896) as Xu and Kemp
(2015) did. Pairs were selected based on a set
of specific target words (see appendix A.7). As
shown in Table 1, we obtain 1, 507 adjective pairs,
2, 689 noun pairs and 1, 489 verb pairs. To assess
whether these word pairs are still synonyms in the
1990’s, we use WordNet (Fellbaum and Princeton,
2010), as this lexical database was originally con-
structed in 1990’s. Thus, WordNet provides us
with S (T 2). Specifically, we considered that a pair
of words/lemmas (u, v) ∈ S (T 1) are still synony-
mous if they point to at least one common synset
in WordNet.

The construction of this dataset relies on two cru-
cial hypotheses, which seem reasonable to make.
First, both lexical resources rely on the same defi-
nition of synonymy. Second, S (T 2) meets some ex-
haustivity criterion, in the sense that (u, v) ∈ S (T 1)
not appearing in S (T 2) should indicate that u and
v are no longer synonymous at T 2, and not be due
to a lack of coverage of the resource (i.e., a false
negative). WordNet is assumed to be exhaustive
enough, as we checked that every word involved in
at least one synonymous pair has its own entry in

Synonyms pairs ADJ

NN

VERB

All

Synonyms at T 1

1507

2689

1489

5685

& synonyms at T 2
& synonyms at T 2(%)

202
13.4

& hypernyms at T 2
& hypernyms at T 2(%)
& hyp. at T 2 (1) (%)
& hyp. at T 2 (2) (%)
& hyp. at T 2 (3) (%)

0
0.0
0.0
0.0
0.0

347
12.9

858
31.9
23.2
6.9
1.4

311
20.9

398
26.7
22.5
3.5
0.5

860
15.1

1256
22.1
16.9
4.1
0.8

Table 1: Numbers of synonymous pairs extracted from
Fernald (1896) (T 1) displayed by POS, and numbers
of those that are also considered as synonyms or hyper-
nyms/hyponyms in WordNet (T 2) For hypernyms, we
detail the proportions of hypernym/hyponym pairs that
are separated by 1, 2 or 3 nodes in the WordNet graph.

WordNet’s database.

Table 1 provides some detailed statistics on the
evolution of synynomous pairs between decades
1890’s and 1990’s, overall and for different parts
of speech. A first observation on these datasets is
that the proportion of pairs that are still synonyms
at T 2 (“Syn”) is globally 15.1%. This implies that
most synonymous pairs underwent differentiation.
While it does not provide information about how
change happened between T 1 and T 2 for the re-
maining 84.9%, it’s a clue that the Law of Differen-
tiation should be a dominant phenomenon among
synonyms.

We exploit the structure of the WordNet database
to analyze the different cases of “Diff ”. Word-
Net includes lexical relations of hyper-/hypo-nymy
(e.g., seat/bench) as well as holo-/mero-nymy (e.g.,
bike/wheel) and antonymy (e.g., small/large) de-
fined over synsets4. Note that the hyper-/hypo-
nymy relation does not exist in WordNet among
adjectives. Among nouns and verbs, we observe
that around 30% of pairs that were synonyms at
T 1 are in an hyper-/hypo-nymy relation at T 2 and
two third of them are direct hypernyms in WordNet
(their synsets are direct parent/child) indicating the
preservation of a very close semantic link. For a
further depiction of the dataset in terms of distance
in WordNet’s graph, see Figure 3 in appendix A.4.
One cannot entirely exclude that S (T 1) includes
some hyper-/hypo-nyms as synonyms. However,
even if we extend the notion of synonymy at T 2
to include these cases, we would have only around
45% of all pairs still considered synonyms among

4As we did for synonyms, we assume that two words w1
and w2 are instances of one of these relations R if R holds for
one of their corresponding synset pair.

nouns and verbs. This indicates that "Diff" largely
remains the most common phenomenon with an
estimated proportion between 55% and 80%. This
finding contradicts the experimental results re-
ported by Xu and Kemp (2015) with their com-
putational approach (only 40% of differentiation).
In lack of additional indication that some of these
hyper-/hypo-nym cases at T 2 are indeed synonyms,
or that they may also have been hyper-/hypo-nym at
T 1, we decided to still consider them as instances
of “Diff”. Another argument for this decision is
precisely that there are well-known reported cases
of lexical semantic changes in which the meaning
of a particular word in effect "widens" to denote
a larger subset (i.e., becomes an hypernym): this
is the case of dog in English that used to denote a
specific breed of dogs (Traugott and Dasher, 2001).

5 Approaches

This section presents two classes of computational
approaches, unsupervised and supervised, for pre-
dicting whether pairs of synonyms at T 1 remain
synonyms ("Syn") or cease to be so ("Diff") at a
later time T 2. Common to all of these approaches
is that they are based on two time-aware DSMs,
one for each time stamp.

5.1 Time-aware DSMs

Inspired by work on LSC, we rely on separate
DSMs for each time stamp T 1 and T 2, respectively
yielding vector spaces V (T 1) and V (T 2) encoding
the (possibly changing) word meanings at T 1 and
T 2. Thus, for each synonym pair (u, v), we have
two pairs of vectors : (u(T 1), v(T 1)) ∈ V (T 1) ×
V (T 1) and (u(T 2), v(T 2)) ∈ V (T 2) × V (T 2).

Specifically, we use pre-computed SGNS
(Mikolov et al., 2013) from Hamilton et al. (2016)
trained on the English part of the GoogleBooks
Ngrams dataset5 for every decade between 1800
and 2000 and extract V (T 1) (1890) and V (T 2)
(1990). For any word w ∈ W and any time pe-
riod T , w(T ) ∈ V (T ) is a single 300 dimensional
vector. We ensure synonymy is accurately reflected
by checking that synonym pairs have a smaller co-
sine distance than non-synonymous pairs for both
time periods, as in Figure 4 of appendix A.5.

Traditional DSM-based approaches for detect-
ing LSC are based on self-similarities over time
for a given word. For instance, for a given time

5https://storage.googleapis.com/books/ngrams/

books/datasetsv3.html

interval (T 1, T 2), they compute for each word
w an individual Diachronic Distance, noted here
DD(T 1,T 2)(w). Cosine distance is often used (re-
call in appendix A.2).

There is no obvious distance for comparing pairs
of word vectors, but one can instead rely on com-
paring the pairwise word vector distance at each
time stamp T ; we call this Synchronic Distance (de-
noted SD). The two types of distances for two time
stamps T 1 and T 2 are described in Figure 1. Our
unsupervised method, proposed in Sec. 5.2 directly
exploit the idea of tracking different types of SD
through time, while Sec. 5.3 presents a supervised
approach that combines both SD and DD.

T 1

•

u

DD(T 1,T 2)(u)

T 2

•

u

Let (u, v) be a pair of synonyms at T 1, as such
we have that SD(T 1)(u, v) ≤ δT 1. If (u, v) are not
synonyms at time T 2 then SD(T 2)(u, v) > δT 2.

Combining these two inequalities, we would say
that a pair of synonyms at T 1 has differentiated at
T 2 if:

SD(T 2)(u, v) − SD(T 1)(u, v)
(cid:125)
(cid:123)(cid:122)
(cid:124)
= ∆(u, v)

> δT 2 − δT 1.

Ideally one could imagine that the distance thresh-
old δT at which, words cease to be synonyms
should be independent of the time period T . Em-
pirically however, because word embeddings are
not necessarily build with an enforced scale, there
might be a dilation or shrinking in the overall syn-
chronic distances between T 1 and T 2. Let us as-
sume that

SD(T 1)(u, v)

SD(T 2)(u, v)

δT 2 = δT 1 + τ, τ ∈ R.

•

v

DD(T 1,T 2)(v)

•

v

Figure 1: Pairs of word embeddings at 2 time periods
and associated diachronic and synchronic distances.

u

and M (T )

5.2 Unsupervised Methods
While we don’t have access to M (T )
, we
can represent the meaning of u and v using DSM
and compare them at a given time to estimate how
close they are in meaning. Indeed, if M (T )
u ∩ M (T )
changes, this should be reflected in difference of
the use contexts of u and those of v, and so reflected
in the distance between u(T ) and v(T ). Let

v

v

SD(T ) : W (T ) × W (T ) → R+

be a measure of synchronic distance between vec-
tors representing two words. By construction of
V (T ), SD(T )(u, v) is smaller for words (u, v) that
appear in similar contexts than for unrelated words.
We assume that there exists a value δT such that

∀(u, v) ∈ S (T ), SD(T )(u, v) ≤ δT .

This entails that for a given pair (u, v):

SD(T )(u, v) > δT ⇒ (u, v) are not synonyms.

Our decision rule could then be rewritten as:

f (u, v) =

(cid:40)

“Diff” if ∆(u, v) ≥ τ
“Syns” otherwise.

(1)

This approach is shortly denoted “∆” in section
6. It diverges from the prior work of Xu and Kemp
(2015) that chooses to rely on control pairs instead
of a threshold. For the sake of comparison, we
implemented their method presented as “XK con-
trols”. It is not the full protocol presented by Xu
and Kemp (2015), as (i) the experimental setting is
not identical, they filtered out some synonym pairs
and we didn’t (ii) we use SGNS word represen-
tations and cosine distance instead of normalized
co-occurrence counts and Jensen-Shannon Diver-
gence. Schlechtweg et al. (2019) provided a longer
comparison between word representations.

We propose a statistically-grounded criterion to
set the value for the threshold τ . Since the meaning
of most words is expected to remain stable6, we
argue that most pairwise distances should remain
stable as well. We can then estimate the dilation
between the representations in the two time peri-
ods by the average gap between the synchronic
distances of words.

τ =

1
|W |2

(cid:88)

∆(w1, w2)

(2)

(w1,w2)∈W ×W

In this setting, one can compare the synchronic
distances within V (T 1) and with V (T 2) and decide
if the pair differentiated or stayed synonymous.

6Intuitively, someone in 2023 can still understand writings
published in the 1890s in their original text, like books from
Charles Dickens or Arthur Conan Doyle.

In practice, we experiment with two different
types of synchronic distances between words. The
first is the cosine distance (see A.2). That is:

SD(T )(u, v) = cos-dist(u(T ), v(T )).

We shortly denote it “SD(cd)”. Another measure
of semantic proximity is based on the shared word
neighborhood between the two vectors u and v:

SD(T )(u, v) = jaccard-dist(N (T )

k

(u) , N (T )

k

(v)),

k

with N (T )
(w) being the set of the k-nearest neigh-
bors of the point representing w in the vector space
at time T , and jaccard-dist being the Jaccard dis-
tance (see appendix A.2). This measure is ranged
between 0 and 1, and we denote it “SD(nk)”.

5.3 Supervised Methods

Approaches described so far use the labels in the
dataset ("Syn" and "Diff") only for evaluation pur-
poses. But one can also use part of the available
data to learn a supervised classifier to predicts these
labels. Concretely, for most of these models, we
trained Logistic Regression (LR) models7

Synchronic Distances Combination In our un-
supervised approach, we compute SD(T 1) and
SD(T 2) and their difference, denoted ∆. This quan-
tity is then compared to a fixed threshold τ . We
propose to investigate two supervised approaches
stemming from this: (i) simply tune τ and (ii) use
a LR model to learn the optimal weighting in the
linear combination of the two distances. This latter
model is called “LR SD”.

Accounting for Individual Change Most works
about computational approaches to LSC focus on
detecting the change of a single word (Tahmasebi
et al., 2021), using a diachronic distance, which we
noted DD(T 1,T 2)(w), across time periods T 1 and
T 2 for individual words w.

In addition to synchronic distances, we input
diachronic distances as features for a LR model.
The resulting classifier (LR SD+DD) uses the 4
distances represented in Figure 1 as variables: self-
similarities across time periods (DDs), and a dis-
tance measure within pairs for each of both time
stamps (SDs). Similarly to synchronic distances
defined in Sec. 5.2, we try two definitions of DD.
First, we compare sets of neighbors at T 1 and T 2:

We also compute the cosine distance between
w(T 1) and w(T 2) after aligning the vector space
V (T 2)
to V (T 1) using Orthogonal Procrustes
(Hamilton et al., 2016; Schlechtweg et al., 2019,
2020). Denoting w(T 2)
align the vector w(T 2) after
alignement with Orthogonal Procrustes, we have:

DD(w) = cos-dist(w(T 1), w(T 2)

align).

Using Distances and Frequencies A final step
of this process is to add word frequencies for both
words at both time periods, as there exist links be-
tween usage frequency and semantic change Zipf
(1945). We could observe whether adding explicit
frequency information helps retrieving discrimi-
natory clues that could be missed by using only
distributional representations.

Word frequencies were estimated from the Cor-
pus of Historical American English (COHA) list,9
which has the advantage to be genre-balanced. As
variables for both words and both periods to feed
our model, we try to add either raw occurrences
counts (indicated by “+FR”), either grouped fre-
quency counts (“+FG”). The procedure to create
such groups is described in appendix A.6.

All Features For the sake of comparison to pre-
vious models, we evaluate LR models that take as
input an implementation of each of these features
(SD + DD + frequency); and an even larger model
that reunites all described
(called “LR multi.”)
implementations of SD, DD and frequencies.

Non-linear Models As a further step increasing
the model’s complexity, we try to combine this
full set of available variables in a non-linear fash-
ion. We compare previous models to polynomial
features (degree 2) preprocessing10 and a SVM
classifier with a Gaussian kernel.

6 Experiments

6.1 Experimental Settings

Target Words Selection We use a unique vocab-
ulary W composed of 6, 453 adjectives, 16, 135
nouns and 10, 073 verbs. The process to select
words is described in appendix A.7.

DD(w) = jaccard-dist(N (T 1)

k

(w) , N (T 2)

k

(w)).

7Implemented with the scikit-learn library for Python8.

9https://www.ngrams.info/download_coha.asp
10We also try degrees higher than 2, finding no consistent

improvement.

Dataset ADJ NN VERB ALL

Evaluation metric

Balanced Accuracy

ALL
F1(Syn) F1(Diff) %(D)

All (Syn)
All (Diff )
LR F

XK controls
∆ (cd)
∆ (nk)

∆ (tuned τ )
LR SD
LR SD + DD
LR SD + F
LR SD + DD + F
LR multi

LR multi. poly. degree (2)
SVM (gaussian)

.50
.50
.51

.52
.50
.48

.51
.60
.61
.61
.62
.62

.56
.60

.50
.50
.56

.49
.49
.49

.52
.62
.62
.64
.64
.64

.63
.64

.50
.50
.59

.51
.51
.49

.52
.59
.60
.63
.63
.65

.62
.65

.50
.50
.55

.50
.50
.50

.51
.60
.60
.62
.62
.62

.62
.62

.48
0
.35

.33
.27
.32

.27
.48
.48
.51
.50
.51

.50
.50

0
.81
.74

.67
.73
.67

.74
.69
.69
.71
.70
.71

.70
.74

0
100
75

65
75
66

79
56
56
57
57
57

60
63

Table 2: Performances of the different approaches. Results are averaged over 20 random splits.

Dataset Splits For every POS tag, we have a set
of word pairs that are synonymous at T 1. We call
ALL the dataset that comprises all pairs indistinctly
of their POS. These datasets (ADJ,NN,VERB or
ALL) are individually shuffled and 33% of their
samples (pairs) are set aside for testing. For each
dataset, a model is trained on the 66% remaining
pairs and evaluated on the test part. Presented re-
sults are averaged over 20 random train/test splits.

Baselines The first two baselines are constant out-
put classifiers, always predicting "Syn" or "Diff "
respectively. They are expected to have a balanced
accuracy of 50%, as they would be fully accurate
for one class and always wrong for the other. The
third baseline (LR Frequency) is a Logistic Regres-
sion model trained only with frequency variables,
without any knowledge on the semantic aspect of
the pair (neither SD or DD).

Hyperparameters We train models with com-
binations of the different definitions of distances
and frequency variables. Choice of synchronic dis-
tances was between SD(cd) and SD(nk) with k in
{5, 10, 15, 20, 40, 100}. For DD, we tried neigh-
borhoods with fixed size 100, like Xu and Kemp
(2015), and Orthogonal Procrustes with cosine dis-
tances. For frequency, the choice is between raw
counts and groups. The selected models are de-
tailed in Appendix A.9. The ideal value for the
SVM’s regularization parameter is found using 5-
fold cross-validation over the training set.

Evaluation Metrics We use two standard eval-
uation metrics: F1 score and Balanced Accuracy
(BA). F1 scores were computed for both classes,
denoting it “F1(Syn)” for Syns and “F1(Diff)” for
Diff. BA is defined as the average of recalls for both
classes, and provide a notion of accuracy robust to
class imbalance. We also display the percentage of
predicted Diff (“%D”).

6.2 Results

Performances over the test parts of the different
datasets are displayed Table 2.

The first observation is that, in line with the
dataset’s proportions, all models predict a majority
of “Diff”, even unsupervised ones (including our
reimplementation of Xu & Kemp’s control pair se-
lection method). While our task does not directly
address the question of the opposition between LD
and LPC, this is an empirical clue in favor of LD,
contradicting Xu and Kemp (2015). However, pre-
dicting the right amount of “Diff” does not guar-
antee the quality of predictions. Indeed, obtained
balanced accuracies range between 0.49 and 0.65.
Considering our unsupervised methods and the
∆ (tuned τ ), we find no real improvement over
baselines. In particular, they fail to outperform the
frequency-based baseline model which performs
surprisingly well. On the other hand, Logistic Re-
gression and SVM models substantially improve

Polysemy WordNet provides us with different
set of synonyms for every entry, corresponding to
different senses or usages, and therefore we can
measure the polysemy of a word at T 2. We found
that pairs misclassified as "Syn" tend to be those
whose second term has fewer senses (6 senses on
average as compared with well classified "Diff"
which have 8 senses on average). Indeed, as we
use static embeddings and no Word Sense Disam-
biguation (WSD) method, our model is subject to
the complexity brought by polysemy. In a recent
shared task about Lexical Semantic Change mea-
sures, best performing models are the one using
WSD methods (Zamora-Reina et al., 2022). This
finding highlights the importance of handling poly-
semy as a potential confounding factor.

Distances in WordNet
In Figure 2 we display
the percentage of prediction with respect to shortest
distance between the two words of noun pairs in
WordNet’s graph. The distance d is the minimum
number of nodes separating the two words. We
remark that, as expected, the model predicts more
and more Diff as d increases. What is more inter-
esting is that for d = 1 (direct hypernymy), there
is still an important proportions of predicted Syn.
This highlights that our model has difficulties to
handle hypernymy and confuses it with synonymy.

7 Conclusion

In this work, we considered two contradicting laws
about the semantic change of synonyms. We dis-
cussed the necessary adaptations of the problem
statement for this particular type of LSC and elab-
orated a framework to evaluate models for this
new classification problem. The use of linguis-
tic resources from two different time periods al-
lowed us to improve model analysis with respect
to prior work on the matter. Then we proposed un-
supervised and supervised approaches relying on
measures of semantic change extracted or inspired
by existing literature on LSC, and also leveraged
the usefulness of explicit word usage frequency
information. We compared these approaches in
our evaluation framework, finding that distances in
vector spaces from different time periods should
not be considered equally. We also observed that
explicit frequency information actually help dis-
tributional methods to capture the change of syn-
onymy. Finally we discussed challenges that DSM
approaches still face and opened a discussion about
the interplay between hypernymy and synonymy.

Figure 2: Proportions of predictions of the models w.r.t.
the actual distance d in WordNet of noun pairs. Pairs
with d = 0 are synonymous pairs in WordNet.

over the baselines, Xu & Kemp’s control pairs and
all ∆-based methods. Interestingly, LR SD outper-
forms ∆-based methods despite the fact that they
rely on the same components.

The gap between baselines and models is larger
for nouns and lesser for verbs. Despite these POS-
specific differences, best models are consistently
the ones using both SD and frequencies, while DD
brings little to no improvement. This can be ex-
pected as individual changes of words seem less
important on the problem of Syn/Diff. However,
this factor could be used in future work to distin-
guish pairs of synonyms (among the Syn class) that
did not change and pairs that went under LPC.

We observe that there is a substantial difference
in F1 scores between the two classes, F1(Syn) be-
ing lower than F1(Diff) across all models. More-
over, models with higher F1(Syn) are often found
to be the ones with higher balanced accuracy, even
when F1(Diff) is lower. This is likely linked to
the fact that the datasets are highly imbalanced as
presented in Table 1: the ground truth proportion
of Syn never exceeds 21%. We also remark that
Xu and Kemp (2015) decision rule based on con-
trol pairs also predicts a majority of Diff, contrarily
to the results they showed. It may be because the
protocol is not fully identical.

6.3 Confounding Factors

Using WordNet, we discuss two aspects that may
be sources of errors when detecting a change in
synonymy: polysemy and hypernymy. We study
predictions of our best performing LR model on
the noun dataset.

Limitations

As mentioned already, the problem Syn/Diff does
not reflect the initial question of LD/LPC. In partic-
ular, the Syn class of pairs that remained synonyms
contains pairs that underwent LPC and pairs which
shared meaning remained unchanged. The latter
does not play a role in the LD/LPC dichotomy
and should be discarded for deeper study of the
two apparently opposite laws. Also, we restrain
the study to some target words that are chosen to
occur at both time periods, thus preventing us to
fully measure the importance of LD. Indeed, re-
call that Bréal’s Law of Differentiation predicts
that some synonyms may disappear in the process.
Thus, our Diff class could be considered incom-
plete. However, including such disappeared words
would prevent the use of time-aware DSMs.

Section 3 presented synonymy as a symmetrical
relation between words. However, a thesaurus like
Fernald (1896) displays asymmetrical synonymy:
for an entry u we have a set of synonyms v1, v2, ...
from which we extract pairs (u, v). We observe that
v itself is rarely an entry of the thesaurus, and when
it does, u may not appear in the list of synonyms
of v. This is contradictory to WordNet’s definition
of synonymy that consider this relationship to be
symmetrical. However, up to our knowledge, there
is no lexical database (like WordNet) being also
historical and that could help us ensure the notion
of synonymy at both time periods is strictly the
same. In the absence of such a resource, we leave
potential disagreements in definition between the
two linguistic resources to future investigations.

In section 4, we discussed that hyper/hypo-nymy
could be misleading. We made the assumption
that Fernald (1896) and Wordnet (Fellbaum and
Princeton, 2010) used similar-enough notions of
synonymy such that our labels Syn/Diff are rele-
vant. However, thesaurus like Fernald (1896) are
created as a tool for writers and authors to avoid
redundancy, thus including wide lists of synonyms
that include hypernyms (instead of repeating the
bench, you could say the seat). In section 6.3 we
showed that direct hypernymy is misleading for our
model. Yet, we still miss guidelines/insights about
the possibility to include some cases of hypernymy
among synonyms at T 2. Another approach would
be to remove hypernyms from the source material
at T 1, which implies to automatically detect them
or manually review thousands of pairs.

There are remaining factors that presented ap-

proaches do not take in account and that one could
think relevant. In particular, further work could
investigate the influence of pressure of words on a
concept, for instance many words sharing (at least
partially) a similar meaning. However, this would
require access to list of senses for each word at
time T 1, which we do not have in Fernald (1896).
To this extent, contextualized language models fine-
tuned for the different time periods could be help-
ful.

Finally, because we used pre-computed SGNS
embeddings on historical data binned in decade, we
have no guarantee that this is the optimal setting
for studying Lexical Semantic Change. Maybe
different kind of changes could be observed using
larger or smaller time periods, and conducting the
study over a larger or a smaller time span instead
of just a century.

Acknowledgements

We would like to thank the three anonymous re-
viewers for their helpful comments on this paper.
We would also thank Anne Carlier for the thought-
ful discussion about this work. This research was
funded by Inria Exploratory Action COMANCHE.

References

Michel Bréal. 1897. Essai de Sémantique. Paris: Ha-

chette.

Eve V. Clark. 1993. Conventionality and contrast, Cam-
bridge Studies in Linguistics, page 67–83. Cambridge
University Press.

Haim Dubossarsky, Y. Tsvetkov, C. Dyer, and Eitan
Grossman. 2015. A bottom up approach to category
mapping and meaning change. CEUR Workshop
Proceedings, 1347:66–70.

Haim Dubossarsky, Daphna Weinshall, and Eitan Gross-
man. 2017. Outta control: Laws of semantic change
and inherent biases in word representation models.
In Proceedings of the 2017 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1136–1145, Copenhagen, Denmark. Association for
Computational Linguistics.

Christiane Fellbaum and University of Princeton. 2010.
Wordnet. In About WordNet. Princeton University.

James Champlin Fernald. 1896. ... English Synonyms

and Antonyms. Funk & Wagnalls Company.

Clémentine Fourrier and Syrielle Montariol. 2022.
Caveats of measuring semantic change of cognates
and borrowings using multilingual word embeddings.

In Proceedings of the 3rd Workshop on Computa-
tional Approaches to Historical Language Change,
pages 97–112, Dublin, Ireland. Association for Com-
putational Linguistics.

Elizabeth Closs Traugott and Richard B. Dasher. 2001.
Prior and current work on semantic change, Cam-
bridge Studies in Linguistics, page 51–104. Cam-
bridge University Press.

William L. Hamilton, Jure Leskovec, and Dan Jurafsky.
2016. Diachronic word embeddings reveal statisti-
cal laws of semantic change. In Proceedings of the
54th Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
1489–1501, Berlin, Germany. Association for Com-
putational Linguistics.

Andrey Kutuzov, Erik Velldal, and Lilja Øvrelid. 2022.
Contextualized embeddings for semantic change de-
tection: Lessons learned. ArXiv, abs/2209.00154.

Adrienne Lehrer. 1985. The influence of semantic fields
on semantic change, pages 283–296. De Gruyter
Mouton, Berlin, New York.

Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositionality.
In Advances in Neural Information Processing Sys-
tems, volume 26. Curran Associates, Inc.

Julia Rodina and Andrey Kutuzov. 2020. RuSemShift:
a dataset of historical lexical semantic change in Rus-
sian. In Proceedings of the 28th International Con-
ference on Computational Linguistics, pages 1037–
1047, Barcelona, Spain (Online). International Com-
mittee on Computational Linguistics.

Eyal Sagi, Stefan Kaufmann, and Brady Clark. 2012.
Tracing semantic change with Latent Semantic Anal-
ysis, pages 161–183. De Gruyter Mouton, Berlin,
Boston.

Dominik Schlechtweg, Anna Hätty, Marco Del Tredici,
and Sabine Schulte im Walde. 2019. A wind of
change: Detecting and evaluating lexical semantic
change across times and domains. In Proceedings
of the 57th Annual Meeting of the Association for
Computational Linguistics, pages 732–746, Florence,
Italy. Association for Computational Linguistics.

Dominik Schlechtweg, Barbara McGillivray, Simon
Hengchen, Haim Dubossarsky, and Nina Tahmasebi.
2020. SemEval-2020 task 1: Unsupervised lexical
semantic change detection. In Proceedings of the
Fourteenth Workshop on Semantic Evaluation, pages
1–23, Barcelona (online). International Committee
for Computational Linguistics.

Gustaf Stern. 1921. Swift, swiftly, and their synonyms:
A contribution to semantic analysis and theory. Wet-
tergren & Kerber.

Nina Tahmasebi, Lars Borina, and Adam Jatowtb. 2021.
Survey of computational approaches to lexical se-
mantic change detection. Computational approaches
to semantic change, 6.

Peter D. Turney and Saif M. Mohammad. 2019. The
natural selection of words: Finding the features of
fitness. PLoS ONE, 14.

Yang Xu and Charles Kemp. 2015. A computational
evaluation of two laws of semantic change. In Pro-
ceedings of the 37th Annual Meeting of the Cognitive
Science Society, CogSci 2015, Pasadena, California,
USA, July 22-25, 2015. Cognitive Science Society.

Frank D. Zamora-Reina, Felipe Bravo-Marquez, and
Dominik Schlechtweg. 2022. LSCDiscovery: A
shared task on semantic change discovery and de-
tection in Spanish. In Proceedings of the 3rd Work-
shop on Computational Approaches to Historical
Language Change, pages 149–164, Dublin, Ireland.
Association for Computational Linguistics.

George Kingsley Zipf. 1945. The repetition of words,
time-perspective, and semantic balance. The Journal
of General Psychology, 32(1):127–148.

A Appendix

A.1 Formalizing LD and LPC

In this work, we reduced the problem from finding
pairs in which LD or LPC operates to a binary
classification problem between pairs that remained
synonymous and those who did not. To understand
the need for a reduction, let us introduce some
notation and definitions.

First, let us denote by W (T ) the set of words (or
vocabulary) for a given language (say English) at
time T . As language evolves through time, vocab-
ularies at two times T 1 and T 2 (with T 2 > T 1)
need not have the exact same extensions: e.g., a
word w in W (T 1) might not be in W (T 2) (i.e., w has
disappeared) or vice versa (i.e., w is a new word).
Assuming a simple, idealized denotational seman-
tics, we will further define C(T ) as the set of dis-
crete concepts available at time T ,11 and M (T )
w ⊂ C
the meaning of word w at time T . It is defined as
a set to model cases of homonymy and/or poly-
semy. From these definitions, we can now define
synonymy at time T between words u ∈ W (T ) and
v ∈ W (T ) as M (T )
̸= ∅; that is, u and
v do share a common meaning. Furthermore, we
can define the semantic change from T 1 to T 2 in
a word w as follows: M (T 1)
; that is, w
has different sets of meanings at T 1 and T 2.

u ∩ M (T )

̸= M (T 2)
w

w

v

11We take C(T ) to be mostly stable over time, but new
concepts might of course appear or disappear (e.g., due to
techonological or cultural evolution).

Equipped with these definitions, we are now
ready to formalize the two laws LD and LPC, start-
ing with what their common scope.

First, both laws concern synonyms: they are re-
stricted to a set of synonyms at some initial time T 1,
defined by S (T 1) = {(u, v) : M (T 1)
̸=
∅}.

∩ M (T 1)
v

u

Second, both LD and LPC assume some individ-
ual semantic change, from T 1 to T 2 (with T 2 >
T 1), in at least one of two synonymous words: that
̸= M (T 2)
is, M (T 1)
.
v
u
Given these preconditions, the application of LD

or (logical) M (T 1)

̸= M (T 2)
u

v

implies that either:

• one of the two words has disappeared:

u ∈ W (T 1) ∧ u ̸∈ W (T 2)
or (exclusive) v ∈ W (T 1) ∧ v ̸∈ W (T 2),

• u and v are no longer synonymous at T 2:
= ∅.

∩ M (T 1)
v

M (T 1)
u

By contrast, LPC implies that words u and v
remain synonymous from T 1 to T 2. While this
could be simply stated as: M (T 2)
̸= ∅,
we feel that this misses an important aspect of the
law, namely that M (T 1)
should evolve
in the same way:

and M (T 1)

∩ M (T 2)
v

u

u

v

• either by acquiring (a) new shared sense(s):
) ∩ (M (T 2)
) ̸= ∅,

u − M (T 1)

v − M (T 1)

(M (T 2)

u

v

• or inversely by losing the same sense(s):
) ∩ (M (T 1)
) ̸= ∅.

u − M (T 2)

v − M (T 2)

(M (T 1)

u

v

A.2 Useful definitions

Recall the definition of cosine distance between
two vectors x and y:

cos-dist(x, y) = 1 −

⟨x, y⟩
∥x∥∥y∥

.

(3)

We also recall the definition of Jaccard distance

between two sets A and B:

jaccard-dist(A, B) = 1 −

|A ∩ B|
|A ∪ B|

.

(4)

A.3 Xu & Kemp’s control pairs

In Table 3 we display samples of word pairs se-
lected as control pairs following Xu and Kemp
(2015)’s procedure. As we can observe, for ev-
ery Part-Of-Speech, a significant number of these
pairs are themselves synonymous. After manu-
ally reviewing a hundred pairs for each POS tag,

we estimate that the proportion of synonyms in
the selected control pairs is between 20 and 40%.
Synonym pairs shouldn’t be used to control other
synonym pairs, which may explain why our repro-
duction of Xu and Kemp (2015) decision rule does
not perform well according to Table 2.

A.4 Distances in WordNet

In Figure 3 are displayed the distributions of dis-
tances in WordNet. The distance in WordNet be-
tween two words (u, v) is the number of nodes of
the shortest path between a synset of u and a synset
of v.

Figure 3: Distribution of shortest distances in WordNet
between pairs of words that were synonymous at T = O.
inf means that there is no path between the two words
in WN. A distance of 0 means that they are actually
synonyms, while a distance of 1 implies there is direct
hypernymy.

A.5 Synonymy in our DSMs

In Figure 4 are displayed the distributions of cosine
distance between word pairs at both periods. In
blue are synonyms at this time (from Fernald (1896)
at T 1, and from WordNet at T 2). In black are all
possible word pairs. We observe that synonymy
is indeed captured by our DSM as synonyms are
significantly closer in cosine distance than other
word pairs.

A.6 Frequency groups

The procedure to create a fixed number M of fre-
quency group is the following. At a time T , the list
of target words is sorted by increasing frequency,
we label as group ‘0’ the first 50% of the list. In the
remaining 50%, The first half is labeled as group
‘1’, and so on until group M − 2 is created. The
still unlabeled words are labeled group M − 1, for
a total of M groups. Group labels are therefore
positively correlated with occurrences counts.

POS

ADJ

NN

VERB

Control pairs

brownish/red, kindly/mild, teeming/agricultural, likeliest/meaningless,
various/heterogeneous, barbarous/cruel, abandoned/unsuccessful, trojan/escaping,
subjective/relative, reliable/readable.

diphtheria/typhus, muskets/pistol, surgery/appendicitis, beech/apples,
accountants/prints, commodity/substances, cups/pots, wife/grandmother,
fool/fisherman, obstacles/multiplication.

moan/groan, divide/span, needed/secured, flowed/flooded,
stall/owned, told/asked, mentioned/described, cooperate/accord,
copy/filed, increased/diminished.

Table 3: Random samples of size 10 among selected control pairs. In italic are control pairs which are considered
synonyms according to the definition in Section 3.1.

A.8 Unsupervised models

In Figure 5, we observe that the quantity ∆ does
not reflect a clear separation between Syn pairs and
Diff pairs. This explains why the unsupervised
methods proposed in Sec. 5.2 fail to significantly
outperform baselines.

Figure 4: Distribution (as density histograms) of cosine
distances between word pairs at time period T 1 (decade
1890s) and T 2 (decade 1990s). In blue are represented
pairs of synonyms, and in black are represented all pairs
of target words, without any particular constraint.

A.7 Target words selection

Among words represented in the embeddings pro-
vided by Hamilton et al. (2016), we keep only
words following these three requirements. The first
is to be POS-tagged as an adjective, a noun and/or
as a verb in the COHA. For a given POS-tag among
these three, the second requirement is to appear at
least 3 times in every decade between 1890 and
1999. Lastly, we require words to be composed of
3 letters or more. If a word appears with multiple
POS-tags in the COHA and fulfills the minimum
frequency requirement with each of these tags, the
same embedding is used as its representation, as
Hamilton et al. (2016)’s training data aggregated
POS-tags.

Figure 5: Histograms of the value of divergence ∆ of
synonymous pairs, depending whether they differenti-
ated (orange) or stayed synonyms (blue).

In Figure 6 we show the influence of k in SD
(neighbors) for the unsupervised ∆ method. We
see that while there is close to no change in balance
accuracy, F1 scores for both classes are more and
more unbalanced as k increases, indicating a more
unfair model for high values of k. This is explained
by the fact that the unsupervised model predicts
more Diff (dominant class) with higher k.

larly. For models forced to use SD(nk) in addition
to SD(cd), the choice of k did not really change the
results.

A.10 Predictive variables in our model

In this supplementary section, we conduct a study
about the role of some predictive variables in our
best-performing Logistic Regression model, as po-
tential sources of errors. The studied model uses
SD with cosine-distance, both implementations of
DD and raw frequency counts.

Pred.

Syn Diff TS

y = Syn

y = Diff
FD TD FS

SD(T T 1)
DD(u)
DD(v)
F G(T 2)
u
F G(T 2)
v

.64
.46
.50
2.3
1.9

.83
.46
.54
2.2
1.4

.62
.45
.48
2.4
2.1

.84
.47
.54
2.1
1.5

.83
.46
.54
2.2
1.4

.64
.47
.50
2.2
1.8

Table 4: Average values of some variables for data
subset based on the prediction of our best-performing
LR model. TS,FS,TD,FD stand for True/False Syn/Diff.
F G(T )
w stands for Frequency Groups of word w at time
T . Significant difference within a pair of columns are
in bold.

For a selected number of variables, we look for
significant differences between well-classified pairs
and pairs with wrong prediction, in both classes
separately. For a given variable, we estimate if a
difference is significant between the well-classified
and the misclassified samples of this class using a
t-test for Gaussian distributed variables, or a Mann-
Whitney U test for other variables. A difference is
significant if the p-value of the test is below 5%.
Results are reported in table 4.

We observe significant differences of SD in pairs
that are predicted as Syn and those predicted as Diff
by our model, the first having a smaller SD at T 1
than the latter. Because our model relies mostly
on these SD to separate both classes, we wrongly
classify Syn pairs whose SD(T T 1) is close to that of
Diff, and conversely Diff pairs whose SD(T T 1) is
close to that of Syn are misclassified. This indicates
that our model still misses some subtleties that are
now reflected by SD.

A similar non-separability of the distribution of
"Syns" and "Diff" appears on DD and Frequency
variable for the second word pair of the pair. While
it seems logical for our model to behave so regard-
ing to the definition of LD, it is a clue that our input

Figure 6: Unsupervised method, neighborhood-based
SD, for ALL (mixed POS).

A.9 Components of selected models

Depending on the POS tag, the implementation
strategies of SD, DD and frequency variables were
different. Recall that these strategies were chosen
given the average performances over 20 random
train/test splits.

On adjectives, neighborhood based DD as well
as raw frequency counts was found to be better
than alternatives. For SD, cosine distance provides
slightly higher performances than neighborhood-
based measures, except when tuning the threshold
for ∆: in this case, SD(nk) with k = 15 was best.
Generally, for every method implying a neighbor-
dhood based SD (∆(nk), LR multi., as well as the
two non-linear models), a small/mid ranged k was
preferable (between 10 and 20).

For nouns, SD(cosine distance) was also the best
choice except for ∆ with tuned threshold: here,
SD(nk) was preferred. Overall, the best range for
the value of k for neighbors-based SD was smaller
(5 to 15). Frequency groups worked better than
raw frequencies, while there was no difference in
performance between the two definitions of DD.

Yet, for verbs, SD(nk) with k = 40 actually out-
performs cosine distance (except for unsupervised
∆), and DD using Orthogonal Procrustes alignment
and cosine distance (Hamilton et al., 2016) was ac-
tually better than the definition relying on compar-
isons local neighborhoods. Both types of frequency
variables (raw counts and groups) worked equally
well.

Finally, on the ALL dataset reuniting pairs ac-
cross POS tags, raw frequencies provide better re-
sults than groups. Cosine distance is better than
neighborhoods for synchronic distances, and both
techniques of diachronic distances performed simi-

variables reflect noisy information that is confus-
ing to the model. In the same idea, Kutuzov et al.
(2022) remarked that recent LSC detection models
tend to raise False Positive, drawing attention to
the limit of current models for LSC.

