Task-Oriented Uncertainty Evaluation for Linked Data
Based on Graph Interlinks
Ahmed El Amine Djebri, Andrea G. B. Tettamanzi, Fabien Gandon

To cite this version:

Ahmed El Amine Djebri, Andrea G. B. Tettamanzi, Fabien Gandon. Task-Oriented Uncertainty Eval-
uation for Linked Data Based on Graph Interlinks. EKAW 2020 - 22nd International Conference on
Knowledge Engineering and Knowledge Management, Sep 2020, Bozen-Bolzano, Italy. ￿10.1007/978-
3-030-61244-3_15￿. ￿hal-02933190￿

HAL Id: hal-02933190

https://hal.science/hal-02933190

Submitted on 8 Sep 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Task-Oriented Uncertainty Evaluation for
Linked Data Based on Graph Interlinks

Ahmed El Amine Djebri[0000−0003−2917−5085], Andrea G.B.
Tettamanzi[0000−0002−8877−4654], and Fabien Gandon[0000−0003−0543−1232]

Universit´e Cˆote d’Azur, Inria, CNRS, I3S, France

Abstract. For data sources to ensure providing reliable linked data,
they need to indicate information about the (un)certainty of their data
based on the views of their consumers. In Addition, uncertainty informa-
tion in terms of Semantic Web has also to be encoded into a readable,
publishable, and exchangeable format to increase the interoperability of
systems. This paper introduces a novel approach to evaluate the uncer-
tainty of data in an RDF dataset based on its links with other datasets.
We propose to evaluate uncertainty for sets of statements related to user-
selected resources by exploiting their similarity interlinks with external
resources. Our data-driven approach translates each interlink into a set
of links referring to the position of a target dataset from a reference
dataset, based on both object and predicate similarities. We show how
our approach can be implemented and present an evaluation with real-
world datasets. Finally, we discuss updating the publishable uncertainty
values.

Keywords: Uncertainty · Semantic Web · Graph interlinks.

1

Introduction

We are witnessing an era fulﬁlling the vision to create a Web of linked intelligent
systems [1], thriving through sharing data they own or have processed. In this
context, many challenges present themselves to developers of such platforms to
retain reliable data that allows enriching their existing knowledge bases using
robust reasoning or with the help of more external relevant content. The latter is
using links with extra pieces of information revealing new dimensions for users to
explore with their requests. Uncertainty is a major issue when related to content
brought out on the Web, or Semantic Web by extension. Nevertheless, most data
providers do not present explicit information about the uncertainty of their data.
On the other hand, completely mistrusting a data source is unfair: while some
data providers may not be reliable on one subject or provide false information
about it, they are experts on other subjects and the pieces of information they
provide should not be ignored. In some cases, references about data provenance
and/or related data are given, from which a data consumer may hope to get
further validation from other data sources.

2

A. DJEBRI et al.

In this paper, we address the need to evaluate uncertainty in linked data
sources. In our approach, a data source may auto-evaluate the level of uncertainty
of its data according to what is being presented by other data sources and for
a speciﬁc use-case. We leverage the fact that diﬀerent knowledge graphs may
provide complementary and/or extra information enabling the assessment of the
conformity of a target source. We also think that a user’s preferences should be
taken into consideration while evaluating uncertainty. Our work is built on top
of the mUnc model [2] to represent and publish uncertainty on the Semantic
Web. The main question we aim to answer is: How to evaluate uncertainty in a
data source, based on its data, other linked data sources, and with respect to a
speciﬁc use-case?

To answer this question, we propose an approach to evaluate the uncertainty
of a target data source, based on graph interlinks with other reference data
sources. We propose to annotate statements with uncertainty values in a pub-
lishable format and provide a method to manipulate and update such values if
existed. The intuition behind this work is that often users who need to conﬁrm
a piece of information will look for diﬀerent sources that conﬁrm or contradict
it. For instance, the traditional veriﬁcation techniques in journalism include the
”two-sources rule” asking to verify that at least two independent trustworthy
sources conﬁrm a piece of information.

The rest of the paper is organized as follows. Section 2 surveys related work
and positions our contribution accordingly. In section 3 we discuss similarity
assessment between two focus graphs of one resource and our choices of indica-
tors. In section 4 we present our main contribution, with a method to evaluate
uncertainty based on existing links and transform it into reusable information
that annotates statements in the data source of interest. In section 5 we discuss
the experimental workﬂow and present our tool for uncertainty evaluation and
annotation. We conclude with a snapshot of our work and our future goals.

2 Related Works

According to Paulheim [3], external error-detection approaches in knowledge
graphs are based on interconnections between data sources: they take advan-
tage of the links (identity links or simply IRI reuse) to check for errors in the
data source of interest. Paulheim [4] proposes in another work an external ap-
proach to detect outlier interlinks between datasets by creating a feature vector
representation of each interlink based on types and incoming/outgoing links to
all instances of a class. That work is meant to evaluate links, whilst here we
check the reliability of data based on presumed correct interlinks. Other works
are based on a statistical analysis of feature vectors associated with predicates
that are linked to interlinked resources [5,6]. Another interesting idea is identity
quantiﬁcation between two linked data sets. It explores the idea of isomorphism
quantiﬁcation between two sets presumably representative of the same real-world
entity. Similar works inspiring data-driven ontology alignment were discussed by
Shvaiko et al. [7].

Task-Oriented Uncertainty Evaluation for Linked Data Based on Graph Interlinks

3

Christodoulou et al. [8] discusses the use of similarity measurements and
Bayesian updating to help to align ontologies from diﬀerent data sources and
using precomputed values provided by ontology matchers. The authors depend
on the Linked Open Vocabularies1 to calculate the likelihood of equivalence vs.
non-equivalence of two distinct classes and use that measure to update the local
probability of similarity between two classes using Bayesian update. Authors
of [9] propose a statistical data-driven approach to detect incorrect property
mappings among the diﬀerent language chapters of DBpedia. The work focuses
on detecting the wrong mappings and the analysis is run through the whole
datasets.

The aforementioned works mostly treated the reliability of the similarity links
between data sources or detecting wrong schema-mappings. Diﬀerent from our
problem that requires analyzing data based on a use-case. The previous works
present a promising set of measures to analyze data uncertainty based on links.
Nevertheless, we notice the absence of speciﬁc sets of interest encapsulating the
linked resources. Moreover, the said works are more in the spirit of ontology-
matching techniques relying on linking all instances of two classes.

The problem relates in general to ontology alignment approaches and is also
inspired by quasi-key detection problems. Most of the literature is assessing the
link quality and not depending on the links themselves to assess data quality. We
believe that it is original to discuss uncertainty evaluation with a task-centered
perspective based on graph interlinks .

3 Uncertainty Assessment in Linked Data

3.1 Terminology and Deﬁnitions for Uncertainty

We introduce the terminology and the formalism used in the paper to propose
an evaluation of uncertainty based on existing links between graphs.

Deﬁnition 1. RDF-dataset — a set of statements (triples) in the form
(cid:104)subject, predicate, object(cid:105) ∈ (I ∪ B) × I × (I ∪ B ∪ L) where I is a set of IRIs,
B a set of blank nodes, L a set of literals, I, B and L are pairwise disjoint and
for every two RDF-datasets D1, D2 the sets of blank nodes are disjoint. we also
denote ID the set of IRIs used in statements of the RDF-dataset D.

Deﬁnition 2. Target dataset — an RDF-dataset noted as Dt that is the target
of the uncertainty evaluation.

Deﬁnition 3. Reference dataset — an RDF-dataset noted as Dr that repre-
sents a reference for the evaluation of the uncertainty of a target dataset.

Deﬁnition 4. RDF-graph — a graph G = (V, E), where V ⊂ (I ∪ B ∪ L) is a
set of vertices, and E ⊂ I is a set of directed edges.

1 https://lov.linkeddata.es/

4

A. DJEBRI et al.

Deﬁnition 5. Focus graph — an RDF-graph noted as GD(e) ⊂ D, where D
is the dataset including the graph (target or reference) and e ∈ I is a focused
resource for which GD(e) is considered representative according to the use-case.

Deﬁnition 6. Set of Linking predicates — a non-empty set of predicates ex-
plicitly chosen to link between the target dataset and the reference dataset. We
note it as Pl ⊂ I. Example: Pl = {owl:sameAs, skos:exactMatch}.

Deﬁnition 7. Contextual Linkset — as deﬁned in the VOID2 vocabulary, a
linkset is a set of RDF triples where all subjects are in one dataset and all objects
are in another dataset. We call a contextual linkset the one containing links
between focused resources of Dt and those of Dr. A contextual linkset deﬁnes the
set of focused resources of each dataset as well as the links between them. A link
between a target focused resource et and a reference focused resource er is also a
link between the focus graphs GDt(et) and GDr (er): LS(Dt, Dr) = {(cid:104)et, p, er(cid:105) |
p ∈ Pl, et ∈ IDt, er ∈ IDr };

Deﬁnition 8. Evidence link — a relationship between two statements tt ∈
GDt(et), tr ∈ GDt(er) discovered using similarity analysis, that supports the
link between two linked focus graphs GDt(et) and GDt(er). The evidence link
refers to a considered relationship between the predicates and/or the objects of
two statements tt and tr. We note E(GDt(et), GDt(er)) the set of evidence links
discovered between the two focus graphs GDt(et) and GDt(er)).

Our purpose is to ﬁnd a method to assess the reliability of the informa-
tion in each target focus graph GDt(et) centered around a target focused re-
source et. To this end, we translated the existing link between the resource et
of a target dataset and the resource er of a reference dataset ( (cid:104)et, p, er(cid:105) ∈
LS(GDt(et), GDt(er)), p ∈ Pl) to a set of evidence links between the target focus
graph GDt(et) and the reference focus graph GDt(er). We statistically analyze
the extracted evidence links to obtain a set of indicators enabling the evaluation
of the overall semantic similarity between the predicates of linked focus graphs.
Finally, we use the extracted evidence links to calculate the uncertainty of each
focus graph based on its local ones.

3.2 Choosing Target Focused Resources

The problem of matching, whether it is data-driven or schema-driven, is context-
related and may not be evident to users or useful for their request if done without
involving them in the process [10]. We consider the concept of uncertainty to
be also context-speciﬁc and that it is possible to choose a diﬀerent evaluation
method for each use case.

A focus graph GD(e) is meant to be the image that represents e in the context
of the application. Hence, the choice of the set of focused resources is necessary
to ensure that uncertainty assessment is built on a user-centered view. The set of

2 https://www.w3.org/TR/void/#linkset

Task-Oriented Uncertainty Evaluation for Linked Data Based on Graph Interlinks

5

targeted focused resources e ∈ IDt (IDt being the set of IRIs in the dataset Dt)
depends on the type of validation a user intends to have within the data-source
and depending on the use-case.

We also need to present a suﬃcient focus graph —in the context of the
use-case—reﬂective of information about the resource. As an example with mu-
sic artists, a focus graph may contain simple information like their names and
birthplaces and deeper-level information like songs from their albums. To limit
the issue in our current use-case, we rely on the proposal3 made by Strikler,
aiming to create a focused subgraph centered around and describing a resource,
called a Concise-Bounded Description and noted as CBD. Some Linked Data
stores like Virtuoso4 propose their proper deﬁnition of CBD and use it as the
mapping of DESCRIBE SPARQL queries. For our current use-case, we ﬁnd the
deﬁnition of CBD an intuitive, simple yet interesting one to deﬁne our GD(e).

3.3 Linking predicates and Contextual Linkset

Unlike the approaches to ontology matching or alignment, we take existing links
in the contextual linkset as ground truth. The ﬁrst links one may ﬁnd between
two data sources can be established by reusing IRIs of resources from one in
the other. Moreover, the RDFS and OWL standards provide predicates such
as owl:sameAs, rdfs:seeAlso with debatable semantics to link between re-
sources [11,12]. Other commonly used ontologies propose more predicates to
indicate the matching between two resources (example: skos:exactMatch [13]).

4 Approach and Uncertainty Assessment Pipeline

We propose a level-based architecture where each level depends on the previous
one, from isolating candidate evidence links to exporting update-ready uncer-
tainty values. A link between a target focused resource et and a reference focused
resource er can be seen as a link between the focus graph of each. The evidence
links supporting that link are discovered and selected based on deﬁned similarity
indicators.
Considering two statements t1 : (cid:104)s1, p1, o1(cid:105), t2 : (cid:104)s2, p2, o2(cid:105) where t1 ∈ GDt(et)
and t2 ∈ GDr (er) and a prior knowledge indicating the existence of a link be-
tween the two resources et and er: (cid:104)et, l, er(cid:105) ∈ LS(Dt, Dr). We deﬁne here a set
of similarity indicators to be used for uncertainty assessment.

4.1 Precomputing: Augmentation and Clustering

During this step, we apply the chosen deﬁnition of focus graphs on Dt based on
LS(Dt, Dr). Beforehand, we use OWL [12] semantics for properties to augment
the data source by calculating the transitive closure of our target dataset Dt. This
helps to unveil more potential evidence links between the linked focus graphs.

3 https://www.w3.org/Submission/CBD/
4 http://docs.openlinksw.com/virtuoso/rdfsqlfromsparqldescribe/

6

A. DJEBRI et al.

4.2 Level 1: Identifying possible evidence links based on Syntactic
similarity between objects of statements in linked focus graphs

In the ﬁrst level, we produce a set of evidence links for each pair of linked focus
graphs using an object similarity measure deﬁned as follows.

Deﬁnition 9. Object similarity — We denote symo(t1, t2) (eq. 1) as the weighted
similarity between objects of statements t1 and t2 (between o1 and o2). This mea-
sure refers to what extent the two objects share the same nature (literal, URI),
the same datatype(xsd:short, xsd:integer, etc.5) and/or the same value:

symo(t1, t2) = (1 − ωval) × typeM atch(o1, o2) + ωval × valM atch(o1, o2).

(1)

The binary function typeM atch returns 1 if both nature (IRI, Literal) and
datatypes are similar and 0 otherwise. The valM atch function can be any syn-
tactic similarity measure (Jaccard, Levenshtein, Jaro-Winkler distance, n-grams,
etc.). Once the ﬁrst level measures are established, a positive threshold τobj ≤ 1
restricts the discovered evidence links to ones of higher object similarity.

4.3 Level 2: Identifying evidence link patterns using Semantic

similarity of predicates in the overall linked focus graphs

The second level introduces semantic similarity between evidence links while
taking into account: the fact that the same predicates are used in schemas of the
diﬀerent data sources, and speciﬁc semantics related to the current use case by
the mean of predicate similarity indicators. This view is inspired by the example
in [8] but adapted to ﬁt predicates due to the generalized, class-independent
deﬁnition of LS(Dt, Dr).

Deﬁnition 10. Predicate similarity — We denote symp(t1, t2) (eq. 3) the sta-
tistical similarity between predicates of statements t1 and t2 (between p1 and p2).
This measure is built on all the linked focus graphs and represents the use-case
related semantic similarity of the two predicates p1 and p2.

To evaluate semantic similarity, we ﬁrst deﬁne four indicators (table 1) to be
statistically extracted for each pair of linked focus graphs GDt(et) and GDr (er).
From the previous indicators and for each pair of linked focus graphs GDt(et)
and GDr (er), we also calculate three local ratios (table 2).

To evaluate the semantic similarity between p1 and p2 on the overall contex-
tual linkset, we average for each pair of predicates p1 and p2 with an evidence
link between t1 and t2 in all linked focus graphs, and add another indicator ˆR0
for the equality p1 = p2 (as it will stay the same if averaged). We get a vector of
averaged ratios ˆR(p1, p2) = [ ˆR0(p1, p2), ˆR1(p1, p2), ˆR2(p1, p2), ˆR3(p1, p2)], with

ˆRi(p1, p2) =

1
|LS(Dt, Dr)|

(cid:88)

(cid:104)et,pl,er(cid:105)∈LS(Dt,Dr)

Ri(GDt(et), GDr (er), p1, p2)

(2)

5 https://www.w3.org/2011/rdf-wg/wiki/XSD Datatypes

Task-Oriented Uncertainty Evaluation for Linked Data Based on Graph Interlinks

7

Table 1: Semantic similarity indicators for each pair of linked focus graphs.

Indicator

Deﬁnition

I1(GDt (et), GDr (er))

I2(GDt (et), GDr (er))

the number of evidence links between the two focus graphs GDt (et) and
GDr (er). i.e. the number of links supporting the similarity hypothesis
between the two resources et and er.

the set of predicate pairs in evidence links between statements of the
two focus graphs GDt (et) and GDr (er). i.e: the set of pairs (p1, p2)
where an evidence link exists between t1 and t2.

I3(GDt (et), GDr (er), p1, p2)

the count of evidence links relying on two predicates p1, p2 between the
two focus graphs GDt (et) and GDr (er).

I4(GDt (et), GDr (er), p1, p2)

I5(GDt (et), GDr (er), p1, p2)

the total number of possible combinations between statements using
each p1 or p2 in the two linked focus graphs GDt (et), GDr (er) (For
instance, if three statements in GDt (et) use p1 and two statements in
GDr (er) use p2 then the total number of links would be six. So this
represents the maximum possible number of evidence links that can be
found linking p1 and p2).

the sum of the quality of evidence links relying on two predicates p1, p2
between the two focus graphs GDt (et) and GDr (er). i.e. the sum of
object similarities of discovered evidence links between GDt (et) and
GDr (er) linking statements using respectively p1 and p2.

Table 2: Normalised local ratios for each pair of linked focus graphs.

Ratio

Deﬁnition

R1(GDt (et), GDr (er), p1, p2)

R2(GDt (et), GDr (er), p1, p2)

I3 is normalised using I1 to reﬂect the participation of evidence links
between two statements having p1 and p2 as predicates, in the overall
evidence links between the two linked focus graphs.

I3 is normalised using I4 to reﬂect the portion of existing statement
that actually participate with a link. If all existing statements between
two focus graphs, with p1 and p2 as predicates are linked with evidence
links, it indicates that the predicates may be functional, or that this
information is a common knowledge that usually have a lower cardinal
(like homepages for artists).

R3(GDt (et), GDr (er), p1, p2)

I5 is normalised using I3 to get the average quality of each evidence
link between statements having p1 and p2 as predicates.

and for which we deﬁne a vector of semantic weights ωsem = [ω0, ω1, ω2, ω3]
with (cid:80) ωi = 1, ωi ≥ 0. We select only the predicate pairs having an average
of link quality equal or greater than a positive deﬁned threshold τsem where
τsem ≤ ˆR3(p1, p2) ≤ 1. Hence, we can deﬁne symp(t1, t2) of statements t1 and
t2 as the dot product of the two vectors ˆR(p1, p2) and ωsem:

symp(t1, t2) = ωsem · ˆR(p1, p2)

(3)

Similarly to the previous level, the overall quality of considered evidence links

should also respect the average quality threshold τsem.

4.4 Level 3: Evaluating Contextual Uncertainty of target focus

graphs

At this level, the previous similarity measures are combined into one value re-
ﬂecting the degree of uncertainty of a target focus graph GDt(et) regarding its

8

A. DJEBRI et al.

linked reference focus graph GDr (er). For this, we deﬁne the notion of contex-
tual uncertainty to be the measure of one of a target focus graph based on its
evidence links.

Deﬁnition 11. Contextual Uncertainty — We deﬁne contextual uncertainty of
a target focus graph GDt(et) compared to a reference focus graph GDr (er), with a
link existing between et and er in the contextual linkset LS(Dt, Dr), as the sum
of products of object(syntactic) and predicate(semantic) similarity scores of the
statements linked by each l ∈ E(GDt(et), GDr (er)), on the number of evidence
links in E(GDt(et), GDr (er)).

U (GDt (et) | (cid:104)et, pl, er(cid:105)) =

(cid:80)

<t1,l,t2>∈E(GDt

(et),GDr (er )) symo(t1, t2) × symp(t1, t2)
|E(GDt (et), GDr (er))|

(4)

5 Experiment and Evaluation

We evaluate a dataset with 714 artists from MusicBrainz against their linked
information from the English chapter of dbpedia. The used dataset including
focus graphs and contextual linkset is available online.

To validate our approach, we developed Archer 6, a tool for analyzing and an-
notating link data with uncertainty values. Archer uses the proposed approach
to extract the object and predicate similarity with respect to the links between
focus graphs. The tool allows the user to query for identity links, extract focus
graphs from both the target and the reference datasets, and evaluate the un-
certainty of each focus graph in the target dataset. It further allows analyzing
and visualizing pairs of linked focus graphs individually as well as the diﬀerent
indicators for the overall analysis.

For the experiment, we chose both a Jaccard distance and a string equal-
ity measures as a valMatch() function. Plots in ﬁgure 5.1 show the eﬀect of
the size of the contextual linkset |LS(Dt, Dr)| on the overall count of evi-
dence links (cid:80) I1(GDt(et), GDr (er)) and the number of distinct predicate-pair
| (cid:83) I2(GDt(et), GDr (er))|. We ﬁxed τsem = 0 to see the eﬀect of τobj on the
evidence link count speciﬁcally. We then changed the value to τsem = 0.5 to
visualise the eﬀect speciﬁcally on the distinct count of predicate-pairs that are
considered as similar in the context of the application. For both experiments,
we chose ωval = 1 to see the eﬀect of each object similarity function as well. We
notice that:

– in all of (a1,a2,a3,a4), the number of evidence links is proportional to the
number of analyzed focus graphs. This points to the fact that focus graphs
in both sides share a certain structure allowing to maintain a relatively ﬁxed
ratio of evidence links per pair of focus graphs. Moreover, in (a1) compared
to the absence of a threshold, more than half the evidence links were ignored
in (τobj = 0.25) indicating that those evidence links were of bad quality. As

6 http://github.com/djebr/archer

Task-Oriented Uncertainty Evaluation for Linked Data Based on Graph Interlinks

9

Fig. 5.1: Results for analysing 714 pairs of linked focus graphs: (ai) total number
of discovered evidence links (bi) Number of distinct discovered predicate-pairs.

for the string equality, the local threshold is not needed as the indicators R1
and R3 will be the same (for each discovered evidence link, the quality is 1
at ωval = 1), so no evidence links will be dropped.

– as seen in (b1,b3), the eﬀect of τobj on the number of evidence links is also
predictable. The threshold will only allow links with better quality to be
part of the overall evaluation.

– the number of predicate-pairs increases with the number of linked focus
graphs. This is due to discovering predicate-pairs that did not have any
evidence links in the ﬁrst analyzed focus graphs. It is notable that for both
object similarity methods, the number converges after analyzing more than
400 pairs of focus graphs. Furthermore, the eﬀect of τobj can be observed

10

A. DJEBRI et al.

conﬁrming that some predicate-pairs were dropped as they presented only
bad quality links.

– when increasing τsem, the plots in (a2) move closer to each other and converg-
ing towards (a4) as it represents strict equality, resulting as well in similar
shapes for (b2) and (b4). The ﬂuctuation is due to the fact that the overall
quality of some predicate-pairs evidence links might drops when considering
new pairs of focus graphs that do not support the hypothesis. However, the
plot remains constant proving that on the overall analysis, ﬁve predicate-
pairs can be considered as best candidates to support the graph interlink.
– the diﬀerence between the number of predicate-pairs in (b3) and (b4) is re-
markable. Comparing to 28 predicate-pairs in the ﬁrst with 6600 evidence
links, the second has only 5 predicate-pairs with almost 6000 evidence links.
This further provides proof that most of the discovered links were not of
general use (not common information between focus graph pairs).

6 Discussion

An argument about statistical extraction of semantics would be the fact that a
target dataset can be completely wrong, or somehow unrelated to the reference
dataset like having the same information but in a diﬀerent language. In both
cases, this does not aﬀect the semantic analysis of evidence links. For the ﬁrst
case, no links will be discovered and this will raise a ﬂag about the current
conﬁguration itself (one is wrong about everything related to a certain subject,
or the references were chosen incorrectly). For the second case, the similarity
links will not be translated as well, and triggering the intuition of completeness
between the two graphs (and not that of negation).

Analyzing the similarity patterns based on graph interlinks may be a good
ﬁrst base to evaluate trustworthiness and inclusion between data sources. This
approach works best if one has already a clustered dataset by structure, and
the system is used to see the reliability of its information according to known
sources.

Further investigations are scheduled to explore the use of other clustering
methods, or customized focus graphs and see the possibility to transform the
existing information about focus graphs using graph embedding. Finally, user
queries should be one of the main triggers of uncertainty measurement, interlink
creation, and evaluation.

7 Conclusion

We have proposed an approach to evaluate uncertainty in linked data sources by
providing graph interlinks. Our approach is based on both object and predicate
similarity and operates on diﬀerent levels to evaluate task-speciﬁc uncertainty
measurements for the data source of interest. The results of our experiments show
that graph interlinks can be supported with a set of evidence links, depending on
the use-case and the user’s choice of quality parameters. Using our tool enables us

Task-Oriented Uncertainty Evaluation for Linked Data Based on Graph Interlinks

11

to assess the quality of a dataset regarding a certain task, and annotate its data
accordingly while producing reusable and publishable uncertainty measurements.
Future work will focus on learning the most suitable structure for a focus graph,
generalizing our approach to consider a set of reference resources, and including
more parameters such as scores from ontology matchers.

References

1. Gandon, F.: Web Science, Artiﬁcial Intelligence and Intelligence Augmentation (in
Dagstuhl Perspectives Workshop 18262 - 10 Years of Web Science: Closing The
Loop). Other, Dagstuhl (2019), https://hal.inria.fr/hal-01976768

2. Djebri, A.E.A., Tettamanzi, A.G.B., Gandon, F.: Publishing Uncertainty on the
Semantic Web: Blurring the LOD Bubbles. In: Endres, D., Alam, M., S¸otropa, D.
(eds.) Graph-Based Representation and Reasoning. pp. 42–56. Springer Interna-
tional Publishing, Cham (2019)

3. Paulheim, H.: Knowledge graph reﬁnement: A survey of approaches and evaluation

methods. Semantic web 8(3), 489–508 (2017)

4. Paulheim, H.: Identifying wrong links between datasets by multi-dimensional out-

lier detection. In: WoDOOM. pp. 27–38 (2014)

5. Hogan, A., Polleres, A., Umbrich, J., Zimmermann, A.: Some entities are more
equal than others: statistical methods to consolidate linked data. In: 4th Interna-
tional Workshop on New Forms of Reasoning for the Semantic Web: Scalable and
Dynamic (NeFoRS2010) (2010)

6. Rico, M., Mihindukulasooriya, N., Kontokostas, D., Paulheim, H., Hellmann, S.,
G´omez-P´erez, A.: Predicting incorrect mappings: a data-driven approach applied
to DBpedia. In: Proceedings of the 33rd annual ACM symposium on applied com-
puting. pp. 323–330 (2018)

7. Shvaiko, P., Euzenat, J.: A survey of schema-based matching approaches. In: Jour-

nal on data semantics IV, pp. 146–171. Springer (2005)

8. Fernandes, A.A., Paton, N.W.: Quantifying and Propagating Uncertainty in Auto-
mated Linked Data Integration. Transactions on Large-Scale Data-and Knowledge-
Centered Systems XXXVII 10940, 81 (2018)

9. Rico, M., Mihindukulasooriya, N., Kontokostas, D., Paulheim, H., Hellmann, S.,
G´omez-P´erez, A.: Predicting incorrect mappings: a data-driven approach applied
to DBpedia. In: Proceedings of the 33rd annual ACM symposium on applied com-
puting. pp. 323–330 (2018)

10. Cheatham, M., Cruz, I.F., Euzenat, J., Pesquita, C.: Special

issue on on-
tology and linked data matching. Semantic Web 8(2), 183–184 (2017).
https://doi.org/10.3233/SW-160251, https://doi.org/10.3233/SW-160251

11. Brickley, D., Guha, R.V., McBride, B.: RDF Schema 1.1. W3C recommendation

25, 2004–2014 (2014)

12. McGuinness, D.L., Van Harmelen, F., et al.: OWL web ontology language overview.

W3C recommendation 10(10), 2004 (2004)

13. Miles, A., Bechhofer, S.: SKOS simple knowledge organization system reference.

W3C recommendation 18, W3C (2009)

