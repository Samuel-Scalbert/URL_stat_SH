Scrutable Robot Actions Using a Hierarchical
Ontological Model
Martin Jedwabny, Pierre Bisquert, Madalina Croitoru

To cite this version:

Martin Jedwabny, Pierre Bisquert, Madalina Croitoru. Scrutable Robot Actions Using a Hierarchical
Ontological Model. ICCS 2022 - 27th International Conference on Conceptual Structures, Sep 2022,
Münster, Germany. pp.11-24, ￿10.1007/978-3-031-16663-1_2￿. ￿hal-03808914￿

HAL Id: hal-03808914

https://hal.science/hal-03808914

Submitted on 10 Oct 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Scrutable robot actions using a hierarchical
ontological model

Martin Jedwabny,1 Pierre Bisquert,1, 2 Madalina Croitoru1
1LIRMM, Inria, Univ Montpellier, CNRS, Montpellier, France
2IATE, INRAE, Institut Agro, Montpellier, France
martin.jedwabny@lirmm.fr, pierre.bisquert@inrae.fr,
madalina.croitoru@lirmm.fr

Abstract

We place ourselves in the context of representing knowledge inside the
cognitive model of a robot that needs to reason about its actions. We
propose a new ontological transformation system able to model differ-
ent levels of knowledge granularity. This model will allow to unfold the
sequences of actions the robot performs for better scrutability.

1

Introduction

In this paper, we present a formal approach to knowledge representation and
reasoning in the setting of a robot making decisions about which action to
perform. We propose a hierarchical structure to examine information about
actions in depth, by unfolding actions into several layers of complexity. The
intuition of this work relies on ideas from episodic memory theory [1], that
organizes information in layers of detail retrievable at the right time, in the
right granularity.

We propose a hierarchical information structure composed by two combina-
torial structures that can be applied in an Artificial Intelligence (AI) planning
[2] setting: (i) an ontology of fluent and action symbols, and (ii) a hierarchical
structure encoding preconditions and effects for the various actions.

The proposed layered catalog of actions is influenced by work on conceptual
graph-based ontological knowledge representation [3]. This work can be seen as
a continuation of previous work on hierarchical conceptual graphs [4], with a
focus on reasoning about action.

The salient points of the paper are the following:

• A knowledge representation model relevant for ontologies of fluents and

actions, and

• A formal method for translating between the different layers of details

corresponding to these ontologies.

1

A

B

PressCallButton

CallElevator

UseElevator

BoardElevator

TakeElevator

Figure 1: Elevator example illustration

After providing a motivating example in Section 2, we recall in Section 3
the necessary notions for graphical knowledge representation. In Section 4 we
introduce the structures that allow to represent the robot’s knowledge about the
world and its possible actions. Section 5 analyses the related work and discusses
ways in which our framework can be used to make a planner more scrutable for
an user. Finally, we will conclude in Section 6.

2 Motivating Example

Consider a situation in which a robot has to board an elevator in a building
to get from floor fA to fB. An action model of the situation might represent
this as a single action U seElevator that, upon execution, takes a situation in
which the robot is in fA and transforms it in such a way the robot goes to fB.
Modeling the action of using the elevator as a single atomic step comes with the
immediate advantage of compactness.

However, in certain cases the elevator could malfunction due to electricity
shortages, a certain button not working, or any other internal or external factor
that disturbs its normal functioning.
In this case, the robot could perceive
that the action U seElevator is no longer producing its intended result, but
would have a hard time realizing the cause without modeling the state of the
electricity in the building. On the other hand, keeping track of this property
might be irrelevant to actions other than U seElevator and make it harder to
a user to understand the model and sequence of actions chosen by the robot if
many other properties are introduced.

2

Upon closer inspection, we realize that the action U seElevator depends
on many factors like the state of electricity, the buttons used to operate the
elevator and the electronic circuit that receives the button’s signal. Furthermore,
the action can be broken down to several steps, as depicted in Figure 1: (i)
CallElevator using button bA from whichever floor it is currently at to fA, and
(ii) T akeElevator by selecting the destination floor fB with selector button
bB. Then, (i) can also be separated into two actions: P ressCallButton, and
BoardElevator. In the same way, these actions can be iteratively broken down
into several layers of increasing complexity.

Nevertheless, from a user point of view, all of these factors and step break-
down could be irrelevant in correct operation circumstances. Both for a mon-
itoring user and a automatic planning robot, it can be useful to take these
multiple levels of model complexity into account and use them only when they
are needed.

3 Background notions

3.1 Bipartite graphs
A bipartite graph is a graph G = (VG, EG) with the nodes set VG = VF ∪ VA,
where VF and VA are finite disjoint sets, and each edge e ∈ EG is a two-element
set e = {vF , vA}, where vF ∈ VF and vA ∈ VA. Usually, a bipartite graph G is
denoted as G = (VF , VA, EG). We call G∅ the empty bipartite graph without
nodes and edges.

We make the informal observation that, later on in the paper, the node set
VF and VA will be used to represent, respectively, the uninstanced fluent (i.e.,
the description of a scene) and action symbols of the planning setting. Edges
in the bipartite graph will thus capture the preconditions and effects, in terms
of fluents that compose an action.

Let G = (VF , VA, EG) be a bipartite graph. The number of edges incident
to a node v ∈ V (G) is the degree, dG(v), of the node v. If, for each vA ∈ VA
there is a linear order e1 = {vA, v1}, . . . , ek = {vA, vk} on the set of edges
incident to vA (where k = dg(v)), then G is called an ordered bipartite graph.
A simple way to express that G is ordered is to provide a labelling l : EG (cid:55)→
{1, . . . , |VF |} with l({vA, w}) the index of the edge {vA, w} in the above ordering
l is called a order labelling of the edges
of the edges incident in G to vA.
of G. We denote an ordered bipartite graph by G = (VF , VA, EG, l).
It will
be useful for the next sections to note that the labelling l can be generalized
into a collection of labellings of different kinds by extending its definition to
l : EG (cid:55)→ 2K×{1,...,|VF |} − {∅} with K a predefined set of kinds, while still being
trivial to construct an overall labelling l′ : EG (cid:55)→ {1, . . . , |VF |} from it.

For a vertex v ∈ VF ∪ VA, the symbol NG(v) denotes its neighbors set, i.e.
NG(v) = {w ∈ VF ∪ VA|{v, w} ∈ EG}. Similarly, if A ⊆ VA ∪ VF , the set of
its neighbors is NG(A) = ∪v∈ANG(v) − A. If G is an ordered bipartite graph,
G(r) denotes the i-th neighbor of r, i.e.
then for each r ∈ VA, the symbol N i

3

v = N i

G(r) if and only if {r, v} ∈ EG and l({r, v}) = i.

Throughout this paper we use a particular type of subgraph of a bipartite
F ⊆ VF ,
graph: G1 = (V 1
A}. In other
A ⊆ VA, NG(V 1
V 1
words, we require that the (ordered) set of all edges incident in G to a vertex
from V 1
must appear in G1. Therefore, a subgraph is completely specified by
A
its vertex set. In particular, if A ⊆ VF :

G) is a subgraph of G = (VF , VA, EG) if V 1
and E1

G = { {v, w} ∈ EG|v ∈ V 1

F , V 1
A, E1
A) ⊆ V 1
F

F , w ∈ V 1

• The subgraph spanned by A in G, denoted as ⌈A⌉G, has VF (⌈A⌉G) =

A ∪ NG(NG(A)) and VA(⌈A⌉G) = NG(A).

• The subgraph generated by A in G, denoted as ⌊A⌋G, has VF (⌊A⌋G) = A

and VA(⌊A⌋G) = {v ∈ NG(A)|NG(v) ⊆ A} .

• For A ⊆ VA, the subgraph induced by A in G, denoted [A]G, has VF ([A]G) =

NG(A) and VA([A]G) = A .

Now that we can represent the links between actions and fluents as a graph,
we will see in the following section how we can define the types of their argu-
ments.

3.2 Planning

We will use an abstract representation inspired by the one in [5] to model belief
state planning. This representation allows to model non-deterministic/belief
states and deterministic actions with conditional effects, i.e., conformant plan-
ning.

It is assumed that one is given a set of fluents FP and actions AP , denoting
the properties of a problem and the actions the agent can perform, respectively.
A literal is either f ∈ FP a fluent, or ¬f its negation. A state s ⊆ FP is a set
of fluents denoting what properties hold in a state. This takes into account the
closed-world assumption, in that all fluents that are not in a state are assumed
to be false. A belief state B ⊆ 2FP is a set of states.

An action a ∈ AP is of the form a = (pre(a), ef f (a)), where pre(a) is a set of
literals over FP called the preconditions. Then, ef f (a) = {ef f1(a), . . . , ef fn(a)}
is a set of effects of the form ef fi(a) = condi(a) → posti(a), where condi(a) and
posti(a) are sets of literals called condition and postcondition, respectively. We
say that a set of literals L over FP is compatible with a state s ⊆ FP , denoted
compat(L, s), when ∀f ∈ FP it holds that f ∈ L ⇒ f ∈ s and ¬f ∈ L ⇒ f ̸∈ s.
An action a ∈ AP is applicable in state s ⊆ FP , denoted applicable(a, s), if
and only if compat(pre(a), s) holds. Similarly, given a belief state B ⊆ 2FP ,
applicable(a, B) holds if and only if ∀s ∈ B it is the case that applicable(a, s) is
true.

If an action a is applicable in state s, the successor state, i.e, the state
that results from performing a in s, is defined as succ(a, s) = (s − {f ∈ FP :
∃i s.t. ¬f ∈ posti(a) and compat(condi(a), s)}) ∪ {f ∈ FP : ∃i s.t. f ∈ posti(a)

4

and compat(condi(a), s)}. The successor to a belief state B ⊆ 2FP is defined as
succ(a, B) = (cid:83)

s∈B succ(a, s).

A sequence of actions π = [a0, a1, . . . , an] where n ∈ N0 and ai ∈ AP is
applicable to belief state B ⊆ 2FP , denoted applicable(π, B) if and only if either
n = 0, or otherwise applicable(a0, B) and applicable([a1, . . . , an], succ(a0, B))
hold.
If applicable(π, B) does indeed hold, then succ(π, B) = B if n = 0,
otherwise succ(π, B) = succ([a1, . . . , an], succ(a0, B)).

A planning problem is a tuple P = (FP , AP , IP , GP ):
• FP is a set of fluents,
• AP is a set of actions over FP ,
• IP ⊆ 2FP is a non-empty set of states called the initial belief state, and
• GP ⊆ 2FP is a non-empty set of states called the goal.
A sequence π of actions is a strong plan, i.e., a solution that always reaches
the goal, when succ(π, IP ) ⊆ GP . Less restrictive, π is a weak plan, i.e., a
sequence that sometimes reaches the goal, when ∃s ∈ succ(π, IP ) such that
s ∈ GP .

We refer the reader to [5, 6, 7] for results on the complexity and heuristics
methods to generate strong and weak plans for a planning model such as the
one described here.

4 Layered Catalog Graphs

Influenced by episodic memory theory [1], the knowledge of an agent is defined
by two combinatorial structures.

• On one hand, we will consider an ontology of fluent and action symbols.
The fluent symbols (represented by unary concepts) are organized in a
type hierarchy. Similarly, the action symbols, represented by binary or n-
ary relations are also organized in a relation hierarchy. The action symbols
have a signature of their arguments, represented as fluent concept types.

• On the other hand, the agent will dispose of a hierarchical structure en-

coding preconditions and effects for various actions.

We only consider unary fluents for simplification purposes, however it is
immediate to see how we could extend this work in order to consider fluents of
any arity.

Let us note that the following definitions 1-7 are based on previous work on
conceptual graphs [4], although adapted to represent fluents and actions instead
of abstract concepts. Moreover, the framework presented in this paper could
not be modeled as-is with the mentioned literature due to the way in which
multiple fluents can relate to actions as preconditions and effects at the same
time.

The ontology is defined as follows:

5

Definition 1. An ontology is a 4-tuple S = (TF , TA, I, ∗) where:

• TF is a finite partially ordered set (poset) (TF , ≤) of fluent types, defining
a type hierarchy which has a greatest element ⊤C, namely the universal
type. In this specialization hierarchy, ∀x, y ∈ TF the symbolism x ≤ y is
used to denote that x is a subtype of y.

• TA is a finite set of action types partitioned into k posets (T i

A, ≤)i=1,k
of relation types of arity i (1 ≤ i ≤ k), where k is the maximum arity
of an action type in TA. Moreover, each action type of arity i, r ∈ T i
A,
, which specifies the
has an associated signature σ(r) ∈ TF × . . . × TF
(cid:125)

(cid:124)

(cid:123)(cid:122)
i times

maximum fluent type of each of its arguments. This means that if we use
r(x1, . . . , xi), then xj is a fluent with type(xj) ≤ σ(r)j (1 ≤ j ≤ i), where
type is the function that returns the type of a fluent. The partial orders
on relation types of the same arity must be signature-compatible, i.e., it
must be such that ∀r1, r2 ∈ T i

A r1 ≤ r2 ⇒ σ(r1) ≤ σ(r2).

• I is a countable set of

individual markers, used represent to given con-

stants.

• ∗ is the generic marker to denote an unspecified fluent (with a known

type).

• The sets TF , TA, I and {∗} are mutually disjoint and I ∪ {∗} is partially
ordered by x ≤ y if and only if x = y or y = ∗, for any given x, y ∈ I ∪{∗}.

It is worth to notice that the generic marker ‘∗’ will be used in this framework
to represent variables/un-instanced concepts in the arguments of fluents and
actions later.

The following depicts an ontology for the situation described before:

Example 1 (Elevator continued). We specify the types of fluents and actions
as:

• TF = {Button, F loor, ⊤C}, the fluent types, where Button, F loor ≤ ⊤C

are the only subtypes,

• TA = {U seElevatorT }, the action types, where σ(U seElevatorT ) =

(Button, Button, F loor, F loor).

• I = {bA, bB, fA, fB}, individuals.

As we can see, the ontology provides a support of types for fluents and actions.
In this case, we represent a basic action type for pressing the elevator button
that has a signature composed of elements of type Button and of type F loor,
corresponding to the arguments of such an action.

6

For the representation of the hierarchical knowledge of the agent we define
a simple graphical catalog of actions (SC) with their preconditions and effects.
The simple graph catalog is rendered hierarchical by a transformation called
transitional description defined further in the paper. The result will be a layered
graphical catalog of actions (LC) that the robot can access according to the need
at hand.

A SC provides a semantic set of pointers to the ontology of fluents and action

symbols.

Definition 2. A simple graphical catalog of actions is a 3-tuple SC = [S, G, λ],
where:

• S = (TF , TA, I, ∗) is the ontological support,

• G = (VF , VA, EG, l) is an ordered bipartite graph, where VF are called

fluent symbols and VA action symbols,

• l is a labelling that maps each edge {vA, vF } ∈ EG to a non-empty set of
pairs (k, i) ∈ l({vA, vF }) where i ∈ {1, . . . , dG(vA)} and k is either pre+,
j , with j ∈ N>0, denoting whether vF
pre−, cond+
is a positive or negative literal in the precondition, jth effect condition, or
jth effect postcondition of vA.

j , or post−

j , cond−

j , post+

• λ is a labelling of the nodes of G with elements from the support S:

∀r ∈ VA, λ(r) ∈ T nA
A such that nA ∈ N>0;
∀c ∈ VF , λ(c) ∈ TF × (cid:0)I ∪ {∗}(cid:1) such that
if c = N i

G(r), λ(r) = tr and λ(c) = (tc, refc), then tc ≤ σ(tr)i.

Intuitively, λ allows to make the link between nodes in G that represent
fluent and action symbols, and their respective types defined in S. Moreover,
the labelling allows to denote that a fluent is a precondition and/or effect of an
action. Let us depict the meaning of λ and l with the following example.

Example 2 (Elevator continued). Having defined an ontological support S =
(TF , TA, I, ∗), we can instantiate a simple graphical catalog of actions SC =
[S, G, λ] by specifying G = (VF , VA, EG, l) and λ as follows:

• VF = {InF loorElevator, InF loorAgent, CanU seCallButton,

CanU seSelectButton}, the set of fluent symbols, where
λ(InF loorElevator) = (∗, F loor),
λ(InF loorAgent) = (∗, F loor),
λ(CanU seCallButton) = (∗, Button),
λ(CanU seSelectButton) = (∗, Button).

• VA = {U seElevator}, the set of action symbols, where λ(U seElevator) =

U seElevatorT .

• EG = {{U seElevator, X} : X ∈ {InF loorElevator, InF loorAgent,

CanU seCallButton, CanU seSelectButton}},

7

InFloorElevator

{post+

1 , 4)}

InFloorAgent

{(pre+, 3), (post+
(post−

1 , 3)}

1 , 4),

UseElevator

CanUseCallButton

{(cond+

1 , 1)}

CanUseSelectButton

{(cond+

1 , 2)}

Figure 2: Bipartite graph for the action symbol U seElevator

• l the labelling assigns

l({U seElevator, CanU seCallButton}) = {(cond+
l({U seElevator, CanU seSelectButton}) = {(cond+
l({U seElevator, InF loorAgent}) = {(pre+, 3), (post+
l({U seElevator, InF loorElevator}) = (post+

1 , 1)},

1 , 2)},

1 , 4).

1 , 4), (post−

1 , 3),

We can see the SC [S, G, λ] in Figure 2. The fluent symbols in VF are
mapped by λ to the generic marker ‘*’ to denote that they refer to a vari-
able and not a specific constant. In particular, the symbol InF loorElevator
represents the current floor of the elevator, InF loorAgent the floor of the
agent, CanU seCallButton whether the agent can use the button to call the
elevator, and CanU seSelectButton the same for the button inside the eleva-
tor. The action symbol U seElevator has type U seElevatorT with signature
σ(U seElevator) = (Button, Button, F loor, F loor). This will be used to char-
acterize the type of the arguments of the (instanced) action. Then, a label
l({U seElevator, vF }) = (k, i) denotes that the ith argument of U seElevator
corresponds to the (unique) argument of the fluent vF , while k represents
the role of the fluent in the action. As we will see later, such an action
will get translated in our planning framework to something similar to an ac-
tion U seElevator(x, y, z, w) = ({InF loorAgent(z)}, {cond1 → ef f1}), where
cond1 = {CanU seCallButton(x), CanU seSelectButton(y)} and
ef f1 = {InF loorAgent(w), ¬InF loorAgent(z), InF loorElevator(w)}.

Transitional descriptions will allow for the definition of layered catalogs,
which represent the different levels of complexity in which we can break down
the model. Briefly, they represent a single step of expansion of action and
fluents into a new layer of complexity. A transitional description T D contains

8

a collection of bipartite graphs for each node of the original bipartite graph G
that one wants to expand, which represent the new added knowledge. Let us
now define what is a transitional description for a graph.

Definition 3. Let G = (VF , VA, EG) be a bipartite graph. A transitional
description associated to G is a pair T D = (D, (G.d)d∈D∪NG(D)) where

• D ⊆ VF is a set of complex fluent symbols, i.e: a subset of the original
fluents symbols in VF that can be expanded into a more complex represen-
tation.

• For each d ∈ D ∪ NG(D) G.d is a bipartite graph.
• If d ∈ D then G.d is the non-empty (G.d ̸= G∅) description of the complex
fluent symbol d. Distinct complex fluent symbols d, d′ ∈ D have disjoint
descriptions G.d ∩ G.d′ = G∅.

• If d ∈ NG(D) then G.d ̸= G∅, NG(d) − D ⊆ VF (G.d) and VF (G.d) ∩

VF (G.d′) ̸= ∅ if and only if d′ ∈ NG(d) ∩ D.

Note that (G.d)d∈D∪NG(D) is the collection of bipartite graphs for each node
d of the original bipartite graph that we want to expand. Moreover, when one
expands a fluent symbol, so do the action symbols it is related to. Conversely,
when an action symbol is expanded, the nodes in its expanded graph are the
same as those in the expansion of its related complex fluent symbols, or its
non-complex neighbors.

Let us illustrate this definition as follows.

Example 3 (Elevator continued). As we explained in Figure 1, we would like
to be able to separate the action symbol U seElevator into two: CallElevator
and T akeElevator. We can do this by using a transitional description T D =
(D, (G.d)d∈D∪NG(D)) as depicted in Figure 3, where D = {CanU seCallButton,
CanU seSelectButton}. Here, we see three SCs, namely ‘G.CanUseCallButton’,
‘G.CanUseSelectButton’ and ‘G.CanUseElevator ’. While the first two represent
the corresponding SCs obtained by augmenting the granularity of those fluents,
the third one showcases the augmented version of the action ‘UseElevator ’,
whose new level of granularity is obtained using the updated SCs of its fluents,
all of which is generated with the transitional description T D.

Finally let us now define how to apply a transitional description to a simple

catalog to expand the representation.

Definition 4. If T D = (D, (G.d)d∈D∪NG(D)) is a transitional description asso-
ciated to the bipartite graph G = (VF , VA, EG), then the graph T D(G) obtained
from G by applying T D is constructed as follows:

1. Take a new copy of ⌊VF − D⌋G.

2. For each d ∈ D, take a new copy of the graph G.d and make the disjoint

union of it with the current graph constructed.

9

G.CanUseCallButton

G.CanUseSelectButton

{(cond+

1 , 1)}

{(cond+

1 , 2)}

InReachCallButton

InReachSelectButton

CallElevator

TakeElevator

HasElectricityCallButton

HasElectricitySelectButton

G.UseElevator

{(cond+

1 , 1)}

CallElevator

{(cond+

1 , 2)}

{(post+

1 , 2)}

{(post+

1 , 3), (post−

1 , 4)}

{(pre+, 3)}

{(cond+

1 , 1)}

{(cond+

1 , 1)}

InFloorAgent HasElectricityCallButton InReachCallButton InFloorElevator HasElectricitySelectButton InReachSelectButton

{(pre+, 3), (post−

1 , 3), (post+

1 , 4)}

{(post−

1 , 1)}

{(cond+

1 , 2)}

{(pre+, 3), (post−

1 , 3), (post+

1 , 4)}

TakeElevator

{(cond+

1 , 2)}

Figure 3: Transitional description for the elevator example

3. For each d ∈ NG(D), identify the nodes of G.d which are already added to
the current graph (i.e. the atomic nodes of G that are neighbors of d and
the nodes of G.d′ which appear in G.d). For each complex neighbor d′ of
d in G, add the remaining nodes of G.d as new nodes in the current graph
and link all these nodes by edges as described in G.d (in order to have an
isomorphic copy of G.d as a subgraph in the current graph).

In the case of the previous example, due to the fact that there is only one
action symbol in the catalog [S, G, λ] defined previously, the bipartite graphs
T D(G) and G.U seElevator are identical.

The following property for bipartite graphs follows.

Proposition 1. If G = (VF , VA, EG) is a bipartite graph and T D is a transi-
tional description associated to G, then the graph T D(G) obtained from G by
applying T D is also a bipartite graph.
Proof sketch. We follow the construction given in the previous definition re-
garding the application of a transitional description T D to a bipartite graph
G.

It is immediate to see that the starting graph in (1) ⌊VF − D⌋G is a bipartite
one because G was bipartite. Then for point (2), each expanded graph G.d
is a bipartite one by definition and by applying a disjoint union with another
bipartite graph, the property is preserved. Finally, point (3) only links fluent
nodes to actions nodes, which also preserves the bipartite property.

10

This proposition ensures that the graph obtained by applying the transitional

description can itself be expanded using another.

So far, our definition of transitional description only accounts for nodes
and actions, but not that their expansions match their types, when considering
ontological supports. The following definition extends the notion for a simple
graphical catalog of actions to account for the types of fluents and actions.

Definition 5. Let SC = [S, G, λ] be a graphical catalog of actions, where G =
(VF , VA, EG, l). A transitional description associated to SC is a pair T D =
(D, (SC.d)d∈D∪NG(D)) where:

• D ⊆ VF is a set of complex fluent symbols.

• For each d ∈ D ∪ NG(D), SC.d = [S.d, G.d, λ.d] is a SC.

• If d ∈ D, then G.d is the non-empty (G.d ̸= G∅) description of the
complex fluent symbol d. Distinct complex fluent symbols d, d′ ∈ D have
disjoint descriptions G.d ∩ G.d′ = G∅. Moreover, for all v ∈ VF (G.d), it
holds that λ(d) = λ.d(v).

• If d ∈ NG(D), then G.d ̸= G∅, NG(d) − D ⊆ VF (G.d), and VF (G.d) ∩
VF (G.d′) ̸= ∅ for each d′ ∈ NG(d) ∩ D. Moreover, S.d ⊇ S ∪d′∈NG(d) S.d′,
λ.d(v) = λ(v) for v ∈ NG(d) − D and λ.d(v) = λ.d′(v) for v ∈ VF (G.d) ∩
VF (G.d′). Finally, for each d′ ∈ VA(G.d), it holds that λ(d) = λ.d(d′),
i.e., when decomposing an action through a transitional description, the
corresponding actions preserve its type.

Note that we disallow G.d = G∅, as this would erase the node when applying
In the simplest case, the new graph can only be

a transitional description.
composed of the original node itself, thus not producing any changes.

Analogously to the extension of transitional descriptions from bipartite graphs
to SCs, the following definition extends the application of a T D, to take into
account the types.

Definition 6. If T D = (D, (SC.d)d∈D∪NG(D)) is a transitional description as-
sociated to SC = [S, G, λ], then the simple graphical catalog of actions T D(SC)
obtained from SC by applying T D is T D(SC) = [S′, T D(G), λ′].

Here, T D(G) is the bipartite graph T D(G) obtained from G by applying
T D, S′ = ∪d∈D∪NG(D)S.d and λ′ is any legal labelling function defined on
V (T D(G)) which preserves the labels given to the vertices in V (G) and V (G.d)
for all v ∈ D ∪ NG(D).

Note that the last condition in Definition 5 (concerning the preservation
of types for the expanded action nodes) is the one that ensures that when
expanding the nodes, the types coming from the ontologies will be preserved
when applying a transitional description.

11

Moreover, using Proposition 1 we can verify that T D(SC) is a simple graph-
ical catalog of actions. This means that we can nest the application of transi-
tional description to produce several expanded catalogs of actions of increasing
complexity, which we define as follows:

Definition 7. Let n be a non-negative integer. A layered catalog graph (LC)
of depth n is a family LC = (cid:10) SC 0, T D0, . . . , T Dn−1 (cid:11) where:

• SC 0 = [S0, (V 0

F , V 0

A, E0), λ0)] is a SC,

• T D0 is a transitional description associated to SC 0,

• for each k, 1 ≤ k ≤ n − 1, T Dk is a transitional description associated to

F , V k

SC k = [Sk, (V k

A , Ek), λk)] = T Dk−1(SC k−1).
SC 0 is the base simple graphical catalog of actions of the layered graph LC and
SC k = T Dk−1(SC k−1) (k = 1, . . . , n), are its layers.

In other words, if we have an interconnected world described by a SC and
if we can provide details about both some complex fluent and action symbols,
then we can construct a second level of knowledge about this world, describ-
ing these new details as graphs and applying the corresponding substitutions.
This process can be similarly performed with the last constructed level, thus
obtaining a coherent set of layered representations of the initial world.

5 Related work

As we mentioned in the introduction, the motivation behind our work was to
provide a mechanism that improved the scrutability of a planner for a human
user. Unfolding representations between multiple granularity levels has been
studied in the context of AI planning optimization [8] and generic conceptual
graphs [4], but not for scrutability and neither in such a way that fluents and
actions can be unfolded with the support of an ontology. In recent years, the
AI planning community has taken interest in what in known as explainable
AI planning (XAIP) [9]. Notably, this branch has proposed several critical
questions for AI planners that can be of interest to human users: (i) why did
you do that?, (ii) why didn’t you do something else?, (iii) why is what you
propose to do more efficient/safe/cheap than something else?, (iv) why can’t
you do that?, (v) why do I need to replan at this point? and (vi) why do I
not need to replan at this point?. With that in mind, our framework could
reinforce other techniques [10, 11] to provide an appropriate level of detail for
the generated plan generated tailored to a specific kind of user. At the same
time, it could be applied in cases where no plan can be generated by using
counterfactuals [12, 13], so that the planner can iteratively inform the reason
behind its failures.

Moreover, as far as we know, there is no work coupling structured hierarchi-
cal knowledge of fluents and actions in such a way that the robot can expand

12

sets of fluents to assess which action could be applied using a general abstract
graph-based ontology. Although our work extends previous literature for con-
ceptual graphs [4], the mentioned literature would not allow to model action
preconditions and effects, due to the fact that the same fluent node cannot be
attached multiple times as one or the other, to the same action.

With regards to classical AI planning, our framework can be related to the
concept of ‘macro operators’ [14]. Macro operators were developed as an op-
timization technique for PDDL planners, which consists in learning operators
(actions) composed of several others before computing the plan for a complex
task, based on simpler ones. While this approach indeed allows to couple actions
together, this does not allow for several fluent granularity levels as we proposed
here.

That being said, the proposed approach is related to the field of hierarchical
task networks (HTN) [15] where dependencies among actions can be structured
in the form of hierarchies linking actions to higher level compound ones. How-
ever, this framework does not allow for the structured representation of knowl-
edge we provide. Some works have proposed ontologies for HTNs [16] domains,
but not with a focus on the transformation from one level of detail to another
on the fly as we do here. Similar to the macro operators, their work does not
allow for multiple fluent granularity levels and neither a mechanism to unfold
them.

Perhaps closer to our work, hierarchical models for STRIPS-like planners
have been studied [8] as a method to improve the efficiency of plan generation
by mapping tasks to different granularity levels. In contrast to out framework,
this avenue of work focused on mapping fluent parameters, instead of fluent and
action symbols.

6 Conclusion

In this paper, we introduced a graph-based hierarchical model of knowledge
about actions and fluents that allows to represent structured knowledge about
the world under the form of increasingly detailed levels. We developed a graph-
based framework supported by an ontology, called layered catalog of actions, to
characterize an agent’s actions. We showed how the fluents and actions of the
framework can be specified using this catalog. Our work not only formalized
this model, but also provided a method to adjust the level of detail of the fluents
and actions using the concept of transitional description.

The proposed approach that joins structured and layered knowledge of ac-
tions opens different avenues of research for future work.
In particular, by
adapting the level of granularity, an agent could adapt to the level of under-
standing of the user. This could pave the way for robot-user explanation by task
measurement, i.e., testing if the user can perform a task where multiple actions
have to be performed after being exposed to an explanation by the robot of a
similar problem.

Finally, because our framework relies on an ontology to represent the fluents

13

of states and considers belief states, it could potentially allow for plausible rea-
soning [17] through the type of individuals. More precisely, when the properties
of a certain individual are not fully known, it could be represented by using
different beliefs about the types of that individual and then implementing plau-
sible reasoning through the planner. In future work, this approach could also
be extended to other kind of uncertainty, such as partial observability planning
[18].

References

[1] Alan Baddeley. The concept of episodic memory. Philosophical Trans-
actions of the Royal Society of London. Series B: Biological Sciences,
356(1413):1345–1350, 2001.

[2] Malik Ghallab, Dana Nau, and Paolo Traverso. Automated Planning: the-

ory and practice. Elsevier, 2004.

[3] Marie-Laure Mugnier and Michel Chein. Conceptual graphs: Fundamental

notions. Revue d’intelligence artificielle, 6(4):365–406, 1992.

[4] Madalina Croitoru, Ernesto Compatangelo, and Chris Mellish. Hierarchical
In International

knowledge integration using layered conceptual graphs.
Conference on Conceptual Structures, pages 267–280. Springer, 2005.

[5] Daniel Bryce, Subbarao Kambhampati, and David E Smith. Planning
graph heuristics for belief space search. Journal of Artificial Intelligence
Research, 26:35–99, 2006.

[6] Blai Bonet and Hector Geffner. Planning with incomplete information as
heuristic search in belief space. In Proceedings of the Fifth International
Conference on Artificial Intelligence Planning Systems, pages 52–61, 2000.

[7] Alessandro Cimatti, Marco Pistore, Marco Roveri, and Paolo Traverso.
Weak, strong, and strong cyclic planning via symbolic model checking.
Artificial Intelligence, 147(1-2):35–84, 2003.

[8] Cipriano Galindo, J-A Fernandez-Madrigal, and Javier Gonzalez. Improv-
ing efficiency in mobile robot task planning through world abstraction.
IEEE Transactions on Robotics, 20(4):677–690, 2004.

[9] Maria Fox, Derek Long, and Daniele Magazzeni. Explainable planning.

arXiv preprint arXiv:1709.10256, 2017.

[10] Michael Cashmore, Anna Collins, Benjamin Krarup, Senka Krivic, Daniele
Magazzeni, and David Smith. Towards explainable ai planning as a service.
arXiv preprint arXiv:1908.05059, 2019.

14

[11] Tathagata Chakraborti, Sarath Sreedharan, and Subbarao Kambhampati.
The emerging landscape of explainable ai planning and decision making.
arXiv preprint arXiv:2002.11697, 2020.

[12] Ruth MJ Byrne. Counterfactuals in explainable artificial intelligence (xai):
Evidence from human reasoning. In IJCAI, pages 6276–6282, 2019.

[13] Devleena Das, Siddhartha Banerjee, and Sonia Chernova. Explainable ai
for robot failures: Generating explanations that improve user assistance
In Proceedings of the 2021 ACM/IEEE International
in fault recovery.
Conference on Human-Robot Interaction, pages 351–360, 2021.

[14] Adi Botea, Markus Enzenberger, Martin Müller, and Jonathan Schaef-
fer. Macro-ff: Improving ai planning with automatically learned macro-
operators. Journal of Artificial Intelligence Research, 24:581–621, 2005.

[15] Kutluhan Erol, James A Hendler, and Dana S Nau. Semantics for hi-
erarchical task-network planning. Technical report, MARYLAND UNIV
COLLEGE PARK INST FOR SYSTEMS RESEARCH, 1995.

[16] Artur Freitas, Daniela Schmidt, Felipe Meneguzzi, Renata Vieira, and
Rafael H Bordini. Using ontologies as semantic representations of hier-
archical task network planning domains. In Proceedings of WWW, page
124, 2014.

[17] Allan Collins and Ryszard Michalski. The logic of plausible reasoning: A

core theory. cognitive science, 13(1):1–49, 1989.

[18] Blai Bonet and Hector Geffner. Planning under partial observability by
classical replanning: Theory and experiments. In Twenty-Second Interna-
tional Joint Conference on Artificial Intelligence, 2011.

15

