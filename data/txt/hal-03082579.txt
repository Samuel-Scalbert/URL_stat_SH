A Multi-Objective Evolutionary Approach to Class
Disjointness Axiom Discovery
Thu Huong Nguyen, Andrea G. B. Tettamanzi

To cite this version:

Thu Huong Nguyen, Andrea G. B. Tettamanzi. A Multi-Objective Evolutionary Approach to Class
Disjointness Axiom Discovery. WI-IAT 2020 - IEEE/WIC/ACM International Joint Conference on
Web Intelligence and Intelligent Agent Technology, Dec 2020, Melbourne/ Virtual, Australia.
￿hal-
03082579￿

HAL Id: hal-03082579

https://inria.hal.science/hal-03082579

Submitted on 18 Dec 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

A Multi-Objective Evolutionary Approach to Class
Disjointness Axiom Discovery

Thu Huong Nguyen
Universit´e Cˆote d’Azur, Inria, CNRS, I3S
Nice, France
thu-huong.nguyen@univ-cotedazur.fr

Andrea G. B. Tettamanzi
Universit´e Cˆote d’Azur, Inria, CNRS, I3S
Nice, France
andrea.tettamanzi@univ-cotedazur.fr

Abstract—The huge wealth of linked data available on the
Web (also known as the Web of data), organized according to the
standards of the Semantic Web, can be exploited to automatically
discover new knowledge, expressed in the form of axioms, one of
the essential components of ontologies. In order to overcome the
limitations of existing methods for axiom discovery, we propose
a two-objective grammar-based genetic programming approach
that casts axiom discovery as a genetic programming problem
involving the two independent criteria of axiom credibility and
generality. We demonstrate the power of the proposed approach
by applying it to the task of discovering class disjointness axioms
involving complex class expression, a type of axioms that plays an
important role in improving the quality of ontologies. We carry
out experiments to determine the most appropriate parameter
settings and we perform an empirical comparison of the proposed
method with state-of-the-art methods proposed in the literature.

Index Terms—Ontology Learning, OWL Axiom, Disjointness
Axiom, Genetic Programming, Grammatical Evolution, Multi-
Objective Optimization.

I. INTRODUCTION

The growth of the Semantic Web also known as the Web
of data, where the Linked Open Data (LOD) is a prominent
representative opens up exciting opportunities for ontology
learning. Due to heterogeneous semantic resources on the Web,
ontological knowledge bases (KBs) may turn out to incomplete
and noisy. Speciﬁcally, the incompleteness refers to the lack
of information in ontology while the noise is relevant to the
issues of invalid information. To enhance the quality of an
ontology, the existence of axioms can be considered as the
agents in pinpointing errors and inconsistencies in KBs. In
ontology construction and knowledge base enrichment, the
automatic asquistion of axiom is a central task which goes
under the name of axiom learning. Like other types of axioms,
class disjointness axioms are used to check the consistencies of
the information contained in the ontologies or to deduce new
information. For example, a reasoner will be able to deduce
an error, i.e., a logical inconsistency of facts in the ontology,
whenever the class Fish is associated to a resource related to
the class Planet, if there is a constraint of disjointness between
the two concepts Fish and Planet.

As a consequence of the essential role of class disjointness
axioms in existing ontologies, learning hidden knowledge in
terms of axioms from a LOD repository in the context of the
Semantic Web has been the object of research using several

different methods. Some prominent research towards the au-
tomatic creation of class disjointness axioms from RDF facts
include supervised classiﬁcation, like in the LeDA system [1],
statistical schema induction via associative rule mining, like
in the GoldMiner system [2], and learning general class
descriptions (including disjointness) from training data, like
in the DL-Learner framework [3]. In adtition, recent contri-
bution has proposed using unsupervised statistical approaches
like Formal Concept Analysis (FCA) [4] or Terminological
Cluster Trees (TCT) [5],
to discover disjointness axioms.
Most approaches to learning axioms in the literature are
based on deterministic level-wise generate-and-test methods,
which essentially perform an exhaustive search, coupled with
heuristic pruning, of the the space of hypotheses. Their main
limitation is that they are incapable of scaling up when the
space of the hypothesis, i.e. axioms, becomes too large. As a
consequence, their applicability is restricted to the discovery
of relatively simple axioms, i.e. atomic axioms.

Given the complexity of the problem, a heuristic approach,
such as evolutionary algorithm, can handle with the search for
more complex axioms whose space is incomparably larger.
In fact, there are also some recent works [6]–[9] applying
an evolutionary approach by using Grammatical Evolution
(GE) to extracting class disjointness axioms from large RDF
i.e., DBpedia1. The use of a grammar allows
repository,
great ﬂexibility: only the grammar needs to be changed to
mine different data repositories for different types of axioms.
Extracted axioms in [6], [7] include both atomic and complex
axioms, i.e., deﬁned with the help of relational operators of in-
tersection and union; in other words, axioms like Dis(C1, C2),
where C1 and C2 are complex class expressions including
operators. However, the dependence on SPARQL endpoints
(i.e., query engines) for testing mined axioms against facts,
i.e. instances, in large RDF repositories limits the performance
of the method. In addition, evaluating the effectiveness of
the method requires the participation of experts in speciﬁc
domains, i.e. the use of a Gold Standard, which is proportional
to the number of concepts. Hence, the extracted axioms are
limited to the classes relevant to a small scope of topics,
namely the Work topic of DBpedia. Also, complex axioms are
deﬁned with the help of relational operators of intersection and

1https://wiki.dbpedia.org/

union, which can also be mechanically derived from the known
atomic axioms. To overcome that limitation, the type of mined
class disjointness axioms in [8], [9] is extended to include
the existence restriction (∃r.C) and value restriction (∀r.C)
constructors, where r is a property and C a class, which cannot
be mechanically derived from a given set of atomic axioms.
Furthermore, a training-testing model is applied to objectively
validate the method. Speciﬁcally, the whole DBpedia is used
as the objective benchmark for evaluating the extracted axioms
from a small training RDF dataset, i.e. sample of DBpedia, and
eliminating the use of Gold Standard created by knowledge
experts. The evaluation framework based on possibility theory
[7]–[9] to determine the ﬁtness values of generated axioms
in the evolutionary cycle, i.e. the credibility and generality of
axioms. However, the selection pressure in each phases of the
evolutionary process tends naturally to drive the diversity of
the population down. In addition, the presence of highly ﬁt but
possibly invalid candidate axioms in the population reduces the
number of valid axioms that can be discovered which can be
derived from unsuited ﬁtness function in evaluation framework
which based on a single criterion.

Along the lines of the studies using GE to mine class
disjointness axioms, we extend the approach as a multi-
objective problem, i.e. multi-objective GE, in additition to
the trade-off between a set of objectives. Speciﬁcally, we
used an multi-objectives approach to reﬁne the evaluation of
candidate axioms that improves the adaptive ﬁt of a population
of candidate axioms constrained by two independent criteria,
i.e. the credibility and generality. We also proposed a new
measure called the similarity and a method to compute it.
We aim to optimize the evaluation framework for the axioms
which ensures the high accuracy, generality and the diversity
of the obtained axioms. In the study, we reuse the grammar
and the training-testing model to extract class disjointness
axioms in [8], [9] and perform comparison with the relevant
approaches.

The rest of the paper is organized as follows: some basics
in GE and GE in axioms discovery are provided in Section II.
Axiom discovery in multi-objective GE approach is presented
in Section III. Section IV introduces the organization of
dataset. The experimental settings and results are presented
and discussed in Section V. Finally, conclusions and directions
for future research are given in Section VI.

II. GRAMMATICAL EVOLUTION FOR AXIOM DISCOVERY

The foundation of our study is Grammatical Evolution (GE),
a recent evolutionary model pioneered by Michael O’Neil and
his collaborators [10]. In this section, we provide a summary
of the GE in addition to theoretical and technical ingredients
concerning axiom discovery.

A. Basics

Grammatical Evolution (GE) is an evolutionary approach
that extends Genetic Programming (GP) [11], [12] to allow
the exploration of the space of computer programs through the
use of a grammar-mediated representation. Programs, viewed

Fig. 1. Grammatical Evolution mechanism

as phenotypic solutions or phenotypes, are decoded from
variable-length binary strings, i.e., genotypic individuals or
genotypes, through a transformation called mapping process.
According to it, the variable-length binary string genomes,
or chromosomes, are split into consecutive groups of bits,
called codons, representing an integer value, used to select,
at each step, one of a set of production rules from a for-
mal grammar, typically in Backus-Naur form (BNF), which
speciﬁes the syntax of the desired programs. Furthermore,
inspired by biological evolution and its fundamental mecha-
nisms, these programs are “bred” using iterative improvement
of an initially random population of programs. That is an
evolutionary process. At each iteration, known as a generation,
improvements are made possible by stochastic variation, i.e.,
by a set of genetic operators, usually crossover and mutation,
and probabilistic selection according to pre-speciﬁed criteria
for judging the quality of an individual (solution). According
to the levels of ﬁtness, the process of selecting individuals,
called ﬁtness-based selection, is performed to create a list of
better qualiﬁed individuals as input for generating a new set of
candidate solutions in the next generation. The new solutions
of each generation are bred by applying genetic operators on
the selected old individuals. Then, replacement is the last step
and decides which individuals stay in a population and which
are replaced on a par, with selection inﬂuencing convergence.
An illustration of the GE mechanism is presented in Fig 1.

B. BNF Grammar

In terms of axioms discovery, “programs” or “phenotypes”
refer to axioms constrained by a given BNF grammar. A BNF
grammar is a context-free grammar consisting of terminal
and non-terminal symbols (also called just terminals and non-
terminals) and being represented in the form of a four-tuple
{N, T, P, S}, where N is the sets of non-terminals, which
can be extended into one or more terminals; T is the set of
terminals, which are tokens in the described language; P is
the set of the production rules that map N to T ; S is the
start symbol and a member of N . When there are a number
of productions that can be used to rewrite one speciﬁc non-
terminal, they are separated by the ‘|’ symbol.

We comply with the BNF grammar given in [8],
the
and C2 may

[9]
form DisjointClasses(C1, C2), where C1

to mine binary disjointness axioms only, of

be atomic or complex classes involving relational operators,
i.e. existential quantiﬁcation and value restriction, and
possibly including more than one single class identiﬁer, like
DisjointClasses(VideoGame, ObjectAllValuesFrom(hasStadium,
Sport)). To make the paper self-contained, we recall here the
most important aspects of this grammar. The grammar is split
into a static and a dynamic part to ensure that changes in the
contents of RDF repositories will not require the grammar
to be rewritten. The static part deﬁnes the syntax of the
types of axioms to be extracted. The content of this part is
loaded from a hand-crafted text ﬁle. The structure of the BNF
grammar here aims at mining well-formed axioms expressing
the facts, i.e. instances, contained in a given RDF triple store.
Hence, only resources that actually occur in the RDF dataset
should be generated. The static part of the grammar is thus
structured as follows:

The dynamic part contains production rules for the low-level
non-terminals, called primitives in [6], [7]. These production
rules are automatically ﬁlled at run-time by querying the
SPARQL endpoint of the RDF data source at hand. Let us
consider an example representing a small sample of an RDF
dataset:

PREFIX dbr: http://dbpedia.org/resource/
PREFIX dbo: http://dbpedia.org/ontology/
PREFIX dbprop: http://dbpedia.org/property/
PREFIX rdf: http://www.w3.org/1999/02/22\-rdf-syntax-ns\#

dbr:Amblycera
dbr:Salweenia
Dbr:Himalayas
dbr:Amadeus
dbr:Cat_Napping
dbr:With_Abandon
dbr:Idris_Muhammad
dbr:Genes_Reunited

rdf:type
rdf:type
rdf:type
rdf:type
dbprop:director
dbprop:artist
dbprop:occupation
dbo:industry

dbo:Animal.
dbo:Plant.
dbo:NaturalPlace.
dbo:Work.
dbr:William_Hanna.
dbr:Chasing_Furies.
dbr:Drummer.
dbr:Genealogy.

The productions for Class and ObjectPropertyOf would

thus be:

(r9) Class := dbo:Animal
|
|
|

(0)
(1)
dbo:Plant
dbo:NaturalPlace (2)
(3)
dbo:Work

(r10) ObjectPropertyOf :=
|
|
|

dbprop:director
dbprop:artist
dbprop:occuptation
dbo:industry

(0)
(1)
(2)
(3)

C. Mapping Process

In the mapping process, codons are used consecutively to
choose production rules in the BNF grammar according to the
function:

production = codon modulo (cid:2)Number of productions for the

current non-terminal

(cid:3)

(1)

We illustrate the decoding of an integer chromosome
into an OWL class disjointness axiom through a speciﬁc
the chromosome be (352, 265,
example (see Fig 2). Let
529, 927, 419). There is only one production for
the
non-terminals Axiom, ClassAxiom, DisjointClasses,
ObjectIntersectionOf, ObjectSomeValuesFrom
and ObjectAllValuesFrom, as it can be seen from
Rules 1–3 and 6–8. In these cases, we skip using any codons
for mapping and concentrate on reading codons for non-
terminals having more than one production, like in Rules 4,
5, 9, and 10.

III. MULTI-OBJECTIVE GE FOR AXIOM DISCOVERY

Within the evolutionary process, the evaluation framework
quantiﬁes the quality of axioms, which is the base for selecting
individuals (solutions) for the recombination, mutation, and
replacement phases. In previous work [7]–[9], the aim was to
look for credible and general axioms, based on possibilistic
axiom scoring for credibility and on a scoring of their gen-
erality. These two scores were then combined into a single
ﬁtness function, i.e., a single objective. The superiority of an
axiom over other ones was simply determined by comparing
their ﬁtness scores. However, the ﬁtness values can suffer
from one of two objectives offsetting the other, for instance
when a high generality score is assigned to axioms possessing
a low possibility. In fact, the two criteria of generality and
credibility are incommensurable and any way of combining
them is therefore largely a matter of points of view, hard to
justify on an objective basis. To overcome that limitation, we
treat the problem as a multi-objective optimization problem,
which allows for explicit trade-offs with respect to a set of
objectives.

A. Multi-Objective Evolutionary Algorithms

A Multi-objective Optimization (MO) [13] problem in-
volves a number of objective functions constituting a multi-
dimensional objective space, in addition to the decision vari-
able space. Speciﬁcally, a solution to a MO problem is a
vector of decision variables x = (x1, x2, ...., xn)T in the
decision space X. For each x, there exists an objective vector
y = (y1, y2, ...., yn)T in the objective space Y mapped by a
function f : X → Y .

The term domination is used for the situation of comparing
two solutions x(1) and x(2). A solution x(1) dominates the
other solution x(2) (x(1) (cid:31) x(2)) if x(1) is no worse than x(2)
in all objectives (no component of y(1) is smaller than the
component of y(2), where y(1) = f (x(1)) and y(2) = f (x(2))),
and x(1) is strictly better than x(2) in at least one objective (at
least one component is greater). The set of optimal solutions
in the decision space X is denoted as Pareto-optimal solutions
or Pareto set. In addition, there are corresponding optimal
objective vectors, i.e. points, in the objective space Y , denoted
as Pareto-optimal front or non-domination front. In MO, all
objectives are equally important, i.e., ﬁnding the optimum
solution cannot be based on one objective alone while skipping
other objectives. The goal of MO is to ﬁnd multiple solutions

Fig. 2. An illustration of mapping process

representing the possible non-dominated trade-offs among the
objective functions, i.e., a set of solutions lying on the Pareto-
optimal front. In addition, a set of obtained solutions is sought
for that is also diverse enough to represent the entire range of
the Pareto-optimal front.

This results in a heuristic approach,

the Multi-objective
Evolutionary Algorithm (MOEA) [13], [14], which follows
the goal of MO but refers to ﬁnding multiple non-dominated
points as close to the Pareto-optimal front as possible, i.e.,
a Pareto-optimal
to the
trade-off among objectives. Also, it provides operators, i.e.,
recombination and mutation operators, to constantly improve
the evolving non-dominated points.

front approximation, with respect

NSGA-II [15] is one of the well-known multi objective
evolutionary algorithms, which simultaneously optimizes each
objective without being dominated by any other solution.
NSGA-II concentrates on ﬁnding non-dominated solutions in
addition to elistist and diversity preserving mechanisms.

As a particular case of MOEA, the approach we propose
comprises the integration of GE in MOEA i.e., using NSGA-
II, for axiom discovery, which we call Multi-Objective GE
(MOGE). Basically, the mechanism of MOGE is quite similar
to the one of a MOEA, except that we deﬁne multi-objective
problems using integer arrays called codons as decision vari-
ables. The codons do not deﬁne axioms, i.e., the programs,
themselves, but provide instructions for deriving axioms using
the BNF grammar through the mapping process explained
above.

B. Multi-objective Evaluation Framework

The goodness of an axioms is determined by its dominance,
whereby it obtains a score on each objective which is not

dominated by the corresponding score of another axiom.
To derive such axioms, we extend the classic GE approach
presented in [6]–[9] to MOGE. We also develop separate
objective functions to evaluate the ﬁtness of each axiom. In
order to ensure the diversity of the obtained axioms, a scoring
of the similarity of each axiom to the other axioms in the
population (essentially, a local phenotypic crowding measure)
is also considered in the evaluation framework. In this section,
we ﬁrst recall axiom the scoring, regarding possibility and
generality applied in [7]–[9]. In addition, we introduce a new
scoring, called the similarity. Finally, the objective functions
for the method are presented.

1) Possibility Measure: is based on possibility theory [16],
a mathematical theory of epistemic uncertainty. In the open-
world, the knowledge base represented by RDF repository is
incomplete. Additionally, as a results of the heterogeneous and
collaborative character of the LOD, there exist some missing
and erroneous facts (instances) in RDF datasets, i.e. noisy
knowledge. Hence, adopting an axiom scoring heuristics based
on possibility theory (see [17] for the theoretical background)
is well-suited. Accordingly, a candidate axiom φ is viewed as a
hypothesis that has to be tested against the evidence contained
in an RDF dataset. Its content is deﬁned as a ﬁnite set of
logical consequences

content(φ) = {ψ : φ |= ψ},

(2)

obtained through the instantiation of φ to the vocabulary of
the RDF repository; every ψ ∈ content(φ) may be readily
tested by means of a SPARQL ASK query. The support of
axiom φ, uφ, is deﬁned as the cardinality of content(φ). The
support, together with the number of conﬁrmations u+
φ (i.e.,
the number of ψ for which the test is successful) and the

number of counterexamples u−
φ (i.e., the number of ψ for
which the test is unsuccessful), are used to compute a degree
of possibility Π(φ) for axiom φ, deﬁned, for u(φ) > 0, as

Π(φ) = 1 −

(cid:118)
(cid:117)
(cid:117)
(cid:116)1 −

(cid:32) uφ − u−
uφ

φ

(cid:33)2

.

Possibility alone is a reliable measure of the credibility of a
class disjointness axiom, all the more so because (and this is a
very important point), in view of the open world assumption,
for two classes that do not share any instance, disjointness can
only be hypothetical (i.e., fully possible, if not contradicted by
facts, but never necessary). Possibility is measured by deﬁning
the numbers of counterexamples and the support. These values
are counted by executing the corresponding SPARQL queries
based on graph patterns, via an accessible SPARQL endpoint.
We refer the interested reader to [7], [8] for an in-depth
description of the relevant SPARQL queries.

2) Generality measure: is determined by the quantities of
the facts(instances), in the extension of its components. In [6],
the generality of an axiom is deﬁned as the cardinality of the
set of the facts in the RDF repository reﬂecting the support of
each axiom, i.e., uφ. However, in case one of the components
of an axiom is not supported by any fact, its generality should
be zero. Hence, the generality of an axiom should be measured
by the minimum of the cardinalities of the extensions of the
two class expressions involved, i.e. gφ = min{(cid:107)[C](cid:107), (cid:107)[D](cid:107)}
where C, D are class expressions.

3) Similarity measure: quantiﬁes the similarity of an axiom
φ, s(φ), to the population of n axioms which is deﬁned by
the average of similarity metrics s(φ, ai) between axiom φ
and each axiom ai in the population:

s(φ) =

1
n − 1

n
(cid:88)

i=1;ai(cid:54)=φ

s(φ, ai)

(3)

In order to measure the similarity coefﬁcient s(φ) as in the
above formula, the similarities s(φ, ai) need to be computed.
As mentioned in II-B, axioms are structured in the form of
binary axioms of the form φ ≡ DisjointClasses(A, B)
and ai ≡ DisjointClasses(C, D) where A, B, C, D can
be atomic expressions or complex expressions containing
relational operators of restriction, i.e., existential quantiﬁcation
and value restriction. We deﬁne the similarity between two
axioms based on the similarities between pairs of expressions
as

s(φ, ai) = max{s(A, C), s(A, D), s(B, C), s(B, D)}

(4)

Expressions in each axiom are represented in the form of
binary trees where each node can be an atomic class or a
relational operator, namely existential quantiﬁcation (∃), value
restriction (∀), or intersection ((cid:117)) operators. Determining each
similarity between expressions, e.g., s(A, C), is performed on
corresponding binary trees t1 and t2. Binary trees are traversed
simultaneously and each pair of corresponding nodes (pj, qj)
in both trees, i.e., pj in t1 and qj in t2, is compared to each

other and the value returned is the similarity between two
nodes, i.e., s(pj, qj), according to Table I. One notable point is
that if both nodes represent atomic classes, the value returned
is 1 if the two nodes represent the same class; otherwise the
value returned is 0. Each similarity between expressions, e.g.
s(A,C), is deﬁned as

s(A, C) =

1
k

k
(cid:88)

j=1

s(pj, qj)

(5)

where k is the number of pairs deﬁned by the number of nodes
in the smallest tree.

TABLE I
MATRIX FOR THE COMPARISON BETWEEN NODES

Node
Atomic class
(cid:117)
∃
∀

Atomic class
0 or 1
0
0
0

(cid:117)
0
1
0
0.5

∃
0
0
1
0

∀
0
0.5
0
1

4) Objective Functions: are used for the comparisons be-
tween axioms which reﬂect the correlation of measures to
determine the quality of each axiom. We propose two objective
functions, f1 and f2, used in our approach, which aim at
obtaining axioms that maximize the value of possibility and
generality, while not being too similar among themselves:






(cid:113)

1 − s(φ)2

Maximize f1 = Π(φ) ·
(cid:113)

Maximize f2 = gφ ·
Where 0 ≤ Π(φ) ≤ 1; gφ ≥ 0 ; 0 < s(φ) < 1

1 − s(φ)2

(6)

IV. DATASET ORGANIZATION

To investigate the effectiveness of our approach, we organize
our dataset following the “training-testing” model. Speciﬁ-
cally, the learning process is performed with the input data
source derived from a training RDF dataset, a random sample
of DBpedia, whereas the evaluation of discovered axioms is
based on a testing dataset, which is the full DBpedia, which
can be considered as an objective benchmark. The workﬂow
of this model is shown in Fig 3.

Fig. 3. Workﬂow of class disjointness axioms discovery using GE in the
training- testing model

We use the same Training Dataset2 (TD) used in [8], [9],
with 6,739,240 connected RDF triples with a variety of topics
from DBpedia, which randomly collect 1% of the triples from
DBpedia 2015-04 (English version).The performance of the
method is measured by using the entire DBpedia 2015-04 as a
test set, measuring possibility, generality, and similarity scores
for every distinct axiom discovered by our algorithm. To avoid
overloading DBpedia’s SPARQL endpoint, we set up a local
mirror using the Virtuoso Universal Server.3

V. EXPERIMENTS & RESULTS

A. Experimental Protocol

We use the BNF grammar introduced in Section II. In
addition, to make fair comparisons possible with previous
studies [8], [9], a set of milestones of total effort k (deﬁned
as the total number of ﬁtness evaluations) corresponding to
each population size are also recorded for each run, namely
100,000; 200,000; 300,000 and 400,000, respectively. The
maximum numbers of generations, maxGenerations (used as
the stopping criterion of the algorithm) are automatically
determined based on the values of the total effort k, thus
popSize · maxGenerations = k.

A prototype system of the proposed method was developed
in Java, using Apache Jena to interface with SPARQL end-
points and GEVA v.2.0 4, a reference Java implementation of
GE. Also, we integrated the system with the MOEA frame-
work API,5 a Java framework for multi-objective optimization.
The parameters are listed in Table II.

TABLE II
PARAMETER VALUES FOR MOGE.

Parameter
Total effort k
initLenChrom
pCross
popSize

Value
100,000; 200,000; 300,000; 400,000
6
80%
1000; 2000; 5000; 10000

B. Results

We ran the MOGE method for 20 distinct runs for each of
the different parameter settings summarized in Table II, using
the BNF grammar deﬁned in Section II-B. The full set of valid
distinct axioms, i.e., axioms φ such that Π(φ) > 0 and gφ > 0
discovered are available online.6 Statistics for automatically
generated axioms are presented in Table III. In addition, we
can see in Fig. 4 that the number of valid distinct axioms
for most parameter settings, i.e., population size popSize and
total effort k, mined by MOGE is signiﬁcantly greater than
those mined by the single-objective GE method in [8], [9].
This means that the diversity of an extracted set of axioms is
considerably enhanced when we use the MOGE method.

2Available for download at http://bit.ly/2OtFqHp
3https://virtuoso.openlinksw.com/
4http://ncra.ucd.ie/Site/GEVA.html
5http://moeaframework.org/javadoc/index.html
6https://bit.ly/38crj4M

TABLE III
NUMBER OF VALID DISTINCT AXIOMS DISCOVERED OVER 20 RUNS

(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)

popSize

k
100000
200000
300000
400000

1000

8084
8713
7970
8457

2000

16085
17400
17680
16258

5000

41320
41813
40303
40656

10000

50535
76804
70562
67722

Furthermore, we follow the use of the fuzzy extension of
the usual deﬁnition of precision in [8], [9] to measure the
accuracy of our results. Accordingly, Π(φ) is interpreted as
the degree of membership of axiom φ in the (fuzzy) set
of the “positive” axioms. The value of precision can thus
be computed against the test dataset, i.e., DBpedia 2015-04,
according to the formula

precision =

(cid:107)true positives(cid:107)
(cid:107)discovered axioms(cid:107)

=

(cid:80)

φ ΠDBpedia(φ)
(cid:80)
φ ΠTD(φ)

. (7)

where ΠTD and ΠDBpedia are the possibility measures com-
puted on the training dataset and DBpedia, respectively.

The results in Table IV conﬁrm the high accuracy of
the proposed MOGE method. The precision values are quite
equivalent to the ﬁgures of GE method [8], [9] with the range
from 0.984 to 0.996 for all the different considered population
sizes and different numbers of generations (reﬂected through
the values of total effort).

Fig. 5 illustrates the distribution of axioms having Π(φ) > 2
3
in terms of the two objectives, i.e. possibility and generality,
compared with the GE methods of [8], [9]. We perform
the comparison based on the results of the best setting,
i.e., those yielding the largest number of obtained distinct
axioms and the highest accuracy, for either method,
i.e.,
{popSize = 10, 000; k = 200, 000} and {popSize =
5, 000; k = 300, 000}, respectively. We can observe that the
number of highly qualiﬁed axioms (Π(Φ) > 2
3 and gΦ > 100))
is maintained in MOGE system. More clearly, based on the
speciﬁc resulting statistics, the number of obtained axioms
from MOGE in the best setting is 38, 134 which is much
greater than those extracted by the GE, i.e., 23, 767 axioms.
In addition, with the smaller value of total effort k reﬂecting
the cost of evaluations, i.e., k = 200, 0000 compared with
k = 300, 000 in [8], [9], MOGE is clearly more effective in
inducing highly qualiﬁed axioms. We also show the distribu-
tion of the discovered axioms in this best setting in terms of
similarity coefﬁcient in Fig. 6. The range of similarity scores
recorded for these axioms lies below 0.35, which indicates a
good diversity of the classes and properties in the components
of axioms. Based on the given grammar, one part of the axioms
is forced to contain a relational operator, i.e. ∃, ∀, or (cid:117), hence,
the overlap of the operators in axioms does not allow the
similarity score to be zero.

According to the results, we consider

the
axioms discovered by the algorithm with this best setting.
First, we witness that
the number of obtained axioms
containing the ∃ operator is slightly larger than the one

in detail

GE

MOGE

Fig. 4. Statistical comparison about the number of axioms discovered over 20 runs between MOGE and GE method.

TABLE IV
AVERAGE PRECISION PER RUN (±std)

GE

MOGE

1,000

2,000

5,000

10,000

1,000

2,000

5,000

10,000

0.981
0.019
0.973
±0.024
0.972
±0.024
0.972
±0.024

0.999
±0.002
0.979
±0.011
0.973
±0.014
0.969
±0.018

0.998
±0.002
0.998
±0.001
0.993
±0.007
0.980
±0.008

0.998
±0.003
0.998
±0.002
0.998
±0.001
0.998
±0.001

0.988
±0.007
0.989
±0.007
0.989
±0.007
0.989
±0.008

0.990
±0.005
0.990
±0.004
0.989
±0.003
0.990
±0.003

0.989
±0.003
0.987
±0.004
0.986
±0.004
0.985
±0.004

0.996
±0.001
0.988
±0.004
0.986
±0.003
0.984
±0.004

(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)(cid:88)

popSize

k

100,000

200,000

300,000

400,000

that

axioms

of those with the ∀ operator, namely 40,122 and 36,682
axioms, respectively. However, together with the mandatory
class expression containing the ∀ or ∃ operator, most
contain an atomic
extracted class disjointness
class expression. This may be due to the fact
the
support of atomic classes is usually larger than the support
of a complex class expression. Speciﬁcally, we obtain
7 axioms containing complex expressions in both their
members. These axioms are less general, even though
they are completely possible. An example is the case with
DisjointClasses(ObjectAllValuesFrom(dbprop:operation
dbo:MilitaryConﬂict) ObjectAllValuesFrom(dbprop:order
dbo:MIlitaryUnit))(Π(φ) = 1.0 ; gφ = 1). Also, we
and
a
analyze
DisjointClasses(dbo:District
highly
ObjectSomeValuesFrom(dbo:birthPlace
dbo:Place))
(Π(φ) = 1.0 ; gφ = 8, 483), which we can paraphrase as
“districts cannot have a place as their birthplace”. Knowing
that District and Place are not disjoint, this axiom states
that District and ∃birthPlace.Place are in fact disjoint; in
addition, ∃birthPlace.Place, i.e., “(people) whose birthplace

an
general

of
axiom,

completely

example

possible

is a place” is a class with many instances, hence the high
generality of the axiom.

VI. CONCLUSION
We have proposed a multi-objective extension to a grammar-
based genetic programming approach to axiom discovery
which consists of using two objectives plus a “similarity”
score, which is in fact a sort of a local phenotypic crowding
factor. The experimental results conﬁrm that the proposed
method is capable of discovering highly accurate and general
axioms and is more effective compared with the single-
objective methods of previous studies. In the future, we will
focus on mining disjointness axioms involving further types of
complex classes, by bringing into the picture other relational
operators such as owl:hasValue and owl:OneOf. We
also plan on reﬁning the evaluation of candidate axioms with
the inclusion of some measurement of their complexity in the
ﬁtness function.

ACKNOWLEDGMENTS
This research was carried out in the Wimmics team, which
is a joint research team of Universit´e Cˆote d’Azur, Inria, and

GE

MOGE

Fig. 5. Possibility and generality distribution of the discovered axioms with Π(φ) > 2
3

Fig. 6. The distribution of the discovered axioms in terms of measures (Π(φ) > 2
3 )

I3S. Our research motto: AI in bridging social semantics and
formal semantics on the Web.

This work has been partially supported by the French
government, through the 3IA Cˆote d’Azur “Investments in the
Future” project managed by the National Research Agency
(ANR) with the reference number ANR-19-P3IA-0002.

REFERENCES

[1] J. V¨olker, D. Vrandecic, Y. Sure, and A. Hotho, “Learning disjointness,”
in ESWC, ser. Lecture Notes in Computer Science, vol. 4519. Springer,
2007, pp. 175–189.

[2] J. V¨olker, D. Fleischhacker, and H. Stuckenschmidt, “Automatic acqui-
sition of class disjointness,” J. Web Sem., vol. 35, pp. 124–139, 2015.
[3] J. Lehmann, “Dl-learner: Learning concepts in description logics,”
Journal of Machine Learning Research, vol. 10, pp. 2639–2642, 2009.
[4] J. Reynaud, Y. Toussaint, and A. Napoli, “Redescription mining for
learning deﬁnitions and disjointness axioms in linked open data,” in
ICCS, ser. Lecture Notes in Computer Science, vol. 11530. Springer,
2019, pp. 175–189.

[5] G. Rizzo, C. d’Amato, N. Fanizzi, and F. Esposito, “Terminological
cluster trees for disjointness axiom discovery,” in ESWC (1), ser. Lecture
Notes in Computer Science, vol. 10249, 2017, pp. 184–201.

[6] T. H. Nguyen and A. G. B. Tettamanzi, “Learning class disjointness
axioms using grammatical evolution,” in EuroGP, ser. Lecture Notes in
Computer Science, vol. 11451. Springer, 2019, pp. 278–294.

[7] ——, “An evolutionary approach to class disjointness axiom discovery,”

in WI. ACM, 2019, pp. 68–75.

[8] ——, “Using grammar-based genetic programming for mining disjoint-
ness axioms involving complex class expressions,” in ICCS. Springer,
2020.

[9] ——, “Grammatical evolution to mine OWL disjointness axioms involv-

ing complex concept expressions,” in WCCI.

IEEE, 2020.

[10] M. O’Neill and C. Ryan, “Grammatical evolution,” Trans. Evol.
Comp, vol. 5, no. 4, pp. 349–358, Aug. 2001. [Online]. Available:
http://dx.doi.org/10.1109/4235.942529

[11] J. R. Koza, Genetic Programming: On the Programming of Computers
by Means of Natural Selection. Cambridge, MA, USA: MIT Press,
1992.

[12] L. Vanneschi and R. Poli, Genetic Programming — Introduction, Appli-
cations, Theory and Open Issues. Berlin, Heidelberg: Springer Berlin
Heidelberg, 2012.

[13] K. Deb, “Multi-objective optimisation using evolutionary algorithms: An
introduction,” in Multi-objective Evolutionary Optimisation for Product
Design and Manufacturing. Springer, 2011, pp. 3–34.

[14] E. Zitzler, M. Laumanns, and S. Bleuler, “A tutorial on evolutionary
multiobjective optimization,” in Metaheuristics for Multiobjective Opti-
misation, X. Gandibleux, M. Sevaux, K. S¨orensen, and V. T’kindt, Eds.
Berlin, Heidelberg: Springer Berlin Heidelberg, 2004, pp. 3–37.
[15] K. Deb, S. Agrawal, A. Pratap, and T. Meyarivan, “A fast and elitist
multiobjective genetic algorithm: NSGA-II,” IEEE Trans. Evol. Comput.,
vol. 6, no. 2, pp. 182–197, 2002.

[16] L. A. Zadeh, “Fuzzy sets as a basis for a theory of possibility,” Fuzzy

Sets and Systems, vol. 1, pp. 3–28, 1978.

[17] A. G. B. Tettamanzi, C. Faron-Zucker, and F. Gandon, “Possibilistic
testing of OWL axioms against RDF data,” Int. J. Approx. Reasoning,
vol. 91, pp. 114–130, 2017.

