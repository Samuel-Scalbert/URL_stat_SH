Enumerating models of DNF faster: breaking the
dependency on the formula size
Florent Capelli, Yann Strozecki

To cite this version:

Florent Capelli, Yann Strozecki. Enumerating models of DNF faster: breaking the dependency on the
formula size. Discrete Applied Mathematics, 2020, ￿10.1016/j.dam.2020.02.014￿. ￿hal-01891483￿

HAL Id: hal-01891483

https://inria.hal.science/hal-01891483

Submitted on 9 Oct 2018

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Enumerating models of DNF faster: breaking the dependency on
the formula size

Florent Capelli1 and Yann Strozecki2

1Universit´e de Lille, CRIStAL Laboratory, France, ﬂorent.capelli@univ-lille.fr
2Universit´e de Versailles Saint-Quentin-en-Yvelines, DAVID Laboratory, France

October 9, 2018

Abstract

In this article, we study the problem of enumerating the models of DNF formulas. The aim
is to provide enumeration algorithms with a delay that depends polynomially on the size of
each model and not on the size of the formula. We succeed for two subclasses of DNF formulas:
we provide a constant delay algorithm for k-DNF with ﬁxed k by an appropriate amortization
method and we give a polynomial delay algorithm for monotone formulas. We then focus on the
average delay of enumeration algorithms and show that we can bring down the dependency of
the average delay to the square root of the formula size and even to a logarithmic dependency
for monotone formulas.

1

1

Introduction

An enumeration problem is the task of listing a set of elements without redundancies, usually
corresponding to the solutions of a search problem, such as enumerating the spanning trees of
a graph or the satisfying assignments of a formula. One way of measuring the complexity of an
enumeration algorithm is the total time needed to compute all solutions. When the total time
depends both on the input and output, an algorithm is called output sensitive. It is considered
tractable and said to be output polynomial when it can be solved in polynomial time in the size of
the input and the output.

Output sensitivity is relevant when all elements of a set must be generated, for instance to
build a library of interesting objects to be studied by experts, as it is done in biology, chemistry
or network analytics [5, 2, 6]. However, when the output is large with regard to the input, output
polynomiality is not enough to capture tractability. Indeed, if one wants only a good solution or
some statistic on the set of solutions, it can be interesting to generate only a fraction of the solutions.
A good algorithm for this purpose must guarantee that the more time it has, the more solutions it
generates. To measure the eﬃciency of such an algorithm, we need to compute the delay between
two consecutive solutions. A ﬁrst guarantee that we can expect is to have a good average delay
(sometimes referred to as amortized delay), that is, to measure the total time divided by the number
of solutions. There are many enumeration algorithms which are in constant amortized time or CAT,
usually for the generation of combinatorial objects, such as the unrooted trees of a given size [26],
the linear extensions of a partial order [19] or the integers by Gray code [14]. Uno also proposed [25]
a general method to obtain constant amortized time algorithms, which can be applied, for instance,
to ﬁnd the matchings or the spanning trees of a graph.

However, when one wants to process a set in a streaming fashion such as the answers of a
database query, it may be interesting to guarantee the regularity of the delay, usually by bounding
it by a polynomial in the input size. We refer to such algorithms as polynomial delay algorithms.
Many problems admit such algorithms, e.g. enumerate the cycles of a graph [20], the satisfying
assignments of variants of SAT [8] or the spanning trees and connected induced subgraphs of a
graph [3]. They are all based on similar techniques (see [16] for a survey).

For some problems, the size of the input may be much larger than the size of the generated
solutions, which makes polynomial delay an unsatisfactory measure of eﬃciency. In that case,
algorithms whose delay depends on the size of a single solution are naturally more interesting
than polynomial delay or output polynomial algorithms. We say that an algorithm is in strong
polynomial delay when the delay between two consecutive solutions is polynomial in the size of
the last solution. To make this notion robust and more relevant, a precomputation step is allowed
before the enumeration, in time polynomial in the input size, so that the algorithm can read the
whole input and set up useful data structures. Observe that the notion of strong polynomial delay
is also well suited for inﬁnite enumeration where the size of the solutions grows arbitrarily [10].

In this paper, we focus on the notion of strong polynomial delay. While strong polynomial
delay is a very desirable property for an algorithm it is rarely considered, since polynomial delay is
often seen as the be-all end-all answer in enumeration. We feel that understanding the diﬀerence
between polynomial delay and strong polynomial delay is a challenge that complexity of enumeration
must address to be more relevant for practitioners. We are especially interested in ﬁnding such
algorithms for the problem of enumerating the models of DNF formulas. Indeed, one can easily
solve it with delay linear in the size of the formula (see Theorem 4) but it appears that removing
the dependency in the number of terms in the delay is not easy, even when allowing exponential

2

Class
Space
DNF
Polynomial
((cid:63)) DNF
Polynomial
((cid:63)) k-DNF
Polynomial
((cid:63)) Monotone DNF O(n3) (Theorem 14)
Exponential
((cid:63)) Monotone DNF O(log(n) log(nm)) average delay (Theorem 16) Polynomial

Delay
O(size(D)) (Theorem 4)
O(n
2O(k) (Theorem 5)

m) average delay (Theorem 13)

√

Table 1: Overview of the results. In this table, D is a DNF, n its number of models and m its
number of terms. New contributions are annotated with ((cid:63)).

space. DNF formulas have a simple structure as it is easy to ﬁnd a large number of solutions or to
approximate their number [15]. Nevertheless, exactly counting the solutions of a DNF formula is a
canonical #P-complete problem. Enumerating the models of a DNF formulas thus appears to be
a reasonable candidate to separate the notions of strong polynomial delay and polynomial delay.
Surprisingly, we manage to remove the dependency of the delay in the number of terms for k-DNF
and monotone DNF and to improve it for the general case. Our results are summarized in Table 1.
There are few examples of strong polynomial delay in the literature. Constant delay algorithms
naturally fall into this category and a whole line of research is dedicated to design such algorithm
for enumerating models of ﬁrst order queries for restricted classes of structures [21] (see also the
survey [22]). However, while these algorithms are called constant delay because their delay does not
depend on the database size, it often depends more than exponentially on the size of the solutions.
Other examples naturally arise from logic such as the enumeration of assignments of MSO queries
over trees or bounded width graphs [4, 7]. Recently, Amarilli et al. [1] presented an algorithm to
enumerate the solutions of a restricted class of Boolean circuits known as structured d-DNNF used
in knowledge compilation with delay linear in the number of variables and hence independent of the
size of the circuit.

The paper is organized as follows. We ﬁrst introduce basic notions on formulas and enumeration
complexity then present tries and Gray code in Section 2. We show in Sec 3 how to adapt three
classical methods to generate the models of a DNF, the best having a linear delay in the formula size.
In Section 4, we give a backtrack search algorithm, using a good amortization, which is in constant
delay for k-DNF. In Section 5, we give another backtrack search algorithm, whose average delay is
better than linear. Finally, in Section 6, we provide a strong polynomial delay for monotone DNF
formulas but with an exponential memory and we specialize and adapt the algorithm of the previous
section to obtain a logarithmic delay for monotone DNF formulas. Proposition with omitted proofs
due to space restrictions are labeled with ((cid:63)) and a proof is given in the appendix.

2 Deﬁnitions and notations

Terms and DNF-formulas. Let X be a set of variables and let n and be the size of X. We ﬁx
some arbitrary order on X and write X = {x1, . . . , xn}. A literal (cid:96) is either a variable x ∈ X or
the negation of a variable ¬x for some x ∈ X. A term C is a ﬁnite set of literals such that every
two literals in C have a diﬀerent variable. A Disjunctive Normal Form formula, DNF for short,
is a ﬁnite set of terms. Given a literal (cid:96), we denote its underlying variable by var((cid:96)). We extend
this notation to terms by denoting var(C) := (cid:83)
(cid:96)∈C var((cid:96)) for a term C and to DNF by denoting
var(D) := (cid:83)
C∈D var(C) for a DNF D.

3

Given an assignment α : X → {0, 1}, we naturally extend α to literals by deﬁning α(¬x) =
1 − α(x). An assignment α satisﬁes a term C if for every (cid:96) ∈ C, α(C) = 1. A model α is an
assignment that satisﬁes a DNF D, that is, there exists C ∈ D such that α satisﬁes C. We write
α |= D if α is a model of D. It is easy to see that given a term C, there exists a unique assignment
of variables in var(C) satisfying C. We denote this assignment by 1C.

Given a DNF D on variables X, we denote by sat(D) = {α | α |= D} the set of models of D. Let
Y ⊆ X, τ : Y → {0, 1} and σ : X → {0, 1}, we say that σ is compatible with τ , denoted by σ (cid:39) τ ,
if the restriction of σ to Y is equal to τ . We denote by sat(D, τ ) = {α | α |= D, σ (cid:39) τ } the set of
models of D compatible with τ . We also denote by D[τ ] the DNF deﬁned as follows: we remove
every term C from D such that there exists a literal (cid:96) ∈ C such that τ ((cid:96)) = 0. For the remaining
terms, we remove every literal whose variable is in Y . Observe that since we consider DNF to be sets
of terms, by deﬁnition, D[τ ] has no duplicated terms. It is clear that: sat(D, τ ) = {τ ∪ α | α |= D[τ ]}.
The size of a DNF D is denoted by (cid:107)D(cid:107) and is equal to (cid:80)

C∈D |C|.

Enumeration complexity. Let Σ be a ﬁnite alphabet and Σ∗ be the set of ﬁnite words built on
Σ. Let A ⊆ Σ∗ × Σ∗ be a binary predicate, we write A(x) for the set of y such that A(x, y) holds.
The enumeration problem Enum·A is the function which associates A(x) to x.

The computational model is the random access machine model (RAM) with addition, subtraction
and multiplication as its basic arithmetic operations and an operation Output(i, j) which outputs
the concatenation of the values of registers Ri, Ri+1, . . . , Rj. We assume that all operations are
in constant time except the arithmetic instructions which are in time linear in the size of their
inputs. While this is arguably not a real-life scenario, this allows us to formally write algorithms
with constant time delay while it is theoretically impossible if the time needed to write the output
is taken into account. A RAM machine solves Enum·A if, on every input x ∈ Σ∗, it produces a
sequence y1, . . . , yn such that A(x) = {y1, . . . , yn} and for all i (cid:54)= j, yi (cid:54)= yj. The space used by
the machine at a given step is the sum of the number of bits required to store the integers in its
registers.

The delay of a RAM machine which outputs the sequence {y1, . . . , yn} is the maximum over
all i ≤ n of the time the machine uses between the generation of yi and yi+1. Note that we allow
a precomputation phase before the machine starts to enumerate solutions, which can be in time
polynomial in the size of the input.

Trie. A trie is a data structure used to represent a set of words on an alphabet M which supports
eﬃcient insertion and deletion. We refer the reader to [12, 14] for more details. We use them to
either store a formula, that is the sets of its terms, or to represent a set of assignments of a formula.
The trie is a M -ary tree, each of its inner nodes is labeled by a letter of the alphabet. A leaf
represents a word: the sequence of labels traversed when going from the root to the leaf. The trie
represents the set of words represented by its leaves. The children of a node are given by a linked
list.

A model α of the DNF is represented by the sequence of its values: α(x1)α(x2) . . . α(xn). The
trie we use to store these models are binary trees, since the labels are in {0, 1}. We represent a
term by the sequence in ascending orders of its literals, with for all i, xi < ¯xi+1 < xi+1. The list of
children of a node in the trie is maintained in this order.

We need to search, insert and suppress elements in a trie. Those three operations are in O(n)

for the two tries we have deﬁned, where n is the number of variables.

4

Gray Code. Gray codes are an eﬃcient way to enumerate the integers between 0 and 2n − 1
written in binary or equivalently the subsets of a set of size n. They enjoy two important properties:
the Hamming distance of two elements in the Gray enumeration order is one and each new element
is produced in constant time using only additional O(log(n)2) space (see [13]). In other words, this
enumeration algorithm has constant delay. We can generate all models of a term in constant delay,
using Gray code and an additional array which contains the indexes of the free variables of the term.

Proposition 1 (((cid:63))). The models of a term C on variables X can be enumerated in constant delay.

3 Classical enumeration algorithms

In this section we present three generic enumeration methods applied to the generation of the models
of a DNF formula. The best one has a linear delay in the size of the instance, and we study in later
sections several restrictions to obtain a delay polynomial in the size of a solution.

3.1 Union of terms

The ﬁrst two methods are based on the fact that the models of a DNF formula are the union of the
models of its terms. The only problem is to avoid repetitions of models. We ﬁrst use a method
to enumerate the union of sets of elements which preserves polynomial delay (see [23]). It relies
on a priority rule between the sets to avoid repetitions, as recalled in the proof of the following
proposition.

Proposition 2 (((cid:63)) Adapted from proposition 2.38 and 2.40 in [23]). The models of a DNF formula
D with m terms can be enumerated with delay O(m(cid:107)D(cid:107)).

By improving the way we test whether a model of a term is the model of any term of larger
index, we can drop the delay to O(m2). In fact, by generating the solutions of each term in the same
order, we can avoid completely the redundancy test and get a better delay. The following algorithm
merges several ordered arrays which are generated dynamically by enumeration procedures.

Proposition 3 (((cid:63)) Adapted from proposition 2.41 in [23]). The models of a DNF formula D with
m terms and n variables can be enumerated with delay O(mn).

The average delay of the two previous algorithms is lower than their delays. Let r be the average
number of times a solution is produced during the algorithm, we can replace m by r in the average
delay of the previous algorithm. It is possible to prove that r is smaller than m by studying how
terms share models, but the complexity gains are very small and we give an algorithm with a much
better average delay in Section 5.

3.2 Flashlight method

We present a classical enumeration method called the Backtrack Search or sometimes the Flashlight
Method used in many previous articles [20, 24] in particular to solve auto-reducible problems. We
describe the method in the context of the generation of the models of D a DNF formula.

We deﬁne a tree TD whose nodes are the assignments τ over variables {x1, . . . xk} such that
there is a model σ of D which is compatible with τ . The children of a node labeled by τ are the
partial assignments τ (cid:48) deﬁned over {x1, . . . xk+1} which are compatible with τ .

5

The leaves of TD are the models we want to generate, therefore a depth ﬁrst traversal visits all
leaves and thus outputs all solutions. Since a path from the root of the tree is of size n, it is enough
to be able to ﬁnd the children of a node in polynomial time to obtain a polynomial delay. Hence
the Flashlight Method has a polynomial delay if and only if the following extension problem is in P:
given τ over {x1, . . . xk} is there σ a model of D compatible with τ ?

The extension problem for a DNF is very simple to solve: compute the formula D[τ ] and decide
whether it is satisﬁable in time O((cid:107)D(cid:107)). This yields an enumeration algorithm with delay O(n(cid:107)D(cid:107)).
The delay can be improved by using the fact that we solve the extension problem several times on
very similar instance as it has been done for other problems [18, 17] such as the enumeration of the
models of a monotone CNF.

Proposition 4. The models of a DNF formula D can be enumerated with delay O((cid:107)D(cid:107)).

Proof. We use the previous algorithm which does a depth ﬁrst search in TD. When it visits the
node τ , we need to decide whether D[τ ] is satisﬁable which is equivalent to testing whether it has a
non falsiﬁed term. To speed-up the ﬂashlight search, we use a data structure to decide quickly this
problem and we need to guarantee that it can be updated fast enough when the tree is traversed.
For each term C, we store an integer fC which represents how many literals of the term are
falsiﬁed by the current partial assignment. A term C is valid when fC = 0. For each literal l, we
store the list of terms which contain the literal. We also store an integer vc for valid terms, which
counts how many terms are not falsiﬁed by the current partial assignment.

At the beginning of the algorithm, all fC are set to 0 and vc = m. Then visiting a child τ (cid:48)
of τ corresponds to choosing the value of some variable xk. If xk is set to 0 then for each term
C containing xk, fC is incremented. The number of terms such that fC is changed from 0 to 1 is
subtracted to vc. If xk is set to 1, then the same is done for ¯xk. The fact that D[τ (cid:48)] is satisﬁable
is equivalent to vc > 0. Remark that going up the tree when backtracking works exactly as going
down, but the variables fc are decremented and vc is incremented instead.

As a consequence, the complexity of the algorithm over a path in the tree is O((cid:107)D(cid:107)) since for
each term C, the variable fC will be modiﬁed |C| times. When the algorithm goes down the tree it
may ﬁrst set xk to 0 and fails, but then it sets xk to 1 and goes down. Hence the cost of going down
to a leaf is at most twice the cost of following the path to the leaf. Since between two outputted
solutions, the algorithm follows one path up and one down, the delay is in O((cid:107)D(cid:107)).

This last algorithm has a delay linear in the size of the formula, however the size of the formula
can be extremely large with regards to the size of a model. In the next sections we will try reduce
or eliminate the dependency of the delay in the size of the input either for particular DNF formulas
or by relaxing the notion of delay.

4 Enumerating models of k-DNF

A term C is a k-term if and only if |C| ≤ k. A DNF is a k-DNF if all its terms are k-terms. In this
section, we present an algorithm to enumerate the models of a k-DNF with a 2O(k) delay. The idea
is to select a k-term and use its 2n−k models to amortize more costly operations. More precisely, we
prove the following:

Theorem 5. The models of a k-DNF with n variables can be enumerated with precomputation in
O(n) and O(k225k) delay.

6

To explain our algorithm, we need ﬁrst to introduce notations. Let H(p) = −p log(p) − (1 −

p) log(1 − p) be the binary entropy. From the following classical inequality (see [11]):

k
(cid:88)

i=0

(cid:19)

(cid:18)n
i

≤ 2nH(k/n),

we get for k ≤ n/2:

Lemma 6. The number of k-terms on n variables is at most 2nH(k/n)+k.

Let D be a DNF-formula on variables X. Assume wlog that X is ordered with <. Given a term
C ∈ D, we denote by 1C : var(C) → {0, 1} the only model of C, that is, for every (cid:96) ∈ C, 1C(x) = 1
if (cid:96) = x and 1C(x) = 0 if (cid:96) = ¬x.

If y ∈ var(C), we denote by 0y

C : {z ∈ var(C) | z ≤ y} → {0, 1} the assignment deﬁned by

C(z) = 1C(z) for z < y and z ∈ var(C) and 0y
0y

C(y) = 1 − 1C(y).

For example, if C = x1 ∧ x2 ∧ ¬x3, we have 1C = {x1 (cid:55)→ 1, x2 (cid:55)→ 1, x3 (cid:55)→ 0} and 0x1
C = {x1 (cid:55)→ 1, x2 (cid:55)→ 1, x3 (cid:55)→ 1}.

C = {x1 (cid:55)→ 1, x2 (cid:55)→ 0} and 0x3
0x2

These assignments naturally induce a partitioning of the model of a DNF:

C = {x1 (cid:55)→ 0},

Lemma 7. Given a DNF D and a term C ∈ D, we have:

sat(D) = sat(D, 1C) (cid:93)

(cid:93)

sat(D, 0y

C).

y∈var(C)

Proof. The right-to-left inclusion is clear as sat(D, τ ) ⊆ sat(D) for any τ . Moreover, these unions
are clearly disjoint since for every y, z ∈ var(C), y < z, we have 0z
C(y).
For the left-to-right inclusion, let τ ∈ sat(D). If τ (cid:39) 1C, then τ ∈ sat(D, 1C). Otherwise, let y

C(y) and 1C(y) (cid:54)= 0y

C(y) (cid:54)= 0y

be the smallest variable of var(C) such that τ (y) (cid:54)= 1C(y). Then we have τ (cid:39) 0y
C.

Proof (of Theorem 5). Given a k-DNF D on variables X, we use Lemma 7 to enumerate sat(D).
We denote by X = var(D), N = |X| and M = |D|.

We start by picking a k-term C ∈ D. It is easy to see that for every τ : X \ var(C) → {0, 1}, we
have τ ∪ 1C |= D. Thus, enumerating sat(D, 1C) can be done very eﬃciently with a O(1) delay by
simply enumerating 2X\var(C) using a Gray code. Observe that the precomputation time boils down
to choosing a term and outputting its ﬁrst solution which can obviously be done in time O(n) as
stated in the theorem.

Between the output of two solutions of sat(D, 1C), we spend some time to precompute D[0y
C]
for every y ∈ var(C). Since |var(C)| ≤ k, we have to compute at most k such DNF. Moreover, to
compute each one of them, we have to inspect every term of D and every variable of these terms.
Since each term has at most k variables, we need O(kM ) steps to precompute all terms in D[0y
C]
for one y ∈ var(C). We then remove all copies but one of the same terms. This can be done in
time O(kM 2) by comparing the terms pairwise. In the end, we need O(k2M 2) steps to precompute
D[0y
C] for every y ∈ var(C). Let A be a constant such that this precomputation can be done in time
A · k2M 2 steps at most.

Assume that between the output of two solutions of sat(D, 1C), we allow dA steps for this
precomputation (the value of d will be ﬁxed later depending on our needs). Since |sat(D, 1C)| ≥ 2N −k,

7

this gives us a total amount of 2N −kdA steps for this precomputation. Thus, if 2N −kdA > Ak2M 2,
that is, if

2N −kd > k2M 2

(1)

we have enough time to compute D[0y
C] for every y ∈ var(C). If this is the case, then we do the
precomputation, ﬁnish the enumeration of sat(D, 1C) and then recursively start the enumeration of
0y
C × D[0y
C] has of course decreased but
we can still allow for dA steps of extra computation between the output of two solutions.

C] for each y ∈ var(C). The number n of variables of D[0y

It is clear that as long as (1) is true, we can output solutions of D with delay dA. We may
however have a problem if, at some point in the recursion, the DNF D(cid:48) we are using to compute
solutions of D may have too few variables making (1) false. We are going to pick d suﬃciently large
so it never happens.

Since we only consider k-DNF, we know by Lemma 6 that at each step of the recursion with n
unassigned variables, the number m of terms veriﬁes m ≤ M0 := 2nH(k/n)+k. Our goal is thus to
ﬁnd d such that for every n ≥ 2k:

2n−kd ≥ k2M 2
0

By rearranging the terms so that k is in factor in the exponent and denoting x = k/n, we conclude
that if the following holds then (1) is true when k ≤ n/2:

d ≥ k22k((2H(x)−1)/x+3)

(2)

It is easy to compute the maximum of the function (2H(x) − 1)/x + 3 over [0, 1/2]. We obtain
a bound of 5 at x = 1/2. Hence for all k ≤ n/2, if d ≥ k225k then (1) is true at each recursive
call. When n < 2k, we enumerate the models using the algorithm of Theorem 4. It gives a delay of
(cid:107)D(cid:107) ≤ k23k since by applying Lemma 6 for n = 2k, we have that that the number of k-terms with
2k variables is at most 22kH(1/2)+k = 23k. Thus, a k-DNF with less than 2k variables has size at
most k23k.

The O(k225k) delay of the previous algorithm could be improved to O(k223k) by using a more
clever algorithm to detect duplicated terms when computing D[0y
C]. This operation can easily be
done in time O(k2M log(M )) by sorting the terms before eliminating duplicates and even in time
O(k2M ) by using a trie with relevant pointers allowing to test if a term is already in the trie in
time O(k). Both solutions would make the presentation of the proof heavier so we chose to present
this simpliﬁed version since the delay is also 2O(k).

Theorem 5 gives an algorithm to enumerate the models of a k-DNF with delay d = 2O(k) and
O(n) precomputation. A pseudo code for this algorithm is given in the appendix (Algorithm 1). It
has constant delay for constant k and it is in strong polynomial delay (polynomial in n the size of
a solution) for terms of size O(log(n)). We conjecture however that the models of a general DNF
cannot be enumerated with strong polynomial delay.

We can use Algorithm 1 to signiﬁcantly improve a result on the enumeration of models of ﬁrst
order formula with free second order variables. In [9], Theorem 10, it is proved that the models
of a Σ1 formula (a single block of existential quantiﬁers followed by a quantiﬁer free formula)
with free second order variables can be enumerated in polynomial delay using a method similar to
Proposition 2. Moreover, this problem is shown to be equivalent to the enumeration of models of
a k-DNF. As a corollary of Theorem 5, the enumeration of models of a Σ1 formula can be done
in constant delay. It is very surprising since it is the same complexity as for Σ0 (quantiﬁer free
formulas), the ﬁrst level of the hierarchy.

8

5 Average delay of enumerating the models of DNF

In this section, we analyze the average delay of the Flashlight method, using appropriate data
structures, to show it is better than the delay. The idea is to amortize the cost of maintaining
the formula D[τ ] during the traversal of the tree over all models of D[τ ] in the spirit of [25]. To
do that we exhibit a relation between the number of models of a DNF and its number of terms.
For any class of DNF for which it is possible to guarantee, for all partial assignments τ , that the
number of models of D[τ ] is large enough with regard to |D[τ ]|, we obtain a good average delay.
We then improve the delay of the Flashlight method by using a diﬀerent branching (in the spirit of
Algorithm 1) which guarantees that the number of terms decreases suﬃciently but not too much in
some branch which allows us to amortize the cost of branching.

The following lemma shows that DNF whose terms share a model have many models. It applies
directly to any monotone formula, since the all one assignment is always a model of a (positive)
monotone term.

Lemma 8. A DNF formula D with m distinct terms which have a common model has at least m
models.

Proof. Let α be a model of the m terms of the DNF formula D and x be a variable of D. We
claim that x appears only negatively or positively in D. Indeed, assume w.l.o.g that that α(x) = 1
and that x ∈ C1 and ¬x ∈ C2. Thus α (cid:54)|= C2 which contradicts the deﬁnition of α. We construct
a monotone DNF D(cid:48) by replacing every variable that appears only negatively in D by positive
occurrences. There is an obvious one-to-one correspondence between the models of D(cid:48) and the
models of D. Now, for C ∈ D(cid:48), let mC be the model of C deﬁned as mC(x) = 1 if and only if
x ∈ var(C). Since D(cid:48) is monotone, it is clear that mC = mC(cid:48) if and only if C = C(cid:48), which gives m
distinct models for D(cid:48) and thus for D.

Using the previous lemma, we prove that a DNF has at most a number of terms which is

quadratic in its number of models.

Lemma 9. A DNF formula with m non empty distinct terms has at least m1/2 models.

Proof. Let α be a model of the DNF D, we denote by rα the number of terms which are compatible
with α:
It corresponds to the number of redundancies of α, that is the
number of terms which has it as model (and the number times it is generated in the algorithm of
Proposition 3).

|{C |= α | C ∈ D}|.

Now, let us denote by A the average of rα over all models. By deﬁnition, we have

|sat(D)| =

(cid:80)

C∈D |sat(C)|
A

.

Since A is an average, there is an α such that rα ≥ A. It means that at least A distinct terms
are compatible with α and then by Lemma 8 these terms have at least A distinct models. Hence we
have |sat(D)| ≥ A. Now, multiplying both equations and observing the fact that |sat(C)| ≥ 1 for
every C ∈ D, we obtain |sat(D)|2 ≥ (cid:80)
C∈D |sat(C)| ≥ m.

In the previous proof, the inequalities are not tight and we may certainly improve the result. In
particular, we can avoid to bound (cid:80)
C∈D |sat(C)| by m. We then get a lower bound on the number
of models of m1/2+c/ log(n) for some constant c. It improves the delay of the next algorithm only for

9

superpolynomial m and require some additional computations, hence we chose to state Lemma 9
with the simpler

m bound.

√

The quality of the algorithms presented in this section is directly connected to this relation
between the number of terms and the number of solutions of a DNF. Any improvement would have
direct consequences on the complexity of enumerating the models of a DNF.

Question 10. What is the best k such that we can guarantee that a DNF with m terms has at
least mk solutions? We are not aware of any results concerning this fact. We only know that
1/2 ≤ k ≤ log3(2). The lower bound is Lemma 9 and the upper bound easily follows from the DNF
having all terms of size at most n on n variables has 2n models and 3n terms.

To improve the average delay of the ﬂashlight method, we need to use an adapted data structure.
In particular we need that, when considering some inner node D[τ ] of TD, the cost to process it is
in O(|D[τ ]|) and not in O(m). In particular, we need to guarantee that there are no redundancy of
terms in the structure representing D[τ ] and that we can maintain it eﬃciently, that is why we use
a trie.
Theorem 11. The models of a DNF can be enumerated with average delay O(n2√
space.

m) and polynomial

Proof. We maintain the formula D[τ ] when we traverse TD using the trie containing its terms as
explained in Section 2. On a node τ we can decide quickly whether D[τ ] has a model and we can
maintain D[τ ] eﬃciently without redundancy of terms. In the ﬂashlight search, we will ﬁx the
variables following their order x1, . . . , xk. Hence, visiting a child τ (cid:48) of τ corresponds to setting the
value of some variable xk with all variables xi with i < k already ﬁxed. If we set xk to 0 then we
need to remove the subtree under the root of the trie, with ﬁrst node xk. Then we remove the
subtree under the root of the trie, with ﬁrst node ¯xk, and insert back all elements in this subtree
into the trie without the ﬁrst node ¯xk. The complexity of the latter is in O(|D[τ ]|n) since the
number of terms is bounded by |D[τ ]| (no term appear several times in the trie). To set xk to 1,
we do the same operation where we exchange the roles of xk and ¯xk. To be able to go up in the
tree during the ﬂashlight search, we must restore the trie to its previous state. To do that in time
O(|D[τ ]|n), it is enough to store the list of elements which have been removed or added in the trie
when going down the same edge and to reverse the operations. The additional memory used during
the algorithm is bounded by O(mn2).

We now compute the average delay, that is the total time of the algorithm divided by the number
of outputted models. To do that we distribute the time spent on each inner node D[τ ] to the models
in the leaves of the subtree rooted at D[τ ]. As we have explained, the time spent on the node D[τ ]
(to do the branching on some variable xk) is in O(|D[τ ]|n). By Lemma 9, we have that D[τ ] has at
least (cid:112)|D[τ ]| models. The time spent in D[τ ] is distributed uniformly over all leaves of the tree
rooted at D[τ ]. Hence each leaf receive at most n(cid:112)|D[τ ]| = n|D[τ ]|/(cid:112)|D[τ ]|.
√
A leaf receives a cost of at most n
average delay) is bounded by O(n2√

m for each of its n ancestors, hence the time per leaf (or the

m).

We now improve the way we choose the next variable on which we branch in order to improve
the delay. The idea is to branch on variables so that the recursion tree kept as balanced as possible.
We use the following lemma:

Lemma 12 (((cid:63))). Let D be a DNF formula with m terms. Let m0 and m1 be the number of terms
of D[x → 0] and D[x → 1] respectively. Then m0 + m1 ≥ m/2.

10

Theorem 13. The models of a DNF can be enumerated with average delay O(n
space.

√

m) and polynomial

Proof. Instead of branching on a variable x1 in the ﬂashlight search, the branching will have the
structure of a potentially large comb, similar to the one used in Algorithm 1. We deﬁne a sequence of
partial assignments αi, α(cid:48)
i are deﬁned over the variables
{x1, . . . , xi} and they are compatible with αi. The assignment α0 is the empty assignment, αi is the
extension of αi−1 by xi → (cid:15)(xi) and α(cid:48)
i is the extension by xi → 1 − (cid:15)(xi). We write mi = |D[αi]|
and m(cid:48)
i] respectively.
Let us now deﬁne the assignment (cid:15), given D[αi−1], (cid:15)(xi) is chosen to maximize mi.

i]|, these numbers are the number of distinct terms in D[αi] and D[α(cid:48)

i with 0 ≤ i ≤ n. The assignments αi and α(cid:48)

i = |D[α(cid:48)

By Lemma 12, we have that mi ≥ mi−1/4 that is the number of terms is divided by at most 4

at each step. Since m0 = m and mn ≤ 1, then there is a i0 such that mi0 ∈ [m/8, m/2].

We use the same method as in Theorem 11 to maintain the trie representing D[τ ]. During the
successive construction of D[αi] and D[α(cid:48)
i], each term of D will be removed or inserted twice at
most in the trie. Hence the total cost of this branching and of the computation of the mi and m(cid:48)
i is
in O(mn), that is as fast as a binary branching. We assign this cost to the solutions in the branch
αi0. By construction, D[αi0] has more than m/4 terms, hence it has by Lemma 9 at least (cid:112)m/8
models. Therefore the cost charged to the leaves is n

m.

√

Now let us analyze how much a leaf is charged. Remark that in the path from the root to the a
leaf, not all nodes charge the leaf. By construction the nodes which charge the leaf have less than
half the terms of the previous node which has charged the leaf. Hence the complexity charged to a
node is bounded by (cid:80)
i 1/2i/2 is bounded by a constant, the
cost of a leaf and thus the average delay is O(n

i 1/2i/2. Since (cid:80)
m).

i n(cid:112)m/2i = n

m (cid:80)

√

√

6 Enumerating models of monotone DNF

When the underlying formula is monotone, that is it does not contain any negated literal, we can
enumerate the models with a delay polynomial in the number of variables only. However, our current
techniques need an exponential memory to work.

Theorem 14. There is an algorithm that given a monotone DNF with n variables and m terms,
enumerate the models of D with preprocessing O(nm2) and delay O(n3). The space needed for this
algorithm is linear in the number of solutions of D.

Proof. We start by removing from D every term C(cid:48) such that there exists C ∈ D with C ⊆ C(cid:48).
Observe that it does not change the models of C since C(cid:48) ⇒ C. This preprocessing phase takes
O(nm2) since comparing two terms may be done in time O(n). Let D(cid:48) be the resulting minimized
monotone DNF.

The algorithm then work as follows: arbitrarily order the terms of D(cid:48) = {C1, . . . , Cp} and its
variables X = {x1, . . . , xn}. We initialize a trie T that will contain the solutions that we have
already enumerated, that is, in the following algorithm, each time we output a solution, we store it
in T , so we can check in time O(n) if a solution has already been enumerated.

We now enumerate the solutions as follows: we start by enumerating all solutions of C1. Then,
i = C1 ∨ · · · ∨ Ci, we enumerate
i until i = p. Once we are done, we have, by

we proceed by induction: once we have enumerated all solutions of D(cid:48)
all solutions of Ci+1 that are not solutions of D(cid:48)
induction, enumerated all models of D.

11

We claim that we can do this with delay O(n3) using a classical reverse search method. Let
Y = (y1, . . . , ym) be the variables that are not in var(Ci), ordered following the natural order we
have on X. The solutions of Ci are in one-to-one correspondence with 2Y as follows: given S ⊆ Y ,
we have a solution mS deﬁned as mS(x) = 1 if x ∈ var(Ci) ∪ S and m(x) = 0 otherwise. We explore
the solution of Ci by following a tree A whose nodes are labeled with mS for every S ⊆ Y . The
root of the tree is label-led by m∅ and for every S, the unique predecessor of node mS is mS(cid:48) with
S(cid:48) = S \ max(S). In other words, given S, the successors of mS are mS∪{xk} for k > max(S).

We enumerate the solution by following the structure of A. We start from the root of A, that
is, we enumerate m∅. We claim that m∅ has not yet been enumerated. Indeed, assume toward a
contradiction that m∅ |= Cj for j < i. Then since D(cid:48) is monotone, it means that Cj ⊆ Ci which is
absurd since D(cid:48) is minimized. Thus, the ﬁrst model we enumerate is guaranteed to be fresh.

Now we follow the structure of A by depth ﬁrst search. When we visit a node of A label-led
with mS, we start by checking in the trie if mS has already been enumerated. It can be done in
O(n). If mS has not been enumerated, then we output it and keep on going down in the tree A.
If mS has been enumerated then we can discard the whole subtree of A rooted in mS. Indeed, by
deﬁnition, every solution mS(cid:48) in this subtree veriﬁes S(cid:48) ⊇ S. Thus, if mS has been enumerated then
mS |= D(cid:48)

i−1, so mS(cid:48) has already been enumerated.

i−1 is monotone, mS(cid:48) |= D(cid:48)

i−1 and since D(cid:48)

Thus, if mS has already been enumerated, we backtrack in the tree to the next node in A that
has not yet been explored and that is not in the discarded subtree. This can be done in O(1) if we
maintain in each visited node a pointer to the ﬁrst ancestor that has an unexplored child.

We claim that we will visit at most n2 nodes of A before ﬁnding a new solution or realizing
that we have enumerated all solutions of D(cid:48)
i and should proceed with Ci+1. Indeed, by the previous
argument, we only have to check the maximal unexplored nodes of A since if a solution has already
been enumerated, so have all its descendants. Now, each node of A has at most n children and A
is of depth n. Hence, during the depth-ﬁrst search, we will have at most n2 such maximal nodes
(at most n per level). Since checking if a solution is already in the trie can be done in O(n), our
algorithm will have delay at most O(n3).

By using a better data structure to store the solutions and another organization of the models of
a term we should bring the delay down to O(n2) or better, but we leave that for further researchs.
Moreover, observe that, using the reduction in the proof of Lemma 8 to the monotone case, the
algorithm described in Theorem 14 also works if every variable appears only positively or negatively
in all terms of the formula.

We now consider algorithms with a good average delay for enumerating the models of a monotone
DNF formula. This allows to obtain a better delay that the previous theorem, while only using a
polynomial space. First, recall that monotone DNF formulas have at least as many models as terms
because of Lemma 8. Hence, using the algorithm of Theorem 13 on a monotone formula, we obtain
the following theorem.

Theorem 15. The models of a monotone DNF can be enumerated with average delay O(n) and
polynomial space.

To improve the bound on the average delay using a similar algorithm, we should either guarantee
a better relationship between the number of terms and solution or we should reduce the complexity
of maintaining the trie during the algorithm. Note that the formula with all positive terms has 2n
models but also 2n terms. If we further assume that no term are redundant, that is there are no
C1, C2 such that C1 ⊆ C2, then the formula with all terms of size n − 1 has n + 1 models and n

12

terms. Even when m is large, the relationship is almost linear: the formula with all terms of size
n/2 has 2n/2 models and O(2n/
n) terms. Hence, to improve the average delay, it seems hard to
rely on a better bound on the number of solutions. However, the cost to deal with the trie can be
reduced, as long as m is not too large as shown in the next theorem.

√

Theorem 16. The models of a monotone DNF can be enumerated with average delay O(log(n)(log(m)+
log(n)) and polynomial space.

Proof. First remark that when a term contains n − k variables, then it has 2k models. Hence, in
the algorithm of Theorem 13, when we compute the cost distributed over all solutions of D[τ ], we
can make the following adjustment. We consider two cases. First say that D[τ ] has nτ variables
and assume there is a term with nτ − k variables such that k > log(|D[τ ]|) + 2 log(n). Then D[τ ]
has at least 2k models which is larger than |D[τ ]|n2. As a consequence, the complexity which is
charged to the leaves is only 1/n and the total cost charged to a leaf by branching steps of this king
is bounded by 1.

Now assume that for some partial assignment τ , all terms in D[τ ] contain more than nτ − k
literals, with k = log(|D[τ ]|) + 2 log(n). Then we change the encoding of the formula: each term of
D is represented by its complementary. Since the formula is monotone, we need only to store

The complementary terms are stored in a trie where the children of a node are organized in an
AVL tree instead of an ordered list. All operation can be done on this trie in time O(log(n) ∗ k),
where k is the size of the object to insert. The algorithm works as the one in Theorem 13 on this
new data structure with the following diﬀerence in branching. When xi is set to 1, we remove the
subtree under the roof with ﬁrst node xi and add back all elements without xi. When xi is set to 0,
we keep only the subtree under the roof with ﬁrst node xi and remove the rest.

The cost of a step is now bounded by O(|D[τ ]|k log(n)) and the cost charged to the leaf is

bounded by k log(n), that is by (log(m) + 2 log(n)) log(n) which proves the proposition.

A better data structure can be used in the previous theorem: a trie where the children of a node
are stored in an array of size n. Then the operations are in time O(k) if we accept that we have an
arbitrary supply of initialized memory. The average delay then drop to O(log(n) + log(m)) and
we conjecture that there is a good data structure allowing such delay without needing initialized
memory.

The result on monotone DNFs can easily be transferred to a problem studied in [17]: the
generation of all unions of given subsets. An instance {s1, . . . , sm} is a set of m subsets of [1, n] and
we want to generate all distinct unions of these si. The delay of the algorithm in [17] is O(nm),
using a ﬂashlight search algorithm similar to the algorithm of Theorem 4. Among the enumeration
problems captured by the framework of saturation by set operators [17] it is the only one not proved
to be in strong polynomial delay and it is also proved to be at least as hard to enumerate as the
models of a monotone DNF.

If there are m distinct subsets in the instance, these subsets are also solutions then we have
an equivalent of Lemma 8. Moreover, if we restrict a set of subsets by ﬁxing an element, we have
an inequality similar to Lemma 12. Hence we obtain an algorithm to enumerate union of sets
with an average delay O(n) using the branching scheme of Theorem 13. However, the algorithm of
Theorem 14 do not seem usable for generating the union of sets, leaving the question of obtaining
an algorithm with strong polynomial delay open.

13

References

[1] Antoine Amarilli, Pierre Bourhis, Louis Jachiet, and Stefan Mengel. A circuit-based approach
to eﬃcient enumeration. In 44th International Colloquium on Automata, Languages, and
Programming, ICALP 2017, July 10-14, 2017, Warsaw, Poland, pages 111:1–111:15, 2017.

[2] Ricardo Andrade, Martin Wannagat, Cecilia C Klein, Vicente Acu˜na, Alberto Marchetti-
Spaccamela, Paulo V Milreu, Leen Stougie, and Marie-France Sagot. Enumeration of minimal
stoichiometric precursor sets in metabolic networks. Algorithms for Molecular Biology, 11(1):25,
2016.

[3] D. Avis and K. Fukuda. Reverse search for enumeration. Discrete Applied Mathematics,

65(1):21–46, 1996.

[4] Guillaume Bagan. Mso queries on tree decomposable structures are computable with linear
delay. In International Workshop on Computer Science Logic, pages 167–181. Springer, 2006.

[5] Dominique Barth, Olivier David, Franck Quessette, Vincent Reinhard, Yann Strozecki, and
In International

Sandrine Vial. Eﬃcient generation of stable planar cages for chemistry.
Symposium on Experimental Algorithms, pages 235–246. Springer, 2015.

[6] Kateˇrina B¨ohmov´a, Luca H¨aﬂiger, Mat´uˇs Mihal´ak, Tobias Pr¨oger, Gustavo Sacomoto, and
Marie-France Sagot. Computing and listing st-paths in public transportation networks. Theory
of Computing Systems, 62(3):600–621, 2018.

[7] Bruno Courcelle. Linear delay enumeration and monadic second-order logic. Discrete Applied

Mathematics, 157(12):2675–2700, 2009.

[8] Nadia Creignou and Jean-Jacques H´ebrard. On generating all solutions of generalized satisﬁa-

bility problems. Informatique th´eorique et applications, 31(6):499–511, 1997.

[9] Arnaud Durand and Yann Strozecki. Enumeration complexity of logical query problems with
second-order variables. In LIPIcs-Leibniz International Proceedings in Informatics, volume 12.
Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik, 2011.

[10] Christophe Costa Florˆencio, Jonny Daenen, Jan Ramon, Jan Van den Bussche, and Dries
Van Dyck. Naive inﬁnite enumeration of context-free languages in incremental polynomial time.
J. UCS, 21(7):891–911, 2015.

[11] J¨org Flum and Martin Grohe. Parameterized complexity theory. Springer Science & Business

Media, 2006.

[12] Edward Fredkin. Trie memory. Communications of the ACM, 3(9):490–499, 1960.

[13] Donald E Knuth. Combinatorial algorithms, part 1, volume 4a of the art of computer

programming, 2011.

[14] Donald Ervin Knuth. The art of computer programming, volume 3. Pearson Education, 1997.

[15] Michael Luby and Boban Veliˇckovi´c. On deterministic approximation of dnf. Algorithmica,

16(4-5):415–433, 1996.

14

[16] Arnaud Mary. ´Enum´eration des Dominants Minimaux d’un graphe. PhD thesis, Universit´e

Blaise Pascal, 2013.

[17] Arnaud Mary and Yann Strozecki. Eﬃcient enumeration of solutions produced by closure

operations. In 33rd Symposium on Theoretical Aspects of Computer Science, 2016.

[18] Keisuke Murakami and Takeaki Uno. Eﬃcient algorithms for dualizing large-scale hypergraphs.

Discrete Applied Mathematics, 170:83–94, 2014.

[19] Gara Pruesse and Frank Ruskey. Generating linear extensions fast. SIAM Journal on Computing,

23(2):373–386, 1994.

[20] RC Read and RE Tarjan. Bounds on backtrack algorithms for listing cycles, paths, and

spanning trees. Networks, 5(3):237–252, 1975.

[21] Nicole Schweikardt, Luc Segouﬁn, and Alexandre Vigny. Enumeration for fo queries over
nowhere dense graphs. In Proceedings of the 37th ACM SIGMOD-SIGACT-SIGAI Symposium
on Principles of Database Systems, SIGMOD/PODS ’18, pages 151–163, New York, NY, USA,
2018. ACM. URL: http://doi.acm.org/10.1145/3196959.3196971, doi:10.1145/3196959.
3196971.

[22] Luc Segouﬁn. Enumerating with constant delay the answers to a query. In Proceedings of the

16th International Conference on Database Theory, pages 10–20. ACM, 2013.

[23] Yann Strozecki. Enumeration complexity and matroid decomposition. PhD thesis, Paris 7, 2010.

[24] Yann Strozecki. On enumerating monomials and other combinatorial structures by polynomial

interpolation. Theory of Computing Systems, 53(4):532–568, 2013.

[25] Takeaki Uno. Constant time enumeration by amortization. In Workshop on Algorithms and

Data Structures, pages 593–605. Springer, 2015.

[26] Robert Alan Wright, Bruce Richmond, Andrew Odlyzko, and Brendan D McKay. Constant

time generation of free trees. SIAM Journal on Computing, 15(2):540–548, 1986.

A Proof of Proposition 1

Proof. The models of C on variables X are exactly the assignments of the form 1C ∪ τ for any
τ : X \ var(C) → {0, 1}. Enumerating the models of C intuitively boils down to enumerating all
assignments on variables X \ var(C). We use a Gray code to do this in constant time.

More precisely, we represent a model of C in n registers R1, . . . , Rn where Ri holds the value of
xi in this model. We initialize the registers such that Ri = 1 if xi ∈ C and Ri = 0 otherwise, that
is, if ¬xi ∈ C or xi /∈ var(C).

Now let k = |X \ var(C)| and σ : {1, . . . , k} → {1, . . . , n} be such that X \ var(C) =
{xσ(1), . . . , xσ(k)} with σ(1) < · · · < σ(k). We start by storing the values of σ in an array of
size k. We then execute Output(1, n) which outputs the ﬁrst model of C. After that, we run a Gray
code enumeration on the subsets of a set of size k. For each new element generated, the Gray code
algorithm ﬂips a bit at some position i. We thus switch the bit of Rσ(i) and call Output(1, n). This
generates all solutions of C since all possible values of the variables not in C are set, while the other

15

have the only allowed value by C. The delay between two solutions is constant since we only look
the value of σ(i) in an array and switch the value of a register between two outputs.

B Proof of Proposition 2

Proof. As explained in Proposition 1, a term C ∈ D, sat(C) can be enumerated in constant delay
using Gray code enumeration. The terms of D are indexed from C1 to Cm in an arbitrary order.
During the algorithm, the state of the enumeration by Gray Code for each term is maintained so
that we can query in constant time the next model of a given term. At each step, the algorithm does
a loop from C1 to Cm. For a term Ci the next model is generated and the algorithm tests whether
it is a model of some Cj with j > i. If not, it is outputted. If a term has no more models we skip it.
By this method, we guarantee that each model is outputted when generated by the term of
largest index it satisﬁes, hence all models are generated and without repetitions. Moreover, at each
step of the algorithm, the model given by the last term which has still models will be outputted,
therefore the delay is bounded by the time to execute one step of the algorithm.

The cost of the generating new models at each step is bounded by O(m) since each solution
is produced in O(1). The cost of testing whether a model satisﬁes some term of larger index is
bounded by (cid:107)D(cid:107) and it is done at most m times before outputting a solution which implies that
the delay is O(m(cid:107)D(cid:107)).

C Proof of Proposition 3

Proof. As in the previous algorithm, we run a simple enumeration algorithm on each term and we
maintain their states so that we can easily query the next model of a term. We chose to enumerate
the models of the terms in lexicographic ascending order (for some arbitrary order of the variables),
which can be done with delay O(n) for each term.

The ﬁrst model of each term which has not yet been outputted is stored in a trie; if all models
of a term have been outputted then nothing is stored for this term. Moreover, for each model in the
trie, we maintain the list of terms from which it has been generated.

At each step of the algorithm, the smallest model α is found in the trie, then outputted and
removed from the trie all in time O(n). Then we use the list of terms which had α as a model, to
generate for each of them their next model and add it to the trie in time O(mn) since the insertion
can be done in time O(n) and the number of new models is bounded by O(m). The delay of this
algorithm is thus bounded by O(mn). By induction, we prove that at each step the smallest non
outputted model is outputted, which implies that all models are outputted without repetitions.

D Pseudocode for Theorem 5

E Proof of Lemma 12

Proof. Denote by n0 the number of terms of D which contain ¯x, n1 the number which contain x and
n(cid:48) the number which do not contain variable x. The terms of D[x → 0] are the terms of D which
contains the literal ¯x or which does not contain the variable x. Remark that ﬁxing the variable x

16

Algorithm 1: Enumerates the models of k-DNF with delay 2O(k).

Data: A k-DNF-formula D
begin

if D = ∅ then
return ∅ ;

if D = {C} then

Enumerates the models of C ;

else

d ← Ak22kα ;
Pick C ∈ D ;
Every d steps of computation in the next block, output a new model of D[1C] ;
begin

for y ∈ var(C) do
Dy ← D[0y
C] ;

for y ∈ var(C) do

Recursively enumerates 0y

C × sat(Dy);

to 0 cannot make two terms equal except when one contains ¯x and the other does not contain the
variable x. Hence m0 ≥ max(n0, n(cid:48)). Similarly, m1 ≥ max(n1, n(cid:48)).

Since max(a, b) ≥ (a + b)/2, we have m0 + m1 ≥ (n0 + n(cid:48))/2 + (n1 + n(cid:48))/2 ≥ (n0 + n1 + n(cid:48))/2.

By deﬁnition m = n0 + n1 + n(cid:48), then we have proved the lemma.

17

