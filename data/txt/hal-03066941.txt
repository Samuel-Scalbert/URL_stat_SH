Compression Boosts Differentially Private Federated
Learning
Raouf Kerkouche, Gergely Ács, Claude Castelluccia, Pierre Genevès

To cite this version:

Raouf Kerkouche, Gergely Ács, Claude Castelluccia, Pierre Genevès. Compression Boosts Differen-
tially Private Federated Learning. EuroS&P 2021 - 6th IEEE European Symposium on Security and
Privacy, Sep 2021, Vienna, Austria. pp.1-15, ￿10.1109/EuroSP51992.2021.00029￿. ￿hal-03066941￿

HAL Id: hal-03066941

https://hal.science/hal-03066941

Submitted on 15 Dec 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Compression Boosts Differentially Private Federated Learning

Raouf Kerkouche
Privatics team
Univ. Grenoble Alpes, Inria
38000 Grenoble, France
raouf.kerkouche@inria.fr

Gergely ´Acs
Crysys Lab
BME-HIT
Budapest, Hungary
acs@crysys.hu

Claude Castelluccia
Privatics team
Univ. Grenoble Alpes, Inria
38000 Grenoble, France
claude.castelluccia@inria.fr

Pierre Genev`es
Tyrex team
Univ. Grenoble Alpes, CNRS,
Inria, Grenoble INP, LIG
38000 Grenoble, France
pierre.geneves@cnrs.fr

Abstract—Federated Learning allows distributed entities to
train a common model collaboratively without sharing their
own data. Although it prevents data collection and aggre-
gation by exchanging only parameter updates, it remains
vulnerable to various inference and reconstruction attacks
where a malicious entity can learn private information about
the participants’ training data from the captured gradients.
Differential Privacy is used to obtain theoretically sound
privacy guarantees against such inference attacks by noising
the exchanged update vectors. However, the added noise is
proportional to the model size which can be very large
with modern neural networks. This can result in poor
model quality. In this paper, compressive sensing is used
to reduce the model size and hence increase model quality
without sacriﬁcing privacy. We show experimentally, using
2 datasets, that our privacy-preserving proposal can reduce
the communication costs by up to 95% with only a negligible
performance penalty compared to traditional non-private
federated learning schemes.

Index Terms—Federated Learning, Compressive Sensing,
Differential Privacy, Compression, Denoising, Bandwidth
Efﬁciency, Scalability.

1. Introduction

Traditional training of machine learning models usu-
ally requires the centralization of the user-held data. This
limitation is considerably penalizing especially when the
data is sensitive such as medical data. To deal with this
problem, federated learning protocols have been proposed
[1], [2] to collaboratively train a common model without
sharing any private training data held by individual parties.
In federated learning, each entity trains a common model
using its own training data, and share only the gradients
(i.e., model update) with each other through a central
server. The server updates the common model with the
shared gradients, and re-distributes the updated model to
the clients for further training. This process repeats until
the convergence of the common model.

However, sharing gradients computed by individual
parties can leak information about their private training

data. Several recent attacks have demonstrated that a
sufﬁciently skilled adversary, who can capture the model
updates (gradients) sent by individual parties, can infer
whether a speciﬁc record [3] or a group property [4] is
present in the dataset of a speciﬁc party. Moreover, com-
plete training samples can also be reconstructed purely
from the captured gradients [5].

Differential privacy (DP) [6] has become a de facto
privacy model which provides a formal privacy guarantee
for any participant. It guarantees that the common model
is roughly independent of any single client’s training data,
and depends only on the characteristics that are shared
among multiple parties’ training data1. DP can be achieved
by adding Gaussian noise to the shared model updates. In
addition, secure aggregation protocols [7] allow parties to
add noise to the model update in a distributed manner,
which increases robustness against byzantine attacks and
requires less noise than other decentralized perturbation
approaches such as randomized response [8] used in local
differential privacy [9].

However, the norm of the added noise is proportional
to the model size (i.e., the number of model parameters or
weights). Indeed, the noise is added to every coordinate
value of the gradient (update) vector including those which
have very small magnitude and would anyway not improve
convergence. In other words, adding noise to sparse model
updates can slow down convergence signiﬁcantly, or result
in poor model quality [10].

In this paper, we propose to ﬁrst lossily compress
the gradients using compressive sensing [11]–[13] and
then add noise to the compressed gradient vector. The
noisy compressed vectors are then transferred to the server
for aggregation. This approach has several beneﬁts. First,
compressed gradients are less sparse and also shorter than
the original gradient vectors. This allows to add less noise
to the compressed gradients, which eventually yields faster
convergence with more accurate models than the uncom-
pressed noisy gradients. Second, compressive sensing is
linear, which means that the sum of compressed gradients

1. If client-level DP is considered. See Section 3.2.1 for more clariﬁ-

cation.

equals the compressed sum of the gradients. Therefore,
compressive sensing can be smoothly integrated with
secure aggregation; the server can only access the ag-
gregated compressed vectors which is identical
to the
compressed aggregation. Finally, by decreasing the size
of the model updates, communication costs are reduced
and bandwidth is saved. This is crucial with resource
constrained parties training large models which is not
uncommon nowadays.

The main contributions of this paper are summarized

as follows:

• We use a slighlty modiﬁed version of compres-
sive sensing to compress sparse model updates
in federated learning. Our protocol, called FL-
CS allows to save bandwidth and reduce com-
munication costs by transferring only the low fre-
quency components of the gradient vector to the
server (instead of some random frequency compo-
nents like in traditional compressive sensing). The
server can reconstruct
the approximated sparse
gradient vector by efﬁciently solving a convex
quadratic optimization problem. This approach
provides more accurate reconstruction than simply
applying the inverse Fourier transform on the low
frequency components. Our approach is scalable to
large gradient vectors and is almost as accurate as
the vanilla federated learning protocol, referred to
FL-STD, without any compression, still incuring
much smaller communication cost.

• We propose a privacy-preserving extension of FL-
CS, called FL-CS-DP, by adding Gaussian noise
to the compressed gradients. In FL-CS-DP, partici-
pants inject Gaussian noise in a distributed manner
so that the sum of the noisy compressed vectors
is differentially private. In addition, secure aggre-
gation guarantees that the server (or any other
third party) can only learn the noisy compressed
aggregate owing to the linear compression scheme.
Reconstructing the approximated gradients is an
instance of Basis Pursuit Denoising (or LASSO),
which can be solved with efﬁcient solvers that
provide large accuracy despite the added Gaussian
noise. We show that FL-CS-DP produces more
accurate models than FL-STD-DP,
the
differentially private variant of the vanilla feder-
ated learning protocol without any compression.
Therefore, compression boosts the accuracy of
differentially private federated learning and also
reduces bandwith cost by more than 60% with
early stopping [14].

that

is,

2. Background

2.1. Federated Learning (FL-STD)

In federated learning [1], [2], multiple parties (clients)
build a common machine learning model from union of
their training data without sharing them with each other.
At each round of the training, a selected set of clients re-
trieve the global model from the parameter server, update
the global model based on their own training data, and
send back their updated model to the server. The server
aggregates the updated models of all clients to obtain a
global model that is re-distributed to some selected parties
in the next round.

t = wk

In particular, a subset K of all N clients are randomly
selected at each round to update the global model, and
C = |K|/N denotes the fraction of selected clients. At
round t, a selected client k ∈ K executes Tgd local gradi-
ent descent iterations on the common model wt−1 using
its own training data Dk (D = ∪k∈KDk), and obtains
the updated model wk
t , where the number of weights is
denoted by n (i.e., |wk
t | = |∆wk
t | = n for all k and t).
Each client k submits the update ∆wk
t −wk
t−1 to the
server, which then updates the common model as follows:
wt = wt−1 + (cid:80)
j |Dj | ∆wk
t , where |Dk| is known
to the server for all k (a client’s update is weighted with
the size of its training data). The server stops training after
a ﬁxed number of rounds Tcl, or when the performance of
the common model does not improve on a held-out data.
Note that each Dk may be generated from different
distributions (i.e., Non-IID case),
is, any client’s
local dataset may not be representative of the population
distribution [2]. This can happen, for example, when not
all output classes are represented in every client’s training
data. The federated learning of neural networks is sum-
marized in Alg. 1. In the sequel, each client is assumed
to use the same model architecture.

that

k∈K

|Dk|

(cid:80)

Algorithm 1: FL-STD: Federated Learning

1 Server:
2

Initialize common model w0
for t = 1 to Tcl do

3

4

5

6

7

8

9

Select K clients uniformly at random
for each client k in K do

∆wk

t = Clientk(wt−1)

end
wt = wt−1 + (cid:80)

k

(cid:80)

|Dk|

j |Dj | ∆wk

t

end
Output: Global model wt

10
11 Clientk(wk
wk
t−1, Tgd)
12
Output: Model update (wk

t−1):
t = SGD(Dk, wk

t − wk

t−1)

• We evaluate our proposals on real datasets, a pri-
vate medical dataset of 1.2 millions of US hospital
patients and the public Fashion-MNIST dataset.
We show that FL-CS-DP reduces its bandwidth
cost with more than 60% compared to FL-STD-
DP, meanwhile suffering negligible performance
loss compared to uncompressed federated learning
without any privacy guarantee (FL-STD).

The motivation of federated learning is three-fold:
ﬁrst, it aims to provide conﬁdentiality of each participant’s
training data by sharing only model updates instead of
potentially sensitive training data. Second, in order to de-
crease communication costs, clients can perform multiple
local SGD iterations before sending their update back to
the server. Third, in each round, only a few clients are
required to perform local training of the common model,

Algorithm 2: Stochastic Gradient Descent

Input: D : training data, Tgd : local epochs, w :

weights

1 for t = 1 to Tgd do
2

Select batch B from D randomly
w = w − η∇f (B; w)

3
4 end

Output: Model w

which further diminishes communication costs and makes
the approach especially appealing with large number of
clients.

However, several prior works have demonstrated that
model updates do leak potentially sensitive information
[3], [4]. Hence, simply not sharing training data per se is
not enough to guarantee their conﬁdentiality.

2.2. Differential Privacy

Differential privacy allows a party to privately release
information about a dataset: a function of an input dataset
is perturbed, so that any information which can differen-
tiate a record from the rest of the dataset is bounded [6].

Deﬁnition 1 (Privacy loss). Let A be a privacy mechanism
which assigns a value Range(A) to a dataset D. The
privacy loss of A with datasets D and D(cid:48) at output
O ∈ Range(A) is a random variable P(A, D, D(cid:48), O) =
log Pr[A(D)=O]
Pr[A(D(cid:48))=O] where the probability is taken on the
randomness of A.

Deﬁnition 2 (((cid:15), δ)-Differential Privacy [6]). A privacy
mechanism A guarantees (ε, δ)-differential privacy if for
any database D and D(cid:48), differing on at most one record,
PrO∼A(D)[P(A, D, D(cid:48), O) > ε] ≤ δ.

Intuitively, this guarantees that an adversary, provided
with the output of A, can draw almost the same conclu-
sions (up to ε with probability larger than 1 − δ) about
any record no matter if it is included in the input of A or
not [6]. That is, for any record owner, a privacy breach is
unlikely to be due to its participation in the dataset.
Moments Accountant. Differential privacy maintains com-
position; the privacy guarantee of the k-fold adaptive com-
position of A1:k = A1, . . . , Ak can be computed using
the moments accountant method [15]. In particular, it fol-
lows from Markov’s inequality that Pr[P(A, D, D(cid:48), O) ≥
ε] ≤ E[exp(λP(A, D, D(cid:48), O))]/ exp(λε) for any output
O ∈ Range(A) and λ > 0. This implies that A is (ε, δ)-
DP with δ = minλ exp(αA(λ) − λε), where αA(λ) =
maxD,D(cid:48) log EO∼A(D)[exp(λP(A, D, D(cid:48), O))] is the log
of the moment generating function of the privacy loss. The
privacy guarantee of the composite mechanism A1:k can
be computed using that αA1:k (λ) ≤ (cid:80)k
Gaussian Mechanism. There are a few ways to achieve
DP, including the Gaussian mechanism [6]. A fundamental
concept of all of them is the global sensitivity of a
function [6].

i=1 αAi (λ) [15].

Deﬁnition 3 (Global Lp-sensitivity). For any function
f : D → Rn,
the Lp-sensitivity of f is ∆pf =
maxD,D(cid:48) ||f (D) − f (D(cid:48))||p, for all D, D(cid:48) differing in at
most one record, where || · ||p denotes the Lp-norm.

The Gaussian Mechanism [6] consists of adding Gaus-
sian noise to the true output of a function. In particular,
for any function f : D → Rn, the Gaussian mechanism
is deﬁned as adding i.i.d Gaussian noise with variance
(∆2f · σ)2 and zero mean to each coordinate value of
f (D). Recall that the pdf of the Gaussian distribution with
mean µ and variance ξ2 is

pdfG(µ,ξ)(x) =

√

1
2πξ

(cid:18)

exp

−

(cid:19)

(x − µ)2
2ξ2

(1)

In fact, the Gaussian mechanism draws vector val-
ues from a multivariate spherical (or isotropic) Gaus-
sian distribution which is described by random variable
G(f (D), ∆2f ·σIn), where n is omitted if its unambiguous
in the given context.

2.3. Compressive Sensing

Compressive Sensing (CS) introduced in [11]–[13]
aims to recover the original signal from signiﬁcantly fewer
samples (or measurements) than other traditional sampling
techniques, which are based on the Nyquist-Shannon the-
orem, by exploiting the sparsity of the signal.

Consider a signal x ∈ Rn which admits a sparse
representation s ∈ Rn, that is, there exists a sparsity
orthonormal basis with matrix Ψ ∈ Rn×n such that:

x = Ψs

(2)

Here, s is U -sparse if (cid:107)s(cid:107)0 = U. Ψ can denote any
linear transformation, such as Discrete Fourier/Cosine or
Wavelet Transform, which render the original signal x
sparse. If x is already sparse, then Ψ can be the identity
matrix which corresponds to the canonical sparsity basis.
In CS, x is reconstructed from some of its linear
measurements. For m measurements, the signal is “sam-
pled” in m values yj = (cid:104)φj, x(cid:105) (1 ≤ j ≤ m), where
the vectors φj ∈ Rn constitute the sensing basis matrix
Φ = (φ1, φ2, . . . , φm)(cid:62) ∈ Rm×n. Here, m = r×n, where
r is the compression ratio. Therefore, the compression
operator C is deﬁned as:

C(x, m) = y = Φx = ΦΨs = Θs

(3)

where Θ is the sparsity sensing matrix.

There are several options to select the sensing matrix
Φ. When Φ is a random matrix (e.g., each element of Φ is
an iid sample from G(0, 1/m)), then Ψ works well with
an arbitrary sparsity basis [16]. On the other hand, the nu-
merical reconstruction of x in that case has a complexity
of O(mn) which can be very large (recall that n is the
model size in the order of 106). Another (faster) option for
the sensing matrix Φ is when it is composed of random m
rows of the matrix of the (real) Discrete Fourier/Cosine
Transform. Then, matrix multiplication can be executed
with the Fast Fourier Transform (FFT) in O(n ln n), but
such sensing matrix provides accurate reconstruction if
Ψ is the identity matrix, i.e. x is already sparse [16].
Fortunately, this usually holds for gradient vectors (or can
be made as such by sparsiﬁcation without signiﬁcantly
affecting convergence) and hence we will use this option
in this paper.

In order to recover s from y, one has to solve a
system of linear equations with m equations and n un-
knowns. Although this system seems underdetermined

because m < n, CS exploits the U -sparsity of s for the
reconstruction. It aims to reconstruct the sparse vector s
from y = Θs given the sparsity sensing basis Θ by solving
the following optimization problem:

arg min

(cid:107)s(cid:107)0

s

s.t. y = Θs

Finally, notice that

the compression operator C in

Eq. (3) is linear, which means that:

(cid:88)

i

C(xi, m) = C

(cid:33)

xi, m

(cid:32)

(cid:88)

i

and therefore

Since this optimization problem is NP-complete [16],
[17], it is further relaxed into the following slightly dif-
ferent problem called Basis Pursuit (BP) [18]:

(cid:32)

(cid:88)

D

i

(cid:33)

C(xi, m)

≈

(cid:88)

xi

i

arg min

(cid:107)s(cid:107)1

s

s.t. y = Θs

This linearity allows to combine secure aggregation and
compressive sensing described in Section 3.2.2.

the convex L1-norm usually approximates the
Indeed,
non-convex L0-norm well, and the relaxed optimization
problem can be efﬁciently solved with any convex opti-
mization technique [16] (e.g., with an LP solver).

When the measurements y are noisy (i.e., y = Θs+z,
where z ∈ Rm is the additional bounded iid noise, i.e.
(cid:107)z(cid:107)2 ≤ κ), then the following convex quadratic variant
of BP called Basis Pursuit Denoising (BPDN) is rather
considered:

R(y, κ) = arg min

(cid:107)s(cid:107)1

s

s.t.

(cid:107)y − Θs(cid:107)2 ≤ κ

and therefore

D(y, n) = Ψ

(cid:18)

arg min

s

1
2

(cid:107)y − Θs(cid:107)2

2 + λ(cid:107)s(cid:107)1

(cid:19)

,

(4)

Eq. (4) deﬁnes our decompression operator and is an
instance of convex quadratic programming. In this paper,
we use the Orthant-Wise Limited-memory Quasi-Newton
(OWL-QN) algorithm [19], [20], an extension of Limited-
memory BFGS, which is a numerical scalable optimiza-
tion procedure that can efﬁciently solve Eq. (4).

When λ → 0, the problem in Eq. (4) becomes BP
because λ(cid:107)s(cid:107)1 tends to 0. In the case of non-noisy
sensing measurements, a BP decoder is more adapted
to reconstruct the sparse signal s. Otherwise, BPDN is
more suited. This has particular importance in our case
when the compressed vector (measurements) are noised
to guarantee Differential Privacy, i.e., y = Θs + z where
z ∼ N (0, SIσ) (see Section 3.2.2). Approximate signal
reconstruction from noisy measurements have been the-
oretically justiﬁed in [21] from the Restricted Isometry
Property of Θ.

Deﬁnition 4 (Restricted Isometry Property (RIP) [22]).
The U -restricted isometry constants 0 ≤ δU < 1 of a
matrix Θ ∈ Rm×n is deﬁned as the smallest number such
that:

(1 − δU )(cid:107)s(cid:107)2

2 ≤ (cid:107)Θs(cid:107)2

2 ≤ (1 + δU )(cid:107)s(cid:107)2
2

for all U -sparse vector s ∈ Rn and we say that the matrix
Θ obeys the Restricted Isometry Property (or RIP(U ,δU ))
of order U < m.

√

Theorem 1 (Reconstruction error of BPDN [21]). If Θ is
RIP(2U, δU ) and δU <
2 − 1, then ||s − R(y, κ)||2 ≤
√
K)||s − sK||1, where C and D are constants
Cκ + (D/
and sK is a vector with all but the K-largest entries of s
set to zero2.

2. For instance, for δU = 0.2, C < 4.2 and D < 8.5

2.4. Error Propagation

Biased estimation of the gradients may prevent model
convergence unless the approximation error introduced
by lossy compression techniques, such as compressive
sensing, sketching, or quantization, is accumulated and
re-injected in every optimization round [23] as follows:

gt = ∇f (B, wt−1) : Computing gradients on batch B

pt = ηgt + et−1 : Error feedback (correction)
∆t = D(C(pt)) : Reconstruction of pt

wt = wt−1 − ∆t : Updating model parameters (weights)

et = pt − ∆t : Error accumulation

The corrected direction pt is obtained by adding the
error et−1 accumulated over all iterations to gt (see Alg. 2
in [23] for more details). Here, the error is calculated
based on the biased estimation of the update given by
D(C(pt)).

3. Federated Learning with Compressive
Sensing

In the FL-STD scheme, presented in Section 2, each
randomly selected client sends its complete model update
to the server. Knowing that a model has on average
millions of parameters (each is a ﬂoating point value
represented on 32 bits), the network can suffer from large
trafﬁc.

To decrease large network trafﬁc, we adapt compres-
sive sensing to federated learning. The new algoritm is
called FL-CS. Moreover, this scheme is also extended
to a privacy-preserving version, called FL-CS-DP, which
aims to protect the training data of every participant. We
show that compression improves model performance with
Differential Privacy by reducing the added noise compared
to the uncompressed DP variant of federated learning.
Hence, both FL-CS and FL-CS-DP improve bandwidth
efﬁciency, and in addition, FL-CS-DP also boosts the
accuracy of differentially private federated learning.

In what follows, we will ﬁrst describe the non-private
scheme FL-CS and then the privacy-preserving FL-CS-DP.

3.1. FL-CS: Federated Learning with Compres-
sive Sensing

CS assumes the sparsity of the reconstructed signal
in a speciﬁc basis domain Ψ as explained in Section 2.

We assume the model update (as a signal) to be already
sparse in the time domain, that is, Ψ is canonical spar-
sity basis (i.e., Ψ = I), and therefore, the compression
operator is C(∆w, m) = Φ∆w, where Φ is composed
of the ﬁrst m rows of the matrix of the Discrete Cosine
Transform (DCT) [24], [25]. Indeed, due to the large
energy compaction property of DCT, the ﬁrst coefﬁcients,
which correspond to the low frequency components of
∆w, tend to have the largest magnitude and hence convey
the most information about the model update [26]. In fact,
for a canonical sparsity basis Ψ = I, Θ = Φ is RIP with
overwhelming probability as soon as m = O(U ln4 n) if
∆w is U -sparse [27]. Therefore, reconstruction is possible
according to Theorem 1.

The decompression operator D is deﬁned Eq. (4).
Note that the compression operator can be computed in
O(n ln n) with FFT and the decompression (or recon-
struction) operator is implemented with the OWL-QN
algorithm [19] which makes our approach reasonably fast
in practice.

FL-CS is described in Alg. 3. A client ﬁrst com-
putes its update ∆wk
t with SGD, and then transfers the
compressed update C(∆wk
t , m), which consists of the
ﬁrst m DCT coefﬁcients of the update (Line 18). The
server takes the average of the client’s updates (Line 8),
updates the momentum (Line 9), and computes the error
et (Line 10-12) due to compression following the error
propagation technique described in Section 2.4. This error
is accumulated over all federated rounds and added to
the model (Line 13) to compensate its negative effect on
convergence. The server uses OWL-QN [19], [20] to re-
construct the error-compensated aggregated model update
st ∈ Rn. Finally, the server updates the global model as
wt = wt−1 + st before re-distributing the updated model
to a new set of clients K.

Notice that the error et, the averaged model update
yt, as well as the momentum are maintained in the com-
pressed domain and have a size of m instead of n. This
is possible due to the linearity of the compression scheme
which is detailed in Section 2.3.

Scalable reconstruction: Although OWL-QN is rea-
sonably fast in practice, its computational overhead may
not be tolerated with very large models. A scalable recon-
struction is proposed as follows. On the client side, the
update vector ∆wt is shufﬂed and then splitted into P
equally-sized chunks. Then, the compression operator C is
applied on each individual chunk. Finally, the compressed
chunks are transferred to the server. On the server side,
each chunk is reconstructed independently using OWL-
QN. The decompressed chunks are concatenated, and the
resulted vector with size n is reshufﬂed to obtain st by
inverting the client-side shufﬂing.

Shufﬂing is performed by each client identically which
guarantees that the compressed chunks can still be aggre-
gated by the server. In practice, this can be implemented
by sharing a common random seed among all participants
to initialize the shufﬂer. As the server also knows this seed,
it can invert this shufﬂing and reconstruct the aggregated
model updates.

Notice that, instead of reconstructing the complete
update vector at once, the server performs reconstruction
on smaller chunks which makes decompression faster.

In addition, shufﬂing guarantees that the sparsity of the
chunks is proportional to the sparsity of the whole update
vector (i.e., if the update vector is U -sparse then all its
chunks are U/P -sparse). Hence, the same compression
operator C(·, m/P ) can be applied on every chunk without
the compressed
increasing the compression ratio (i.e.,
update still has a size of m).

Note that shufﬂing is also performed identically over

all the rounds to maintain the error.

3.2. FL-CS-DP: Differentially Private Federated
Learning with Compressive Sensing

3.2.1. Privacy Model. We consider an adversary, or a
set of colluding adversaries, who can access any update
vector sent by the server or any clients at each round
of the protocol. A plausible adversary is a participating
entity, i.e. a malicious client or server, that wants to infer
the training data used by other participants. The adversary
is passive (i.e., honest-but-curious), that is, it follows the
learning protocol faithfully.

Different privacy requirements can be considered de-
pending on what information the adversary aims to infer.
In general, private information can be inferred about:

•

•

any record (user) in any dataset of any client
(record-level privacy),
any client/party (client-level privacy).

To illustrate the above requirements, suppose that sev-
eral banks build a common model to predict the credit-
worthiness of their customers. A bank certainly does not
want other banks to learn the ﬁnancial status of any of
their customers (record privacy) and perhaps not even the
average income of all their customers (client privacy).

Record-level privacy is a standard requirement used
in the privacy literature and is usually weaker than client-
level privacy. Indeed, client-level privacy requires to hide
any information which is unique to a client including
perhaps all its training data.

We aim at developing a solution that provides client-
level privacy and is also bandwidth efﬁcient. For example,
in the scenario of collaborating banks, we aim at protect-
ing any information that is unique to each single bank’s
training data. The adversary should not be able to learn
from the received model or its updates whether any client’s
data is involved in the federated run (up to ε and δ). We
believe that this adversarial model is reasonable in many
practical applications when the conﬁdential information
spans over multiple samples in the training data of a
single client (e.g., the presence of a group a samples,
such as people from a certain race). Differential Privacy
guarantees plausible deniability not only to any groups of
samples of a client but also to any client in the federated
run. Therefore, any negative privacy impact on a party
(or its training samples) cannot be attributed to their
involvement in the protocol run.

3.2.2. Operation. FL-CS-DP is described in Alg. 4.
Client-level differential privacy requires each client
to
add Gaussian noise to the compressed model updates. In
particular, each client ﬁrst calculates ck
t , m)
(in Line 19), which is then clipped (in Line 20) to ob-
tain ˆck
t with L2-norm at most S. Then, random noise

t = C(∆wk

√

t such that (cid:80)

K) is added to ˆck

zk ∼ G(0, SσI/
t +
zk) = (cid:80)
k∈K ˆck
t + G(0, SσI) as the sum of Gaussian
random variables also follows Gaussian distribution3 and
then differential privacy is satisﬁed where ε and δ can
be computed using the moments accountant described in
Section 2.2.

k∈K(ˆck

K,
However, as the noise is inversely proportional to
zk is likely to be small if |K| is too large. Therefore,
the adversary accessing an individual update ˆck
t + zk
can almost learn a non-noisy update since zk is small.
Hence, each client uses secure aggregation to encrypt its
individual update before sending it to the server. Upon
reception, the server sums the encrypted updates as:
(cid:88)

(cid:88)

√

yk

t =

EncKk (ˆck

t + zk)

k∈K

=

=

k∈K
(cid:88)

k∈K
(cid:88)

k∈K

ˆck
t +

(cid:88)

zk

k∈K
ˆck
t + G(0, SσI)

(5)

t + zk) = ˆck

t + zk + Kk mod p and
k Kk = 0 (see [7], [28] for details). Here the modulo
t +zk||∞|K|)(cid:101).

where EncKk (ˆck
(cid:80)
is taken element-wise and p = 2(cid:100)log2(maxk ||ˆck
1, ||ck
Let γk

. Then,

(cid:16)

(cid:17)

t = 1/ max
(cid:88)

t ||2
S
(cid:88)

ˆck
t =

t ck
γk
t

k∈K

k∈K
(cid:88)

=

t C(∆wk
γk

t , m)

k∈K

= C(

(cid:88)

k∈K

t ∆wk
γk

t , m)

(6)

where the last equality comes from the linearity of the
compression operation (see Section 2.3). Plugging Eq. (6)
into Eq. (5). we get that
(cid:88)

(cid:88)

yk

t = C(

t ∆wk
γk

t , m) + G(0, SσI)

k∈K

k∈K

t ∆wk

k∈K γk

k∈K yk

k∈K yk

This is an instance of BPDN (see Section 2.3), and
therefore the direct reconstruction of (cid:80)
t would
be an approximation of (cid:80)
t . However, anal-
the server applies error propaga-
ogously to FL-CS,
from yt =
tion and computes the (noisy) error et
(1/|K|) (cid:80)
t (in Line 10), and decompresses et into
st by using OWL-QN. Recall that the reconstruction al-
gorithm solves the BPDN problem, where a sparse vector
s is reconstructed from m noisy measurements of the
form Θs + z, where the noise z ∈ Rm is assumed
to be identically and independently distributed over its
elements with a Gaussian distribution [16], [18]. Since
z ∼ G(0, SIσ) in our case, the reconstruction algorithm is
therefore optimized to reconstruct the differentially private
compressed vectors (see Theorem 1).

Privacy analysis: The server can only access the noisy
aggregate which is sufﬁciently perturbed to ensure differ-
ential privacy; any client-speciﬁc information that could
be inferred from the noisy aggregate is tracked and quanti-
ﬁed by the moments accountant, described in Section 2.2,
as follows.

3. More precisely, (cid:80)

i G(νi, ξi) = G((cid:80)

i νi,

(cid:113)(cid:80)

i ξ2
i )

Let η0(x|ξ) = pdfG(0,ξ)(x) and η1(x|ξ) = (1 −
C)pdfG(0,ξ)(x) + CpdfG(1,ξ)(x) where C is the sampling
probability of a single client in a single round. Let

α(λ|C) = log max(E1(λ, ξ, C), E2(λ, ξ, C))

(7)

where E1(λ, ξ, C) = (cid:82)
E2(λ, ξ, C) = (cid:82)

R η1(x|ξ, C) ·

R η0(x|ξ, C) ·

(cid:16) η1(x|ξ,C)
η0(x|ξ,C)

(cid:17)λ

dx.

(cid:16) η0(x|ξ,C)
η1(x|ξ,C)

(cid:17)λ

dx and

Theorem 2 (Privacy of FL-CS-DP). FL-CS-DP is
(minλ(Tcl · α(λ|C) − log δ)/λ, δ)-DP.

Given a ﬁxed value of δ, ε is computed numerically

as in [15], [29].

The magnitude of the added Gaussian noise is propor-
tional to the sensitivity S, which is in turn often propor-
tional to the model size n [10]. Hence, when n becomes
large, SGD often fails to converge due to the perturbation
error caused by the added noise [10]. In our approach, the
perturbation error is less since Gaussian noise is added to
the compressed vector with size m < n. On the other
hand, compression also induces some reconstruction error
owing to its lossy nature. The total error is the sum of the
reconstruction and the perturbation error and is quantiﬁed
in Theorem 1. Finding the right trade-off between these
two errors is the key to achieve good model quality.

Algorithm 3: FL-CS: Federated Learning

1 Server:
2

Initialize common model w0 , ηG , ρ, ut = 0,

et = 0

3

4

5

6

7

8

9

10

11

12

13

14

for t = 1 to Tcl do

Select K clients uniformly at random
for each client k in K do
t = Clientk(wt−1)

yk

k=1

yk
|K| : Averaging
t

end
yt = (cid:80)|K|
ut = ρut−1 + yt : Momentum
et = ηGut + et−1 : Error Feedback
st = D(et, n) : Reconstruction
et = et − C(st, m) : Error accumulation
wt = wt−1 + st : Update

end
Output: Global model wt

15
16 Clientk(wk
wk
17
t − wk
∆wk
Output: Model update C(∆wk

t−1):
t = SGD(Dk, wk
t−1

t = wk

t−1, Tgd)

18

t , m)

4. Experimental Results

The goal of this section is to evaluate the performance
of our proposed schemes FL-CS and FL-CS-DP on a
benchmark dataset and a realistic in-hospital mortality pre-
diction scenario. We aim at evaluating their performance
with different levels of compression and comparing them
with the performance of the following learning protocols:

•

•

FL-STD: It is described in Section 2.1 (see Alg. 1).
FL-RND: This baseline follows the algorithm of
FL-STD except that a random subset of the update
vector with size m ≤ n is sent to the server instead

Algorithm 4: FL-CS-DP: Private Compressive Sens-
ing Federated Learning

1 Server:
2

Initialize common model w0 , ηG , ρ, ut = 0,

et = 0

3

4

5

6

7

8

9

10

11

12

13

14

for t = 1 to Tcl do

Select K clients uniformly at random
for each client k in K do
t = Clientk(wt−1)

yk

k=1

yk
|K| : Averaging
t

end
yt = (cid:80)|K|
ut = ρut−1 + yt : Momentum
et = ηGut + et−1 : Error Feedback
st = D(et, n) : Reconstruction
et = et − C(st, m) : Error accumulation
wt = wt−1 + st : Update

end
Output: Global model wt

18

t−1):
t = SGD(Dk, wk
t−1

15
16 Clientk(wk
wk
17
∆wk
t = wk
t = C(∆wk
ck
1, ||ck
t = ck
ˆck
t / max
Output: EncKk (G(ˆck

t − wk
t , m)
(cid:16)

20

19

t−1, Tgd)

(cid:17)

t ||2
S
t , SIσ/(cid:112)|K|))

Algorithm 5: FL-STD-DP: Federated Learning with
Client Privacy

1 Server:
2

Initialize common model w0
for t = 1 to Tcl do

Select K clients randomly
for each client k in K do

∆ ˜wk

t = Clientk(wt−1)

end
wt = wt−1 + 1
|K|

(cid:80)

k ∆ ˜wk

t

3

4

5

6

7

8

t−1 = w

end
9
10 Clientk(w):
wk
11
∆wk
∆ ˆwk
Output: EncKk (G(∆ ˆwk

t = SGD(Dk, wk−1
t = ∆wk

t / max

t
(cid:16)

13

12

t−1

, Tgd) − wk
1, ||∆wk
t ||2
t , SIσ/(cid:112)|K|))

(cid:17)

S

•

of the complete update of size n. Each client
selects the same random subset of coordinates
from the update vector, but a different subset in
every round. The server then averages the received
updates before updating only the corresponding
if m = n, FL-RND is
m weights. Note that
equivalent to FL-STD (see Alg. 6).
FL-FREQ: In this baseline, a client transforms the
model update to the frequency domain by using
DCT [24], [25], and then the ﬁrst m coefﬁcients
(low frequency components) are extracted and sent
to the server as in FL-CS. However, as opposed
to FL-CS, the server reconstructs the aggregated
update vector by applying the inverse DCT on the
aggregated compressed vectors where the last n −
m coefﬁcients are zeroed out (see Alg. 7). This
baseline corresponds to a low-pass ﬁlter applied
on the update vector. Φ in Alg. 7 is composed of

the ﬁrst m rows of the matrix of the DCT.

4.1. Medical Dataset

4.1.1. The In-hospital Mortality Prediction Scenario.
The ability to accurately predict the risks in the patient’s
perspectives of evolution is a crucial prerequisite in order
to adapt the care that certain patients receive [30].

We consider the scenario where several hospitals are
collaborating to train models for in-hospital mortality pre-
diction using our Federated Learning schemes. This well-
studied real-world problem consists in trying to precisely
identify the patients who are at risk of dying from compli-
cations during their hospital stay [30]–[32]. As commonly
found in the literature [30], for such predictions, we focus
on hospital admissions of adults hospitalized for at least
3 days, excluding elective admissions.

4.1.2. The Premier Healthcare Database. We used EHR
data from the Premier healthcare database4 which is one
of the largest clinical databases in the United States,
collecting information from millions of patients over a
period of 12 months from 415 hospitals in the USA
[30]. These hospitals are supposedly representative of the
United States hospital experience [30]. Each hospital in
the database provides discharge ﬁles that are dated records
of all billable items (including therapeutic and diagnostic
procedures, medication, and laboratory usage) which are
all linked to a given patient’s admission [30], [33].

The initial snapshot of the database used in our work
(before pre-processing step) comprises the EHR data of
1,271,733 hospital admissions. Electronic Health Record
(EHR) is a digital version of a patient’s paper chart readily
available in hospitals. For developing supervised learning
and speciﬁcally deep learning models, we focus on a
speciﬁc set of features from EHR data. The features of
interest that capture the patients information are summa-
rized in Table 1. There is a total of 24,428 features per
patient, mainly due to the variety of drugs possibly served.
As in [31], we also removed all the features which appear
on less than 100 patients’ records, hence, the number of
features was reduced to 7,280 features.

The Medication regimen complexity index (MRCI)
[34] is an aggregate score computed from a total of 65
items, whose purpose is to indicate the complexity of the
patient’s situation. The minimum MRCI score for a patient
is 1.5, which represents a single tablet or capsule taken
once a day as needed (single medication). However the
maximum is not deﬁned since the number of medications
increases the score [34]. In our case, after statistical
analysis of our dataset, we consider the MRCI score as
ranging from 2 to 60.

Most real datasets like ours are generally imbalanced
with a skewed distribution between the classes. In our
case, the positive cases (patients who die during their
hospital stay) represent only 3% of all patients. Table 2
gives more details about this distribution after the pre-
processing step which is discussed in A.1. To deal with
this well-known problem, we have decided to use down-

4. https://www.premierinc.com/newsroom/education/premier-

healthcare-database-whitepaper

TABLE 1: Descriptions of features

Features
Age

Descriptions
Value in the range of 15 and 89

Gender Male, Female or Unknown

Admission type

Emergency, Urgent, Trauma Center: visits to a trauma center/hospital or Unknown

MRCI Medication regimen complexity index score (ranging from 2 to 60)
Drugs

Drugs given to the patient on the 1st day of hospitalization. There is a total of 24,419 possible drugs that can be served.

sampling technique [35], [36], a standard solution used
for this purpose 5.

4.1.3. Model architecture. As in [31], we use a fully
connected neural network model with the following ar-
chitecture: two hidden layers of 200 units, which use a
Relu activation function followed by an output layer of 1
unit with sigmoid activation function and a binary cross
entropy loss function. A dropout layer with a rate set
to 0.5 is used between each hidden layer and between
the last hidden layer and the output layer. This results
in 1,496,601 parameters in total. We tune η from 0.01
to 0.5 with an increment value of 0.005. As in [37], we
ﬁx the momentum parameter ρ to 0.9 and we tuned the
global learning rate ηG from 0.05 to 2.0 with an increment
value of 0.05. The number of chunks is P = 200. The
hyperparameters used by each of the considered schemes
are summarized in Table 6.

The sensitivity S is selected during an initialization
round for each scheme by taking the median value over
N L2-norm values. We also noticed that the sensitivity of
FL-CS-DP, FL-RND and FL-FREQ are nearly equivalent
for the same level of compression. For this reason, the
same sensitivity value is used for each compressed scheme
and for the same compression ratio. Table 5 and Table 6
show the selected clipping threshold (i.e., sensitivity S)
for each dataset and according to each compression ratio.

TABLE 2: Number of instances for our case study. The
Medical dataset contains in total 1,271,733 records.

Data
Train
Test

Positive cases
32,106
7,882

Negative cases
985,280
246,465

Total

Ratio
3.16% 1,017,386
254,347
3.10%

4.2. Fashion-MNIST

4.2.1. Data Description. Fashion-MNIST database of
fashion articles consists of 60,000 28x28 grayscale images
of 10 fashion categories, along with a test set of 10,000
images [38] [39].

4.2.2. Data pre-processing & experimental setup.
Preprocessing: The pixel of each image is an unsigned
integer in the range between 0 and 255. We rescale them
to the range [0,1] instead.

Model architecture: For Fashion-MNIST, we use a model
[2] with the following architecture: a convolutional neural
network (CNN) with two 5x5 convolution layers (the ﬁrst
with 32 ﬁlters, the second with 64, each followed with

2x2 max pooling), a fully connected layer with 512 units
and ReLu activation, and a ﬁnal softmax output layer. This
results in 1,663,370 parameters in total. We tune η from
0.01 to 0.5 with an increment value of 0.005. As in [37],
we ﬁx the momentum parameter ρ to 0.9 and we tuned the
global learning rate ηG from 0.05 to 2.0 with an increment
value of 0.05. The number of chunks used is P = 200. The
hyperparameters used by each of the considered schemes
are summarized in Table 5.

4.3. Computational environment

Our experiments were performed on a server running
Ubuntu 18.04 LTS equipped with a Intel(R) Xeon(R)
Silver 4114 CPU @ 2.20GHz, 192GB RAM, and two
NVIDIA Quadro P5000 GPU card of 16 Go each. We
use Keras 2.2.0 [40] with a TensorFlow backend 1.12.0
[41] and Numpy 1.14.3 [42] to implement our models and
experiments. We use Python 3.6.5 and our code runs on
a Docker container to simplify reproducibility.

4.4. Results

Table 3 represents the best accuracy over 200 rounds
for each scheme on the Fashion-Mnist dataset. Round
corresponds to the round when the best accuracy is
reached and Cost is the average bandwidth consumption
calculated as: r × n × 32 × Round × C, where 32 is the
number of bits necessary to represent a ﬂoat value, n is the
uncompressed model size, r = m
n , m is the compressed
model size, C is the sampling probability of a client, and
Round is the round when we get the the best accuracy.

Table 4 represents the best balanced accuracy over 100
rounds for each scheme on the Medical dataset. AUROC
(area under the receiver operating characteristic curve
[43]) corresponds to the AUROC value when the best
balanced accuracy is reached, round is also the round
when we get the best balanced accuracy, and ﬁnally, Cost
is the average bandwidth consumption calculated as for
the Fashion-MNIST dataset described above.

Without DP, notice that our FL-CS scheme outper-
forms FL-RND and FL-FREQ whatever the considered
compression ratio or the dataset are. Also, compared to
FL-STD, our scheme started to reach the same accuracy
from a compression ratio r being equal or greater than 0.1
for both datasets, although the differences between FL-CS
and FL-STD for a compression ratio of 0.05 are only of
6% 6 and 1% 7 for the Fashion-Mnist and the medical
datasets, respectively. However, FL-STD consumes much
more bandwidth than FL-CS. Indeed, FL-CS reduces the
bandwidth cost by 95% compared to FL-STD with a
compression ratio of 0.05 for both datasets, while the

5. We have also tested weighted loss function and oversampling
techniques. But, we noticed experimentally that downsampling technique
outperforms the others whatever the considered scheme.

6. Based on the accuracy
7. Based on the balanced accuracy [44], [45]

bandwidth cost is reduced to 80% and 85% with a com-
pression ratio of 0.2 for Fashion-MNIST and the medical
data, respectively.

Surprisingly, for the smallest compression ratio 5%,
FL-CS-DP performs as well as FL-RND-DP or FL-FREQ
in terms of accuracy and much better in terms of band-
width consumption. Indeed, FL-CS-DP with a compres-
sion ratio of 5% reached 0.78 of accuracy on Fashion-
MNIST, however, our baseline FL-RND needs a com-
pression ratio of 10% to reach a similar result (0.77) and
20% to have slightly better result (0.80). The same holds
for the medical dataset, where FL-CS-DP reached 0.69
and 0.76 of balanced accuracy and Auroc, respectively.
However, our other baseline FL-FREQ needs a compres-
sion ratio of 20% to reach the same performance. FL-CS-
DP performs better for a small compression ratio. Indeed,
FL-CS-DP reaches 0.78, 0.73 and 0.66 for 5%, 10% and
20% of accuracy, respectively, on Fashion-MNIST. The
accuracy degradation with DP can be explained by the
fact increasing the compression ratio r also increases the
sensitivity S which has a direct impact on the additive
Gaussian noise as explained in Section 3.2.2. Indeed, the
standard deviation of the normal distribution is σ × S.

On both datasets, FL-STD-DP suffers from the noise
due to the large sensitivity which is the largest one in
Table 5 and 6 for a compression ratio of 1.0 (uncom-
pressed model). Even for FL-RND and FL-FREQ, the gap
between the non-private and the private version is larger
when the compression ratio increases for both datasets.
As the noise proportional to S and is added to every
coordinate, the norm of the added noise increases with
the model size n. This has negative impact on model con-
vergence for a large n as discussed in [10]. By decreasing
n, compression helps reach better utility.

On Fashion-MNIST, FL-CS-DP with a compression
ratio of 0.05 outperforms FL-STD-DP on both utility and
bandwidth preservation. However, and even though FL-
CS-DP reduces the bandwidth cost by 95% which is not
negligible, they have both comparable accuracy on the
medical data. It can be explained by the reduction of the
noise due to the reduction of S and σ (see Table 6 and
Table 5) needed to reach an (cid:15) value of at most 1 after Tcl
rounds.

There is a possible tradeoff between the privacy, com-
munication cost, and utility. Indeed, having a small (cid:15)
(better privacy) results in a reduction of the commu-
nication costs while it decreases accuracy. FL-STD-DP,
for example, converges to the best accuracy (61%) after
only 25 rounds with early stopping, which results on
high privacy ((cid:15)=0.69) and low communication cost (only
22.18 Megabyte). However, the accuracy degradation is
more important (about 30% which is the worst accuracy
degradation indicated in Table 3). Indeed, the large amount
of added noise impacts the convergence of the model
which can not achieve an accuracy larger than 61%.

Finally, we highlight a trade-off for FL-CS-DP. As
mentioned above, FL-CS-DP performs better when the
smallest compression ratio r is used, as the sensitivity
for this level of compression is the smallest one. On the
other hand, the compression ratio cannot be decreased
arbitrarily as it will result in large reconstruction error.
Therefore, one has to ﬁnd the smallest compression ratio
thay is small enough to reduce the perturbation error but

large enough to induce small reconstruction error.

5. Related work

Privacy of Federated Learning: There exist a few
inference attacks speciﬁcally designed against federated
learning schemes. In [4], the adversary’s goal is to infer
whether records with a speciﬁc property are included in
the training dataset of the other participants (called batch
property inference). The authors demonstrate the attack
by inferring whether black people are included in any
of the training datasets, where the common model
is
trained for gender classiﬁcation (i.e., the inferred property
is independent of the learning objective). The adversary is
supposed to have access to the aggregated model update
of honest participants. In [3], the proposed attack infers if
a speciﬁc person is included in the training dataset of the
participants (aka, Membership inference). The adversary
extracts the following features from every snapshot of the
common model, which is a neural network: output value,
hidden layers, loss values, and the gradient of the loss with
respect to the parameters of each layer. These features are
used to train a membership inference model, which is a
convolutional neural network.

The concept of Client-based Differential Privacy has
been introduced in [46] and [47], where the goal is to hide
any information that is speciﬁc to a single client’s training
data. These algorithms bound and noise the contribution
of a single client’s instead of a single record in the client’s
dataset. The noise is added by the server, hence, unlike
our solution, these works assume that the server is trusted.
Also, the noise is drawn from continuous distributions.
Bandwidth Optimization in Federated Learning: Dif-
ferent quantization methods have been proposed to save
the bandwidth and reduce the communication costs in fed-
erated learning. They can be divided into two main groups:
unbiased and biased methods. The unbiased approxima-
tion techniques use probabilistic quantization schemes to
compress the stochastic gradient and attempt to approx-
imate the true gradient value as much as possible [48]
[49] [50] [51]. However, biased approximations of the
stochastic gradient can still guarantee convergence both
in theory and practice [52]–[54]. In signSGD [52], all the
clients calculate the stochastic gradient based on a single
mini-batch and then send the sign vector of this gradient
to the server. The server calculates the aggregated sign
vector by taking the median (majority vote) and sends the
signs of the aggregated signs back to each client.

A different line of works exploit the sparsity of model
updates to compress model updates. Our work belongs to
this line. The authors in [55] use CS for low-complexity
energy-efﬁcient ECG compression. Although compressed
sensing was primarily designed for compression [11],
[13], it was extended for denoising as in [56], [57] where
compressive sensing is used for the purpose of denoising.
In [58], compressed sensing based denoising and certain
artiﬁcial intelligence are combined to improve the predic-
tion performance.

CS was also used with DP in [59]. The authors
n)
show that the amount of noise is reduced from O(
to O(log(n)), when the noise is added on the sampled
coefﬁcients instead of the original database.

√

Compression ratio (r)

Algorithms

0.05

0.1

0.2

1.0

FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-STD
FL-STD-DP

Performance

Accuracy
0.73
0.73
0.82
0.73
0.72
0.78
0.78
0.78
0.85
0.77
0.76
0.73
0.82
0.82
0.87
0.80
0.79
0.66
0.87
0.61

Round
192
189
200
196
200
197
200
197
199
199
200
101
200
195
193
199
200
150
191
25

Cost (Megabyte)
8.52
8.38
8,87
8.69
8,87
8.74
17.74
17.48
17.65
17.65
17.74
8,96
35,49
34,60
34,24
35.31
35,49
26,61
169.44
22.18

(cid:15)
N/A
N/A
N/A
0.99
1
1
N/A
N/A
N/A
1
1
0.84
N/A
N/A
N/A
1
1
0.92
N/A
0.69

TABLE 3: Summary of results on Fashion-MNIST dataset.

Compression ratio (r)

Algorithms

0.05

0.1

0.2

1.0

FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-RND
FL-FREQ
FL-CS
FL-RND-DP
FL-FREQ-DP
FL-CS-DP
FL-STD
FL-STD-DP

Performance

Bal Acc
0.60
0.69
0.73
0.60
0.65
0.69
0.66
0.71
0.73
0.65
0.67
0.69
0.69
0.72
0.73
0.67
0.69
0.68
0.74
0.70

AUROC
0.69
0.76
0.80
0.69
0.72
0.76
0.73
0.78
0.81
0.72
0.74
0.76
0.76
0.80
0.81
0.74
0.76
0.74
0.82
0.77

Round
99
100
100
100
100
100
100
100
87
100
100
99
100
100
74
99
100
64
99
93

Cost(Megabyte)
4.73
4.78
4.78
4.78
4.78
4.78
9.56
9.56
8.31
9.56
9.56
9.46
19.11
19.11
14.14
18.92
19.11
12.23
94.62
88.88

(cid:15)
N/A
N/A
N/A
1
1
1
N/A
N/A
N/A
1
1
1
N/A
N/A
N/A
1
1
0.92
N/A
0.99

TABLE 4: Summary of results on Medical dataset.

Existing works [60], [61] proposed to use a compres-
sive sensing for federated learning in order to compress
model updates without privacy guarantees. However, they
assume that all clients participate in each round (as they
maintain an error accumulation vector at each client due
to the compression scheme), but as discussed in [62]
this assumption is not always realistic. Recently in [63]
another compressive sensing algorithm was proposed for
federated learning for the denoising purpose (instead of
the compression), where the added noise is due to the
network transmission.

Sketching was adapted to federated learning for the
purpose of compressing model updates in [37]. The au-
thors proposed to use Count-Sketch [64] to retrieve the
largest weights in the update vector on the server side.
After that, the server uses two additional communication
rounds to inform the clients about what gradient values
they need to send back to the server. The server then
takes the average of the received gradients and zeros-
out the others before updating the model. The error due
to the compression is maintained at each client, and the
participation of all clients are required in each round

which, as per [62] and as discussed above, is not practical
to federated learning. In [65], the aforementioned scheme
is improved further by directly retrieving the most updated
gradient values without asking for their positions in the
update vector. This makes the scheme more efﬁcient as
it needs fewer communication rounds. Similarly to our
approach, the error vector is also maintained on the server
side instead of the client side, which is clearly a better ﬁt
for federated learning.

6. Conclusion

In this paper, we propose to extend Federated Learning
with compressive sensing. Speciﬁcally, we propose two
schemes: the ﬁrst one (FL-CS) uses compressive sens-
ing in order to reduce communication bandwidth. The
second one (FL-CS-DP) combines compressive sensing
and differential privacy in order to protect participants’
information.

We present some experimental results that are based on
the Fashion-MNIST dataset as well as on a medical dataset
of 1.2 millions of US hospital patients. Results indicate

that using compressive sensing in Federated Learning
allows to reduce the communication costs by up to 95%
for a moderate loss of accuracy.

Results with the privacy-preserving extension FL-CS-
DP indicate that compression happens to be especially
useful and interesting in this context as it improves ac-
curacy. This is due to the sensitivity reduction which
is proportional to the added noise needed to guarantee
differential privacy, and to the considered optimization
problem (BPDN) which reconstructs data from noisy mea-
surements.

We believe that the proposed privacy-preserving ex-
tension (FL-CS-DP) is an interesting alternative to dif-
ferentially private federated learning (FL-STD-DP), as it
improves both accuracy and bandwidth cost.

References

[1] Reza Shokri and Vitaly Shmatikov,

“Privacy-preserving deep
learning,” in ACM SIGSAC Conference on Computer and Com-
munications Security, 2015, 2015, pp. 1310–1321.

[2] H. Brendan McMahan, Eider Moore, Daniel Ramage, Seth Hamp-
son, and Blaise Ag¨uera y Arcas, “Communication-efﬁcient learning
of deep networks from decentralized data,” in AISTATS, 2016.

[3] Milad Nasr, Reza Shokri, and Amir Houmansadr, “Comprehensive
privacy analysis of deep learning: Passive and active white-box
inference attacks against centralized and federated learning,” in
IEEE Symposium on Security and Privacy, 2019, 2019, pp. 739–
753.

[4] Luca Melis, Congzheng Song, Emiliano De Cristofaro, and Vitaly
“Inference attacks against collaborative learning,”

Shmatikov,
CoRR, vol. abs/1805.04049, 2018.

[5] Ligeng Zhu, Zhijian Liu, and Song Han,

“Deep leakage from
gradients,” in Advances in Neural Information Processing Sys-
tems 32: Annual Conference on Neural Information Processing
Systems 2019, NeurIPS 2019, 8-14 December 2019, Vancouver, BC,
Canada, Hanna M. Wallach, Hugo Larochelle, Alina Beygelzimer,
Florence d’Alch´e-Buc, Emily B. Fox, and Roman Garnett, Eds.,
2019, pp. 14747–14756.

[6] Cynthia Dwork and Aaron Roth, “The Algorithmic Foundations
of Differential Privacy,” Foundations and Trends in Theoretical
Computer Science, vol. 9, no. 3–4, 2014.

[7] Keith Bonawitz et al., “Practical secure aggregation for federated

[8]

learning on user-held data,” CoRR, vol. abs/1611.04482, 2016.
´Ulfar Erlingsson, Vasyl Pihur, and Aleksandra Korolova, “RAP-
POR:
re-
randomized aggregatable privacy-preserving ordinal
sponse,” in Proceedings of the 2014 ACM SIGSAC Conference
on Computer and Communications Security, Scottsdale, AZ, USA,
November 3-7, 2014, Gail-Joon Ahn, Moti Yung, and Ninghui Li,
Eds. 2014, pp. 1054–1067, ACM.

[9]

Stacey Truex and al., “A hybrid approach to privacy-preserving
federated learning,” CoRR, vol. abs/1812.03224, 2018.

[10] Yuqing Zhu, Xiang Yu, Yi-Hsuan Tsai, Francesco Pittaluga, Ma-
soud Faraki, Manmohan chandraker, and Yu-Xiang Wang, “Voting-
based approaches for differentially private federated learning,”
2020.

[11] David L Donoho, “Compressed sensing,” IEEE Transactions on

information theory, vol. 52, no. 4, pp. 1289–1306, 2006.

[12] Emmanuel J Candes and Terence Tao, “Near-optimal signal re-
covery from random projections: Universal encoding strategies?,”
IEEE transactions on information theory, vol. 52, no. 12, pp. 5406–
5425, 2006.

[13] Emmanuel J Cand`es, Justin Romberg, and Terence Tao, “Robust
uncertainty principles: Exact signal reconstruction from highly
incomplete frequency information,” IEEE Transactions on infor-
mation theory, vol. 52, no. 2, pp. 489–509, 2006.

[14] Franc¸ois Chollet et al., “Keras early stopping,” https://keras.io/api/

callbacks/early stopping/, 2015.

[15] Martin Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan,
Ilya Mironov, Kunal Talwar, and Li Zhang, “Deep learning with
differential privacy,” in ACM CCS, New York, NY, USA, 2016,
pp. 308–318, ACM.

[16] Laurent Jacques and Pierre Vandergheynst, “Compressed sensing:
When sparsity meets sampling,” Tech. Rep., Wiley-Blackwell,
2010.

[17] Balas Kausik Natarajan, “Sparse approximate solutions to linear
systems,” SIAM journal on computing, vol. 24, no. 2, pp. 227–234,
1995.

[18] Scott Shaobing Chen, David L Donoho, and Michael A Saunders,
“Atomic decomposition by basis pursuit,” SIAM review, vol. 43,
no. 1, pp. 129–159, 2001.

[19] Galen Andrew and Jianfeng Gao,

“Scalable training of l 1-
regularized log-linear models,” in Proceedings of the 24th inter-
national conference on Machine learning, 2007, pp. 33–40.

[20] Robert Taylor,

“Orthant-wise limited-memory quasi-newton
(owl-qn) algorithm implementation,” https://bitbucket.org/rtaylor/
pylbfgs/src/master/, 2020.

[21] Emmanuel Cand`es, “The restricted isometry property and its im-
plications for compressed sensing,” Compte Rendus de l’Academie
des Sciences, vol. 346, pp. 589–592, 05 2008.

[22] Emmanuel J Candes and Terence Tao,

“Decoding by linear
programming,” IEEE transactions on information theory, vol. 51,
no. 12, pp. 4203–4215, 2005.

[23] Sai Praneeth Karimireddy, Quentin Rebjock, Sebastian U. Stich,
and Martin Jaggi, “Error feedback ﬁxes signsgd and other gradient
compression schemes,” CoRR, vol. abs/1901.09847, 2019.

[24] Nasir Ahmed, T Natarajan, and Kamisetty R Rao,

“Discrete
cosine transform,” IEEE transactions on Computers, vol. 100, no.
1, pp. 90–93, 1974.

[25] Nasir Ahmed, “How I came up with the discrete cosine transform,”

Digit. Signal Process., vol. 1, no. 1, pp. 4–5, 1991.

[26] K Ramamohan Rao and Ping Yip, Discrete cosine transform:
algorithms, advantages, applications, Academic press, 2014.

[27] E. J. Candes and T. Tao,

“Near-optimal signal recovery from
random projections: Universal encoding strategies?,” IEEE Trans-
actions on Information Theory, vol. 52, no. 12, pp. 5406–5425,
2006.

[28] Gergely ´Acs and Claude Castelluccia, “I have a dream! (differ-
entially private smart metering),” in Information Hiding - 13th
International Conference, IH 2011, 2011, pp. 118–132.

[29] Ilya Mironov, Kunal Talwar, and Li Zhang,

“R´enyi differen-
tial privacy of the sampled gaussian mechanism,” CoRR, vol.
abs/1908.10530, 2019.

[30] A. Fejza, P. Genev`es, N. Laya¨ıda, and J. Bosson, “Scalable and
interpretable predictive models for electronic health records,” in
2018 IEEE 5th International Conference on Data Science and
Advanced Analytics (DSAA), Oct 2018, pp. 341–350.

[31] Anand Avati, Kenneth Jung, Stephanie Harman, Lance Downing,
Andrew Ng, and Nigam H. Shah, “Improving palliative care with
deep learning,” BMC Medical Informatics and Decision Making,
vol. 18, no. 4, pp. 122, Dec 2018.

[32] Alvin Rajkomar and al.,

“Scalable and accurate deep learning
npj Digital Medicine, vol. 1,
with electronic health records,”
no. 1, pp. 18, 2018, url, An earlier version appeared in eprint
arXiv:1801.07860.

[33] Rupa Makadia and Patrick B. Ryan, “Transforming the premier
perspective® hospital database into the observational medical out-
comes partnership (omop) common data model,” in EGEMS, 2014.

[34] Margaret Mcdonald, Timothy Peng, Sridevi Sridharan, Janice
Foust, Polina Kogan, Liliana Pezzin, and Penny Feldman, “Au-
tomating the medication regimen complexity index,” Journal of
the American Medical Informatics Association : JAMIA, vol. 20,
12 2012.

[35] Ajinkya More, “Survey of resampling techniques for improving
classiﬁcation performance in unbalanced datasets,” arXiv preprint
arXiv:1608.06048, 2016.

Algos

FL-STD & FL-STD-DP (r=1.0)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.2)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.1)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.05)

Parameters
S = 2.15; C = 1/60; N = 6000; Tcl = 200; Tgd = 5; |B| = 10;
|Dk| = 10; n = 1, 663, 370; δ = 10−5; SGD(η = 0.215); σ = 1.54
S = 0.98; C = 1/60; N = 6000; Tcl = 200; Tgd = 5; |B| = 10;
|Dk| = 10; n = 1, 663, 370; δ = 10−5; SGD(η = 0.215);
ηG = 0.35; ρ = 0.9; P = 200; σ = 1.54
S = 0.69; C = 1/60; N = 6000; Tcl = 200; Tgd = 5; |B| = 10;
|Dk| = 10; n = 1, 663, 370; δ = 10−5; SGD(η = 0.215);
ηG = 0.35; ρ = 0.9; P = 200; σ = 1.54
S = 0.47; C = 1/60; N = 6000; Tcl = 200; Tgd = 5; |B| = 10;
|Dk| = 10; n = 1, 663, 370; δ = 10−5; SGD(η = 0.215);
ηG = 0.35; ρ = 0.9; P = 200; σ = 1.54

TABLE 5: Common environment between the schemes on Fashion-MNIST. ρ, ηG and P are only used with FL-CS
and FL-CS-DP.

Algos

FL-STD & FL-STD-DP (r=1.0)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.2)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.1)

FL-CS,FL-RND,FL-FREQ and their private extensions (r=0.05)

Parameters
S = 0.31; C = 100/5011; N = 5011; Tcl = 100; Tgd = 5;
n = 1, 496, 601; δ = 10−5; SGD(η = 0.1) ; σ = 1.49
S = 0.14; C = 100/5011; N = 5011; Tcl = 100; Tgd = 5;
n = 1, 496, 601; δ = 10−5; SGD(η = 0.1); ηG = 1.0; ρ = 0.9; P = 200; σ = 1.49
S = 0.1; C = 100/5011; N = 5011; Tcl = 100; Tgd = 5;
n = 1, 496, 601; δ = 10−5; SGD(η = 0.1); ηG = 1.0; ρ = 0.9; P = 200; σ = 1.49
S = 0.07; C = 100/5011; N = 5011; Tcl = 100; Tgd = 5;
n = 1, 496, 601; δ = 10−5; SGD(η = 0.1); ηG = 1.0; ρ = 0.9; P = 200; σ = 1.49

TABLE 6: Common environment between the schemes on the Medical dataset. ρ, ηG and P are only used with FL-CS
and FL-CS-DP.

[36] Haibo He and Edwardo A Garcia, “Learning from imbalanced
IEEE Transactions on knowledge and data engineering,

data,”
vol. 21, no. 9, pp. 1263–1284, 2009.

[37] Nikita Ivkin, Daniel Rothchild, Enayat Ullah, Ion Stoica, Raman
Arora, et al., “Communication-efﬁcient distributed sgd with sketch-
ing,” in Advances in Neural Information Processing Systems, 2019,
pp. 13144–13154.

[38] Han Xiao, Kashif Rasul, and Roland Vollgraf, “Fashion-mnist:
a novel image dataset for benchmarking machine learning algo-
rithms,” CoRR, vol. abs/1708.07747, 2017.

[39] Franc¸ois Chollet et al., “Keras datasets,” https://keras.io/datasets/,

2015.

[40] Franc¸ois Chollet et al., “Keras,” https://keras.io, 2015.

[41] Mart´ın Abadi, , et al., “TensorFlow: Large-scale machine learning
on heterogeneous systems,” 2015, Software available from tensor-
ﬂow.org.

[42] Travis E Oliphant, A guide to NumPy, vol. 1, Trelgol Publishing

USA, 2006.

[43] Sarang Narkhede,

“Understanding

auc

-

roc

curve,”

https://towardsdatascience.com/understanding-auc-roc-curve-
68b2303cc9c5, 2018.

[44] Kay Henning Brodersen, Cheng Soon Ong, Klaas Enno Stephan,
and Joachim M Buhmann, “The balanced accuracy and its posterior
distribution,” in 2010 20th International Conference on Pattern
Recognition. IEEE, 2010, pp. 3121–3124.

[45] Mohamed Bekkar, Hassiba Djema, and T.A. Alitouche, “Evalua-
tion measures for models assessment over imbalanced data sets,”
Journal of Information Engineering and Applications, vol. 3, pp.
27–38, 01 2013.

[46] H. Brendan McMahan, Daniel Ramage, Kunal Talwar, and
Li Zhang,
language
models,” in International Conference on Learning Representations,
2018.

“Learning differentially private recurrent

[47] Robin C. Geyer, Tassilo Klein, and Moin Nabi, “Differentially
private federated learning: A client level perspective,” CoRR, vol.
abs/1712.07557, 2017.

[50] Hongyi Wang, Scott Sievert, Shengchao Liu, Zachary B. Charles,
“Atomo:
in

Dimitris S. Papailiopoulos, and Stephen Wright,
Communication-efﬁcient learning via atomic sparsiﬁcation,”
NeurIPS, 2018.

[51] Jakub Konecn´y, H. Brendan McMahan, Felix X. Yu, Peter
Richt´arik, Ananda Theertha Suresh, and Dave Bacon,
“Feder-
ated learning: Strategies for improving communication efﬁciency,”
CoRR, vol. abs/1610.05492, 2016.

[52] Jeremy Bernstein, Yu-Xiang Wang, Kamyar Azizzadenesheli, and
Anima Anandkumar, “signsgd: compressed optimisation for non-
convex problems,” CoRR, vol. abs/1802.04434, 2018.

[53] Yujun Lin, Song Han, Huizi Mao, Yu Wang, and Bill Dally, “Deep
gradient compression: Reducing the communication bandwidth for
in International Conference on Learning
distributed training,”
Representations, ICLR 2018, 2018.

[54] Frank Seide, Hao Fu, Jasha Droppo, Gang Li, and Dong Yu, “1-
bit stochastic gradient descent and its application to data-parallel
in INTERSPEECH 2014,
distributed training of speech dnns,”
2014, pp. 1058–1062.

[55] Hossein Mamaghanian, Nadia Khaled, David Atienza, and Pierre
Vandergheynst, “Compressed sensing for real-time energy-efﬁcient
ecg compression on wireless body sensor nodes,” IEEE Transac-
tions on Biomedical Engineering, vol. 58, no. 9, pp. 2456–2466,
2011.

[56] Christopher A Metzler, Arian Maleki, and Richard G Baraniuk,
“From denoising to compressed sensing,” IEEE Transactions on
Information Theory, vol. 62, no. 9, pp. 5117–5144, 2016.

[57] Amin Tavakoli and Ali Pourmohammad, “Image denoising based
on compressed sensing,” International Journal of Computer Theory
and Engineering, vol. 4, no. 2, pp. 266, 2012.

[58] Lean Yu, Yang Zhao, and Ling Tang,

“A compressed sensing
based ai learning paradigm for crude oil price forecasting,” Energy
Economics, vol. 46, pp. 236–245, 2014.

[59] Yang D. Li, Zhenjie Zhang, Marianne Winslett, and Yin Yang,
“Compressive mechanism: Utilizing sparse representation in differ-
ential privacy,” in Proceedings of the 10th Annual ACM Workshop
on Privacy in the Electronic Society, New York, NY, USA, 2011,
WPES ’11, p. 177–182, Association for Computing Machinery.

[48] Dan Alistarh, Jerry Li, Ryota Tomioka, and Milan Vojnovic,
randomized quantization for communication-optimal

“QSGD:
stochastic gradient descent,” CoRR, vol. abs/1610.02132, 2016.

[60] Mohammad Mohammadi Amiri and Deniz G¨und¨uz,

“Machine
learning at the wireless edge: Distributed stochastic gradient de-
scent over-the-air,” CoRR, vol. abs/1901.00844, 2019.

[49] Wei Wen and al., “Terngrad: Ternary gradients to reduce commu-
nication in distributed deep learning,” CoRR, vol. abs/1705.07878,
2017.

[61] Mohammad Mohammadi Amiri and Deniz G¨und¨uz,
erated learning over wireless fading channels,”
abs/1907.09769, 2019.

“Fed-
CoRR, vol.

[62] Peter Kairouz, H Brendan McMahan, Brendan Avent, Aur´elien
Bellet, Mehdi Bennis, Arjun Nitin Bhagoji, Keith Bonawitz,
Zachary Charles, Graham Cormode, Rachel Cummings, et al., “Ad-
vances and open problems in federated learning,” arXiv preprint
arXiv:1912.04977, 2019.

[63] Yo-Seb Jeon, Mohammad Mohammadi Amiri, Jun Li, and H. Vin-
cent Poor, “A compressive sensing approach for federated learning
over massive mimo communication systems,” 2020.

[64] Moses Charikar, Kevin Chen, and Martin Farach-Colton, “Finding
frequent items in data streams,” in International Colloquium on
Automata, Languages, and Programming. Springer, 2002, pp. 693–
703.

[65] Daniel Rothchild, Ashwinee Panda, Enayat Ullah, Nikita Ivkin,
Ion Stoica, Vladimir Braverman, Joseph Gonzalez, and Raman
Arora, “Fetchsgd: Communication-efﬁcient federated learning with
sketching,” 2020.

[66] Josephine Akosa, “Predictive accuracy: a misleading performance
measure for highly imbalanced data,” in Proceedings of the SAS
Global Forum, 2017, pp. 2–5.

Appendix A.
Medical data: Data pre-processing & experi-
mental setup details

This section describes the experimental setting which
is used to evaluate the accuracy and the privacy of our
proposals.

A.1. Preprocessing

1) Features normalization: we extract from the
dataset the values of each feature represented in
Table 1. For gender, we use one-hot encoding:
Male, Female and Unknown. Similarly, for ad-
mission type we use 4 features: Emergency, Ur-
gent, Trauma Center, and Unknown 8. For drugs,
we extract 24,419 features which correspond to
the different drugs (name and dosage). A given
patient receives only a few of the possible drugs
served, resulting in a very sparse patient’s record.
We use a MinMax normalization for age and
MRCI in order to rescale the values of these
features between 0 and 1 (using MinMaxScaler
class of scikit-learn9). The labels that we consider
are boolean:
the patient died
during his hospital stay while false means she
survived.

true means that

2) Patients ﬁltering: We consider patient and drug
information of the ﬁrst day at the hospital so that
we can make predictions 24 hours after admission
(as commonly found in the literature [30], [32]).
We ﬁlter out the pregnant and new-born patients
because the medication types and admission ser-
vices are not the same for theses two categories
of patients. Our model prediction is built without
patients’ historical medical data. This has the ad-
vantage to require minimum patient’s information
and to work for new patients.

3) Hospitals ﬁltering: The dataset contains 415
hospitals for a total size of 1,271,733 records. We

split randomly the dataset into disjoint training
and testing data (80% and 20% respectively). The
ﬁnal dataset for testing contains 254,347 patients,
with 7,882 deceased patients and 246,465 non-
deceased patients (see Table 2).
Using Client-Level differential privacy requires
to add more noise than Record-Level differential
privacy, because the privacy purposes are not
the same as detailled in Section 2. To reduce
the noise (when (cid:15) is ﬁxed) and then improve
the utility, we have to reduce the number of
iterations or to reduce the sampling probability
which are the parameters used to compute (cid:15). We
therefore have two options to reduce the sampling
probability:

-

- Reducing the number of clients selected at
each round |K|. However this option also
decreases the amount of data, and hence
have a negative impact on the utility. We
therefore preferred to use the next option.
Increasing the total number of clients N :
we created more hospitals by splitting ran-
domly the training data over 5011 ”virtual”
hospitals. We also, took care to have at
least one in-hospital dead patient per hos-
pital. Each hospital contains 203 patients
except one which has 356 patients. We
created 5011 hospitals in order to have ap-
proximately the same number of patients
per hospital, each of them with some in-
hospital dead patients.
In practise, Client-Level differential pri-
vacy is more adapted to an environment
with a large set of clients as explained in
[46], [47].

A.2. Imbalanced data

The dataset of each hospital is imbalanced because
the proportion of patients that leave the hospital alive
is, fortunately, much larger than in-hospital dead patients.
To deal with this well-known problem, we have decided
to use downsampling technique [35], [36], a standard
solution used for this purpose. 10

A.3. Performance Metrics

We use the following metrics:

P + TN

N ) = TPR +TNR

• Balanced accuracy [44], [45] is computed as
1/2 · ( TP
and is mainly used
2
with imbalanced data. True Positive Rate (TPR )
and True Negative Rate (TNR ): TPR = TP
P and
TNR = TN
N , where P and N are the number of
positive and negative instances, respectively, and
TP and TN are the number of true positive and
true negative instances. We note that traditional
(“non-balanced”) accuracy metrics such as TP +TN
P +N
can be misleading for very imbalanced data [66]:

8. https://www.resdac.org/cms-data/variables/claim-inpatient-

admission-type-code-ffs

9. https://scikit-learn.org/stable/modules/generated/

sklearn.preprocessing.MinMaxScaler.html

10. We have also tested weighted loss function and oversampling
techniques. But, we noticed experimentally that downsampling technique
outperforms the other techniques for all the schemes.

in our dataset, the minority class has only 3% of all
the training samples (see Table 2), which means
that a biased (and totally useless) model always
predicting the majority class would have a (non-
balanced) accuracy of 97%.

• The area under the ROC curve (AUROC ) is also a
frequently used accuracy metric. The ROC curve
is calculated by varying the prediction threshold
from 1 to 0, when TPR and FPR are calculated
at each threshold. The area under this curve is
then used to measure the quality of the predic-
tions. A random guess has an AUROC value of
0.5, whereas a perfect prediction has the largest
AUROC value of 1.

A.4. Evaluation Method.

First, we split randomly the dataset of each hospital
training and testing data (80% and 20%
into disjoint
respectively). An entire federated run is executed with this
split, and all the metrics are evaluated in every round on
the union of all clients’ testing data. All metric values of
the round with the best balanced metric are recorded.

Algorithm 6: FL-RND

1 Server:
2

Initialize common model w0
for t = 1 to Tcl do

Generate a random seed ζ Select K clients
uniformly at random
for each client k in K do

3

4

5

6

7

8

9

10

11

12

13

14

yk

t = Clientk(wt−1, ζ)

k

(cid:80)N

∆wk
t

|Dk|
j |Dj |

end
yt = (cid:80)
j = 0
for each element i in G do
wt[i] = wt−1[i] + yt[j]
j = j + 1

end

end
Output: Global model wt

18

19

t − wk

t−1, Tgd)

t = wk

t−1, ζ):
t = SGD(Dk, wk
t−1

15
16 Clientk(wk
wk
17
∆wk
Generates a random set G = {x ∈ {1, · · · , n}} of
m random integer values such that m ≤ n based
on the seed ζ
ˆ∆wk
each element of G as a coordinate
Output: The sampled Model update

t =Sample m elements from ∆wk

t by taking

ˆ∆wk

20

t

Algorithm 7: FL-FREQ

1 Server:
2

Initialize common model w0
for t = 1 to Tcl do

Select K clients uniformly at random
for each client k in K do

∆yk

t = Clientk(wt−1)

end
yt = (cid:80)
∆wk
t
ˆyt = Φ−1yt : Transform to time domain
wt = wt−1 + ˆyt

|Dk|
j |Dj |

(cid:80)N

k

end
Output: Global model wt

12
13 Clientk(wk
wk
14
∆wk
Output: The sampled Model update Φ∆wk
t

t−1):
t = SGD(Dk, wk
t−1

t = wk

t−1, Tgd)

t − wk

15

Algorithm 8: FL-RND-DP

1 Server:
2

Initialize common model w0
for t = 1 to Tcl do

Generate a random seed ζ Select K clients
uniformly at random
for each client k in K do

yk

t = Clientk(wt−1, ζ)

k

(cid:80)N

∆wk
t

|Dk|
j |Dj |

end
yt = (cid:80)
j = 0
for each element i in G do
wt[i] = wt−1[i] + yt[j]
j = j + 1

end

end
Output: Global model wt

3

4

5

6

7

8

9

10

11

3

4

5

6

7

8

9

10

11

12

13

14

18

19

t − wk

t−1, Tgd)

t = wk

t−1, ζ):
t = SGD(Dk, wk
t−1

15
16 Clientk(wk
wk
17
∆wk
Generates a random set G = {x ∈ {1, · · · , n}} of
m random integer values such that m ≤ n based
on the seed ζ
ˆ∆wk
each element of G as a coordinate
(cid:19)
ˆ∆wk
Output: EncKk (G( ˆ∆wk

t =Sample m elements from ∆wk

, SIσ/(cid:112)|K|))

(cid:18)
1, || ˆ∆wk

t by taking

= ˆ∆wk

t / max

t ||2
S

21

20

t

t

(cid:48)

(cid:48)

Algorithm 9: FL-FREQ-DP

1 Server:
2

3

4

5

6

7

8

9

10

11

Initialize common model w0
for t = 1 to Tcl do

Select K clients uniformly at random
for each client k in K do

∆yk

t = Clientk(wt−1)

end
yt = (cid:80)
∆wk
t
ˆyt = Φ−1yt : Transform to time domain
wt = wt−1 + ˆyt

|Dk|
j |Dj |

(cid:80)N

k

end
Output: Global model wt

15

t−1):
t = SGD(Dk, wk
t−1

12
13 Clientk(wk
wk
14
∆wk
ˆ∆wk
Output: EncKk (G( ˆ∆wk

t = wk
t = Φ∆wk

t − wk

t / max

16

t−1, Tgd)

(cid:19)

(cid:18)
1, ||C( ˆ∆wk
t , SIσ/(cid:112)|K|))

t ,m)||2
S

