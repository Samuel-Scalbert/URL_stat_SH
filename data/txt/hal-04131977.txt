Exploring heterogeneous data graphs through their
entity paths
Nelly Barret, Antoine Gauquier, Jia-Jean Law, Ioana Manolescu

To cite this version:

Nelly Barret, Antoine Gauquier, Jia-Jean Law, Ioana Manolescu. Exploring heterogeneous data graphs
through their entity paths. ADBIS 2023 - 27th European Conference on Advances in Databases and
Information Systems, Sep 2023, Barcelona, Spain. ￿hal-04131977￿

HAL Id: hal-04131977

https://hal.science/hal-04131977

Submitted on 21 Jun 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Exploring heterogeneous data graphs through their
entity paths

Nelly Barret1[0000−0002−3469−4149], Antoine Gauquier2, Jia Jean Law3, and Ioana
Manolescu1[0000−0002−0425−2462]

1 Inria and Institut Polytechnique de Paris, France
nelly.barret@inria.fr, ioana.manolescu@inria.fr
2 Institut Mines Télécom, France antoine.gauquier@etu.imt-nord-europe.fr
3 Ecole Polytechnique, France jia-jean.law@polytechnique.edu

Abstract. Graphs, and notably RDF graphs, are a prominent way of sharing data.
As data usage democratizes, users need help ﬁguring out the useful content of a
graph dataset. In particular, journalists with whom we collaborate [4] are inter-
ested in identifying, in a graph, the connections between entities, e.g., people,
organizations, emails, etc.
We present a novel, interactive method for exploring data graphs through their
data paths connecting Named Entities (NEs, in short); each data path leads to
a tabular-looking set of results. NEs are extracted from the data through dedi-
cated Information Extraction modules. Our method builds upon the pre-existing
ConnectionLens platform [4,5] and follow-up work on dataset abstraction [8,9].
The contribution of the present work is in the interactive and eﬃcient approach
to enumerate and compute NE paths, based on an algorithm which automatically
recommends subpaths to materialize, and rewrites the path queries using these
subpaths. Our experiments demonstrate the interest of NE paths and the eﬃciency
of our method for computing them.

Keywords: Data graphs · Graph exploration · Information Extraction

1 Motivation and Problem Statement

Data graphs, including RDF knowledge graphs, as well as Property Graphs (PGs), are
often used to represent data. More broadly, any structured or semi-structured dataset
can be viewed as a graph, having: (i) an internal node for each structural element of the
original dataset, e.g., relational tuple, XML element or attribute, JSON map or array,
URI in an RDF graph; (ii) a leaf node for each value in the dataset, e.g., attribute value
in a relational tuple, text node or attribute value in XML, atomic (leaf) value in a JSON
document, or literal in RDF. The connections between the data items in the original
dataset lead to edges in the graph, e.g. parent-child relationships between XML or JSON
nodes, edges connecting each relational tuple node with their attributes, etc. In a rela-
tional database, primary/foreign keys may lead to more edges, e.g., the node represent-
ing an Employee tuple “points to” the Company tuple representing their employer. This
graph view of a dataset has been introduced to support unstructured (keyword-based)
search on (semi)structured data, since [3,15] and through many follow-up works [20].
Entity-rich graphs Building on this idea, the ConnectionLens system [4,5] has been
developed to facilitate, for non-IT users such as data journalists, the exploration of

2

N. Barret et al.

Fig. 1. Sample data graph (top), and corresponding collection graph (bottom) on which paths
linking entities are explored (highlighted areas).

datasets of various models, including relational/CSV, XML, JSON, RDF, and PGs.
ConnectionLens turns any (set of) datasets into a single graph as outlined above. For in-
stance, the data graph at the top of Fig. 1 features RDF triples about NASA spacecrafts
(labeled edges), and an XML document describing presidents who attended spacecraft
launches (tree with labeled nodes and unlabeled edges). ConnectionLens also includes
Information Extraction modules, which extract, from any leaf node in the data graph,
Named Entities (People, Locations and Organizations) [5], as well as other types of
entities that journalists ﬁnd interesting: temporal moments (date, time), Website URIs,
email addresses, and hashtags. We designate any of these pieces of information as en-
tities, and we model them as extra nodes, e.g., in Fig. 1 (top), organizations appear on
a pink background, people on yellow and locations on green, respectively. Each entity
is extracted from a leaf text node, to which it is connected by a dashed edge. When an
entity is extracted from more than one text node, the edges connecting it to those nodes
increase the graph connectivity, e.g., “NASA” extracted from the nodes 15 and 17.
Goal: eﬃcient, interactive exploration of entity connections Journalists are inter-
ested in data paths ending in entity pairs of certain kinds in a given dataset, e.g. in
Fig. 1, “how people are connected to places?”. When shown the set of corresponding
labeled paths, users may pick one to further explore: how many pairs of entities are con-
nected by each path?, which entities are most frequent?, etc. Note that it is important to
consider paths irrespective of the edges directions in the data graph. This is because,

depending on how the data is modeled, we may encounter x

boughtProperty
−−−−−−−−−−→ y

locatedIn
−−−−−−→ c,

hasOwner
←−−−−−−− y

locatedIn
−−−−−−→ c; both paths are interesting.

or x
Challenges and contributions The analysis outlined above raises two challenges. First,
it requires materializing the entity pairs connected by the paths, which may be very
costly, if (i) the graph is large, and/or (ii) there are many paths (the latter is almost

Exploring heterogeneous data graphs through their entity paths

3

always true, if the data is complex/heterogeneous, and/or if we allow paths to traverse
edges in both directions). Second, the large number of paths may overwhelm users.
Non-expert users, or users which are not familiar with the dataset structure, cannot be
expected to state “only the paths that they would like to see”, since they lack technical
expertise and/or dataset knowledge. However, if prompted by the system, they can give
valuable input on whether certain links (or connections) are worth making, or whether
they are just spurious links that would generate uninteresting paths. An example of
uninteresting path is: in a dataset of French national assembly members, all addresses
are in France, thus the France named entity enables connecting any two people.

Our contributions towards addressing these challenges is as follows. (i) From the
data, we generate a small set of user questions, which help us leverage the domain
knowledge that users may have, to generate interesting paths (Sec. 2 and 3). (ii) To speed
up the materialization of interesting paths, we recommend a set of views (subpaths)
to materialize, and rewrite each path query using these materialized views (Sec. 4).
This allows to identify subpaths that appear in more than one path, and compute the
corresponding data paths only once, greatly improving performance (Sec. 5).

2 From datasets to data graphs

In order to propose a general approach that works on any data format (e.g. RDF, JSON,
XML, etc.), we start by building a data graph out of each input dataset (Sec. 2.1). These
graphs may be large, thus enumerating paths on them would be ineﬃcient. Therefore,
we leverage a more compact structure, namely a collection graph (Sec. 2.2). The graph
representation and the collection graph are based on prior work [8,9]. Finally, we ex-
plain how we produce a single collection graph out of several datasets (Sec. 2.3), which
journalists may need to exploit together in a particular investigation.

2.1 From a dataset to a data graph

We transform any dataset as a directed graph G0 = (N0, E0, λ0) where N0 is a set of
nodes, E0 is a set of vertices connecting N0 nodes and λ0 is a function assigning a label
l to each node and edge (l may be empty). We map each data model on G0 as follows.
RDF graphs are naturally mapped on G0: each subject, respectively object, is turned
into a node and an edge labelled with the property is connecting them.
An XML document can be naturally viewed as a tree, with element nodes having el-
ement and attribute children. XML elements may carry #ID attributes whose values
uniquely identify them; other XML elements may carry #IDREF attributes, whose val-
ues act as “foreign keys” referring to other elements by their #ID value. ID-IDREF
information can be supplied in an optional Document Type Description (DTD) or XML
Schema (XSD); when these are not available, ID-IDREF links can be found by proﬁl-
ing [16,1] techniques, which we also implemented. In the graph representation of an
XML document, ID-IDREF links lead to more edges between elements (thus, the graph
is no longer a tree).
JSON documents are also modelled as trees, where each map, array, and leaf value is a
node and parent-child edges are connecting them.

4

N. Barret et al.

Named entities (NE) are extracted from each leaf of the data graph (RDF literal,
XML text node or attribute value, or JSON value). For instance, in Fig. 1, the NASA
organization (pink background) is extracted from both the RDF and XML datasets. Each
extracted NE is materialized by a new node in the graph, connected via an extraction
edge (dashed arrows in Fig. 1) to each leaf text node from which it has been extracted.

2.2 From a data graph to a collection graph

The collection graph is a compact representation of the data graph. It is based on an
equivalence relation between the data graph nodes: the collection graph has exactly one
node for each equivalence class of data graph nodes; further, whenever n1 → n2 is an
edge in the data graph, the collection graph comprises an edge C1 → C2, where C1, C2
are the equivalence classes (also called collections) to which n1, n2 belong, respectively.
The most natural node equivalence relation diﬀers across data models. Speciﬁcally,
XML nodes we consider equivalent are elements with the same name; text nodes that
are children of equivalent elements; and values of same-name attributes of equivalent
elements. For instance, in Fig. 1, the pilot nodes 7 and 8 are equivalent. In JSON, we
consider equivalent nodes found on the same labeled path, from the JSON document
root, to the node. A path is a concatenation of node and edge labels, separated by .
(dots), where we assign special labels: µ to each map node, α to each array node, and
(cid:15) to each empty node or edge label. For instance, in the JSON snippet [{“name”: “Alice”,
“address”: {“street”: “Main”, “city”: “NY”}}] the path to “NY” is: α.(cid:15).address.µ.city. In RDF,
there are numerous ways to deﬁne node equivalence [10]. RDF collection graphs are
built through the TypedStrong summarization method [12], working as follows. When-
ever an RDF node has one or more types, all nodes with the same set of types are said
equivalent (in RDF, a node can have several types, related or not, e.g. Student and Em-
ployee). For nodes without types, TypedStrong summarization relies on the properties
(labels of incoming and outgoing edges) that the nodes have, by introducing a notion of
outgoing/incoming property cliques: (i) two properties that a node have, are in the same
outgoing clique, e.g., agency and pilot are in the same outgoing clique because they are
both property of node 10 in Fig. 1, and also with descr because node 14 has agency
and descr; incoming property cliques are symmetrically deﬁned based on incoming
properties; (ii) two nodes without types are equivalent if they have identical outgoing
and incoming property cliques. For instance, nodes 10 and 14 (the two spacecrafts) are
equivalent, since they have the same outgoing and incoming property cliques.

Fig. 1 (bottom) shows the collection graph corresponding to the data graph. We
named the collections C1, C2, etc. Note that some data models have labeled edges, e.g.,
RDF, while others have (mostly) unlabeled edges, e.g., XML. For uniformity, we trans-
form any labeled edge into a node and extend our summarization also to such nodes.
In Fig. 1, collection C6 contains the nodes introduced instead of the pilot edges in the
RDF dataset. Collection names in our ﬁgure are only for ease of explanation (they are
not required in our method). Some collections, such as C12, C13, have nodes with identi-
cal names, in which case we use that name. For collections such as C1, with RDF nodes
each with a diﬀerent URI, we use an intuitive name, e.g., “Spacecraft”.
Entity collection proﬁles Each leaf collection in the collection graph corresponds to
a set of literals (strings), out of which various NEs may have been extracted. These
collections’ names end with a # to help distinguish them (e.g. C5 agency#). For each

Exploring heterogeneous data graphs through their entity paths

5

such collection C, we compute an entity proﬁle storing how many entities of each type
were extracted from its string nodes. In Fig. 1, there are four such proﬁles, each shown
as a box ﬁlled with the color of an entity type, e.g., the child of C5 is pink reﬂecting the
Organization entities extracted from agency values. In practice, long text nodes often
lead to multiple NEs extracted, of several types. Knowledge of which leaf collections
contain which kind of entities will be crucial to help users explore the graph (Sec. 3).

2.3 From multiple datasets to a collection graph

Journalists often need to work with several datasets, e.g. a JSON collection of political
tweets, the list of French mayors in XML, and an RDF graph of public investment
in companies across France. Such datasets often have common values, e.g., the cities
that mayors represent are also the places where companies are situated. Interesting data
paths can be found across data sources.

To obtain a single collection graph from a set of datasets, we proceed as follows.
First, we build a separated collection graph from each dataset (as in Sec. 2.2). Then,
whenever two collections C1, C2 from distinct datasets share values, we replace them
by a new collection C1,2, which contains the values of C1 and C2, and inherits all the
incoming and outgoing edges of C1 and C2 in the collection graph they came from.
Their original collection graphs are thus connected, and the entity proﬁle of the new
collection C1,2 is built. In Fig. 1, the collection graph reﬂects this uniﬁcation: the pink
ﬁlled node reﬂects organizations from both RDF and XML.

3 Paths between entities

In this section, we discuss categories of paths that users might be interested in, and how
to ask for their input.

An important ﬁrst observation is: by the way we built the collection graph, to each
dataset path corresponds a path in the collection graph. For instance, consider the data

path 13 ← 12
the corresponding path (cid:4) ← C9 ← C8 ← C7 ← C6 ← C1 → C4 → C5 → (cid:4).

agency
−−−−−→ 15 → 16 in Fig. 1. The collection graph features

name
←−−− 11

pilot
←−−− 10

Further, some paths in the collection graph correspond to no paths in the data
graph. For instance, the path C6 ← C1 → C2 does not correspond to any path in the
data, because no spacecraft (part of the collection C1) has both the agency and descr
properties. Such collection paths, with no support in the data, are introduced by sum-
marization, which compresses the graph structure with some information loss. In our
example, the fact that a spacecraft has agency and pilot, another has pilot and descr, and
none has agency and descr is “simpliﬁed” into a collection C1 that may have any combi-
nation of the three properties (represented by collections C2, C4, C6). We consider this
loss of information acceptable in exchange for the ability to work on a much smaller
object (collection graph) instead of a potentially very large data graph.

Based on the above, our approach will be to (i) enumerate paths on the collection
graph, then (ii) turn each path into a query, and (iii) evaluate this query on the data
graph, and show users the resulting actual data connections (if any).

6

N. Barret et al.

3.1 Characterizing entity paths in the collection graph

Each path between two entities is ﬁrst, characterized by a pair of entity types of the
form (τ1, τ2), where τ1, τ2 ∈ E, with E being the set of supported entity types. E contains
entity types such as Person, Location, Organization, Email, URI, Hashtag, Date, etc.

An entity path is also characterized by its length, i.e., the number of edges it con-
tains. Depending on the application, interesting connections can be made by paths of
diﬀerent lengths; however, it appears likely that beyond a length such as 10 or 15, con-
nections may become meaningless. Therefore, and also to control how many collection
paths they want to inspect, users may specify a maximum path length Lmax, whose
default value we set to 10.
Path directionality By deﬁnition, each entity-to-entity collection path cp is of the form:
(cid:3) ← C1 (cid:33) C2 → (cid:4), where (cid:3), (cid:4) are two entity proﬁles, such that the ﬁrst, respectively,
the second, contains some entities of types τ1, respectively, τ2, and C1, C2 are value
collections such as C5 and C9 in the example at the beginning of Sec. 3. The direc-
tions of the leftmost and rightmost edges are by convention always towards (cid:3), (cid:4), which
represent entities. Let cp0 denote the path C1 (cid:33) C2. This path may be:

– Unidirectional, i.e., all cp0 edges go from C1 towards C2, or the opposite;
– Shared-sink, i.e., cp0 may contain a (collection) node C such that all edges between
C1 and C (if any) go from C1 towards C, and all edges between C2 and C (if any)
go from C2 towards C. A shared-sink path is C1 → C6 → C7 ← C10 ← C11.

– Shared-root, i.e., cp0 may contain a (collection) node C such that all edges between
C and C1 (if any) go from C towards C1, and all edges between C and C2 (if any)
go from C towards C2. A shared-root path is C9 ← C8 ← C7 ← C6 ← C1 → C4 →
C5.

– General, i.e., the edges may be in any direction.

Unidirectional paths are quite rare. This is because entity-connecting paths must
have at each end a node from which an entity is extracted. Most of the time, these are two
literal (string) nodes (as opposed to internal nodes structuring the dataset). Literals have
incoming edges, but not outgoing ones (other than those towards extracted entities);
thus, there is no unidirectional path from a literal to another. However, in some RDF
datasets, NEs are extracted from URIs, e.g., the triple https://dbpedia.org/Facebook
locatedIn
−−−−−−→ http://dbpedia.org/California is a unidirectional data path from an Organiza-
tion to a Location. Similarly, shared-sink paths only occur when nodes in C1 and C2
have outgoing edges, and NEs appear in their labels; this only happens in RDF URIs.
Low-speciﬁcity connections Some edges in the data graph reﬂect connections that can
be seen as weak, or non-speciﬁc. In details, let’s ﬁrst consider data edges with non-
a
−→ n2 for some URIs n1, a, n2.
empty labels, e.g., RDF triples. Let e be the edge n1
The speciﬁcity of e, denoted es, is computed as 2/(N1,a + N2,a), where N1,a, N2,a are
the numbers edges labeled a outgoing, resp. incoming n1, resp. n2 [5]. The highest N1,a
and/or N2,a, the lowest es. For instance, the speciﬁcity of each agency edge in Fig. 1 is
2/(1 + 2) = 2/3. For our purposes, we extend speciﬁcity to unlabeled edges as follows:
(cid:15)
−→ n2 is 2/(1 + n1,2) where n1,2 is the number of (cid:15) (empty-
the speciﬁcity of an edge n1
label) edges outgoing n1, towards nodes having the same label as n2. For instance, the
speciﬁcity of the edge between nodes 6 and 7 is also 2/3.

Exploring heterogeneous data graphs through their entity paths

7

In the collection graph, the edges with a non-empty label, connecting nodes from
two equivalence classes lead to a collection, e.g., agency triples lead to C4. We attach
to this collection, the average speciﬁcity of all the data edges it comes from, e.g., to
C4 we attach 2/3. Empty-label edges connecting graph nodes from two equivalence
classes lead to an edge in the collection graph, e.g., C11 → C10. We attach the average
speciﬁcity of the original edges to this edge between two collections.

3.2 Eliciting user input and collection path enumeration

First, we ask users which two entity types they want to connect (thus selecting τ1, τ2).
Next, we ask the maximum path length Lmax (with a default value, currently 10). Then,
we ask how many types of data edges they are willing to review, in order to possibly
decide to disallow paths to traverse such connections; the default value is 5. By type of
data edge, we mean either an edge label, such as agency, or a pair of (parent name, child
name), in case the edge is unlabeled, such as launch-pilot in Fig. 1. Once the user chooses
this value, say nspec, we show her successively the nspec collections (or collection graph
edges) with the lowest average speciﬁcity, and ask if such a collection (or edge) should
be excluded from the paths we search for, or not.

Finally, based on the collection graph, we enumerate all the paths connecting enti-
ties of types τ1, τ2, of maximum length Lmax, and respecting the exclusion constraints
which users may have speciﬁed. We use a simple dynamic programming algorithm,
running in memory, as the collection graph is typically much smaller than the data. We
then inform the user: “There are Nuni unidirectional paths, Nsink shared-sink paths, Nroot
shared-root paths, and Ngen general paths between entities of type τ1 and τ2.” The user
can then either (i) chose to materialize one of these path sets, or (ii) change settings,
e.g., Lmax, nspec, exclude more or less edge types, etc., until the user is satisﬁed with the
predicted number of paths and decides to trigger materialization of a path set (Sec 4).

4 Materializing data paths

At this point, we have a set of collection paths, which must be transformed into queries
and evaluated on the data graph. Each such query matches similar-structure data paths,
thus its results are shown to users as a table: the ﬁrst and last attribute of such a table
comprise entities of type τ1, τ2, while the intermediary attributes are the nodes and
edges connecting these entities in the data graph. For instance, let τ1 be Person, τ2
be Organization: the light-yellow, respectively, light-pink background shapes in Fig. 1
materialize the two paths which, in this graph, connect the pink child of C5 ((cid:4)) with the
yellow children ((cid:4)) of C9, respectively, C15.

4.1 From a collection path to a query over the data graph

Each collection path translates into a chain-shaped conjunctive query. For instance, the
path on yellow background in Fig. 1, going through C5 and C9, becomes:

q1( ¯x) :- n(x1, τOrg, (cid:4)), e(x2, x1, _), n(x2, _, C5), e(x3, x2, agency), n(x3, _, C1),
e(x3, x4, pilot), n(x4, _, C7), e(x4, x5, name), n(x5, _, C9), e(x5, x6, _),
n(x6, τPerson, (cid:4))

This query refers to two relations: n(ID, type, equiv), describing nodes, with the
last attribute denoting their equivalence class, and e(s, d, label), describing edges be-
tween nodes s and d and carrying a certain label. Each xi is a variable; ¯x in the query

8

N. Barret et al.

head denotes all the xi variables, 1 ≤ i ≤ 6. We use _ to denote a variable which
only appears once, in a single query body atom. Finally, τOrg and τPerson denote the
node types of extracted Organization, respectively, extracted Person entity. Similarly,
the pink-background collection path translates into:

q2( ¯x) :- n(x1, τOrg, (cid:4)), e(x2, x1, _), n(x2, _, C3), e(x3, x2, descr), n(x3, _, C1),

e(x3, x4, pilot), n(x4, _, C7), e(x5, x4, _), n(x5, _, C11), e(x6, x5, _), n(x6, _, C12),
e(x6, x7, _), n(x7, _, C14), e(x7, x8, _), n(x8, _, C15), e(x8, x9, _), n(x9, τPerson, (cid:4))
Each of these queries can be evaluated through any standard graph database. How-
ever, evaluating dozens or hundreds of path queries on large graphs can get very costly.
Further, since we do not know which paths may result from the user choices, we cannot
establish path indexes beforehand.
View-based optimization To address this problem, we propose an optimization, based
on the observation that queries resulting from collection paths may share some sub-
paths. For instance, the subquery s(x3, x4) :- n(x3, _, C1), e(x3, x4, pilot), n(x4, _, C7) is
shared by q1( ¯x) and q2( ¯x). Therefore, we decide to (i) evaluate s and store its results;
(ii) rewrite q1( ¯x) and q2( ¯x) by replacing these atoms in each query, by a single occur-
rence of the atom s(x3, x4). The next sections formalize this for larger query sets, also
showing how to handle diﬀerent alternatives that may arise as to which shared subpaths
to materialize.

4.2 Enumerating candidate views

A ﬁrst question we need to solve is enumerating, based on a set Q of path queries, the
possible subqueries that we could materialize, and based on which we could rewrite
some workload queries.

Let q ∈ Q be a path query: it is an alternating sequence of node (n) and edge (e)
atoms. We denote by nq the number of edge atoms, then the number of node atoms is
nq + 1. We denote by nQ the highest nq over all q ∈ Q.

Without loss of generality, our ﬁrst heuristic (H1) is: we only consider connected
subpaths of q as candidate subqueries. If q is of the form q( ¯x) :- n1, e1, . . . , enq , nnq+1,
each connected subpath of q, denoted sq, is determined by two integers 1 ≤ i ≤ nq,
i < j ≤ nq + 1, such that sq(xi, x j) :- ni, ei, . . . , n j, e j, and xi, x j are the IDs of the
nodes in the atoms ni, n j, respectively. We denote by q|i, j the subquery of q determined
by the positions i, j. For instance, when q1 is the sample query in Sec. 4.1, q1|3,4 is
the subquery s(x3, x4) introduced there. Considering connected (cartesian-product free)
candidate views is common in the literature, too (see Sec. 6).

Each query q ∈ Q has O(n2

q) connected subpaths, that can be easily enumerated from
q’s syntax. A second heuristic (H2) we adopt is: we only consider shared subpaths, that
is, those subpaths s for which there exist q(cid:48), q(cid:48)(cid:48) ∈ Q, q(cid:48) (cid:44) q(cid:48)(cid:48), and integers i(cid:48), j(cid:48), i(cid:48)(cid:48), j(cid:48)(cid:48)(cid:48)
such that s = q(cid:48)|i(cid:48), j(cid:48) = q(cid:48)(cid:48)|i(cid:48)(cid:48), j(cid:48)(cid:48)
, possibly after some variable renaming. For the queries
q1, q2 in Sec. 4.1, the subquery s3,4 is q1|3,4 and also q2|3,4. (H2) restricts the number
of candidate views from |Q| × n2
Q to a number that depends on the actual workload Q,
and which decreases when Q paths look more like each other. Another interest of (H2)
is: the beneﬁt of using a view v to rewrite one query q is likely oﬀset by the cost of
materializing v; actual performance improvements start when v is used twice (or more),
which is exactly the case for subqueries shared by several Q queries.

Exploring heterogeneous data graphs through their entity paths

9

Algorithm 1: Selecting views to materialize and the respective view-based
rewritings
Input
Output: Materialized views M and rewritings R for some Q queries

: Queries Q, candidate materialized views V

1 M ← ∅; R ← ∅
2 while V (cid:44) ∅ do
for v ∈ V do
3

4

5

6

7

8

9

10

11

12

13

14

15

16

ben(v) ← 0; cost(v) ← cost to compute and store the view v
for q ∈ Q, q can be rewritten using v do

(ben(v, q), rq,v) ← the cost of evaluating q based on v, through the rewriting
rq,v, minus the cost of evaluating q directly on the graph
ben(v) ← ben(v) + ben(v, q)

(vmax, bmax) ← a view vmax maximizing ben(v) − cost(v), and its beneﬁt
if bmax − cost(vmax) < 0 then

exit

Add vmax to M
for q ∈ Q, q can be rewritten using vmax do

if ben(vmax, q) > 0 then
Add rq,vmax to R
Remove q from Q

Remove vmax from V

Our third heuristic (H3) is: among the possible subqueries shared by two queries
q(cid:48), q(cid:48)(cid:48), consider only the longest ones. That is, if s1, s2 are two shared subqueries of q(cid:48)
and q(cid:48)(cid:48) such that ns1 > ns2 , do not consider the subquery s2.

Our heuristics (H1), (H2), (H3) lead to building the candidate view set V as
follows. For each pair of distinct queries (q(cid:48), q(cid:48)(cid:48)) where q(cid:48), q(cid:48)(cid:48) ∈ Q, add to V the
longest, shared, connected subqueries of q(cid:48) and q(cid:48)(cid:48). The complexity of this algorithm is
O(|Q|2 × n2

Q), while |V| is in O(|Q|2).

4.3 Selecting materialized views and rewriting path queries

Knowing the path queries Q and the candidate view set V, we need to determine: a set
M ⊆ V of views which we actually materialize, in order to rewrite some Q queries.
We collect the rewriting of each such queries in R. The decision to materialize a view
incurs a cost, since the view data must be computed and stored. We denote cost(·) the
cost of evaluating a view (or query), and assume it can be computed without actually
computing it. Materializing a view is more attractive if (i) rewritings using it reduce
signiﬁcantly query evaluation costs, and (ii) its own materialization cost is small.

In the most general case, a query could be rewritten based on any number of views,
and also involving the base graph. For instance, query q1 from Sec. 4.1 could be rewrit-
ten as: q1|1,3 (cid:46)(cid:47) q1|3,4 (cid:46)(cid:47) q1|4,6, where each (cid:46)(cid:47) denotes a natural join, on the variables
x3, respectively, x4. However, enumerating all such alternatives makes the query rewrit-
ing problem NP-hard [14]. Instead, we adopt another pragmatic heuristic (H4): rewrite

10

N. Barret et al.

each query using not more than one view. This simple choice keeps the view selection
complexity under control, all the while providing good performance.

Algorithm 1 depicts our greedy method for ﬁnding M and V. It computes the
beneﬁt of each view v for each query that may be rewritten using v, as well as the cost
of v. In a greedy fashion, it decides to materialize the view vmax maximizing the overall
beneﬁt (for all Q queries), and uses it to rewrite all queries whose evaluation cost can
be reduced thanks to vmax, via the rewriting rq,vmax . These queries are then removed from
Q, the beneﬁts of the remaining views are recomputed over the diminished Q, and the
process repeats until no proﬁtable view to materialize can be found.

Estimating costs Algorithm 1 needs to compute: (i) cost(·), the cost to evaluate a query
q or materialize a view v; (ii) rq,v, the rewriting of q using a view v; and (iii) cost(rq,v),
the cost of such a rewriting. All these costs must be estimated before any query or view
results are computed. We do this as follows. For (i), we use the cost estimation of the
graph data management system (GDBM, in short) storing the graph. Our implementa-
tion relies on PostgreSQL, whose explain command returns both the estimated number
of results of certain query (or view), denoted size(q), and the cost of computing those
results. For (ii), recall (Sec. 4.2) that when v is used to rewrite q, v is a subpath of q,
thus there exist i, j such that v = q|i, j. The rewriting rq,v is easily obtained by replacing,
in the body of q, the atoms from the ith to the jth, with the head of v. Handling (iii) is
more complex than (i). This is because the cost of a query (or view) is estimated based
on statistics the GDBM has about the stored graph. In contrast, the GDBM cannot es-
timate cost of rq,v, because v has not been materialized yet, thus the GDBM cannot
reason about v like it does about the graph. To compensate, we proceed as follows: we
compute the cost of reading the hypothetical view vmax from the database, by multiply-
ing size(vmax), the estimation of the view size, with a constant (we used Postgres’ own
CPU_TUPLE_COST); then, we estimate the cost of rq,vmax as this reading cost plus the
cost of estimating the parts of q not in vmax plus the cost of joining vmax with these (one
or two) remaining query parts. We estimate the cost of each such join by adding their
input sizes, which we then multiply with another (GDBM) constant. This reﬂects the
fact that modern databases feature eﬃcient join algorithms, such as memory-based hash
joins, whose complexity is linear in the size of their inputs.
Complexity Algorithm 1 makes at most O(|V| × |Q|) iterations, which can be simpliﬁed
into O(|Q|3). Forming a rewriting takes O(nQ), bringing the total to O(|Q|3 × nQ).
Impact of heuristics As previously discussed, (H1) is universally adopted in the liter-
ature: no candidate view features cartesian products. (H2), imposing that views beneﬁt
at least two queries, preserves result quality, i.e., cost savings, under every monotone
cost model, ensuring that the cost of evaluating a query q is at least that of evaluating s,
when s is a subquery of q. In contrast, (H3) and (H4) may each divert from the globally
optimal solution. However, as our experiments show, our chosen rewritings perform
well in practice, and the algorithm itself is very eﬃcient.

5 Experimental evaluation

Our approach is fully implemented in Java 11, on top of ConnectionLens [4,5] which
builds the data graph (Sec. 2.1) and Abstra [8,9] which builds the collection graph
(Sec. 2.2); these are stored in PostgreSQL. We experimented on a Linux server with an

Exploring heterogeneous data graphs through their entity paths

11

|E|

|N|

|τL|

|τP|

|τO| min(es)
Dataset name
0.001
PubMed
690 4,530 0.0002
Nasa
YelpBusiness
0.001
427 1,437
YelpBusiness4 229,949 247,074 1,099 1,230 4,199 0.0002
Table 1. Dataset overview.

63,052 89,710 5,993 2,151 5,096
59,408 128,068
57,963 61,627

634
322

Intel Xeon Gold 5218 CPU @ 2.30 GHz and 196GB of RAM. We used PostgreSQL
v9.6. Our system is available at: https://team.inria.fr/cedar/projects/pathways/.
Our evaluation seeks to answer the two following questions: (i) how are entities con-
nected in each dataset? (Section 5.2) and (ii) does Algorithm 1 help to evaluate paths
queries over the data graph? (Section 5.3).

5.1 Datasets and settings

We present experiments on an XML, an RDF and a JSON dataset. They all come from
real-life applications (as opposed to synthetic) to stay close to application needs, and
to ensure realistic Named Entities (NEs). Indeed, synthetic datasets are often generated
with an interest on structure, while the leaf (text) values lack interesting information.

We used an XML PubMed subset describing scientiﬁc articles from PubMed, a
database of biomedical publications. Each article is described by its title, journal, link,
year, DOI, keywords list and authors list. Authors are identiﬁed by their name and their
aﬃliation; they may declare their conﬂicts of interest in the <COIStatement> tag. We
used the RDF Nasa dataset, describing NASA ﬂights, spacecrafts involved in launches,
related space missions and the participating agencies. Finally, we used the JSON Yelp-
Business dataset where each business has an id, a name, an address, a city, a state, a
postal code and coordinates (latitude and longitude). It also has a set of categories (e.g.
bakery, shoe store, etc.) and a set of attributes (e.g. acceptCreditCards), the latter
may be deeply nested. They also received reviews from customers modeled as a num-
ber of stars (from 0 to 5) and the number of reviews. YelpBusiness4, 4 times larger
than YelpBusiness, allows studying the scalability of our algorithm. Tab. 1 shows for
each dataset: its number of nodes |N|, edges |E|, numbers of extracted NEs |τP|, |τL|, |τO|
and the minimum edge speciﬁcity min(es). Without loss of generality, we experiment
with the NE types Person, Location, Organization, whose types are denoted τP, τL, τO,
respectively. We set Lmax to 10, and avoided connections whose assigned speciﬁcity
(Sec. 3) was less than 5% of the average speciﬁcity over all node/edge collections.

5.2 Path enumeration

For each dataset and pair of entity types, Fig. 2 and 3 report the number of paths of
each directionality (Sec. 3.1), the minimum and maximum length Lp of each path, and
the minimum and maximum data path support (number of results when evaluated on the
data), this is denoted S p. For the PubMed (XML) and YelpBusiness (JSON) datasets, we
obtained only shared-root paths: this is because of the tree structure of these datasets,
where text values (leaves) are only connected by going through a common ancestor
node. In the RDF Nasa dataset, we also found general-directionality paths. The JSON
datasets are more irregular, leading to more paths. In almost every case, a few collection
paths had 0 support, due to dataset summarization (Sec. 3). The maximum support may
be high, e.g. 15,181 in the PubMed dataset.

12

N. Barret et al.

(τ1, τ2) Nroot min(S p) max(S p)
(τP, τO)
13,988
(τP, τL)
15,181
(τL, τO)
5,054
(τP, τP)
389
(τL, τL)
1,214
(τO, τO)
3,090

21
21
21
21
21
21

0
0
0
0
0
3

(τ1, τ2) Nroot Ngen min(S p) max(S p)
(τP, τO)
629
1
(τP, τL)
137
5
(τL, τO)
603
3
(τP, τP)
89
3
(τL, τL)
3,050
3
(τO, τO)
8,960
3

99
95
97
97
97
97

0
0
0
0
0
0

Fig. 2. Entity paths in PubMed (left) and Nasa (right). PubMed: min(Lp) = 5; max(Lp) = 8. Nasa:
min(Lp) = 5; max(Lp) = 9.
(τ1, τ2) Nroot max(Lp) min(S p) max(S p)
(τP, τO)
651
(τP, τL)
193
(τL, τO)
1,412
(τP, τP)
35
(τL, τL)
158
(τO, τO)
1,232

(τ1, τ2) Nroot max(Lp) min(S p) max(S p)
(τP, τO)
2,593
(τP, τL)
760
(τL, τO)
258
(τP, τP)
207
(τL, τL)
674
(τO, τO)
4,889

41
33
21
28
15
21

48
39
39
36
15
21

7
7
5
7
5
5

0
0
0
0
2
0

7
7
5
7
5
5

0
0
0
0
0
0

Fig. 3. Entity paths in the YelpBusiness (left) and YelpBusiness4 (right) datasets. YelpBusiness
and YelpBusiness4: min(Lp) = 5.

(τ1, τ2)

T0

|QT O| |QNV | |V| |M|

TR
PubMed

TQNV T = TR + TQNV s = T0/T

(τP, τO) 250.36
(τP, τL)
37.29
(τL, τO) 151.29
(τP, τP) 152.59
(τL, τL) 169.64
(τO, τO) 317.92

(τP, τO) 195.47
(τP, τL) 254.26
(τL, τO) 1073.55
(τP, τP) 278.95
(τL, τL) 1103.48
(τO, τO) 1318.78

5
0
2
3
2
5

1
3
32
4
30
37

1 16
1 16
2 16
1 16
1 16
1 16

5
3.78 0.32
5 19.06 0.32
5 11.88 8.59
5 44.19 0.08
5 71.32 0.31
5 22.99 0.25
Nasa
0 80 10 54.14 N/A
0 68 10 44.57 N/A
9 131.58 N/A
0 77
0 76 10 92.01 N/A
9 101.35 N/A
0 77
9 247.43 N/A
0 77

4.10
19.38
20.47
44.27
71.63
23.24

54.14
44.57
131.58
92.01
101.35
247.43

61×
2×
7×
3×
2×
13×

3×
5×
8×
3×
10×
5×

Table 2. Data paths evaluation on the PubMed and Nasa datasets.

These results show that numerous interesting entity paths exist in our datasets, of
signiﬁcant length (up to 9), and some with high support, bringing the need for an eﬃ-
cient evaluation method.

5.3 Eﬃciency of path evaluation

We now study the eﬃciency of data path computations over the graph. Tab. 2 and Tab. 3
show, for each dataset and entity type pair, T0 is the time to evaluate the corresponding
path queries without the view-based optimization of Sec. 4.2 and 4.3, referred to as
VBO from now on. |QT O| is the number of queries whose execution we stopped (time-
out of 30s) without VBO. |QNV | is the number of queries for which Algo. 1 did not
recommend a view. TR is the time to evaluate the rewritten queries on the data graph,

Exploring heterogeneous data graphs through their entity paths

13

(τ1, τ2)

T0

|QT O| |QNV | |V| |M| TR

TQNV T = TR + TQNV s = T0/T

(τP, τO) 205.95
(τP, τL) 410.87
(τL, τO) 239.90
(τP, τP) 466.58
(τL, τL) 450.00
(τO, τO) 334.22

2
7
0
9
15
4

YelpBusiness

6 4.20 N/A
0 22
1.27
1 19
5 40.87
1 20 10 1.15
0.6
5 15.33 12.02
2 23
4 9.89 < 0.01
1
8
5 2.83 < 0.01
1 10

YelpBusiness4

4.20
42.12
1.75
27.35
9.89
2.83

(τP, τO) 804.70
(τP, τL) 454.19
(τL, τO) 242.57
(τP, τP) 317.00
(τL, τL) 395.49
(τO, τO) 347.23

6 62.52 N/A
5 92.50 < 0.01
6.61
5 62.74
7 14.35
1.08
4 2.62 18.15
2.34
5 42.93
Table 3. Data path evaluation on the YelpBusiness datasets.

62.52
92.50
69.35
15.43
20.77
45.27

0 23
1 20
1 10
1 27
1
8
1 10

26
10
5
7
10
8

49×
9×
137×
17×
45×
118×

12×
5×
3×
20×
19×
7×

while TQNV is the time to evaluate the non-rewritten queries QNV ; T = TR + TQNV is the
(total) execution time to evaluate queries using VBO. Finally, s = T0/T is the speed-up
due to VBO. We do not report times to materialize views because they were all very
short (less than 0.01s). All times are in seconds.

The evaluation time T0 without VBO ranges from 100s to 2000s; these path queries
require 5 to 9 joins, on graphs of up to more than 200,000 edges (Tab. 1). |QNV |, the num-
ber of queries that could not make use of any views, is rather small, which is good. The
number of candidate views, respectively, materialized views depend on the complexity
of the dataset, and thus on the complexity of the paths. The total path evaluation time T
is reasonable. Finally, the VBO speed-up is at least 2× and at most 137×, showing that
our view-based algorithm allows to evaluate path queries much more eﬃciently.

5.4 Experiment conclusion

On graph leading to entity paths of various lengths and support, the view-based rewrit-
ing signiﬁcantly reduces the path query evaluation time over the data graph.

6 Related work and conclusion

Many graph exploration methods exist, see, e.g., [18]. Modern graph query languages
such as GPML [11] (no implementation so far) or the JEDI [2] SPARQL extension
allow checking for paths between query variables, if users can specify a regular expres-
sion that the path labels match. Other systems interact with users to incrementally build
SPARQL queries, In keyword-based search (KBS, in short) [3,5,20], one asks for con-
nections between two or more nodes matching speciﬁc keywords. KBS is handy when
users know keywords (entities) to search for. In [6], graph queries are extended with
a KBS primitive. The algorithms proposed there work directly on the graph; ﬁnding
such trees in general is NP-hard, since it is related to the Group Steiner Tree problem.
Complementary to these, we focus on identifying, and eﬃciently computing, all paths
between certain extracted entities, to give a ﬁrst global look at the dataset content, for
graphs obtained from multiple data models.

14

N. Barret et al.

Our view selection problem is a restriction (to path-only queries) of those consid-
ered, e.g., in [13,14,17,19]. This allows for its low complexity, while being very eﬀec-
tive. Our algorithms rely on collection graphs built by Abstra [8,9], the interactive path
enumeration approach, including VBO, is novel; it has been demonstrated in [7].

Acknowledgments This work has been funded by the DIM RFSI PHD 2020-01 project
and the AI Chair SourcesSay (ANR-20-CHIA-0015-01) chair.

References

1. Abedjan, Z., Golab, L., Naumann, F., Papenbrock, T.: Data Proﬁling. Synthesis Lectures on

Data Management, Morgan & Claypool Publishers (2018)

2. Aebeloe, C., Setty, V., Montoya, G., Hose, K.: Top-K Diversiﬁcation for Path Queries in

Knowledge Graphs. In: ISWC Workshops (2018)

3. Agrawal, S., Chaudhuri, S., Das, G.: DBXplorer: A system for keyword-based search over

relational databases. In: ICDE (2002)

4. Anadiotis, A., Balalau, O., Bouganim, T., et al.: Empowering investigative journalism with

graph-based heterogeneous data management. IEEE DEBull. (2021)

5. Anadiotis, A., Balalau, O., Conceicao, C., et al.: Graph integration of structured, semistruc-

tured and unstructured data for data journalism. Inf. Systems 104 (2022)

6. Anadiotis, A.C., Manolescu, I., Mohanty, M.: Integrating Connection Search in Graph

Queries. In: ICDE (Apr 2023)

7. Barret, N., Gauquier, A., Law, J.J., Manolescu, I.: Pathways: entity-focused exploration of

heterogeneous data graphs (demonstration). In: ESWC (2023)

8. Barret, N., Manolescu, I., Upadhyay, P.: Abstra: toward generic abstractions for data of any

model (demonstration). In: CIKM (2022)

9. Barret, N., Manolescu, I., Upadhyay, P.: Computing generic abstractions from application

datasets. In: EDBT (2024)

10. Cebiric, S., Goasdoué, F., Kondylakis, H., Kotzinos, D., Manolescu, I., Troullinou, G.,
Zneika, M.: Summarizing Semantic Graphs: A Survey. The VLDB Journal 28(3) (Jun 2019)
11. Deutsch, A., Francis, N., Green, A., Hare, K., Li, B., Libkin, L., et al.: Graph pattern match-

ing in GQL and SQL/PGQ. In: SIGMOD (2022)

12. Goasdoué, F., Guzewicz, P., Manolescu, I.: RDF graph summarization for ﬁrst-sight structure

discovery. The VLDB Journal 29(5) (Apr 2020)

13. Goasdoué, F., Karanasos, K., Leblay, J., Manolescu, I.: View selection in semantic web

databases. PVLDB 5(2) (2011)

14. Halevy, A.Y.: Answering queries using views: A survey. VLDB J. 10(4) (2001)
15. Hristidis, V., Papakonstantinou, Y., Balmin, A.: Keyword proximity search on XML graphs.

In: ICDE (2003)

16. Jiang, L., Naumann, F.: Holistic primary key and foreign key detection. J. Intell. Inf. Syst.

54(3) (2020)

17. Le, W., Kementsietsidis, A., Duan, S., et al.: Scalable multi-query optimization for SPARQL.

In: ICDE (2012)

18. Lissandrini, M., Mottin, D., Hose, K., Pedersen, T.B.: Knowledge graph exploration systems:

are we lost? In: CIDR. www.cidrdb.org (2022)

19. Mistry, H., Roy, P., Sudarshan, S., Ramamritham, K.: Materialized view selection and main-

tenance using multi-query optimization. SIGMOD Rec. 30(2), 307–318 (may 2001)

20. Yang, J., Yao, W., Zhang, W.: Keyword search on large graphs: A survey. Data Sci. Eng. 6(2)

(2021)

