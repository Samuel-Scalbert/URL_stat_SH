Uma abordagem para coleta e análise de dados de
configurações em redes neurais profundas
Débora Pina, Liliane Kunstmann, Daniel de Oliveira, Patrick Valduriez,

Marta Mattoso

To cite this version:

Débora Pina, Liliane Kunstmann, Daniel de Oliveira, Patrick Valduriez, Marta Mattoso. Uma abor-
dagem para coleta e análise de dados de configurações em redes neurais profundas. SBBD 2020 - 35ª
Simpósio Brasileiro de Banco de Dados, Sep 2020, Virtual, Brazil. pp.1-6, ￿10.5753/sbbd.2020.13639￿.
￿lirmm-02969506￿

HAL Id: lirmm-02969506

https://hal-lirmm.ccsd.cnrs.fr/lirmm-02969506

Submitted on 16 Oct 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Uma abordagem para coleta e an´alise de dados de conﬁgurac¸ ˜oes
em redes neurais profundas ∗

D´ebora Pina1, Liliane Kunstmann1, Daniel de Oliveira2,
Patrick Valduriez3, Marta Mattoso1

1Universidade Federal do Rio de Janeiro (PESC/COPPE/UFRJ), Brasil

{dbpina, lneves, marta}@cos.ufrj.br

2Universidade Federal Fluminense (IC/UFF), Brasil

danielcmo@ic.uff.br

3Inria, University of Montpellier, CNRS, LIRMM, Franc¸a

Patrick.Valduriez@inria.fr

Resumo. O tempo de durac¸ ˜ao do ciclo de vida no aprendizado por meio de redes
neurais profundas depende do acerto em decis˜oes de conﬁgurac¸ ˜ao de dados que le-
vem ao sucesso na obtenc¸ ˜ao de modelos. A an´alise de hiperparˆametros e dados da
evoluc¸ ˜ao da rede permite adaptac¸ ˜oes que diminuem o tempo de durac¸ ˜ao do ciclo de
vida. No entanto, h´a desaﬁos n˜ao apenas na coleta de hiperparˆametros, mas tamb´em
na modelagem dos relacionamentos entre esses dados. Este trabalho apresenta uma
abordagem centrada em dados de proveniˆencia para enfrentar esses desaﬁos, pro-
pondo uma coleta com ﬂexibilidade na escolha e representac¸ ˜ao de dados a serem
analisados. Experimentos com a abordagem junto ao Keras, usando uma aplicac¸ ˜ao
real com uma rede neural convolucional, d˜ao evidˆencias da ﬂexibilidade, eﬁciˆencia
da coleta de dados, an´alise e validac¸ ˜ao dos dados da rede.

Abstract. The duration of the life cycle in deep neural networks depends on the data
conﬁguration decisions that lead to success in obtaining models. Analyzing hyper-
parameters along the evolution of the network’s execution allows adapting the data,
thus reducing the life cycle time. However, there are challenges not only in collec-
ting hyperparameters, but also in modeling the relationships between these data. This
work presents a provenance data based approach to address these challenges, propo-
sing a collection mechanism with ﬂexibility in the choice and representation of data
to be analyzed. Experiments of the approach with Keras, using a real application pro-
vide evidence of the ﬂexibility, the efﬁciency of data collection, the analysis and the
validation of network data.

1. Introduc¸ ˜ao

Nos ´ultimos anos, a comunidade cient´ıﬁca tem presenciado um aumento na populari-
dade de aplicac¸ ˜oes em t´ecnicas de aprendizado profundo (i.e., Deep Learning ou AP)
[Gharibi et al. 2019, Miao et al. 2017], incluindo as PINNs, redes neurais profundas guiadas
pelas leis da F´ısica na soluc¸ ˜ao de problemas em ciˆencia computacional [Raissi et al. 2017].

∗Este trabalho foi realizado com apoio da Coordenac¸ ˜ao de Aperfeic¸oamento de Pessoal de N´ıvel Superior -

Brasil (CAPES) - C´odigo de Financiamento 001, CNPq, FAPERJ e INRIA.

AP ´e o termo usado para denotar o problema de treinar redes neurais profundas e permitir
inferˆencias, como a rede neural convolucional (CNN) [Badan and Sekanina 2019]. O treina-
mento das CNNs busca pela conﬁgurac¸ ˜ao de uma s´erie de hiperparˆametros (p. ex., taxa de
aprendizado, batch size, n´umero de ´epocas, momentum e dropout) que levem `a validac¸ ˜ao dos
resultados. As CNNs s˜ao particularmente sens´ıveis `a deﬁnic¸ ˜ao de hiperparˆametros. Essas
deﬁnic¸ ˜oes dependem da evoluc¸ ˜ao do comportamento dos dados, s´o conhecido durante ou ao
t´ermino da execuc¸ ˜ao do treinamento. Adaptac¸ ˜oes a essas decis˜oes s˜ao realizadas em um pro-
cesso de tentativa e erro at´e se atingir a validac¸ ˜ao dos resultados [Zaharia et al. 2018]. A etapa
de treinamento torna o ciclo de vida da CNN computacionalmente custoso, cansativo e pro-
penso a erros. Apesar de soluc¸ ˜oes de otimizac¸ ˜ao autom´atica de hiperparˆametros, como o Cloud
Auto ML1, e [Badan and Sekanina 2019], a an´alise de dados junto `a conﬁgurac¸ ˜ao ´e necess´aria.
O uso de dados de proveniˆencia [Moreau and Groth 2013] vem sendo proposto para contri-
buir para a ﬂexibilidade da representac¸ ˜ao e an´alise de dados quando especializados para AP
[Breck et al. 2019, Caveness et al. 2020]. Uma vantagem no uso de dados de proveniˆencia ´e a
padronizac¸ ˜ao na representac¸ ˜ao de metadados e a derivac¸ ˜ao dos dados ao longo do treinamento
da CNN por meio do PROV-DM do W3C [Moreau and Groth 2013].

A avaliac¸ ˜ao das diversas conﬁgurac¸ ˜oes de hiperparˆametros exige que seja feita a relac¸ ˜ao
entre v´arios tipos de dados e metadados, p. ex., m´etricas como acur´acia, dados do ambiente
computacional utilizado para o treinamento da CNN [Zaharia et al. 2018]. Soluc¸ ˜oes de coleta
autom´atica de dados para an´alise tendem a ser pouco ﬂex´ıveis quanto `a escolha do que ser´a
coletado e principalmente sobre como esses dados s˜ao analisados. Soluc¸ ˜oes com ﬂexibilidade
na coleta e an´alise de dados de proveniˆencia como em [Pina et al. 2019] exigem uma etapa de
modelagem que pode ser uma barreira para a adoc¸ ˜ao de ferramentas de proveniˆencia.

Este artigo apresenta uma abordagem centrada em dados de proveniˆencia, propondo um
mecanismo de coleta autom´atica, por´em com ﬂexibilidade na escolha de dados a serem coleta-
dos e analisados. A abordagem foi baseada na CNNProv [Pina et al. 2019] e implementada por
meio do Keras-Prov, uma extens˜ao do Keras2, que ´e uma API que executa sobre a plataforma de
AP TensorFlow3. O objetivo do Keras-Prov ´e reduzir as ac¸ ˜oes que o usu´ario deve realizar para
a an´alise de dados, em especial hiperparˆametros, durante o treinamento de CNNs. Ao adotar o
padr˜ao W3C PROV-DM, o Keras-Prov provˆe uma representac¸ ˜ao de dados p´ublica, extens´ıvel e
adotada em diversos dom´ınios de aplicac¸ ˜ao, o que facilita a interoperabilidade. O Keras-Prov
´e capaz de rastrear as transformac¸ ˜oes de dados e conjuntos de dados relacionados aos hiper-
parˆametros e m´etricas do treinamento da CNN de modo autom´atico. O armazenamento dos
dados de proveniˆencia e adaptac¸ ˜oes dos usu´arios em conﬁgurac¸ ˜oes em SGBDs permite que os
dados ao longo do treinamento sejam analisados globalmente. Por ser poss´ıvel estender o es-
quema da base de dados de proveniˆencia, dados do dom´ınio da aplicac¸ ˜ao podem ser modelados
e acrescentados `a base de proveniˆencia ao serem coletados ao longo do treinamento. Experi-
mentos realizados com a DenseED, uma aplicac¸ ˜ao real de CNN densa guiada por leis da F´ısica,
mostram a adequac¸ ˜ao do Keras-Prov para a an´alise de hiperparˆametros de CNNs e o baixo
impacto no desempenho da API no Keras. Al´em desta introduc¸ ˜ao, este artigo cont´em outras
quatro sec¸ ˜oes. A Sec¸ ˜ao 2 discute os trabalhos relacionados, a Sec¸ ˜ao 3 apresenta a abordagem
Keras-Prov, a Sec¸ ˜ao 4 os experimentos e, ﬁnalmente, a Sec¸ ˜ao 5 conclui este artigo.

1https://cloud.google.com/automl
2https://keras.io/
3www.tensorflow.org/

2. Trabalhos Relacionados

H´a um crescente uso de dados de proveniˆencia em aprendizado de m´aquina (AM)
[Schelter et al. 2017, Tsay et al. 2018, Miao et al. 2017]. No entanto, n˜ao foram encontradas
abordagens que oferec¸am funcionalidades do Keras-Prov (i.e., utilizac¸ ˜ao de dados de pro-
veniˆencia especiﬁcamente na fase de treinamento de CNNs, possibilidade de realizar a an´alise
online, ﬂexibilidade quanto `a escolha do que vai ser coletado e a extens˜ao para coleta de outros
dados, independˆencia de portal, e com baixa sobrecarga). O ModelHub [Miao et al. 2017] ´e
um sistema para gerˆencia do ciclo de vida de redes neurais profundas cujo objetivo ´e armaze-
nar pesos de modelos em diferentes vers˜oes, com foco no AP. O ModelHub possui um modelo
propriet´ario para representac¸ ˜ao dos metadados do treinamento da rede neural, o que diﬁculta a
interoperabilidade. A ferramenta Runway [Tsay et al. 2018] tem como objetivo a gerˆencia de
artefatos de AM e AP, como modelos, dados ou experimentos. A soluc¸ ˜ao permite rastrear o
modelo e os dados desde o uso no treinamento at´e a implementac¸ ˜ao, facilitando a reprodutibili-
dade. No entanto, al´em de ser uma soluc¸ ˜ao propriet´aria, ´e restrita `a linguagem de programac¸ ˜ao
Python. [Schelter et al. 2017] prop˜oem uma ferramenta automatizada para extrair os metada-
dos do modelo e apresent´a-los com uma visualizac¸ ˜ao interativa para auxiliar na comparac¸ ˜ao
de experimentos. Dessa forma, essa soluc¸ ˜ao concentra-se no rastreamento de metadados e na
proveniˆencia dos dados de experimentac¸ ˜ao de AM. Por´em, a abordagem proposta n˜ao utiliza
padr˜oes de representac¸ ˜ao, como o W3C PROV, afetando a interoperabilidade. Essas soluc¸ ˜oes
preveem o uso de AM para aplicac¸ ˜oes de neg´ocios. Keras-Prov herda os benef´ıcios da DfA-
nalyzer [Silva et al. 2018] para acomodar dados cient´ıﬁcos junto `a proveniˆencia e execuc¸ ˜ao em
ambientes de processamento de alto desempenho, facilitando seu uso em PINNs.

3. Abordagem centrada em dados: Keras-Prov

O objetivo principal do Keras-Prov ´e reduzir o esforc¸o de adaptac¸ ˜ao do c´odigo para captura de
dados de proveniˆencia (uma vez que o Keras n˜ao captura tais dados de forma nativa) durante o
treinamento da CNN. O Keras foi escolhido por ser uma API de rede neural de c´odigo aberto
muito utilizada e com documentac¸ ˜ao dispon´ıvel. A arquitetura do Keras-Prov ´e apresentada
na Figura 1, e ´e composta de trˆes camadas: (i) Treinamento, (ii) Dados e (iii) An´alise. A ca-
mada de Treinamento ´e onde o Keras ´e executado e interage com bibliotecas de AP como o
TensorFlow e o Theano. ´E importante ressaltar que o Keras teve seu c´odigo modiﬁcado para
capturar os hiperparˆametros mais comuns e enviar seus valores para o Extrator de Proveniˆencia.
O Keras-Prov identiﬁca automaticamente as transformac¸ ˜oes de dados no c´odigo do usu´ario, os
hiperparˆametros e seus valores utilizados em cada treinamento, assim como as m´etricas coleta-
das. O Extrator recebe os dados assincronamente e os grava na camada de Dados. O banco de
dados de proveniˆencia segue o esquema da Figura 3, que estende o Prov-Df [Silva et al. 2017].
A Figura 3 representa em termos dos conceitos Agente (Agent), Atividade (Activity) e Entidade
(Entity) do W3C PROV as transformac¸ ˜oes de dados do processo de treinamento das CNNs e os
hiperparˆametros. Al´em dos dados de proveniˆencia, o modelo treinado tamb´em ´e armazenado
na camada de dados. O Visualizador de proveniˆencia gera uma representac¸ ˜ao visual do grafo
de proveniˆencia, de forma a facilitar a an´alise por parte do usu´ario. Tais componentes s˜ao ex-
tens´ıveis, de forma que diferentes bibliotecas de treinamento de CNNs podem ser acopladas
para capturar e armazenar hiperparˆametros e outros dados de treinamento.

Para utilizar o Keras-Prov ´e necess´ario que o usu´ario deﬁna no c´odigo quais os hiper-
parˆametros devem ser capturados e armazenados, com base na lista disponibilizada, deﬁnindo
com o valor True ou False. O trecho de c´odigo na Figura 2 deﬁne dados de conﬁgurac¸ ˜ao da
DenseED.

tf1 = Transformation (”Encoder”)
tf1 output = Set(”oEncoder”, OUTPUT,
[ Attribute (”PADDING”, TEXT),
Attribute (”STRIDES”, NUMERIC)])
...
tf3 = Transformation (”DenseBlock”)
tf3 input = Set(”iDenseBlock”, INPUT,
[ Attribute (”K”, NUMERIC),
Attribute (”L”, NUMERIC)])
...

Figura 1: Arquitetura do Keras-Prov

Figura 2: C ´odigo no Keras-Prov

Figura 3: Modelo de Proveni ˆencia do Keras-Prov

4. Avaliac¸ ˜ao Experimental

Utilizamos a DenseED [Freitas et al. 2020] como estudo de caso do Keras-Prov. A Den-
seED ´e uma PINN que usa uma CNN densa, como um modelo substitutivo para viabilizar a
quantiﬁcac¸ ˜ao de incertezas [Zhu and Zabaras 2018]. A DenseED tem como objetivo substituir
o c´alculo da migrac¸ ˜ao reversa no tempo (MRT) por um modelo treinado. Desta forma o c´alculo
da MRT que teria que ser realizado para cada distribuic¸ ˜ao de probabilidade pode ser reduzido.

A instrumentac¸ ˜ao desta CNN utiliza as transformac¸ ˜oes Treinamento, Adaptac¸ ˜ao e Teste.
Treinamento consome (used) o nome do otimizador, os hiperparˆametros taxa de aprendizado,
n´umero de ´epocas e n´umero de camadas da rede, e produz (wasGeneratedBy) um conjunto
de m´etricas que auxiliam na avaliac¸ ˜ao dos resultados obtidos durante o treinamento, p. ex., a
acur´acia, o valor da func¸ ˜ao de perda, o tempo decorrido e a data e hora do ﬁm da execuc¸ ˜ao
de cada ´epoca. Adaptac¸ ˜ao consome (used) o conjunto produzido pela transformac¸ ˜ao anterior
(Treinamento), um conjunto de dados com informac¸ ˜oes para a adaptac¸ ˜ao ocorrida e o conjunto
de dados de sa´ıda cont´em a nova taxa de aprendizado, o valor da ´epoca e a data e hora em
que a adaptac¸ ˜ao ocorreu, al´em de uma identiﬁcac¸ ˜ao para a adaptac¸ ˜ao. Teste provˆe dados sobre a
avaliac¸ ˜ao do modelo de acordo com o conjunto de dados de treinamento e tem como sa´ıda os va-
lores de acur´acia e da func¸ ˜ao de perda. Por´em, nesse caso, foram acrescentadas transformac¸ ˜oes
para captura de informac¸ ˜oes acerca das camadas encoder, decoder e dense block.

O Keras-Prov foi avaliado sob duas perspectivas: (i) sobrecarga introduzida com a cap-
tura de proveniˆencia e (ii) capacidade de consulta aos dados de proveniˆencia. Com o c´odigo
da DenseED adaptado para a utilizac¸ ˜ao do Keras-Prov, foi realizado o treinamento variando-

se o n´umero de ´epocas, taxa de aprendizado, momentum, decay e o otimizador escolhido. As
execuc¸ ˜oes foram feitas com 20, 50 e 100 ´epocas, a taxa de aprendizado foi variada com os valo-
res 0,0005, 0,001 e 0,002, o decay foi variado com os valores 0,0001 e 0,000001 e o momentum
foi variado com os valores 0,5 e 0,9. Cada conﬁgurac¸ ˜ao de hiperparˆametros foi executada cinco
vezes e a m´edia do tempo de execuc¸ ˜ao foi considerada. O tempo de execuc¸ ˜ao foi medido a
partir do in´ıcio da aplicac¸ ˜ao at´e sua ﬁnalizac¸ ˜ao, o Keras-Prov j´a estava inicializado antes da
execuc¸ ˜ao da aplicac¸ ˜ao e o MonetDB j´a estava com o schema deﬁnido (conforme Figura 3). O
desvio padr˜ao das cinco medic¸ ˜oes para as diferentes conﬁgurac¸ ˜oes de hiperparˆametros ﬁcou
entre 0,009 e 0,265. A medic¸ ˜ao da sobrecarga adicionada pelo Keras-Prov corresponde a um
aumento de menos de 2,5% (no pior caso) sobre o tempo total de treinamento da CNN.

O potencial anal´ıtico do Keras-Prov resulta do processamento de consultas na base de
proveniˆencia. Foram executadas consultas para avaliar conﬁgurac¸ ˜oes de hiperparˆametros junto
aos dados de m´etricas sobre o treinamento das CNNs para o usu´ario poder realizar os ajustes
com mais seguranc¸a e conﬁanc¸a. Para as consultas da Figura 4 utilizamos a DenseED com o
otimizador Adam, 20 ´epocas e taxa de aprendizado 0,001. A consulta (a) mostra “Qual o valor
de perda para a DenseED com K=24 e L=4 no momento atual (´epoca 200)?” e a consulta (b)
mostra “Qual o valor da func¸ ˜ao de perda (loss function) de cada ´epoca para as quatro primeiras
`A medida que o treinamento progride, o usu´ario continua reali-
´epocas da CNN DenseED?”.
zando consultas `a base. Por exemplo, ao se chegar em 200 ´epocas, o usu´ario decide ﬁnalizar a
execuc¸ ˜ao, pois esses valores n˜ao est˜ao satisfazendo seus crit´erios. Nesse caso, o usu´ario altera
o n´umero de camadas no bloco denso para 8 e o treinamento segue com os novos dados que s˜ao
armazenados na base de dados.

Figura 4: Consultas sobre o bloco denso = 4 junto `as camadas encoder/decoder.

5. Conclus˜ao

Este artigo tem como objetivo apoiar a fase de treinamento e otimizac¸ ˜ao das CNNs ao registrar
informac¸ ˜oes relevantes `a an´alise de combinac¸ ˜oes de hiperparˆametros para reconﬁgurac¸ ˜oes. O
Keras-Prov ´e uma extens˜ao `a API Keras, que ´e utilizada por muitas bibliotecas de AP (p. ex.,
TensorFlow e Theano). Por meio do Keras-Prov, o usu´ario n˜ao necessita de um grande esforc¸o
de adaptac¸ ˜ao de seu c´odigo para capturar dados de proveniˆencia, ao mesmo tempo que possui
ﬂexibilidade para incluir novos dados a serem analisados e armazenados. O Keras-Prov foi ava-
liado com a CNN DenseED, um exemplo de uso de CNN por pesquisadores que n˜ao s˜ao da ´area
de ciˆencia da computac¸ ˜ao, uma situac¸ ˜ao que tende a aumentar e necessitar ainda mais de aux´ılio
na an´alise e conﬁgurac¸ ˜ao de hiperparˆametros. Experimentos evidenciam a adequac¸ ˜ao do uso de
proveniˆencia nas atividades de an´alise ao longo do treinamento de CNNs, incluindo extens˜oes
para redes densas, contribuindo para um padr˜ao de esquema que permite ao usu´ario consultar de
forma integrada os dados de proveniˆencia associados aos dados usados no treinamento. Como

trabalhos futuros, pretende-se estender o uso do Keras-Prov no apoio `as redes neurais guiadas
pelas leis da F´ısica e quantiﬁcac¸ ˜ao de incertezas, que assim como em AP, requerem um processo
anal´ıtico na criac¸ ˜ao de novos modelos.

Referˆencias
Badan, F. and Sekanina, L. (2019). Optimizing convolutional neural networks for embedded

systems by means of neuroevolution. In TPNC 2019, volume 11934, pages 109–121.

Breck, E., Polyzotis, N., Roy, S., Whang, S. E., and Zinkevich, M. (2019). Data validation for

machine learning. In Conference on Systems and Machine Learning (SysML).

Caveness, E., GC, P. S., Peng, Z., Polyzotis, N., Roy, S., and Zinkevich, M. (2020). Tensorﬂow
data validation: Data analysis and validation in continuous ml pipelines. In Proceedings of
the 2020 ACM SIGMOD, pages 2793–2796.

Freitas, R. S., Barbosa, C. H., Guerra, G. M., Coutinho, A. L., and Rochinha, F. A. (2020).
An encoder-decoder deep surrogate for reverse time migration in seismic imaging under
uncertainty. arXiv preprint arXiv:2006.09550.

Gharibi, G., Walunj, V., Rella, S., and Lee, Y. (2019). Modelkb: towards automated mana-
In Int. Work. on Realizing Art. Intel.

gement of the modeling lifecycle in deep learning.
Synergies in Soft. Eng., pages 28–34. IEEE Press.

Miao, H., Li, A., Davis, L. S., and Deshpande, A. (2017). Towards uniﬁed data and lifecycle

management for deep learning. In 2017 IEEE 33rd ICDE, pages 571–582. IEEE.

Moreau, L. and Groth, P. (2013). Provenance: an introduction to prov. Synthesis Lectures on

the Semantic Web: Theory and Technology, 3(4):1–129.

Pina, D. B., Neves, L., Paes, A., de Oliveira, D., and Mattoso, M. (2019). An´alise de hiper-
parˆametros em aplicac¸ ˜oes de aprendizado profundo por meio de dados de proveniˆencia. In
XXXIV SBBD, pages 223–228. SBC.

Raissi, M., Perdikaris, P., and Karniadakis, G. E. (2017). Physics informed deep learning
(part i): Data-driven solutions of nonlinear partial differential equations. arXiv preprint
arXiv:1711.10561.

Schelter, S., B¨ose, J.-H., Kirschnick, J., Klein, T., and Seufert, S. (2017). Automatically trac-
king metadata and provenance of machine learning experiments. In ML Systems workshop.

Silva, V., de Oliveira, D., Valduriez, P., and Mattoso, M. (2018). Dfanalyzer: runtime dataﬂow

analysis of scientiﬁc applications using provenance. PVLDB, 11(12):2082–2085.

Silva, V., Leite, J., Camata, J. J., De Oliveira, D., Coutinho, A. L., Valduriez, P., and Mattoso,
M. (2017). Raw data queries during data-intensive parallel workﬂow execution. FGCS,
75:402–422.

Tsay, J., Mummert, T., Bobroff, N., Braz, A., Westerink, P., and Hirzel, M. (2018). Runway:

machine learning model experiment management tool. In SysML.

Zaharia, M., Chen, A., Davidson, A., Ghodsi, A., Hong, S. A., Konwinski, A., Murching, S.,
Nykodym, T., Ogilvie, P., Parkhe, M., Xie, F., and Zumar, C. (2018). Accelerating the
machine learning lifecycle with mlﬂow. IEEE Data Eng. Bull., 41:39–45.

Zhu, Y. and Zabaras, N. (2018). Bayesian deep convolutional encoder–decoder networks
for surrogate modeling and uncertainty quantiﬁcation. Journal of Computational Physics,
366:415–447.

