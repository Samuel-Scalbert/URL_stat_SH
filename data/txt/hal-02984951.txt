Agent ontology alignment repair through dynamic
epistemic logic
Line van den Berg, Manuel Atencia, Jérôme Euzenat

To cite this version:

Line van den Berg, Manuel Atencia, Jérôme Euzenat. Agent ontology alignment repair through
dynamic epistemic logic. AAMAS 2020 - 19th ACM international conference on Autonomous Agents
and Multi-Agent Systems, May 2020, Auckland, New Zealand. pp.1422-1430. ￿hal-02984951￿

HAL Id: hal-02984951

https://hal.science/hal-02984951

Submitted on 2 Nov 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Agent Ontology Alignment Repair
through Dynamic Epistemic Logic

Line van den Berg
Univ. Grenoble Alpes, Inria, CNRS,
Grenoble INP, LIG, F-38000 Grenoble
France
line.van-den-berg@inria.fr

Manuel Atencia
Univ. Grenoble Alpes, Inria, CNRS,
Grenoble INP, LIG, F-38000 Grenoble
France
manuel.atencia@inria.fr

Jérôme Euzenat
Univ. Grenoble Alpes, Inria, CNRS,
Grenoble INP, LIG, F-38000 Grenoble
France
jerome.euzenat@inria.fr

ABSTRACT
Ontology alignments enable agents to communicate while preserv-
ing heterogeneity in their information. Alignments may not be
provided as input and should be able to evolve when communica-
tion fails or when new information contradicting the alignment is
acquired. In the Alignment Repair Game (ARG) this evolution is
achieved via adaptation operators. ARG was evaluated experimen-
tally and the experiments showed that agents converge towards
successful communication and improve their alignments. However,
whether the adaptation operators are formally correct, complete or
redundant is still an open question. In this paper, we introduce a
formal framework based on Dynamic Epistemic Logic that allows
us to answer this question. This framework allows us (1) to express
the ontologies and alignments used, (2) to model the ARG adapta-
tion operators through announcements and conservative upgrades
and (3) to formally establish the correctness, partial redundancy
and incompleteness of the adaptation operators in ARG.

KEYWORDS
Ontology alignment; alignment repair; agent communication; dy-
namic epistemic logic

Reference:
Line van den Berg, Manuel Atencia and Jérôme Euzenat. 2020. Agent Ontol-
ogy Alignment Repair through Dynamic Epistemic Logic. In B. An, N. Yorke-
Smith, A. El Fallah Seghrouchni, G. Sukthankar (eds.), Proc. of the 19th
International Conference on Autonomous Agents and Multiagent Systems
(AAMAS 2020), pp1422-1430, Auckland, New Zealand, May 9-13.

1 INTRODUCTION
Agents use ontologies to represent their knowledge of the world.
Generally, these ontologies are not the same. This causes a problem
when agents try to communicate: how do the agents understand
each other if they express their knowledge in different ways? This
question is part of the more general problem of facilitating interop-
erability between agents while preserving heterogeneity in their
information. Ontology matching algorithms have been developed to
allow agents with different knowledge representations, structured
in ontologies, to communicate [22]. These aim to find relationships
holding across entities of two ontologies, the ontology alignment.

This is the author’s version of the work. It is posted here for your personal use. Not for
redistribution. The definitive Version of Record was published in B. An, N. Yorke-Smith,
A. El Fallah Seghrouchni, G. Sukthankar (eds.), Proc. of the 19th International Conference
on Autonomous Agents and Multiagent Systems (AAMAS 2020), May 9–13, 2020
© 2020 International Foundation for Autonomous Agents and Multiagent Systems
(www.ifaamas.org). All rights reserved.

Alignments are typically computed and provided as input to the
agents before any communication or joint task occurs.

Ontology matching algorithms may output only partially correct
or incomplete alignments. This means that, even if alignments are
available, communication failures can still occur due to mistakes in
the alignment. There have been several attempts to repair ontology
alignments [1, 17, 21] that have been integrated with multi-agent
systems via specific protocols [1, 19]. In these approaches, align-
ment repair is performed statically, i.e. independently of agent inter-
action. However, in some multi-agent scenarios, it is not realistic nor
desirable for agents to stop interacting until the repair is completed.
This is why several approaches to ontology matching have been pro-
posed that attempt to dynamically repair alignments [2, 9, 10]. The
Alignment Repair Game (ARG) [11–13] that is inspired by ideas of
cultural language evolution [23] is one of them. In ARG, the agents
are adaptive: they communicate and, in parallel, evolve alignments
through local corrective actions whenever communication fails.
This is achieved via adaptation operators that specify precisely how
agents adapt the failing correspondence of the alignment.

ARG was evaluated experimentally and the experiments showed
that the adaptive agents converge towards successful communica-
tion and improve their alignment [11, 13]. However, experiments
alone are not sufficient to logically assess properties of operators;
whether they are correct, complete or redundant. In this paper
we introduce a formal framework based on Dynamic Epistemic
Logic [25] to answer this question. This contributes to (1) providing
a formal framework for knowledge and belief evolution for logical
agents in ARG, (2) formally defining correctness, redundancy and
completeness of the adaptation operators, (3) theoretically com-
paring adaptive agents and logical agents and (4) defining new
adaptation operators.

Yet, the scope of this theoretical framework is not limited to ARG:
it can be extended to establish formal properties of other games
that are designed for agents to improve and repair alignments
through interaction. This would allow for a theoretical comparison
of different dynamic matching algorithms.

In the remainder, we discuss the related work (§2) and provide the
preliminaries (§3). We introduce DEOL (§4) and translate states of
ARG to DEOL models (§5). The formal properties of the adaptation
operators are then proved (§6). We conclude by emphasizing the
contribution to the broader dynamic ontology matching field (§7).

2 RELATED WORK
Different techniques have been proposed to evolve alignments:
gossiping amongst agents to reach global agreement [1], logical
repair to enforce consistency [16, 18, 21] and prevention of logical

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

Line van den Berg, Manuel Atencia, and Jérôme Euzenat

violations to agents’ ontologies via conservativity principles [17].
These have been integrated with multi-agent systems via specific
protocols [1, 19]. However, they are performed independently of
agent tasks.

To overcome this problem, interaction-situated semantic align-
ment was proposed [2]. This is an ontology matching algorithm
as framed by the interaction protocols used by agents to commu-
nicate. Alignments are induced depending on repeated successful
interactions and failing interactions lead to revision. This proposal
was further advanced to repair alignments through their use and
generalized to less constrained protocols [9, 10].

The Alignment Repair Game (ARG) [11] is inspired by cultural
language evolution [23] to repair alignments through their use.
Cultural language evolution offers an experimental methodology
in which language (or more generally: culture) is shared amongst a
population of agents and evolves through local corrective actions
whenever communication fails. ARG adapts this methodology to
the evolution of ontology alignments and experiments showed that
the adaptive agents converge towards successful communication
through local corrective actions [11, 13].

The purpose of this paper is to examine the corrective actions
performed by adaptive agents in ARG from a logical perspective.
We introduce a formal framework based on Dynamic Epistemic
Logic (DEL) to compare adaptive agents to logical agents, and we
prove the logical limitations of the adaptation operators proposed
in [11, 13]. The logic introduced here is an extension of the work
on Epistemic Description Logics [4]. DEL has been widely used as
a framework to reason about information flow in multi-agents sys-
tems and has been applied communication [7, 25], belief revision [6]
and agent interaction [24].

3 PRELIMINARIES
In this section, we first explain what are ontologies and ontology
alignments (§3.1), then we describe the Alignment Repair Game as
a way for agents to evolve alignments (§3.2) and give the syntax
and semantics of Dynamic Epistemic Logic (DEL) (§3.3). This logic
is the basis for the logic introduced later in this paper.

3.1 Ontologies and ontology alignments
An ontology provides a vocabulary of a domain of interest and a
specification of the meaning of terms via semantic relations: spe-
cialization (Ď), equivalence (”), exclusion (‘) and membership
(P) [15]. Formally, an ontology can be expressed as a knowledge
base in Description Logics [3]. The definition we use in this paper
is that an ontology is defined as a quintuple O “ xD, C, Ď, ‘, Py
where D is a set of objects, C is a non-empty set of class names,
Ď, ‘ Ď C ˆ C are the semantic relations, and P Ď D ˆ C is
the membership relation. To give meaning to these relations an
interpretation I “ x∆, ¨I y is provided specifying a domain ∆ and
a function ¨I assigning to object names o P D an element in the
domain ∆ and to class names C P C a set of elements of ∆. We
then say that “C is subsumed by D” (C Ď D) iff CI Ď DI , “C and
D are equivalent” (C ” D) iff C Ď D and D Ď C, “C and D are
disjoint” (C ‘ D) iff CI X DI “ H and “o is a member of C” (o P C)
iff oI P CI . We also write O ⊨ C Ď D, O ⊨ C ” D, O ⊨ C ‘ D
and O ⊨ Cpoq, respectively. For two classes C, D that overlap (i.e.

that are not disjoint) we also write C ≬ D and in each ontology J
is the class such that JI “ ∆. From classes C, D, we also form the
classes C \ D, C [ D and ␣C that represent the union, intersection
and complement of C (and D). In this paper, the signature of an
ontology is the set of class names C P C and object names o P D.
with
(generally) different signatures is a set of correspondences between
classes of the two [15]. Formally, such a correspondence is a triple
, respec-
xCa, Cb, Ry where Ca and Cb
tively, and R P tĎ, Ě, ”, ‘u is a relation that is asserted to hold
between Ca and Cb

between two ontologies Oa and Ob

are class names of Oa and Ob

. We also write CaRCb

An alignment Aab

for xCa, Cb, Ry.

3.2 Alignment Repair Game
The Alignment Repair Game (ARG) is a protocol designed for adap-
tive agents to evolve alignments between their ontologies through
their use [11, 13]. The aim of ARG is to detect and repair mistakes
in alignments whenever a communication failure occurs through
application of the adaptation operators. The idea is that ultimately,
by repeatedly playing ARG, the alignments converge towards better
alignments.

Definition 3.1 (Adaptation Operator). An adaptation operator pro-
vides a strategy for agents to revise the failing correspondence
of the alignment. It specifies, given the failure of the correspon-
dence xCa, Cb, Ry with R P tĚ, ”u and failing object o, what the
agents should do. In [11, 13] the following adaptation operators are
introduced:

;

;

Cb

‚ delete: delete the correspondence from Aab
‚ replace: replace the correspondence by Ca Ď Cb
‚ add: in addition to replace, add the correspondence Csup
a Ě
of Ca ;
‚ addjoin: in addition to replace, add the correspondence
and the lowest superclass CsupO

CsupO
a
of Ca that is compatible with the object o (i.e. CsupO

and the immediate superclass Csup

between Cb

between Cb

a
poq);

‚ refine: in addition to replace, add the correspondences
of Cb
poq);

between Ca and all the subclasses Csub
Ca Ě Csub
that are not compatible with the object o (i.e. ␣Csub

Ě Cb

a

a

b

b

b

‚ refadd: addjoin and refine.

We write αxCa ,Cb ,Rypoq
α to correspondence xCa, Cb, Ry with failing object o.

for the application of adaptation operator

From the definition, every operator entails delete, the opera-
tors add, addjoin, refine and refadd entail replace and refadd
entails addjoin and refine. Furthermore, the order of the actions
that are performed by the adaptation operators does not matter.
Figure 1 illustrates the effect of the adaptation operators.

Definition 3.2 (Alignment Repair Game). The Alignment Repair
Game is played by a set of agents A with a common set D of objects.
Each agent a P A is associated with an ontology Oa and a set tAab u
of non-empty alignments is given between any two ontologies Oa
and Ob
. We write Oi P Oi for the
most specific class (Ď-wise) of object o P D available in Oi .

that at least includes Ja ” Jb

At each round of the game:
(1) Two agents a, b P A and an object o P D are picked at

random.

Agent Ontology Alignment Repair
through Dynamic Epistemic Logic

Ď

Ja

‘

Ď

Ď

Da

Ď

Ca

Ě (addjoin)

Ě (add)

Ě

(replace)
Ď
Ě (refine)

Jb

Ď

Ď

Ď

Cb

‘

Ď

Db

o

Figure 1: Schematic diagram of the deleted (red, solid) and
added correspondences (blue and green, dashed and dash
dotted) by the different adaptation operators in ARG.

(2) Agent a asks agent b to which class in his ontology the object
o belongs so that it can be translated to agent a’s ontology
⊨ Cb poq
via the alignment. Agent b answers Cb
and xCa, Cb, Ry P Aab

where R P tĚ, ”u).

(with Ob

(3) Agent a compares Ca with Oa . If Oa ⊨ Oa Ď Ca , then
the round is a success, else the round is a failure and an
adaptation operator αxCa ,Cb ,Rypoq

is applied to Aab

.

ARG consists of a fixed number of rounds as described above for a
chosen operator.

As an illustration of one ARG round consider Example 3.3 that

will serve as a running example throughout this paper.

Example 3.3 (Running Example). Let agent a and agent b play
ARG where their ontologies Oa and Ob
are described in Figure 2.
Note that each class in the ontology corresponds to the conjunction
of the class label and the label of its ancestors. For instance, the
bottom-leftmost class in Figure 2 is defined by Squarea [ Smalla .
The initial alignment Aab
is represented by the dotted red corre-
spondences between classes of their ontologies. Now, consider two
cases: the object ▲ and the object △. Let in both cases agent a ask
agent b to which class the object belongs in her ontology so that
it can be translated to Oa via the alignment. In both cases, agent
b will answer Smallb
.
as both objects belong to this class in Ob
However, while for the object ▲ the round would be successful
(because ▲ P Blacka ), for the object △ a failure is reached (because
▲ P W hitea and W hitea ‘ Blacka ).

In the latter case αxBl acka ,Smallb ,”yp▲q

is applied to the align-

ment Aab

.

Ja

‘

Ď

Blacka

Ď

Ď

”

Ď

”

W hitea

Ď

Ď

Jb

‘

Ď

Ď

Smallb

Ď

Ď

Ď

Larдeb

Ď

Smalla
▲

‘

Larдea

‘

Smalla
△

Larдea

Squareb

Oa

Squareb

‘

T rianдleb

‘

Trianдleb
▲, △

Ob

Figure 2: The ontologies (black) of agent a (left) and agent
b (right) and the alignment (red, dashed) between them of
Example 3.3.

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

An ARG state is the state of the alignments reached after a,
possibly empty, sequence of rounds where in each failing round an
adaptation operator is applied.

Definition 3.4 (ARG State). For an ARG game with a set A of
agents, a set tOi uiPA of ontologies and a set tAi j ui,jPA of align-
ments, an ARG state tA1
reached
from tAi j ui,jPA after a, possibly empty, sequence of rounds.

i j ui,jPA is the set of alignments A1
i j

For an ARG state s, we also write αxCa ,Cb ,Rypoqpsq for the result
of applying the adaptation operator α to s with failing correspon-
dence CaRCb
and object o, or simply αpsq when the correspondence
and object are clear from the context.

Example 3.5 (Running Example). In case of a failure of the cor-
respondence Blacka ” Smallb
, an adaptation operator is applied,
adding the following new correspondences to the alignment and
deleting the initial correspondence:

and Blacka Ě pSquareb [ Smallb q

‚ delete: none
‚ replace: Blacka Ď Smallb
‚ add: Ja Ě Smallb
‚ addjoin: Ja Ě Smallb
‚ refine: Blacka Ě pSquareb [ Smallb q
‚ refadd: Ja Ě Smallb
By playing ARG with different operators, they can be compared.
In Euzenat [11, 13], the operators are compared experimentally
in terms of success rate (ratio of successes over rounds played),
semantic precision and recall with respect to the known correct
reference alignment (the degree of correctness and completeness of
the resulting alignment) and convergence (the number of rounds
needed to converge). It was found that all the operators have a
relatively high success rate, yet do not reach 100% precision, and
that recall and convergence both increases with operators that
add new correspondences. The operator refadd, followed by add,
shows the highest semantic recall and replace, again followed by
add, the slowest convergence.

3.3 Dynamic Epistemic Logic
Dynamic Epistemic Logics (DEL) are a family of modal logics de-
scribing information flow in multi-agent systems. DEL has been
widely used as a formal framework to model agent communica-
tion [7, 20, 25], belief revision [6] and agent interaction [24]. As
such, it provides a solid basis to study knowledge and belief evolu-
tion of logical agents playing ARG. Here we consider the syntax
and semantics introduced by Baltag, Moss and Solecki [5].

Definition 3.6 (Syntax of DEL). The syntax, LDEL, of (multi-

agent) DEL is defined in the following way:

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | r†ϕsψ
where p P P is a proposition, Ka and Ba are the knowledge and
belief operators for each agent a and †ϕ with † P t!, Òu the dynamic
upgrades.

The connectives _ and Ñ, and the duals ˆKa, ˆBa, x†ϕy are defined
in the usual way: ϕ _ ψ iff ␣p␣ϕ ^ ␣ψ q, ϕ Ñ ψ iff ␣ϕ _ ψ ,
ˆKaϕ “ ␣Ka ␣ϕ, ˆBaϕ “ ␣Ba ␣ϕ, and x†ϕy “ ␣r†ϕs␣ψ . DEL
models are based on Kripke frames with plausibility relations where
the logical dynamics act as model transformers.

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

Line van den Berg, Manuel Atencia, and Jérôme Euzenat

Definition 3.7 (DEL Model). A model of (multi-agent) DEL is a

quadruple M “ xW , pěa qaPA, w ˚, V y where

‚ W is a non-empty set of states, or worlds;
‚ pěa qaPA Ď W ˆ W are the plausibility relations on W ,
one for each agent, that are converse well-founded, locally
connected preorders;

‚ w ˚ P W is the actual world;
‚ and V is a propositional valuation mapping propositions to

sets of worlds in which that proposition is true.

The plausibility relation w ěa v reads as “w is at least as plausi-
ble as v for agent a” and the epistemic and doxastic relations are
defined on W accordingly:

w „a v iff w pďa Y ěa q v
w Ña v iff v P Maxďa |w|a
(2)
where |w|a is the information cell (or accessible cell) of agent a at
state w and is defined by:

(1)

|w|a “ tv P W | w „a vu
It follows from the properties of ďa and ěa that the relations
„a are reflexive, transitive and symmetric, and the relations Ña
are transitive, serial and Euclidean. Therefore they satisfy the usual
properties of knowledge and belief, respectively [8, 25].

(3)

Definition 3.8 (Semantics of DEL). The semantics for DEL is de-

fined in the following way:

M, w ⊨p
M, w ⊨ϕ ^ ψ
M, w ⊨␣ϕ
M, w ⊨Kaϕ
M, w ⊨Baϕ
M, w ⊨r!ϕsψ
M, w ⊨rÒϕsψ

iff w P V ppq
iff M, w ⊨ ϕ and M, w ⊨ ψ
iff M, w ⊭ ϕ
iff @v s.t. w „a v : M, v ⊨ ϕ
iff @v s.t. w Ña v : M, v ⊨ ϕ
iff M!ϕ, w ⊨ ψ
iff MÒϕ, w ⊨ ψ
where !ϕ and Òϕ act as model transformers !ϕ : M Ñ M!ϕ and
Ò ϕ : M Ñ MÒϕ in the following ways, with ||ϕ||M “ tw P
W | M, w |ù ϕu:

Announcement (!ϕ) Delete all ‘␣ϕ’-worlds from the model.
!ϕ ,

!ϕ “ ||ϕ||M , w ě

I.e. W
!ϕ ppq “ V ppq X ||ϕ||M and pw ˚q
V

!ϕ
a v iff w ěa v and w, v P W
!ϕ “ w ˚;

Conservative upgrade (Òϕ) Change the plausibility orders
so that the best ‘ϕ’-worlds become better than all other
worlds, while the old ordering on the rest of the worlds re-
mains. I.e. W Òϕ “ W , w ěÒϕ
a v iff either w P Maxďa p|v|a X
||ϕ||M q or w ěa v, V Òϕ ppq “ V ppq and pw ˚qÒϕ “ w ˚.
We also write †1ϕ; †2ψ for the sequence of upgrades †1ϕ and
†2ψ .

then †2ψ . The resulting model M†1ϕ;†2ψ is equal to pM†1ϕ q

The intuition behind the different upgrades is that the trustwor-
thiness of the information source may vary: it may be considered
from an infallible source (announcements), or from a trusted, but
not infallible source (conservative upgrades). For this reason, con-
servative upgrades only change the plausibility of worlds without
deleting any alternatives.

Note that in all cases, w ˚ remains the actual world of the model.
This also means that an announcement !ϕ can only be validly per-
formed on a model M if ϕ is true there.

4 DYNAMIC EPISTEMIC ONTOLOGY LOGIC
To compare adaptive agents with logical agents, we need a logical
framework to model ARG. Here, we introduce Dynamic Epistemic
Ontology Logic (DEOL) that is a variant of Dynamic Epistemic
Logic where the propositions are object classifications (Cpxq) and
class relations (C ” D, C Ď D and C ‘ D) of a Description Logic
language. This logic enables us to later capture knowledge and
belief evolution in alignment repair.

Definition 4.1 (Syntax of DEOL). The syntax, LDEO L, of (multi-

agent) DEOL is defined in the following way:

ϕ ::“ Cpoq | CRD | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | r†ϕsψ

R P tĎ, ”, ‘u, † P t!, Òu

where C, D, J P C, o P D, Ka and Ba are the knowledge and
belief operators for agent a and †ϕ with † P t!, Òu are the dynamic
upgrades.

The connectives Ñ and _ and the duals ˆKa, ˆBa, x†ϕy are defined

as in the case of DEL.

DEOL models are plausibility models. The difference with DEL
models is that instead of a valuation of propositions, we consider a
domain of interpretation ∆ representing the objects and an inter-
pretation function I assigning to each world a function interpreting
each class as a set of objects of the domain.

Definition 4.2 (DEOL Model). A model of (multi-agent) DEOL is

a quintuple M “ xW , pěa qaPA, w ˚, ∆, I y where

‚ W is the set of states, or worlds;
‚ pěa qaPA Ď W ˆ W are the plausibility relations on W ,
one for each agent, that are converse well-founded, locally
connected preorders;

‚ w ˚ P W is the actual world;
‚ ∆ is the domain of interpretation (a set of objects);
‚ and I is an interpretation function s.t. I pwq “ ¨Iw and ¨Iw :
C Ñ Pp∆q, where it holds that JIw “ ∆, and for any two
classes C, D P C we have that pC [ DqIw “ CIw X DIw and
p␣CqIw “ ∆ z CIw for each w P W .

We also write C \ D for the class defined by ␣p␣C [ ␣Dq, and
[tCi u and \tCi u for the classes defined by C1 [ C2 [ . . . and
C1 \ C2 \ . . ., respectively. Their interpretations at world w are
Ť
, respectively. In each DEOL
given by CIw Y DIw ,
model K “ ␣J is the empty class.

CIw
i

CIw
i

and

Ş

The semantics of DEOL is equivalent to that of DEL except that
we now have instance classifications Cpoq and class relations C Ď D,
C ” D and C ‘ D.

Agent Ontology Alignment Repair
through Dynamic Epistemic Logic

Definition 4.3 (Semantics of DEOL). The semantics for DEOL

extends that of DEL (Definition 3.8) by:

M, w ⊨Cpoq
M, w ⊨C Ď D
M, w ⊨C ” D
M, w ⊨C ‘ D

iff oIw P CIw
iff CIw Ď DIw
iff CIw “ DIw
iff CIw X DIw “ H

The additional capacities of logical agents compared to the origi-
nal game are that logical agents can now use the relations between
concepts to reason about instance classification. For instance, the
following axiom schemata are valid:

Ka pCpxqq ^ Ka pC Ď Dq ñ Ka pDpxqq

(4)

(5)

Ka pCpxqq ^ Ka pC ‘ Dq ñ Ka p␣Dpxqq
In addition, agents can combine their knowledge and beliefs to
obtain new beliefs. For instance, Ka pCa poqq and Ba pCa Ě Cb q
entails Ba pCb poqq. In other words, agent a can transfer some of her
knowledge about Ca to beliefs about Cb

This increased reasoning capacity of logical agents compared to
adaptive agents is crucial in the results later about the correctness,
partial redundancy and incompleteness of the adaptation operators.

.

5 TRANSLATION
In the previous section, we have provided a formal framework for
knowledge and belief evolution in alignment repair. We now use
this framework to capture the Alignment Repair Game. More pre-
cisely, we define a translation from ARG states to DEOL axioms
that are interpreted as sets of DEOL models (§5.1) and from adapta-
tion operators for ARG to dynamic upgrades on DEOL (§5.2), see
Figure 3. These translations are labeled by z and δ , respectively,
and the interpretation on DEOL models by I . This enables us to
define and prove correctness, redundancy and completeness of the
adaptation operators in the remainder of this paper.

ARG state (s)

α

ARG state (αpsq)

z

δ

z

DEOL axioms

δ pαq

DEOL axioms

I

I

DEOL models (M)

DEOL models (Mδ pα q)

Figure 3: Diagram of translations from ARG states to DEOL
axioms (z) that are interpreted by sets of DEOL models (I ),
and from adaptation operators to dynamic upgrades (δ ).

5.1 Semantics of ARG states
Let agents a and b play ARG with ontologies Oa and Ob
, respec-
tively, and alignment Aab
. Given the nature of ontologies and align-
ments, we impose the following three conditions on the DEOL ax-
ioms describing the epistemic-doxastic states of agents a and b:

Ontology Knowledge (OK) Oa (Ob
) is known to agent a (b);
is believed by agents a and b and;
Alignment Belief (AB) Aab
Public Signature Awareness (PSA) The signatures of all on-

tologies are known to all agents.

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

In the interpretation on DEOL models, this means that the sen-
tences that describe Oa are true in any world in |w ˚|a , and the
sentences that describe Aab
are true in all most plausible worlds in
both |w ˚|a and |w ˚|b

.

Example 5.1 (Running Example). In the running example, this
means that the sentences pSquarea [ Smalla q Ď Smalla , Smalla Ď
Ja , T rianдlea [ Smalla p▲q, etc, are true in every accessible world
for agent a and that the sentences Smalla ” Blacka and Ja ” Jb
are true in the most plausible worlds for both agents.

Public signature awareness ensures that agents are allowed to
update their information when we consider the dynamics of the
adaptation operators. It requires that, for each agent a, each object
with b ‰ a and not
o P D and for each two classes C, D P Ob
appearing in the alignment, i.e. C, D R tCb P Ob | xCa, Cb, Ry P
Aab, Ca P Oa, R P t”, Ď, Ě, ‘uu, agent a considers all combina-
tions of the following alternatives equally plausible:

‚ Cpoq and ␣Cpoq
‚ Dpoq and ␣Dpoq
‚ C ” D and C ı D

‚ C Ď D and C Ę D
‚ C Ě D and C Ğ D
‚ C ‘ D and C ≬ D

Formally, this is achieved on the interpretation on DEOL models
by ultimately making as many copies of the worlds describing
the agent’s knowledge and belief as there are combinations of
the alternatives above, ranking them all equally plausible while
respecting the order imposed by the alignments.

Because models rapidly explode, we will only draw the informa-

tion given by the ontologies and alignments.

Example 5.2 (Running Example). Figure 4 depicts the epistemic-
doxastic state of agent a at the start of the game. Note that the
consisted of xJa, Jb ”, y and xBlacka, Smallb, ”y.
alignment Aab

Trianдleb [ Smallb

Squareb [ Larдeb

Jb

Ď

Larдeb

Smallb
▲, ␣△

Squareb [ Smallb

Ě

Trianдleb [ Larдeb

Ě
”

Ď

Ě

‘

”

Ja

‘

Ď

Ď

Blacka

Ď

Ď

Ď

W hitea

Ď

Ď

‘

Larдea

‘

Larдea

Smalla
△

Oa

Smalla
▲

‘

‘

Figure 4: Initial knowledge (solid black lines) and belief
(dashed red lines) of agent a in the Running Example.

and Aab

Note that the interpretation of the DEOL translation of ARG with
satisfying OK, AB and PSA is not unique. Indeed,
Oa, Ob
there are many variations of models that qualify, and, in particular
the minimal DEOL model M Oa , Ob ,Aab
(or Mmin in short when it
is clear from the context) in which agents have no other knowledge
or beliefs than given by the closure of the three conditions.

min

Proposition 5.3. Any DEOL model M describing ARG with
Oa, Ob and Aab that satisfies the three conditions is an extension of
the minimal DEOL model M Oa , Ob ,Aab

.

min

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

Line van den Berg, Manuel Atencia, and Jérôme Euzenat

5.2 Dynamics
During the gameplay of ARG, new information is learned. There are
two dynamic acts involved in the learning: the communication of
Cb poq in step 2 of ARG and the adaptation operator applied in step
5 (see Definition 3.2). How do these acts change the knowledge and
beliefs of the agents? And are the adaptation operators as defined
by Euzenat [11, 13] sufficient to account for these changes?

In order to answer these questions, we translate the communica-

tion taking place in ARG to dynamic upgrades on DEOL.

Definition 5.4 (ARG Dynamics in DEOL). We model each round

of ARG as defined in Definition 3.2 by

!Cb poq; if ␣Ca poq then δ pαxCa ,Cb ,Ěypoqq
where δ pαxCa ,Cb ,Ěypoqq denotes the translation of adaptation op-
erator α applied to the correspondence Ca Ě Cb
with failing object
o.

(6)

Given that Cb poq is knowledge to agent b, the communication of
this information in step 3 of ARG translates to an announcement
on DEOL. For the adaptation operators, announcements are not the
correct tool: adaptation operators tell the agents how to revise the
alignment, their beliefs, upon a communication failure. Therefore
adaptation operators translate to conservative upgrades.

Definition 5.5 (Adaptation Operators as Dynamic Upgrades). Let
be the failing correspondence with object o, the
xCa, Cb, Ěy P Aab
adaptation operators (αxCa ,Cb ,Ěypoq
) are translated to the following
dynamic upgrades on DEOL (where the subscript xCa, Cb, Ěypoq is
left out for readability):

δ pdeleteq “ Ò pCa Ğ Cb q
δ preplaceq “ Ò pCa Ğ Cb q

a Ě Cb q

δ paddq “ Ò pCa Ğ Cb ^ Csup
δ paddjoinq “ Ò pCa Ğ Cb ^ CsupO
δ prefineq “ Ò pCa Ğ Cb ^
δ prefaddq “ Ò pCa Ğ Cb ^ CsupO

a
ľ

a

Ě Cb q
tCa Ě Csub

b

Ě Cb ^

uq
ľ

tCa Ě Csub

b

uq

a

are unique) and tCa Ě Csub

a “ MinĎtC P Oa | Ca Ĺ Cu, CsupO

where Csup
“ MinĎtC P
Oa | Ca Ĺ C ^ Cpoqu (and by construction of the ontologies, Csup
and CsupO
u “ tCa Ě C | C P
a
Ob ^C Ď Cb ^Cpoqu. If the initial correspondence of the alignment
is an equivalence-relation, i.e. if xCa, Cb, ”y P Aab
, then the corre-
sponding dynamic upgrade for delete is Ò pCa Ğ Cb ^ Ca Ę Cb q.
The upgrades for the other adaptation operators remain the same.

a

b

Again, as was the case for the adaptation operators on ARG states,
δ paddq, δ paddjoinq, δ prefineq and δ prefaddq entail δ preplaceq,
and δ prefaddq entails δ paddjoinq and δ prefineq.

Example 5.6 (Running Example - Success). When ARG is played
with ▲, agent b announces that !Smallb p▲q and the correspondence
used is xBlacka, Smallb, ”y P Aab
. This information is compatible
with the information of agent a: Blacka is compatible with Smalla [
Blacka , i.e. the most specific class of ▲.

Compared to ARG where the round is now finished, there are
additional epistemic-doxastic changes on the corresponding DEOL

model. The announcement carries more information than just
indicating that the round of ARG was a success, it transforms
some beliefs of agent a into knowledge: Ba pSmallb p▲qq becomes
Ka pSmallb p▲qq. In other words, agent a is now given concrete
evidence that ▲ is a member of Smallb
whereas before she only
believed this. Figure 4 can be compared to and the upper schema of
Figure 5 for an overview of the changes to the epistemic-doxastic
state of agent a.

Jb

Ď

Smallb
▲ △

Ě

Jb

Ď

Smallb
▲ ␣ △

Ě

Ě
ı

Ę

Ě

Ě
”

Ď

Ě

≬

”

Ď

Ď

Blacka

Ď

Ď

‘

Larдea

Smalla
▲

‘

‘

‘

”

Ď

Ď

Blacka

Ď

Ď

‘

Larдea

Smalla
▲

‘

‘

Ď

W hitea
Ď

Ď

‘

Larдea

Smalla
△

Ď

W hitea
Ď

Ď

‘

Larдea

Smalla
△

Ja

‘

Oa

Ja

‘

Oa

Figure 5: The knowledge (solid black) and belief (dashed red)
of agent a of Example 3.3 after the announcement !Smallb p△q
(above) and after the announcement !Smallb p▲q (below).

Example 5.7 (Running Example - Failure). If instead ARG is played
with △, the round is a failure. Agent b announces !Smalla p△q using
the same correspondence xBlacka, Smallb, ”y P Aab
. However,
this information contradicts the knowledge of agent a and, as a
result, the correspondence (belief) of the alignment will be dropped.
However, this is not the only revised belief. The contradicted
initial beliefs turn into knowledge of their negation. For example,
Ba p␣Smallb p△qq becomes Ka pSmallb p△qq after the announcement.
Compare also Figure 4 and the lower schema of Figure 5 for an
overview of the changes to the epistemic-doxastic state of agent a.
According to ARG, an adaptation operator is applied, which re-
sults in an updated alignment as explained in Example 3.5. These
correspondences should be amongst the beliefs of the agents at the
end of the round of ARG. However, for some operators, the corre-
spondences are already believed by agent a before the adaptation
operator is applied. We will see why in the next section.

The translation provided in this section is faithful because the
semantics of ontologies and alignments we use is the same as in
Description Logic and the only dynamic epistemic component arises

Agent Ontology Alignment Repair
through Dynamic Epistemic Logic

from modeling the agents’ knowledge and beliefs, see also [4]. A
formal proof is out of the scope of this paper.

6 FORMAL PROPERTIES OF THE
ADAPTATION OPERATORS

With the formal representation of ARG in DEOL we can explore
the correctness, redundancy and completeness of the operators. For
this, we consider the diagram as pictured in Figure 3.

6.1 Correctness
To show that the adaptation operators are correct, we need to show
that the diagram of Figure 3 commutes.

Definition 6.1 (Correctness). Adaptation operator α is correct if

and only if @s: pzpsqqδ pα q ⊨ zpαpsqq.

Proposition 6.2. The adaptation operators delete, replace,

addjoin, refine and refadd are correct.

Proof. We do the proof for agent a and adaptation operator
addjoin. The proof for replace now follows because it is entailed
by addjoin, and the proof for refine is symmetric.

a

a

a

!Cb poq;ÒpCa ĞCb ^C supO

Because addjoin only adds beliefs, it suffices to show that these
ĚCb q ⊨ Bi pCa Ď Cb q ^
are entailed: pzpsqq
Bi pCsupO
Ě Cb q. This holds because initially the correspondence
a
is believed, i.e. zpsq ⊨ Bi pCa Ě Cb q, and the upgrade !Cb poq; Ò
pCa Ğ Cb ^ CsupO
Ě Cb q deletes all the worlds from zpsq in
which Cb poq is false and then rearranges the remaining worlds
such that the ‘Ca Ğ Cb ^ CsupO
’-worlds become more
Ě Cb
plausible that the ‘␣pCa Ğ Cb ^ CsupO
Ě Cb q’-worlds. Because
a
there remain ‘Ca Ğ Cb ^ CsupO
’-worlds accessible for
Ě Cb
both agents, the belief is enforced. For agent b, this is true because
the announcement !Cb poq does not alter her epistemic-doxastic
state (she already knew that Cb poq as it is in her ontology), and for
agent a, because the announcement !Cb poq deletes the worlds in
(␣Ca poq holds because the correspondence and
which Ca Ď Cb
announcement caused a failure) or Ca ” Cb
but not those in which
or CsupO
. Therefore the beliefs Bi pCa Ď Cb q and
Ca Ğ Cb
Ě Cb
a
Bi pCsupO
Ě Cb q are enforced for agents i P ta, bu. Hence addjoin
a
□
is correct.

a

Yet, the adaptation operator add is not correct because it does
not take into account whether the immediate superclass of Ca is
consistent with the object o. And if it is consistent, add is equivalent
to addjoin.

Proposition 6.3. The adaptation operator α “ add is incor-
rect, i.e. Ds : pzpsqqδ paddq ⊭ zpaddpsqq, and @s s.t. pzpsqqδ paddq ⊨
zpaddpsqq: addpsq “ addjoinpsq.

a Ě Cb q, object o s.t. Ob

Proof. We need to prove the existence of an ARG state s where
pzpsqqδ paddq ⊭ zpaddpsqq with upgrade δ paddq “!Cb poq; Ò pCa Ğ
Cb ^ Csup
⊨ Cb poq and xCa, Cb, Ěy P Aab
the failing correspondence. Pick s to be any such ARG state where
the immediate superclass Csup
of Ca is incompatible with o, i.e.
Oa ⊭ Csup
poqq and pzpsqqδ paddq ⊨
Ka pCb poqq ^ Ka pCsup
a Ğ Cb q. This is because δ paddq deletes all

poq. Then zpsq ⊨ Ka p␣Csup

a

a

a

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

‘␣Cb poq’-worlds from zpsq and therefore also all the worlds acces-
for C such that zpsq ⊨ Ka pCpoqq. In
sible by agent a where C Ě Cb
particular, this holds for Csup
. But, after applying the adaptation
operator add, xCsup
, Cb, Ěy becomes part of the alignment, so that
zpaddpsqq ⊨ Ba pCsup

a Ě Cb q. Hence pzpsqqδ paddq ⊭ zpaddpsqq.

Moreover, whenever pzpsqqδ paddq ⊨ zpaddpsqq it must be that
, i.e. add is
□

poq so that, per definition, Csup

Oa ⊨ Csup
equivalent to addjoin.

a “ CsupO

a

a

a

a

Proposition 6.3 is in line with initial predictions and experimental
results by Euzenat [13, 14]: addjoin shows faster convergence than
add. This is because add can force false correspondences to be added
to the alignment that can later cause a failure. From these results,
it is clear that for a logical agent, add should be abandoned.

6.2 Redundancy
The redundancy of some operators in the running example is not a
coincidence. For logical agents, i.e. DEOL agents, some adaptation
operators are redundant for every ARG state: delete, replace
and addjoin are redundant with respect to agent a and refine is
redundant with respect to agent b. Before we define this redundancy
with respect to one agent (partial redundancy), let us first consider
what it means for an operator to be redundant (with respect to both
agents). An adaptation operator α is redundant if and only if solely
applying !Cb poq on the DEOL translation of s is already sufficient
to obtain an interpretation of the DEOL translation of αpsq.

Definition 6.4 (Redundancy). Adaptation operator α is redundant

if and only if @s: pzpsqq

!Cb poq ⊨ zpαpsqq.

ARG state (s)

z
"

δ

α

DEOL axioms
!Cb poq

Òoperator

ARG state (αpsq)

z

DEOL axioms

I

I

I

DEOL models (M)

DEOL models (Mδ pα q)

Figure 6: Diagram of translations between ARG states DEOL
axioms that are interpreted on DEOL models, adaptation op-
erators and dynamic upgrades as in Figure 3 where the op-
erators are redundant.

The adaptation operators discussed here are not redundant, but
partially redundant. This means that they are redundant with re-
spect to one agent. To prove redundancy, we show that the knowl-
edge and belief of this agent are invariant to the application of
the adaptation operator. In fact, because adaptation operators only
alter the beliefs of agents, it suffices to show partial redundancy by
showing that the beliefs of that agent remain unchanged.

Definition 6.5 (Partial Redundancy). An adaptation operator α
!Cb poq ⊨ Baϕ
is partially redundant for agent a if and only if pzpsqq
implies zpαpsqq ⊨ Baϕ for each ARG state s and each ϕ in LDEO L.
Proposition 6.6. The adaptation operators delete, replace and
addjoin are partially redundant with respect to agent a, and refine
is partially redundant with respect to agent b.

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

Line van den Berg, Manuel Atencia, and Jérôme Euzenat

Proof. We do the proof for agent a and the adaptation operator
addjoin. The proof for replace now follows because it is entailed
by addjoin, and the proof for refine is symmetric.

Thus we need to show that pzpsqq

!Cb poq ⊨ Baϕ implies that
zpaddjoinxCa ,Cb ,Ěypoqpsqq ⊨ Baϕ. So consider a sentence ϕ that
is not believed by agent a in zpaddjoinxCa ,Cb ,Ěypoqpsqq, but is in
zpsq. By construction of the dynamics of the operator addjoin, this
can only be (1) a belief that is inconsistent with Cb poq (because
the announcement !Cb poq deletes these worlds), or (2) Ca Ę Cb
(because it is enforced by the conservative upgrade part of the dy-
!Cb poq:
namics). But these are also not believed by agent a in pzpsqq
(1) because !Cb poq has deleted all these beliefs, and (2) because
zpsq ⊨ Ka p␣pCa poqqq and this knowledge is invariant under the
announcement !Cb poq, causing the belief in Ca Ę Cb
to be dropped.
Hence, by contraposition, addjoin is partially redundant with re-
spect to agent a. In Figure 7 the knowledge and belief of agent
a is illustrated before and after the announcement !Cb poq for an
□
intuition.

Ď

Ď

‘

‘

Ď

Da
o

‘

Ě

Ě

Ě
”

Ď

Ď

Ď

Ca
␣o

‘

Cb
␣o

Ď

Ď

Ď

‘

‘

Ď

Da
o

≬

Ě

Ğ

Ğ
ı

Ď

Ď

Ď

Ca
␣o

≬

Cb
o

Ď

Figure 7: The knowledge (solid black) and beliefs (dashed
red) of agent a before (left) and after (right) the announce-
ment !Cb poq.

However, none of the adaptation operators are redundant with
respect to both agents. Even the simple delete carries valuable
information to agent b: namely that the initial correspondence fails.
Without this operator, agent b would not be aware whether the
round of ARG is a success of a failure.

6.3 Incompleteness
Finally, we consider completeness of the adaptation operators: do
the operators capture all the information that can be learned? Intu-
itively, this is proven by comparing what is learned by the agents
in ARG scenarios from application of the adaptation operators with
what is learned by logical agents in DEOL from the dynamic up-
grades. If the former implies the later, the operator is (epistemically)
complete.

Definition 6.7 (Completeness). Adaptation operator α is complete

if and only if @s: zpαpsqq ⊨ pzpsqqδ pα q.

Proposition 6.8. All adaptation operators (delete, replace,

add, addjoin, refine, refadd) are incomplete.

Proof. Again, consider the knowledge and belief of agent a be-
fore and after the announcement !Cb poq, see also Figure 7. After
the announcement !Cb poq, agent a receives concrete information
, i.e. she comes to know this
that object o belongs to the class Cb

!Cb poq ⊨ Ka pCb poqq. And, by definition, this
information: pzpsqq
knowledge remains after application of any conservative upgrade,
i.e. pzpsqqδ pα q ⊨ Ka pCb poqq. Yet, this knowledge is never acquired
through application of the adaptation operators because they only
concern the alignment, i.e. beliefs of class relations, and not knowl-
edge of instance classification. Hence zpαpsqq ⊭ Ka pCb poqq and
□
zpαpsqq ⊭ pzpsqqδ .

The incompleteness proof of the adaptation operators relies on
the agent not memorizing the failure of the correspondence with
the drawn object. Yet, from Figure 7 it is clear that there is more
knowledge gained by the agents from the announcement !Cb poq.
This occurs because we measure completeness, and correctness,
with respect to the full knowledge and belief of the agent. When
concentrating on the alignment only, as expressed by adaptive
agents, the operators may be complete.

7 DISCUSSION AND CONCLUSION
We developed a theoretical framework for knowledge and belief
evolution in ARG and formally defined correctness, completeness
and redundancy of adaptation operators to compare adaptive agents
and logical agents. We complement the current experimental ap-
proach by proving that, in this framework, all but the add operator
are correct, delete, replace, addjoin and refine are redundant
for one agent and that all operators are incomplete. This contributes
to theoretically comparing the different operators and could inspire
new adaptation operators for ARG. However, this does not mean
that the adaptive agents are meaningless. In fact, the adaptive agents
in [11, 13] implement deliberately a ‘sublogical’ behavior and the
experiments show that, in some cases, they can perform well. For
instance, agents do not need to be fully complete, and not even
fully correct, to reach 100% success in ARG. The purpose of our
work is to examine them under a logical light. We compare adaptive
agents to logical agents, and we prove the logical limitations of the
adaptation operators.

Yet, the scope of this paper lays beyond ARG. We have provided
a theoretical framework that can be extended to establish formal
properties of other games that are designed for agents to improve
and repair alignments through interaction. This allows for a theo-
retical comparison of different dynamic matching algorithms.

In this paper, public signature awareness was a prerequisite in
the translation from ARG states to DEOL to capture the dynamics
of the game by announcements and conservative upgrades. In the
future, we want to drop this prerequisite. We suspect that this might
provide the means to capture the ability to generate new (random)
correspondences [13].

ACKNOWLEDGMENTS
The authors thank the anonymous reviewers for their valuable
comments and helpful suggestions. This work has been partially
supported by MIAI @ Grenoble Alpes (ANR-19-P3IA-0003).

Agent Ontology Alignment Repair
through Dynamic Epistemic Logic

REFERENCES
[1] Karl Aberer, Philippe Cudré-Mauroux, and Manfred Hauswirth. 2003. Start
making sense: The Chatty Web approach for global semantic agreements. J. Web
Semant. 1, 1 (2003), 89–114. https://doi.org/10.1016/j.websem.2003.09.001
[2] Manuel Atencia and W. Marco Schorlemmer. 2012. An interaction-based approach
to semantic alignment. J. Web Semant. 12 (2012), 131–147. https://doi.org/10.
1016/j.websem.2011.12.001

[3] Franz Baader, Diego Calvanese, Deborah L. McGuinness, Daniele Nardi, and
Peter F. Patel-Schneider (Eds.). 2003. The Description Logic Handbook: Theory,
Implementation, and Applications. Cambridge University Press.

[4] Franz Baader, Ralf Küsters, and Frank Wolter. 2003. Extensions to Description Log-
ics. In The Description Logic Handbook: Theory, Implementation, and Applications.
219–261.

[5] Alexandru Baltag, Lawrence S. Moss, and Slawomir Solecki. 1998. The Logic
of Public Announcements and Common Knowledge and Private Suspicions.
In Proceedings of the 7th Conference on Theoretical Aspects of Rationality and
Knowledge (TARK-98), Evanston, IL, USA, July 22-24, 1998. 43–56.

[6] Johan Van Benthem. 2007. Dynamic logic for belief revision. Journal of Applied
Non-Classical Logics 17, 2 (2007), 129–155. https://doi.org/10.3166/jancl.17.129-155
[7] Johan Van Benthem, Jan van Eijck, and Barteld P. Kooi. 2006. Logics of
Inf. Comput. 204, 11 (2006), 1620–1662. https:

communication and change.
//doi.org/10.1016/j.ic.2006.04.006

[8] Patrick Blackburn, Johan Van Benthem, and Frank Wolter (Eds.). 2007.
reasoning,
https://www.sciencedirect.com/bookseries/

Handbook of Modal Logic. Studies
Vol. 3.
studies-in-logic-and-practical-reasoning/vol/3/suppl/C

in logic and practical

North-Holland.

[9] Paula Chocron and Marco Schorlemmer. 2016. Attuning Ontology Alignments
to Semantically Heterogeneous Multi-Agent Interactions. In ECAI 2016 - 22nd
European Conference on Artificial Intelligence, 29 August-2 September 2016, The
Hague, The Netherlands - Including Prestigious Applications of Artificial Intelligence
(PAIS 2016). 871–879. https://doi.org/10.3233/978-1-61499-672-9-871

[10] Paula Chocron and Marco Schorlemmer. 2017. Vocabulary Alignment in Openly
Specified Interactions. In Proceedings of the 16th Conference on Autonomous Agents
and MultiAgent Systems, AAMAS 2017, São Paulo, Brazil, May 8-12, 2017. 1064–
1072. http://dl.acm.org/citation.cfm?id=3091275

[11] Jérôme Euzenat. 2014. First Experiments in Cultural Alignment Repair (Extended
Version). In The Semantic Web: ESWC 2014 Satellite Events - ESWC 2014 Satellite
Events, Anissaras, Crete, Greece, May 25-29, 2014, Revised Selected Papers. 115–130.
https://doi.org/10.1007/978-3-319-11955-7_10

[12] Jérôme Euzenat. 2017. Crafting Ontology Alignments from Scratch Through
Agent Communication. In PRIMA 2017: Principles and Practice of Multi-Agent

AAMAS 2020, May 9–13, 2020, Auckland, New Zealand

[13] Jérôme Euzenat. 2017.

Systems - 20th International Conference, Nice, France, October 30 - November 3,
2017, Proceedings. 245–262. https://doi.org/10.1007/978-3-319-69131-2_15

Interaction-based ontology alignment repair with ex-
pansion and relaxation. In Proceedings of the Twenty-Sixth International Joint
Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August
19-25, 2017. 185–191. https://doi.org/10.24963/ijcai.2017/27

[14] Jérôme Euzenat. 2018.

https://gforge.inria.fr/plugins/
mediawiki/wiki/lazylav/index.php/20180826-NOOR. (2018). Accessed: 2018-
08-26.

20180826-NOOR.

[15] Jérôme Euzenat and Pavel Shvaiko. 2013. Ontology Matching, Second Edition.

Springer.

[16] Ernesto Jiménez-Ruiz, Christian Meilicke, Bernardo Cuenca Grau, and Ian Hor-
rocks. 2013. Evaluating Mapping Repair Systems with Large Biomedical Ontolo-
gies. (2013), 246–257. http://ceur-ws.org/Vol-1014/paper_63.pdf

[17] Ernesto Jiménez-Ruiz, Terry R. Payne, Alessandro Solimando, and Valentina A. M.
Tamma. 2016. Limiting Logical Violations in Ontology Alignnment Through
Negotiation. In Principles of Knowledge Representation and Reasoning: Proceedings
of the Fifteenth International Conference, KR 2016, Cape Town, South Africa, April
25-29, 2016. 217–226. http://www.aaai.org/ocs/index.php/KR/KR16/paper/view/
12893

[18] Christian Meilicke. 2011. Alignment incoherence in ontology matching. Ph.D.
Dissertation. University of Mannheim. https://ub-madoc.bib.uni-mannheim.de/
29351

[19] Terry R. Payne and Valentina A. M. Tamma. 2014. Negotiating over ontological
correspondences with asymmetric and incomplete knowledge. In International
conference on Autonomous Agents and Multi-Agent Systems, AAMAS ’14, Paris,
France, May 5-9, 2014. 517–524. http://dl.acm.org/citation.cfm?id=2615816
[20] Jan Plaza. 1989. Logic of public communications. In Proceedings of the 4th Inter-
national Symposium on Methodologies for Intelligent Systems, Zbigniew W. Ras
(Ed.). North-Holland, 201–216.

[21] Emanuel Santos, Daniel Faria, Catia Pesquita, and Francisco M. Couto. 2013. On-
tology alignment repair through modularization and confidence-based heuristics.
CoRR abs/1307.5322 (2013). arXiv:1307.5322 http://arxiv.org/abs/1307.5322
[22] Pavel Shvaiko and Jérôme Euzenat. 2013. Ontology Matching: State of the Art
IEEE Trans. Knowl. Data Eng. 25, 1 (2013), 158–176.

and Future Challenges.
https://doi.org/10.1109/TKDE.2011.253

[23] Luc Steels. 2012. Experiments in cultural language evolution. Vol. 3. John Benjamins

Publishing.

[24] Johan Van Benthem. 2011. Logical dynamics of information and interaction.

Cambridge University Press.

[25] Hans Van Ditmarsch, Wiebe Van Der Hoek, and Barteld Kooi. 2007. Dynamic

epistemic logic. Vol. 337. Springer Science & Business Media.

