Learning Class Disjointness Axioms Using Grammatical
Evolution
Thu Huong Nguyen, Andrea G B Tettamanzi

To cite this version:

Thu Huong Nguyen, Andrea G B Tettamanzi. Learning Class Disjointness Axioms Using Grammatical
Evolution. EuroGP 2019 - 22nd European Conference on Genetic Programming, Apr 2019, Leipzig,
Germany. pp.278-294, ￿10.1007/978-3-030-16670-0_18￿. ￿hal-02100230￿

HAL Id: hal-02100230

https://inria.hal.science/hal-02100230

Submitted on 15 Apr 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Learning Class Disjointness Axioms Using
Grammatical Evolution

Thu Huong Nguyen (cid:0)[0000−0003−3744−0467] and Andrea G.B.
Tettamanzi[0000−0002−8877−4654]

Universit´e Cˆote d’Azur, CNRS, Inria, I3S, France
{thu-huong.nguyen,andrea.tettamanzi}@univ-cotedazur.fr

Abstract. Today, with the development of the Semantic Web, Linked
Open Data (LOD), expressed using the Resource Description Frame-
work (RDF), has reached the status of “big data” and can be considered
as a giant data resource from which knowledge can be discovered. The
process of learning knowledge deﬁned in terms of OWL 2 axioms from
the RDF datasets can be viewed as a special case of knowledge discov-
ery from data or “data mining”, which can be called “RDF mining”.
The approaches to automated generation of the axioms from recorded
RDF facts on the Web may be regarded as a case of inductive reasoning
and ontology learning. The instances, represented by RDF triples, play
the role of speciﬁc observations, from which axioms can be extracted by
generalization. Based on the insight that discovering new knowledge is
essentially an evolutionary process, whereby hypotheses are generated
by some heuristic mechanism and then tested against the available evi-
dence, so that only the best hypotheses survive, we propose the use of
Grammatical Evolution, one type of evolutionary algorithm, for mining
disjointness OWL 2 axioms from an RDF data repository such as DBpe-
dia. For the evaluation of candidate axioms against the DBpedia dataset,
we adopt an approach based on possibility theory.

Keywords: Ontology learning · OWL 2 axiom · Grammatical Evolu-
tion.

1

Introduction

The manual acquisition of formal conceptualizations within domains of knowl-
edge, i.e. ontologies [1] is an expensive and time-consuming task because of the
requirement of involving domain specialists and knowledge engineers. This is
known as the “knowledge acquisition bottleneck ”. Ontology learning, which com-
prises the set of methods and techniques used for building an ontology from
scratch, enriching, or adapting an existing ontology in a semi-automatic fashion,
using several knowledge and information sources [2, 3], is a potential approach
to overcome this obstacle. An overall classiﬁcation of ontology learning methods
can be found in [4, 3, 5]. Ontology learning may be viewed as a special case of
knowledge discovery from data (KDD) or data mining, where the data are in a

Nguyen and Tettamanzi

special format and knowledge can consist of concepts, relations, or axioms from
a domain-speciﬁc application.

Linked Open Data (LOD) being Linked Data1 published in the form of an
Open Data Source can be considered as a giant real-world knowledge base. Such
a huge knowledge base opens up exciting opportunities for learning new knowl-
edge in the context of an open world. Based on URIs, HTTP, and RDF, Linked
Data is a recommended best practice for exposing, sharing, and connecting pieces
of data, information, and knowledge on the Semantic Web. Some approaches to
ontology learning from linked data can be found in [6–8]. The advantages of LOD
with respect to learning described in [8] is that it is publicly available, highly
structured, relational, and large compared with other resources. Ontology learn-
ing on the Semantic Web involves handling the enormous and diverse amount of
data in the Web and thus enhancing existing approaches for knowledge acquisi-
tion instead of only focusing on mostly small and uniform data collections.

In ontology learning, one of the critical tasks is to increase the expressive-
ness and semantic richness of a knowledge base (KB), which is called ontology
enrichment. Meanwhile, exploiting ontological axioms in the form of logical as-
sertions to be added to an existing ontology can provide some tight constraints
to it or support the inference of implicit information. Adding axioms to a KB
can yield several beneﬁts, as indicated in [9]. In particular, class disjointness
axioms are useful for checking the logical consistency and detecting undesired
usage patterns or incorrect assertions. As for the deﬁnition of disjointness [10],
two classes are disjoint if they do not possess any common individual according
to their intended interpretation, i.e., the intersection of these classes is empty in
a particular KB.

A simple example can demonstrate the potential advantages obtained by the
addition of this kind of axioms to an ontology. A knowledge base deﬁning terms
of classes like Person, City and asserting that Sydney is both a Person and
a City would be logically consistent, without any errors being recognized by a
reasoner. However, if a constraint of disjointness between classes Person and
City is added, the reasoner will be able to reveal an error in the modeling of
such a knowledge base. As a consequence, logical inconsistencies of facts can be
detected and excluded—thus enhancing the quality of ontologies.

As a matter of fact, very few DisjointClasses axioms are currently found in
existing ontologies. For example, in the DBpedia ontology, the query SELECT
?x ?y { ?x owl:disjointWith ?y } executed on November 11, 2018 returned
only 25 solutions, whereas the realistic number of class disjointness axioms gen-
erated from hundreds of classes in DBpedia (432 classes in DBpedia 2015-04, 753
classes in DBpedia 2016-04) is expected to be much more (in the thousands).
Hence, learning implicit knowledge in terms of axioms from a LOD repository
in the context of the Semantic Web has been the object of research in sev-
eral diﬀerent approaches. Recent methods [11, 12] apply top-down or intensional
approaches to learning disjointness which rely on schema-level information, i.e.,
logical and lexical decriptions of the classes. The contributions based on bottom-

1 http://linkeddata.org/

Learning Class Disjointness Axioms Using Grammatical Evolution

up or extensional approaches [9, 10], on the other hand, require the instances in
the dataset to induce instance-driven patterns to suggest axioms, e.g., disjoint-
ness class axioms.

Along the lines of extensional (i.e. instance-based) methods, we propose an
evolutionary approach, based on grammatical evolution, for mining implicit ax-
ioms from RDF datasets. The goal is to derive potential class disjointness axioms
of more complex types, i.e., deﬁned with the help of relational operators of in-
tersection and union; in other words, axioms like Dis(C1, C2), where C1 and C2
are complex class expressions including (cid:117) and (cid:116) operators. Also, an evaluation
method based on possibility theory is adopted to assess the certainty level of
induced axioms.

The rest of the paper is organized as follows: some related works are described
brieﬂy in Section 2. In Section 3, some background is provided. OWL 2 classes
disjointness axioms discovery with a GE approach is presented in Section 4. An
axiom evaluation method based on possibility theory is also presented in this
section. Section 5 provides experimental evaluation and comparison. Conclusions
and directions for future research are given in Section 6.

2 Related work

The most prominent related work relevant to learning disjointness axioms con-
sists of the contributions by Johanna V¨olker and her collaborators [12, 10, 13].
In early work, V¨olker developed supervised classiﬁers from LOD incorporated in
the LeDA tool [12]. However, the learning algorithms need a set of labeled data
for training that may demand expensive work by domain experts. In contrast
to LeDA, statistical schema induction via associative rule mining [10] was given
in the tool GoldMiner, where association rules are representations of implicit
patterns extracted from large amount of data and no training data is required.
Association rules are compiled based on a transaction table, which is built from
the results of SPARQL queries. That research only focused on generating axioms
involving atomic classes, i.e., classes that do not consist of logical expressions,
but only of a single class identiﬁer.

Another relevant research is the one by Lorenz B¨uhmann and Jens Lehmann,
whose proposed methodology is implemented in the DL-Learner system [11] for
learning general class descriptions (including disjointness) from training data.
Their work relies on the capabilities of a reasoning component, but suﬀers
from scalability problems for the application to large datasets like LOD. In [9],
they tried to overcome these obstacles by obtaining predeﬁned data queries,
i.e., SPARQL queries to detect speciﬁc axioms hidden within relevant data in
datasets for the purpose of ontology enrichment. That approach is very sim-
ilar to ours in that it uses an evolutionary algorithm for learning concepts.
B¨uhmann and Lehmann also developed methods for generating more complex
axiom types [14] by using frequent terminological axiom patterns from sev-
eral data repositories. One important limitation of their method is the time-
consuming and computationally expensive process of learning frequent axioms

Nguyen and Tettamanzi

patterns and converting them into SPARQL queries before generating actual
axioms from instance data. Also, the most frequent patterns refer to inclusion
and equivalence axioms like A ≡ B (cid:117) ∃r.C or A (cid:118) B (cid:117) ∃r.C.

Our solution is based on an evolutionary approach deriving from previous
work, but concentrating on a speciﬁc algorithm, namely Grammatical Evolution
(GE) [15] to generate class disjointness axioms from an existing RDF repository
which is diﬀerent from the use of Genertic Algorithm as in the approach of
B¨uhmann and Lehmann [14]. GE aims at overcoming one shortcoming of GP,
which is the growth of redundant code, also known as bloat. Furthermore, instead
of using probability theory, we applied a possibilistic approach to assess the
ﬁtness of axioms.

3 Background

This section provides a few background notions required to understand the ap-
plication domain of our contribution.

3.1 RDF Datasets

The Semantic Web2 (SW) is an extension of the World Wide Web and it can
be considered as the Web of data, which aims to make Web contents machine-
readable. The Linked Open Data3 (LOD) is a collection of linked RDF data. The
LOD covers the data layer of the SW, where RDF plays the roles of its standard
data model.

RDF uses as statements triples of the form (Subject, Predicate, Object). Ac-
cording to the World Wide Web Consortium (W3C), RDF4 has features that
facilitate data merging even if the underlying schemas diﬀer, and it speciﬁcally
supports the evolution of schemas over time without requiring all the data con-
sumers to be changed. RDF data may be viewed as an oriented, labeled multi-
graph. The query language for RDF is SPARQL,5 which can be used to express
queries across diverse data sources, whether the data is stored natively as RDF
or viewed as RDF via some middleware.

One of the prominent examples of LOD is DBpedia,6 which comprises a
rather rich collection of facts extracted from Wikipedia. DBpedia covers a broad
variety of topics, which makes it a fascinating object of study for a knowledge
extraction method. DBpedia owes to the collaborative nature of Wikipedia the
characteristic of being incomplete and ridden with inconsistencies and errors.
Also, the facts in DBpedia are dynamic, because they can change in time. DB-
pedia has become a giant repository of RDF triples and, therefore, it looks like
a perfect testing ground for the automatic extraction of new knowledge.

2 https://www.w3.org/standards/semanticweb/
3 https://www.w3.org/egov/wiki/Linked Open Data
4 https://www.w3.org/RDF/
5 https://www.w3.org/TR/rdf-sparql-query/
6 https://wiki.dbpedia.org/

Learning Class Disjointness Axioms Using Grammatical Evolution

3.2 OWL 2 Axioms

We are interested not only in extracting new knowledge from an existing knowl-
edge base expressed in RDF, but also in being able to inject such extracted
knowledge into an ontology in order to be able to exploit it to infer new logical
consequences.

While the former objective calls for a target language, used to express the
extracted knowledge, which is as expressive as possible, lest we throttle our
method, the latter objective requires using at most a decidable fragment of ﬁrst-
order logic and, possibly, a language which makes inference problems tractable.
OWL 27 is an ontology language for the Semantic Web with formally de-
ﬁned meaning which strikes a good compromise between these two objectives.
In addition, OWL 2 is standardized and promotes interoperability with diﬀerent
applications. Furthermore, depending on the applications, it will be possible to
select an appropriate proﬁle (corresponding to a diﬀerent language fragment)
exhibiting the desired trade-oﬀ between expressiveness and computational com-
plexity.

4 A Grammatical Evolution Approach to Discovering

OWL 2 Axioms

This section introduces a method based on Grammatical Evolution (GE) to mine
an RDF repository for class disjointness axioms. GE is similar to GP in automat-
ically generating variable-length programs or expressions in any language. In the
context of OWL 2 axiom discovery, the “programs” are axioms. A population of
individual axioms is maintained by the algorithm and iteratively reﬁned to ﬁnd
the axioms with the highest level of credibility (one key measure of quality for
discovered knowledge). In each iteration, known as a generation, the ﬁtness of
each individual in the population is evaluated using a possibilistic approach and
is the base for the parent selection mechanism. The oﬀspring of each generation
is bred by applying genetic operators on the selected parents. The overall ﬂow
of such GE algorithm is shown in Algorithm 1.

4.1 Representation

As in O’Neill et al [15] and unlike GP, GE applies the evolutionary process on
variable length binary strings instead of on the actual programs. GE has a clear
distinction in representation between genotype and phenotype. The genotype to
phenotype mapping is employed to generate axioms considered as phenotypic
programs by using the Backus-Naur form (BNF) grammar [15–17].

7 https://www.w3.org/TR/owl2-overview/

Nguyen and Tettamanzi

Algorithm 1 - GE for discovering axioms from a set of RDF datasets

Input: T : RDF Triples data; Gr : BNF grammar; popSize: the size of the population;

initlenChrom: the initialized length of chromosome ;
maxWrap: the maximum number of wrapping; pElite: elitism propotion
pselectSize: parent selection propotion; pCross: the probability of crossover;
pMut: the probability of mutation;

Output: Pop: a set of axioms discovered based on Gr

1: Initialize a list of chromosomes L of length initlenChrom.

Each codon value in chromosome are integer.

2: Create a population P of size popSize mapped from list of chromosomes L

on grammar Gr by performing popSize times CreateNewAxiom()

3: Compute the ﬁtness values for all axioms in Pop.
4: Initialize current generation number ( currentGeneration = 0 )
5: while( currentGeneration ¡ maxGenerations) do
6:
7: Create a list of elite axioms listElites with the propotion pElite of the number

Sort Pop by descending ﬁtness values

of the ﬁttest axioms in Pop

8: Add all axioms of listElites to a new population newPop
9:

Select the remaining part of population after elitism selection
Lr ← Pop\listElites
Eliminate the duplicates in Lr
Lr ← Distinct (Lr )

10:

11: Create a a list of axioms listCrossover used for crossover operation

with the propotion pselectSize of the number of
the ﬁttest individuals in Lr

Shuﬄe(listCrossover )
for (i=0,1....listCrossover.length-2 ) do

11:
12:
10:
13:
14:
15:
16:
17:

parent1 ← listCrossover [i]
parent2 ← listCrossover [i+1]
child1, child2 ← CROSSOVER(parent1,parent2 ) with the probability pCross
for each oﬀspring {child1,child2 } do MUTATION (oﬀspring)
Compute ﬁtness values for child1, child2
Select w1, w2 - winners of competition between parents and oﬀsprings
w1,w2 ← CROWDING((parent1, parent2, child1, child2)
Add w 1, w2 to new population newPop

Pop= newPop
Increase the number of generation curGeneration by 1

18:
19:
20:
21: return Pop

Structure of BNF Grammar We applied the extended BNF grammar con-
sisting of the production rules extracted from the normative grammar8 of OWL 2
in the format used in W3C documentation for constructing diﬀerent types of
OWL 2 axioms. The noteworthy thing is that the use of a BNF grammar here
does not focus on deﬁning what a well-formed axiom may be, but on generating
well-formed axioms which may express the facts contained in a given RDF triple
store. Hence, resources, literals, properties, and other elements of the language
that actually occur in the RDF repository could be generated. We organized our
BNF grammar in two main parts (namely static and dynamic) as follows:

– the static part contains production rules deﬁning the structure of the axioms
loaded from the text ﬁle. Diﬀerent grammars will generate diﬀerent kinds of
axioms.

8 https://www.w3.org/TR/owl2-syntax/

Learning Class Disjointness Axioms Using Grammatical Evolution

– the dynamic part contains production rules for the low-level non-terminals,
which we will call primitives. These production rules are automatically built
at runtime by querying the SPARQL endpoint of the RDF repository at
hand.

This approach to organizing the structure of BNF grammar ensures the changes
in the contents of RDF repositories will not require to rewrite the grammar.

In the following, we will refer to generating class disjointness axioms con-
taining atomic expression such as DisjointClasses(Film, WrittenWork) or complex
expression in the cases of relational operators, i.e., intersection and union, such
as DisjointClasses(Film, ObjectIntersectionOf(Book,ObjectUnionOf(Comics, Musi-
calWork))). We built the following pattern of the grammar structured for gener-
ating class disjointness axioms:

% Static part

(r1) Axiom := ClassAxiom
(r2) ClassAxiom := DisjointClasses
(r3) DisjointClasses := ’DisjointClasses’ ’(’ ClassExpression ’ ’ClassExpression ’)’
(r4) ClassExpression :=

Class

(0)
| ObjectUnionOf
(1)
| ObjectIntersectionOf (2)

(r5) ObjectUnionOf := ’ObjectUnionOf’ ’(’ ClassExpression ’ ’ ClassExpression ’)’
(r6) ObjectIntersectionOf := ’ObjectIntersectionOf’ ’(’ ClassExpression’ ’ClassExpression ’)’

% Dynamic part - Primitives

(r7) Class := % production rules are constructed by using SPARQL queries

This produces rules of the primitive Class, which will be ﬁlled by using
SPARQL queries to extract the IRI of a class mentioned in the RDF store. An
example representing a small excerpt of an RDF triple repository is the following:

PREFIX dbr: http://DBpedia.org/resource/
PREFIX dbo: http://DBpedia.org/ontology/
PREFIX rdf: http://www.w3.org/1999/02/22\-rdf-syntax-ns\#

rdf:type
dbr:Quiet_City_(film)
rdf:type
dbr:Cantata
rdf:type
dbr:The_Times
dbr:The_Hobbit
rdf:type
dbr:Fright_Night_(comics) rdf:type

dbo:Film.
dbo:MusicalWork.
dbo:WrittenWork.
dbo:Book.
dbo:Comic

and options for the nonterminal Class are represented as follows:

(r7) Class := dbo:Film

|
|
|
|

dbo:MusicalWork
dbo:WrittenWork
dbo:Book
dbo:Comic

(0)
(1)
(2)
(3)
(4)

Encoding and Decoding Individual axioms are encoded as variable-length
binary strings with numerical chromosomes. The binary string consists of a se-
quence of 8-bit words referred to as codons.

Nguyen and Tettamanzi

According to the structure of the above BNF grammar, chromosomes are then
decoded into OWL 2 axioms in diﬀerent OWL syntaxes through the mapping
process according to the function:

Rule = Codon value modulo Number of Rules for the current terminal

(1)

In the advantageous cases, axioms are generated before the end of the genome
is reached; otherwise, a wrapping operator [15, 16] is applied and the reading
of codons will continue from the beginning of the chromosome, until the maxi-
mum allowed number of wrapping events is reached. An unsuccessful mapping
will happen if the threshold on the number of wrapping events is reached but
the individual is still not completely mapped; in this case, the individual is as-
signed the lowest possible ﬁtness. The production rule for ClassExpression is
recursive and may lead to a large fan-out; to alleviate this problem and pro-
mote ”reasonable” axioms, we increase the probability of obtaining a successful
mapping to complex axiom expressions, we double the appearance probability
of non-terminal ClassExpression. Rule (r4) in the grammar is modiﬁed to

(r4) ClassExpression :=

Class
| Class
| ObjectUnionOf
| ObjectIntersectionOf

(0)
(1)
(2)
(3)

4.2 Initialization

In the beginning of the evolutionary process, a set of chromosomes, i.e., genotypic
individuals, are randomly initialized once and for all. Each chromosome is a set
of integers with the initialized length initlenChrom. Its length can be extended to
maxlenChrom in the scope of the threshold of maxWrap in the wrapping process.
The next step is the transformation of genotypes into phenotypic individuals, i.e.,
axioms according to grammar Gr, by means of the mapping process based on the
input grammar called CreateNewAxiom() operator. The population of popSize
class disjointness axioms is created by iterating popSize times CreateNewAxiom()
operator described in Algorithm 2.

Algorithm 2 - CreateNewAxiom()

Input: Chr : Chromosome - a set of integers; Gr : BNF grammar
Output: A: a new axiom individual

1: maxlenChrom ← initlenChrom * maxWrap
2: ValCodon ← random(maxValCodon).
3: Set up Chr as input genotype gp used in mapping proccess to axiom individual A
4: while (Chr.length <maxlenChrom) && (incomplete mapping) do
5:

mapping from input genotype gp to output phenotype of axiom individual A
according to grammar Gr

6: return A

Learning Class Disjointness Axioms Using Grammatical Evolution

4.3 Parent selection

Before executing the selection operator, the axioms in the populations are evalu-
ated and ranked in descending order of their ﬁtness. To combat the loss of ﬁttest
axioms as a result of the application of the variation operators, elitism selection
is applied to copy the small proportion pElite of the best axioms into the next
generation (line 7-8 of Algorithm 1). In the remaining part of the population,
the elimination of duplicates is carried out to ensure only distinct individuals
will be included in the candidate list for parent selection. The parent selection
mechanism amounts to choosing the ﬁttest individuals from this list for repro-
duction. Fig. 1. illustrates the process of selecting potential candidate solutions
for recombination, i.e., a list of parents. The top proportion pselectSize of dis-
tinct individuals in the candidate list is selected and it is replicated to maintain
the size popSize of population. The list of parents is shuﬄed and the individuals
are paired in order from the beginning to the end of the list.

Fig. 1. An illustration of the parent selection mechanism.

4.4 Variation Operators

The purpose of these operators is to create new axioms from old ones. The stan-
dard genetic operators of crossover and mutation in the Evolutionary Algorithms
(EA) are applied in the search space of genotypes. Well-formed individuals will
then be generated syntactically from the new genotypes in the genotype-to-
phenotype mapping process.

Crossover A standard one-point crossover is employed whereby a single crossover
point on the chromosomes of both parents is chosen randomly. The sets of codons

Nguyen and Tettamanzi

Algorithm 3 - Crowding(parent1, parent2, oﬀspring1, oﬀspring2)

Input: parent1, parent2, child 1, child 2 : a crowd of individual axioms;
Output: A: ListWinners- a list containing two winners of individual axioms

1:

d1 ← DISTANCE(parent1,child1) +DISTANCE (parent2,child2)
d2 ← DISTANCE(parent1, child2) + DISTANCE(parent2, child1)
in which DISTANCE(parent, child) - the number of distinct codons between
parent and child.

2: if (d1 >d2 )

ListWinners[0]← COMPARE(parent1,child1)
ListWinners[1]← COMPARE(parent2,child2)

else

ListWinners[0]← COMPARE(parent1,child2)
ListWinners[1]← COMPARE(parent2,child1)
in which COMPARE(parent, child) - deﬁnes which individual in (parent,child)
having higher ﬁtness value.

3: return ListWinners

beyond those points are exchanged between the two parents with probability
pCross. The result of this exchange is two oﬀspring genotypes. The mapping of
these genotype into phenotypic axioms is performed by executing the Create-
NewAxiom() operator (Algorithm 2) again with the oﬀspring chromosomes as
input.

Mutation The mutation is applied to the oﬀspring genotypes of crossover with
probability pMut. A selected individual undergoes single-point mutation, i.e. a
codon is selected at random, and this codon is replaced with a new randomly
generated codon.

4.5 Survival selection

In order to preserve population diversity, we used the Deterministic Crowding
approach developed by Mahfoud [18]. Each oﬀspring competes with its most
similar peers, based on a genotypic comparison, to be selected for inclusion in
the population of the next generation. Algorithm 3 describes this approach in
detail. Even though we are aware that computing distance at the phenotypic level
would yield more accurate results, we chose to use genotypic distance because it
is much faster and easier to compute.

4.6 Fitness Evaluation

As a consequence of the heterogeneous and collaborative character of the linked
open data, some facts (instances) in the RDF repository may be missing or erro-
neous. This incompleteness and noise determines a sort of epistemic uncertainty
in the evaluation of the quality of a candidate axiom. In order to properly cap-
ture this type of uncertainty, typical of an open world, which contrasts with
the ontic uncertainty typical of random processes, we adopt an axiom scoring

Learning Class Disjointness Axioms Using Grammatical Evolution

heuristics based on possibility theory, proposed in [19], which is suitable for deal-
ing with incomplete knowledge. This is a justiﬁed choice for assessing knowledge
extracted from an RDF repository. We now provide a summary of this scoring
heuristics.

Possibility theory [20] is a mathematical theory of epistemic uncertainty.
Given a ﬁnite universe of discourse Ω, whose elements ω ∈ Ω may be regarded
as events, values of a variable, possible worlds, or states of aﬀairs, a possibility
distribution is a mapping π : Ω → [0, 1], which assigns to each ω a degree
of possibility ranging from 0 (impossible, excluded) to 1 (completely possible,
normal). A possibility distribution π for which there exists a completely possible
state of aﬀairs (∃ω ∈ Ω : π(ω) = 1) is said to be normalized.

A possibility distribution π induces a possibility measure and its dual neces-
sity measure, denoted by Π and N respectively. Both measures apply to a set
A ⊆ Ω (or to a formula φ, by way of the set of its models, A = {ω : ω |= φ}),
and are usually deﬁned as follows:

Π(A) = max
ω∈A

π(ω);

N (A) = 1 − Π( ¯A) = min
ω∈ ¯A

{1 − π(ω)}.

(2)

(3)

In other words, the possibility measure of A corresponds to the greatest of the
possibilities associated to its elements; conversely, the necessity measure of A is
equivalent to the impossibility of its complement ¯A.

A generalization of the above deﬁnition can be obtained by replacing the min

and the max operators with any dual pair of triangular norm and co-norm.

In the case of possibilistic axiom scoring, the basic principle for establishing
the possibility of a formula φ should be that the absence of counterexamples to
φ in the RDF repository means Π([φ]) = 1, i.e., that φ is completely possible.
Let φ be an axiom that we wish to evaluate (i.e., a theory). The content of an
axiom φ that we wish to evaluate is deﬁned as a set of logical consequences

content(φ) = {ψ : φ |= ψ},

(4)

obtained through the instatiation of φ to the vocabulary of the RDF repository;
the cardinality of content(φ) is ﬁnite and every formula ψ ∈ content(φ) may be
readily tested by means of a SPARQL ASK query. Let us deﬁne uφ = (cid:107)content(φ)(cid:107)
as the support of φ. Let then u+
φ be the number of conﬁrmations (basic statements
ψ that are satisﬁed by the RDF repository) and u−
φ the number of counterex-
amples (basic statements ψ that are falsiﬁed by the RDF repository).

The possibility measure Π(φ) and the necessity measure N (φ) of an axiom

have been deﬁned as follows in [19]: for uφ > 0,

Π(φ) = 1 −

(cid:118)
(cid:117)
(cid:117)
(cid:116)1 −

(cid:32) uφ − u−
uφ

φ

(cid:33)2

;

(5)

N (φ) =

(cid:118)
(cid:117)
(cid:117)
(cid:116)1 −

(cid:33)2

(cid:32) uφ − u+
uφ

φ

,

if Π(φ) = 1, 0 otherwise.

(6)

Nguyen and Tettamanzi

The cardinality of the sets of the facts in the RDF repository reﬂects the general-
ity of each axiom. An axiom is all the more necessary as it is explicitly supported
by facts, i.e., conﬁrmations, and not contradicted by any fact, i.e., counterex-
amples, while it is the more possible as it is not contradicted by any fact. These
numbers of conﬁrmations and counterexamples are counted by executing corre-
sponding SPARQL queries via an accessible SPARQL endpoint.

In principle, the ﬁtness of axiom φ should be directly proportional to its
necessity N (φ), its possibility Π(φ), and its support uφ, which is an indicator
of its generality. In other words, what we are looking for is not only credible
axioms, but also general ones. A deﬁnition of the ﬁtness function that satisﬁes
such requirement is

f (φ) = uφ ·

Π(φ) + N (φ)
2

,

(7)

which we adopted for our method.

5 Experiment & Result

We applied our approach to mine the classes disjointness axioms relevant to the
topic Work in DBpedia. The statistical data of classes and instances about this
topic in DBpedia 2015-04 is given in Table 1.
All data used in this experiment is represented in the form of RDF triples, as
explained in Section 3. In order to assess its ability to discover axioms, we ran

Table 1. Statistical data in the topic Work in DBpedia

Total number of classes
Total number of classes having instances
Total number of instances

62
53
519,5019

the GE indicated in Section 4 by repeating the sample procedure of Algorithm 1
for each run with the same parameters indicated in Table 2. The chart in Fig. 2
illustrates the average diversity of the population of axioms over the generations
of the evolutionary process. It shows how many diﬀerent “species” of axioms
are contained in the population, i.e., axioms that cover diﬀerent aspects of the
known facts. One of the remarkable points here is that there is a more rapid loss
of diversity in the phenotype axioms compared with this decrease in the genotype
ones. The use of Crowding method on genotypes instead of phenotypes can be the
reason of this diﬀerence. Likewise, a set of codons of two parent chromosomes
which are used for the mapping to phenotypes can fail to be swapped in the
single-point crossover operator.

From the chart in Fig. 3, we can observe a gradual increase in the quality of

discovered axioms over generations.

In order to evaluate the eﬀectiveness of our method in discovering disjoint-
ness class axioms of the Work on RDF datasets of DBpedia, a benchmark of

Learning Class Disjointness Axioms Using Grammatical Evolution

Fig. 2. The diversity of axioms over generations

Fig. 3. The growth of average ﬁtness over generations

12345678910111213141516171819202122232425262728293000.10.20.30.40.50.60.70.80.91Average axioms diversity over generations(20 runs)Distinct genotypesDistinct phenotypesGenerationsThepropotionofdistinctaxioms1234567891011121314151617181920212223242526272829300100000020000003000000400000050000006000000The growth of average fitness(20runs)GenerationsAveragefitnessNguyen and Tettamanzi

Table 2. Input parameter values for GE

Parameter
popSize
numGenerations
initlenChrom
maxWrap
pCross
pMut
pselectSize
pElite

Value
500
30
20
2
80%
1%
70%
2%

Table 3. Experimental results

Our approach

GoldMiner

Precision (per run)
Recall (per run)
Recall (over 20 runs)

Complex axioms Atomic axioms Atomic axioms
0.95 ± 0.02
0.15 ± 0.017
0.54

0.867 ± 0.03
N/A
N/A

0.95
0.38
0.38

class disjointness axioms about this topic was manually created, which we called
Gold Standard. The process of creating the Gold Standard was carried out by
knowledge engineers and consisted of two phases. In the ﬁrst phase, the disjoint-
ness of the top-most classes to their siblings was assessed manually. Therefrom,
two sibling classes being disjoint will infer automatically the disjointness of their
corresponding pair of subclasses. This process is repeated in the same way on
the next level of concepts. The second phase of Gold Standard creation con-
sisted in manually annotating the disjointness for the not yet noted pairs of
classes which did not belong to the cases given in the previous phase. The result
of the completion of the Gold Standard is the disjointness evaluation between
1,891 pairs of distinct classes relevant to the chosen topic. Table 3 summarizes
the performance of our approach in discovering axioms with the parameters
setting in Table 2 over 20 runs. The precision and recall are computed by com-
parison to the Gold Standard. Although the main purpose in our research is to
focus on exploring the more complex disjointness axioms which contain logical
relationship—intersection and union expression, we also performed experiments
to generate axioms involving atomic classes only, for comparison purpose. We
carry out the comparison with the results of GoldMiner [10] in generating class
disjointness axioms about the topic Work. The precision and recall are com-
puted by comparison to the Gold Standard. The results in Table 3 conﬁrm the
high accuracy of our approach in discovering class disjointness axioms in the
case of atomic expressions (Precision = 0.95 ± 0.02). Also, the recall value is
higher than the value in GoldMiner. There are a number of class disjointness
axioms generated in our experiments which are absent in the result of Gold-
Miner. For example, there are no any axioms relevant to class Archive in the
axioms generated by GoldMiner. In the case of more complex axioms, there is

Learning Class Disjointness Axioms Using Grammatical Evolution

a smaller degree of precision (Precision = 0.867 ± 0.03). The reason may stem
from the complexity in the content of generated axioms which is relevant to
more diﬀerent classes. We do not present the recall for the case of complex ax-
ioms, since the discovery process of this type of axioms cannot deﬁne how many
of the complex axioms should have been generated. After 20 runs, from 10,000
candidate individual axioms, we got 5,728 qualiﬁed distinct complex axioms.
We performed an analysis of the discovered axioms and found some noticeable
points. Almost all generated axioms have high ﬁtness values with millions of
support instances from the DBpedia dataset, which witness the generality of
the discovered axioms. However, we found some deﬁciencies in determining the
disjointness of classes. As in the case of axiom DisjointClasses(MovingImage, Ob-
jectUnionOf(Article,ObjectUnionOf(Image, MusicalWork ))), 4,839,992 triples in
DBpedia conﬁrm that this class disjointness axiom is valid. However, accord-
ing to the Gold Standard, these two classes should not be disjoint a priori.
Indeed, the class MovingImage can be assessed as a subclass of Image, which
makes the disjointness between class MovingImage and any complex class ex-
pression involving relational operator union of class Image altogether impossi-
ble. Another similar case is the axiom DisjointClasses(ObjectUnionOf(Article, Ob-
jectUnionOf(ObjectUnionOf(ObjectUnionOf (ObjectUnionOf(TelevisionShow, Writ-
tenWork), MusicalWork), Image), Film)), UndergroundJournal), having 5,037,468
triples in its support. However, according to the Gold Standard, these two classes
should not be disjoint.

From the above examples we can infer that the main reason for such erro-
neous axioms may lie in the inconsistencies and errors in the DBpedia dataset.
Therefore, a necessary direction to improve the quality of the knowledge base is
to use the results of our mining algorithms to pinpoint errors and inconsistencies
and thus aim at tighter constraints by excluding problematic triples from the
RDF repository.

6 Conclusion and Future Work

We proposed an algorithm based on GE to discover class disjointness axioms
from the DBpedia dataset relevant to the topic “Work”. The experiment results
have allowed us to evaluate the eﬀectiveness of the model and analyze some of
its shortcomings.

In future work, we will focus on three main directions:

1. improving the diversity of generated axioms by applying the crowding method

at the level of phenotypes;

2. mining diﬀerent types of axioms like identity axioms, equivalence axioms

and relevant to broader topics;

3. enhancing the performance of the algorithm on parallel hardware in order

to be able to carry out bigger data analytics.

Nguyen and Tettamanzi

References

1. Guarino, N., Oberle, D., Staab, S.: What Is an Ontology? Handbook on Ontologies.

International Handbooks on Information Systems, Springer (2009)

2. Maedche, A., Staab, S.: Ontology learning for the semantic web. IEEE Intelligent

Systems 16(2), 72–79 (March 2001)

3. Lehmann, J., V¨olker, J.: Perspectives on Ontology Learning, Studies on the Se-

mantic Web, vol. 18. IOS Press (2014)

4. Drumond, L., Girardi, R.: A survey of ontology learning procedures. In: WONTO.

CEUR Workshop Proceedings, vol. 427. CEUR-WS.org (2008)

5. Hazman, M., El-Beltagy, S.R., Rafea, A.: Article: A survey of ontology learning
approaches. International Journal of Computer Applications 22(8), 36–43 (May
2011)

6. Zhao, L., Ichise, R.: Mid-ontology learning from linked data. In: JIST. Lecture

Notes in Computer Science, vol. 7185, pp. 112–127. Springer (2011)

7. Tiddi, I., Mustapha, N.B., Vanrompay, Y., Aufaure, M.: Ontology learning from
open linked data and web snippets. In: OTM Workshops. Lecture Notes in Com-
puter Science, vol. 7567, pp. 434–443. Springer (2012)

8. Zhu, M.: DC proposal: Ontology learning from noisy linked data. In: International
Semantic Web Conference (2). Lecture Notes in Computer Science, vol. 7032, pp.
373–380. Springer (2011)

9. B¨uhmann, L., Lehmann, J.: Universal OWL axiom enrichment for large knowl-
edge bases. In: EKAW. Lecture Notes in Computer Science, vol. 7603, pp. 57–71.
Springer (2012)

10. V¨olker, J., Fleischhacker, D., Stuckenschmidt, H.: Automatic acquisition of class

disjointness. J. Web Sem. 35, 124–139 (2015)

11. Lehmann, J.: Dl-learner: Learning concepts in description logics. Journal of Ma-

chine Learning Research 10, 2639–2642 (2009)

12. V¨olker, J., Vrandecic, D., Sure, Y., Hotho, A.: Learning disjointness. In: ESWC.
Lecture Notes in Computer Science, vol. 4519, pp. 175–189. Springer (2007)
13. Fleischhacker, D., V¨olker, J.: Inductive learning of disjointness axioms. In: OTM
Conferences (2). Lecture Notes in Computer Science, vol. 7045, pp. 680–697.
Springer (2011)

14. B¨uhmann, L., Lehmann, J.: Pattern based knowledge base enrichment. In: Inter-
national Semantic Web Conference (1). Lecture Notes in Computer Science, vol.
8218, pp. 33–48. Springer (2013)

15. O’Neill, M., Ryan, C.: Grammatical evolution. Trans. Evol. Comp 5(4), 349–358

(Aug 2001), http://dx.doi.org/10.1109/4235.942529

16. Dempsey, I., O’Neill, M., Brabazon, A.: Foundations in Grammatical Evolution for
Dynamic Environments - Chapter 2 Grammatical Evolution, Studies in Computa-
tional Intelligence, vol. 194. Springer (2009)

17. Ryan, C., Collins, J.J., O’Neill, M.: Grammatical evolution: Evolving programs for
an arbitrary language. In: EuroGP. Lecture Notes in Computer Science, vol. 1391,
pp. 83–96. Springer (1998)

18. Mahfoud, S.W.: Crowding and preselection revisited. In: PPSN. pp. 27–36. Elsevier

(1992)

19. Tettamanzi, A.G.B., Faron-Zucker, C., Gandon, F.L.: Testing OWL axioms against
RDF facts: A possibilistic approach. In: EKAW. Lecture Notes in Computer Sci-
ence, vol. 8876, pp. 519–530. Springer (2014)

20. Zadeh, L.A.: Fuzzy sets as a basis for a theory of possibility. Fuzzy Sets and Systems

1, 3–28 (1978)

