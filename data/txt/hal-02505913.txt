Widening for MDL-based Retail Signature Discovery
Clément Gautrais, Peggy Cellier, Matthijs van Leeuwen, Alexandre Termier

To cite this version:

Clément Gautrais, Peggy Cellier, Matthijs van Leeuwen, Alexandre Termier. Widening for MDL-
based Retail Signature Discovery. IDA 2020 - Symposium on Intelligent Data Analysis, Apr 2020,
Konstanz, Germany. pp.1-12. ￿hal-02505913￿

HAL Id: hal-02505913

https://inria.hal.science/hal-02505913

Submitted on 11 Mar 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Widening for MDL-based
Retail Signature Discovery

Cl´ement Gautrais1[0000−0001−8486−9616](cid:63), Peggy Cellier2, Matthijs van Leeuwen3,
and Alexandre Termier2

1 KU Leuven, Department of Computer Science, Leuven, Belgium
clement.gautrais@cs.kuleuven.be
2 Univ Rennes, Inria, INSA, CNRS, IRISA
3 LIACS, Leiden University, Leiden, the Netherlands

Abstract. Signature patterns have been introduced to model repetitive
behavior, e.g., of customers repeatedly buying the same set of products
in consecutive time periods. A disadvantage of existing approaches to
signature discovery, however, is that the required number of occurrences
of a signature needs to be manually chosen. To address this limitation, we
formalize the problem of selecting the best signature using the minimum
description length (MDL) principle. To this end, we propose an encoding
for signature models and for any data stream given such a signature
model. As ﬁnding the MDL-optimal solution is unfeasible, we propose a
novel algorithm that is an instance of widening, i.e., a diversiﬁed beam
search that heuristically explores promising parts of the search space.
Finally, we demonstrate the eﬀectiveness of the problem formalization and
the algorithm on a real-world retail dataset, and show that our approach
yields relevant signatures.

Keywords: signature discovery · minimum description length · widening

1

Introduction

When analyzing (human) activity logs, it is especially important to discover
recurrent behavior. Recurrent behavior can indicate, for example, personal pref-
erences or habits, and can be useful in contexts such as personalized marketing.
Some types of behavior are elusive to traditional data mining methods: for ex-
ample, behavior that has some temporal regularity but not strong enough to be
periodic, and which does not form simple itemsets or sequences in the log. A
prime example is the set of products that is essential to a retail customer: all of
these products are bought regularly, but often not periodically due to diﬀerent
depletion rates, and they are typically bought over several transactions—in any
arbitrary order—rather than all at the same time.

To model and detect such behavior, we have proposed signature patterns [3]:
patterns that identify irregular recurrences in an event sequence by segmenting
the sequence (see Figure 1). We have shown the relevance of signature patterns

(cid:63) This work has received funding from the European Research Council (ERC) under the
European Unions Horizon 2020 research and innovation programme (grant agreement
No [694980] SYNTH: Synthesising Inductive Data Models)

2

C. Gautrais et al.

in the retail context, and demonstrated that they are general enough to be used
in other domains, such as political speeches [2]. As a disadvantage, however,
signature patterns require the analyst to provide the number of recurrences, i.e.,
the number of segments in the segmentation. This number of segments inﬂuences
the signature: fewer segments give a more detailed signature, while more segments
result in a simpler signature. Although in some cases domain experts may have
some intuition on how to choose the number of segments, it is often diﬃcult to
decide on a good trade-oﬀ between the number of segments and the complexity
of the signature. The main problem that we study in this paper is therefore how
to automatically set this parameter in a principled way, based on the data.

Our ﬁrst main contribution is a problem formalization that deﬁnes the best
signature for a given dataset, so that the analyst no longer needs to choose
the number of segments. By considering the signature corresponding to each
possible number of segments as a model, we can naturally formulate the problem
of selecting the best signature as a model selection problem. We formalize this
problem using the minimum description length (MDL) principle [4], which,
informally, states that the best model is the one that compresses the data best.
The MDL principle perfectly ﬁts our purposes because 1) it allows to select the
simplest model that adequately explains the data, and 2) it has been previously
shown to be very eﬀective for the selection of pattern-based models (e.g., [11, 7]).
After deﬁning the problem using the MDL principle, the remaining question
is how to solve it. As the search space of signatures is extremely large and the
MDL-based problem formulation does not oﬀer any properties that could be used
to substantially prune the search space, we resort to heuristic search. Also here,
the properties of signature patterns lead to technical challenges. In particular,
we empirically show that a na¨ıve beam search often gets stuck in suboptimal
solutions. Our second main contribution is therefore to propose a diverse beam
search algorithm, i.e., an instance of widening [9], that ensures that a diverse set
of candidate solutions is maintained on each level of the beam search. For this,
we deﬁne a distance measure for signatures based on their segmentations.

2 Preliminaries

Sequence α
Transactions

a
T1

c
T2

a, b, d
T3

b
T4

a
T5

a, b
T6

a, b, c, e
T7

Segments

S1

S2

S3

S4

Fig. 1. A sequence of transactions and a 4-segmentation. We have the signature items
R = {a, b}, the remaining items E = {c, d, e}, the set of items I = {a, b, c, d, e}, the
segmentation S = (cid:104)[T1, T2, T3], [T4, T5], [T6], [T7](cid:105).

Widening for MDL-based Retail Signature Discovery

3

Tj ∈Si

Si∈S(α,k)((cid:83)

Signatures. Let us ﬁrst recall the deﬁnition of a signature as presented in [3].
Let I be the set of all items, and let α = (cid:104)T1 . . . Tn(cid:105), Ti ⊆ I be a sequence of
itemsets. A k-segmentation of α, denoted S(α, k) = (cid:104)S1 . . . Sk(cid:105), is a sequence of k
non-overlapping consecutive sub-sequences of α, denoted Si and called segments,
each consisting of consecutive transactions. An example of a 4-segmentation is
given in Figure 1. Given S(α, k) = (cid:104)S1 . . . Sk(cid:105), a k-segmentation of α, we have
Rec(S(α, k)) = (cid:84)
Tj): the set of all recurrent items that are
present in each segment of S(α, k). For example in Figure 1, the segmentation
S(α, 4) = (cid:104)S1, S2, S3, S4(cid:105) gives Rec(S(α, 4)) = {a, b}. Given k and α, one can
compute Smax(α, k), the set of k-segmentation of α yielding the largest sets
of recurrent items: Smax(α, k) = argmaxS(α,k) |Rec(S(α, k))|. For example, in
Figure 4, (cid:104)S1, S2, S3, S4(cid:105) is the only 4-segmentation yielding two recurrent items.
As all other 4-segmentations either yield zero or one recurrent item, Smax(α, 4) =
{(cid:104)S1, S2, S3, S4(cid:105)}. A k-signature (also named signature when k is clear from
context) is then deﬁned as a maximal set of recurrent items in a k-segmentation
S, with S ∈ Smax(α, k). As Smax(α, k) can contain several segmentations, we
deﬁne the k-signature set Sig(α, k), which contains all k-signatures: Sig(α, k) =
{Rec(Sm(α, k)) | Sm ∈ Smax(α, k)}. k gives the number of recurrences of the
recurrent items in sequence α. Given a number of recurrences k, ﬁnding a k-
signature relies on ﬁnding a k-segmentation that maximizes the size of the itemset
that occurs in each segment of that segmentation. For example, in Figure 1, given
segmentation S = (cid:104)S1, S2, S3, S4(cid:105) and given that Smax(α, 4) = {S}, we have
Sig(α, 4) = {Rec(S)} = {{a, b}}. For simplicity, the segmentation associated
with a k-signature in Sig(α, k) is denoted S = (cid:104)S1 . . . Sk(cid:105), and the signature
items are denoted R ⊆ I. The remaining items are denoted E, i.e., E = I \ R.

Minimum description length (MDL). Let us now brieﬂy introduce the basic
notions of the minimum description length (MDL) principle [4] as it is commonly
used in compression-based pattern mining [7]. Given a set of models M and
a dataset D, the best model M ∈ M is the one that minimizes L(D, M ) =
L(M ) + L(D|M ), with L(M ) the length, in bits, of the encoding of M , and
L(D|M ) the length, in bits, of the encoding of the data given M . This is called
two-part MDL because it separately encodes the model and the data given the
model, which results in a natural trade-oﬀ between model complexity and data
complexity. To fairly compare all models, the encoding has to be lossless. To use
the MDL principle for model selection, the model class M has to be deﬁned (in
our case, the set of all signatures), as well as how to compute the length of the
model and the length of the data given the model. It should be noted that only
the encoded length of the data is of interest, not the encoded data itself.

3 Problem Deﬁnition

To extract recurrent items from a sequence using signatures, one must deﬁne the
number of segments k. Providing meaningful values for k usually requires expert
knowledge and/or many tryouts, as there is no general rule to automatically set

4

C. Gautrais et al.

k. Our problem is therefore to devise a method that adjusts k, depending on the
data at hand. As this is a typical model selection problem, our approach relies
on the minimum description length principle (MDL) to ﬁnd the best model from
a set of candidate models. However, the signature model must be reﬁned into a
probabilistic model to use the MDL principle for model selection. Especially, the
occurrences of items in α should be deﬁned according to a probability distribution.
With no information about these occurrences, the uniform distribution is the
most natural choice. Indeed, without information on the transaction in which
an item occurs, the best is to assume it can occur uniformly at random in any
transaction of the sequence α. Moreover, the choice of the uniform distribution
has been shown to minimize the worst case description length [4].

To make the signature model probabilistic, we assume that it generates three
diﬀerent types of occurrences independently and uniformly. As the signature
gives the information that there is at least one occurrence of every signature
item in every segment, the ﬁrst type of occurrences correspond to this one
occurrence of signature items in every segment. These are generated uniformly
over all the transactions of every segment. The second type of occurrences are
the remaining signature items occurrences. Here, the information is that these
items already have occurrences generated by the previous type of occurrences.
As α is a sequence of itemsets, an item can occur at most once in a transaction.
Hence, for a given signature item, the second type of occurrences for this item
are distributed uniformly over the transactions where this item does not already
occur for the ﬁrst type of occurrences. Finally, the third type are the occurrences
of the remaining items: the items that are not part of the signature. There is
no information about these items occurrences, hence we assume them to be
generated uniformly over all transactions of α.

With these three types of occurrences, the signature model is probabilistic: all
occurrences in α are generated according to a probability distribution that takes
into account the information provided by the signature speciﬁcation. Hence, we
can now deﬁne the problem we are tackling:
Problem 1. Let S denote the set of signatures for all values of k, S = (cid:83)|α|
Given a sequence α, it follows from the MDL principle that the best signature
S ∈ S is the one that minimizes the two-part encoded length of S and α, i.e.,

k=1 Sig(α, k).

where L(α, S) is the two-part encoded length that we present in the next section.

SM DL = argminS∈S L(α, S),

4 An Encoding for Signatures

As typically done in compression-based pattern mining [7], we use a two-part
MDL code that leads to decomposing the total encoded length L(α, S) into
two parts: L(S) and L(α|S), with the relation L(α, S) = L(S) + L(α|S). In the
upcoming subsection we deﬁne L(S), i.e., the encoded length of a signature, after
which Subsection 4.2 introduces L(α|S), i.e., the length of the sequence α given
a signature S. In the remainder of this paper, all logarithms are in base 2.

Widening for MDL-based Retail Signature Discovery

5

4.1 Model Encoding: L(S)

A signature is composed of two parts: 1) the signature items, and 2) the signature
segmentation. The two parts are detailed below.

Signature items encoding The encoding of the signature items consists
of three parts. The signature items are a subset of I, hence we ﬁrst encode the
number of items in I. A common way to encode non-negative integer numbers
4. This yields a code
is to use the universal code for integers [4, 8], denoted LN
of size LN(|I|). Next, we encode the number of items in the signature, using
again the universal code for integers, with length LN(|R|). Finally, we encode the
items of the signature. As the order of signature items is irrelevant, we can use
an |R|-combination of |I| elements without replacement. This yields a length of
log((cid:0) |I|

(cid:1)). From R and I, we can deduce E.

|R|

Segmentation encoding We now present the encoding of the second part
of the signature: the signature segmentation. To encode the segmentation, we
encode the segment boundaries. These boundaries are indexed on the size of the
sequence, hence we ﬁrst need to encode the number of transactions n. This can be
done using again the universal code for integers, which is of size LN(n). Then, we
need to encode the number of segments |S|, which is of length LN(|S|). To encode
the segments, we only have to encode the boundaries between two consecutive
segments. As there are |S| − 1 such boundaries, a naive encoded length would be
(|S| − 1) ∗ log(n). An improved encoding takes into account the previous segments.
For example, when encoding the second boundary, we know that its value will
not be higher than n − |S1|. Hence, we can encode it in log(n − |S1|) instead of
log(n) bits. This principle can be applied to encode all boundaries. Another way
to further reduce the encoded length is to use the fact that we know that each
signature segment contains at least one transaction. We can therefore subtract
the number of remaining segments to encode the boundary of the segment we are
encoding. This yields an encoded length of (cid:80)|S|−1
j=1 |Sj|).

log(n − (|S| − i) − (cid:80)i−1

i=1

Putting everything together The total encoded length of a signature S is
(cid:1)) +

L(S) = LN(|I|) + LN(|R|) + log((cid:0) |I|
LN(n) + LN(|S|) + (cid:80)|S|−1

|R|

log(n − (|S| − i) − (cid:80)i−1

j=1 |Sj|).

i=1

4.2 Data Encoding: L(α|S)

We now present the encoding of the sequence given the model: L(α|S). This
encoding relies on the reﬁnement of the signature model into a probabilistic model
presented in Section 3. To summarize, we have three separate encoding streams
that encode the three diﬀerent types of occurrences presented in Section 3: 1) one
that encodes one occurrence of every signature item in every segment, 2) one that
encodes the rest of the signature items occurrences, and 3) one that encodes the
remaining items occurrences. An example illustrating the three diﬀerent encoding
streams is presented in Figure 2.

4 LN = log∗(n) + log(2.865064), with log∗(n) = log(n) + log(log(n)) + . . .

6

C. Gautrais et al.

a

Sig : 1st occ
Sig : other occ
Other items occ
a
Sequence α
T1
Transactions

c
c
T2

b
a
d
a, b, d
T3

b

a

a, b

a, b

b
T4

a
T5

a, b
T6

c, e
a, b, c, e
T7

Segments

S1

S2

S3

S4

Fig. 2. A sequence of transactions and its encoding scheme. We have R = {a, b},
E = {c, d, e} and I = {a, b, c, d, e}. The ﬁrst occurrence of each signature item in each
segment is encoded in the red stream, the remaining signature items occurrences in the
orange stream, and the items from E in the blue stream.

Encoding one occurrence of each signature item in each segment
As stated in Section 3, the signature says that in each segment, there is at least
one occurrence of each signature item. The size of each segment is known (from
the encoding of the model, in Subsection 4.1), hence we encode one occurrence
of each signature item in segment Si by encoding the index of the transaction,
within segment Si, that contains this occurrence. From Section 3, this occurrence
is uniformly distributed over the transactions in Si. As encoding an index over
|Si| equiprobable possibilities costs log(|Si|) bits and as in each segment, |R|
occurrences are encoded this way, we encode each segment in |R| ∗ log(|Si|) bits.
Encoding the remaining signature items’ occurrences As presented
in Figure 2, we now encode remaining signature items occurrences to guarantee
a lossless encoding. Again, this encoding relies on encoding transactions where
signature items occur. For each item a, we encode its occurrences occ(a) =
(cid:80)
1a=p by encoding to which transaction it belongs. As S occurrences
have already been encoded using the previous stream, there are occ(a) − |S|
remaining occurrences to encode. These occurrences can be in any of the n − |S|
remaining transactions. From Section 3, we use a uniform distribution to encode
them. More precisely, the ﬁrst occurrence of item a can belong to any of the n−|S|
transactions where a does not already occur. For the second occurrence of a, there
are now only n−|S|−1 transactions where a can occur. By applying this principle,
we encode all the remaining occurrences of a as (cid:80)occ(a)−|S|−1
log(n − |S| − i). For
each item, we also use LN(occ(a) − |S|) bits to encode the number of occurrences.
This yields a total length of (cid:80)
log(n−|S|−i).

a∈R LN(occ(a)−|S|)+(cid:80)occ(a)−|S|−1

Ti∈α

p∈Ti

(cid:80)

i=0

i=0

Remaining items occurrences encoding Finally, we encode the remaining
items occurrences, i.e., the occurrences of items in E. The encoding technique is
identical to the one used to encode additional signature items occurrences, with the
exception that the remaining items occurrences can initially be present in any of
the n transactions. This yields a total code of (cid:80)
log(n−i).

a∈E LN(occ(a))+(cid:80)occ(a)

i=0

Putting everything together The total encoded length of the data given the
a∈R LN(occ(a) − |S|) +

model is given by: L(α|S) = (cid:80)
(cid:80)occ(a)−|S|−1

log(n − |S| − i) + (cid:80)

Si∈S |R| ∗ log(|Si|) + (cid:80)
a∈E LN(occ(a)) + (cid:80)occ(a)

i=0

log(n − i).

i=0

Widening for MDL-based Retail Signature Discovery

7

5 Algorithms

The previous section presented how a sequence is encoded, completing our problem
formalization. The remaining problem is to ﬁnd the signature minimizing the
code length, that is, ﬁnding SM DL such that SM DL = argminS∈S L(α, S).

Naive algorithm A naive approach would be to directly mine the whole set
of signatures S and ﬁnd the signature that minimizes the code length. However,
mining a signature with k segments has time complexity O(n2k). Mining the
whole set of signatures requires k to vary from 1 to n, resulting in a total
complexity of O(n4). The quartic complexity does not allow us to quickly mine
the complete set of possible signatures on large datasets, hence we have to rely
on heuristic approaches.

To quickly search for the signature in S that minimizes the code length,
we initially rely on a top-down greedy algorithm. We start with one segment
containing the whole sequence, and then search for the segment boundary that
minimizes the encoded length. Then, we recursively search for a new single
segment boundary that minimizes the encoded length. We stop when no segment
can be added, i.e., when the number of segments is equal to the number of
transactions. During this process, we record the signature with the best encoded
length. However, this algorithm can perform early segment splits that seem
promising initially, but that eventually impair the search for the best signature.

5.1 Widening for signatures

To solve this issue, a solution is to keep the w signatures with the lowest code
length at each step instead of keeping only the best one. This technique is called
beam search and has been used to tackle optimization problems in pattern mining
[6]. The beam width w is the number of solutions to keep at each step of the
algorithm. However, the beam search technique suﬀers from having many of the
best w signatures that tend to be similar and correspond to slight variations of
one signature. Here, this means that most signatures in the beam would have
segmentations that are very similar. The widening technique [9] solves this issue
by adding a diversity constraint into the beam. Diﬀerent constraints exist [5, 6,
9], but a common solution is to add a distance constraint between each pair of
elements in the beam: all pairwise distances between the signatures in the beam
have to be larger than a given threshold θ. As this threshold is dependent on the
data and the beam width, we propose a method to automatically set its value.
Algorithm 1 presents the proposed widening algorithm. Line 3 iterates over the
number of segments. Line 4 computes all signatures having k segments that are
considered to enter the beam. More speciﬁcally, function Split1Segment computes
the direct reﬁnements of each of all signatures in BestKSign. A direct reﬁnement
of a signature corresponds to splitting one segment in the segmentation associated
with that signature. Line 5 selects the reﬁnement having the smallest code length.
If several reﬁnements yield the smallest code length, one of these reﬁnements
is chosen at random. Lines 8 to 11 perform the widening step by adding new
signatures to the beam while respecting the pairwise distance constraint. Line

8

C. Gautrais et al.

BestKSign = ∅, BestSign = ∅
for k = 1 → n do

Algorithm 1 Widening algorithm for signature code length minimization.
1: function Signature Mining(α = (cid:104)T1, . . . , Tn(cid:105), β, w)
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:

AllKSign = Split1Segment(BestKSign)
Sopt = argminS∈AllKSign L(α, S)
BestSign = BestSign (cid:83){Sopt}
BestKSign = {Sopt}
θ = threshold(β, w,AllKSign)
while Sopt (cid:54)= ∅ and |BestKSign| < w do

Sopt = argminS∈AllKSign L(α, S), (cid:64)Si ∈ BestKSign, d(Si, S) ≤ θ
BestKSign = BestKSign (cid:83){Sopt}

return argminS∈BestSign L(α, S)

Algorithm 2 Distance threshold computation.
1: function threshold(β, w, AllSign)
2:
3:
4:

KBest = β ∗ |AllSign|
BestS = GetBestSign(AllSign, KBest)
return argminθ{N (θ), N (θ) = |{S ∈ BestS, d(S, BestS[0]) < θ}|, N (θ) ≥

|BestS|/w}

8 computes the distance threshold (θ) depending on the diversity parameter
(β), the beam width (w), and the current reﬁnements. Algorithm 2 presents the
details of the threshold computation. With this threshold, we recursively add a
new element in the beam, until either the beam is full or no new element can
be added (line 9). Lines 10 and 11 add the signature having the smallest code
length and being at a distance of at least θ to any current element of the beam.
Line 12 returns the best overall signature we have encountered.

Distance between signatures We now deﬁne the distance measure for
signatures (used in line 10 of Algorithm 1). As the purpose of the signature
distance is to ensure diversity in the beam, we will use the segmentation to deﬁne
the distance between two elements of the beam, i.e., between two signatures.
Terzi et al. [10] presented several distance measures for segmentations. The
disagreement distance is particularly appealing for our purposes as it compares
how transactions belonging to the same segment in one segmentation are allocated
to the other segmentation. Let Sa = (cid:104)Sa1 . . . Sak(cid:105) and Sb = (cid:104)Sb1 . . . Sbk(cid:105) be two
k-segmentations of a sequence α. We denote by d(Sa, Sb) the disagreement
distance between segmentation a and segmentation b. The disagreement distance
corresponds to the number of transaction pairs that belong to the same segment in
one segmentation, but that are not in the same segment in the other segmentation.
Techniques on how to eﬃciently compute this distance are presented in [10].

Deﬁning a distance threshold Algorithm 1 uses a distance threshold θ
between two signatures, that controls the diversity constraint in the beam. If θ is
equal to 0, there is no diversity constraint, as any distance between two diﬀerent

Widening for MDL-based Retail Signature Discovery

9

signatures is greater than 0. Higher values of θ enforce more diversity in the
beam: good signatures will not be included in the beam if they are too close to
signatures already in the beam. However, setting the θ threshold is not easy. For
example θ depends on the beam width w. Indeed, with large beam widths, θ
should be low enough to allow many good signatures to enter the beam.

To this end, we introduce a method that automatically sets the θ parameter,
depending on the beam width and on a new parameter β that is easier to interpret.
The β parameter ranges from 0 to 1 and controls the strength of the diversity
constraint. The intuition behind β is that its value will approximately correspond
to the relative rank of the worst signature in the beam. For example, if β is set
to 0.2, it means that signatures in the beam are in the top-20% in ascending
order of code length. Algorithm 2 details how θ is derived from β and w; this
algorithm is called by the threshold function in line 8 of Algorithm 1.

Knowing the set of all candidate signatures that are considered to enter
the beam, we retain only the proportion β of the best signatures (line 3 of
Algorithm 2). Then, in line 4 we extract the best signature. Finally, we look for
the distance threshold θ such that the number of signatures within a distance of
θ from the best signature is equal to the number of considered signatures divided
by the beam width w (line 5). The rationale behind this threshold is that since
we are adding w signatures to the beam and we want to use the proportion β of
the best signatures, the distance threshold should approximately discard 1/w of
the proportion β of the best signatures around each signature of the beam.

6 Experiments

This section, analyzes runtimes and code lengths of variants of our algorithm on
a real retail dataset5. We show that our method runs signiﬁcantly faster than
the naive baseline, and give advice on how to choose the w and β parameters.
Next, we illustrate the usefulness of the encoding to analyze retail customers.

6.1 Algorithm runtime and code length analysis

We here analyze the runtimes and code lengths obtained by variants of Algorithm
1. 3000 customers having more than 40 baskets in the Instacart 2017 dataset are
randomly selected6. Customers having few purchases are less relevant, as we are
looking for purchase regularities. These 3000 customers are analyzed individually,
hence the algorithm is evaluated on diﬀerent sequences.

Code length analysis To assess the performance of the diﬀerent algorithms,
we analyze the code length yielded by each algorithm on each of these 3000
customers. We evaluate diﬀerent instances of the widening algorithm with diﬀerent
beam widths w and diversity constraints β. The resulting relative mean code

5 Code is available at https://bitbucket.org/clement_gautrais/mdl_signature_

ida2020/

6 The

Instacart Online Grocery Shopping Dataset

2017, Accessed from

https://www.instacart.com/datasets/grocery-shopping-2017 on 05/04/2018

10

C. Gautrais et al.

Fig. 3. Left: Mean relative code length for diﬀerent instances of the widening algorithm.
For each customer, the relative code length is computed with regard to the smallest
code length found for this customer. Averaging these lengths across all customers gives
the mean relative code length. The β parameter sets the diversity constraint and w the
beam width. The solid black line shows the mean code length of the naive algorithm.
Bootstrapped 95% conﬁdence intervals [1] are displayed. Right: Mean runtime in
seconds for diﬀerent instances of the widening algorithm. The dotted black lines shows
a bootstrapped 95% conﬁdence interval of the naive algorithm’s mean runtime.

lengths per algorithm instance are presented in Figure 3 left. When increasing
the beam width, the code length always decreases for a ﬁxed β value. This is
expected, as increasing the beam size allows the widening algorithm to explore
more solutions. As increasing the beam size improves the search, we recommend
setting it as high as your computational budget allows you to do.

Increasing the β parameter usually leads to better code lengths. However, for
w = 5, higher β values give slightly worse results. Indeed, if β is too high, good
signatures might not be included in the beam, if they are too close to existing
solutions. Therefore, we recommend setting the β value to a moderate value, for
example between 0.3 and 0.5. A strong point of our method is that it is not too
sensitive to diﬀerent β values. Hence, setting this parameter to its optimal value
is not critical. The enforced diversity is highly relevant, as a ﬁxed beam size with
some diversity ﬁnds code lengths that are similar to the ones found by a larger
beam size with no diversity. For example, with w = 5 and β = 0.3, the code
lengths are better than with w = 10 and β = 0. As using a beam size of 5 with
β = 0.3 is faster than using a beam size of 10 with β = 0, it shows that using
diversity is highly suited to decrease runtime while yielding smaller code lengths.
Runtime analysis We now present runtimes of diﬀerent widening instances
in Figure 3 right. The beam width mostly inﬂuences the runtime, whereas the β
value has a smaller inﬂuence. Overall, increasing β slightly increases computation

w=1Naive methodw=5Naive methodw=10Naive method1.0001.0051.0101.0151.0201.025Relative MDL code lengthw=20Naive methodw=1Naive methodw=5Naive methodw=10Naive method0123456789101112Runtime (seconds)w=20Naive methodbeta0.00.10.20.30.40.50.6Widening for MDL-based Retail Signature Discovery

11

time, while yielding a noticeable improvement in the resulting code length,
especially for small beam sizes. Our method also runs 5 to 10 times faster than
the naive method. In this experiment, customers have a limited number of
baskets (at most 100), thus the O(n4) complexity of the naive approach exhibits
reasonable runtimes. However in settings with more transactions (retail data
over a longer period for example), the naive approach will require hours to run,
and the performance gain of our widening approach will be a necessity. Another
important thing is that the naive method has a high variability in runtimes.
Conﬁdence intervals are narrow for the widening algorithm (they are barely
noticeable on the plot), whereas it spans over 5 seconds for the naive algorithm.

6.2 Qualitative analysis

Fig. 4. Example of two signatures found by our algorithms. Gray vertical lines are
segments boundaries and each dot represents an item occurrence in a purchase sequence.
Top: best signature (code length of 5221.33 bits) found by the widening algorithm,
with w = 20 and β = 0.5. Bottom: signature found by the beam search algorithm:
w = 1 and β = 0, with a code length of 5338.46 bits (the worst code length).

Figure 4 presents two signatures of a customer, to illustrate that signatures
are of practical use to analyze retail customers, and that ﬁnding signatures with
smaller code lengths is of interest. We use the widening algorithm to get a variety
of good signatures according to our MDL encoding. The top signature in Figure
4 is the best signature found: it has the smallest code length. This signature
seems to correctly capture the regular behavior of this customer, as it contains
7 products that are regularly bought throughout the whole purchase sequence.
Knowing these 7 favorite products, a retailer could target its oﬀers. The segments
also give some information regarding the temporal behavior of this customer. For

10203040Organic Sticks Low Moisture Part Skim Mozzarella String CheeseBananaOrganic Whole MilkFrozen Broccoli FloretsOrganic Mesa Sunrise CerealAsparagusGlobe Eggplant10203040Natural Artesian Bottled WaterOrignial Recipe Chocolate PuddingOrganic Whole MilkFrozen Broccoli FloretsOriginal Recipe Rice PuddingHass AvocadoOrganic Mesa Sunrise CerealHoneycrisp AppleGlobe Eggplant12

C. Gautrais et al.

example, because segments tend to be smaller and more frequent towards the
end of the sequence, one could guess that this customer is becoming a regular.
On the other hand, the bottom signature is signiﬁcantly worse than the top
one. It is clear that it mostly contains products that are bought only at the end
of the purchase sequence of this customer. This phenomenon occurs because the
beam search algorithm, with w = 1, only picks the best solution at each step of
the algorithm. Hence, it can quickly get stuck in a local minimum. This example
shows that considering larger beams and adding diversity is an eﬀective approach
to optimize code length. Indeed, having a large and diverse beam is necessary to
have the algorithm explore diﬀerent segmentations, yielding better signatures.

7 Conclusions

We tackled the problem of automatically ﬁnding the best number of segments
for signature patterns. To this end, we deﬁned a model selection problem for sig-
natures based on the minimum description length principle. Then, we introduced
a novel algorithm that is an instance of widening. We evaluated the relevance
and eﬀectiveness of both the problem formalization and the algorithm on a
retail dataset. We have shown that the widening-based algorithm outperforms
the beam search approach as well as a naive baseline. Finally, we illustrated
the practical usefulness of the signature on a retail use case. As part of future
work, we would like to study our optimization techniques on larger databases
(thousands of transactions), like online news feeds. We would also like to work on
model selection for sets of interesting signatures, to highlight diverse recurrences.

References

1. Davison, A.C., Hinkley, D.V., et al.: Bootstrap methods and their application,

vol. 1. Cambridge university press (1997)

2. Gautrais, C., Cellier, P., Quiniou, R., Termier, A.: Topic signatures in political

campaign speeches. In: Proc. of EMNLP 2017. pp. 2342–2347 (2017)

3. Gautrais, C., Quiniou, R., Cellier, P., Guyet, T., Termier, A.: Purchase signatures

of retail customers. In: PAKDD. pp. 110–121. Springer (2017)

4. Gr¨unwald, P.D.: The minimum description length principle. MIT press (2007)
5. Ivanova, V.N., Berthold, M.R.: Diversity-driven widening. In: International Sympo-

sium on Intelligent Data Analysis. pp. 223–236. Springer (2013)

6. van Leeuwen, M., Knobbe, A.: Diverse subgroup set discovery. Data Mining and

Knowledge Discovery 25(2), 208–242 (2012)

7. van Leeuwen, M., Vreeken, J.: Mining and using sets of patterns through compression.

In: Frequent Pattern Mining, pp. 165–198. Springer (2014)

8. Rissanen, J.: A universal prior for integers and estimation by minimum description

length. The Annals of statistics pp. 416–431 (1983)

9. Shell, P., Rubio, J.A.H., Barro, G.Q.: Improving search through diversity. In: Proc.
of the AAAI Nat. Conf. on Artiﬁcial Intelligence. pp. 1323–1328. AAAI Press (1994)
10. Terzi, E.: Problems and algorithms for sequence segmentations. Ph.D. thesis (2006)
11. Vreeken, J., van Leeuwen, M., Siebes, A.: Krimp: mining itemsets that compress.

Data Mining and Knowledge Discovery 23(1), 169–214 (2011)

