Forgetting agent awareness: a partial semantics
approach
Line van den Berg

To cite this version:

Line van den Berg. Forgetting agent awareness: a partial semantics approach. WiL 2020 - 4th Women
in Logic workshop, Jun 2020, Paris, France. pp.18-21. ￿hal-03148041￿

HAL Id: hal-03148041

https://hal.science/hal-03148041

Submitted on 21 Feb 2021

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Forgetting Agent Awareness: a Partial Semantics Approach

Line van den Berg

Univ. Grenoble Alpes & Inria, France
line.van-den-berg@inria.fr

Abstract

Partial Dynamic Epistemic Logic allows agents to have diﬀerent knowledge represen-
tations about the world through agent awareness. Agents use their own vocabularies to
reason and talk about the world and raise their awareness when confronted with new vo-
cabulary. Through raising awareness the vocabularies of agents are extended, suggesting
there is a dual, inverse operator for forgetting awareness that decreases vocabularies. In
this paper, we discuss such an operator. Unlike raising awareness, this operator may induce
an abstraction on models that removes evidence while preserving conclusions. This is use-
ful to better understand how agents with diﬀerent knowledge representations communicate
with each other, as they may forget the justiﬁcations that led them to their conclusions.

1 Introduction
Agents use diﬀerent ways to represent their knowledge about the world. This causes problems
when they try to communicate: how do the agents translate their knowledge, expressed in their
vocabulary, to the knowledge of other agents, which could be expressed in diﬀerent vocabularies?
When we require that agents are fully aware of each other’s vocabularies, we can model their
interactions with Dynamic Epistemic Logic (DEL). This has been achieved in the context of
ontologies (a formal knowledge representation) and alignments (translations between diﬀerent
ontologies) in [8]. However, full awareness is not desirable nor realistic for open multi-agent
systems where agents are continuously required to adapt their knowledge representations.

The problem with the modeling in DEL is that, on DEL, agents can only revise their
knowledge and beliefs via dynamic upgrades such as announcements (changing knowledge),
conservative and radical upgrades (changing beliefs). These eliminate or reorganize (some)
worlds of the model. However, this also means that whatever may be learned in the future
and whatever vocabulary may be acquired, should already be available in the present situation.
This prevents agents to expand their vocabularies as is required in an open, dynamic setting.
To loosen this requirement, agent unawareness has been modeled for Dynamic Epistemic
Logic using partial valuations [9]. This provides us with a richer framework because partial
valuations allow propositions to be true, false or undeﬁned and, when a proposition is undeﬁned,
agents are unaware of it. Whenever agents are confronted with new vocabulary, they raise their
awareness via an “awareness raising” operator +p [9].

Once provided with such an awareness raising operator it is natural to think of a dual,
In
inverse operator for forgetting awareness.
particular, unlike raising awareness, forgetting awareness requires to understand what to do with
consequences obtained from removed evidence. They may be forgotten as well or preserved.
In the latter case, forgetting awareness induces an abstraction on models that may delete
justiﬁcations while preserving their conclusions.

In this paper, we discuss such an operator.

Besides its theoretical interest, this operator allows us to better understand how agents with
diﬀerent knowledge representations communicate and improve their alignments. Indeed, simple
agents may forget the examples that led them to induce or discard more abstract conclusions [1,
2]. Hence, a full logical model of these agents [8] could take advantage of such a forgetting
operator.

Forgetting Agent Awareness

Van den Berg

2 Related Work

Partial semantics have been introduced before for modal logic [6, 5, 10, 4], yet the connection
with agent awareness was never explored. Instead, awareness and unawareness of agents have
been studied from an epistemic logic perspective by adding an awareness operator to the lan-
guage Aφ [3]. A complete dynamic awareness logic with dynamics for increasing and decreasing
awareness was developed in [13, 11, 7, 12].

However, in awareness logic, raising awareness of a proposition p comes equipped with
disclosing the truth value of p. This is because all the propositions an agent may become aware
of in the future are already speciﬁed in the initial setting and only awareness is considered as a
partial function. We consider these two as diﬀerent acts: becoming aware of a proposition and
learning its truth value. In this way, unlike in awareness logic, models are truly open to evolve.

3 Forgetting

To raise awareness of a proposition p, +p, the valuation function is extended: p is added to
the worlds of the model in which it was initially undeﬁned [9]. Formally, this means that, in
the model, all the worlds (globally), or all the accessible worlds for an agent (locally), in which
p was initially undeﬁned are duplicated and p is deﬁned as true in one world and false in the
other, while accessibility to and from duplicated worlds is preserved. This means that agents
unaware of p become uncertain about p after raising awareness of p.

Similarly, to forget awareness of p, −p, we may delete the valuations of p from all the worlds
in the model (globally), or from all the accessible worlds for an agent (locally). Worlds that are
similar up to bisimilarity may be merged. This forces models on which awareness of p is raised
and subsequently forgotten to be bisimilar to the original situation, see Figure 1.

However, this also raises a question what happens if awareness of p is raised, then p is used
to learn something about another proposition q, and ﬁnally p is forgotten again. Consider, for
example, the upgrade +p; +q; !p; !(p → q); −p as illustrated in Figure 2. When we apply −p
and remove the valuations of p from the worlds in the model, the truth value of q remains
untouched: q will still be true even though its justiﬁcation, p (because p → q was announced,
linking the truth value of q to that of p), is removed. This means that this type of forgetting
awareness induces an abstraction on models: removing evidence while preserving conclusions.
The question is then: is this feature of the forgetting awareness operator desirable? Should
agents remember the conclusions drawn from forgotten evidence? Indeed, simple agents may
forget the examples that led them to induce or discard more abstract conclusions [1, 2] because
the conclusions enable them to successfully communicate without referring to the examples.

4 Conclusion

We have discussed a forgetting awareness operator for partial dynamic epistemic logic that
removes valuations of the proposition that is to be forgotten from the worlds of the model. We
have then shown that this type of forgetting awareness induces an abstraction on models that
removes evidence while preserving conclusions.

Forgetting awareness is useful to better understand how agents with diﬀerent knowledge rep-
resentations communicate with each other and improve their alignments because simple agents
may forget the justiﬁcation for their drawn conclusions, without eﬀecting the communication to
take place successfully [1, 2]. Therefore, this could beneﬁt a full logical model of such agents [8].

2

Forgetting Agent Awareness

Van den Berg

Acknowledgments

This work has been partially supported by MIAI @ Grenoble Alpes (ANR-19-P3IA-0003).

Appendix: Figures

a

w

w0

p

+p
−p

a

¬p

w1

a

a

Figure 1: Raising awareness of p, +p, (left to right, the red dashed lines indicate how the worlds
are mapped from the model on the left to the model on the right) and −p (right to left, the
blue dashed lines indicate how the worlds are mapped from the model on the right to the model
on the left), where the worlds are merged up to bisimilarity. We have that M+p;−p and M are
bisimilar.

!p

p

p, q

a

p, ¬q

p, q

a

p, ¬q

+p

a

+q

a

a

a

!(p → q)

¬p

¬p, q

¬p, ¬q

a

p, q

−p

q

Figure 2: The ﬁgure illustrates the steps of the complex upgrade +p; +q; !p; !(p → q); −p applied
to the “empty model” (where no propositions are deﬁned), from left to right. For simplicity,
the reﬂexive arrows are omitted and the dashed lines indicate how the worlds are mapped
from the initial model (on the left) to the resulting model (on the right) where red stands for
an awareness raise upgrade, green for an announcement and blue for a forgetting awareness
upgrade. In the resulting model, on the right, q is known, but not justiﬁed anymore.

3

Forgetting Agent Awareness

Van den Berg

References

[1] J´erˆome Euzenat. First experiments in cultural alignment repair (extended version). In The Seman-
tic Web: ESWC 2014 Satellite Events - ESWC 2014 Satellite Events, Anissaras, Crete, Greece,
May 25-29, 2014, Revised Selected Papers, pages 115–130, 2014.

[2] J´erˆome Euzenat. Interaction-based ontology alignment repair with expansion and relaxation. In
Proceedings of the Twenty-Sixth International Joint Conference on Artiﬁcial Intelligence, IJCAI
2017, Melbourne, Australia, August 19-25, 2017, pages 185–191, 2017.

[3] Ronald Fagin and Joseph Y Halpern. Belief, awareness, and limited reasoning. Artiﬁcial intelli-

gence, 34(1):39–76, 1987.

[4] Jens Ulrik Hansen. Modeling truly dynamic epistemic scenarios in a partial version of del. The

Logica Yearbook 2013, pages 63–75, 2014.

[5] Jan Jaspars and Elias Thijsse. Fundamentals of partial modal logic. Studies in Logic Language

and Information, 1996.

[6] Elias Thijsse. Partial logic and knowledge representation. 1994.
[7] Johan Van Benthem and Fernando R Vel´azquez-Quesada. The dynamics of awareness. Synthese,

177(1):5–27, 2010.

[8] Line van den Berg, Manuel Atencia, and J´erˆome Euzenat. Agent ontology alignment repair through
dynamic epistemic logic.
In Proceedings of the 19th International Conference on Autonomous
Agents and MultiAgent Systems, page to appear. International Foundation for Autonomous Agents
and Multiagent Systems, 2020.

[9] Line van den Berg, Manuel Atencia, and J´erˆome Euzenat. Unawareness in multi-agent systems
with partial valuations. In Workshop on Logical Aspects of Multi-Agent Systems (LAMAS 2020),
2020.

[10] Wiebe Van der Hoek, Jan Jaspars, and Elias Thijsse. Honesty in partial logic. Studia Logica,

56(3):323–360, 1996.

[11] Hans Van Ditmarsch and Tim French. Awareness and forgetting of facts and agents. In 2009
IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent Agent Tech-
nology, volume 3, pages 478–483. IEEE, 2009.

[12] Hans Van Ditmarsch and Tim French. Becoming aware of propositional variables.

In Indian

Conference on Logic and Its Applications, pages 204–218. Springer, 2011.

[13] Hans Van Ditmarsch, Andreas Herzig, J´erˆome Lang, and Pierre Marquis. Introspective forgetting.

Synthese, 169(2):405–423, 2009.

4

