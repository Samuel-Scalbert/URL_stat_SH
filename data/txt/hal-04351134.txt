Raising awareness without disclosing truth
Line van den Berg, Manuel Atencia, Jérôme Euzenat

To cite this version:

Line van den Berg, Manuel Atencia, Jérôme Euzenat. Raising awareness without disclosing truth.
￿10.1007/s10472-022-
Annals of Mathematics and Artificial Intelligence, 2023, 91 (4), pp.431-464.
09809-y￿. ￿hal-04351134￿

HAL Id: hal-04351134

https://hal.science/hal-04351134

Submitted on 18 Dec 2023

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Distributed under a Creative Commons Attribution 4.0 International License

Annals of mathematics and artificial intelligence, 2022
DOI:10.1007/s10472-022-09809-y

Raising Awareness without Disclosing Truth

Line van den Berg ¨ Manuel Atencia ¨
J´erˆome Euzenat

Received: 2021-02-14 / Accepted: 2022-07-22 / Published: 2022-10-27

Abstract Agents use their own vocabularies to reason and talk about the world.
Public signature awareness is satisfied if agents are aware of the vocabularies,
or signatures, used by all agents they may, eventually, interact with. Multi-agent
modal logics and in particular Dynamic Epistemic Logic rely on public signature
awareness for modeling information flow in multi-agent systems. However, this
assumption is not desirable for dynamic and open multi-agent systems because
(1) it prevents agents to use unique signatures other agents are unaware of, (2)
it prevents agents to openly extend their signatures when encountering new in-
formation, and (3) it requires that all future knowledge and beliefs of agents are
bounded by the current state.

We propose a new semantics for awareness that enables us to drop public signa-
ture awareness. This semantics is based on partial valuation functions and weakly
reflexive relations. Dynamics for raising public and private awareness are then de-
fined in such a way as to differentiate between becoming aware of a proposition
and learning its truth value. With this, we show that knowledge and beliefs are
not affected through the raising operations.

Keywords Awareness ¨ Raising awareness ¨ Dynamic epistemic logic ¨ Partial
valuations ¨ Multi-agent systems

L. van den Berg
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, F-38000 Grenoble France. E-mail:
line.van-den-berg@inria.fr

M. Atencia
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, F-38000 Grenoble France. E-mail:
manuel.atencia@inria.fr

J. Euzenat
Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG, F-38000 Grenoble France. E-mail:
jerome.euzenat@inria.fr

2

1 Introduction

Line van den Berg et al.

Agents use propositions to represent the information they have about the world,
that together form their vocabulary, also called their signature. Agents’ signatures
may be the same or different, and in the latter case either exclusive or overlapping.
When they are the same and this is known by all agents, public signature aware-
ness holds: it is commonly known that agents use the same propositions—i.e. they
are aware of the same vocabulary. Multi-agent modal logics, and in particular
Dynamic Epistemic Logic (DEL), are frameworks for modeling the information
flow in multi-agent systems and are based on this assumption. DEL has been used
as a framework to investigate how knowledge and beliefs of agents evolve under
dynamic upgrades in multi-agents systems and has been applied to communica-
tion [8,19], belief revision [6] and agent interaction [7]. However, because of public
signature awareness, in DEL agents have full awareness of all the propositions
used currently, and in the future, by all agents. This ensures that any formula
that is communicated, via the dynamic upgrades, can be understood by all agents
and that each agent can update her knowledge and beliefs accordingly. But as a
consequence, all future evolutions of agents’ knowledge and beliefs are constrained
to the current situation: learning takes place via eliminating or re-organizing the
possibilities agents consider, rather than extending it with the new information.

The public signature awareness assumption becomes a restriction when con-
sidering dynamic and open multi-agent systems. In such systems, agents may use
different signatures to communicate and may be required to continuously adapt
and extend their signatures to their environment [2, 20, 21]. A typical question for
such systems is: how do agents understand each other and interact if not everyone
is aware of the propositions used?

The problem of public signature awareness is hidden in the semantics of DEL:
valuation functions are total functions and accessibility relations are reflexive.
Therefore, in order to eliminate public signature awareness, we need to adjust the
structure of the models. In this paper, we propose a novel semantics, called Partial
Dynamic Epistemic Logic (ParDEL), with valuations that are partial (instead
of total) and relations that are weakly reflexive (instead of reflexive). The first
adjustment creates a distinction between uncertain agents, agents that are aware
of a proposition but do not know its truth value, and unaware agents, agents that
do not consider the proposition in its entirety. The second adjustment enables
agents to use different signatures to represent their knowledge and beliefs.

We extend this semantics with raising awareness dynamics that allow agents
extend their signatures when encountering new information from the environment
or from other agents they interact with. These operations act on the models by
duplicating the worlds in which the proposition, whose awareness is raised of, is
undefined, making it true in one while false in the other. This ensures that raising
awareness does not imply disclosing truth. We then show that raising awareness
preserves agents’ knowledge and beliefs and that, if a sentence they know or be-
lieve after raising awareness of a proposition does not involve this proposition,
this sentence was already known or believed before the operation. This result is
extended to non-epistemic formulas and it is proven that raising awareness of a
proposition does not imply disclosing its truth value. Hence, awareness and truth
are disconnected.

Raising Awareness without Disclosing Truth

3

The semantics introduced in this paper can be used to model communication
and interaction between agents that use different signatures and extend their sig-
natures when encountering new propositions via raising awareness. As such, it is
a generalization of DEL for modeling dynamic and open multi-agent systems.

In the remainder, we discuss the related work (§2) and introduce Dynamic
Epistemic Logic (§3). We then discuss how we characterize awareness and un-
awareness of agents through partial valuations (§4). We formally define the syntax
and semantics of Partial Dynamic Epistemic Logic (§5). Then, we formalize the
dynamics for raising public and private awareness on ParDEL+ (§6) and show
that knowledge and beliefs of agents are not affected through the raising opera-
tions (§7). Finally, we discuss issues about supporting a dual forgetting awareness
operator (§8) and we conclude by pointing out the applications of this work and
discuss possible future directions (§9).

2 Related work

Dynamic Epistemic Logics (DEL) are a family of modal logics (see e.g. [12])
studying knowledge, belief and other epistemic attitudes that are studied in epis-
temic logic [23], under model change, using formal languages and mathemati-
cal models [19]. These model changes, also called dynamic upgrades, are model-
transforming actions that enable to shift away from the static semantics of truth
in an individual Kripke model to a dynamic semantics of truth occurring across
Kripke models, specified by the upgrade. This allows us to analyze the epistemic
and doxastic consequences of, for example, public announcements [35]. DEL has
been widely used as a formal framework to model agent communication [8, 19, 35],
belief revision [6] and agent interaction [7].

Awareness has been first formalized in logic by Fagin and Halpern [22] as a
way to solve the problem of logical omniscience [30]. They wondered how agents
can say that they know or believe a proposition p if p is a concept they are com-
pletely unaware of. As a consequence, the interpretation of Kaϕ is changed from
“agent a knows ϕ” to “agent a implicitly knows ϕ”, denoting the knowledge an
agent could eventually get. Another notion of knowledge called explicit knowledge
is then defined as a combination of implicit knowledge and awareness, denoting
the knowledge an agent has access to at a particular moment. The logic introduced
in [22], called Awareness Logic, extends the language of epistemic logic with an
operator Aaϕ that reads as “agent a is aware of ϕ” and that is interpreted with
respect to an awareness function assigning to each world and each agent a set of
sentences. Agents then (explicitly) know or believe a formula ϕ if it is true in all ac-
cessible worlds or all most plausible worlds, respectively, such that Aaϕ holds.The
awareness function can therefore be viewed as acting like a filter: extracting explicit
knowledge from implicit knowledge.

With this notion of awareness, an interest has arisen to study the dynamics of
awareness using DEL, e.g. [9, 14–16, 26, 28, 29, 34]. Particularly interesting to this
paper, in [14, 15] Awareness Logic is extended to account for dynamic awareness,
where the dynamic part is modeled by a bisimulation quantification on structures.
Event models for changing awareness following this approach are defined in [16,17]
and modalities to change awareness have been introduced in [9, 15], called the
consider and drop operations, that, respectively, extend or reduce the scope of the

4

Line van den Berg et al.

awareness function. A complete dynamic epistemic logic of awareness is defined and
the operations are generalized to multi-agent situations where awareness changes
may occur privately in [9, 17].

These works on awareness have mainly concentrated on awareness of the truth
value of a statement not on awareness of the statement itself. This is because
they are, like DEL, based on total valuation functions and only awareness is con-
sidered as a partial function. This means that raising awareness comes equipped
with disclosing the ‘underlying’ truth value of the proposition awareness is raised
of [14, 15]. The underlying truth value may be defined as such that agents become
ignorant when raising their awareness [17], however, the problem is that this needs
to be determined in advance. That is, the valuations of the proposition awareness
is raised of are already defined, but are ‘invisible’ to the agents. Therefore, two
problems remain: it disables agents to openly evolve their signatures when encoun-
tering new information and any future evolution of agents’ knowledge and beliefs,
and now also awareness, is bound by the initial setting.

In the notion of awareness introduced in this paper, awareness is present in
the structure of the logic and no awareness operator Aϕ or awareness function is
required. Instead, awareness arises from the use of partial valuation functions and
weakly reflexive relations. This means that agents may use different signatures,
but we also tackle the other two problems: (1) their signatures can openly evolve
via raising awareness causing knowledge, belief and awareness to evolve without
any prior defined way of how this evolution might take place, and (2) awareness is
completely disconnected from truth: raising awareness does not imply disclosing
its truth values.

The connection between partial valuation functions and awareness is novel
in this paper. Partial valuation functions have been introduced for (Dynamic)
Epistemic Logic in [31, 32, 41], where worlds of the models are equipped with
partial, instead of total, valuation functions that either interpret the propositions
as true or false or do not interpret them, leaving them undefined. This offers a
more natural way to deal with growth of information by extending the models
rather than merely reducing or re-organizing them, what is the typical approach
in standard Dynamic Epistemic Logic to model changes in information [19]. This
means that in DEL only certainty grows in parallel with new information, but in a
partial approach also awareness can grow in parallel with new information. Yet, a
link to awareness, and therefore the possibility of agents using different, dynamic
signatures to represent their knowledge and beliefs, has not yet been established.
We extend the work by [27, 31, 32, 41] in three ways: (1) we replace reflexiv-
ity by weak reflexivity, (2) we consider a different clause for the falsification of
conjunctions and (3) we make a connection between partial valuations and aware-
ness of agents. Weak reflexivity enables us to model how agents with different
signatures, other agents are unaware of, interact. The new clause for falsification
of conjunctions enforces that both conjuncts must belong to the domain of the
valuation functions at the world considered in order to be false. This ensures that
agents can only know that a conjunction “p and q” is false, if they are aware of
both p and q and know that at least one of the two conjuncts is false. Finally, the
connection with awareness, gives a novel semantics for awareness and unawareness
of agents in which becoming aware of a proposition and learning its truth value
are two independent acts and in which agents can extend their signatures when
learning new information from the environment or from other agents.

Raising Awareness without Disclosing Truth

5

3 Dynamic Epistemic Logic

We consider the syntax and semantics of Dynamic Epistemic Logic as introduced
by [4].

Definition 1 (Syntax of DEL) Given a countable, non-empty set P of propo-
sitios and a finite, non-empty set A of agents, the syntax, LDEL, of (multi-agent)
Dynamic Epistemic Logic is defined in the following way:

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | r†ϕsψ

where p P P is a proposition, Ka and Ba are the knowledge and belief operators
for each agent a P A and †ϕ with † P t!, ò, Òu the dynamic upgrades.

The connectives _ and Ñ, and the duals ˆKa, ˆBa, x†ϕy are defined in the usual
way: ϕ _ ψ iff ␣p␣ϕ ^ ␣ψq, ϕ Ñ ψ iff ␣ϕ _ ψ, ˆKaϕ iff ␣Ka␣ϕ, ˆBaϕ iff ␣Ba␣ϕ,
and x†ϕyψ iff ␣r†ϕs␣ψ.

We read the formula Kaϕ as “agent a knows that ϕ is true” and the formula
Baϕ as “agent a believes that ϕ is true”. The standard semantics for LDEL are
given by means of Kripke, or DEL, models with plausibility relations.

Definition 2 (DEL Model) Given a countable, non-empty set P of proposi-
tions and a finite, non-empty set A of agents, a model of (multi-agent) Dynamic
Epistemic Logic is a triple M “ xW, pďaqaPA, V y where

– W is a non-empty set of worlds;
– pďaqaPA : A Ñ PpW ˆ W q are the plausibility relations on W , one for each

agent, that are well-founded, locally connected preorders;

– V : P Ñ PpW q is a propositional valuation mapping propositions to sets of

worlds in which that proposition is true.

A pointed DEL model is a pair xM, wy, with w P W .

For a DEL model M “ xW, pďaqaPA, V y, the part xW, pďaqaPAy is also referred
a and V M are
to as a DEL frame and is denoted by F. By convention, W M, RM
used to refer to the components of M, but we also omit the superscript M if it is
clear from the context which model we are concerned with. We write w P M write
to mean w P W M. Furthermore, we write Vwppq “ 1 to denote that w P V ppq, and
Vwppq “ 0 to denote that w R V ppq.

The plausibility relation w ďa v reads as “v is at least as plausible as w for
agent a”. We write w ěa v if and only if v ďa w. This plausibility relation is used
to define knowledge and beliefs of agents: agent a knows something if and only
if it is true at all the worlds agent a considers plausible (in any direction) and
agent a believes something if and only if it is true at the maximal worlds with
respect to the plausibility relation for agent a. Knowledge and beliefs can also be
defined with respect to the epistemic („a) and doxastic relations (Ña) that can
be deduced from the plausibility relation ďa.

Definition 3 (Epistemic and Doxastic Relation) Given a DEL model M “
xW, pďaqaPA, V y for a set A of agents, then the epistemic relation „a is defined as:

w „a v iff w pďa Y ěaq˚ v

(1)

6

Line van den Berg et al.

And the doxastic relation Ña is defined as:

w Ña v iff v P M axďa |w|a

(2)

where R˚ is the transitive closure of any relation R and |w|a is the information
cell (or accessible cell ) of agent a at state w and is defined by:

|w|a “ tv P W | w „a vu

(3)

Then an agent a knows ϕ if it holds at all the worlds reached via „a and she

believes ϕ if it holds at all the worlds reached via Ña.

It follows from the properties of ďa and ěa that the relations „a are re-
flexive, transitive and symmetric, and the relations Ña are transitive, serial and
Euclidean. Therefore they satisfy the usual properties of knowledge and beliefs,
S5 (K (distributivity), T (factivity), 4 (positive introspection) and 5 (negative
introspection)) and KD45 (K, D (consistency), 4 and 5), respectively [19].

The dynamic upgrades !ϕ, ò ϕ and Ò ϕ act as model transformers. Model trans-

formers are functions whose domain and range are the set of DEL models.

Definition 4 (Model Transformer) A model transformer is a function †ϕ :
a qaPA, V †ϕy.
M ÞÑ M†ϕ, applying a certain action to M to obtain M†ϕ “ xW †ϕ, pď
†ϕ
We consider three model transformers !ϕ, ò ϕ and Ò ϕ that are defined as follows,
with ||ϕ||M :“ tw P W | M, w ( ϕu denoting the set of worlds in which ϕ is true:
Announcement (!ϕ) deletes all ‘␣ϕ’-worlds from the model, i.e. W !ϕ “ ||ϕ||M,

w ď!ϕ

a v iff w ďa v and w, v P W !ϕ, V !ϕppq “ V ppq X ||ϕ||M;

Radical upgrade (ò ϕ) makes all ϕ worlds more plausible than all ␣ϕ worlds,
and within these two zones, the old ordering remains. I.e. W òϕ “ W , w ďòϕ
a v
iff v P ||ϕ||M and w P ||␣ϕ||M or else if w ďa v, and V òϕppq “ V ppq;

Conservative upgrade (Ò ϕ) makes the best ‘ϕ’-worlds more plausible than all
other worlds, while the old ordering on the rest of the worlds remains. I.e.
W Òϕ “ W , w ďÒϕ
a v iff either v P M axďa p|w|a X ||ϕ||Mq or w ďa v, V Òϕppq “
V ppq.

Satisfiability is considered with respect to a pointed model xM, wy.

Definition 5 (Satisfiability for DEL) Satisfiability for Dynamic Epistemic
Logic by a pointed model xM, wy is defined in the following way:

M, w ( p
M, w ( ϕ ^ ψ
M, w ( ␣ϕ
M, w ( Kaϕ
M, w ( Baϕ
M, w ( r†ϕsψ

iff w P V ppq
iff M, w ( ϕ and M, w ( ψ
iff M, w * ϕ
iff @v s.t. w „a v : M, v ( ϕ
iff @v s.t. w Ña v : M, v ( ϕ

iff M

†ϕ, w ( ψ

where † P t!, ò, Òu.

ing that first †
†
pM†
2ψ.

1ϕq

We also write †

1ϕ; †

2ψ for the sequence of upgrades †

1ϕ is applied and then †

2ϕ, i.e. the model M†

1ϕ and then †
1ϕ;†

2ψ mean-
2ψ is defined as

Raising Awareness without Disclosing Truth

7

We may use K to denote p ^ ␣p for any proposition p P P , which is false on
all (non-empty) models, and likewise J to denote ␣K, which is true on all (non-
empty) models. As usual, we say that a set of formulas is consistent if there is
a pointed model satisfying all formulas of the set. Otherwise, a set of formulas
is inconsistent. Furthermore, a formula ϕ is a consequence of a set of formulas Γ
(written Γ ( ϕ) if every pointed model xM, wy satisfying all formulas of Γ , also
satisfy ϕ.

When we draw DEL models, we write, inside the worlds, p to denote that the
valuation of p at that world is 1 and ¯p to denote that the valuation is 0. Relations
w ďa v are represented by drawing an arrow from w to v (w Ñ v) with the label
a. When considering pointed models xM, wy we also double circle the world w.
Consider the following example of a DEL model.

Example 1 A DEL model M “ xW, pďaqaPA, V y for a set A “ ta, bu of agents is
depicted below. In the pointed model xM, wy agent a knows that p is true but q
is false, and agent b believes that q is true.

a, b

a, b

w

p, ¯q

b

p, q v

b

b

u

¯p, q

a, b

The different upgrades are used to capture differences in the trustworthiness
of the information source: the source may be considered as an infallible source
(announcements), as a highly trusted, but fallible source (radical upgrades), or
as a trusted, but not infallible source (conservative upgrades) [3]. Radical and
conservative upgrades have been discussed under various names in the context
of Belief Revision (for example the AGM framework [24]), e.g. in [38, 42], and
have been formalized for DEL in an attempt to bridge DEL with Belief Revision
in [6]. Fixed points of announcements, radical and conservative upgrades have been
investigated in [5].

Example 2 Let M “ xW, pďaqaPA, V y be the DEL model of Example 1. Then M!p,
Mòp and MÒp are depicted below. It holds that, among others, M!p, w ( Kbp,
Mòp, w ( Bbp and MÒp, w ( Bbp.

8

Line van den Berg et al.

a, b

a, b

a, b

a, b

a, b

a, b

w1

p, ¯q

b

p, q w2

w1

p, ¯q

b

p, q w2

w1

p, ¯q

b

p, q w2

b

b

b

b

w3

¯p, q

w3

¯p, q

M!p

a, b

Mòp

a, b

MÒp

Interestingly, announcements, radical and conservative upgrades do not actu-
ally add something new to the language. Indeed, the expressivity of DEL is the
same as for an epistemic-doxastic logic: any sentence involving an announcement,
radical or conservative upgrade can be reduced to one without via reduction ax-
ioms [6, 35].

Lastly, when working with DEL models, a useful and important notion is that

of bisimulation. It formalizes when two models are semantically equivalent.

Definition 6 (Bisimulation) Let two DEL models M “ xW, pďaqaPA, V y and
M1 “ xW 1, pď1

aqaPA, V 1y be given for set A of agents.

A relation Z Ď W ˆ W 1 is a bisimulation if and only if for all pw, w1q P Z the

following three conditions hold:

– [Propositional agreement] V pwq “ V 1pw1q;
– [Forth] For every agent a P A and for every v P W such that w ďa v there

exists a v1 P W 1 such that w1 ď1

a v1 and pv, v1q P Z;

– [Back] For every agent a P A and for every v1 P W 1 such that w1 ď1

a v1 there

exists a v P W such that w ďa v and pv, v1q P Z.

Two pointed models xM, wy and xM1, w1y are bisimilar if and only if there is

a bisimulation Z such that pw, w1q P Z.

In DEL, the semantic notion of bisimulation coincides with the statement that

models satisfy the same formulas [19].

3.1 Dynamic Epistemic Logic with Event Models

In the previous section, three ways have been discussed and formalized to change
the knowledge and beliefs of agents: announcements, radical upgrades and conser-
vative upgrades. In this section, we look at a generalization of these upgrades called
event models, or action models, as introduced in [3]. Event models are relational
structures that allow us to talk about the dynamics of information in the same
way that DEL models formalize static information. The general idea is to think
of event models as Kripke models, but instead of consisting of worlds, we consider

Raising Awareness without Disclosing Truth

9

it to be consisting of a set of events, and instead of a valuation a precondition is
defined. Like on a DEL model, the relational structure of an event model specifies
which events the agents can tell apart.

Event models can be used to describe a variety of informational events: from
public announcements to more subtle communication containing privacy, mislead-
ing or suspicion. For example, information may be shared in secret, hidden com-
pletely (other agents do not observe the communication) or partially (other agents
observe the communication, but not what is communicated) from others.

To formalize these situations, we first introduce an alternative language: the

language of Epistemic Action Logic (EAL) [3].

Definition 7 (Syntax of EAL) Given a countable, non-empty set P of propo-
sitions and a finite, non-empty set A of agents, the syntax, LEAL, of (multi-agent)
Epistemic Action Logic (EAL) is defined in the following way.

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | rxE, eysϕ

where p P P is a proposition, Ka and Ba are the knowledge and belief operators
for each agent a, and xE, ey are pointed event models.

Models of EAL are equivalent to models of DEL (Definition 2), with a plausi-

bility relation for each agent that is a well-founded, locally connected preorder.

Event models for EAL provide a relational structure to dynamic upgrades.
Formally, an event model is like a Kripke model but instead of worlds we consider
events and instead of a valuation a precondition is defined.

Definition 8 (Event Model) Let A be a finite, non-empty set of agents. An
event model for EAL is a triple E “ xE, pRaqaPA, prey where

– E is a non-empty, finite set of events;
– pRaqaPA Ď E ˆ E are the accessibility relations on E, one for each agent a P A;
– pre : E Ñ LDEL is a precondition function assigning to each event a formula

ϕ.

Given an event model E and an event e P E, xE, ey is a pointed event model.

When drawing a pointed event model xE, ey, events are drawn as squares to

distinguish them from EAL models and e is double-squared.

The product update M b E determines what happens if an event model E takes

place on a EAL model M [3].

Definition 9 (Product Update) Let M “ xW, pďaqaPA, V y be a EAL model
and E “ xE, pRaqaPA, prey be an event model. Their product update, denoted by
M b E, is the triple xW MbE , pďMbE

qaPA, V MbE y defined by:

a

– W MbE “ txw, ey P W ˆ E | M, w ( prepequ
– xw, ey ďMbE
– V MbE ppq “ txw, ey P W ˆ E | w P V ppqu

a

xw1, e1y iff xw, ey, xw1, e1y P W MbE , w ďa w1 and eRae1

The product update M b E is the result of the events e P E happening at
the worlds w P W whenever w satisfies the precondition prepeq. The precondition
therefore serves as a selection to which worlds an event may be applied. For ex-
ample, if prepeq “ ϕ, that means that the event e may only be applied to worlds

10

Line van den Berg et al.

w that make ϕ true. Then, if e is the sole event of E, this means that the worlds
falsifying ϕ are deleted from the product update. In the following we also refer to
the events e such that M, w ( prepeq as the events that can be applied to w.

The accessibility relations Ra express how the different agents observe the
event. This determines which relations remain in the product update from the
initial epistemic model. Hence, for a to have access to a world in the product
update, there needs to be a ďa-arrow between the corresponding worlds in the
DEL model and a Ra-arrow between their corresponding events in the event model.
In general, agents may observe the event differently.

Finally, the valuation in the product update is the same as before, ranging over

the worlds in the product update.

Satisfiability for events is then determined with respect to the product update.

Definition 10 (Satisfiability for Events) Satisfiability for EAL extends satis-
fiability for DEL (Definition 5), replacing the last clause by:

M, w ( rxE, eysψ iff M, w ( prepeq implies that M b E, xw, ey ( ψ

We can capture public announcements with event models.

Definition 11 (Public Announcement) The pointed event model for the pub-
lic announcement !ϕ is xE!ϕ, eϕy where E!ϕ “ xteϕu, pIaqaPA, prey and prepeϕq “ ϕ:

A

ϕ

eϕ

Indeed, the event model for public announcements is equivalent to the model
transformer !ϕ in Definition 5: only the worlds satisfying the precondition, namely
ϕ, remain in the resulting model, while the accessibility relations to and from
these worlds are equivalent to the relations in the initial model. In other words,
␣ϕ-worlds are deleted.

Giving event structures to dynamic upgrades is interesting because it allows for
more complex upgrades such as private announcements. A private announcement
is an announcement that is only received by a subset G of agents and that is
“invisible” to the other agents [3].

Definition 12 (Private Announcement) The pointed event model for the
fully private announcement !Gϕ to a group G Ď A is xE!Gϕ, eϕy where the event
model is defined as E!Gϕ “ xteϕ, eJu, pRaqaPA, prey such that for a P G, Ra “
txeϕ, eϕy, xeJ, eJyu and otherwise Ra “ teϕ, eJu ˆ teJu, prepeϕq “ ϕ and prepeJq “
J:

Raising Awareness without Disclosing Truth

11

G

eϕ

ϕ

AzG

eJ

J

A

A private announcement of a formula ϕ to a group G of agents makes two
copies of the worlds: in one of the copies, only accessible by agents in the group G,
all the worlds in which ϕ is false are eliminated (through eϕ), leaving these agents
to learn ϕ, whereas the other copy preserves the old epistemic structure for agents
not in G. This ensures that they do not receive any information about the private
announcement that took place.

Whereas public announcements preserve the structures of EAL models—the
plausibility relations are well-founded, locally connected preorders—this is not
true for private announcements. To ensure that the event takes place privately,
the agents b R G do not have access to eϕ in Definition 12, i.e. there is no reflexive
relation for these agents at eϕ. This means that, in the product update, the worlds
‘created’ with eϕ do not have reflexive relations for b R G. As a consequence,
the resulting models are no longer EAL models. To prevent this, typically event
models are required to be such that they preserve the properties of the model
structures [3]. Then it holds that applying an event to a EAL model yields a EAL
model. In the situation here, this requirement boils down to requiring the relations
Ra in event models to satisfy the same properties as the plausibility relations ďa
in DEL models [3].

Of course, this restriction constraints the type of event models that can be
applied. Another way to deal with this would be to weaken the logic. Later in this
paper it is explained how weak reflexivity can be another way out.

Event models as described here have been generalized in [8] to accommodate
factual change by introducing postconditions that define the new valuation func-
tion in the product update.

4 Agent awareness and unawareness

Dynamic Epistemic Logic is a rich framework for analyzing epistemic and doxastic
changes under dynamic actions. However, there is a category of multi-agent sys-
tems for which DEL may be considered to fall short: dynamic and open multi-agent
systems. In such systems, agents are typically required to continuously adapt to
their environment and to interact while preserving heterogeneity in their knowl-
edge representations [2, 20, 21].

There are two problems when it comes to using DEL to model dynamic and
open multi-agent systems: (1) agents cannot use their own vocabularies in DEL,

12

Line van den Berg et al.

and (2) agents cannot extend (nor shrink) their vocabularies. The reason for this is
what we call public signature awareness: the agents use the same, fixed vocabulary.
This means that agents are aware of all the propositions used by other agents, now
or in the future, and that learning new information is limited to eliminating or
re-organizing the possibilities with respect to these propositions.

The problem of public signature awareness is hidden in the structure of DEL:
valuation functions are total functions and accessibility relations are reflexive.
Therefore, in order to eliminate public signature awareness and to faithfully cap-
ture dynamic and open multi-agent systems, the structure of the models needs to
be adjusted. For that purpose, total valuations are replaced by partial valuations
and reflexivity by weak reflexivity. First, we motivate both before defining them
precisely.

Partial valuation functions

By using total valuation functions, the vocabularies of agents become equivalent
to the set of all propositions, P . This is because they enforce each proposition to
be evaluated to 0 or 1 at each world, therefore enforcing agents to be aware of
all of them. With partial valuation functions, on the contrary, propositions may
either be true, false, or a third option: undefined. The latter occurs when the
propositions are not interpreted by the valuation function at a certain world, i.e.
they do not belong to the domain DompVwq of the valuation function V at some
world w. By assigning a different partial valuation function to each world, we can
specify both which propositions are evaluated (those belonging to the domain) and
how they are evaluated (true or false), enabling agents to use different signatures,
denoted by sigpaq Ď P for agent a, to represent their knowledge and beliefs. This
is achieved by defining the signature of agent a as the domain of the worlds w she
can reach, i.e. sigpaq “ DompVwq. Later we will define natural restrictions on the
domain so that the signature of agents is constant over the worlds they can reach
and sigpaq “ DompVwq is a proper definition.

Weakly reflexive relations

However, even with partial valuation functions, as long as reflexivity is satisfied,
agents still share the same signature. This is because reflexive relations cause
agents to have access to at least one common world w (such that xM, wy is the
pointed model to which formulas are evaluated) so that sigpaq “ DompVwq “
sigpbq. Hence, we also need to drop reflexivity as an assumption on the model struc-
tures. Without reflexivity, two agents a and b can have access to different worlds
v and u from w, respectively, such that DompVvq “ sigpaq and DompVuq “ sigpbq
and neither wRaw nor wRbw. In order to preserve consistency of agents’ knowledge
and beliefs, reflexivity is asserted to hold at v and u. That means that reflexivity
is not satisfied globally, but locally at the worlds that determine the signatures
(propositions defined) and the awareness (which worlds satisfy reflexivity) of the
agents.

We call our alternative definition of reflexivity weak reflexivity. It requires that,
whenever reflexivity holds at a world w for an agent a, it will continue to hold at
any other world v agent a can access from w. As we will see later, as a consequence

Raising Awareness without Disclosing Truth

13

the usual properties of knowledge and beliefs, and in particular factivity of knowl-
edge, still hold within the aware cells of agents: those worlds in which reflexivity
holds.

4.1 A definition of awareness

The accessibility relations indicate which worlds the agents are aware of—those
where reflexivity is satisfied—and the partial valuation functions determine which
propositions the agents are aware of—those propositions belonging to the domain
of these worlds. This enables agents to use their own signatures to represent their
knowledge and beliefs, and to adapt or extend it.

As a consequence of using partial valuation functions, lack of truth and fal-
sity do no longer coincide. Instead, there is a third option: propositions may be
undefined. Whenever this happens for a proposition p at a world accessible by an
agent, this agent is said to be unaware of p.

Unawareness is different from uncertainty, which is also called ignorance. The
latter occurs when agents have no information about the truth value of a proposi-
tion, i.e. they do not know nor believe the proposition, nor its truth value, whereas
unawareness occurs when agents do not consider a proposition at all, i.e. the propo-
sition is undefined in the worlds accessible by that agent. Uncertain agents have
access to at least one world in which p is true and at least one world in which p
is false, which are considered equally plausible, and unaware agents do not have
access to any p-world nor ␣p-world (Figure 1).

a

p, q

w

a

a

p, ¯q

v

a

p, q

w1

a

a

¯p, ¯q

v1

a

q

w2

Fig. 1 Agent a is certain about p (|ù Kap, left), uncertain about p (|ù Kapp _ ␣pq, middle)
and unaware of p (right). In all cases, agent a knows q.

Unawareness of a proposition means that agents do not consider the proposi-
tion. Awareness of a proposition means that agents do consider the proposition,
and hence also its truth value of it. Therefore, awareness of a proposition implies
that agents are at least uncertain about the proposition.

The signature of an agent, also more generally called the awareness of an agent,
is defined as the propositions evaluated to 0 or 1 in the worlds that she can access
such that reflexivity holds.

In Figure 1, agent a is aware at w, v, w1, v1 and w2, the awareness of agent a
is tp, qu in the models on the left and in the middle, and tqu in the model on the
right. Note that, like before, we write, inside a world w, p to denote that Vwppq “ 1
and ¯p to denote that Vwppq “ 0, but now, when we do not write p nor ¯p, it means
that p R DompVwq.

Definition 13 (Agent Awareness) If W is a non-empty set of worlds, P a
countable, non-empty set of propositions, A a finite, non-empty set of agents,

14

Line van den Berg et al.

tVwuwPW a set of partial valuation functions Vw : P Ñ t0, 1u, and a an agent with
accessibility relation Ra Ď W ˆ W , then a is said to be aware at w if and only if
wRaw and the awareness (or signature, or vocabulary) of agent a at w is defined
as:

ď

AWapwq “

DompVvq

(4)

tvPW | wpRaYR´1

a qv^vRavu

Whenever w is clear from the context in a pointed model xM, wy, we will also
use AWapxM, wyq, AWapMq or simply AWa for AWapwq to denote the awareness
of agent a in the pointed model.

a

b

p, ¯q

w

a

p

v

b

¯q

u

a, b

t

b

a

Fig. 2 Two agents, a and b, with different, disjoint signatures, tpu and tqu, respectively.
Agents are not aware of the same propositions.

In Figure 2, the awareness of agent a is tpu and the awareness of agent b is tqu.

4.2 Properties of awareness

Partial valuation functions and a weaker form of reflexivity are necessary for agents
to use different signatures to represent their knowledge and beliefs. Here we discuss
the properties of awareness that we require.

It is a natural assumption to let awareness of agents be constant over their
accessibility relations. This is to ensure that agents do not consider it possible
that their awareness is different from what they are actually aware of, i.e. what
one can consider is limited to one’s awareness. This means that the awareness of
agents is constant over their considerations. Similar properties for awareness were
already motivated: in [22], awareness is assumed to not be able to decrease under
evolution (i.e. there is no “forgetting”) and in [25] awareness is considered constant
for all the worlds the agent has access to. Compared to these works, the properties
of awareness we introduce here are not different, but the framework for awareness
itself is (using partial valuation functions and weakly reflexive relations).

Take note that requiring that awareness is constant over accessibility does not
imply that it is fixed: agents can extend their awareness through model-changing

Raising Awareness without Disclosing Truth

15

dynamic upgrades that is not restricted to the set of propositions P , which we will
define in Section 6 on raising awareness.

Letting agent awareness be constant over their accessibility comes twofold:

– whenever there is a reflexive relation for an agent a from a world w to w, then
for any v that is also accessible from w for a, there is a reflexive relation from
v to v (weak reflexivity), and

– the domains of two worlds v and u that are both accessible by the same agent

from a single world w are equal (consideration consistency).

Weak reflexivity ensures that if an agent is aware at a world w, she will remain

aware at all the worlds she can reach from w, see Figure 3.

Definition 14 (Weak Reflexivity) Let W be a non-empty set of worlds and
let a P A be an agent with a relation Ra Ď W ˆ W . Then Ra is called weakly
reflexive if @w, v P W :

wRaw ^ wRav ñ vRav

(5)

a

w

a

a

v

Fig. 3 An illustration of weak reflexivity: if the black arrows hold for a certain agent a, then
there must also be the red arrow for a.

Consideration consistency ensures that the awareness of agents, i.e. the propo-
sitions that are defined in a world with reflexivity, is constant over accessibility.
Figure 4 illustrates this property.

Definition 15 (Consideration Consistency) Let W be a non-empty set of
worlds, P be a countable, non-empty set of propositions, A be a finite, non-empty
set of agents, tVwuwPW be a set of partial valuation functions, and let a P A be
an agent with a relation Ra Ď W ˆ W . Then tVwuwPW satisfies consideration
consistency if @w, v, u P W :

wRav ^ wRau ñ DompVvq “ DompVuq

(6)

Consideration consistency does not only apply to worlds w, v, u such that wRav
and wRau (hence DompVvq “ DompVuq), but also stipulates that if wRaw and
wRav then DompVwq “ DompVvq. Therefore when combining consideration con-
sistency with weak reflexivity, it enforces that agents are consistent in their con-
siderations: if an agent a considers a proposition p (or its negation) to be true at
a world w (i.e. p P DompVwq and wRaw), she considers p to have a truth value at
every world v she can reach via Ra from w (i.e. also p P DompVvq and vRav), and
vice-versa. This is independent from the actual truth value of p—it only requires
that p is assigned a truth value 0 or 1.

16

Line van den Berg et al.

a

a

w

P 1

v

P 1

u

Fig. 4 An illustration of consideration consistency: if the arrows hold for a certain agent a,
and the domains are DompVvq and DompVuq, then these domains are equal, here drawn to be
P 1.

Proposition 1 (Awareness is constant over accessibility) Let W be a set
of worlds, P be a set of propositions, tVwuwPW a set of partial valuation functions
satisfying consideration consistency, and let a be an agent with a relation Ra Ď
W ˆ W that is weakly reflexive. It holds that @w P W : if wRaw then @v P W such
that wR˚
a is the transitive
closure of Ra.

av, we have vRav and AWapvq “ AWapwq, where R˚

Proof Follows directly by Definitions 14 and 15 for weak reflexivity and consider-
ation consistency.

Lastly, we require that agents cannot reason about what other agents know
or believe when it involves a proposition they are not aware of themselves. For
example, in Figure 2, if DompVtq included q, it would allow agent a to know that
b knows q, whereas a is unaware of q. To avoid this, we require a last condition
called specification:

– the domain of the valuation function cannot increase over accessibility (speci-

fication).

Specification avoids the situation in which, for example, KaKbp but p R AWa.
This will be further discussed in Section 4.3. Note that when wRaw and wRav,
by consideration consistency, DompVvq “ DompVwq and therefore DompVvq Ď
DompVwq. Figure 5 illustrates specification.

Definition 16 (Specification) Let W be a non-empty set of worlds, P be a
countable, non-empty set of propositions, A be a finite, non-empty set of agents,
tVwuwPW be a set of partial valuation functions, and let a be an agent with a
relation Ra Ď W ˆ W . Then tVwuwPW satisfies specification if @w, v P W :

wRav ñ DompVvq Ď DompVwq

(7)

The three properties—weak reflexivity, consideration consistency and specification—

ensure that agents are consistent in their considerations, while allowing models in
which agents are aware of different signatures, or vocabularies. For example, the
model shown in Figure 2 satisfies weak reflexivity, consideration consistency and
specification, yet the awareness of agents is different: tpu for agent a and tqu for
agent b.

Lastly, it may be clear that if for two agents a and b reflexivity is satisfied at w,
their awareness is the same, i.e. AWapwq “ AWbpwq, by consideration consistency.

Raising Awareness without Disclosing Truth

17

P1

w

a

P2

v

Fig. 5 An illustration of specification: if the arrow from w to v holds for a certain agent a,
and the domains are DompVwq “ P1 and DompVvq “ P2, then P2 Ď P1.

4.3 Awareness for knowledge and beliefs

We define the knowledge and beliefs of agents as usual with respect to the ac-
cessibility relations. However, since reflexivity is not satisfied globally, there is an
additional requirement: reflexivity needs to hold. Thus knowledge is defined as
everything that is true in all accessible worlds for an agent in which reflexivity
is satisfied for that agent, and belief is defined as everything that is true in the
maximal worlds with respect to the accessibility relation for an agent in which re-
flexivity is satisfied. These notions can also be captured by epistemic and doxastic
relations, which are deduced from the accessibility relations. In particular, they
are defined with respect to the aware cell of an agent. This aware cell consists
of all the worlds satisfying reflexivity accessible by an agent, see Figure 6 for an
example.

Definition 17 (Aware Cell) Let W be a non-empty set of worlds and a finite,
non-empty set A of agents and let Ra Ď W ˆ W be an accessibility relation for
agent a that is well-founded, locally connected, weakly reflexive and transitive.
Then the aware cell of agent a at world w P W , denoted by ||w||a, is the set of
worlds that are accessible via the transitive closure of Ra and R´1
and in which
a
reflexivity is satisfied:

||w||a “ tv P W | wpRa Y R´1

a q˚v and vRavu

(8)

a

v

a

w

a

w1

a

a

v1

Fig. 6 The aware cells are as follows: ||w||a “ ||v||a “ tvu and ||w1||a “ ||v1||a “ tw1, v1u
(marked by dotted boxes).

Within the aware cells, the awareness of agents is constant: @w, u, v P W ,
@a P A: if u, v P ||w||a then AWapvq “ DompVvq “ DompVuq “ AWapuq. Therefore
we also simply use DompVwq to denote the awareness of agent a at world w.

The epistemic and doxastic relations are defined with respect to the aware cell

of an agent.

Definition 18 (Epistemic and Doxastic Relations) Let A be a finite, non-
empty set of agents, W be a non-empty set of worlds and let a P A be an agent with

18

Line van den Berg et al.

accessibility relation Ra Ď W ˆ W that is well-founded, locally connected, weakly
reflexive and transitive. Then the epistemic („a) and doxastic (Ña) relations are
defined as follows:

w „a v iff v P ||w||a

w Ña v iff v P M axRa ||w||a

(9)

(10)

Within aware cells of an agent a, „a and Ña satisfy the usual properties for
epistemic and doxastic relations. Therefore, within the aware cells of agents, knowl-
edge and beliefs satisfy the usual axioms as for DEL: S5 and KD45, respectively.

Proposition 2 Let W be a set of worlds and a an agent with accessibility relation
Ra Ď W ˆW that is well-founded, locally connected, weakly reflexive and transitive.
Then within ||w||a, „a is reflexive, transitive and symmetric and Ña is transitive,
serial and Euclidean.

Proof The only difference with the plausibility relation ďa for DEL (Definition 2)
is that Ra is not reflexive, but weakly reflexive. By Definition 17 of aware cells,
we have that @w P W and @v P ||w||a: vRav. Hence, within ||w||a, the relation
Ra is a well-founded locally connected pre-order and it therefore follows that „a
and Ña satisfy the same properties as the epistemic and doxastic relations for
DEL [19]: „a is reflexive, transitive and symmetric and Ña is transitive, serial
and Euclidean.

However, outside the aware cells, knowledge is not necessarily factive, i.e. the
T axiom is no longer valid. Instead, it is only valid within the aware cells of agents.
This behavior is due to weak reflexivity: reflexivity holds only in the aware cells of
agents. As a consequence, the knowledge operators Ka are intermediate operators
between S5 and KD45: Ka satisfies S5 within the aware cell of agent a, but
satisfies KD45 outside the aware cell. In practice, such a knowledge operator may
be thought of as “subjective knowledge”: it takes the perspective of the agent in
question and what is known by her.

5 Partial Dynamic Epistemic Logic

We are now ready to define our logic, Partial Dynamic Epistemic Logic (ParDEL).
The syntax of ParDEL is equivalent to that of DEL.

Definition 19 (Syntax of ParDEL) Given a non-empty set P of propositions
and a finite non-empty set A of agents, the syntax, LParDEL, of (multi-agent)
Partial Dynamic Epistemic Logic (ParDEL) is defined in the following way.

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | r†ϕsψ

where p P P is a proposition, Ka and Ba are the knowledge and belief operators for
each agent a P A, and †ϕ with † P t!, ò, Òu the dynamic upgrades: announcements,
radical and conversative upgrades.

ParDEL frames are DEL frames but satisfy weak reflexivity instead of reflexiv-
ity in order to allow agents to use different signatures to represent their knowledge
and beliefs.

Raising Awareness without Disclosing Truth

19

Definition 20 (ParDEL Frames) Given a finite non-empty set A of agents, a
frame of (multi-agent) ParDEL is a pair F “ xW, pRaqaPAy where

– W is a non-empty set of worlds, and
– pRaqaPA : A Ñ PpW ˆ W q are the accessibility relations on W , one for each
agent, that are well-founded, locally connected, weakly reflexive and transitive.

A ParDEL model is a ParDEL frame equipped with a partial valuation function

satisfying consideration consistency and specification.

Definition 21 (ParDEL Models) Given a non-empty set P of propositions
and a finite non-empty set A of agents, a model of (multi-agent) ParDEL is a pair
M “ xF, V y where

– F “ xW, pRaqaPAy is a ParDEL frame, and
– V : W Ñ pP Ñ t0, 1uq is a partial valuation function that assigns to each world
w P W a partial function Vw : P Ñ t0, 1u satisfying consideration consistency
and specification.

A pointed ParDEL model is a pair xM, wy, where w P W .

Satisfiability for ParDEL is considered with respect to a pointed model xM, wy
which associates a ParDEL model M with a world w P W . Since lack of truth and
falsity do not coincide when considering partial valuation functions, two relations
are specified: one for verification (() and one for falsification ()).

Satisfiability for ParDEL is based on satisfiability for partial semantics in [32]
and extends it in three ways: (1) by introducing a novel connection between partial
valuations and agent awareness (Section 4), (2) by considering knowledge and
beliefs of agents as truth in all accessible worlds and most plausible worlds in
which reflexivity is satisfied (Section 4.3) and (3) by considering a different clause
for the falsification of a conjunction: a conjunction is false whenever at least one
of the conjuncts is false, as usual, but in addition both conjuncts belong to the
domain of the valuation function. In particular, we require (3) in order to prevent
agents from gaining the knowledge that a conjunction is false (or similarly that
a disjunction is true) whenever they know that one of the conjuncts is false (or
one of the disjuncts is true), but are unaware of the other conjunct (or disjunct).
This enforces that the knowledge and beliefs of agents are constrained to their
awareness.

Definition 22 (Satisfiability for ParDEL) Satisfiability for ParDEL extends
that of DEL (Definition 5) and is defined as:

M, w ( p
M, w ( ϕ ^ ψ
M, w ( ␣ϕ
M, w ( Kaϕ
M, w ( Baϕ
M, w ( r†ϕsψ

iff Vwppq “ 1
iff M, w ( ϕ and M, w ( ψ
iff M, w ) ϕ
iff @v s.t. w „a v : M, v ( ϕ
iff @v s.t. w Ña v : M, v ( ϕ

iff M

†ϕ, w ( ψ

20

Line van den Berg et al.

for verification (() and for falsification ()):

M, w ) p
M, w ) ϕ ^ ψ

iff Vwppq “ 0
iff M, w ) ϕ and M, w ( ψ,

or M, w ( ϕ and M, w ) ψ,
or M, w ) ϕ and M, w ) ψ

iff M, w ( ϕ
iff Dv s.t. w „a v : M, v ) ϕ
iff Dv s.t. w Ña v : M, v ) ϕ

iff M

†ϕ, w ) ψ

M, w ) ␣ϕ
M, w ) Kaϕ
M, w ) Baϕ
M, w ) r†ϕsψ

with † P t!, ò, Òu.

As usual, a set of formulas is said to be inconsistent if there does not exist
a pointed model verifying it. In the following, we say that a formula ϕ is a con-
sequence of a set of formulas Γ (written Γ ( ϕ) if every pointed model xM, wy
verifying all formulas of Γ , also verifies ϕ.

Whenever a proposition p does not belong to the domain of the valuation
function at a world w, i.e. p R DompVwq, we have indeed that M, w * p and
M, w + p. Hence, p is neither true nor false.

As disjunctions and implications can be defined using conjunctions and nega-
tions, the falsification clause for conjunctions also affects their satisfiability. In
particular, disjunctions are only true if both disjuncts are defined and at least one
of them is true. This ensures that agents only know or believe a disjunction if they
are aware of both disjuncts.

Example 3 Since ϕ _ ψ is the abbreviation for ␣p␣ϕ ^ ␣ψq:

M, w ( ϕ _ ψ

iff M, w ( ϕ and M, w ) ψ,

or M, w ) ϕ and M, w ( ψ,
or M, w ( ϕ and M, w ( ψ

M, w ) ϕ _ ψ

iff M, w ) ϕ and M, w ) ψ

There is a link between intuitionism [13] and awareness, in particular the way
satisfiability is defined for ParDEL. Example 3 shows that the truth of a disjunction
is defined constructively: ϕ_ψ is true as long as both disjuncts are defined, of which
at least one is true. That means that satisfiability for ParDEL follows that of Weak
Kleene Logic [33]. In this sense, we may say that awareness is constructive. Other
than that, however, awareness and intuitionism are rather orthogonal: intuitionism
drops the law of the excluded middle, dissociating ϕ from ␣ϕ, whereas awareness
dissociates being aware of ϕ from knowing the truth value of ϕ and ␣ϕ.

6 The dynamics of raising awareness

Partial valuation functions allow agents to use different signatures to represent
their knowledge. We have seen how these can be used to describe awareness and
unawareness of agents directly in the structure of the models when we replace

Raising Awareness without Disclosing Truth

21

reflexivity by weak reflexivity. We have also seen some properties of awareness that
are natural to require: consideration consistency and specification. Here, we discuss
some dynamics for awareness. In particular, the dynamics of raising awareness.
Because even though awareness of agents is constant over their accessibility, partial
valuations enable to define a model-changing dynamic upgrade allowing agents to
extend their awareness.

We extend the syntax of ParDEL with a dynamic modality `p for raising the
awareness of a proposition p. We call the logic obtained Partial Dynamic Epistemic
Logic with raising awareness (ParDEL+).

Definition 23 (Syntax of ParDEL+) Given a non-empty set P of propositions
and a finite non-empty set A of agents, the syntax, LParDEL`, of (multi-agent)
Partial Dynamic Epistemic Logic with raising awareness (ParDEL+) is defined in
the following way.

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | r†ϕsψ | r`psϕ

where p P P is a proposition, Ka and Ba are the knowledge and belief operators
for each agent a P A, †ϕ with † P t!, ò, Òu the dynamic upgrades announcements,
radical and conversative upgrades, and `p is an operation for raising awareness.

Frames and models of ParDEL+ are equal to frames and models of ParDEL
(Definitions 20 and 21), using accessibility relations that are weakly reflexive and
partial valuation functions satisfying consideration consistency and specification.
When awareness was introduced, it was discussed how to interpret awareness
of a proposition: as considering at least one truth value of the proposition. This
means that awareness at least implies ignorance. Becoming ignorant is therefore
the minimal way to raise awareness without disclosing truth.

To raise the awareness of a proposition p, we define a model transformation
that extends the valuation function at each world in which p does not belong
to the domain to include p. In order to solely raise awareness, i.e. to perform it
without disclosing truth values, it does so by first duplicating each of these worlds,
accessibility to and from duplicated worlds being preserved, such that p is made
true in one world and false in the other. Other than the different valuation of p
(and related sentences), the two duplicated worlds are indifferent, satisfying the
same valuations and relations. After raising the awareness of p, agents come to
consider equally plausible either that p is true or that p is false, see Figure 7.
Therefore, raising the awareness of p transforms unaware agents into uncertain
agents: agents who are aware of p but do not know whether p is true or false.

When raising the awareness of p, we categorize the worlds of the model into
three: worlds in which p is true (W |p “ tw P W | Vwppq “ 1u), worlds in which
p is false (W |␣p “ tw P W | Vwppq “ 0u) and worlds in which p is undefined
(W zpW |p YW |␣pq). In this way, the worlds in which p is undefined can be identified
to be duplicated by raising awareness.

Definition 24 (Raising Awareness (`p)) Let M “ xW, pRaqaPA, V y be a
ParDEL+ model and let p P P be a proposition. Then `p is a model transformer
`p : M ÞÑ M`p where M`p is the triple xW `p, pR`p
– W `p “ W |p ˆ t1u Y W |␣p ˆ t0u Y W zpW |p Y W |␣pq ˆ t0, 1u
– xw, iyR`p

a qaPA, V `py defined by:

a xv, jy iff wRav

22

Line van den Berg et al.

a

w

`p

a

a

p

¯p

a

pw, 1q

pw, 0q

Fig. 7 Raising the awareness of p, `p. The red dashed lines indicate how the world w from
the model on the left is mapped to both pw, 1q and pw, 0q in the model on the right. p (¯p)
written inside a world w means that Vwppq “ 1 (Vwppq “ 0), and whenever neither p nor ¯p is
written, it means that p does not belong to DompVwq.

#

– V `p

xw,iypqq “

Vwpqq
i

if q ‰ p
otherwise

The new valuation function corresponds to the old one in the case that p is
defined: V `p
xw,iyppq “ i “ Vwppq because only in this case xw, 1y P W `p, where i “ 1
if Vwppq “ 1 and i “ 0 if Vwppq “ 0 (Figure 8). For worlds where p is undefined, i.e.
p R DompVwq, raising awareness of p maps w to both xw, 1y and xw, 0y, in which p
is made true and false, respectively.

Because worlds may be duplicated, satisfiability for r`psϕ is defined for all
xw, iy P W `p with i P t0, 1u for verification, and for some xw, iy P W `p with
i P t0, 1u for falsification.

Definition 25 (Satisfiability for ParDEL+) Satisfiability for ParDEL+ ex-
tends that of ParDEL (Definition 22) as follows:

M, w ( r`psϕ

M, w ) r`psϕ

iff @xw, iy P W `p s.t. i P t0, 1u : M`p, xw, iy ( ϕ
iff Dxw, iy P W `p s.t. i P t0, 1u : M`p, xw, iy ) ϕ

As we discussed before, in Figure 8, we can also see that knowledge is no longer
factive, except within the aware cells of agents: it holds that pw, 0q ( Kap implies
pw, 0q ( p because pw, 0q P ||pw, 0q||a, hence Ka is factive at pw, 0q. However,
pw, 0q ( Kb␣Kap holds, but pw, 0q * ␣Kap because pw, 0q R ||pw, 0q||b. Therefore
Kb is not factive at pw, 0q.

Raising awareness needs not to be constrained to the set of propositions P . We
can use the same definition to raise the awareness of q R P and extend P with q.
In this case, q will be undefined at every world of the model, leaving each world
to be duplicated by `q. This means that P does not need to be fixed in the initial
setting.

6.1 Raising awareness with event models

Similar to announcements, we can capture the dynamics of raising awareness in
an alternative way through event structures that specify how agents observe the

Raising Awareness without Disclosing Truth

23

a

pw

b

`p

a

p

pw, 0q

b

b

v

`p

pv, 1q

p

¯p

pv, 0q

a, b

a, b

a, b

a, b

Fig. 8 Raising the awareness of a proposition p, `p. The red dashed lines indicate how the
world w from the model on the left is mapped to pw, 1q in the model on the right and v to
both pv, 0q and pv, 1q.

events. Just as event structures enable us to capture private announcements on
Epistemic Action Logic (EAL), event structures for Partial Epistemic Action Logic
(ParEAL), the logic combining the syntax of EAL with the semantics of ParDEL,
enable us to define private raising awareness.

ParEAL follows the syntax of EAL (Definition 7) with modalities for multi-

pointed event models xE, E1y.

Definition 26 (Syntax of ParEAL) Given a countable, non-empty set P of
propositions and a finite, non-empty set A of agents, the syntax, LParEAL, of
(multi-agent) Partial Epistemic Action Logic (ParEAL) is defined in the following
way.

ϕ ::“ p | ϕ ^ ψ | ␣ϕ | Kaϕ | Baϕ | rxE, E1ysϕ

where p P P is a proposition, Ka and Ba are the knowledge and belief operators
for each agent a, and xE, E1y are multi-pointed event models.

The semantics of ParEAL is that of ParDEL and ParDEL+: frames and models
of ParEAL are equivalent to ParDEL and ParDEL+ frames and models (Defini-
tions 20 and 21), with accessibility relations satisfying weak reflexivity and partial
valuations satisfying consideration consistency and specification.

Multi-pointed event models for ParEAL are based on event models for EAL
(Definition 8), but with an added feature to specify the valuation of the proposition
awareness is raised of: postconditions poste for event e.

Event models have been extended before with postconditions in [8] to accom-
modate for factual change, through a substitution function. Here, we consider a
different definition of a postcondition. Postconditions for ParEAL event models
are functions assigning to each event e a partial function poste : P Ñ t0, 1u such
that this becomes the new valuation of p, if defined, and preserves the old valu-
ation if posteppq is undefined. This can likewise be used to define factual change,
by letting posteppq be equal to 0 or 1.

Definition 27 (Event Model with Postconditions) Let A be a finite, non-
empty set of agents. An event model for ParEAL is a quadruple E “ xE, pRaqaPA, pre, posty
where

24

Line van den Berg et al.

– E is a non-empty, finite set of events,
– pRaqaPA Ď E ˆ E are the accessibility relations on E, one for each agent a P A,
– pre : E Ñ LP arDEL` is a precondition function assigning to each event a

formula ϕ, and

– post : E Ñ pP Ñ t0, 1uq is a postcondition function assigning to each event a

partial function poste : P Ñ t0, 1u.

A pointed event model (with postconditions) is a pair xE, ey where E is an event
model with postconditions and e P E.

A multi-pointed event model (with postconditions) is a pair xE, E1y where E is

an event model with postconditions and E1 Ď E.

We will also write pree for prepeq and posteppq for ppostpeqqppq.
Given an event model E and a set of events te1, . . . , enu Ď E, the multi-pointed
event model xE, te1, . . . , enuy describes the set of pointed event models xE, ey with
e P te1, . . . , enu. When drawing a multi-pointed event model xE, te1, . . . , enuy for
ParEAL, events are again drawn as squares to distinguish them from ParDEL
models and all e P te1, . . . , enu are double-squared to emphasize the points of
reference.

Like for DEL, the product update of a ParEAL model M and an event model
E determines what happens if the event takes place. In this product update, the
preconditions again specify how to select the worlds in the product update. How-
ever, different to DEL, in ParEAL this selection takes place on the basis of ‘not
falsifying the precondition’, instead of requiring that the precondition is verified.
This is because lack of truth and falsity do not coincide on ParEAL. As a result, a
precondition p selects the worlds in which either p is true, or p is undefined. That
is, the worlds in which the precondition is undefined will remain too. This ensures
that we can capture raising awareness in a natural way, as we will see.

Additionally, postconditions are used to specify the valuations that change in
the product update. When the postcondition of a proposition is 1, this proposition
becomes true, when it is 0, it becomes false, and when it is K, it becomes undefined.
Lastly, when the postcondition for a proposition is undefined, the old valuation is
preserved.

Definition 28 (Product Update for ParEAL) Let M “ xW, pRM
a ParEAL model and E “ xE, pRE
update, denoted by M b E, is the triple xW MbE , pRMbE
– W MbE “ txw, ey P W ˆ E | M, w + preeu
– xw, eyRMbE

a qaPA, V y be
a qaPA, pre, posty be an event model. Their product
qaPA, V MbE y defined by:

xw1, e1y iff xw, ey, xw1, e1y P W MbE , wRM
#

a w1 and eRE

a e1

a

a

– V MbE

xw,ey ppq “

posteppq
Vwppq

if posteppq “ 1 or posteppq “ 0
otherwise

In the following we also refer to the events e such that M, w + prepeq as the
events that can be applied to w. It follows from the definition that whenever no
postcondition is defined, this means that the old valuation is preserved completely.

The event model for raising awareness is as follows.

Definition 29 (Event Model for Raising Awareness) The multi-pointed
event model for raising awareness of a proposition p P P is the pair xE`p, tep, e ¯puy
where E`p “ xE`p, pRaqaPA, pre, posty, with E`p “ tep, e ¯pu, Ra “ tep, e ¯pu ˆ
tep, e ¯pu and the pre- and postconditions defined as follows (see Figure 9):

Raising Awareness without Disclosing Truth

25

– preep “ p, postep ppq “ 1
– pree ¯p “ ␣p, poste ¯p ppq “ 0

`p to denote the points of reference tep, e ¯pu.

We also use E˚
Because the pre- and postconditions ‘coincide’ (that is, the valuation defined
by the postcondition verifies the precondition), we can draw the event model as
follows, where written p inside an event e means that pree “ p and posteppq “ 1
and written ␣p means that pree “ ␣p and posteppq “ 0:

A

A

ep

p

A

␣p e ¯p

Fig. 9 The event model E`p for raising awareness of p, `p.

The event model for raising awareness then duplicates all the worlds of a model
in which p was undefined, making p in one world and false in the other, while it
preserves the other worlds. This is because worlds w such that Vwppq is undefined
do not falsify p nor ␣p, hence W, w + preep and W, w + pree ¯p and both events ep
and e ¯p can be applied to w. For an example of the application of E`p to a model,
see Figure 10.

a

pw

A

A

a

p

pw, epq

b

b

ep

p

A

␣p e ¯p

“

b

b

v

a, b

pv, epq

p

¯p

pv, e ¯pq

a, b

a, b

a, b

Fig. 10 The event E`p applied to the epistemic model on the left.

Satisfiability is defined analogously as for EAL (Definition 10), but now with
respect to multi-pointed event models. The multiple points of reference are used
to enforce that, whenever p was initially undefined at w of xM, wy and awareness
of p is raised, so that it is duplicated in two worlds xw, epy and xw, e ¯py, both these
duplicated worlds must make ϕ true in order for r`psϕ to hold at w. In this way,
satisfiability for the raising awareness event model is equivalent to the clause for
`p in Definition 25.

Definition 30 (Satisfiability for Multi-pointed Event Models) Given a
multi-pointed event model xE, E1y, satisfiability for ParEAL extends satisfiability
of ParDEL (Definition 22), replacing the clause for r†ϕsψ by:

26

Line van den Berg et al.

M, w ( rxE, E1ysϕ iff
M, w ) rxE, E1ysϕ iff

@e P E1 : M, w + prepeq : M b E, xw, ey ( ϕ
De P E1 : M, w + prepeq : M b E, xw, ey ) ϕ

Figures 8 and 10 illustrate that `p as defined as a model transformer in Defi-

nition 24 and the multi-pointed event model E`p lead to the same model.
Proposition 3 For any ParDEL+/ParEAL model M, M`p is bisimilar to M b
E`p.
Proof M`p is M with every world w P M such that p R DompVwq duplicated
into xw, 0y and xw, 1y making p false and true, respectively, while the relations
and valuations for other propositions remain the same. This is exactly the same
as M b E`p, by replacing 1 by ep and 0 by e ¯p. I.e. the same valuations and the
same relations hold. Therefore Z defined as @xw, iy P W `p: xw, 0yZxw, e ¯py and
xw, 1yZxw, epy is a bisimulation.

Furthermore, the semantics is equivalent for `p and xE`p, tep, e ¯puy. Therefore,

we can use these two interchangeably.

Proposition 4 For any ParDEL+/ParEAL model M, any world w P M, any
proposition p P P and any formula ϕ, it holds that:

M, w ( r`psϕ iff M, w ( rxE`p, tep, e ¯puysϕ
M, w ) r`psϕ iff M, w ) rxE`p, tep, e ¯puysϕ

Proof We prove the case of verification, the case of falsification is analogous. It
holds that M, w ( r`psϕ iff @xw, iy P W `p with i P t0, 1u: M`p, xw, iy ( ϕ.
But since M`p and M b E`p are bisimilar (Proposition 3), they can be ex-
changed so that, by renaming xw, iy with events ep, e ¯p, M, w ( r`psϕ iff @xw, ey P
W MbE with e P tep, e ¯pu: M b E, xw, ey ( ϕ. Therefore, M, w ( r`psϕ iff M, w (
rxE`p, tep, e ¯puysϕ.

6.2 Raising private awareness

When we discussed event models for DEL (see Section 3.1), we explained how
these models enable us to study more complex epistemic upgrades such as pri-
vate announcements, by computing the product update [3]. Analogous to private
announcements, in this section we consider the dynamics of raising private aware-
ness: a group G of agents raises their awareness of a proposition p, but this occurs
in full privacy to the other agents (AzG). This means that the other agents do not
observe the upgrade, they do not even consider that it occured.

We can capture raising private awareness with an event model that looks sim-
ilar to the event model for public awareness (Definition 29), but instead of two
events, one with precondition p and another with precondition ␣p, a third event
needs to be considered: an event with precondition J, analogous to eJ in the event
model for private announcements (see Definition 12). Like for public raising aware-
ness, the first two events duplicate the worlds in which p is undefined, making it
true in one and false in the other, but now the third event ensures that the other
agents do not observe this to occur.

Raising Awareness without Disclosing Truth

27

Definition 31 (Event Model for Private Raising Awareness) The multi-
pointed event model for private raising awareness of a proposition p amongst
a group G Ď A of agents is xE`Gp, tep, e ¯puy where E`Gp “ xE`GppRaqaPA, prey
with E`Gp “ tep, e ¯p, eJu, Ra “ ptep, e ¯pu ˆ tep, e ¯puq Y txeJ, eJyu for a P G and
Ra “ tep, e ¯p, eJu ˆ teJu otherwise, and the pre- and postconditions are defined as
follows (see Figure 11):

– preep “ p, postep ppq “ 1
– pree ¯p “ ␣p, poste ¯p ppq “ 0
– preeJ “ J

As before, we also use E˚
Private raising awareness could be used to raise awareness of a single agent
when G “ tau, i.e. `taup. In that case, only agent a has her awareness of p raised,
and the other agents remain in the old state.

`Gp to denote the points of reference tep, e ¯pu.

Because the pre- and postconditions ‘coincide’ (that is, the valuation of the
postcondition verifies the precondition), we can draw the event model as in Fig-
ure 11, where written p inside an event e means that prepeq “ p and posteppq “ 1,
and J denotes pree “ J and posteppq is undefined for every p P P .

G

G

ep

p

G

␣p e ¯p

AzG

AzG

eJ

J

A

Fig. 11 The event model E`Gp for private raising awareness of p, `Gp.

After privately raising the awareness of p, a formula ϕ holds if ϕ holds at the
mappings xw, epy and xw, e ¯py in the product update, because the multi-pointed
event model is defined as xE`Gp, tep, e ¯puy. We also refer to this multi-pointed event
model by `Gp and the product update M b E`Gp as M`Gp. We do not require
this for eJ because this event only represents that the other agents do not observe
the event.

Like with public and private announcements, privately raising the awareness
of p for the group of all agents, G “ A, amounts to raising (public) awareness of
p.

Proposition 5 Given a pointed ParEAL model xM, wy, a proposition p and a
formula ϕ. Then M, w ( r`Apsϕ if and only if M, w ( r`psϕ and M, w ) r`Apsϕ
if and only if M, w ) r`psϕ.

28

Line van den Berg et al.

Proof The model M`Ap consists of two disconnected components: the first one
is exactly M`p, the result of taking the product update of M with the part of
E`Ap which is identical to E`p (i.e. the events ep and e ¯p and the relations between
them), and the second component is the result of taking the product update of M
with the single event eJ. The two components are disconnected because the edges
between them, holding for AzG, are empty when G “ A.

[only if ] Assume that M, w ( r`psϕ. Then @xw, ey P W `p s.t. e P E˚
`p:
M`p, xw, ey ( ϕ. But these worlds are exactly these worlds in the image of w
under `Ap that are used to determine satisfiability, and these worlds satisfy the
same formulas. Therefore M, w ( r`Apsϕ.

Similarly, assume that M, w ) r`psϕ. Then Dxw, ey P W `p s.t. e P E˚
`p:
M`p, xw, ey ) ϕ. But again, this world is also in the image of w under `Ap that is
used to determine satisfiability, and this world satisfies the same formulas. Hence
M, w ) r`Apsϕ.

[if ] We can reverse the reasoning above to show that M, w ( r`Apsϕ implies
M, w ( r`psϕ and M, w ) r`Apsϕ implies M, w ) r`psϕ because satisfiability
for `Ap is determined by the worlds xw, epy and xw, e ¯py in the image of w under
`Ap, because eJ R E˚
`Ap. And these worlds are also in the image of w under `p
and again, satisfy the same conditions. So whenever something holds for all these
worlds (for () or for at least one of the worlds ()) under `Ap, this must also be
the case for these worlds under `p.

Raising private awareness for the group of all agents, i.e. G “ A “ ta1, . . . , anu,
is not equivalent to privately raising awareness for agent a1, then a2, then a3, ...,
until an. I.e., `ta1up; . . . ; `tanup is not the same as `Gp. This is because in the
first case, neither agent observes that the other agents raise their awareness. Hence,
even though each agent becomes aware of p, this is not common information—but
this is the case for `Gp.

In Figure 12, an example is shown of applying the event model for raising

private awareness for a single agent.

a

pw

ep

b

p

b

b

¯p

e ¯p

b

b

a

a

“

v

eJ

J

a, b

M

a, b

E`tbup

pw, epq

p

b

p

pv, epq

b

b

a

b

¯p

a

b

a

p

pw, eJq

pv, e ¯pq

a

b

pv, eJq

M b E`tbup

a, b

Fig. 12 The event model of `tbup, E`tbup, applied to an epistemic model M, on the left. In
the product update (right), the aware cell ||pw, epq||a is indicated by a dotted box and the
aware cell ||pw, epq||b by a dashed box.

Raising Awareness without Disclosing Truth

29

7 Raising awareness without disclosing truth

By switching to partial valuations, raising awareness of a proposition p acts on
models by extending the valuation function in such a way that p and ␣p become
equally plausible for the agents. This implies that in our semantics, unlike previous
work on awareness where raising awareness also unveiled truth values [9, 14, 15, 18,
22], raising awareness does not disclose truth. This was illustrated in Figure 12 in
which agent b becomes aware of p without knowing the truth value of p, and agent
a does not change her mind. In this section, we provide a proof.

First, we consider the knowledge and beliefs of agents under raising awareness.

We prove that no new knowledge or belief is acquired:

– everything agents previously knew or believed, is still known and believed after

raising awareness (knowledge and belief preservation), and

– everything˚ known or believed after raising awareness, was already known or

believed before (knowledge and belief correspondence).

In the second clause, there is a catch. This holds only for formulas not including
the proposition awareness is raised of. Hence for p-free ϕ when the modality is `Gp.
This is for the obvious reason that tautologies involving p, for example p _ ␣p, or
formulas of the form p Ñ ϕ where ϕ was previously known or believed, will also
be known or believed after raising the awareness of p. The term ‘everything˚’ is
used to exclude these cases.

In fact, preservation and correspondence do not only apply to epistemic for-
mulas but also to non-epistemic formulas: truth is also preserved and corresponds
to the case of formulas not including the proposition awareness is raised of. This is
straightforward: raising awareness extends the valuation function with proposition
p but does not alter the valuation of other propositions. Therefore, formulas not
involving p keep their old truth value, and formulas involving p acquire a truth
value.

Proposition 6 (Truth preservation and correspondence) Let M be a ParEAL
model and let w be a world in M. Then for any group G Ď A and for any formula
ϕ:

M, w ( ϕ Ñ r`Gpsϕ

(truth preservation)

and for any ψ not containing p:

M, w ( r`Gpsψ Ñ ψ

(truth correspondence)

Proof For preservation, assume that M, w ( ϕ. Then, after raising the awareness
of p, for all xw, ey P W `Gp with e P E˚
xw,ey is either equal to Vw
(in case p P DompVwq) or extends it Vw by a valuation for proposition p (in case
p R DompVwq). In both cases, for all q P DompVwq: V `Gp
xw,eypqq “ Vwpqq. Therefore,
`Gp it holds that M`Gp, xw, ey ( ϕ, and thus
for all xw, ey P W `Gp with e P E˚
M, w ( r`Gpsϕ.

`Gp the valuation V `Gp

For correspondence, assume that M, w ( r`Gpsψ for some formula ψ not
containing p. This means that M`Gp, xw, ey ( ψ for all xw, ey P W `Gp with
e P E˚
xw,eypqq “ Vwpqq. Therefore,
it must also hold that M, w ( ψ.

`Gp. But since ψ did not contain p, for all q in ψ: V `Gp

30

Line van den Berg et al.

In the proof of Proposition 6, there is no distinction between propositional
formulas ϕ and non-propositional formulas ϕ, for example ϕ “ Kaψ, because
in both cases all the propositions q occurring in ϕ are evaluated at v. For the
non-propositional formulas, this is true because of the specification property for
valuations in ParEAL: this causes any propositions q occuring in ϕ such that Kaϕ,
even if ϕ “ Kbψ, to have a truth value at v. Then, the fact that raising awareness
does not alter the valuation of these propositions q completes the proof.

Furthermore, raising the awareness of p does not disclose the truth of p itself.
That is, whenever p was undefined (* p and + p), it is false that after awareness
is raised of p, p is true, and that p is false, i.e. ) r`Gpsp and ) r`Gps␣p.

Proposition 7 (Raising awareness without disclosing truth) Let M be a
ParEAL model and let w be a world in M. Then for any group G Ď A and any
proposition p:

If M, w * p and M, w + p then M, w ) r`Gpsp and M, w ) r`Gps␣p

Proof Whenever M, w * p and M, w + p, it means that p R DompVwq. Hence,
V `Gp
xw,epyppq “ 1 and V `Gp
xw,e ¯pyppq “ 0. Thus M`Gp, xw, epy ( p and M`Gp, xw, e ¯py ) p.
By satisfiability for ParDEL+, then M`Gp, xw, epy ) ␣p. Thus, since E˚
`Gp “
tep, e ¯pu, M, w ) r`Gpsp and M, w ) r`Gps␣p.

In conclusion, raising awareness does not disclose truth values nor add new
truths, other than the trivial cases (p _ ␣p or p Ñ ϕ, where ϕ was true before,
amongst others). This means that the raising awareness modalities introduced for
ParEAL truly disconnect awareness from truth.

8 Forgetting awareness

We have defined a novel way to capture awareness of agents directly in the model
structures using partial valuation functions and weakly reflexive relations. More-
over, we have introduced a dynamic modality for raising awareness on this seman-
tics. A natural question to ask is then: can we define a reverse modality? I.e. is
there a modality ´p for forgetting awareness?

Reverse modalities and operations have been studied throughout the history
of logic: the AGM model for belief revision considers expansion as well as contrac-
tion [1], temporal logics are defined in function of future and past modalities [36,37]
and in other work on awareness both raising and forgetting modalities have been
introduced [9,14,15,18]. Besides the theoretical motivation, there is also a practical
motivation to study forgetting coming from multi-agent systems. In such systems,
agents use different ontologies and alignments to represent their knowledge and
beliefs. During communication, they may encounter a counter-example to their
alignments that they revise accordingly [39, 40]. However, they do not need spe-
cific examples to communicate successfully, so they do not store them. In other
words, they forget the examples. Therefore, a logical modeling of such agents could
benefit from forgetting [10, 11].

At first sight, forgetting may be considered as the opposite of raising awareness,
reversing the models back to the initial situation before awareness was raised. Such

Raising Awareness without Disclosing Truth

31

an operation can easily be achieved by reducing the domain of the valuation func-
tion by the proposition that is forgotten of and merging worlds up to bisimilarity:
the proposition becomes undefined and hence, agents become unaware. This also
forces models on which the awareness of p is raised and then directly forgotten to
be bisimilar to the original situation, see Figure 13.

a

w

´p

`p

a

p

¯p

a

a

xw, 1y

xw, 0y

Fig. 13 Raising the awareness of p, `p, (left to right) and forgetting awareness of p, ´p, (right
to left), merging worlds up to bisimilarity. It holds that that M`p;´p and M are bisimilar.

We can also capture such a forgetting operation with event models for ParEAL,
by extending the definition of a postcondition in Definition 27 with an option that
we call K, as follows:

– post : E Ñ pP Ñ t0, 1, Kuq is a postcondition function assigning to each event

a partial function poste : P Ñ t0, 1, Ku.

Then, whenever for an event e P E and a proposition p P P it holds that
posteppq “ K, we “delete” the valuation of p in the product update. This means
that in Definition 28, we adjust the clause for the new valuation function as follows:

– V MbE

xw,ey ppq “

$
’&

’%

posteppq
undefined if posteppq “ K
Vwppq

otherwise

if posteppq “ 1 or posteppq “ 0

The event model for forgetting the awareness of a proposition p would then

consist of a single event with precondition J and postcondition postppq “ K:

A

J
postppq “ K

However, unlike raising awareness, this type of forgetting cannot be performed
independently of forgetting truth. Recall that when raising their awareness, agents
come to consider equally possible that a proposition is true and false—hence, they
do not acquire any knowledge or belief about it. In contrast, when forgetting their
awareness, agents also forget truth values (because they are no longer aware of a

32

Line van den Berg et al.

proposition, they do not know whether it is true or not)—and hence, whatever
was known or believed about it, is lost. This means that forgetting is not a true
inverse operation of raising awareness, but more the reverse of raising awareness
followed by an announcement of the proposition or its negation.

Yet, we may still study this forgetting modality, ´p. For example, to investigate
what happens if the proposition whose awareness is forgotten was used as evidence
for another proposition. Consider the consecutive upgrade `p; `q; !pp Ñ qq; !p; ´p,
where awareness of p and then of q is raised, a relation between the two propositions
(p Ñ q) is established, p is announced and finally p is forgotten again. When ´p
is applied, the truth value of q remains untouched: q will still be true even though
its justification, p, is removed. But when we forget p, should we not also forget the
conclusion q?

There are two options. Either we can keep the conclusion q and view forgetting
as a generalization or abstraction modality getting rid of the evidence but keeping
the conclusions, or we can discard the conclusions as well to arrive back at the
original state (unless, of course, the conclusions are supported independently from
p—in the example before, if we have both p Ñ q, r Ñ q and r, we can still deduce
q when forgetting p). For both options, there are arguments: for full logical agents,
forgetting evidence should imply to forget its conclusions since the deductions that
led to them can no longer be repeated, whereas for non-logical agents, it may not
be necessary to keep all evidence that led them to certain conclusions because
these conclusions alone may be sufficient for them to communicate successfully,
like in [20, 21]. Therefore this form of forgetting could benefit a formal model of
non-logical agents [10, 11].

A definitive answer about the different views on forgetting is beyond the scope

of this paper, but awareness does provide a starting point for the discussion.

9 Conclusion

We have introduced a new semantics for agent awareness using partial valuation
functions and weakly reflexive relations. This semantics allows agents to use dif-
ferent signatures to describe their knowledge and beliefs that other agents may be
unaware of. Whenever agents communicate, what they learn is described by two
steps: (1) raising their awareness of the propositions they hear, and (2) learning
the truth values of these propositions in the form of knowledge or belief through
announcements, radical and conservative upgrades. Unlike other approaches to ex-
tend DEL with agent awareness, our work completely disconnects awareness from
truth: awareness is raised without affecting the knowledge and beliefs of agents.

As a consequence of this two-step approach to learning ((1) raising awareness
and (2) learning truth), models are able to truly dynamically evolve: any future
evolution of agents’ knowledge, belief and awareness is not bound by the initial
state. In contrast, in DEL, any evolution was bound and agents can only learn by
restricting their possibilities: eliminating worlds or reorganizing them in a different
way with respect to the plausibility relations. These features are also available
in our framework, as the dynamic upgrades from DEL remain, but now worlds
may see their scope increasing through raising awareness. This open approach
to modeling the evolution of agents’ epistemic states is desirable for dynamic and

Raising Awareness without Disclosing Truth

33

open multi-agent systems where agents are required to continuously adapt to their
environment or to information learned from other agents [2, 20, 21].

The effect of dropping reflexivity to capture agent awareness and unawareness
also opens the door for interpreting complex epistemic upgrades, in particular those
that involve a component of privacy. Private announcements have been introduced
for DEL in [3], however, they do not preserve the typical structure of DEL models:
reflexivity is lost in order to ensure privacy. As a solution, it has been suggested
that the only dynamic upgrades permitted are those that preserve the properties
of the DEL models [3]. This means that private announcements are no longer
permitted to be performed, let alone more complex dynamic upgrades involving
privacy. The work we present in this paper offers a different solution: by weakening
the properties of the models, i.e. replacing reflexivity by weak reflexivity, we do
not only provide a novel way to approach agent awareness, but also allow for more
complex upgrades involving privacy to be interpreted. To illustrate this, private
announcements do preserve weak reflexivity. As such, our framework can be seen
as a more general framework for modelling communication and knowledge or belief
change in multi-agent systems.

Dropping reflexivity also has a drawback: factivity no longer holds. However,
it still holds locally within the aware cells of agents. This corresponds to the weak
reflexivity condition required for the accessibility relations. As a result, knowl-
edge may be considered ‘intermediate’ between S5 (within aware cells) and KD45
(outside aware cells). It is an open question to what axiom such an intermediate
knowledge operator corresponds that formalizes weak reflexivity as a condition on
the models.

In DEL, reduction axioms are used to ‘reduce’ formulas with dynamics, such
as announcements, to a formula without dynamics recursively. This is used to
reduce expressivity, soundness and completeness to the case of modal logic. In
our framework, these reduction axioms do not translate directly. This is because
preconditions are used in a different way: they are used to select worlds that
“do not falsify the precondition”, i.e. they either verify the precondition, or the
precondition is undefined. Since undefinedness cannot be captured in our language,
this complicates reducing formulas with raising awareness modalities to formulas
without them. A three-valued approach may be useful for this purpose and could
be used to define an axiomatization of our logic.

This work can be extended to investigate a dual-operator for raising aware-
ness: forgetting. The discussion whether forgetting should serve as an abstraction
operator, which experiments have shown does not negatively affect communica-
tion between adaptive agents [20, 21], or should function more truthful to logical
agents could be a starting point for this purpose. Furthermore, another notion of
forgetting may be considered that preserves awareness while deleting the truth of
propositions. Such a forgetting modality would cause agents to unlearn what they
knew or believed, while their awareness is unaffected.

ParDEL+ is an extension of DEL in the sense that if all agents were aware
of the same propositions and would not use raising awareness, the logics would
coincide. In addition, with ParDEL+ one can consider situations starting from no
awareness and raising agent awareness progressively to reach a DEL state. Hence,
DEL with public signature awareness may be considered as the limit of ParDEL+
restricted to raising only the DEL signature. Yet, it may not be strictly necessary

34

Line van den Berg et al.

to reach full signature awareness for agents to communicate satisfactorily with each
other: they only need to be aware of the subsignatures of other agents that occur
in their communication. It would be worth investigating this relation further.

Acknowledgements This work has been partially supported by MIAI @ Grenoble Alpes
(ANR-19-P3IA-0003).

Conflict of interest

The authors declare that they have no conflict of interest.

References

1. Alchourr´on, C.E., G¨ardenfors, P., Makinson, D.: On the logic of theory change: Partial
meet contraction and revision functions. The Journal of Symbolic Logic 50(2), 510–530
(1985)

2. Atencia, M., Schorlemmer, W.M.: An interaction-based approach to semantic alignment.

J. Web Semant. 12, 131–147 (2012). DOI 10.1016/j.websem.2011.12.001

3. Baltag, A., Moss, L.S., Solecki, S.: The logic of public announcements and common knowl-
edge and private suspicions. In: Proceedings of the 7th Conference on Theoretical Aspects
of Rationality and Knowledge, Evanston, USA, 1998, pp. 43–56 (1998)

4. Baltag, A., Smets, S.: Dynamic belief revision over multi-agent plausibility models. In:
Proceedings of the 2016 conference on Logic and the Foundations of Game and Decision
Theory, vol. 6, pp. 11–24. University of Liverpool (2006)

5. Baltag, A., Smets, S.: Group belief dynamics under iterated revision: fixed points and
cycles of joint upgrades. In: Proceedings of the 12th Conference on Theoretical Aspects
of Rationality and Knowledge, pp. 41–50. ACM (2009)

6. van Benthem, J.: Dynamic logic for belief revision. Journal of Applied Non-Classical Logics

17(2), 129–155 (2007). DOI 10.3166/jancl.17.129-155

7. van Benthem, J.: Logical dynamics of information and interaction. Cambridge University

Press (2011)

8. van Benthem, J., van Eijck, J., Kooi, B.: Logics of communication and change. Information

and Computation 204(11), 1620–1662 (2006)

9. van Benthem, J., Vel´azquez-Quesada, F.R.: The dynamics of awareness. Synthese 177(1),

5–27 (2010)

10. van den Berg, L.: Cultural knowledge evolution in dynamic epistemic logic. Ph.D. thesis,

University of Grenoble (2021)

11. van den Berg, L., Atencia, M., Euzenat, J.: A logical model for the ontology alignment

repair game. Autonomous Agents and Multi-Agent Systems 35(2), 1–34 (2021)

12. Blackburn, P., De Rijke, M., Venema, Y.: Modal Logic. Cambridge Tracts in Theoretical
Computer Science. Cambridge University Press (2001). DOI 10.1017/CBO9781107050884

13. Brouwer, L.E.J.: Over de grondslagen der wiskunde. Maas & van Suchtelen (1907)
14. van Ditmarsch, H., French, T.: Awareness and forgetting of facts and agents. In: 2009
IEEE/WIC/ACM International Joint Conference on Web Intelligence and Intelligent
Agent Technology, vol. 3, pp. 478–483. IEEE (2009)

15. van Ditmarsch, H., French, T.: Becoming aware of propositional variables.
Conference on Logic and Its Applications, pp. 204–218. Springer (2011)

In: Indian

16. van Ditmarsch, H., French, T., Vel´azquez-Quesada, F.R.: Action models for knowledge and
awareness. In: Proceedings of the 2012 International Conference on Autonomous Agents
and Multi-Agent Systems, pp. 1091–1098 (2012)

17. van Ditmarsch, H., French, T., Vel´azquez-Quesada, F.R., W´ang, Y.N.: Knowledge, aware-

ness, and bisimulation. arXiv preprint arXiv:1310.6410 (2013)

18. van Ditmarsch, H., Herzig, A., Lang, J., Marquis, P.: Introspective forgetting. Synthese

169(2), 405–423 (2009)

19. van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic Epistemic Logic, vol. 337.

Springer Science & Business Media (2007)

Raising Awareness without Disclosing Truth

35

20. Euzenat, J.: First experiments in cultural alignment repair (extended version). In: The
Semantic Web: ESWC 2014 Satellite Events - ESWC 2014 Satellite Events, Anissaras,
Crete, Greece, May 25-29, 2014, Revised Selected Papers, pp. 115–130 (2014). DOI
10.1007/978-3-319-11955-7z 10

21. Euzenat, J.: Interaction-based ontology alignment repair with expansion and relaxation.
In: Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelli-
gence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017, pp. 185–191 (2017). DOI
10.24963/ijcai.2017/27

22. Fagin, R., Halpern, J.Y.: Belief, awareness, and limited reasoning. Artificial Intelligence

34(1), 39–76 (1987)

23. Fagin, R., Moses, Y., Halpern, J.Y., Vardi, M.Y.: Reasoning about knowledge. MIT press

(2003)

24. G¨ardenfors, P., Rott, H., Gabbay, D., Hogger, C., Robinson, J.: Belief revision. Compu-

tational Complexity 63(6), 35–132 (1995)

25. Halpern, J.Y.: Alternative semantics for unawareness. Games and Economic Behavior

37(2), 321–339 (2001)

26. Halpern, J.Y., Rˆego, L.C.: Reasoning about knowledge of unawareness. Games and Eco-

nomic Behavior 67(2), 503–525 (2009)

27. Hansen, J.U.: Modeling truly dynamic epistemic scenarios in a partial version of del. The

Logica Yearbook 2013 pp. 63–75 (2014)

28. Heifetz, A., Meier, M., Schipper, B.C.: Interactive unawareness. Journal of economic theory

130(1), 78–94 (2006)

29. Hill, B.: Awareness dynamics. Journal of Philosophical Logic 39(2), 113–137 (2010)
30. Hintikka, J.: Knowledge and belief: An introduction to the logic of the two notions. Studia

Logica 16 (1962)

31. van der Hoek, W., Jaspars, J., Thijsse, E.: Honesty in partial logic. Studia Logica 56(3),

323–360 (1996)

32. Jaspars, J., Thijsse, E.: Fundamentals of partial modal logic. Studies in Logic Language

and Information (1996)

33. Kleene, S.C.: Introduction to metamathematics (1952)
34. Modica, S., Rustichini, A.: Awareness and partitional informational structures. In: Epis-
temic Logic and the Theory of Games and Decisions, pp. 151–168. Springer (1997)

35. Plaza, J.: Logic of public communications.

In: Z.W. Ras (ed.) Proceedings of the 4th
International Symposium on Methodologies for Intelligent Systems, pp. 201–216. North-
Holland (1989)

36. Prior, A.: Time and modality. Revue Philosophique de la France Et de l 148 (1957)
37. Prior, A.: Past, present and future. Revue Philosophique de la France Et de l 157 (1967)
38. Rott, H.: Conditionals and theory change: Revisions, expansions, and additions. Synthese

81(1), 91–113 (1989)

39. Shvaiko, P., Euzenat, J.: Ontology matching: state of the art and future challenges. IEEE

Transactions on Knowledge and Data Engineering 25(1), 158–176 (2013)

40. Tamma, V., Cranefield, S., Finin, T.W., Willmott, S.: Ontologies for agents: Theory and

experiences. Springer Science & Business Media (2005)

41. Thijsse, E.: Partial logic and knowledge representation (1994)
42. Veltman, F.: Defaults in update semantics. Journal of philosophical logic 25(3), 221–261

(1996)

