Summarizing Semantic Graphs: A Survey
Sejla Cebiric, François Goasdoué, Haridimos Kondylakis, Dimitris Kotzinos,

Ioana Manolescu, Georgia Troullinou, Mussab Zneika

To cite this version:

Sejla Cebiric, François Goasdoué, Haridimos Kondylakis, Dimitris Kotzinos, Ioana Manolescu, et al..
Summarizing Semantic Graphs: A Survey. The VLDB Journal, 2019, 28 (3). ￿hal-01925496￿

HAL Id: hal-01925496

https://inria.hal.science/hal-01925496

Submitted on 16 Nov 2018

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Summarizing Semantic Graphs: A Survey

ˇSejla ˇCebiri´c1

Fran¸cois Goasdou´e2

Haridimos Kondylakis3

Dimitris Kotzinos4

Ioana Manolescu1

Georgia Troullinou3

Mussab Zneika4
1Inria and LIX (UMR 7161, CNRS and Ecole polytechnique), France 2U. Rennes, Inria, CNRS, IRISA, France

3ICS-FORTH, Greece

4ETIS, UMR 8051, U. Cergy-Pontoise, ENSEA, CNRS, France

November 15, 2018

Abstract

1

Introduction

The explosion in the amount of the available RDF
data has lead to the need to explore, query and un-
derstand such data sources. Due to the complex
structure of RDF graphs and their heterogeneity,
the exploration and understanding tasks are signiﬁ-
cantly harder than in relational databases, where the
schema can serve as a ﬁrst step toward understand-
ing the structure. Summarization has been applied
to RDF data to facilitate these tasks. Its purpose is
to extract concise and meaningful information from
RDF knowledge bases, representing their content as
faithfully as possible. There is no single concept of
RDF summary, and not a single but many approaches
to build such summaries; each is better suited for
some uses, and each presents speciﬁc challenges with
respect to its construction. This survey is the ﬁrst
to provide a comprehensive survey of summarization
method for semantic RDF graphs. We propose a tax-
onomy of existing works in this area, including also
some closely related works developed prior to the
adoption of RDF in the data management commu-
nity; we present the concepts at the core of each ap-
proach and outline their main technical aspects and
implementation. We hope the survey will help read-
ers understand this scientiﬁcally rich area, and iden-
tify the most pertinent summarization method for a
variety of usage scenarios.

Semantic languages and models are increasingly used
in order to describe, represent and exchange data
in multiple domains and forms. In particular, given
the prominence of the World Wide Web Consortium
(W3C)1 in the international technological arena, its
standard model for representing semantic graphs,
namely RDF, has been widely adopted. Many RDF
Knowledge Bases (KBs, in short) of millions or even
billions of triples are now shared through the Web,
also thanks to the development of the Open Data
movement, which has evolved jointly with the data
linking best practices based on RDF. A famous repos-
itory of open RDF graphs is the Linked Open Data
cloud, currently referencing more than 62 billion RDF
triples, organized in large and complex RDF data
graphs [88]. Further, several RDF graphs are con-
ceptually linked together into one, as soon as a node
identiﬁer appears in several graphs. This enables
querying KBs together, and increases the need to un-
derstand the basic properties of each data source be-
fore ﬁguring out how they can be exploited together.
The fundamental diﬃculty toward understanding
an RDF graph is its lack of a standard structure (or
schema), as RDF graphs can be very heterogeneous
and the basic RDF standard does not give means to
constrain graph structure in any way. Ontologies can
(but do not have to) be used in conjunction to RDF

1http://www.w3.org

1

data graphs, in order to give them more meaning,
notably by describing the possible classes resources
may have, their properties, as well as relationships
between these classes and properties. On one hand,
ontologies do provide an extra entry point into the
data, as they allow to grasp its conceptual structure.
On the other hand, they are sometimes absent, and
when present, they can be themselves quite complex,
growing up to hundreds or thousands of concepts;
SNOMED-CT2, a large medical ontology, comprises
millions of terms.

To cope with these layers of complexity, RDF
graph summarization has aimed at extracting con-
cise but meaningful overviews from RDF KBs, repre-
senting as close as possible the actual contents of the
KB. RDF summarization has been used in multiple
application scenarios, such as:
identifying the most
important nodes, query answering and optimization,
schema discovery from the data, or source selection,
and graph visualization to get a quick understand-
ing of the data.
It should be noted that indexing,
query optimization and query evaluation were stud-
ied as standalone problems in the data management
areas, before the focus went to semantic RDF graphs;
therefore, several summarization methods initially
studied for data graphs were later adapted to RDF.
Among the currently known RDF summarization ap-
proaches, some only consider the graph data without
the ontology, some others consider only the ontology,
ﬁnally some use a mix of the two. Summarization
methods rely on a large variety of concepts and tools,
comprising structural graph characteristics, statis-
tics, pattern mining or a mix thereof. Summarization
methods also diﬀer in their usage scope. Some sum-
marize an RDF graph into a smaller one, allowing
some RDF processing (e.g., query answering) to be
applied on the summary (also). The output of other
summarization methods is a set of rules, or a set of
frequent patterns, an ontology etc.

Summarizing semantic graphs is a multifaceted
problem with many dimensions, and thus many algo-
rithms, methods and approaches have been developed
to cope with it. As a result, there is now a confusion
in the research community about the terminology in

2https://www.snomed.org/snomed-ct

the area, further increased by the fact that certain
terms are often used with diﬀerent meanings in the
relevant literature, denoting similar, but not identical
research directions or concepts. We believe that this
lack of terminology and classiﬁcation hinders scien-
tiﬁc development in this area.

To improve understanding of this ﬁeld and to help
students, researchers or practitioners seeking to iden-
tify the summarization algorithm, method or tool
best suited for a speciﬁc problem, this survey at-
tempts to provide a ﬁrst systematic organization of
knowledge in this area. We propose a taxonomy of
RDF (and most representative, prior graph) summa-
rization approaches. Then, we classify existing works
according to the main class of algorithmic notions
they are based on; further, for each work, we specify
their accepted inputs, outputs, and when a tool is
publicly available, we provide the reference to it. We
place each of the works in the space deﬁned by the
dimensions of our classiﬁcation; we summarize their
main concepts and compare them when appropriate.
Since our focus is on RDF graph summarization
techniques, we leave out of our scope graph sum-
marization techniques tailored for other classes of
graphs, e.g., biological data graphs [90], social net-
works [57] etc. We focus on techniques that have
either been speciﬁcally devised for RDF, or adapted
to the task of summarizing RDF graphs. The litera-
ture comprises surveys on generic (non-RDF) graph
summarization, and/or partial surveys related to our
area of study. The authors of [113] present generic
graph summarization approaches, with a main focus
on grouping-based methods. A recent survey [59] has
a larger focus than ours. It considers static graphs as
well as graphs changing over time; graphs which are
just connection networks (node and edge labels are
non-existent or ignored), but also labeled directed or
undirected graphs, which can be seen as simple sub-
sets of RDF. Also, a recent tutorial [40] covers a sim-
ilar set of topics. However, given their broad scope,
these works describe areas of work we are not con-
cerned with, such as social (network) graph summa-
rization, and ignore many of the proposals speciﬁcally
tailored for RDF graphs, which are labeled, oriented,
heterogeneous, and may be endowed with type infor-
mation and semantics. In contrast, our survey seeks

2

2.1 Labeled directed graphs:

core

concepts

Labeled directed graphs are the core concept allowing
to model RDF datasets. Further, most (not all) pro-
posals for summarizing an RDF graph also model the
summary as a directed graph. Thus, without loss of
generality, we will base our discussion on this model.
Note that it can be easily generalized to more com-
plex graphs, e.g., those with (multi-)labeled nodes.

Given a set A of labels, we denote by G = (V, E)
an A-edge labeled directed graph whose vertices are
V , and whose edges are E ⊆ V × A × V .

Figure 1 displays two such graphs; A edge la-
bels are attached to edges. Node labels will be
used/explained shortly in our discussion.

to answer a need we encountered among many Se-
mantic Web practitioners, for a comprehensive review
of summarization techniques tailored exactly to such
graphs. Another recent work [80] focuses on metrics
used for ontology summarization only, whereas we
consider both RDF graphs and their ontologies.

Our survey is structured as follows: Section 2 re-
calls the foundations of the RDF data model, and
RDF Schema (RDFS, in short), the simplest ontology
language which can be used in conjunction with RDF
to specify semantics for its data. Section 3 describes
RDF summarization scope, applications and dimen-
In Section 4, we
sions of analysis for this survey.
classify along these dimensions a selection of the main
graph summarization works which preceded works on
RDF summarization. We include a short discussion
of these works here, as they were the ﬁrst to intro-
duce a set of concepts crucial for summarization, and
on which RDF-speciﬁc summaries have built. In the
sequel of the survey, Sections 5, 6, 7 and 8 analyze
the related works in each category. Finally, Section 9
concludes this paper and identiﬁes ﬁelds of future ex-
ploration.

2 Preliminaries: RDF graphs

Figure 1: Sample edge-labeled directed graphs

We recall here the core concepts and notations related
to RDF graphs. At a ﬁrst glance, these can be con-
sidered particular cases of labeled, oriented graphs,
and indeed classical graph summarization techniques
have been directly adapted to RDF; we recall them
in Section 2.1. Then, we present RDF graphs in Sec-
tion 2.2, where we introduce the terminology and spe-
ciﬁc constraints which make up the RDF standard,
established by the W3C; we also introduce here on-
tologies, which play a central role in most RDF ap-
plications, with a focus on the simple RDF Schema
ontology language. From a database perspective,
the most common usage of RDF graphs is through
queries; therefore, we recall the Basic Graph Pattern
(BGP) dialect at the core of the SPARQL RDF query
language in Section 2.3. Finally, a brief discussion of
more expressive ontology languages, sometimes used
in conjunction with RDF graphs, is provided in Sec-
tion 2.4.

In addition, the notions of graph homomorphism
and graph isomorphism frequently appear in graph
summary proposals:

Deﬁnition 1 (Homomorphism and isomorphism)
Let G = (V, E) and G(cid:48) = (V (cid:48), E(cid:48)) be two A-edge
labeled directed graphs. A function φ : V → V (cid:48) is
a homomorphism from G to G(cid:48) iﬀ for every edge
(v1, l, v2) ∈ E there is an edge (φ(v1), l, φ(v2) ∈ G(cid:48).
If, moreover, φ is a bijection, and its inverse φ−1 is
also a homomorphism from G(cid:48) into G, then φ is an
isomorphism.

A homomorphism from G to G(cid:48) ensures that the
graph structure present in G has an ”image” into G(cid:48).
For our discussion, this is interesting in three diﬀerent
settings:

1. If G is a data graph and G(cid:48) is a summary graph
representing G, a homomorphism from G to G(cid:48)

3

ensures that every subgraph of G has an image
in G(cid:48).

2. Conversely, a homomorphism from a summary
graph G(cid:48) into the data graph G means that all
the graph structures present in the summary also
appear in the data graph.

3. If Q is a graph query, e.g., expressed in SPARQL,
and G is a data graph, e.g., an RDF graph, the
answer to Q on G, denoted Q(G), is exactly de-
ﬁned through the set of homomorphisms which
may be established from G to G(cid:48). Together with
the two items above, this leads to several inter-
esting relationships between queries, data graphs
and their summaries, in particular allowing to
use the summary to gain some knowledge about
Q(G) without actually evaluating it.

Observe that while homomorphisms between a
graph and its summary have useful properties, an
isomorphism would defeat the purpose of summariza-
tion, as two isomorphic graphs would have the same
size.

In Figure 1, the graph shown on the right is homo-
morphic to that on the left. Indeed, a homomorphism
maps each node from the graph at left into the right
graph node whose label contains its number.

Notations: node and edge counts Throughout
this survey, unless otherwise speciﬁed, N denotes the
number of nodes and M the number of edges of a di-
rected graph input to some summarization approach.

2.2 The Resource Description Frame-

work (RDF)

Our study of graph summarization techniques is cen-
trally motivated by their interest when summarizing
RDF graphs. RDF is the standard data model pro-
moted by the W3C for Semantic Web applications.

RDF graph. An RDF graph (in short a graph) is
a set of triples of the form (s, p, o). A triple states
that a subject s has the property p, and the value of
that property is the object o. We consider only well-
formed triples, as per the RDF speciﬁcation [107],

Assertion
Class
Property

Triple
(s, rdf:type, o)
(s, p, o)

Relational notation
o(s)
p(s, o)

Constraint
Subclass
Subproperty
Domain typing
Range typing

Triple
(s, ≺sc, o)
(s, ≺sp, o)
(p, ←(cid:45)d, o)
(p, (cid:44)→r, o)

OWA interpretation
s ⊆ o
s ⊆ o
Πdomain(s) ⊆ o
Πrange(s) ⊆ o

Figure 2: RDF (top) & RDFS (bottom) statements.

belonging to (U ∪ B) × U × (U ∪ B ∪ L) where U
is a set of Uniform Resource Identiﬁers (URIs), L
a set of typed or untyped literals (constants), and
B a set of blank nodes (unknown URIs or literals);
U, B, L are pairwise disjoint. Blank nodes are essen-
tial features of RDF allowing to support unknown
URI/literal tokens. These are conceptually similar to
the labeled nulls or variables used in incomplete re-
lational databases [1], as shown in [27]. As described
above, it is easy to see that any RDF graph is a la-
beled graph as described in Section 2.1. However, as
we explain below, RDF graphs may contain an ontol-
ogy, that is, a set of graph edges to which standard
ontology languages attach a special interpretation.
The presence of ontologies raises speciﬁc challenges
when summarizing RDF graphs, which do not occur
when only plain data graphs are considered.

Notations. We use s, p, and o as placehold-
ers for subjects, properties and objects, respec-
tively. Literals are shown as strings between quotes,
e.g., “string”. Fig. 2 (top) shows how to use triples to
describe resources, that is, to express class (unary re-
lation) and property (binary relation) assertions. The
RDF standard [107] has a set of built-in classes and
properties, as part of the rdf: and rdfs: pre-deﬁned
namespaces. We use these namespaces exactly for
these classes and properties, e.g., rdf:type speciﬁes
the class(es) to which a resource belongs. For brevity,
we will sometimes use τ to denote rdf:type.

Example 1 (RDF graph) For example,
the fol-
lowing RDF graph G describes a book, identiﬁed by
doi1, its author (a blank node :b1 whose name is

4

known), title and date of publication:

G =

{(doi1, rdf:type, Book), (doi1, writtenBy, :b1),
(doi1, hasTitle, “Le Port des Brumes”),
( :b1, hasName, “G. Simenon”),
(doi1, publishedIn, “1932”)}

RDF Schema (RDFS). RDFS allows enhancing
the assertions made in an RDF graph with the use
of an ontology, i.e., by declaring semantic constraints
between the classes and the properties they use. Fig.
2 (bottom) shows the four main kinds of RDFS con-
straints, and how to express them through triples
hence particular graph edges. For concision, we de-
note the properties expressing subclass, subproperty,
domain and range constraints by the symbols ≺sc,
≺sp, ←(cid:45)d and (cid:44)→r, respectively. Here, “domain” de-
notes the ﬁrst, and “range” the second attribute of
every property.

The RDFS constraints depicted in Fig. 2 are inter-
preted under the open-world assumption (OWA) [1],
if
i.e., as deductive constraints.
the triple (hasFriend, ←(cid:45)d, Person) and the triple
(Anne, hasFriend, Marie) hold in the graph, then so
does the triple (Anne, τ, Person). The latter is due to
the domain constraint in Fig. 2.

For instance,

Example 2 (RDF graph with an RDFS ontology)
Assume that
the RDF graph G in the preced-
ing
example
extended with the RDFS on-
is
(Book, ≺sc, Publication),
tological
constraints:
(writtenBy, ≺sp, hasAuthor), (writtenBy, ←(cid:45)d, Book)
and (writtenBy, (cid:44)→r, Person). The resulting graph
is depicted in Fig. 3.
Its implicit triples are those
represented by dashed-line edges.

RDF entailment. An important feature of RDF
graphs are implicit triples. Crucially, these are con-
sidered part of the RDF graph even though they
are not explicitly present in it, e.g., the dashed-line
G edges in Fig. 3, hence require attention for RDF
graph summarization.

W3C names RDF entailment

the mechanism
through which, based on a set of explicit triples and
some entailment rules, implicit RDF triples are de-
rived. We denote by (cid:96)i
RDF immediate entailment,

Publication

rdfs:domain

hasAuthor

rdfs:subClassOf

rdfs:subPropertyOf

“1932”

rdf:type

Book

rdfs:domain

writtenBy

publishedIn

rdf:type

rdfs:range

doi1

hasTitle

writtenBy
hasAuthor

:b1

rdf:type

Person

hasName

“Le Port des Brumes”

“G. Simenon”

Figure 3: RDF graph and its implicit triples.

i.e., the process of deriving new triples through a sin-
gle application of an entailment rule. More generally,
a triple (s, p, o) is entailed by a graph G, denoted
G (cid:96)RDF (s, p, o), if and only if there is a sequence of
applications of immediate entailment rules that leads
from G to (s, p, o) (where at each step, triples previ-
ously entailed are also taken into account).

Saturation. The immediate entailment rules allow
deﬁning the ﬁnite saturation (a.k.a. closure) of an
RDF graph G, which is the RDF graph G∞ deﬁned
as the ﬁxed-point obtained by repeatedly applying
(cid:96)i

RDF rules on G.
The saturation of an RDF graph is unique (up
to blank node renaming), and does not contain im-
plicit triples (they have all been made explicit by
saturation). An obvious connection holds between
the triples entailed by a graph G and its saturation:
G (cid:96)RDF (s, p, o) if and only if (s, p, o) ∈ G∞.

RDF entailment is part of the RDF standard itself;
in particular, the answers to a query posed on G must
take into account all triples in G∞ [110], since in the
presence of RDF Schema constraints, the semantics
of an RDF graph is its saturation [107]. As a result,
the summarization of an RDF graph should reﬂect
its saturation, e.g., by summarizing the saturation of
the graph instead of the graph itself.

Example 3 (RDF entailment and saturation)
The saturation of the RDF graph comprising RDFS
constraints G, displayed in Fig. 3, is the graph G∞
obtained by adding to G all its implicit triples that
i.e., the
can be derived through RDF entailment,

5

graph G in which the implicit/dashed edges are made
explicit/solid ones.

We introduce below a few more notions we will
need in order to describe existing RDF summariza-
tion proposals.

Instance and schema graph. An RDF instance
graph is made of assertions only (recall Fig. 2), while
an RDF schema graph is made of constraints only
(i.e., it is an ontology). Further, an RDF graph can
be partitioned into its (disjoint) instance and schema
subgraphs.

Properties and attributes of an RDF graph.
While this is not part of the W3C standard, some
authors use attribute to denote a property (other than
those built in the RDF and RDFS standards, such
as τ , ←(cid:45)d etc.) of an RDF resource such that the
property value is a literal. In these works, the term
property is reserved for those RDF properties whose
value is an URI.

In the following we use the conjunctive
Notations.
query notation Q(¯x):- t1, . . . , tα, where {t1, . . . , tα} is
a BGP. The head of Q is Q(¯x), and the body of Q
is t1, . . . , tα. The query head variables ¯x are called
distinguished variables, and are a subset of the vari-
ables occurring in t1, . . . , tα; for boolean queries ¯x is
empty. We denote by VarBl(Q) the set of variables
and blank nodes occurring in the query Q.
In the
sequel, we will use x, y, z, etc. to denote variables in
queries.

evaluation. Given

Query
query
Q(¯x):- t1, . . . , tα and an RDF graph G, the evaluation
of Q against G is:

a

Q(G) = {Φ(¯x) | Φ : VarBl(Q) → Val(G) is a Q to G
homomorphism such that {Φ(t1), . . . , Φ(tα)} ⊆ G}

where we denote by Φ(t) (resp. Φ(¯x)) the result of
replacing every occurrence of a variable or blank node
e ∈ VarBl(Q) in the triple t (resp. the distinguished
variables ¯x), by the value Φ(e) ∈ Val(G).

Example 4 (Instance, schema, properties and attributes of an RDF graph)
The RDF graph G shown in Fig. 3 consists of the
RDF schema graph comprising the blue triples, and
of the RDF instance graph comprising the black
triples. Further, within this G instance subgraph,
the properties considered attributes are the following:
publishedIn, hasTitle and hasName.

Query answering. The evaluation of Q against G
uses only G’s explicit triples, thus may lead to an
incomplete answer set. The (complete) answer set
of Q against G is obtained by the evaluation of Q
against G∞, denoted by Q(G∞).

Example 5 (Query evaluation versus answering)
The query below asks for the author’s name of “Le
Port des Brumes”:

2.3 BGP queries

SPARQL3 is the standard W3C query langage used
to query RDF graphs. We consider its popular con-
junctive fragment consisting of Basic Graph Pattern
(BGP) queries. Subject of several recent works [27,
95, 26, 78, 9], BGP queries are also the most widely
used in real-world applications [78, 53]. A BGP is
a generalization of an RDF graph in which variables
may also appear as subject, property and object of
triples.

3https://www.w3.org/TR/rdf-sparql-query/

Q(x3):- (x1, hasAuthor, x2), (x2, hasName, x3)
(x1, hasTitle, “Le Port des Brumes”)

Its answer against the explicit and implicit triples
of our sample graph is: Q(G∞) = {(cid:104)“G. Simenon”(cid:105)}.
Note that evaluating Q only against G leads to the

empty answer, which is obviously incomplete.

2.4 OWL

Semantic graphs considered in the literature for sum-
marization sometimes go beyond the expressiveness
of RDF, which comes with the simple RDF Schema

6

ontology language. The standard by W3C for seman-
tic graphs is the OWL [108, 109] family of dialects
that builds on Description Logics (DLs) [4].

presenting several dimensions along which the cor-
responding RDF summarization techniques can be
classiﬁed (Section 3.3).

DLs are ﬁrst-order logic languages that allow de-
scribing a certain application domain by means of
concepts, denoting sets of objects, and roles, denoting
binary relations between concept instances. DL di-
alects diﬀer in the ontological constraints they allow
expressing on complex concepts and roles, i.e., de-
ﬁned by DL formula. One of the most important is-
sues in DLs is the trade-oﬀ between expressive power
and computational complexity of reasoning with the
constraints (consistency checking, query answering,
etc.)

The ﬁrst ﬂavour of OWL [108] consists of three di-
alects of increasing complexity: OWL-Lite, OWL-DL
and OWL-Full. Unfortunately, very basic reasoning
(concept satisﬁability) in these dialects is highly in-
tractable: ExpTime-complete in OWL-lite that cor-
responds to the SHIF D DL, NExpTime-complete
in OWL-DL that corresponds to the SHION D DL,
and even undecidable in OWL-full. A second ﬂavour
of OWL [109], a.k.a. OWL2, deﬁnes three new di-
alects, OWL2 EL based on the EL DL, OWL2 QL
based on the DL-liteR DL and OWL2 RL which can
be expressed using logical rules. These new dialects
comes with PTIME complexity for most of the rea-
soning tasks. In particular, data management tasks
(consistency checking, query answering, etc.) un-
der OWL2 QL/DL-liteR ontologies have the same
complexity as their counterparts in the relational
database model [10].

3.1 Scope

Our goal in this survey is to study summarization
notions and tools which are useful to concrete RDF
data management applications. We will thus dis-
cuss a broad set of techniques, some of which are
also used outside our target RDF data management
contexts. However, to keep the survey focused, self-
contained, and useful to RDF practitioners, we do not
cover graph summarization or clustering techniques
designed for very speciﬁc classes of graphs. For in-
stance, while social network graphs can be modeled
in RDF, such graphs have a very speciﬁc semantics,
for instance, to reﬂect the important role of “user”
nodes.
Instead, we aim to cover summarization of
general RDF graphs (without making assumptions
on their application domain), without ontologies (in
which case they basically coincide with labeled ori-
ented graphs) or with ontologies (that are a speciﬁc,
crucial feature of RDF data graphs).

Our review of the literature leads us to the follow-
ing generic deﬁnition. An RDF summary is one or
both among the following:

1. A compact information, extracted from the orig-
inal RDF graph; intuitively, summarization is a
way to extract meaning from data, while reduc-
ing its size;

3 RDF summarization: scope,
applications and dimensions
of analysis for this survey

2. A graph, which some applications can exploit in-
stead of the original RDF graph, to perform some
tasks more eﬃciently; in this vision, a summary
represents (or stands for) the graph in speciﬁc
settings.

As we shall see, RDF summarization has been at-
tached many diﬀerent meanings in the literature, and
research is still ongoing. Therefore, we start with de-
limiting the scope of RDF summarization as consid-
ered in this survey (Section 3.1), before describing
the RDF summary applications most frequently en-
countered within this scope (Section 3.2), and ﬁnally

Clearly, these notions intersect, e.g., many graph
summaries extracted from the RDF graphs are com-
pact and can be used for instance to make some query
optimization decisions; these ﬁt into both categories.
However, some RDF summaries are not graphs; some
(graph or non-graph) summaries are not always very
compact, yet they can be very useful etc.

7

3.2 Applications

We illustrate the above generic deﬁnition of an RDF
summary through a (non-exhaustive) list of uses
and applications.

Indexing. Most (RDF) summarization methods
from the literature build summaries which are smaller
graphs; each summary node represents several nodes
of the original graph G. This smaller graph, then,
serves as an index as follows. The identiﬁers of all the
G nodes represented by each summary node v are as-
sociated with the node v. To process a query on G, we
ﬁrstly identify the summary nodes, which may match
the query; then identify based on the index, the graph
nodes corresponding to these summary nodes, as a
ﬁrst step toward answering the query.

Estimating the size of query results. Consider
a summary deﬁned as a set of statistics about prop-
erty (edge label) co-occurrence in G, that is: the sum-
mary stores, for any two properties a, b appearing in
G, the number of nodes which have at least an outgo-
ing a edge and at least an outgoing b edge. If a query
searches, e.g., for resources having both a “descrip-
tion” and an “endorsement” in an RDF graph storing
product information, if the summary indicates that
there are no such resources, we can return an empty
query answer without consulting G. Further, assume
that a BGP query requires a resource with proper-
ties p1, p2, somehow connected to another resource
with properties p3, p4.
If the summary shows that
the former property combination is much rarer than
the latter, a query optimizer can exploit this to start
evaluating the query from the most selective condi-
tions p1, p2.

short and simple path queries are typically evaluated
very eﬃciently.

Source selection One can detect based on a sum-
mary whether a graph is likely to have a certain kind
of information that the user is looking for, without
actually consulting the graph. In a distributed query
processing setting, this can be used to know which
data partition(s) are helpful for a query; in a LOD
cloud querying context, when answering queries over
a large set of initially unknown data sources, this
problem is typically referred to as source selection.

Graph visualization A graph-shaped summary
may be used to support the users’ discovery and ex-
ploration of an RDF graph, helping them get ac-
quainted with the data and/or as a support for visual
querying.

Vocabulary usage analysis RDF is often used as
a mean to standardize the description of data from
a certain application domain, e.g., life sciences, Web
content metadata etc. A standardization commit-
tee typically works to design a vocabulary (or set of
standard data properties) and/or an ontology; appli-
cation designers learn the vocabulary and ontology
and describe their data based on them. A few years
down the road, the standard designers are interested
to know which properties and ontology features were
used, and which were not; this can inform decisions
about future versions of the standard4.

Making BGPs more speciﬁc BGPs queries may
comprise path expression with wildcards; these are
hard to evaluate, as they require traversing a poten-
tially large part of G. A graph summary may help
understand, e.g., that a path speciﬁed as “any num-
ber of a edges followed by one or more b edges” cor-
responds to exactly two data paths in G, namely: a b
edge; and an a edge followed by a b edge. These two

Schema (or ontology) discovery When an on-
tology is not present in an RDF graph, some works
aim at extracting it from the graph. In this case, the
summary is meant to be used as a schema, which is
considered to have been missing from the initial data
graph.

4Thanks to William van Voensel from schema.org for shar-

ing this application with us.

8

3.3 Classiﬁcation of RDF summariza-

tion methods

From a scientiﬁc viewpoint, existing summarization
proposals are most meaningfully classiﬁed according
to the main algorithmic idea behind the summariza-
tion method:

per class, property and value type; other quanti-
tative measures are frequency of usage of certain
properties, vocabularies, average length of string
literals etc. Statistical approaches may also ex-
plore (typically small) graph patterns, but al-
ways from a quantitative, frequency-based per-
spective.

1. Structural methods are those which consider
ﬁrst and foremost the graph structure, respec-
tively the paths and subgraphs one encounters
in the RDF graph. Given the prominence of ap-
plications and graph uses, where structural con-
ditions are paramount, graph structure is promi-
nently used in summarization techniques.

4. Hybrid methods: To this category belong
works that combine structural, statistical and
pattern-mining techniques.

Another interesting dimension of analysis is the
required input by each summarization method, in
terms of the actual dataset, and of other user inputs
which some methods need:

• Quotient: A particular natural concept
when building summaries is that of quotient
graphs (Deﬁnition 2). They allow charac-
terizing some graph nodes as ”equivalent”
in a certain way, and then summarizing a
graph by assigning a representative to each
class of equivalence of the nodes in the orig-
inal graph. A particular feature of struc-
tural quotient methods is that each graph
node is represented by exactly one sum-
mary node, given that one node can only
belong to one equivalence class.

• Non-quotient: Other methods for struc-
turally summarizing RDF graphs are based
on other measures, such as centrality, to
identify the most important nodes, and in-
terconnect them in the summary.
Such
methods aim at building an overview of the
graph, even if (unlike quotient summaries)
some graph nodes may not be represented
at all.

2. Pattern mining methods: These methods
employ mining techniques for discovering pat-
terns in the data; the summary is then built out
of the patterns identiﬁed by mining.

1. Input parameters: Many works in the area
require user parameters to be deﬁned, e.g. user-
speciﬁed equivalence relations, maximum sum-
mary size, weights assigned to some graph ele-
ments etc., whereas others are completely user
independent. While parameterized methods are
able to produce better results in speciﬁc sce-
narios, they require some understanding of the
methodology and as such limit their exploitation
ability only to experts.

2. Input Dataset: Diﬀerent works have diﬀerent
requirements from the dataset they get as in-
put. RDF data graphs are most frequently ac-
cepted, usually RDF/S and/or OWL are used
for specifying graph semantics whereas only very
few works consider DL models.
In addition,
some works consider or require only ontologies
(semantic schema), whereas other works exploit
only instances. Hybrid approaches exploit both
instance and schema information. For instance,
the instance and schema information can be used
to compute the summary of the saturated graph,
even if the instance graph is not saturated.

For what concerns the summarization output,

we identify the following dimensions:

3. Statistical methods: These methods summa-
rize the contents of a graph quantitatively. The
focus is on counting occurrences, such as count-
ing class instances or building value histograms

1. Type: This dimension diﬀerentiates techniques
according to the nature of the ﬁnal result (sum-
mary) that is produced. The summary is some-
times a graph, while in other cases it may be just

9

a selection of frequent structures such as nodes,
paths, rules or queries.

2. Nature: Along this dimension, we distinguish
summaries which only output instance represen-
tatives, from those that output some form of
summary a posteriori schema, and from those
that output both.

Availability: Last but not least, from a practical
perspective it is interesting to know the availability
of a given summarization service. This will allow a
direct comparison with future similar tools:

1. System/Tool:

Several

summarization ap-
proaches are made available by their authors as a
tool or system shared with the public; in our sur-
vey, we signal when this is the case. In addition,
some of the summarization tools can be readily
tested from an online deployment provided by
the authors.

2. Open source: The implementation of some
summarization methods is provided in open
source by the authors, facilitating comparison
and reuse.

We also consider the quality characteristics of each
individual algorithm. Quality has to do with: com-
pleteness in terms of coverage, precision and recall
of the results if an “ideal” summary is available as a
gold standard to compare with, the connectivity of
the computed summary and, at the end, computa-
tional complexity. Given variety of RDF summariza-
tion approaches, it is not easy to deﬁne and evaluate
a single meaningful notion of quality. A more com-
prehensive, eﬀort to establish a generic framework for
computing quality metrics on summaries is proposed
in [122], where authors discuss summarization qual-
ity concerning both the schema and instances lev-
els. However, diﬃculties remain, e.g. identifying the
complexity of a summarization algorithm is not al-
ways possible when the available description of the
algorithm does not provide suﬃcient information.

The main categorization we retain for the dif-
ferent RDF summarization approaches is based on
their measurable/identiﬁable characteristics and not

10

on their intended use. This is because the bound-
aries among the diﬀerent usages are not very clear
and there are types of methods that can be used
in diverse cases/applications. Thus, the advantages
and/or disadvantages for each category of methods
cannot be identiﬁed in a generic way, however, we
inserted a discussion whenever pertinent.

Fig. 4 depicts a high-level taxonomy of the RDF
summarization works, based on the aforementioned
dimensions. Note that many of the dimensions are
orthogonal, thus a work may be classiﬁed in multi-
ple categories. In the sequel, we classify the works,
describe the main ideas and the implemented algo-
rithms. Then we identify the speciﬁc dimension of
analysis captured in Fig. 4 for each of these works.

4 Generic graph (non-RDF)
summarization approaches

In this Section we review generic graph summariza-
tion approaches. While these have not been specif-
ically devised for RDF, they have either been ap-
plied to RDF subsequently, or served as inspira-
tion for similar RDF-speciﬁc proposals. An overview
of the generic graph summarization works is pro-
vided in Table 1 and Table 2. More precisely, Sec-
tion 4.1 presents structural graph summarization
methods, Section 4.2 describes works based on min-
ing and statistics, while Section 4.3 considers sum-
maries based on statistic and hybrid (structural and
statistic) methods.

4.1 Structural graph summarization

The structural complexity and heterogeneity of
graphs make query processing a challenging prob-
lem, due to the fact that nodes which may be part
of the result of a given query can be found anywhere
in the input graph. To tame this complexity and di-
rect query evaluation to the right subsets of the data,
graph summaries have been proposed as a basis for
indexing, by storing next to each summary node, the
IDs of the original graph nodes summarized by this
node; this set is typically called the extent. Given a
query, evaluating the query on the summary and then

Figure 4: A taxonomy of the works in the area.

using the summary node extents allows obtaining the
ﬁnal query results.

4.1.1 Quotient graph summaries

Many proposals for indexing graph data are based on
establishing some notion of equivalence among graph
nodes, and storing the IDs of all nodes as the extent
of the summary node. Formally, these correspond to
quotient graphs, whose deﬁnition we recall below:

Deﬁnition 2 (Quotient graph) Let G = (V, E) be
an A-edge labeled directed graph and ≡ ⊆ V × V be
an equivalence relation over the nodes of V . The
quotient graph of G using ≡, denoted G/≡, is an A
edge-labeled directed graph having:

• a node uS for each set S of ≡-equivalent V

nodes;

• an edge (vS1, l, vS2) iﬀ there exists an E edge
(v1, l, v2) such that vS1 (resp. vS2 ) represents
the set of V nodes ≡-equivalent to v1 (resp. v2).

Prominent node equivalence relations used for
graph summarization build on backward, forward, or
backward-and-forward bisimulation [32]:

Deﬁnition 3 (Backward bisimulation) In
an
edge labeled directed graph, a relation ≈b between the
graph nodes is a backward bisimulation if and
only if for any u, v, u(cid:48), v(cid:48) ∈ V :

1. If v ≈b v(cid:48) and v has no incoming edge, then v(cid:48)

has no incoming edge;

2. If v ≈b v(cid:48) and v(cid:48) has no incoming edge, then v

has no incoming edge;

3. If v ≈b v(cid:48), then for any edge u a−→ v there exists

an edge u(cid:48) a−→ v(cid:48) such that u ≈b u(cid:48);

4. If v ≈b v(cid:48), then for any edge u(cid:48) a−→ v(cid:48) there exists
an edge u a−→ v such that such that u ≈b u(cid:48).

Forward bisimulation, noted ≈f , is deﬁned sim-
ilarly to backward simulation, but considers the out-
going edges of v and v(cid:48), instead of the incoming ones.
Forward and backward simulation, noted ≈f b,
is both a backward and a forward bisimulation.

We already pointed out that, in Figure 1, the graph
on the right is homomorphic to that on the left. The
former is actually the quotient graph of the latter
using ≈f b. In particular, the classes of ≈b-equivalent
nodes are {1}, {2, 3, 4, 5}, {6, 8, 9}, {7}, those of ≈f -
equivalent nodes are {1}, {2}, {3, 4}, {5, 6, 7, 8, 9},

11

those

of
and
{1}, {2}, {3, 4}, {5}, {6}, {7}, {8, 9}.

≈f b-equivalent

nodes

are

tain set only.

Finally, we remark that it easily follows from the
bisimulation deﬁnitions that if v ≈ v(cid:48), for instance for
forward-bisimulation, then any label path that can be
followed from v in the graph G can also be followed
from v(cid:48) in G and the other way around.
In other
words, the same paths start (respectively, end) in two
≈-equivalent nodes. This condition is hard to meet
in graphs that exhibit some structural heterogeneity:
in such cases, every node is ≈-equivalent to very few
(if any) other nodes.

The Template Index (or T-index) [64] summary
considers that two graph nodes are equivalent if they
are backward bisimilar. In particular, in a T-index,
nodes represented together need to be reachable by
the exact same set of incoming paths. The goal of
the T-index is to speed up the evaluation of com-
plex queries of a certain form (or template), such as
P.v (all nodes v reachable by a path matching the
regular expression P ) or v.P.u (all v, u node pairs
connected by a path matching P ); the proposal gen-
eralizes to arbitrary arity queries, although the au-
thors note it is likely to be most useful in the above
two simplest forms. The simulation relation between
the nodes of a graph G is known to be computable in
O(M ∗ log(M )) [71] or O(N ∗ M ) [32]; the cost drops
to linear for acyclic graphs. All these algorithms as-
sume the graph ﬁts in memory.

To support eﬃcient processing of graph queries
that navigate both forward (in the direction of the
graph edges) and backward, [37] describes the For-
ward and Backward Index (F&B) which considers
two nodes equivalent if they are undistinguishable by
any navigation path composed only of forward and
backward steps (see Figure 5 for an example). While
this equivalence condition is very powerful, it is rarely
satisﬁed by two nodes, thus the F&B index is likely
to have a large amount of nodes (close to the number
of nodes in the original graph), making the manip-
ulation of the F&B index structure ineﬃcient. To
address the problem, the authors note that in prac-
tice not any path query is frequently asked by appli-
cations, therefore it suﬃces to consider F&B equiva-
lence of nodes as being undistinguishable by forward
and backward navigation along the paths from a cer-

Another method proposed in [38, 83], in order to
make the F&B index smaller and more manageable,
is to consider bisimilarity restricted only to paths of
a certain length around the graph nodes (see Figure 5
for an example). This increases the chances that two
nodes be considered equivalent, thus reducing the size
of the bisimilarity-based summary. Limited bisimula-
tion summaries like this, can be computed by evaluat-
ing structural group-by queries (for k-bounded bisim-
ilarity), respectively, queries derived from the work-
load of interest (for workload-driven F&B summa-
rization). While the theoretical complexity of such
queries is O(M k), with M the number of edges and k
the size of the most complex query involved, eﬃcient
graph query processors, with the help of good index-
ing, achieve much better performance in practice.

[18] considers the summarization of large Web doc-
ument collections. While the main structure in this
case consists of trees, they may also feature reference
edges which turn the dataset into a global graph. The
authors build a summary as a collection of regular ex-
pression queries, such that the set of results to these
queries, together, make up a partition over the set
of nodes in all the documents of the input collec-
tion. To each such regular expression is associated
a set of cardinality statistics, to help application de-
signers chose meaningful queries and inform them on
the expected performance which may be reached on
those queries. The dominant-cost operation required
by this approach is computing simulations among N
nodes; summaries can then be reﬁned based on user-
speciﬁed path queries.

[62] provides an I/O eﬃcient external memory
based algorithm for constructing the k-bisimulation
summary of a disk-resident graph on a single ma-
chine, based on several passes of sorting and grad-
ually reﬁning partitions of nodes on disk. The I/O
complexity of the algorithm is O(k ∗ sort(Mp) + k ∗
scan(Np) + sort(Np)), where Mp, respectively, Np
are the numbers of disk pages required to store the
graph edges, respectively, graph nodes, while sort(·)
and scan(·) quantify the cost of an external sort, re-
spectively, the cost to scan a certain number of pages.

12

4.1.2 Non-quotient graph summaries

There are also many methods that construct non-
quotient graph summaries. They distinguish nodes
according to several criteria/measures and create
summaries in which summary nodes represent multi-
ple nodes out of the original graph.

A Dataguide [28] (see Figure 5 for an example) is
a summary of a directed acyclic graph, having one
node for each data path in the original graph. A
graph node reachable by a set of paths belongs to the
extents of all the respective Dataguide nodes. Thus,
given a path query which may also contain wildcards,
and a Dataguide, it is easy to identify the Dataguide
nodes corresponding to the query, and from there
their extents. The authors show how to integrate
the Dataguide path index with more conventional in-
dexes, e.g., a value index which gives access to all
the nodes containing a certain constant value etc. A
Dataguide is not a quotient: an input node may be
represented by two Dataguide nodes, if it is reach-
able by two distinct paths in the input graph. Build-
ing a Dataguide out of a data graph amounts to de-
terminizing an undeterministic ﬁnite automaton; the
worst-case complexity of this is known to be expo-
nential in the size of the input graph, yet only linear
when the database is tree-structured.

Summary-based query answering with an accept-
able level of error is considered in [41, 69]. The focus
is on graph compression while preserving bounded-
error query answering and/or the ability to fully re-
construct the graph from the summary with the help
of so-called “corrections” (i.e. edges to add to or re-
move from the “expansion” of the summary into the
regular part of the graph it derives from). The nodes
of the resulting structural summary represent parti-
tions of similar nodes from G, while a summary edge
exists between two summary nodes u and v only if
the nodes from G represented by u and v are densely
connected. Similarly, [55] aims to compress G, but
without considering corrections, while their edge la-
bels represent the number of edges within each par-
tition set, and the number of edges between every
two such sets. To determine similar nodes, [41] re-
lies on locality-sensitive hashing, while [69, 55] use a
clustering method where pairs of nodes to merge are

chosen based on the optimal value of an objective
function. In [84], the authors build on the concepts
of [55] to show how to obtain in polynomial time,
summaries which are close to the optimal one (in
terms of corrections needed. However, these works
focus on node connectivity, and ignore the node and
edge labels which crucially encode the data content
of an RDF graph.
[97] proposes

the SNAP (Summarization on
Grouping Nodes on Attributes and Pairwise Rela-
tionships) technique, whose purpose is to construct,
with some user input, a summary graph that can be
used for visualization. A SNAP summary represents
all the input graph nodes and edges: its nodes forms
a partition of the input graph nodes, and there is an
edge of type t between two summary nodes A and B if
and only if some input graph node represented by A is
connected through an edge of type t to an input graph
node represented by B. Further, a SNAP summary
has a minimal number of nodes such that (i) all in-
put graph nodes represented by a summary node have
same values for some user selected attributes and (ii)
every input graph node represented by some sum-
mary node is connected to some input graph nodes
through edges of some user-selected types.

[22] considers

reachability and graph pattern
queries on labeled graphs, and builds answer-
preserving summaries for such queries, that is:
for
a given graph G, summary S(G) and query Q,
there exists a query Q(cid:48) which can be computed
from Q, and a post-processing procedure P such
that P (Q(cid:48)(S(G))) = Q(G).
In other words, eval-
uating Q(cid:48) on the summary and then applying the
post-processing P leads to the result Q(G). This
property is rather strong, however,
it is attained
not under the usual query semantics based on graph
homomorphism, underlying SPARQL, but under a
bounded graph simulation one. Under these se-
mantics, answering a query becomes P (instead of
N P ), at the price of not preserving the query struc-
ture (i.e., joins). The authors propose two paral-
lel graph compression strategies, targeting diﬀerent
kinds of queries: (i) reachability queries, where we
seek to know if one node is reachable from another;
(ii) graph pattern queries, for which they attain a
It should be again
signiﬁcant compression ratio.

13

Figure 5: Structural graph summarization examples.

stressed that the authors consider these queries under
non-standard, more lenient semantics than the ones
used for RDF querying. The complexity of build-
ing their summaries are O(N ∗ M ) for reachability
queries, and O(N ∗log(M )) for graph pattern queries.

4.2 Mining-based graph summariza-

tion

OLAP and data mining techniques applied to data
graphs have considered them through global, aggre-
gated views, looking for statistics and/or trends in
the graph structure and content.

[112] leverages pattern mining techniques to build
graph indices in order to help processing a graph
query.
It ﬁrstly applies a frequent pattern mining
algorithm to identify all the frequent patterns with
the size support constraint. Once the frequent pat-
terns are extracted, they are organized in a preﬁx tree
structure, where each pattern is associated with a list
of ids of the graphs containing it. This preﬁx tree is
then used to answer queries asking for the respective
part of the graph. This approach by design does not
reﬂect all data and is based on numeric information.
[118] uses the same idea, but considers trees instead
of graphs.

(VoG) [51] aims at summarizing a graph by its char-
acteristic subgraphs of some ﬁxed types, which have
been observed encoding meaningful information in
real graphs: cliques, bi-partite cores, stars, chains,
and approximations thereof. VoG ﬁrst decomposes
the input graph, using any clustering method, into
possibly overlapping subgraphs, the (approximate)
type of each is then identiﬁed using the Minimum
Description Length principle [85]. Finally, the input
graph summary is composed of some non-redundant
subgraphs, picked by some heuristic like top k, hence
may not reﬂect all the input graph. Importantly, the
VoG method has been shown to scale well; it is near-
linear in the number of edges. The VoG code is avail-
able for download5.

An aggregation framework for OLAP operations
on labeled graphs is introduced in [16]. The authors
assume as available an OLAP-style set of dimensions
with their hierarchies and measures;
in particular,
graph topological information is used as aggregation
dimensions. Based on these, they deﬁne a “graph
cube” and investigate eﬃcient methods for comput-
ing it. With a diﬀerent perspective, [15] focuses on
building out of node- and edge-labeled graphs, a set
of randomized summaries, so that one can apply data

The Vocabulary-based summarization of Graphs

5https://github.com/yikeliu/VoG-Overlap

14

mining techniques on the summary set instead of the
original graph. Using the summary set leads to bet-
ter performance, while guaranteeing upper bounds on
the information loss incurred.

A graph summarization approach, based solely on
the graph structure is reported in [58]. It produces a
summary graph that describes the underlying topol-
ogy characteristics of the original one. Every sum-
mary node, or super-node, comprises of a set of nodes
from the original graph; every summary edge, or
super-edge, represents an all-to-all connections be-
tween the nodes in the corresponding super nodes.
The goal of this work is to generate a summary
that minimizes the false positives and negatives in-
troduced by this summarization. The authors in-
vestigate diﬀerent distributed graph summarization
methods, which proceed in an incremental fashion,
gradually merging nodes into supernodes; the meth-
ods diﬀer in the way they chose the pairs of nodes
to be merged, and cut diﬀerent trade-oﬀs between
eﬃciency (running time) and eﬀectiveness (keeping
the false positives and negatives under control). The
method termed Dist-LSH selects node pairs with a
high probability to be merged; the probability is es-
timated based on locality-sensitive hashing (LSH) of
the nodes. The algorithms are implemented on top
of the Apache Giraph framework.

[57] surveys many other quantitative, mining-
oriented graph sampling and summarization meth-
ods.

4.3 Statistical and hybrid graph sum-

marization

Several follow-ups on the SNAP summarization ap-
proach (Section 4.1.2) have been proposed in the lit-
erature.

The k-SNAP summarization approach [97, 98] is
an approximation of the SNAP one. It allows setting
the desired number k of summary nodes, so that a
whole graph can be visualized at diﬀerent granular-
ity levels, similarly to roll-up and drill-down OLAP
operations. A k-SNAP summary is a graph of k sum-
mary nodes which satisfy the above condition (i) of
a SNAP summary, but relax condition (ii) so that
only some (not every) input graph node represented

by some summary node satisﬁes it. Further, as many
such summaries may exist, a k-SNAP summary is
deﬁned as one that best satisfy the condition (ii) of
SNAP summaries. Finding such a summary is NP-
complete [97], hence tractable heuristic-based algo-
rithms are proposed to compute approximations of
k-SNAP summaries.

The k-SNAP summarization approach has been
further extended [115] to handle numerical attributes,
while k-SNAP as well as SNAP before have only con-
sidered categorial attributes whose domains are made
of a limited number of values. The proposed CANAL
approach allows bucketizing the values of some nu-
merical attribute into the desired number of cate-
gories, hence reducing the summarization of graphs
with categorial and numerical attributes to that of
graphs with categorial attributes only. For a given
numerical attribute a, each of the obtained categories
represent a range of a values that nodes with similar
edge structure have. Computing such categories is
in O(N log N + k4
a), where ka is the number of dis-
tinct a values that the input graph contains. Also,
to ease the use of k-SNAP to inspect a graph in an
roll-up and drill-down OLAP fashion, [115] provides
a solution to automatically recommend k values for
visualizing this graph. It consists in ranking k-SNAP
summaries of varying k according to a so-called inter-
estingness measure, deﬁned in terms of conciseness,
coverage and diversity criteria.

k-SNAP has also strongly inspired the summariza-
tion approach in [60], which similarly aims at com-
puting graph summaries w.r.t. user selected num-
ber of summary nodes, attributes and edge types.
The summaries are computed using a variant of
one above-mentionned tractable k-SNAP heuristics,
which keeps the SNAP condition (i) but changes the
SNAP condition (ii) that k-SNAP tries to best sat-
isﬁes, so that a summary best reﬂects the organiza-
tion in social communities of the input graph nodes
w.r.t. the selected attributes and edge types.

From a diﬀerent perspective,

[86] sketches SAP
HANA’s approach for large graph analytics through
summarization. It consists in deﬁning rules to sum-
marize part of an analyzed graph. Rules are made
of two components, one graph pattern to be matched
on the graph, and how the matched data should be

15

Work

Input requirements

Purpose

Output type

Visualization

Graph

Output
nature
Instance

System -
Theory
Theory

al.

et

SNAP/k-SNAP
[97, 98]
Zhang
[115]
Louati
[60]
Fan et al. [22]

et

al.

Required user param-
eters
Required user param-
eters
Required user param-
eters
Required
selected queries

user-

Visualization

Graph

Instance

Theory

Visualization

Graph

Instance

Theory

Query answer-
ing

Graph

DescribeX [18]

None

Luo et al. [62]

None

T-index [64]

Parametrized user in-
put

Query answer-
ing

Indexing, query
answering
Query answer-
ing

D(K)-index [83]

Parametrized user in-
put

Query answer-
ing

F&B-index [37]

Parametrized user in-
put

Query answer-
ing

root

Single
node-labeled
graphs
Graph

Multi-roots
edge-labeled
graphs
Single
node-labeled
graphs
Single
node-labeled
graphs

root

root

Node-
labeled
directed
graph
Instance

Theory

System

Instance

Theory

Instance

Theory

Instance

Theory

Instance

Theory

Table 1: Graph summaries based on structural quotients.

grouped and aggregated into a result graph.

the remaining structural summarization methods are
described in 5.2

5 Structural RDF summariza-

tion

5.1 Structural quotient RDF sum-

maries

Structural summarization of RDF graphs aims at
producing a summary graph, typically much smaller
than the original graph, such that certain interesting
properties of the original graph (connectivity, paths,
certain graph patterns, frequent nodes etc.) are pre-
served in the summary graph. Moreover, these prop-
erties are taken into consideration to construct a sum-
mary. The methods for structural summarization are
distinguished into two categories. The quotient sum-
marization methods, discussed in Section 5.1, while

We begin with summarization techniques that are
based on quotient methods.
Intuitively, each sum-
mary node corresponds to (represents) multiple nodes
from the input graph, while an edge between two
summary nodes represents the relationships between
the nodes from the input graph, represented by the
two adjacent summary nodes. Often, the nodes for-
mulated in summaries like these, are called super-
nodes, while their edges are called super-edges.

An interesting property, which directly follows

16

from the notion of quotient graph, relates query an-
swers on an RDF graph G to query answers on its
quotient summary:

an
Deﬁnition 4 (Representativeness) Given
RDF query language (dialect) Q, an RDF graph G
and a summary Sum of it, Sum is Q-representative
of G if and only if for any query Q ∈ Q such that
Q(G∞) (cid:54)= ∅, we have Q(Sum∞) (cid:54)= ∅.

Informally,

representativeness guarantees

that
queries having answers on G should also have an-
swers on the summary. This is desirable in order
for the summary to help users formulate queries: the
summary should reﬂect all graph patterns that occur
in the data.

An overview of the structural quotient summaries
is shown in Table 3. Section 5.1.1 introduces sum-
maries deﬁned based on bisimulation graph quotients
(recall Deﬁnition 2), while Section 5.1.2 discusses
other quotient summaries.

5.1.1

(Bi)simulation RDF summaries

The classical notion of bisimulation (Section 4.1) has
been used to deﬁne many RDF structural quotient
summaries.

Thus, [78] presents SAINT-DB, a native RDF man-
agement system based on structural indexes. This
index is an RDF quotient simulation, based on triple
(not node) equivalence. The summary is not an RDF
graph: its nodes group triples from the input, while
edge labels indicate positions in which triples in ad-
jacent nodes join. Thus, the index is tailored for re-
ducing the query join eﬀort, by pruning any dangling
triples which do not participate in the join. Since the
index contains only information on joins, and nothing
of the values present in the input graph, the query
language is restricted to BGPs comprising of vari-
ables in all positions; further, these BGPs must be
acyclic. For compactness, they bound the simula-
tion, for small k values, e.g., 2; this enables com-
pression factors of about 104. Semantic information
or ontologies are not considered. The time complex-
ity of the algorithm comes from the corresonding al-
gorithms for computing graph simulation. This is

17

O(N 2 ∗ M ), where N is the number of nodes (equiv-
alent types) and M is the number of edge labels in
the result graph. In practice, diﬀerent query process-
ing strategies aimed at join pruning are implemented
by integrating the structural index with the RDF-3X
[70] engine.

A structure-based index is proposed in [99], deﬁned
as a bisimulation quotient; the authors show that the
summary is representative of only tree-shaped queries
over non-type and non-schema triples, comprising a
single distinguished variable which corresponds to the
root node. Further, the authors study limited ver-
sions of the bisimulation quotient by considering: (i)
only forward bisimulation, (ii) only backward bisim-
ulation or (iii) only neighborhoods of a certain length
for tree structures of the input graph. The proposed
applications of the structure index are twofold: (i)
for data partitioning, by creating a table for each
node of the structure index, thereby physically group-
ing triples with subjects that share the same struc-
ture, and (ii) for query answering, where the query
may be run ﬁrst on the structure index, to obtain
the set of candidate answers, thus achieving prun-
ing of the (larger) original graph. The authors do
not consider graph semantics, nor answering queries
The complexity of
over type and schema triples.
the corresponding algorithm for generating the index
is O((N1 ∪ N2) ∗ M ∗ log N ), where N1 and N2 are
the nodes selected for backward and forward bisimu-
lation respectively, M is the number of edges and N
the number of nodes of the input graph.

RDF summaries deﬁned in [17] are quotients based
on FW bisimulation. The authors do not consider
graph semantics or ontologies. They show how to
use the summary as a support for query evaluation:
incoming navigational SPARQL queries are evaluated
on the summary, then the results on the summary are
transformed into results on the original graph by ex-
ploring the extents of summary nodes. They propose
in [45] an implementation based on GraphChi [52],
the single-machine multi-core processing framework,
to construct the summary in roughly the amount of
time required to load the input KB plus write the
summary. GraphChi supports the Bulk Synchronous
Parallel (BSP) [106] iterative, node-centric process-
ing model, by which nodes in the current iteration

execute an update function in parallel, depending on
the values from the previous iteration. Their sum-
marization approach is based on the parallel, hash-
based approach of [6] which iteratively updates each
node’s block identiﬁer by computing a hash value
from the node’s signature deﬁned by the node’s neigh-
bors from the previous iteration. The main idea is
that two bisimilar nodes will have the same signa-
ture, the same hash value, and thus have the same
block identiﬁer. Due to the large size of the result-
ing bisimulation summary, the authors propose a so-
called singleton optimization, which involves remov-
ing summary nodes representing only one node from
G; the reduced summary is therefore no longer a quo-
tient of G.

into

ExpLOD [42, 43] produces summaries of RDF
graphs, by ﬁrst transforming the original RDF
an unlabeled-edge-ExpLOD-graph,
dataset
where a node is created for each triple in the orig-
inal RDF graph, labeled with the triple property;
unlabeled edges go from the original triple’s subject
and object, to the newly constructed property node.
Then,
the ExpLOD graph is summarized by a
forward bisimulation quotient, grouping together
nodes having the same RDF usage. RDF usage can
the number of instances of a
be statistical, e.g.,
particular class, or the number of times a property
is used to describe resources in the graph. RDF
usage can also be structural, e.g., the set of classes
to which an instance belongs, the sets of properties
describing an instance, or sets of resources connected
by the owl:sameAs property. As such, they do not
propose one summary, but rather a framework where
one can select the summary according to his ”usage”
preferences. Finally, the bisimulation quotient is
applied without taking into account neither schema
nor type triples, thus the summary is not represen-
tative. There are two sequential implementations
of ExpLOD. The ﬁrst implementation computes
the relational coarsest partition of a graph using
a partition reﬁnement algorithm [72], and requires
datasets to ﬁt in main memory. The second ap-
proach uses SPARQL queries against an RDF triple
store; although in principle this is more scalable,
as datasets need not be stored in main memory,
it is slower due to the query answering time. To

Figure 6: RDF vocabulary for the data graph sum-
mary [11].

overcome the limitation of the centralized approach,
the authors extend ExpLOD, proposing a novel,
scalable mechanism to generate usage summaries of
billions of Linked Data triples based on a parallel
Hadoop implementation [44].

[87] considers the problem of eﬃciently building
quotient summaries of RDF graphs based on the FW
bisimulation node equivalence relation. The authors
do not reserve any special treatment to RDF type
and schema triples, which prevents the resulting RDF
summaries of being representative. Two implemen-
tations of the algorithm for computing graph bisim-
ulations, ﬁrst introduced in [3], are presented: one
for sequential single-machine execution using SQL,
and the other for distributed execution, taking advan-
tage of MapReduce parallelization to reduce running
time. They both have worst-case time complexity of
a O(M ∗ N + N 2).

5.1.2 Other structural quotient summaries

To assist users whose task is query formulation, [11]
creates the summary graph, the so called node collec-
tion layer, by grouping nodes having the exact same
types, or in the absence of types, the same outgo-
ing properties, into entity nodes; further, nodes from
the input with no outgoing properties, and having
the same incoming properties from subjects with the
same set of types, are represented by blank nodes.
An edge exists between two summary nodes v1 and
v2, labeled by a property p, if there exist two nodes
1 and v(cid:48)
v(cid:48)
1 is represented by v1,
v(cid:48)
2 is represented by v2, and there exists an edge la-
1 to v(cid:48)
beled by p in G from v(cid:48)
2. The number of rep-

2 in G, such that v(cid:48)

18

resented nodes from the input is attached to each
summary node, and the number of represented edges
from the input to each summary edge. This summary
graph may group resources from multiple datasets.
The proposed dataset layer groups together nodes of
the node collection layer which belong to the same
dataset. Schema triples are not considered. The ap-
proach bears similarities with ExpLOD, since nodes
in the ﬁrst layer are partitioned by types, and par-
titions are represented by distinct summary nodes.
However, unlike ExpLOD, the G nodes having a type,
are not further distinguished by their data proper-
ties, i.e., two nodes of the same type A, one having
the data properties a, b and c and the other hav-
ing the properties a and d will be represented by the
same summary node. Unlike ExpLOD, their sum-
mary graph is an RDF graph.

RDF summaries are deﬁned in a rather restricted
setting in [34]. The authors assume that all subjects
and objects are typed, and that each has exactly one
type; class and property URIs are not allowed in sub-
ject and object position, and no usage is made of
possible schema triples. Under this hypothesis, they
construct from the RDF graph a typed object graph
(TOG) comprising (s, p, o) triples and assigning an
RDF type for each such s and o. Two methods are
proposed for summarizing the TOG, namely, equiva-
lent compression and dependent compression. The
equivalent compression produces a quotient of the
TOG by grouping together nodes having the same
type and the same set of labels on the edges adja-
cent to the node. In the dependent compression, two
nodes v1 and v2 of the TOG are grouped together if
v1 is adjacent only to v2, or vice-versa. As application
scenarios of this approach the authors indicate min-
ing semantic associations, usually deﬁned as graph
or path structures representing group relationships
among several instances.

Based on query-preserving graph compression [22]
(Section 4.1.2), an Adaptive Structural Summary for
RDF graphs (ASSG, in short) is introduced in [114].
ASSG aims at building compressed summaries of the
part of an RDF graph which is concerned by a cer-
tain set of queries. The authors compute a structural
rank of nodes, which is 0 for leaves, and grows with
the shortest distance between the node and a leaf;

then, nodes having the same label and the same rank
are considered equivalent, and are all compressed to-
gether in a single ASSG node. To partition the N
nodes of a graph G to diﬀerent equivalent classes by
their label and rank the cost is O(N + M ), where M
the number of the edges of the graph.

RDF summaries deﬁned in [13, 14, 12] adapt the
idea of quotient summaries to two characteristic fea-
tures of RDF graphs: (i) the presence of type triples
(zero, one, or any number of types for a given re-
source), and (ii) the presence of schema triples. As
we explained in Section 2.1, RDF Schema informa-
tion is also expressed by means of triples, which are
part of G. [12] shows that quotient summarization of
schema triples does more harm than good, as it de-
stroys the semantics of the original graph. To address
this, they introduce a notion of RDF node equiva-
lence which ensures that class and property nodes
(part of schema triples) are not equivalent to any
other G nodes, and deﬁne a summary as the quotient
of G through one such RDF node equivalence. Such
summaries are shown to preserve the RDF Schema
triples intact, and to enjoy representativeness (Deﬁni-
tion 4) for BGP queries having variables in all subject
and object positions. The authors show how bisim-
ulation summaries can be cast in this framework,
and introduce four novel summaries based property
cliques, which generalize property co-occurrence as
follows. A clique cG is a set of data properties from
G such that for any p1, p2 ∈ cG, a resource of G is the
source and/or target of both p1 and p2. For instance,
if resource r1 has properties a and b while r2 has b
and c, then a, b, c are part of the same source clique;
if, instead, r1 and r2 are targets of these properties,
then a, b, c are part of the same target clique. The
so-called weak summary groups together nodes hav-
ing the same source or target clique, while the strong
summary requires the same source and the same tar-
get clique; their variant typed-weak and typed-strong
summaries ﬁrst group nodes according to their types,
and then according to their cliques. All these sum-
maries can be computed in linear-time in the size of
the input graph. A beneﬁt of this speciﬁc approach is
that clique summaries are orders of magnitude more
compact than bisimulation summaries. The authors
also study how to obtain the summary of G’s seman-

19

tics, which is the saturation of G. They provide a
suﬃcient condition on the RDF equivalence relation,
ensuring that the summary of G∞ can be computed
from G without saturating it, and show that this may
be many times faster than the direct procedure of ﬁrst
saturating G, then summarizing G∞. The software
tool implementing this approach is available as open
source6.

5.2 Structural
summaries

non-quotient RDF

Several structural RDF summaries have been based
on techniques diﬀerent from structural quotients.
Our presentation below attempts to identify fami-
lies of proposals based on the summarization tech-
niques and/or, as appropriate, on the usage for which
the summaries are built. An overview of all struc-
tural, non-quotient summaries is shown in Table 4,
depicting their individual characteristics as well. Sec-
tion 5.2.1 presents proposals based on text summa-
rization and information retrieval; Section 5.2.2 de-
scribes summaries built around concepts of central-
ity (or rank, importance) of nodes in a graph; Sec-
tion 5.2.3 considers structural RDF summarization
based on an index or other structures which aim at
selective data access; ﬁnally, Section 5.2.4 discusses
RDF summaries whose goal is to facilitate the extrac-
tion of a schema, understood as a compact structural
description, of the input RDF graph.

5.2.1

Inspired by text summarization and in-
formation retrieval

One way of summarizing data, especially when the
summary is meant for human users, is to select a
most signiﬁcant subset thereof. Such summarization
is very useful, considering that the human ability to
process information does not change as the available
data volumes grow. We describe here RDF knowl-
edge base summarization eﬀorts inspired from infor-
mation retrieval and text summarization.

In [96], the authors study the problem of select-
ing the most important part of an RDF graph which

6https://gitlab.inria.fr/cedar/quotientSummary

is to be shown to a user interested in a certain en-
tity (resource). A ﬁxed space (triple) budget is to be
used; beyond labels, authors also allow the edges of
the RDF graph to carry weights, with higher-weight
edges being more important to show. The authors
provide algorithms which select triples favoring close-
ness to the target entity and weight; then, they ex-
tend this with criteria based on diversity (include
edges with diﬀerent labels in the selection) and pop-
ularity (favor frequently occurring edge labels).
It
is worth noting that similar techniques have recently
been included in Google’s search engine, when the
user searches for an entity present in Google’s Knowl-
edge Graph, and is presented with a small selection
of this entity’s properties.

Besides this, text summarization principles, where
a text can be seen as a collection of terms or a bag
of sentences, have been applied to summarize ontolo-
gies. An ontology summarization method along these
lines is introduced in [117], based on RDF Sentence
Graphs. An RDF Sentence Graph is a weighted, di-
rected graph where each vertex represents an RDF
sentence, which is a set of RDF Schema statements
as illustrated in Fig. 7. A link between two sentences
exists, if an object of one sentence belongs to another
sentence as well. The creation of a sentence graph is
customized by domain experts, who provide as in-
put the desired summary size, and their navigation
preferences, i.e. weights in the links they are mostly
interested in. Then, the importance of each RDF sen-
tence is assessed by determining its centrality in the
sentence graph. The authors compare diﬀerent cen-
trality measures (based on node degree, betweenness,
and the PageRank and HITS scores, and show that
weighted in-degree centrality and some eigenvector-
based centralities produce better results. Finally, the
most important RDF sentences are re-ranked consid-
ering the coherence of the summary and the coverage
of the original ontology, and the constructed result
is returned to the user. This method does not han-
dle implicit information (thus, it should be applied to
a saturated ontology); also, it does not consider the
instance graph.

Subsequently, the authors extended their technique
from one ontology, to the global set of ontologies har-
vested from the semantic web [116]. Speciﬁcally, to

20

compounds; (ii) basic level measures how cen-
tral a concept is in the taxonomy of the ontol-
ogy. This is combined with the density favouring
concepts which have many properties and taxo-
nomic relationships.

• The coverage tires to ensure that no part of the

ontology is neglected.

• Lastly, the notion of popularity, is based on lexi-
cal statistics, and tries to identify concepts com-
monly used in natural language.

Each ontology concept is assigned a score, which is
a weighted sum of the scores assigned for each indi-
vidual criterium; then the key concepts of the ontolo-
gies are taken to be those with the highest score. This
approach extracts only schema elements, based on
both schema and instance information. Implicit in-
formation in the ontology is also taken into account in
the process. To ﬁne-tune result quality, the method
requires the user to specify values for a set of pa-
rameters. The tool implementing this approach is
available online and in open source7.

5.2.2 Focused on centrality measures

In this section, we present approaches that focus on
exploiting centrality measures (and in some cases in
combination with other parameters)in order to pro-
duce summaries.

RDFDigest [102],

[100] produces summaries of
RDF schemas, consisting of the most representative
concepts of the schema, seen also from the angle
of their frequency in a given instance (RDF graph).
Thus, the input of the process includes both an ontol-
ogy and a data graph. The tool starts by saturating
the knowledge base with all implicit data and schema
information, thus taking them into account for the
rest of the process. The goal of the work is to iden-
tify the most important nodes in the ontology, and
to link them in order to produce a valid sub-graph of
the input scema.

In its ﬁrst version [101], node relevance is deﬁned
based on the relative cardinality, and the in/out de-
gree centrality of the node. Then the most relevant

7http://www.essepuntato.it/kce

Figure 7: Sample RDF sentences [117].

decide the importance (salience) of an RDF sentence,
they extend it with neighboring information, for ex-
ample counting how often the terms of the sentence
are linked or instantiated in the global semantic web.
Two salience measures are proposed: structural and
pragmatic importance. Structural importance, mea-
sures the number of entities in the web that have a
reference to the local RDF sentences with regards to
subjects, predicates or objects. Secondly, the prag-
matics importance takes into account the statistical
frequency of terms instantiated across the global se-
mantic web. The two measures are combined in order
to produce an integrated importance value for each
RDF sentence, which again is passed to a re-ranking
step to ensure coverage over the whole ontology. Al-
though, in the second approach, statistical informa-
tion over the instances is considered, the approach
still does not consider implicit information.

KCE [76], [66], on the other hand, attempts to au-
tomatically identify the key concepts in an ontology.
To achieve this, it combines cognitive principles with
lexical and topological measures (the density and the
coverage). The goal is to identify a number of con-
cepts that would be selected by human experts. To
this direction a number of criteria are deﬁned:

• The notion of natural category is used for iden-
tifying concepts that are information-rich in a
psycho-linguistic sense. This is approximated by
two measures: (i) name simplicity promotes con-
cepts labeled with simple names and penalizes

21

nodes are retained as being part of the answer. To
ﬁnd out how to connect these nodes in a sub-schema,
two algorithms are proposed, trying to maximize the
importance of the selected ontology edges either glob-
ally or locally. In the ﬁrst case a spanning tree is cal-
culated maximizing the importance of the selected
edges, and then the most important nodes are con-
nected using paths from this tree.
In the second
case, the edges linking the most important nodes are
selected based on the notion of coverage trying to
maximize the most representative edges out of the
whole schema graph. The authors report that link-
ing the most important nodes based on maximum-
cost spanning trees produces better summaries ac-
cording to their experiments with both methods hav-
ing a worst-case time complexity of O(N 3
O), where
NO is the number of nodes in the ontology. How-
ever, this method does not guarantee that the total
weight of the selected subgraph is maximized, and
when picking a connecting path, it may introduce
many additional nodes in the result, some of which
may not be important at all. The size and quality
of the resulting summary can be ﬁne-tuned by spec-
ifying values for a set of parameters; the system is
available online8 and is mostly targeted for visually
presenting the ontology summaries.

The more recent version [75] tries to identify
the most important schema nodes using six well-
known measures from graph theory (i.e., degree,
betweennes, bridging centrality, harmonic centrality,
radiality, and ego centrality [8]) and adapting them
for RDF/S KBs in order to consider instance infor-
mation as well. The authors model the problem of
linking those nodes as a graph Steiner Tree selec-
tion problem [30], trying to minimize the total num-
ber of additional nodes introduced, employing ap-
proximations and heuristics to speed up the execu-
tion of the respective algorithms. According to the
authors, the optimal selection of importance mea-
sure and approximation for linking the most impor-
tant nodes yields a worst-case time complexity of
O(N 2∗M )+O(S∗(N +M )) where N is the number of
nodes, M is the number of edges in the ontology and
S the number of most important nodes to be selected.

8http://www.ics.forth.gr/isl/rdf-digest/

An overview of the summarization process is shown
in Fig. 8. Also in this version, users have the op-
portunity to parameterize the process by specifying
values of diﬀerent parameters, such as the number of
summary nodes to be selected. In the latest version
of the system [103, 104], the authors propose explo-
ration operations based on summaries such as zoom
and extend. Extend focuses on a speciﬁc subgraph
of the initial ontology whereas zoom on the whole
graph, providing more or less detailed information
for the selected nodes.

[82] on the other hand, tries to combine user pref-
erences with centrality measures in order to calculate
the importance of a node. Then paths that include
the most important nodes are identiﬁed to produce
the ﬁnal graph. Thus, the result is a subgraph of the
original graph. The main steps of this summarization
method are shown in Fig. 9: (i) select the parame-
ters (e.g., the size of the summary and importance
thresholds) and possibly nodes that are important ac-
cording to user’s opinion; (ii) compute the relevance
of the concepts in the ontology as the weighted sum
of the the degree centrality and the closeness central-
ity; (ii) identify the paths linking the selected nodes
using the Broaden Relevant Paths algorithm. The
speciﬁc algorithm tries to ﬁnd paths of greatest qual-
ity within the summarized graph by considering the
relevance of the included nodes in the path. The ap-
proach supports RDF or OWL ontologies and mainly
aims to help ontology understanding through visual-
ization.

5.2.3 Index-driven RDF summaries

Besides summaries focusing on centrality measures,
other approaches try to exploit summaries for index-
ing.

GRIN [105], for example,

is an index for RDF
graphs that has been designed for eﬃcient query an-
swering. The semantics of the indexed RDF graph is
taken into account by assuming that the input graph
is saturated before being indexed, however the RDF
Schema is not part of the index. A GRIN index is
a hierarchical clustering of the resources of an RDF
graph, modelled as a balanced binary tree. The set
of leaf nodes in the tree, form a partition of the set of

22

Figure 8: Creating an ontology schema graph using [75].

Figure 9: Flowchart of the ontology summarization method [82].

triples in the RDF graph; each leaf node represents
the resources of the triples it holds. Interior nodes
are constructed by ﬁnding a center triple, and a ra-
dius value R. An interior node in the tree implicitly
represents the set of all vertices in the graph that are
within R units of distance (i.e. less than or equal to
R links) from that center. Inner nodes at a same level
of the index form a partition of the input RDF graph;
each inner node reﬂects the resources of the triples of
the nodes it is an ancestor of. The worst case com-
plexity for building the index is O(R4 ∗ log2R). Then
at query time, GRIN derives a set of inequality con-
straints from the query, evaluated againes the nodes
of the GRIN index in order to identify the smallest
sub-graph that contains answers to the input query.

[29] studies eﬃcient query processing in the TriAD

distributed RDF data management system, by rely-
ing on a summary of the RDF graph stored within the
system. This summary, which is an RDF graph, fol-
lows from a standard partitioning of the input RDF
graph, computed with METIS9, which minimizes the
number of edges across the partition’s blocks. The
p
summary is made of triples of the form B1
−→ B2 re-
ﬂecting that there exists a triple (s, p, o) in the input
graph with s a resource of the partition block B1 and
o a resource of the block B2. The proposed technique
does not consider implicit triples of the input RDF
graph and basically reﬂects how (some resources of)
sets of strongly connected triples, i.e., those reﬂected
by the partition blocks, are loosely connected. Then

9http://glaros.dtc.umn.edu/gkhome/metis/metis/

overview

23

at query time, the index is used to prune dangling
triples by identifying the bindings for the join vari-
ables in the query, which are later used to generate
results via the relational joins of the underlying sys-
tem.

[54] builds RDF graph summaries meant to help
answer keyword queries in RDF graphs. As common
in this setting, a match is a tree of interconnected
RDF triples, such that each keyword from the query
is present in one of the triples; the score of a query
match is consisted of several keywords and decreases
with the number of edges (triples) in this tree, that is,
the closest the nodes (thus, the smaller the tree) the
better; and the answer to the query is the set of the
highest-scoring matches. To enable eﬃcient query
answering, the authors build a summary as a collec-
tion of tree structures (see below), each representing
a subset of the graph triples; the summary trees, to-
gether, represent all graph triples. Given a summary
tree, the authors estimate the length of a path which
may connect the tree with the nodes matching diﬀer-
ent query keywords. If the result tree has a length
larger than one already found, there is no reason of
visiting the nodes of this tree. To summarize an RDF
graph (the authors consider a restricted setting where
each resource has at most one type), they proceed as
follows. (i) For each type T and each resource r of
this type, given a user-speciﬁed integer parameter α,
a partition block is created comprising of the triples
forming paths of length at most α from r, except the
triples included in previously built partition blocks.
(ii) Next, they search for a partition block (sub-graph
of G) which can be embedded via homomorphism into
another, and when this happens, they discard the for-
mer (as it can be considered to be “suﬃciently well
represented” by the latter). More speciﬁcally, each
partition is represented by its graph core, and homo-
morphisms are identiﬁed between cores; for eﬃciency,
covering trees of sub-graphs are used instead of the
subgraphs themselves. Overall, this technique does
not consider RDF Schema nor implicit information.

5.2.4 Oriented towards schema extraction

In this subsection we focus on methods that try to
creata schema-like structures of the available data

sources.

One of the challenges when working with Linked
Open Data is the lack of a concise schema, or a clear
description of the data that can be found in the data
source. SchemEX [49, 50], an indexing and schema
extraction tool for the LOD cloud, attempts to solve
this problem. Out of an RDF graph, it produces a
three-layered index, based on resource types. Each
layer groups input data sources of the LOD cloud
into nodes, as follows: (i) in the ﬁrst layer, each node
is a single class c from the input, to which, the data
sources containing triples whose subject is of type c
are associated; (ii) in the second layer, each node,
now named as an RDF type cluster, is a set of classes
C mapped to those data sources having instances
whose exact set of types is C; (iii) in the third layer,
each node is an equivalence class, where: two nodes
u and v from the input belong to the same equiva-
lence class if and only if they have the exact same
set of types, they are both subjects of the same data
property p, and the objects of that property p belong
to the same RDF type cluster. Further, each equiva-
lence class is mapped to all data sources comprising of
triples (s, p, o) from an input RDF graph, such that s
belongs to the equivalence class of the node. To build
the index, a stream-based computation approach is
proposed, depicted in Fig. 10. The restriction to a
certain window size of the data stream typically leads
to incomplete results, thus the choice of the appro-
priate window size is an essential parameter for the
quality of the extracted index. The speciﬁc approach
does not consider implicit triples, nor untyped re-
sources. In addition, the resulting index is not a quo-
tient, since in each layer data sources may be mapped
to multiple index nodes (while a quotient partitions
the graph nodes). Finally the time complexity of the
approach is O(N ∗ logN ) or O(M ∗ logM ), where N
is the number of RDF classes available and M is the
number of properties.

Towards the same goal of building a compact rep-
resentation of an RDF graph to be used as a schema,
[39] proposes an approach to extract a schema-like di-
rected graph, as follows. A density-based clustering
algorithm is used on the input RDF graph to iden-
tify the summary nodes: each such node, called a
(derived) type, corresponds to a set of resources with

24

Figure 10: Graph compression technique for SchemEX.

suﬃcient structural similarity. Further, each of these
types is described by a proﬁle, i.e., a set of (property,
probability) pairs of the form (−→p , α) or (←−p , α) mean-
ing that a resource of that type has the outgoing or in-
coming property p with probability α. These proﬁles
are used to deﬁne output schema edges of two kinds:
(i) There is a p-labeled edge from a type node T1 to
p
a type node T2, i.e., T1
−→ T2, whenever p is an out-
going property of T1’s proﬁle and an incoming prop-
erty of T2’s proﬁle. (ii) There is an rdfs:subClassOf-
labeled edge from a type node T1 to a type node T2,
rdfs:subClassOf
i.e., T1
−−−−−−−−−−→ T2, whenever T1 is found more
speciﬁc than T2 by an ascending hierarchical clus-
tering algorithm applied to their proﬁles. The time
complexity of the corresponding algorithm is O(N 2)
where N is the number of entities in the dataset. The
output directed graph can be seen as a summary de-
scribing ﬁrst, types which correspond to structurally
similar resources, and second, how properties relate
resources of various types.

6 Pattern-based RDF summa-

rization

In this section we review summarization methods
based on data mining techniques, which extract
the frequent patterns from the RDF graph, and
use these patterns to represent the original RDF
graph. A frequent pattern, usually referred to as
a knowledge pattern in the RDF/OWL KB con-

text (or simply pattern from now on), character-
izes a set of instances in an RDF data graph that
share a common set of types and a common set of
properties.
It is usually modeled as a star BGP
of the form {(x, τ, c1), . . . , (x, τ, cn), (x, P r1, ?b1), . . . ,
(x, P rm, ?bm)} denoting some resource x having
types c1, . . . , cn and properties P r1, . . . , P rm. Given
an RDF graph G, a pattern KP identiﬁes all the G
resources that match x in the embeddings of KP into
G; the number of such embeddings is called the sup-
port of KP in G. Patterns identiﬁed in such a manner
become representative nodes (supernodes).

sample RDF graph G presented in
knowledge pattern

Example 6 (Knowledge pattern) Consider
again our
Figure 1.
{(x, τ, Publication), (x, hasTitle, y), (x, hasAuthor, z)}
has no support in G and a support of 1 in G∞ (when
the embedding matches x to doi1).

following

The

An overview of the works in this category is shown
in Table 5. Section 6.1 discusses methods that exploit
mining graph patterns, while Section 6.2 is concerned
with methods which summarize the RDF graph based
on rules derived from mining techniques.

6.1 Mining graph patterns

In this section we describe methods that exploit pat-
terns that eventually appear in the RDF graph and
construct the summary based on these patterns.

25

Figure 11: Zneika et al. approach. [121]

[121, 120] present an approach for RDF graph sum-
marization based on mining a set of approximate
graph patterns that “best” represent the input graph;
the summary is an RDF graph itself, which allows to
take advantage of SPARQL to evaluate (simpliﬁed)
queries on the summary instead of the original graph.
The approach proceeds in three steps, as shown in
Fig. 11. First, the RDF graph is transformed into
a binary matrix. In this matrix the rows represent
the subjects and the columns represent the predi-
cates. The semantics of the information is preserved,
by capturing the available distinct types and all at-
tributes and properties (capturing property partici-
pation both as subject and object for an instance).
Second, the matrix created in the previous step, is
used in a calibrated version of the PaNDa+ [61] al-
gorithm, which allows to retrieve the best approx-
imate RDF graph patterns, based on diﬀerent cost
functions. Each extracted pattern identiﬁes a set of
subjects (rows), all having approximately the same
properties (columns). The patterns are extracted so
as to minimize errors and to maximize the coverage
(i.e. provide a richer description) of the input data.
A pattern thus encompasses a set of concepts (type,
property, attribute) of the RDF dataset, holding at
the same time information about the number of in-
stances that support this set of concepts. Based on
the extracted patterns and the binary matrix, the
summary is reconstructed as an RDF graph, enriched
with the computed statistic information; this enables

SPARQL query evaluation on the summary to re-
turn approximate answers to queries asked on the
original graph. The time complexity of the approach
is O(M ∗ N + K ∗ M 2 ∗ N ), where K is the max-
imum number of patterns to be extracted, M and
N are respectively the number of distinct properties
and subjects/resources in the original KB. The au-
thors note that the algorithm works equally well on
homogeneous and heterogeneous RDF graphs.

In [91], the goal is to discover the k patterns which
maximize an informativeness measure (an informa-
tiveness score function is provided as input). The
algorithm takes as input an integer distance in d,
which will be used to control the neighborhoods in
which we will look for similar entities, and a bound
k as the maximum number of the desired patterns.
The algorithm discovers the k d-summaries/patterns
that maximize the informativeness score function.

The authors use d-similarity to capture similarity
between entities in terms of their labels and neigh-
borhood information up to the distance d. Com-
pared to other graph patterns like frequent graph pat-
terns, (bi)simulation-based, dual- simulation-based
and neighborhood-based summaries, d-similarity of-
fers greater ﬂexibility in matching, while it takes into
account the extended neighborhood, something that
provides better summaries especially for schema-less
knowledge graphs, where similar entities that are not
equivalent in a strict pairwise manner. A node v of
the original graph G is attributed to the base graph

26

of the d-summary P if and only if there is a node
u of P which has the same label as v and for every
parent/child u1 of u in P , there exists a parent/child
v1 of v in G such that edges (u1, u) and (v1, v) have
the same edge label. Then the d-summaries are used
e.g. to facilitate query answering.

A d-summary P is said to dominate another d-
summary P (cid:48) if and only if supp(P ) ≥ supp(P (cid:48)); a
maximal d-summary P is one that dominates any
summary P (cid:48) that may be obtained from P by adding
one more edge. The algorithm starts by discovering
all maximal d-summaries by mining and verifying all
k-subsets of summaries for the input graph G, then
greedily adds a summary pair (P, P 1) that brings the
greatest increase to the informativeness score of the
summary. The time complexity of the approach is
O(S ∗ (b + N ) ∗ (b + M ) + K
2 ∗ S2), where N , M
are respectively the total number of nodes (subject
and objects) and edges (triples) of the original RDF
graph, and S is the number of possible d-summaries
whose size is bounded by b.

The authors leverage the Apriori [2] or FP-Growth
[31] frequent pattern mining algorithms, to identify
sets of association rules. First, for each property
p, a “transaction” (in classical data mining terms)
is a list of objects which are the values of prop-
erty p for a given subject. Each rule thus is de-
ﬁned by: a property p, an object item k, and a fre-
quent itemset x associated with k. One sample rule
is: ∀x, (x, p, k) → (cid:86)n
i=1(x, p, vi), stating that the
subjects that carry the value k for property p, carry
also the values ui for the same property. Based on
such a rule, the triple (x, p, k) is encoded in the sum-
mary while the inferred triples (cid:86)n
i=1(x, p, vi) can be
removed. Further, the authors extend the approach
to use as a transaction, the lists of all (p, o) pairs for
a given subject, and similarly mine for frequent item-
sets in this context, each of which will be interpreted
as a logical compression rule.

6.2 Mining rules

Methods described here use rule mining techniques
in order to extract rules for summarizing the RDF
graph. A common limitation of such methods is that,
by design, the summary is not an RDF graph, thus
it cannot be exploited using the common set of RDF
tools (e.g., SPARQL querying, reasoning etc.)

[36, 35] propose compressing the RDF datasets re-
moving triples that can be inferred using logical and
inference rules. Thus, graph decompression infers
such triples again, to retrieve the original graph.

This approach, which is depicted in Fig. 12, gen-
erates, from a given RDF graph G, an active graph
GA containing the triples that adhere to certain log-
ical rules, and a dormant graph GD, which contains
the set of triples of the original graph which none
of the identiﬁed rule can infer. This leads to view-
ing an RDF graph G as being R(GA) ∪ GD, where
R represents the set of rules to be applied to the ac-
tive graph GA, while (GA, GD) together represent the
compressed graph. An association rule mining algo-
rithm is employed to automatically identify the set
of logical rules.

The speciﬁc approach works well when the original
graph contains many diﬀerent nodes, sharing many
same “neighbors”, but it is not eﬀective when the
contrary is true. To deal with the last issue, the
authors of [74] extend the previous approach by ex-
ploiting a graph pattern with two variables instead of
one, which makes it applicable to more generic graph
structures, reducing the size of the summary graph.
This is because the number of triples in the sum-
mary graph is halved (a rule can now represent more
triples). The time complexity of the two previous ap-
proaches is O(M ∗ R + Np ∗ O2
v ∗ Ns), where M is the
total number of triples, R is the number of the gen-
erated logical rules, Np and Ns are respectively the
number of distinct properties and subjects/resources
in the graph and Ov is the average number of diﬀer-
ent objects/values that are assigned to a property p
(we should remember that we are looking for common
neighbours and thus for common values for the prop-
erties in the object/value part, (s, p, o) or (s, p, v) in
the triple notation); thus the lower the average num-
ber of diﬀerent values the more common the neigh-
bourhood and the better the algorithm behaves as
already stated earlier.

27

Figure 12: Graph compression technique for Joshi et al. [36].

Figure 13: Graph compression framework following [74].

7 Statistical summarization

The works we discuss here focus on quantitatively
summarization of the contents of an RDF graph. An
overview is shown in Table 6.

A ﬁrst motivation for statistical summarization
works comes from the source selection problem. In
general, statistical methods are interested in provid-
ing quantitative statistics on the content of the KBs
in order to decide if it is pertinent to use the KB or
not. In that respect, compared to the pattern mining
category (which is conceptually close) and the other
categories, it has the advantage not to care too much
about issues of structural completeness of the sum-

mary and thus reducing computational costs. Early
works in this area [5, 89] use SPARQL ASK queries
to identify whether a triple pattern exists in a source
node or not, and query those sources only in a subse-
quent step. The main problem of this solution is that
many sources might contain the same facts, meaning
that we will have many duplicate results and there-
fore many unnecessary requests. The authors of [33]
propose to expand ASK queries in order not to return
a boolean answer, but a concise summary of the re-
sult, in the form of Bloom ﬁlters [7]. Based on these
summaries, a corresponding algorithm estimates the
beneﬁt of retrieving results for a triple pattern from
a speciﬁc source, ignoring sources with low or zero

28

beneﬁt. The summaries produced are called sketches,
and include statistical information on the instances.
In this approach, input is not required from the users.
Another approach, which seeks to identify the most
important resources in an ontology, is [111]. The
proposed algorithm, named Concept-And-Relation-
Ranking, does not consider instances and tries to
identify the most important schema concepts and re-
lations in an iterative manner. The importance of a
concept is a combination of the number of relations
starting from it, its relations to more important con-
cepts, and the weights of these relations. The more
important the concept at the source of a relation, the
higher the weight of the relation. The importance of
nodes and the weights of the relations reinforce one
another in an iterative process. The approach con-
siders implicit and semantic information as well; it
is based on an ontology graph model to which RDF,
DAML+OIL and OWL ontologies can be mapped.

[79] proposes an method to automatically summa-
rize local ontologies that are used as schemas of peers
participating in a peer-to-peer system. The goal is to
help peer clustering, where an incoming peer must
search for semantically similar peers in order to join.
To do that, a schema summary of the new node is
compared with the schema summaries of the existing
peers in order to decide where to join.

In order to determine the relevance of a concept,
two measures are combined: centrality and frequency.
Centrality is an adaptation of the degree central-
ity; diﬀerent weights can be assigned to user-deﬁned
properties, on one hand, and to the special proper-
ties isA (RDFS subclassOf), partOf and sameAs; fre-
quency is the ratio between the number of concept
correspondences and the number of distinct local on-
tologies. The algorithm starts by computing the rel-
evance, then it selects the top-k nodes, and subse-
quently groups adjacent relevant concepts. Finally,
in order to link non-adjacent groups, the ﬁrst k-paths
connecting them are examined in order to select the
ones that have the best f -measure and average rel-
evance. The approach does not consider the data
triples of the input graph, nor the implicit triples.
However, it supports OWL ontologies. Using it re-
quires setting the values of a set of parameters and
weights, in particular to determine the importance of

diﬀerent properties, to compute the relevance, to de-
termine the summary size etc. The tool is available
online for download10.

LODSight [21] is an RDF dataset summary visu-
alization tool that displays typical combinations of
types and predicates.
It relies solely on SPARQL
queries and as such, given a SPARQL endpoint, it can
theoretically summarize all accessible data, without
requiring any user input. Through those SPARQL
queries, it collects statistical information on the avail-
able combinations of types and predicates, and visu-
alizes them in a labelled graph. Implicit RDF data
is only accounted for to the extent that the endpoint
returns full answers based on reasoning. The tool
provides dynamic means of changing the level of de-
tails, and is able to summarize very large datasets.
The system is available online11.

LODSight was extended in [68] in order to further
improve the understanding of a dataset, by instanti-
ating the summary patterns identiﬁed by LODSight.
To do that, the authors propose an approach to se-
lect instances through three methods, namely ran-
dom, distinct and representative.
In random selec-
tion, random examples of each RDF summary path
are selected; this runs the risk of returning dupli-
cates. The distance selection method aims to select
data paths as distinct from one another as possible;
to this eﬀect, distance measures are used to ﬁnd how
similar two paths are, and a greedy heuristic is em-
ployed to construct a suﬃciently diverse set of pairs.
The representation selection method combines diver-
sity and representativeness criteria in order to select
a set of paths achieving a comprehensive result. The
selection method is available as a web service 12.

[81] proposes a dataset analysis method based on
recognizing and discovering patterns. The aim of this
method is to support query answering. As such, the
authors create initially an ontology that depicts the
organization of the dataset and identiﬁes its main fea-
tures, i.e. information about triples, paths, and types
and properties occurring in the paths. In addition,
it includes statistics about these elements, such as

10http://www.cin.ufpe.br/~speed/OWLSummarizer/
11http://lod2-dev.vse.cz/lodsight/about.html
12https://github.com/jindrichmynarz/

rdf-path-examples

29

the number of occurrences of each path. Using this
ontology, the core types and properties can be distin-
guished based on their frequencies and the position
in paths. According to these observations, central
knowledge patterns (containing a central type and
properties) are extracted in order to deﬁne prototyp-
ical queries.
Implicit information is not taken into
account.

8 Other summarization meth-

ods

In this section, we present approaches that combine
methods from the structural, statistical and pattern-
mining categories in order to get better results. In
addition, there are methods going beyond RDF graph
summaries, for example summarizing DL ontologies.
An overview of the works in this category is shown
in Table 7.

[3] proposes a hybrid structural summarization
technique for RDF graphs, the purpose of which is
to reduce their size while retaining their structure
as much as possible. It consists of a graph quotient
step followed by a graph clustering step. The ﬁrst
one adopts bounded forward bisimulation, as accord-
ing to the authors, previous studies showed that, in
general, unbounded bisimulation is not amenable to
signiﬁcant graph size reduction. This intermediate
graph being a quotient, it represents all the N nodes
and M edges of the input graph, and is computed in
O(M ∗N +N 2). It is then further compressed by hier-
archical clustering, which fuses root nodes of similar
depth-bounded tree subgraphs. This is achieved with
the so-called Complete-Link Clustering algorithm in
O(N 2) [67], where N is the number of nodes of the
aforementioned intermediate graph. This technique
produces a standard graph out of an RDF one, with-
out user input, which summarizes the whole input
graph (nodes and edges). However, it does not per-
form particular treatment on RDF Schema triples,
hence does not capture the implicit triples they en-
tail, unless input RDF graph are saturated prior to
summarization.

for RDF graphs (and OWL KBs), which aims at re-
ﬂecting how class instances are related through prop-
erties. A summary is not a graph but a set of abstract
knowledge patterns (AKPs) of the form (c1, p, c2) rep-
resenting the (s, p, o) graph triples with c1 (resp. c2)
one of the most speciﬁc types of s (resp. o); there
may have several such c1, c2 pairs for a given prop-
erty p. An ABSTAT summary is built in polynomial
time in the size of the input RDF graph, by ﬁrst
computing for every value presents in the graph all
its types, from which are pruned out the redundant
ones. Then, for each property assertion (s, p, o), an
AKP (c1, p, c2) is built if c1 (resp. c2) is a most spe-
ciﬁc type for value s (resp. o). ABSTAT is available
online13.

[94] proposes to use structural summaries of RDF
graphs for estimating the cardinality of conjunctive
queries. The authors build a graph summary of an
RDF graph by grouping together nodes having ex-
actly the same set of types, same outgoing and same
incoming properties. A summary edge is labeled with
the number of edges of G that have been collapsed
due to merging (thus, the summary is not a quo-
tient). The classes (appearing in the object position
of type triples), and properties appearing in the prop-
erty position are preserved, i.e., they are represented
in the summary by themselves. However, properties
appearing in the subject/object positions are not pre-
served; moreover, possible RDFS properties are sum-
marized just as any other data property, thus the
schema is not conserved either. These summaries,
built in time linear in M , the number of graph edges,
may be too large; therefore, the authors propose an
algorithm to reduce the summary to a target size
speciﬁed by the user, by merging nodes having simi-
lar incoming and outgoing properties. The similarity
is determined by a Jaccard index, approximated by
MinHashing [56]; to eﬃciently compute the similarity
between all pairs of summary nodes, locality-sensitive
hashing [56] is used. The approach gets as input only
instances and optional parameters for summary re-
ﬁnement and returns an instance graph. This graph
is further used to enable the estimation of the cardi-
nality for easing query answering and evaluation.

ABSTAT [73, 92, 93] is a summarization method

13http://abstat.disco.unimib.it/search

30

[77] combines structural non-quotient and statisti-
cal methods to create a summary of an RDF graph,
which they call relational schema. The initial sum-
mary is generated, in linear time of the RDF graph
size (average complexity), by computing sets of prop-
erties joining on the subject, the so called character-
istic sets, denoted CS. A summary node is created
for each CS, thus representing nodes of G having the
same outgoing properties. An edge exists between
two summary nodes, labeled by a property p, if there
exist two G nodes in their respective extents, such
that there exists an edge labeled by p in G between
the two G nodes. This structural aspect therefore
considers only the instance component of an RDF
graph.
In the second step, a short human-friendly
label is computed for summary nodes and edges, by
relying on type triples, or in their absence, on ontol-
ogy information. To reduce the summary size, sum-
mary nodes are subsequently merged.
In semantic
merging, two summary nodes can be merged in two
ways: (i) if they have the same label, taken from an
ontology, or (ii) if their labels, originating from dif-
ferent ontologies, have a common superclass, and the
generality score of this superclass is lower than a cer-
tain threshold. The generality score of an ontology
class v is computed as the ratio between the number
of instances of v’s subclasses and the total number of
instances covered by the ontology to which v belongs.
Moreover, the two ways in which two summary nodes
can be merged in structural merging are as follows:
(i) if they both have an incoming edge with the same
property, from another summary node, or (ii) if the
properties in their respective CSs have the TF/IDF
similarity score higher than a given threshold. The
merging order of the nodes, aﬀects the resulting sum-
mary. The summary is modeled relationally: a ta-
ble is created per summary node, with a column for
each property in the CS represented by the summary
node; the relationships between the nodes are stored
as foreign keys. The chosen relational model proves
challenging for storing the possibly highly heteroge-
neous graph structure, inherent to RDF graphs, and
it drives the modiﬁcations to the summary. First, the
CS of each summary node may be a result of merging
multiple summary nodes and thus their CSs. There-
fore, a G node in the extent of a summary node may

not have a value for each property in the CS of the
summary node, and will have a NULL value in the
table for each such property. Properties having few
non-NULL values are deleted. Second, a single prop-
erty in RDF may have multiple literal values, possibly
of diﬀerent types. In such cases, [77] chooses to add a
column for each distinct literal value type per prop-
erty, which other than incurring space costs, may lead
to more NULL values. Therefore, for each literal value
type below the infrequency threshold, all triples are
moved to a separate single PSO table. Finally, infre-
quent edges are deleted from the summary, while a
summary node is deleted if the number of nodes it
represents is below a threshold; with the exception
of summary nodes which are referred to many times
from other tables. The approach relies on end-users
for choosing the right parameters whereas, the au-
thors propose also an auto-tuning algorithm for de-
termining the best value of the similarity threshold.
[119] proposes a framework for mining equivalent
structure patterns with equivalent semantic mean-
ing. As in RDF KBs, it is common to have diﬀer-
ent graph structures, sharing the same meaning, the
authors’ aim is to ease end-user’s querying task. As
such, instead of demanding from the users to have
the complete knowledge of the schema - enumerat-
ing in the query all possible semantically equivalent
graph structures -. the authors propose an approach
that performs query rewriting, exploiting automati-
cally other possible graph structures with the same
meaning. To achieve that, they deﬁne the notion of
semantic graph edit distance and present a framework
that tries ﬁrst to rewrite the input query to one con-
sidering semantic equivalences and then ﬁnding the
subgraphs minimizing the semantic graph edit dis-
tance. For eﬃciency, they build oﬄine a semantic
summary graph over which they perform a two-level
pruning at query time in order to ﬁnally provide an-
swers. The semantic summary graph is a multi-layer
graph where the ﬁrst layer is consisted of the linked
types of the instances (they call them semantic facts).
Then, they abstract this graph in the layers above,
replacing/abstracting in each layer classes with their
superclass. The summary produced does not require
user input to be produced, whereas the aforemen-
tioned method can only be applied in fully typed

31

RDF KBs.

9 Conclusions

and

Future

Finally, the next works consider structural meth-
ods for the summarization of ABoxes (facts) in de-
scription logics KBs.

[25] proposes a method for compressing (hence
summarizing) the ABox of a Horn-ALCHOI de-
scription logic KBs, using the notion of ABox
abstraction. Given an ABox A, for each A value v,
a type pattern of the form tp(v) = (tp↓, tp→, tp←)
is computed, where tp↓ denotes the explicit types
v has in A (C’s such that C(v) ∈ A), tp→ the
outgoing properties v has in A (R’s such that
R(v, v(cid:48)) ∈ A) and tp← the incoming properties v
has in A (S’s such that S(v(cid:48), v) ∈ A). These type
patterns are then used to build the abstraction B
of the ABox, which is an ABox itself; each such
type pattern is used to represent all the ABox
values that match it:
for every type pattern tp =
({C1, . . . , Cm}, {R1, . . . , Rn}, {S1, . . . , Sl}), B con-
tains {C1(xtp), . . . , Cm(xtp), R1(xtp, yR1
S1(yS1
tp , xtp)}. We remark that,
given an ABox, its abstraction is simply obtained
by traversing its facts.
It is further shown in
[25] how the abstraction of the ABox of an input
Horn-ALCHOI KB can be gradually reﬁned, using
reasoning steps, to obtain the abstraction of the
ABox of the input KB saturation.

tp , xtp), . . . , Sl(ySl

tp ), . . . , Rn(xtp, yRn

ABox summaries has also been considered for
the data management tasks of consistency checking
[24, 23] and query answering [19, 20] in SHIN KBs.
In these works, the notion of a summary ABox is very
general: an ABox A(cid:48) is a summary of another ABox
A w.r.t. some function f that maps A values to A(cid:48)
ones whenever f deﬁnes a homomorphism from A to
A(cid:48). Based on this property of ABox summaries, the
purpose of [24, 23, 19, 20] is to study how SHIN con-
sistency and query answering reasoning techniques
can be performed correctly and more eﬃciently than
when handling the input ABox.

32

Work

In this survey, we present a comprehensive state-of-
the-art in semantic graph summarization. To this di-
rection, we introduce a taxonomy of the works in the
area (based on diﬀerent properties/criteria that the
works adhere to), that can help practitioners and re-
searchers to determine the method most suitable for
their data and goal. In this taxonomy, we grouped
the main methods of the algorithms presented into
four main categories structural, statistical, pattern-
mining and hybrid, identifying subcategories when-
ever possible. In addition we also classiﬁed works in
the ﬁeld according to their input, output, availabil-
ity on the internet and purpose, showing the rapidly
evolving dynamics in the area.

In general, RDF graph summaries can be useful in
various application scenarios ranging from data un-
derstanding to query answering and from RDF graph
data indexing to RDF graph visualization. Struc-
tural quotient summaries are most applicable to in-
dexing and query answering through graph reduc-
tp ),
tion; this holds especially for quotients built through
equivalence relations such as bisimilarity (possibly
bounded). Non-quotient summaries mostly target vi-
sualization, schema discovery and data understand-
ing. Pattern mining summaries provide in many cases
logical rules besides the summary graph as part of
the ﬁnal result, so could be possibly more useful in
RDF graph compression scenarios. Summaries could
also be really useful in data integration scenarios [48],
where instead of generating mappings [63], [65] be-
tween data source schemas, summaries could be used
to drive the deﬁnition of the mapping. Extending
this to a scenario where the sources can also evolve
[47], [46], summaries can play a key role in schema
understanding and mapping redeﬁnition. Diﬀerent
RDF summarization scenarios each bring their very
speciﬁc requirements (e.g., whether the summary size
is bounded or not, whether a schema is present or
not, whether to summarize the data or the schema,
whether the summary needs to reﬂect all the struc-
ture or not etc.); in many cases more than one al-
gorithm or family of algorithms will provide suitable

results. The goal of our survey was to provide enough
information to the users of these algorithms (i.e. ap-
plication developers or researchers) in order to be
able to easily refer to the characteristics of each ap-
proach, and evaluate their suitability to their appli-
cation requirements.

Despite the considerable amount of work in the
area of semantic graph summarization, there still are
many important open problems in the ﬁeld. Below
we mention two of the most notable ones.

The ﬁrst one is the quality of the produced RDF
summary. Since the result summary for the diﬀerent
algorithms, varies among a selection of nodes, quo-
tients, some other frequency structure or a complete
graph with various types of nodes and links identify-
ing a single golden standard is a complex task. On
the other hand, even domain experts in many cases
disagree on which speciﬁc elements should be selected
in a semantic summary. However, having in mind our
proposed taxonomy we believe that the next step in
the area is the establishment of diﬀerent golden stan-
dards speciﬁc to each subcategory focusing on speciﬁc
purpose input and output.

Another open issue we perceive as really impor-
tant, is the dynamic nature of all these datasets. As
new information becomes available due to new ex-
perimental evidence or observations and erroneous
past conceptualizations are constantly updated many
datasets are rapidly changing. However, summa-
rization in most cases and especially for big data
sources is a time-consuming process that should be
constantly updated to facilitate data exploration. As
such, novel ideas should focus in this dynamicity, aug-
menting the exploration experience of end users.

The work in RDF graph summarization gains more
importance as the RDF Knowledge Bases become
larger and more connected and thus we expect to see
additional advances in the ﬁeld in the near future.
Acknowledgments This research is implemented
through IKY scholarships programme and co-
ﬁnanced by the European Union and Greek national
funds through the action entitled ”Reinforcement of
Postdoctoral Researchers”, in the framework of the
Operational Programme ”Human Resources Devel-
opment Program, Education and Life-long Learn-
ing” of the National Strategic Reference Framework

(NSRF) 2014-2020.

References

[1] Abiteboul, S., Hull, R., Vianu, V.: Foundations of

Databases. Addison-Wesley (1995)

[2] Agrawal, R., Imielinski, T., Swami, A.N.: Mining associ-
ation rules between sets of items in large databases. In:
Proceedings of the 1993 ACM SIGMOD International
Conference on Management of Data, Washington, DC,
USA, May 26-28, 1993., pp. 207–216 (1993)

[3] Alzogbi, A., Lausen, G.: Similar structures inside rdf-
graphs.
In: Proceedings of the WWW2013 Workshop
on Linked Data on the Web, Rio de Janeiro, Brazil, 14
May, 2013 (2013)

[4] Baader, F., Calvanese, D., McGuinness, D.L., Nardi,
D., Patel-Schneider, P.F. (eds.): The Description Logic
Handbook: Theory, Implementation, and Applications.
Cambridge University Press (2003)

[5] Basca, C., Bernstein, A.: Avalanche: Putting the spirit
of the web back into semantic web querying. In: Pro-
ceedings of the ISWC 2010 Posters & Demonstrations
Track: Collected Abstracts, Shanghai, China, Novem-
ber 9, 2010 (2010)

[6] Blom, S., Orzan, S.: A distributed algorithm for strong
bisimulation reduction of state spaces. STTT 7(1), 74–
86 (2005)

[7] Bloom, B.H.: Space/time trade-oﬀs in hash coding with
allowable errors. Commun. ACM 13(7), 422–426 (1970)

[8] Boldi, P., Vigna, S.: Axioms for centrality.

Internet

Mathematics 10(3-4), 222–262 (2014)

[9] Bursztyn, D., Goasdou´e, F., Manolescu, I.: Eﬃcient
query answering in dl-lite through FOL reformulation
(extended abstract). In: Proceedings of the 28th Interna-
tional Workshop on Description Logics, Athens,Greece,
June 7-10, 2015. (2015)

[10] Calvanese, D., De Giacomo, G., Lembo, D., Lenzerini,
M., Rosati, R.: Tractable reasoning and eﬃcient query
answering in description logics: The DL-Lite family. J.
Autom. Reasoning 39(3), 385–429 (2007)

[11] Campinas, S., Perry, T., Ceccarelli, D., Delbru, R., Tum-
marello, G.: Introducing RDF graph summary with ap-
plication to assisted SPARQL formulation. In: 23rd In-
ternational Workshop on Database and Expert Systems
Applications, DEXA 2012, Vienna, Austria, September
3-7, 2012, pp. 261–266 (2012)

[12] ˇCebiri´c, ˇS., Goasdou´e, F., Guzewicz, P., Manolescu,
I.: Compact Summaries of Rich Heterogeneous Graphs.
Research Report RR-8920, INRIA Saclay ; Univer-
sit´e Rennes 1 (2017). URL https://hal.inria.fr/
hal-01325900

33

[13] ˇCebiri´c, ˇS., Goasdou´e, F., Manolescu, I.: Query-oriented
summarization of RDF graphs. PVLDB 8(12), 2012–
2015 (2015)

[14] Cebiric, S., Goasdou´e, F., Manolescu, I.: Query-oriented
summarization of RDF graphs. In: Data Science - 30th
British International Conference on Databases, BICOD
2015, Edinburgh, UK, July 6-8, 2015, Proceedings, pp.
87–91 (2015)

[15] Chen, C., Lin, C.X., Fredrikson, M., Christodorescu, M.,
Yan, X., Han, J.: Mining graph patterns eﬃciently via
randomized summaries. PVLDB 2(1) (2009)

[16] Chen, C., Yan, X., Zhu, F., Han, J., Yu, P.S.: Graph
OLAP: towards online analytical processing on graphs.
In: Proceedings of the 8th IEEE International Confer-
ence on Data Mining (ICDM 2008), December 15-19,
2008, Pisa, Italy (2008)

[17] Consens, M.P., Fionda, V., Khatchadourian, S., Pirr`o,
G.: S+epps: Construct and explore bisimulation sum-
maries, plus optimize navigational queries; all on exist-
ing SPARQL systems. PVLDB 8(12), 2028–2031 (2015)

[18] Consens, M.P., Miller, R.J., Rizzolo, F., Vaisman, A.A.:
Exploring XML web collections with DescribeX. TWEB
4(3), 11:1–11:46 (2010)

[19] Dolby, J., Fokoue, A., Kalyanpur, A., Kershenbaum,
A., Schonberg, E., Srinivas, K., Ma, L.: Scalable se-
mantic retrieval through summarization and reﬁnement.
In: Proceedings of the Twenty-Second AAAI Conference
on Artiﬁcial Intelligence, July 22-26, 2007, Vancouver,
British Columbia, Canada, pp. 299–304 (2007)

[20] Dolby, J., Fokoue, A., Kalyanpur, A., Schonberg,
E., Srinivas, K.: Scalable highly expressive reasoner
(SHER). J. Web Sem. 7(4), 357–361 (2009)

[21] Dud´as, M., Sv´atek, V., Mynarz, J.: Dataset summary vi-
sualization with lodsight. In: The Semantic Web: ESWC
2015 Satellite Events - ESWC 2015 Satellite Events Por-
toroˇz, Slovenia, May 31 - June 4, 2015, Revised Selected
Papers, pp. 36–40 (2015)

[22] Fan, W., Li, J., Wang, X., Wu, Y.: Query preserving
graph compression. In: Proceedings of the ACM SIG-
MOD International Conference on Management of Data,
SIGMOD 2012, Scottsdale, AZ, USA, May 20-24, 2012,
pp. 157–168 (2012)

[23] Fokoue, A., Kershenbaum, A., Ma, L.: SHIN abox re-
duction. In: Proceedings of the 2006 International Work-
shop on Description Logics (DL2006), Windermere, Lake
District, UK, May 30 - June 1, 2006 (2006)

[24] Fokoue, A., Kershenbaum, A., Ma, L., Schonberg, E.,
Srinivas, K.: The summary abox: Cutting ontologies
down to size. In: The Semantic Web - ISWC 2006, 5th
International Semantic Web Conference, ISWC 2006,
Athens, GA, USA, November 5-9, 2006, Proceedings,
pp. 343–356 (2006)

[25] Glimm, B., Kazakov, Y., Liebig, T., Tran, T., Vialard,
V.: Abstraction reﬁnement for ontology materialization.
In: The Semantic Web - ISWC 2014 - 13th International
Semantic Web Conference, Riva del Garda, Italy, Octo-
ber 19-23, 2014. Proceedings, Part II, pp. 180–195 (2014)
[26] Goasdou´e, F., Karanasos, K., Leblay, J., Manolescu, I.:
View selection in semantic web databases. PVLDB 5(2),
97–108 (2011)

[27] Goasdou´e, F., Manolescu, I., Roatis, A.: Eﬃcient query
answering against dynamic RDF databases.
In: Joint
2013 EDBT/ICDT Conferences, EDBT ’13 Proceedings,
Genoa, Italy, March 18-22, 2013, pp. 299–310 (2013)
[28] Goldman, R., Widom, J.: Dataguides: Enabling
query formulation and optimization in semistructured
databases. In: VLDB’97, Proceedings of 23rd Interna-
tional Conference on Very Large Data Bases, August
25-29, 1997, Athens, Greece, pp. 436–445 (1997)

[29] Gurajada, S., Seufert, S., Miliaraki, I., Theobald, M.:
Using graph summarization for join-ahead pruning in a
distributed RDF engine. In: Proceedings of the Sixth
Workshop on Semantic Web Information Management,
SWIM 2014, Snowbird, UT, USA, June 22-27, 2014
(2014)

[30] Hakimi, S.L.: Steiner’s problem in graphs and its impli-

cations. Networks 1(2), 113–133 (1971)

[31] Han, J., Pei, J., Yin, Y., Mao, R.: Mining frequent pat-
terns without candidate generation: A frequent-pattern
tree approach. Data Min. Knowl. Discov. 8(1), 53–87
(2004)

[32] Henzinger, M.R., Henzinger, T.A., Kopke, P.W.: Com-
In:
puting simulations on ﬁnite and inﬁnite graphs.
FOCS (1995)

[33] Hose, K., Schenkel, R.: Towards beneﬁt-based RDF
source selection for SPARQL queries. In: Proceedings of
the 4th International Workshop on Semantic Web Infor-
mation Management, SWIM 2012, Scottsdale, AZ, USA,
May 20, 2012, p. 2 (2012)

[34] Jiang, X., Zhang, X., Gao, F., Pu, C., Wang, P.:
Graph compression strategies for instance-focused se-
mantic mining. In: Linked Data and Knowledge Graph -
7th Chinese Semantic Web Symposium and 2nd Chinese
Web Science Conference, CSWS 2013, Shanghai, China,
August 12-16, 2013. Revised Selected Papers, pp. 50–61
(2013)

[35] Joshi, A.K., Hitzler, P., Dong, G.: Towards logical
linked data compression. In: Proceedings of the Joint
Workshop on Large and Heterogeneous Data and Quan-
titative Formalization in the Semantic Web, LHD+
SemQuant2012, at the 11th International Semantic Web
Conference, ISWC2012. Citeseer (2012)

[36] Joshi, A.K., Hitzler, P., Dong, G.: Logical linked data
compression.
In: The Semantic Web: Semantics and
Big Data, 10th International Conference, ESWC 2013,
Montpellier, France, May 26-30, 2013. Proceedings, pp.
170–184 (2013)

34

[37] Kaushik, R., Bohannon, P., Naughton, J.F., Korth,
H.F.: Covering indexes for branching path queries. In:
Proceedings of the 2002 ACM SIGMOD International
Conference on Management of Data, Madison, Wiscon-
sin, June 3-6, 2002, pp. 133–144 (2002)

[38] Kaushik, R., Shenoy, P., Bohannon, P., Gudes, E.: Ex-
ploiting local similarity for indexing paths in graph-
structured data.
In: Proceedings of the 18th Interna-
tional Conference on Data Engineering, San Jose, CA,
USA, February 26 - March 1, 2002, pp. 129–140 (2002)

[39] Kellou-Menouer, K., Kedad, Z.: Schema discovery in
RDF data sources. In: Conceptual Modeling - 34th In-
ternational Conference, ER 2015, Stockholm, Sweden,
October 19-22, 2015, Proceedings (2015)

[40] Khan, A., Bhowmick, S.S., Bonchi, F.: Summarizing
static and dynamic big graphs. PVLDB 10(12), 1981–
1984 (2017)

[41] Khan, K., Nawaz, W., Lee, Y.: Set-based approximate
approach for lossless graph summarization. Computing
97(12), 1185–1207 (2015)

[42] Khatchadourian, S., Consens, M.P.: Explod: Summary-
based exploration of interlinking and RDF usage in the
linked open data cloud.
In: The Semantic Web: Re-
search and Applications, 7th Extended Semantic Web
Conference, ESWC 2010, Heraklion, Crete, Greece, May
30 - June 3, 2010, Proceedings, Part II, pp. 272–287
(2010)

[43] Khatchadourian, S., Consens, M.P.: Exploring RDF us-
age and interlinking in the Linked Open Data Cloud
In: WWW2010 Workshop on Linked
using ExpLOD.
Data on the Web (LDOW) (2010)

[44] Khatchadourian, S., Consens, M.P.: Understanding bil-
lions of triples with usage summaries. Semantic Web
Challenge (2011)

[45] Khatchadourian, S., Consens, M.P.: Constructing bisim-
ulation summaries on a multi-core graph processing
framework. In: Proceedings of the Third International
Workshop on Graph Data Management Experiences and
Systems, GRADES 2015, Melbourne, VIC, Australia,
May 31 - June 4, 2015 (2015)

[46] Kondylakis, H., Plexousakis, D.: Ontology evolution in
data integration: Query rewriting to the rescue. In: Con-
ceptual Modeling - ER 2011, 30th International Confer-
ence, ER2011, Brussels, Belgium, October 31 - Novem-
ber 3, 2011. Proceedings, pp. 393–401 (2011)

[47] Kondylakis, H., Plexousakis, D.: Ontology evolution:
Assisting query migration. In: Conceptual Modeling -
31st International Conference ER 2012, Florence, Italy,
October 15-18, 2012. Proceedings, pp. 331–344 (2012)

[48] Kondylakis, H., Plexousakis, D.: Ontology evolution

without tears. J. Web Sem. 19, 42–58 (2013)

[49] Konrath, M., Gottron, T., Scherp, A.: Schemex–web-
scale indexed schema extraction of Linked Open Data.

Semantic Web Challenge, Submission to the Billion
Triple Track pp. 52–58 (2011)

[50] Konrath, M., Gottron, T., Staab, S., Scherp, A.:
Schemex - eﬃcient construction of a data catalogue by
stream-based indexing of linked data. J. Web Sem. 16,
52–58 (2012)

[51] Koutra, D., Kang, U., Vreeken, J., Faloutsos, C.: Sum-
marizing and understanding large graphs. Statistical
Analysis and Data Mining 8(3), 183–202 (2015)

[52] Kyrola, A., Blelloch, G.E., Guestrin, C.: Graphchi:
Large-scale graph computation on just a PC. In: 10th
USENIX Symposium on Operating Systems Design and
Implementation, OSDI 2012, Hollywood, CA, USA, Oc-
tober 8-10, 2012, pp. 31–46 (2012)

[53] Lanti, D., Rezk, M., Xiao, G., Calvanese, D.: The NPD
benchmark: Reality check for OBDA systems. In: Pro-
ceedings of the 18th International Conference on Extend-
ing Database Technology, EDBT 2015, Brussels, Bel-
gium, March 23-27, 2015., pp. 617–628 (2015)

[54] Le, W., Li, F., Kementsietsidis, A., Duan, S.: Scalable
keyword search on large RDF data. IEEE TKDE 26(11)
(2014)

[55] LeFevre, K., Terzi, E.: Grass: Graph structure sum-
marization. In: Proceedings of the SIAM International
Conference on Data Mining, SDM 2010, April 29 - May
1, 2010, Columbus, Ohio, USA, pp. 454–465 (2010)

[56] Leskovec, J., Rajaraman, A., Ullman, J.D.: Mining of
Massive Datasets, 2nd Ed. Cambridge University Press
(2014)

[57] Lin, S.D., Yeh, M.Y., Li, C.T.: Sampling and summa-

rization for social networks (tutorial) (2013)

[58] Liu, X., Tian, Y., He, Q., Lee, W., McPherson, J.:
Distributed graph summarization.
In: Proceedings of
the 23rd ACM International Conference on Conference
on Information and Knowledge Management, CIKM
2014, Shanghai, China, November 3-7, 2014, pp. 799–
808 (2014)

[59] Liu, Y., Safavi, T., Dighe, A., Koutra, D.: Graph sum-
marization methods and applications: A survey. ACM
Comput. Surv. 51(3), 62:1–62:34 (2018)

[60] Louati, A., Aufaure, M., Lechevallier, Y.: Graph aggre-
gation : Application to social networks. In: Advances in
Theory and Applications of High Dimensional and Sym-
bolic Data Analysis, HDSDA 2011, October 27-30, 2011,
Beihang University, Beijing, China, pp. 157–177 (2011)

[61] Lucchese, C., Orlando, S., Perego, R.: A unifying frame-
work for mining approximate top- \(k\) binary pat-
terns. IEEE Trans. Knowl. Data Eng. 26(12), 2900–2913
(2014)

[62] Luo, Y., Fletcher, G.H.L., Hidders, J., Wu, Y., Bra,
P.D.: External memory k-bisimulation reduction of big
graphs. In: 22nd ACM International Conference on In-
formation and Knowledge Management, CIKM’13, San

35

Francisco, CA, USA, October 27 - November 1, 2013,
pp. 919–928 (2013)

[63] Marketakis, Y., Minadakis, N., Kondylakis, H., Konso-
laki, K., Samaritakis, G., Theodoridou, M., Flouris, G.,
Doerr, M.: X3ML mapping framework for information
integration in cultural heritage and beyond. Int. J. on
Digital Libraries 18(4), 301–319 (2017)

[64] Milo, T., Suciu, D.: Index structures for path expres-
sions. In: Database Theory - ICDT ’99, 7th International
Conference, Jerusalem, Israel, January 10-12, 1999, Pro-
ceedings., pp. 277–295 (1999)

[65] Minadakis, N., Marketakis, Y., Kondylakis, H., Flouris,
G., Theodoridou, M., de Jong, G., Doerr, M.: X3ML
framework: An eﬀective suite for supporting data map-
pings.
In: Proceedings of the Workshop on Extend-
ing, Mapping and Focusing the CRM co-located with
19th International Conference on Theory and Practice
of Digital Libraries (2015), Pozna´n, Poland, September
17, 2015., pp. 1–12 (2015)

[66] Motta, E., Mulholland, P., Peroni, S., d’Aquin, M.,
G´omez-P´erez, J.M., Mendez, V., Zablith, F.: A novel
approach to visualizing and navigating ontologies.
In:
The Semantic Web - ISWC 2011 - 10th International
Semantic Web Conference, Bonn, Germany, October 23-
27, 2011, Proceedings, Part I, pp. 470–486 (2011)

[67] Murtagh, F.: A survey of recent advances in hierarchical
clustering algorithms. Comput. J. 26(4), 354–359 (1983)

[68] Mynarz, J., Dud´as, M., Tomeo, P., Sv´atek, V.: Gener-
ating examples of paths summarizing RDF datasets. In:
Joint Proceedings of the Posters and Demos Track of
the 12th International Conference on Semantic Systems
- SEMANTiCS2016 and the 1st International Work-
shop on Semantic Change & Evolving Semantics (SuC-
CESS’16) co-located with the 12th International Confer-
ence on Semantic Systems (SEMANTiCS 2016), Leipzig,
Germany, September 12-15, 2016. (2016)

[69] Navlakha, S., Rastogi, R., Shrivastava, N.: Graph sum-
marization with bounded error. In: Proceedings of the
ACM SIGMOD International Conference on Manage-
ment of Data, SIGMOD 2008, Vancouver, BC, Canada,
June 10-12, 2008 (2008)

[70] Neumann, T., Weikum, G.: The RDF-3X engine for scal-
able management of RDF data. VLDB J. 19(1), 91–113
(2010)

[71] Paige, R., Tarjan, R.E.: Three partition reﬁnement al-
gorithms. SIAM J. Comput. 16(6), 973–989 (1987)

[72] Paige, R., Tarjan, R.E.: Three partition reﬁnement al-
gorithms. SIAM J. Comput. 16(6), 973–989 (1987)

[73] Palmonari, M., Rula, A., Porrini, R., Maurino, A.,
linked data sum-
Spahiu, B., Ferme, V.: ABSTAT:
maries with abstraction and statistics. In: The Semantic
Web: ESWC 2015 Satellite Events - ESWC 2015 Satel-
lite Events Portoroˇz, Slovenia, May 31 - June 4, 2015,
Revised Selected Papers, pp. 128–132 (2015)

[74] Pan, J.Z., G´omez-P´erez, J.M., Ren, Y., Wu, H., Wang,
H., Zhu, M.: Graph pattern based RDF data compres-
sion. In: Semantic Technology - 4th Joint International
Conference, JIST 2014, Chiang Mai, Thailand, Novem-
ber 9-11, 2014. Revised Selected Papers, pp. 239–256
(2014)

[75] Pappas, A., Troullinou, G., Roussakis, G., Kondylakis,
H., Plexousakis, D.: Exploring importance measures for
summarizing RDF/S kbs. In: The Semantic Web - 14th
International Conference, ESWC 2017, Portoroˇz, Slove-
nia, May 28 - June 1, 2017, Proceedings, Part I, pp.
387–403 (2017)

[76] Peroni, S., Motta, E., d’Aquin, M.: Identifying key con-
cepts in an ontology, through the integration of cognitive
principles with statistical and topological measures. In:
The Semantic Web, 3rd Asian Semantic Web Confer-
ence, ASWC 2008, Bangkok, Thailand, December 8-11,
2008. Proceedings, pp. 242–256 (2008)

[77] Pham, M., Passing, L., Erling, O., Boncz, P.A.: De-
riving an emergent relational schema from RDF data.
In: Proceedings of the 24th International Conference on
World Wide Web, WWW 2015, Florence, Italy, May 18-
22, 2015, pp. 864–874 (2015)

[78] Picalausa, F., Luo, Y., Fletcher, G.H.L., Hidders, J.,
Vansummeren, S.: A structural approach to indexing
triples. In: The Semantic Web: Research and Applica-
tions - 9th Extended Semantic Web Conference, ESWC
2012, Heraklion, Crete, Greece, May 27-31, 2012. Pro-
ceedings (2012)

[79] Pires, C.E.S., Queiroz-Sousa, P.O., Kedad, Z., Salgado,
A.C.: Summarizing ontology-based schemas in PDMS.
In: Workshops Proceedings of the 26th International
Conference on Data Engineering, ICDE 2010, March 1-6,
2010, Long Beach, California, USA, pp. 239–244 (2010)

[80] Pouriyeh, S.A., Allahyari, M., Kochut, K., Arabnia,
H.R.: A comprehensive survey of ontology summariza-
tion: Measures and methods. CoRR abs/1801.01937
(2018)

[81] Presutti, V., Aroyo, L., Adamou, A., Schopman, B.A.C.,
Gangemi, A., Schreiber, G.: Extracting core knowl-
In: Proceedings of the Sec-
edge from linked data.
ond International Workshop on Consuming Linked Data
(COLD2011), Bonn, Germany, October 23, 2011 (2011)

[82] Queiroz-Sousa, P.O., Salgado, A.C., Pires, C.E.S.: A
method for building personalized ontology summaries.
JIDM 4(3), 236–250 (2013)

[83] Qun, C., Lim, A., Ong, K.W.: D(k)-index: An adap-
tive structural summary for graph-structured data. In:
Proceedings of the 2003 ACM SIGMOD International
Conference on Management of Data, San Diego, Califor-
nia, USA, June 9-12, 2003, pp. 134–144 (2003)

[84] Riondato, M., Garc´ıa-Soriano, D., Bonchi, F.: Graph
summarization with quality guarantees. Data Mining
and Knowledge Discovery 31(2), 314–349 (2017)

36

[85] Rissanen, J.: Modeling by shortest data description. Au-

tomatica 14(5), 465–471 (1978)

[86] Rudolf, M., Paradies, M., Bornh¨ovd, C., Lehner, W.:
large graph analytics in the SAP HANA
Synopsys:
database through summarization.
In: First Interna-
tional Workshop on Graph Data Management Experi-
ences and Systems, GRADES 2013, co-loated with SIG-
MOD/PODS 2013, New York, NY, USA, June 24, 2013,
p. 16 (2013)

[87] Sch¨atzle, A., Neu, A., Lausen, G., Przyjaciel-Zablocki,
M.: Large-scale bisimulation of RDF graphs. In: Pro-
ceedings of the Fifth Workshop on Semantic Web In-
formation Management, SWIM@SIGMOD Conference
2013, New York, NY, USA, June 23, 2013, pp. 1:1–1:8
(2013)

[88] Schmachtenberg, M., Bizer, C., Paulheim, H.: State of
the LOD Cloud 2014. http://linkeddatacatalog.dws.
informatik.uni-mannheim.de/state/. Accessed: 2017-
03-30

[89] Schwarte, A., Haase, P., Hose, K., Schenkel, R., Schmidt,
M.: Fedx: Optimization techniques for federated query
processing on linked data.
In: The Semantic Web -
ISWC 2011 - 10th International Semantic Web Confer-
ence, Bonn, Germany, October 23-27, 2011, Proceedings,
Part I, pp. 601–616 (2011)

[90] Seah, B., Bhowmick, S.S., Jr., C.F.D., Yu, H.: FUSE: a
proﬁt maximization approach for functional summariza-
tion of biological networks. BMC Bioinformatics 13(S-
3), S10 (2012)

[91] Song, Q., Wu, Y., Dong, X.L.: Mining summaries for
knowledge graph search.
In: IEEE 16th International
Conference on Data Mining, ICDM 2016, December 12-
15, 2016, Barcelona, Spain, pp. 1215–1220 (2016)

[92] Spahiu, B., Porrini, R., Palmonari, M., Rula, A., Mau-
rino, A.: ABSTAT: ontology-driven linked data sum-
maries with pattern minimalization. In: SumPre (2016)

[93] Spahiu, B., Porrini, R., Palmonari, M., Rula, A., Mau-
rino, A.: ABSTAT: ontology-driven linked data sum-
maries with pattern minimalization. In: The Semantic
Web - ESWC 2016 Satellite Events, Heraklion, Crete,
Greece, May 29 - June 2, 2016, Revised Selected Papers,
pp. 381–395 (2016)

[94] Stefanoni, G., Motik, B., Kostylev, E.V.: Estimating the
Cardinality of Conjunctive Queries over RDF Data Us-
ing Graph Summarisation. Research report, University
of Oxford (2017). URL https://www.cs.ox.ac.uk/isg/
tools/SumRDF/paper-tr.pdf

[95] Stocker, M., Seaborne, A., Bernstein, A., Kiefer, C.,
Reynolds, D.: SPARQL basic graph pattern optimiza-
tion using selectivity estimation.
In: Proceedings of
the 17th International Conference on World Wide Web,
WWW 2008, Beijing, China, April 21-25, 2008, pp. 595–
604 (2008)

[96] Sydow, M., Pikula, M., Schenkel, R.: The notion of di-
versity in graphical entity summarisation on semantic
knowledge graphs. J. Intell. Inf. Syst. 41(2), 109–149
(2013)

[97] Tian, Y., Hankins, R.A., Patel, J.M.: Eﬃcient aggrega-
In: Proceedings of the
tion for graph summarization.
ACM SIGMOD International Conference on Manage-
ment of Data, SIGMOD 2008, Vancouver, BC, Canada,
June 10-12, 2008, pp. 567–580 (2008)

[98] Tian, Y., Patel, J.M.: Interactive graph summarization.
In: Link Mining: Models, Algorithms, and Applications,
pp. 389–409. Springer (2010)

[99] Tran, T., Ladwig, G., Rudolph, S.: Managing structured
and semistructured RDF data using structure indexes.
IEEE TKDE 25(9) (2013)

[100] Troullinou, G., Kondylakis, H., Daskalaki, E., Plex-
ousakis, D.: RDF digest: Eﬃcient summarization of
RDF/S kbs. In: The Semantic Web. Latest Advances
and New Domains - 12th European Semantic Web Con-
ference, ESWC 2015, Portoroz, Slovenia, May 31 - June
4, 2015. Proceedings, pp. 119–134 (2015)

[101] Troullinou, G., Kondylakis, H., Daskalaki, E., Plex-
ousakis, D.: RDF digest: Ontology exploration using
summaries. In: Proceedings of the ISWC 2015 Posters
& Demonstrations Track co-located with the 14th Inter-
national Semantic Web Conference (ISWC-2015), Beth-
lehem, PA, USA, October 11, 2015. (2015)

[102] Troullinou, G., Kondylakis, H., Daskalaki, E., Plex-
ousakis, D.: Ontology understanding without tears: The
summarization approach. Semantic Web 8(6), 797–815
(2017)

[103] Troullinou, G., Kondylakis, H., Stefanidis, K., Plex-
ousakis, D.: Exploring RDFS kbs using summaries. In:
The Semantic Web - ISWC 2018 - 17th International Se-
mantic Web Conference, Monterey, CA, USA, October
8-12, 2018, Proceedings, Part I, pp. 268–284 (2018)

[104] Troullinou, G., Kondylakis, H., Stefanidis, K., Plex-
ousakis, D.: Rdfdigest+: A summary-driven system for
kbs exploration.
In: Proceedings of the ISWC 2018
Posters & Demonstrations, Industry and Blue Sky Ideas
Tracks co-located with 17th International Semantic Web
Conference (ISWC 2018), Monterey, USA, October 8th
- to - 12th, 2018. (2018)

[105] Udrea, O., Pugliese, A., Subrahmanian, V.S.: GRIN: A
graph based RDF index. In: Proceedings of the Twenty-
Second AAAI Conference on Artiﬁcial Intelligence, July
22-26, 2007, Vancouver, British Columbia, Canada, pp.
1465–1470 (2007)

[106] Valiant, L.G.: A bridging model for parallel computa-

tion. Commun. ACM 33(8), 103–111 (1990)

[107] W3C:

Resource

description

framework.

http://www.w3.org/RDF/

[108] W3C:

Owl

1

web

ontology

language.

https://www.w3.org/TR/owl-features/ (2012)

37

International Conference on Extending Database Tech-
nology, EDBT 2016, Bordeaux, France, March 15-16,
2016., pp. 684–685 (2016)

[122] Zneika, M., Vodislav, D., Kotzinos, D.: Quality Metrics
For RDF Graph Summarization. Semantic Web Journal
(SWJ) accepted, to appear (2018)

[109] W3C:

Owl

2

web

ontology

language.

https://www.w3.org/TR/owl2-overview/ (2012)

[110] W3C:

SPARQL

1.1

query

language.

http://www.w3.org/TR/sparql11-query/ (2013)

[111] Wu, G., Li, J., Feng, L., Wang, K.:

Identifying po-
tentially important concepts and relations in an ontol-
ogy. In: The Semantic Web - ISWC 2008, 7th Interna-
tional Semantic Web Conference, ISWC 2008, Karlsruhe,
Germany, October 26-30, 2008. Proceedings, pp. 33–49
(2008)

[112] Yan, X., Yu, P.S., Han, J.: Graph indexing: A fre-
quent structure-based approach. In: Proceedings of the
ACM SIGMOD International Conference on Manage-
ment of Data, Paris, France, June 13-18, 2004, pp. 335–
346 (2004)

[113] You, J., Pan, Q., Shi, W., Zhang, Z., Hu, J.: Towards
graph summary and aggregation: A survey. In: Social
Media Retrieval and Mining, pp. 3–12. Springer (2013)

[114] Zhang, H., Duan, Y., Yuan, X., Zhang, Y.: ASSG: adap-
tive structural summary for RDF graph data. In: Pro-
ceedings of the ISWC 2014 Posters & Demonstrations
Track a track within the 13th International Semantic
Web Conference, ISWC 2014, Riva del Garda, Italy, Oc-
tober 21, 2014., pp. 233–236 (2014)

[115] Zhang, N., Tian, Y., Patel, J.M.: Discovery-driven graph
summarization.
In: Proceedings of the 26th Interna-
tional Conference on Data Engineering, ICDE 2010,
March 1-6, 2010, Long Beach, California, USA, pp. 880–
891 (2010)

[116] Zhang, X., Cheng, G., Ge, W., Qu, Y.: Summarizing
vocabularies in the global semantic web. J. Comput.
Sci. Technol. 24(1), 165–174 (2009)

[117] Zhang, X., Cheng, G., Qu, Y.: Ontology summarization
based on rdf sentence graph. In: Proceedings of the 16th
International Conference on World Wide Web, WWW
2007, Banﬀ, Alberta, Canada, May 8-12, 2007, pp. 707–
716 (2007)

[118] Zhao, P., Yu, J.X., Yu, P.S.: Graph indexing: Tree +
delta >= graph. In: Proceedings of the 33rd Interna-
tional Conference on Very Large Data Bases, University
of Vienna, Austria, September 23-27, 2007 (2007)

[119] Zheng, W., Zou, L., Peng, W., Yan, X., Song, S.,
Zhao, D.: Semantic SPARQL similarity search over RDF
knowledge graphs. PVLDB 9(11), 840–851 (2016)

[120] Zneika, M., Lucchese, C., Vodislav, D., Kotzinos, D.:
RDF graph summarization based on approximate pat-
terns. In: Information Search, Integration, and Personal-
ization - 10th International Workshop, ISIP 2015, Grand
Forks, ND, USA, October 1-2, 2015, Revised Selected
Papers, pp. 69–87 (2015)

[121] Zneika, M., Lucchese, C., Vodislav, D., Kotzinos, D.:
Summarizing linked data RDF graphs using approxi-
mate graph pattern mining. In: Proceedings of the 19th

38

Work

Method

Input requirements

Purpose

Dataguide
[28]

Structural
non-
quotient

None

Indexing,
query
answering

Output na-
ture
Instance

System -
Theory
System

Output
type
Single
root,
node-
and edge-
labeled
graphs

Required user param-
eters

Visualization Property

Instance

System

graph

Rudolf
al. [86]

et

Chen
et
al. Graph
OLAP [16]
Zhao et al.
[118]

Structural
non-
quotient
Structural
non-
quotient
Pattern
mining

None

None

Yan et al.
[112]

Pattern
mining

Parameterized
input

user

None

Required
threshold,
ratio

degree
overlap

Optional
speciﬁed
error parameter

user-
bounded

Koutra et
al. [51]

Khan
al. [41]

et

Navlakha
et al. [69]

LeFevre et
al.
[55],
Riondato
et al. [84]

et
Ran-

Chen
al.
domized
summaries
[15]

Clustering,
pattern
mining
Structural
non-
quotient,
data
mining
Structural
non-
quotient,
data
mining
Structural
non-
quotient,
data
mining
Structural
non-
quotient,
pattern
mining

OLAP

Multiple
non-RDF
graphs
Set
frequent
trees

of

Indexing,
graph con-
tainment
queries
Indexing,
query
answering
Visualization Graph

Tree

Multiple In-
stances

Theory

Instance

Theory

Instance

Theory

Instance

Theory

Visualization Graph

Instance

Theory

Visualization Graph

Instance

Theory

Required number of
summary nodes, size
of the extent of sum-
mary nodes

Required
threshold

support

Graph

Answering
adjacency,
degree and
centrality
queries
Visualization Graph

Instance

Theory

Instance

Theory

Table 2: Other graph summary proposals.

39

Work

ExpLOD
[43]

[42]

Campinas et al.
[11]

Consens et al.
[17, 45]

Khatchadourian
et al. [44]

Schatzle et al.
[87]

RDF
input
compo-
nent
Instance

Input
require-
ments

None

Instance

None

Instance

None

Instance

None

Instance

None

ASSG [114]

Instance

ˇCebiri´c
[12]

et

al.

Instance
and
schema

Required
user-
selected
queries
None

Jiang et al. [34]

Instance

None

Picalausa et al.
[78]

Instance

None

Tran et al. [99]

Instance

Optional
param-
eters
FW/BW/FB
and neigh-
borhood
size

Purpose

Output
type

Output
nature

System -
Theory

explo-
visual-

Data
ration,
ization
Query formula-
tion

Graph

RDF
graph

Query answer-
ing

RDF
graph

Data
ration,
ization
Graph
tion

explo-
visual-

Graph

reduc-

Graph

Query answer-
ing

Graph

RDF
graph

Labeled
graph
Graph

Graph

Query optimiza-
tion, query for-
mulation, visu-
alization
Semantic min-
ing
Indexing, query
answering

Indexing, data
partitioning,
query process-
ing

System

Theory

System

Theory

Theory

Theory

System

Instance
and
schema
Instance
and
schema
Instance
and
schema
Instance
and
schema
Instance
and
schema
Compressed
graph

Instance
and
schema

Instance

Theory

System

Theory

Instance
and
schema
Instance
and
schema

Table 3: Structural quotient RDF summaries.

40

Work

SchemEX
[49, 50]
RDF
Graph
[116]

Sentence
[117],

KCE [76], [66]

RDFDigest [102],
[100], [75]

RDF
input
compo-
nent
Instance

Schema

Instance
and
schema

Instance
and
schema

Queiroz
[82]

et

al.

Schema

Sydow et al. [96]

Instance

Gurajada et al.
[29]
Kellou et al. [39]

Le et al. [54]

Instance

Instance
and
Schema
Instance

Udrea et al. [105]

Instance

Input
ments

require-

Purpose

Output
type

Output
nature

System -
Theory

Pa-

Pa-

input,

input,

stream

Data
window size
Required
schema,
rameterized
user
RDF/OWL
Required
schema,
rameterized
user
RDF/OWL
Required
schema,
rameterized
user
RDF/OWL,
Semantics-
aware, Handle
implicit data
Required
schema,
rameterized
user
RDF/OWL
Entity of inter-
est
None

input,

input,

Pa-

Pa-

None

Required neigh-
borhood size

sat-
Assumes
urated
input
graph, Required
the
size k of
input
graph
partition

Indexing

RDF
graph

Instance

Theory

Visualization Labeled

Schema

System

graph

Visualization Isolated

nodes

Schema
nodes

System

Labeled
graph

Visualization,
query an-
swering
tasks

Schema

System

Visualization Labeled

Schema

System

graph

Instance

Theory

Instance

System

Schema

Theory

Instance

Theory

Instance

System

Visualization RDF
graph
RDF
graph
Graph

Query an-
swering
Schema
discovery

Indexing,
keyword
queries
Indexing,
visual
querying

Partitioned
RDF
graph
Balanced
binary
tree
(leaves
= parti-
tion
over
resources)

Table 4: Structural non-quotient RDF summaries.
41

Input requirements

Purpose

Output
type

Output
nature

System -
Theory

Theory

Instance
and
schema
Instance Theory

Instance Theory

Schema

Theory

RDF
input
compo-
nent
Instance

Work

Zneika et
al.
[120,
121]
Joshi et al.
[36, 35]

Pan et al.
[74]

Song et al.
[91]

Optional user param-
eters

Query answer-
ing

RDF
graph

Instance

None

Compression

Instance

None

Compression

Instance

Bounded hop neigh-
bors d, maximum size
of patterns K,

Query answer-
ing

Graph
and logical
rules
Graph
and logical
rules
Graph
patterns

Table 5: Pattern mining RDF summaries.

42

Input requirements

Purpose

Output
type

Output
nature

System -
Theory

Work

Hose et al.
[33]

RDF
input
compo-
nent
Instance

None

Source se-
lection

Statistical
informa-
tion

Wu et al.
[111]

Schema

Pires et al.
[79]

Schema

schema,
Requires
RDF/OWL, minor
user input
Requires
OWL

schema,

LODSight
[21]

Mynarz et
al. [68]

Presutti et
al. [81]

Instance
and
schema
Instance
and
schema

Instance
and
schema

None

schema
patterns,
(k) of

Required
summary
the number
selected examples,
None

Visualization Isolated
schema
nodes
Labeled
graph

Query
answering
tasks
Compression,
Visualiza-
tion
Understanding
of dataset,
Visualiza-
tion
Querying
Dataset

Labeled
graph

Labeled
graphs

Labeled
graphs

Table 6: Statistical RDF summaries.

43

Instance

Theory

Schema

Theory

Schema

System

Instance

System

Instance

System

Theory

Construct
an ontol-
ogy
and
the corre-
sponding
instances
that sum-
marize key
features
of dataset
and iden-
tify
the
core KPs

require-

Purpose

Output
type

Output
nature

System -
Theory

Work

Method

Alzogbi et
al. [3]

Stefanoni
et al. [94]

ABSTAT
[73] [92]

Structural
quotient,
clustering
Structural
non-
quotient,
data
mining
Statistical,
pattern
mining

Input
ments

RDF
input
compo-
nent
Instance None

Compression Graph

Instance Optional
rameters
summary
ﬁnement

pa-
for
re-

Conjunctive
query car-
dinality
estimation

Graph

Instance
and
schema

RDF/OWL,
Semantic-
aware, Handles
implicit data

Visualization,
schema
discovery

Labeled
graph
(pat-
terns)

Instance
and
schema
Instance

Theory

Theory

Schema
graph
(Abstract
Knowl-
edge
Patterns)
Instance

System

Theory

Query op-
timization

Relational
tables
and
foreign
keys

Pham et
al. [77]

Structural
non-
quotient,
statistical

Instance
and
schema

Zheng
al. [119]

et

Structural
quotient,
pattern-
mining

Instance
and
schema

Glimm et
al. [25]

Pattern
mining

Instance
and
schema

Fokoue et
al. [24, 23,
19, 20]

Structural
non
quo-
tient

Instance
and
schema

Required max.
number of sum-
nodes,
mary
number
min.
of nodes
rep-
resented by a
summary node,
infrequency
threshold, simi-
larity threshold
Each
instance
should have a
the
type,
list
meaning-
of
equivalent
in-
should
stances
be provided
Description
Logics,
Semantic-
aware, Handles
implicit data
Description
Logics,
Semantic-
aware, Handles
implicit data

Query op-
timization

Multi-
layer
Graph

Schema

Theory

Compression ABox
(facts)

Instance

Theory

ABox
(facts)

Consistency-
checking
and query
answering

Instance

System

Table 7: Hybrid RDF summaries.

44

