Yes, we can! Mining Arguments in 50 Years of US
Presidential Campaign Debates
Shohreh Haddadan, Elena Cabrio, Serena Villata

To cite this version:

Shohreh Haddadan, Elena Cabrio, Serena Villata. Yes, we can! Mining Arguments in 50 Years
of US Presidential Campaign Debates. ACL 2019 - 57th Annual Meeting of the Association for
Computational Linguistics, Jul 2019, Florence, Italy. pp.4684-4690. ￿hal-02194887￿

HAL Id: hal-02194887

https://inria.hal.science/hal-02194887

Submitted on 21 Dec 2020

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Yes, we can!
Mining Arguments in 50 Years of US Presidential Campaign Debates

Shohreh Haddadan
University of Luxembourg
Luxembourg
shohreh.haddadan@uni.lu

Elena Cabrio and Serena Villata
Universit´e Cˆote d’Azur, CNRS, Inria, I3S
France
firstname.surname@unice.fr

Abstract

Political debates offer a rare opportunity for
citizens to compare the candidates’ positions
on the most controversial topics of the cam-
paign. Thus they represent a natural applica-
tion scenario for Argument Mining. As ex-
isting research lacks solid empirical investiga-
tion of the typology of argument components
in political debates, we ﬁll this gap by propos-
ing an Argument Mining approach to politi-
cal debates. We address this task in an em-
pirical manner by annotating 39 political de-
bates from the last 50 years of US presidential
campaigns, creating a new corpus of 29k ar-
gument components, labeled as premises and
claims. We then propose two tasks: (1) iden-
tifying the argumentative components in such
debates, and (2) classifying them as premises
and claims. We show that feature-rich SVM
learners and Neural Network architectures out-
perform standard baselines in Argument Min-
ing over such complex data. We release the
new corpus USElecDeb60To16 and the ac-
companying software under free licenses to
the research community.

1

Introduction

Political debates are public interviews where the
candidates of elections are requested to confront
each other on topics such as unemployment, taxes,
and foreign policy. During presidential elections
in the US, it is customary for the main candidates
of the two largest parties, i.e., the Democratic
and the Republican Parties, to engage in a debate
around the most controversial issues of the time.
Such debates are considered as a de facto elec-
tion process, and in some cases they have nearly
decided the outcomes of the elections (Coleman
et al., 2015).

Given the importance of these debates and
their innate argumentative features, they represent

a natural playground for Argument(ation) Min-
ing (AM) methods (Peldszus and Stede, 2013;
Lippi and Torroni, 2016b; Cabrio and Villata,
2018). AM deals with analyzing argumentation
in various domains, such as legal cases (Mochales
and Moens, 2011), persuasive essays (Stab and
Gurevych, 2017), clinical
trials (Mayer et al.,
2018) and scientiﬁc articles (Teufel et al., 2009).
The ability of identifying argumentative compo-
nents and predicting their relations in such a
kind of texts opens the door to cutting-edge tasks
like fallacy detection, fact-checking, and counter-
argumentation generation.

Despite the plethora of existing approaches and
annotated corpora for AM, very few of them
tackle the issue of mining argumentative structures
from political debates (Lippi and Torroni, 2016a;
Menini et al., 2018; Duthie and Budzynska, 2018;
Visser et al., 2019). To be best of our knowledge,
none of them take on the identiﬁcation of argu-
ment components (i.e., premises and claims) on a
large corpus of political debates. This paper ﬁlls
this gap by (1) performing a large-scale annotation
study over 50 years of US presidential campaigns
from 1960 (Nixon vs. Kennedy) to 2016 (Trump
vs. Clinton), resulting in 29k annotated argument
components, and (2) experimenting with feature-
rich SVM learners and neural architectures out-
performing standard baselines in Argument Min-
ing. Finally, to ensure full reproducibility of our
experiments, we provide all data and source codes
under free licenses.

The paper is organized as follows. Section 2
discusses the related work and compares it to the
proposed approach. In Section 3, we present the
corpus of political debates we built along with
some examples from the annotation guidelines.
Section 4 describes the experimental setting, re-
ports on the obtained results and discusses the
main errors which occurred.

Proceedingsofthe57thAnnualMeetingoftheAssociationforComputationalLinguistics,pages4684–4690Florence,Italy,July28-August2,2019.c(cid:13)2019AssociationforComputationalLinguistics46842 Background and related work

AM is “the general task of analyzing discourse on
the pragmatics level and applying a certain argu-
mentation theory to model and automatically an-
alyze the data at hand” (Habernal and Gurevych,
2017). Two tasks are crucial in Argument Mining:
i) Argument component detection in the input text:
this step may be further split in the detection of
argument components (i.e., claims and premises)
and of their textual boundaries. Different meth-
ods have been tested, like Support Vector Ma-
chines (SVM) (e.g., (Lippi and Torroni, 2016c)),
Na¨ıve Bayes classiﬁers (Duthie et al., 2016), Lo-
gistic Regression (Levy et al., 2014) and Neu-
ral Networks (Stab and Gurevych, 2017), and ii)
Prediction of the relations holding between the
argumentative components (i.e., attacks and sup-
ports). Relations can be predicted between argu-
ments (Cabrio and Villata, 2013) or between argu-
ment components (Stab and Gurevych, 2017).

Regarding political debates, (Menini et al.,
2018) predict relations on speeches of the Nixon-
Kennedy campaign considering only annotations
on the relations among such arguments. (Lippi and
Torroni, 2016a) focus on the 2015 UK election de-
bates to study the impact of vocal features from
the speeches on the identiﬁcation of claims in de-
bates. They built a small corpus of political de-
bates annotated with premises and claims. (Duthie
and Budzynska, 2018) proposed the ethos mining
task aiming at detecting ethotic arguments and the
relations among the politicians and the parties in
the UK Parliament. Sentences are annotated as
being ethotic arguments or not.
(Basave and He,
2016) studied the use of semantic frames for mod-
elling argumentation in speakers’ discourse. They
investigated the impact of argumentation as a in-
ﬂuence rank indicator for politicians on the 20
debates for the Republican primary election. Fi-
nally, (Visser et al., 2019) present a dataset com-
posed of the transcripts of televised political de-
bates leading up to the 2016 presidential election
in the US, with the addition of the reactions from
the social media platform Reddit. The corpus is
annotated based on the Inference Anchoring The-
ory, and not with argument components. Contrary
to past works, we create a huge annotated dataset
including 39 political debates, and we present a
successful attempt to argument component detec-
tion on such a big corpus of political debates.

Year
1960
1976
1980
1984
1988
1992
1996
2000
2000
2004
2004
2008
2012
2012
2016
TOT.

Candidates
Kennedy-Nixon
Carter-Ford
Anderson-Reagan
Mondale-Reagan
Bush-Dukakis
Bush-Clinton-Perot
Clinton-Dole
Bush-Gore
Cheney-Lieberman
Bush-Kerry
Cheney-Edwards
McCain-Obama
Obama-Romney
Biden-Ryan
Clinton-Trump

T
255
270
200
365
484
929
280
564
106
419
169
505
676
425
954
6601

S
2082
1874
1141
2376
2599
4057
2299
3225
835
3487
1069
2829
2352
1252
2536
34013

W
48326
46444
28765
50126
52780
73688
32088
71852
16395
55486
20486
56379
62097
20785
40530
676227

Table 1: Statistics on the debate transcripts: number of
speech turns (T), sentences (S) and words (W).

3 Dataset creation

The USElecDeb60To16 v.01 dataset was collected
from the website of the Commission on Presiden-
tial Debates1, which provided transcripts of the de-
bates broadcasted on TV and held among the lead-
ing candidates for the presidential and vice presi-
dential nominations in the US. USElecDeb60To16
includes the debates starting from Kennedy and
Nixon in 1960 until those between Clinton and
Trump in 2016. Table 1 provides some statis-
tics on the dataset in terms of number of turns
in the conversations, of sentences and of words
in the transcripts. The unique properties of this
dataset are its size (see Table 1), its peculiar na-
ture of containing reciprocal discussions (mainly
between Democrats and Republicans), and its time
line structure. The motivation for creating a new
i) to the best of our knowl-
corpus is twofold:
edge, no other big corpus on political debates an-
notated at a argument component level for Argu-
ment Mining exists, and ii) we ensure the repro-
ducibility of the annotation, writing guidelines, in-
spired from (Rinott et al., 2015; Lippi and Torroni,
2016a), with precise rules for identifying and seg-
menting argument components (i.e., claims and
premises) in political debates.2

In the following, we detail the annotation of the
argument components through examples from the
USElecDeb60To16 dataset.

1http://www.debates.org
2The USElecDeb60To16 v.01 dataset and the annotation
guidelines are available here: https://github.com/
ElecDeb60To16/Dataset.

4685Claims. Being them the ultimate goal of an ar-
gument, in the context of political debates, claims
can be a policy advocated by a party or a candi-
date to be undertaken which needs to be justiﬁed
in order to be accepted by the audience. In Exam-
ple 1,3 Bush is defending the decisions taken by
his administration by claiming that his policy has
been effective. Claims might also provide judg-
ments about the other candidate or parties (Exam-
ple 2).

1. Bush-Kerry, September 30, 2004:

BUSH: My administration started what’s called the
Proliferation Security Initiative. Over 60 nations
involved with disrupting the trans-shipment of infor-
mation and/or weapons of mass destruction materials.
And [we’ve been effective]. [We busted the A.Q. Khan
network. This was a proliferator out of Pakistan that
was selling secrets to places like North Korea and
Libya]. [We convinced Libya to disarm].

2. Kennedy-Nixon, September 26, 1960:

[I believe the programs that Senator
NIXON:
Kennedy advocates will have a tendency to stiﬂe
those creative energies], [I believe in other words,
that his program would lead to the stagnation of the
motive power that we need in this country to get
progress].

3. Kennedy-Nixon, October 13, 1960:

NIXON: Senator Kennedy’s position and mine com-
pletely different on this. [I favor the present depletion
allowance]. [I favor it not because I want to make a lot
of oil men rich], but because [I want to make America
rich]. Why do we have a depletion allowance? Because
[this is the stimulation, the incentive for companies to
go out and explore for oil, to develop it].

Taking a stance towards a controversial subject, or
an opinion towards a speciﬁc issue is also con-
sidered as a claim (e.g., “I’ve opposed the death
penalty during all of my life”). The presence of
discourse indicators (e.g., “in my opinion”, “I be-
lieve”) is generally a useful hint in ﬁnding claims
that state opinions and judgments.

Premises. Premises are assertions made by the
debaters for supporting their claims (i.e., reasons
or justiﬁcations). A type of premise commonly
used by candidates is referring to past experi-
ence: more experienced candidates exploit this
technique to assert that their claims are more rel-
evant than their opponents because of their past
experience (Example 4).

4. Carter-Ford, September 23, 1976:

CARTER: [Well among my other experiences in the

3In the examples, claims are marked in bold, premises in

past, I’ve - I’ve been a nuclear engineer, and did grad-
uate work in this ﬁeld]. [I think I know the - the uh
capabilities and limitations of atomic power].

Statistics are very commonly used as evidence
to justify the claims (Example 6). Moreover,
premises may be asserted in the form of examples
(in such cases, they may contain discourse indica-
tors to introduce examples and justiﬁcations, such
as “because”).

5. Nixon-Kennedy, September 26, 1960:

NIXON: We often hear gross national product dis-
cussed and in that respect may I say that [when we
compare the growth in this administration with that of
the previous administration that then there was a total
growth of eleven percent over seven years]; [in this ad-
ministration there has been a total growth of nineteen
percent over seven years]. [That shows that there’s
been more growth in this Administration than in its
predecessor].

6. Clinton-Dole, October 6, 1996:

CLINTON: [We have ten and a half million more jobs,
a faster job growth rate than under any Republican ad-
ministration since the 1920s]. [Wages are going up for
the ﬁrst time in a decade]. [We have record numbers
of new small businesses]. [We have the biggest drop
in the number of people in poverty in 27 years]. [All
groups of people are growing].
[We had the biggest
drop in income inequality in 27 years in 1995]. [The
average family’s income has gone up over $1600 just
since our economic plan passed]. So [I think it’s clear
that we’re better off than we were four years ago].

Three expert annotators deﬁned the annotation
guidelines, then three other annotators carried out
the annotation task relying on such guidelines.
Each transcript has been independently annotated
by at least two annotators4. 86% of the sentences,
which were annotated at least with one compo-
nent, were tagged with only one argument compo-
nent, while the remaining 14% with more than one
component (7% with both claims and premises).5
Only 0.6% of the dataset contains cross-sentence
annotations (i.e., annotations which are not bound
19 debates have been inde-
in one sentence).
pendently annotated by three annotators to mea-
sure the IAA. The observed agreement percentage
and IAA at sentence-level (following (Stab and
Gurevych, 2014)) are respectively 0.83% and κ =
0.57 (moderate agreement) for argumentative-non
argumentative sentences, and 63% and κ = 0.4
(fair agreement) for the argument components.
Such annotation tasks are very difﬁcult with po-
litical debates. In many examples, the choice be-
tween a premise and a claim is hard to deﬁne. In

4We used the Brat annotation tool (Stenetorp et al., 2012).
5A component cannot be both a claim and a premise (see

Italics and the component boundaries by [square brackets].

Guidelines).

4686Example 7, the sentence “the way Senator [...]” is
used as a premise for the previous claim, but if ob-
served out of this context, it can be identiﬁed as
a claim. This justiﬁes the IAA on the argument
component annotation.

7. McCain-Obama, October 15, 2008:

OBAMA: [I disagree with Senator McCain in how
to do it], because [the way Senator McCain has de-
signed his plan, it could be a giveaway to banks if we’re
buying full price for mortgages that now are worth a lot
less]?.

To release a consistent dataset, in the reconcil-
iation phase we computed the IAA of the annota-
tors with two other expert annotators with back-
ground in computational linguistics on a sample
of 6 debates. In case of disagreement among the
ﬁrst three annotators, the annotation provided by
the annotator which showed to be consistently in
line with the expert annotators (i.e., with a higher
IAA) was included in the released dataset.
the USE-
After
reconciliation
lecDeb60To16 dataset contains the annotation of
29521 argument components (i.e., 16087 claims
and 13434 premises). Notice that the number
of claims is higher than the number of premises,
because in political speeches the candidates make
arguments mostly without providing premises for
their claims. Moreover, the candidates use longer
sentences (more words) to express their premises
than their claims.

phase,

the

For our experiments, we split the dataset into
train (13894 components), validation (6577 com-
ponents) and test (9050 components) sets, keeping
the same component distribution as in the original
dataset.

4 Experimental setting

We address the argument component detection
task as two subsequent classiﬁcation steps, i.e., the
argumentative sentences detection (Task 1), and
the argumentative components identiﬁcation (Task
2). We address both of these classiﬁcation tasks at
the sentence level (e.g., we label a sentence ac-
cording to the longest component annotated in the
sentence).

Methods For Task 1, we trained both a linear-
kernel SVM with stochastic gradient descent
learning method using bag of words features only,
and a SVM classiﬁer with rbf kernel (python
scikit-learn v0.20.1, penalty parameter=10) us-
ing the features listed below to distinguish argu-

mentative sentences (i.e., sentences which con-
tain at least one argument component) from the
non-argumentative ones. For comparison, we also
tested a Neural Network structured with two bidi-
rectional LSTM layers (Hochreiter and Schmid-
huber, 1997) using word embeddings from Fast-
Text (Joulin et al., 2016; Mikolov et al., 2018) as
the weights for the embedding layer. The output
layer determines the class Argumentative/Non-
Argumentative for the input sentence. A feed-
forward Neural Network was also trained using
the same sentence-based features used with the
SVM classiﬁer. This network consists of two hid-
den layers with 64 and 32 neurons for the 1st and
2nd hidden layer, respectively.

As for the component classiﬁcation step, we ap-
plied the same classiﬁers as for Task 1 (SVM and
LSTM). For both tasks, we implemented the ma-
jority baseline for argument component classiﬁca-
tion used in (Stab and Gurevych, 2017).

We considered the following features:

tf-idf
of each word, NGram (bigrams and trigrams),
POS of adverbs, adjectives (used by debaters to
stress the correctness of their premises), different
tenses of verbs and modal verbs (they often af-
fect the certainty of the assertions, hence would
be a hint of facts/non-facts in discerning between
argument components), syntactic features (con-
stituency parse trees, dept of the parsing tree), dis-
course connectives (and their position), NER (de-
baters often mention party members, former pres-
idents, organizations and dates or numbers like
statistics as examples to strengthen the premises
for the claims), semantic features (sentiment po-
larity of the argument component and of its cover-
ing sentence (Menini et al., 2018)).

Evaluation Tables 2 and 3 present
the re-
sults obtained on detecting argumentative sen-
tences (Task 1) and classifying argumentative
components (Task 2), respectively. Results ob-
tained with linear-kernel SVM signiﬁcantly out-
performed the majority baseline in both tasks. En-
riching the feature-set increased the classiﬁcation
performances by 9% on Task 1 using the rbf-
kernel SVM, while only by 2.2% on Task 2. Run-
ning ablation tests for features analysis, we no-
ticed that the lexical features (tf-idf and NGram
features) strongly contribute to performance in-
crease in both tasks. NER features – selected
on the assumption that they would have improved
the detection of premises as candidate tend to use

4687NERs to provide examples – showed to be more
effective in Task 1 only. Sentiment and discourse
indicator features did not show to be effective in
either classiﬁcation tasks. Results obtained by
LSTM with word-embedding as features in both
tasks are comparable to that of the SVM using all
the features, showing the efﬁciency of neural clas-
siﬁers on AM tasks using less dimensionality for
the input data.

Classiﬁer

Majority
baseline

SVM
Linear Kernel
BOW

SVM
Rbf Kernel
All features

LSTM network
word-embeddings features

Feed Forward Network
All features

Class
Arg
None
Average
Arg
None
Average
Arg
None
Average
Arg
None
Average
Arg
None
Average

Precision Recall F-Score
1.000
0.000
0.681
0.980
0.335
0.774
0.986
0.293
0.853
0.946
0.463
0.854
0.859
0.528
0.796

0.810
0.000
0.551
0.855
0.486
0.737
0.916
0.433
0.823
0.913
0.547
0.843
0.872
0.498
0.800

0.681
0.000
0.463
0.758
0.886
0.799
0.855
0.834
0.851
0.882
0.668
0.841
0.885
0.471
0.805

Table 2: Classiﬁcation results on Task 1.

Classiﬁer

Majority
baseline

SVM
Linear Kernel
BOW

SVM
Rbf Kernel
All features

LSTM network
word-embeddings

Feed Forward Network
All features

Class
Claim
Premise
Average
Claim
Premise
Average
Claim
Premise
Average
Claim
Premise
Average
Claim
Premise
Average

Precision Recall F-Score
1.00
0.00
0.51
0.757
0.534
0.647
0.830
0.484
0.662
0.810
0.739
0.673
0.697
0.581
0.641

0.68
0.00
0.35
0.685
0.599
0.643
0.717
0.581
0.651
0.829
0.710
0.673
0.667
0.611
0.640

0.51
0.00
0.26
0.625
0.682
0.653
0.631
0.728
0.678
0.848
0.683
0.673
0.639
0.644
0641

Table 3: Classiﬁcation results on Task 2.

Given the complexity of the task, we computed
the human upper bound as the average F-score of
the annotation agreement between annotators and
It resulted in 0.87 and 0.75
the gold-standard.
on argumentative vs. non-argumentative, and 0.74
and 0.65 on claims and premises, respectively.

Error Analysis Argumentative sentences are
rarely misclassiﬁed, which results in high recall
on argumentative sentence identiﬁcation. Some
patterns can be identiﬁed from the misclassiﬁed
non-argumentative sentences. One of these pat-
terns appears in very short non-argumentative sen-
tences which contain an argument indicator such

as “so”, for instance the sentence: “So what should
we do?” is classiﬁed as argumentative although in
the context it is considered a non-argumentative
sentence. Since indicators for claims are more
numerous in these debates, this misclassiﬁcation
mostly occurs when a claim-indicator is uttered by
the candidate in a non-argumentative manner.

In other cases, candidates make ﬁnal remarks
phrasing their speech with a structure similar to
argumentative sentences, for example: “I think
when you make that decision, it might be well if
you would ask yourself, are you better off than you
were four years ago?”.

Misclassiﬁcation between claims and premises,
instead, is primarily due to the fact that the com-
ponent classiﬁcation is highly dependent on the
structure of the argument.

5 Conclusion

We investigated the detection of argument compo-
nents in the US presidential campaign debates: i)
providing a manually annotated resource of 29k
argument components, and ii) evaluating feature-
rich SVM learners and Neural Networks on such
data (achieving ∼90% w.r.t. human performance).
We highlighted the strengths (e.g., satisfactory
performances on different oratory styles across
time and topics) and weaknesses (e.g., no argu-
ment boundaries detection on a clause level, the
context of the whole debates is not considered).

For future work, we plan to i) automatically
predict relations between argument components in
the USElecDeb60To16 dataset, and ii) propose a
new task, i.e., fallacy detection so that common
fallacies in political argumentation (Zurloni and
Anolli, 2010) can be automatically identiﬁed, in
line with the work of (Habernal et al., 2018).

Acknowledgments

Shohreh Haddadan acknowledges the support of
the Luxembourg National Research Fund (FNR)
(10929115). Elena Cabrio and Serena Villata
have been partially supported by EU H2020 re-
search and innovation programme under the Marie
Sklodowska-Curie grant agreement No. 690974
for the project MIREL: MIning and REasoning
with Legal texts.
The experiments presented in this paper were car-
ried out using the HPC facilities of the Univer-
sity of Luxembourg (Varrette et al., 2014) – see
https://hpc.uni.lu.

4688References

Amparo Elizabeth Cano Basave and Yulan He. 2016.
A study of the impact of persuasive argumentation
In NAACL HLT 2016, The
in political debates.
2016 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, San Diego California,
USA, June 12-17, 2016, pages 1405–1413. The As-
sociation for Computational Linguistics.

Elena Cabrio and Serena Villata. 2013. A natural lan-
guage bipolar argumentation approach to support
users in online debate interactions. Argument &
Computation, 4(3):209–230.

Elena Cabrio and Serena Villata. 2018. Five years of
In Pro-
argument mining: a data-driven analysis.
ceedings of the Twenty-Seventh International Joint
Conference on Artiﬁcial Intelligence, IJCAI 2018,
July 13-19, 2018, Stockholm, Sweden., pages 5427–
5433.

Stephen Coleman, J Blumler, G Moss, and M Homer.
2015. The 2015 televised election debates; democ-
racy on demand? Leeds University Press.

Rory Duthie and Katarzyna Budzynska. 2018. A deep
modular RNN approach for ethos mining. In Pro-
ceedings of the Twenty-Seventh International Joint
Conference on Artiﬁcial Intelligence, IJCAI 2018,
July 13-19, 2018, Stockholm, Sweden., pages 4041–
4047.

Rory Duthie, Katarzyna Budzynska, and Chris Reed.
In Com-
2016. Mining ethos in political debate.
putational Models of Argument - Proceedings of
COMMA 2016, Potsdam, Germany, 12-16 Septem-
ber, 2016, volume 287 of Frontiers in Artiﬁcial In-
telligence and Applications, pages 299–310. IOS
Press.

Ivan Habernal and Iryna Gurevych. 2017. Argumenta-
tion mining in user-generated web discourse. Com-
put. Linguist., 43(1):125–179.

Ivan Habernal, Henning Wachsmuth, Iryna Gurevych,
and Benno Stein. 2018. Before name-calling: Dy-
namics and triggers of ad hominem fallacies in web
In Proceedings of the 2018 Con-
argumentation.
ference of the North American Chapter of the As-
sociation for Computational Linguistics: Human
Language Technologies, NAACL-HLT 2018, New
Orleans, Louisiana, USA, June 1-6, 2018, Volume
1 (Long Papers), pages 386–396. Association for
Computational Linguistics.

Sepp Hochreiter and J¨urgen Schmidhuber. 1997.
Neural computation,

Long short-term memory.
9(8):1735–1780.

Armand Joulin, Edouard Grave, Piotr Bojanowski,
Matthijs Douze, H´erve J´egou, and Tomas Mikolov.
2016. Fasttext.zip: Compressing text classiﬁcation
models. arXiv preprint arXiv:1612.03651.

Ran Levy, Yonatan Bilu, Daniel Hershcovich, Ehud
Aharoni, and Noam Slonim. 2014. Context depen-
dent claim detection. In COLING 2014, 25th Inter-
national Conference on Computational Linguistics,
Proceedings of the Conference: Technical Papers,
August 23-29, 2014, Dublin, Ireland, pages 1489–
1500. ACL.

Marco Lippi and Paolo Torroni. 2016a. Argument min-
ing from speech: Detecting claims in political de-
In Proceedings of the Thirtieth AAAI Con-
bates.
ference on Artiﬁcial Intelligence, February 12-17,
2016, Phoenix, Arizona, USA, pages 2979–2985.

Marco Lippi and Paolo Torroni. 2016b. Argumentation
mining: State of the art and emerging trends. ACM
Trans. Internet Techn., 16(2):10.

Marco Lippi and Paolo Torroni. 2016c. Margot: A
web server for argumentation mining. Expert Sys-
tems with Applications, 65:292–303.

Tobias Mayer, Elena Cabrio, Marco Lippi, Paolo Tor-
roni, and Serena Villata. 2018. Argument mining on
clinical trials. Computational Models of Argument -
Proceedings of COMMA 2018, Warsaw, Poland, 12-
14 September 2018, 305:137.

Stefano Menini, Elena Cabrio, Sara Tonelli, and Ser-
ena Villata. 2018. Never retreat, never retract:
In
Argumentation analysis for political speeches.
Proceedings of the Thirty-Second AAAI Conference
on Artiﬁcial Intelligence, (AAAI-18), New Orleans,
Louisiana, USA, February 2-7, 2018, pages 4889–
4896. AAAI Press.

Tomas Mikolov, Edouard Grave, Piotr Bojanowski,
Christian Puhrsch, and Armand Joulin. 2018. Ad-
vances in pre-training distributed word representa-
In Proceedings of the International Con-
tions.
ference on Language Resources and Evaluation
(LREC).

Raquel Mochales and Marie-Francine Moens. 2011.
Argumentation mining. Artiﬁcial Intelligence and
Law, 19(1):1–22.

Andreas Peldszus and Manfred Stede. 2013. From ar-
gument diagrams to argumentation mining in texts:
A survey. Int. J. Cogn. Inform. Nat. Intell., 7(1):1–
31.

Ruty Rinott, Lena Dankin, Carlos Alzate, Mitesh M.
Khapra, Ehud Aharoni, and Noam Slonim. 2015.
Show me your evidence - an automatic method for
context dependent evidence detection. In Proceed-
ings of the 2015 Conference on Empirical Methods
in Natural Language Processing, EMNLP 2015, Lis-
bon, Portugal, September 17-21, 2015, pages 440–
450. The Association for Computational Linguistics.

Christian Stab and Iryna Gurevych. 2014. Annotating
argument components and relations in persuasive es-
In COLING 2014, 25th International Con-
says.
ference on Computational Linguistics, Proceedings
of the Conference: Technical Papers, August 23-29,
2014, Dublin, Ireland, pages 1501–1510. ACL.

4689Christian Stab and Iryna Gurevych. 2017. Parsing ar-
gumentation structures in persuasive essays. Com-
putational Linguistics, 43(3):619–659.

Pontus Stenetorp, Sampo Pyysalo, Goran Topi´c,
Tomoko Ohta, Sophia Ananiadou, and Jun’ichi Tsu-
jii. 2012. Brat: a web-based tool for nlp-assisted
text annotation. In Proceedings of the Demonstra-
tions at the 13th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 102–107. Association for Computational Lin-
guistics.

Simone Teufel, Advaith Siddharthan, and Colin R.
Batchelor. 2009. Towards domain-independent ar-
gumentative zoning: Evidence from chemistry and
In Proceedings of the
computational linguistics.
2009 Conference on Empirical Methods in Natu-
ral Language Processing, EMNLP 2009, 6-7 August
2009, Singapore, A meeting of SIGDAT, a Special
Interest Group of the ACL, pages 1493–1502. ACL.

S. Varrette, P. Bouvry, H. Cartiaux, and F. Georgatos.
2014. Management of an academic hpc cluster: The
In Proc. of the 2014 Intl. Conf. on
ul experience.
High Performance Computing & Simulation (HPCS
2014), pages 959–967, Bologna, Italy. IEEE.

Jacky Visser, Barbara Konat, Rory Duthie, Marcin
Koszowy, Katarzyna Budzynska, and Chris Reed.
2019. Argumentation in the 2016 us presidential
elections: annotated corpora of television debates
and social media reaction. Language Resources and
Evaluation.

Valentino Zurloni and Luigi Anolli. 2010. Fallacies as
argumentative devices in political debates. In Multi-
modal Communication in Political Speech. Shaping
Minds and Social Action - International Workshop,
Political Speech 2010, Rome, Italy, November 10-
12, 2010, Revised Selected Papers, volume 7688 of
Lecture Notes in Computer Science, pages 245–257.
Springer.

4690