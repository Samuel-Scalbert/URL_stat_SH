Private Sampling with Identifiable Cheaters
César Sabater, Florian Hahn, Andreas Peter, Jan Ramon

To cite this version:

César Sabater, Florian Hahn, Andreas Peter, Jan Ramon. Private Sampling with Identifiable Cheaters.
Proceedings on Privacy Enhancing Technologies, In press, 2023 (2). ￿hal-03904200￿

HAL Id: hal-03904200

https://inria.hal.science/hal-03904200

Submitted on 16 Dec 2022

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Private Sampling with Identifiable Cheaters

César Sabater
INRIA Lille
Villeneuve d’Ascq, France
cesar.sabater@inria.fr

Andreas Peter
University of Oldenburg
Oldenburg, Germany
andreas.peter@uni-oldenburg.de

Florian Hahn
University of Twente
Enschede, Netherlands
f.w.hahn@utwente.nl

Jan Ramon
INRIA Lille
Villeneuve d’Ascq, France
jan.ramon@inria.fr

ABSTRACT
In this paper we study verifiable sampling from probability distri-
butions in the context of multi-party computation. This has various
applications in randomized algorithms performed collaboratively
by parties not trusting each other. One example is differentially
private machine learning where noise should be drawn, typically
from a Laplace or Gaussian distribution, and it is desirable that no
party can bias this process. In particular, we propose algorithms to
draw random numbers from uniform, Laplace, Gaussian and arbi-
trary probability distributions, and to verify honest execution of the
protocols through zero-knowledge proofs. We propose protocols
that result in one party knowing the drawn number and protocols
that deliver the drawn random number as a shared secret.

KEYWORDS
differential privacy, sampling, zero knowledge proofs, multiparty
computation

1 INTRODUCTION
Nowadays, randomization is an important algorithmic technique.
Its numerous applications include randomized algorithms, e.g., for
many problems the simplest or most efficient known solution strat-
egy is a randomized algorithm, and hiding information, e.g., in
cryptography or in differential privacy. While true randomness is
hard to achieve in most cases it is sufficient to be able to gener-
ate pseudo-random numbers. A wide range of approaches exist to
generate pseudo-random numbers of good quality.

The situation becomes more complicated when we consider gen-
erating random numbers in the context of multi-party computation
between parties which do not trust each other. We are particularly
interested in algorithms which allow multiple parties to draw a
random number from a specified probability distribution in such
a way that all parties can be convinced that the number drawn is
truly random and that either all parties, only one party, or none of
the parties learn the drawn random number. This implies that no
party should be able to influence the probability distribution or be
able to predict or guess the random number.

This work is licensed under the Creative Commons Attribu-
tion 4.0 International License. To view a copy of this license
visit https://creativecommons.org/licenses/by/4.0/ or send a
letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.
Proceedings on Privacy Enhancing Technologies YYYY(X), 1–23
© YYYY Copyright held by the owner/author(s).
https://doi.org/XXXXXXX.XXXXXXX

1

Such algorithms are particularly useful for differentially private
federated machine learning using sensitive data from multiple data
owners. In this setting, one would like to learn a statistical model
M with parameters 𝜃 on the sensitive data of multiple data owners.
Such model could reveal sensitive information and therefore one
possible technique is to perturb the model before publication suf-
ficiently such that it becomes differentially private [27], i.e., such
ˆM with parameters ˆ𝜃 one cannot
that from the perturbed model
distinguish a change in a single individual. This can be achieved by
drawing some noise 𝜂 from an appropriate probability distribution,
e.g., 𝜂 often is a vector of Laplace or Gaussian random variables,
and setting ˆ𝜃 = 𝜃 +𝜂. In such scenario it is important nobody knows
𝜂 as else that party could subtract 𝜂 from the published ˆ𝜃 to obtain
the sensitive model parameters 𝜃 . At the same time, all data owners
want to be sure that 𝜂 is drawn correctly: if anyone can bias the
distribution of this noise, privacy may not be guaranteed anymore
or the model parameters may be biased in a way similar as what
one can achieve with data poisoning [49, 53].

In this paper we develop algorithms to verifiably draw random
numbers. We consider uniform distributions, Laplace distributions,
Gaussian distributions and arbitrary distributions. We develop
strategies with three different privacy levels for the random num-
ber: strategies which verifiably draw a publicly known random
number, strategies which verifiably draw a random number which
is revealed to only one party and strategies which verifiably draw
a random number and output it as a shared secret so that none of
the parties knows the random number.

An important tool to prove correct behavior can be found in
zero knowledge proofs (ZKP). These are cryptographic techniques
that allow a party to prove statements without revealing anything
else. Typically, one considers statements involving logical and arith-
metic relations over private values which can be expressed using
additions, multiplications and other elementary operations such as
comparisons. For drawing from Laplace or Gaussian distributions,
transcendental functions are needed. We work towards bridging
this gap based on Cordic [52], a classic technique for computing
such functions.

The main contributions of this paper can be summarized as
follows: (1) we propose strategies to prove relationships involving
logarithms or trigonometric functions in zero knowledge, (2) we
propose and compare several strategies to let a party verifiably
draw Gaussian random numbers, (3) we propose algorithms to let
one party verifiably sample from the Laplace distribution and from
an arbitrary distribution, (4) we propose algorithms to draw from

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

the Gaussian or Laplace distribution a random number represented
as a shared secret.

The remainder of this paper is structured as follows:
After reviewing some common notations and concepts in Sec-
tion 2, we formalize our problem statement in Section 3. Next, in
Section 4 we discuss related work and in Section 5 we provide a
high-level overview of our method. After that, in Section 6 we re-
view the Cordic algorithm and adapt it for zero-knowledge proofs.
In Sections 7 and 8 we apply these techniques for sampling from
the Laplace and Gaussian distributions. To show how our methods
work in practice, in Section 9 we provide an experimental compari-
son of the several possible strategies to sample from the Gaussian
distribution. In Section 10 we discuss the application of our tech-
niques to the problem of differentially private machine learning.
Finally, in Section 11 we conclude and outline directions of future
work.

2 PRELIMINARIES
We will denote the set of the first 𝑘 positive integers by [𝑘] = {𝑖 ∈
N | 1 ≤ 𝑖 ≤ 𝑘 }. We denote the security parameter by 𝜆. We say that
a function is negligible in 𝜆 if, for each positive polynomial 𝑓 , it is
smaller than 1
for sufficiently big 𝜆. We omit 𝜆 sometimes in
𝑓 (𝜆)
negligible functions when it is clear it refers to 𝜆. 𝑎 ←𝑅 𝑆 means
that 𝑎 is sampled uniformly at random from elements of 𝑆. For
vectors a = (𝑎1, . . . , 𝑎𝑘 ) and b = (𝑏1, . . . , 𝑏𝑘 ), a + b and a ∗ b are the
element wise addition and product. ab is the multi-exponentiation
(cid:206)𝑘
. For a scalar 𝑠, 𝑠 + a = (𝑠, . . . , 𝑠) + a, 𝑠 ∗ a = (𝑠, . . . , 𝑠) ∗ a
and a𝑠 = a(𝑠,...,𝑠) . The function sign(𝑥) is equal to 1 if 𝑥 ≥ 0 and to
−1 otherwise.

𝑖=1 𝑎𝑏𝑖

𝑖

2.1 Setting and Threat Model
We consider a set of 𝑛 parties P = {𝑃1, . . . , 𝑃𝑛 }. We assume parties
have access to a public-key infrastructure which they can use to
prove their identity when sending messages. Parties communicate
through secure channels and have access to a public bulletin board
that they can use to post messages. When a party sends a message
to the bulletin board, it is forwarded to all other agents as when
using a broadcast channel. In addition, all broadcasted messages
remain publicly visible in the bulletin board, which allows to have
publicly verifiable protocols.

We assume that a subset of parties P𝑐𝑜𝑟 ⊂ P is corrupted and
controlled by an adversary A. A can make corrupted parties to
deviate arbitrarily from the protocol and perform coordinated at-
tacks. Our protocols are secure if at least one party is honest. The
set P𝑐𝑜𝑟 of corrupted parties is assumed to be static, meaning that
it does not change after the beginning of the execution.

We prove security in the simulation paradigm, using the model
of security with identifiable abort [33] for the stand-alone setting
[29]. This setting allows to obtain sequentially composable proto-
cols in which parties are able to detect malicious actions and can
in such cases abort the protocol. Deterrence measures may be in
place to discourage parties from being detected as malicious. In
fact, unless parties stop participating our protocols either complete
successfully or abort with a proof that a specific party is a cheater,
i.e., in case our protocols abort the message trace (which is kept on
the bulletin board) allows for proving that a specific party did not

follow the protocol. Assuming that adversaries will be deterred if
they risk getting caught is a standard assumption that applies in
many scenarios [3].

In parts of our protocols, we make use of specific Zero Knowledge
Proofs that are non-interactive versions of compressed Σ-protocols
whose security relies on the Random Oracle Model [6]. We provide
a detailed description of our security framework and prove the
security of our protocols in Appendix B.

2.2 Commitment Schemes
A commitment scheme allows for committing to values while keep-
ing them hidden. We use the vector variant of the Pedersen commit-
ment scheme [47]. Let G be a cyclic multiplicative group of prime
order 𝑝 exponential in 𝜆 in which the Discrete Logarithm Assump-
tion (DLA) holds. The setup of the commitment scheme takes as
input a string of length 𝑂 (1𝜆) and outputs a vector g = (𝑔1, . . . , 𝑔𝑘 )
of elements sampled at random from G \ {1}. It is required that no
pairwise discrete logarithm on the elements 𝑔1, . . . , 𝑔𝑘 is known,
which can be guaranteed without a trusted party as the setup only
requires public randomness. A commitment 𝑃 ∈ G of a vector
x = (𝑥1, . . . , 𝑥𝑘 ) ∈ Z𝑘
𝑝 satisfies 𝑃 = gx. We say that x is an open-
ing of 𝑃. The scheme is binding as no computationally bounded
adversary can find two openings x and x′ of 𝑃 such that x ≠ x′
except with probability negligible in 𝜆. If x = ( ˆx, 𝑟 ), where ˆx is the
data and 𝑟 is sampled uniformly at random from Z𝑝 , 𝑃 is uniformly
distributed in G and therefore does not reveal any information
about ˆx. This is known as the hiding property. In our protocols, one
coordinate of g is always reserved for randomness. The scheme
is also homomorphic as, given commitments 𝑃 and 𝑄 of x and y
respectively, 𝑃𝑄 is a commitment of x + y.

2.3 Arithmetic Circuits
An arithmetic circuit (or just circuit) 𝐶 : Z𝑘
𝑝 is a function
that only contains additions and multiplications modulo 𝑝. In the
following sections we will define circuits using the notation

𝑝 → Z𝑠

𝐶 (𝑎; 𝑖1, . . . , 𝑖𝑘 ) (cid:66)

,

𝑜1


...



𝑜𝑠











where (𝑖1, . . . , 𝑖𝑘 ) is the input, (𝑜1, . . . , 𝑜𝑠 ) is the output, and 𝑎 are
constants that may change the circuit structure, for example, in the
case we are defining a family of similar circuits.

2.4 Compressed Σ-Protocols
We will prove statements about private committed values using
Zero Knowledge Proofs [31]. In such proofs, for a NP relation R, a
prover P interacts with a verifier V to prove, for a public statement
𝑎, the knowledge of a private witness 𝑤 such that (𝑎; 𝑤) ∈ R. At the
end of the interaction, V either accepts or rejects the proof. ZKPs
are (1) complete, as V always accepts a proof of an honest P, (2)
sound, as a proof of a dishonest P is rejected except with negligible
probability and (3) zero knowledge, as no information other than
(𝑎; 𝑤) ∈ R is revealed by the protocol. The ZKPs that we use are
also called zero knowledge arguments, as they are sound if P is
computationally bounded. Additionally, they rely on the DLA.

2

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

The ZKPs we use are called compressed Σ-protocols [2]. Partic-
ularly, we use Protocol Π𝑐𝑠 of [2], that proves the nullity of the
output of arithmetic circuits in Z𝑝 applied to private inputs. Let
G, Z𝑝 , and g be as defined for commitments, then for any circuit
𝐶 : Z𝑘
𝑝 , by applying Π𝑐𝑠 to 𝐶 we obtain a complete, sound
and zero knowledge proof for the relation

𝑝 → Z𝑠

{(𝑃 ∈ G; x ∈ Z𝑘

𝑝 ) : 𝑃 is a commitment of x ∧ 𝐶 (x) = 0)}.

While Π𝑐𝑠 is an interactive protocol between P and V, it can be
turned into a non-interactive proof using the Strong Fiat-Shamir
heuristic [8]. By this transformation, ZKPs can be generated offline
by P and later be verified by any party.

Let 𝑚 be the number of multiplication gates of 𝐶, then the proof
generated by the execution of Π𝑐𝑠 has a size of 2⌈log(𝑘 +2𝑚 +4)⌉ −1
elements of G and 6 elements of Z𝑝 . To generate such proof, the
dominant computations are modular exponentiations in G (GEX). P
performs 5𝑘 + 8𝑚 + 2⌈log2 (𝑘 + 2𝑚 + 4)⌉ + 6 GEX, and the verification
cost is of 𝑘 + 2𝑚 + 2⌈log2 (𝑘 + 2𝑚 + 4)⌉ − 1 GEX.

We provide a detailed explanation of compressed Σ-protocols,

their cost and some optimizations in Appendix A.

2.5 Secret Sharing
Consider again 𝑛 parties {𝑃𝑖 }𝑛
𝑖=1. For a positive prime 𝑝, group Z𝑝 ,
and a number 𝑎 ∈ Z𝑝 , one can generate an additive secret share
for 𝑎 by drawing a random vector (𝑎1, . . . , 𝑎𝑛) ∈ Z𝑛
𝑝 subject to the
constraint that (cid:205)𝑛
𝑖=1 𝑎𝑖 = 𝑎 mod 𝑝. We then denote this sharing of 𝑎
as ⟦𝑎⟧ = (𝑎1 . . . 𝑎𝑛). The process of computing and revealing 𝑎 from
the sharing ⟦𝑎⟧ is called opening the sharing ⟦𝑎⟧. If every party
𝑃𝑖 only receives 𝑎𝑖 (for 𝑖 ∈ [𝑛]), then if not all parties collude each
party can only see at most 𝑛 − 1 uniformly randomly distributed
numbers, and hence has no information about the value of 𝑎.

If for one or more values a sharing is available, it is possible to
perform various operations on them without revealing any new in-
formation, see [24] for an overview. If ⟦𝑎⟧ = (𝑎1 . . . 𝑎𝑛) is a sharing
of 𝑎 and ⟦𝑏⟧ is a sharing of 𝑏, then ⟦𝑎 + 𝑏⟧ = (𝑎1 + 𝑏1 . . . 𝑎𝑛 + 𝑏𝑛)
is a sharing of 𝑎 + 𝑏. Given a sharing ⟦𝑎⟧ of 𝑎 and a public con-
stant 𝑐, then ⟦𝑐𝑎⟧ = (𝑐𝑎1 . . . 𝑐𝑎𝑛) is a sharing of 𝑐𝑎. For multiply-
ing two sharings, one can use pre-computed triples of sharings
(⟦𝑥⟧, ⟦𝑦⟧, ⟦𝑧⟧) with 𝑥 and 𝑦 random and 𝑥𝑦 = 𝑧. Given such
triple, and two sharings ⟦𝑎⟧ and ⟦𝑏⟧ which one wants to mul-
tiply, one can compute ⟦𝑑⟧ = ⟦𝑎⟧ − ⟦𝑥⟧ and ⟦𝑒⟧ = ⟦𝑏⟧ − ⟦𝑦⟧
and open both ⟦𝑑⟧ and ⟦𝑒⟧. Then, a sharing of 𝑐 = 𝑎𝑏 is obtained
by ⟦𝑐⟧ = ⟦𝑧⟧ + 𝑑⟦𝑦⟧ + 𝑒⟦𝑥⟧ + 𝑑𝑒. Several approaches have been
proposed to generate such triples of sharings (⟦𝑎⟧, ⟦𝑏⟧, ⟦𝑐⟧) effi-
ciently, typically involving a somewhat homomorphic encryption
(SHE) scheme with distributed decryption, where the parties can
generate random sharings ⟦𝑎⟧ and ⟦𝑏⟧ uniformly at random, en-
crypt them, multiply them and decrypt the product in a distributed
way to obtain ⟦𝑐⟧ [24].

We’ll adopt a number of ideas from [23]. In particular, we will
represent sharings in binary form, denoting by 𝐵𝐼𝑇 𝑆 (𝑥, (𝑥 (𝑖) )𝑙−1
𝑖=0 )
the relation ⟦𝑥⟧ = (cid:205)𝑙−1
𝑖=0⟦𝑥 (𝑖) ⟧2𝑖 with 𝑥 (𝑖) ∈ {0, 1}. The protocol
𝑖=0 ) returns (⟦𝑧 (𝑖) ⟧)𝑙−1
Bit-add((⟦𝑥 (𝑖) ⟧)𝑙−1
𝑖=0 such that
there holds 𝑧 = 𝑥 +𝑦 for 𝐵𝐼𝑇 𝑆 (𝑥, (⟦𝑥 (𝑖) ⟧)𝑙−1
𝑖=0 ), 𝐵𝐼𝑇 𝑆 (𝑦, (⟦𝑦 (𝑖) ⟧)𝑙−1
𝑖=0 )
𝑖=0 ). To implement it, let 𝑐 (−1) = 0. For 𝑖 =
and 𝐵𝐼𝑇 𝑆 (𝑧, (⟦𝑧 (𝑖) ⟧)𝑙−1

𝑖=0 ; (⟦𝑦 (𝑖) ⟧)𝑙−1

3

0 . . . 𝑙 − 1:

⟦𝑧 (𝑖) ⟧ = Bit-xor(⟦𝑥 (𝑖) ⟧, Bit-xor(⟦𝑦 (𝑖) ⟧, ⟦𝑐 (𝑖−1) ⟧))
where Bit-xor(𝑎, 𝑏) = (𝑎 − 𝑏)2; and ⟦𝑐 (𝑖) ⟧ = ⟦𝑥 (𝑖) ⟧⟦𝑦 (𝑖) ⟧ +
⟦𝑐 (𝑖−1) ⟧((1 − ⟦𝑥 (𝑖) ⟧)⟦𝑦 (𝑖) ⟧ + ⟦𝑥 (𝑖) ⟧(1 − ⟦𝑦 (𝑖) ⟧)). After this loop,
return (⟦𝑧 (𝑖) ⟧)𝑙

𝑖=1.

2.6 Random Numbers
A (secure) pseudo-random number generator (PRG) is a function 𝐺 :
{0, 1}𝑘 → {0, 1}𝑝 (𝑘) for some polynomial 𝑝 with 𝑝 (𝑘) > 𝑘 such that
for any randomized polynomial time algorithm 𝐴 : {0, 1}𝑝 (𝑘) →
{0, 1} there holds |𝑃𝑥←𝑅 {0,1}𝑘 (𝐴(𝐺 (𝑥)) = 1)−𝑃𝑥←𝑅 {0,1}𝑝 (𝑘 ) (𝐴(𝑥) =
1)| ≤ 𝜇 (𝑘) for some function 𝜇 negligible in 𝑘. In other words, a
PRG is a function which takes a string 𝑥 as input and outputs a
longer string 𝐺 (𝑥) which cannot be distinguished from a random
sequence by a polynomial time algorithm.

3 PROBLEM STATEMENT
We call 𝜋 a sampling protocol over a domain X if 𝜋 is a randomized
multi-party protocol which outputs sequences of elements of X.
We consider sampling protocols which take only one input per
party at the beginning of the protocol. In particular, let P = {𝑃𝑖 }𝑛
𝑖=1
be the set of 𝑛 parties which participate to a sampling protocol
𝜋, and let 𝑠𝑖 be the input (also called seed) of party 𝑃𝑖 (for 𝑖 ∈
[𝑛]). We denote the output of 𝜋 by 𝜋 (s) where s = (𝑠𝑖 )𝑛
𝑖=1 is the
vector of seeds. We assume that there is some increasing polynomial
𝑝 : N → N such that if s ∈ {0, 1}𝑘×𝑛 then 𝜋 (s) ∈ X𝑝 (𝑘) . Let
s−𝑖 = (𝑠1, . . . , 𝑠𝑖−1, 𝑠𝑖+1, . . . , 𝑠 |𝑠 |) denote the vector s without the
𝑖-th component.

Definition 1 (Correct Sampling). For a multi-party protocol 𝜋, we
say a party is honest if it follows the steps of protocol 𝜋 correctly and
does not collude with other parties. We say that a sampling protocol
𝜋 correctly samples from a probability distribution D if there is a
function 𝜇 with 𝜇 (𝑘) negligible in 𝑘 such that for every run of 𝜋
by parties P = {𝑃𝑖 }𝑛
𝑖=1 among which there is at least one 𝑖 ∈ [𝑛]
such that party 𝑃𝑖 is honest, for every s−𝑖 ∈ {0, 1}𝑘×(𝑛−1) , for any
probabilistic polynomial time algorithm 𝐴 : {0, 1}𝑘 (𝑛−1) ×X𝑝 (𝑘) →
{0, 1}, there holds that either 𝜋 finishes correctly and

|𝑃𝑠𝑖 ←𝑅 {0,1}𝑘 (𝐴(s−𝑖, 𝜋 (s)) = 1)
− 𝑃𝑡←𝑅 {0,1}𝑘 (𝑛−1) ,𝑥←𝑅 D𝑝 (𝑘 ) (𝐴(𝑡, 𝑥) = 1)| ≤ 𝜇 (𝑘),
or 𝜋 aborts and detects a party that attempted to cheat, where D𝑝 (𝑘)
draws vectors from X𝑝 (𝑘) whose components are independently
distributed according to D.

In other words, if there is at least one honest party, then 𝜋 acts
as a (generalized) PRG even if all parties except that honest party
would disclose their seeds. As a result, as soon as a single party is
honest it can trust that any output of 𝜋 used by any party is pseudo-
random and no party could predict it in advance. We denote the
fact that 𝑥 is correctly drawn from D by 𝑥 ←∗

We say a protocol 𝜋 verifiably samples from D if 𝜋 correctly
samples from D and after every execution of 𝜋 the value of 𝑥 is
uniquely defined given the union of the information obtained by all
parties and the information published by 𝜋 is sufficient to convince

𝑅 D.

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

𝑅 D.

any party that 𝑥 has been correctly drawn. We denote the fact that
𝑥 is verifiably drawn from D by 𝑥 ←𝑉

In this paper, we will often informally consider both discrete
and continuous probability distributions, and 𝑃 D then either rep-
resents a probability mass or probability density according to the
context. As computers work with finite precision, we will eventu-
ally discretize up to some parameter-defined precision. While in
the end all distributions will be discrete, we will use the continuous
representations whenever this simplifies the explanation.

In the sequel, unless made explicit otherwise, we’ll assume there
are 𝑛 parties among whom at least one is honest, and that D is
a publicly agreed probability distribution. Also, to simplify the
explanation we will often describe protocols generating just one
random number, the extension to streams of random numbers is
then straightforward.

We can distinguish several types of verifiable sampling proto-
cols, depending on how they output the sampled number 𝑥. For a
verifiable sampling protocol 𝜋, we say it is a

• public draw if after running 𝜋 the value of 𝑥 is published.
• private draw if after running 𝜋 exactly one party knows 𝑥,
but the other parties have no information on 𝑥 next to the
prior distribution D.

• hidden draw if after running 𝜋 the parties have received
an additive secret share (𝑥1, . . . , 𝑥𝑛) for 𝑥, but still no party
has any information about 𝑥 next to the prior distribution
D.

In this paper, we study the problem of finding efficient verifiable
sampling protocols of each of the three above types given the prob-
ability distribution D.

This problem is reasonably straightforward if D is the uniform
distribution over the integers in the interval [0, 𝐿) for some 𝐿 > 0:

Protocol 1 (Public uniform sampling). For each 𝑖 ∈ [𝑛] let
party 𝑃𝑖 generate its own random number 𝑟𝑖 uniformly distributed
over [0, 𝐿) from its own secret seed 𝑠𝑖 and publish a commitment 𝐶𝑖
to it. Then, all parties open their commitment, i.e., they publish 𝑟𝑖 and
the randomness associated to the commitment to prove that 𝐶𝑖 was a
commitment to 𝑟𝑖 . Finally, all parties compute publicly (cid:205)𝑛
𝑖=1 𝑟𝑖 mod 𝐿.

It is easy to see Protocol 1 draws 𝑟 verifiably: if at least one
party 𝑃𝑖 is honest, it has generated a uniformly distributed number
𝑟𝑖 and 𝑟 is also uniformly distributed because non-honest parties
𝑃 𝑗 cannot change their 𝑟 𝑗 as a function of other parties because
they start with a commitment on their 𝑟 𝑗 . Note that Protocol 1 is a
generalization for multiple parties of [10]. We present the protocol
in more detail and prove its security in Appendix B.3.

Protocol 2 (Private uniform sampling). One can sample a
vector of 𝑘 numbers private to 𝑃1 as follows: 𝑃1 draws uniformly at
random a vector a = (𝑎1, . . . , 𝑎𝑘 ) ∈ [0, 𝐿)𝑘 and publishes a vector
commitment 𝐶 to it. Then, all parties generate jointly a public random
number 𝑟 ∈ [0, 𝐿) with Protocol 1. 𝑃1 expands 𝑟 to random numbers
(𝑟1, . . . , 𝑟𝑘 ) ∈ [0, 𝐿)𝑘 using a PRG. Finally, for 𝑖 ∈ [𝑘], 𝑃1 computes
𝑢𝑖 = 𝑎𝑖 +𝑟𝑖 mod 𝐿 and performs a zero knowledge proof of the modular
sum for each 𝑢𝑖 . (𝑢1, . . . , 𝑢𝑘 ) is a vector of private uniform random
numbers.

4

Again, it is easy to see that (𝑢1, . . . , 𝑢𝑘 ) is drawn verifiably. This
protocol has many aspects in common with the Augmented Coin-
Tossing protocol defined in [29, Section 7.4.3.5]. We provide a proof
of the security of Protocol 2 in Appendix B.4.

Protocol 3 (Hidden uniform sampling). For each 𝑖 ∈ [𝑛] let
party 𝑃𝑖 generate its own random number 𝑟𝑖 uniformly distributed
over [0, 𝐿) and publish a commitment 𝐶𝑖 to it. Then, they consider
(𝑟1, . . . , 𝑟𝑛) as a secret share of the random number 𝑟 = (cid:205)𝑛
𝑖=1 𝑟𝑖 mod 𝐿.
After running Protocol 3, if there is a honest party, 𝑟 is fixed and
follows the right probability distribution, and as not all parties col-
lude no party knows more about 𝑟 than that it follows the uniform
distribution over [0, 𝐿).

The problem of finding efficient verifiable sampling protocols
becomes more challenging when D is not the uniform distribution,
but a more general distribution such as a normal distribution or a
Laplace distribution. Even for single party computation there some-
times exist multiple approaches with varying cost and precision.

4 RELATED WORK
Below we describe lines of work that are related to ours.

Multiparty Computation between unreliable participants. The
seminal work of [10] proposed the first protocol to sample a public
random bit (i.e. tossing a coin) between two parties that do not trust
each other. Subsequent works such as [13] proposed protocols to
perform coin tossing between an arbitrary number of parties.

The work of [20] proved that in the malicious model without
aborts it is impossible that a multiparty protocol is guaranteed to
finish correctly and perform an unbiased coin toss if the number of
malicious users is half or more of the total of participants. For such
cases, there is no other possibility than providing weaker security
guarantees. In the framework of malicious security with abort[29],
protocols either end correctly or are aborted by malicious parties.
This could lead to bias in the computations if a protocol is restarted
after an abort and the adversary speculatively chooses when allow
the protocol to finish correctly. To prevent this, a possible solution
is to identify and punish malicious parties that cause aborts. The
work of [3] proposes covert security, where cheating adversaries can
get caught with certain probability. This is weaker than malicious
security with abort, but allows cheaters to be detected. A stronger
notion is malicious security with identifiable abort[33], where a
party that cheats causes the protocol to abort with overwhelming
probability and, in addition, the cheater is identified. Our work fits
in that framework.

If deterrence measures are strong enough, this could be sufficient
to discourage malicious behavior. Otherwise, if corrupted peers are
willing to sacrifice themselves at any cost, other measures can be
taken to attenuate the bias as much as possible [5, 43].

The work [30] proposes a method to securely perform a wide
family of randomized computations (related to interactive games)
over private data and private random numbers, using zero knowl-
edge proofs to verify correctness. They prove that this is secure
in the ideal paradigm without abort if the majority of parties is
honest.

Sampling from Gaussians and other popular non-uniform distribu-
tions. Distributions such as the Gaussian distribution, the Laplace

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

distribution, the Poisson distribution or the exponential distribution
are important in the field of statistics. Algorithms to securely draw
from such distributions have applications in federated machine
learning. Several contributions concern the problem of verifiable
noise for differential privacy [35, 50] and hence can benefit from
secure drawing.

Even in the semi-honest model where parties follow the specified
protocol, drawing hidden random numbers is sometimes non-trivial.
For example, in [19] one needs to make a sum of statistics and
a Laplacian-distributed noise term, hence the authors propose a
protocol where parties generate random numbers summing to a
Laplacian distributed value which can then be included in a secure
aggregation without being revealed.

In [26], protocols are proposed to generate secret-shared sam-
ples for Gaussian, Exponential and Poisson distributions. For the
Gaussian distribution, their approach generates samples by aver-
aging uniform seeds, a method which we call the Central Limit
Theorem (CLT) approach. We compare the CLT approach with our
approaches in Section 9. Even if more than a decade has passed
since [26], recent contributions still resort to these techniques to
generate Gaussian samples among unreliable participants. For ex-
ample, recent protocols use the technique of [26] by adapting it
to generate private draws from the Exponential distribution [45]
and to sample hidden draws from the Binomial distribution [9].
The work of [41] proposes techniques to securely sample from the
geometrical and Gaussian distributions, both building on [26], and
studies them in the light of differentially private memory access
patterns. In addition, [41] defines an extension of the malicious
security model which includes information leakage, as measured
in differential privacy, and proves the security of their protocols
within this model.

In our work, we propose new techniques for privately drawing
from the Gaussian distribution and show that all our techniques for
all but the lowest precision requirements outperform the technique
of [26], which is the most efficient method known so far. The same
dynamics are at play for exponential, Poisson and Laplace distri-
butions. Compared to the techniques in [26], our methods have a
better complexity as a function of the precision parameter. We ex-
tend our methodology to hidden draws of Gaussian, Laplacian and
Arbitrary distributions. Achieving sufficient precision when sam-
pling is important for both the statistical quality and the security
of the algorithms [42].

Implementation of math functions using cryptographic primitives.
Using secret sharing techniques, there is a large body of work on
how to compute math functions such as square roots, logarithms
and trigonometric [1, 4, 25, 32, 32, 37]. However they usually rely on
splines or other approximation techniques that approximate func-
tions by splitting the domain and using low-degree polynomials
for each part. Alternatively, they rely on rational approximations.
Piecewise approximations require the use of conditionals which
are expensive when computing with secret shares, and rational
approximations only allow for a fixed precision. Our work uses
iterative approximations which allow to customize the precision
of the approximation and are easy to compute given that we avoid
the use of comparison gates in our circuits. Furthermore, for the

5

Gaussian distribution, piecewise approximations require an exter-
nal method to sample from the tails of the distribution. We also
show protocols for private sampling from Gaussian and Laplace
distributions where we avoid the high cost of secret shared compu-
tation by letting one party perform the calculation and then prove
correct behavior using compressed Σ-protocols.

Zero Knowledge Proofs for such functions, as we apply in our
work, is a less explored technique. [54] proposes techniques to prove
a limited set of relations involving common activation functions in
machine learning.

5 METHOD
We start with discussing two generic approaches: a strategy based
on the inverse cumulative probability distribution and a strategy
based on table lookup.

5.1 Inverse Cumulative Probability

Distribution

Assume D is a probability distribution on X ⊆ R. The cumulative
probability distribution is defined as

∫

𝐹 D (𝑥) =

𝑃 D (𝑡) d𝑡

𝑡 ≤𝑥
To the extent D is discrete, we can see 𝑃 D as a sum of scaled Dirac
delta functions over which integration is possible and results in a
sum. Then, the inverse 𝐹 −1
D

is a function on the interval (0, 1).

An approach to sampling from arbitrary distributions D on do-
mains X ⊆ R, known as the inversion method, consists of sampling
uniformly from the (0, 1) interval and applying the inverse of the
cumulative distribution function 𝐹 −1
. Indeed, if 𝑡 ←𝑅 (0, 1), then
D
𝑃 (𝐹 −1

D (𝑡) = 𝑥) = 𝑃 D (𝑥).
Public Sampling from an Arbitrary Distribution. This approach

can easily be applied to draw random numbers publicly:

Protocol 4 (Public draw from arbitrary distribution). Run
protocol 1 to generate a public uniformly distributed random number
𝑟 ′, and then publicly compute 𝑟 = 𝐹 −1

D (𝑟 ′).

Using the inversion method for private or hidden draws is more
involved since one needs a multi-party algorithm to compute 𝐹 −1
D
or a ZKP algorithm to prove to other parties that 𝐹 −1
was applied
D
correctly. In many practical cases, 𝐹 −1
does not have a simple closed
D
form. This especially holds for the Gaussian distribution which we
will discuss in more detail in Section 8.

We can extend this method to multi-variate distributions. For
example, consider a distribution D over R2. To sample a pair (𝑥, 𝑦)
according to D, we first define 𝑃𝑥 (𝑥) = ∫ 𝑃 D (𝑥, 𝑦) d𝑦, apply the
inversion method to draw a random number 𝑥 according to 𝑃𝑥 , and
then define 𝑃𝑦 |𝑥 (𝑦) = 𝑃 D (𝑦|𝑥) = 𝑃 D (𝑥, 𝑦)/𝑃𝑥 (𝑥) and apply again
the inversion method to draw a random 𝑦.

5.2 Table Lookup
As pointed out above, practical inverse cumulative probability func-
tions are often expensive to compute, especially in a secure multi-
party setting. In such scenarios approaches such as the ones dis-
cussed in Sections 5.1 and 8 incur a high cost for each drawn random

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

number. In this section we consider an approach based on table
lookup. While the involved techniques are well-known, this ap-
proach is interesting as a baseline, especially as it has a number of
properties which are different from the other methods considered
in this paper. In particular, the method studied here has a high
pre-processing cost but then allows for drawing random numbers
at a low constant cost per drawn random number.

Protocol 5 (Table-lookup private sampling).

• Preprocessing. Let 𝑀 ∈ N. The parties publicly pre-compute
(cid:17)(cid:17) for all 𝑖 ∈ [𝑀] and store them into a

(cid:16) 2𝑖−1
2𝑀

the pairs (cid:16)
database DB.

𝑖, 𝐹 −1
D

• Sampling. Party 𝑃1 privately draws using Protocol 2 a random
number 𝑟 ′ distributed uniformly in [𝑀]. Then, 𝑃1 sets 𝑟 =
(cid:17), publishes commitments to 𝑟 ′ and 𝑟 , and publishes
𝐹 −1
D
a ZKP that (𝑟 ′, 𝑟 ) ∈ DB.

(cid:16) 2𝑟 ′−1
2𝑀

In Protocol 5 a zero knowledge set membership proof is needed.
There is a large body of work on this topic since in [15] the first
method was shown that has a large preprocessing cost (linear in
𝑀) but only a unit communication cost for proving membership.
Several improvements have been proposed which vary in their
assumptions and efficiency, [7] discusses some lines of recent work.
Only already storing the database DB may take a prohibitive
amount of space if a high precision is needed, as 𝑀 is exponential
in the number of desired correct digits. As a result, this technique
can only be used when the needed precision is not too high. If it is
feasible, it is expensive for drawing only a few random numbers but
it can become more efficient than other methods if a huge number
of random numbers need to be drawn, as asymptotically the cost
per sample will dominate.

5.3 Laplace Distribution
The Laplace distribution, denoted 𝐿𝑎𝑝 (𝑏) is defined by

𝑃𝐿𝑎𝑝 (𝑏) (𝑥) = exp(−|𝑥 |/𝑏)/2𝑏.

The cumulative distribution is

𝐹𝐿𝑎𝑝 (𝑥) = 1/2 + sign(𝑥)/2 − sign(𝑥) exp(−|𝑥 |/2).

To sample a number 𝑟 from 𝐿𝑎𝑝 (𝑏) it is convenient to separately
draw the sign 𝑠 and absolute value 𝑎 of 𝑟 . Then, 𝑃 (𝑠 = −1) = 𝑃 (𝑠 =
(cid:17). In
1) = 1/2 and 𝑃 (𝑎) = 1
𝑏
Section 7 we will describe protocols for both private and hidden
Laplace-distributed draws.

(cid:17) and 𝑃 (𝑎 ≤ 𝑡) = 1 − exp (cid:16)

exp (cid:16)

− 𝑎
𝑏

− 𝑡
𝑏

5.4 Gaussian Distribution
The Gaussian distribution, denoted by N (𝜇, 𝜎2), is defined by
𝑃N (𝜇,𝜎 2) (𝑥) = exp(−(𝑥 − 𝜇)2/2𝜎2)/

2𝜋𝜎.

√

We will sometimes use the shorthand 𝑃N = 𝑃N (0,1) . The cumulative
distribution is

𝐹 N (𝑥) = (1 + erf(𝑥/

(1)
where erf is the error function. There is no closed form for 𝑃N, 𝐹 N
nor its inverse. In the single party setting multiple strategies have
been investigated to sample from this important distribution:

2))/2

√

• the Central Limit Theorem (CLT) approach, which consists
of sampling repeatedly from a uniform distribution and com-
puting the average, which is simple but requires 𝑂 (1/Δ2)
time for a root mean squared error Δ,

• the Box-Müller method [12], that can obtain two Gaussian
numbers from two uniform samples by the application of
a closed form formula, but involves the computation of a
square root, trigonometric functions and a logarithm,

• rejection sampling methods, such as the polar version of
Box-Müller [36] or the Ziggurat Method [40] are efficient
and highly accurate. While the former avoids the compu-
tation of trigonometric functions and leads to an efficient
verifiable implementation, the latter uses several conditional
branches which are expensive to prove in zero knowledge
and requires an external method for sampling in the tails of
the distribution,

• the inversion method for Gaussians that involves the approx-
imation of the inverse error function erf −1, which can be
done with rational functions or Taylor polynomials, and
• the recursive method of Wallace [51], which is very popular
for its efficiency, but requires as input a vector of already
generated Gaussian samples to generate an output vector
of the same size; furthermore, samples from input and out-
put vectors are correlated, which deteriorates the statistical
quality.

Before studying some of these in the multi-party setting, we will
first provide Σ-protocols of relations involving approximations of
certain elementary functions.

6 PROOFS OF ELEMENTARY FUNCTIONS
In this section, we construct zero knowledge proofs of statements
that involve the approximation of elementary functions, i.e. sine,
cosine, natural logarithm and square root. These functions can
be numerically approximated using basic operations such as addi-
tion and multiplication. While classic cryptographic tools are used
to prove statements over integers, we operate with real numbers
which we approximate with fixed precision. Therefore, we use rep-
resentations of integer multiples of 2−𝜓 by multiplying our values
with 2𝜓 and rounding them deterministically to obtain elements of
Z𝑝 . Negative numbers are represented in the upper half of Z𝑝 . For
example, the number 𝑎 < 0 is represented with 𝑝 + 2𝜓 𝑎. The set of
representable numbers is denoted by

Q⟨𝑝,𝜓 ⟩ = {𝑣 ∈ Q : 2𝜓 𝑣 ∈ Z ∧ −𝑝/2 ≤ 2𝜓 𝑣 < 𝑝/2}

which is closed under addition and multiplication modulo 𝑝 (rounded
up to 2−𝜓 ). The encoding of 𝑣 ∈ Q⟨𝑝,𝜓 ⟩ is denoted by ⟨𝑣⟩ =
2𝜓 𝑣 mod 𝑝.

We show circuits such that the nullity of their output is equiv-
alent to the statements we want to prove. We will first construct
circuits to describe low level statements and then use these as
building blocks for higher level statements. In the end, we apply
compressed Σ-protocols (see Section 2.4) to produce zero knowl-
edge proofs of these circuits. For parameters (𝑎; 𝑏) of all circuits
defined below, 𝑎 always contains public constants and 𝑏 private
values.

6

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

We present in Section 6.1 circuits for proving various types of
simple statements. In Section 6.2, we introduce Cordic, the core
approximation algorithm. We implement circuits to prove its correct
execution in Section 6.3, and details on how to expand its domain
of application, particularly for our sampling techniques, in Section
6.4.

6.1 Building Blocks
We introduce below proofs of basic statements that we will use to
prove approximations, including the handling of some statements
of numbers in Q⟨𝑝,𝜓 ⟩. Note that additions, multiplication by an
integer and range proofs port directly to Z𝑝 by our encoding ⟨·⟩.
In Appendix A.5, we show that to prove that an integer 𝑥 ∈ Z𝑝
belongs to [0, 2𝑘 ) we can use the circuit

𝐶𝑅𝑎 (𝑘; 𝑥, x) (cid:66)

(cid:20) x ∗ (1 − x)
𝑥 − (cid:205)𝑘

𝑖=1 𝑥𝑖 2𝑖−1

(cid:21)

where x = (𝑥1, . . . , 𝑥𝑘 ) is the bit map of 𝑥. Here, x ∗ (1 − x) is a
vector with at position 𝑖 the value 𝑥𝑖 (1−𝑥𝑖 ), which is 0 if 𝑥𝑖 ∈ {0, 1}.
The second expression evaluates to 0 if x is indeed the correct bit
map of 𝑥. Hence, the nullity of the circuit, i.e., its righthandside
evaluating to the zero vector, proves 𝑥 ∈ [0, 2𝑘 ).

Generalized range proof. 𝐶𝑅𝑎 can be used twice to prove mem-
bership in any range [𝑎, 𝑏] ⊂ Z𝑝 . To prove 𝑥 ∈ [𝑎, 𝑏] we use the
circuit

𝐶𝐺𝑅𝑎 (𝑎, 𝑏; 𝑥, s1, s2) (cid:66)

(cid:20) 𝐶𝑅𝑎 (⌊log(𝑏 − 𝑎)⌋ + 1; 𝑥 − 𝑎, s1)
𝐶𝑅𝑎 (⌊log(𝑏 − 𝑎)⌋ + 1; 𝑏 − 𝑥 + 𝑎, s2)

(cid:21)

where s1, s2 ∈ {0, 1} ⌊log(𝑏−𝑎) ⌋+1 the auxiliary bit vectors required
for 𝐶𝑅𝑎.

(Right) Bit-shift. For 𝑎 ∈ Q⟨𝑝,𝜓 ⟩ and an integer 𝑘 > 0, a bit shift
𝑎 >> 𝑘 is equal to the biggest value in Q⟨𝑝,𝜓 ⟩ smaller than 𝑎/2𝑘 .
We have that 𝑏 = 𝑎 >> 𝑘 if ⟨𝑎⟩ − 2𝑘 ⟨𝑏⟩ ∈ [0, 2𝑘 ). For the vector s
of the bit decomposition of ⟨𝑎⟩ − 2𝑘 ⟨𝑏⟩, the circuit is

𝐶>> (𝑘; ⟨𝑎⟩, ⟨𝑏⟩, s) (cid:66) 𝐶𝑅𝑎 (𝑘; ⟨𝑎⟩ − 2𝑘 ⟨𝑏⟩, s).

Note that in the definition of 𝐶>>, as in all subsequent circuits, the
evaluation of inputs to sub-circuits such as 𝐶𝑅𝑎 are computations
performed within the circuit.

Approximate product. For private 𝑎, 𝑏, 𝑐 ∈ Q⟨𝑝,𝜓 ⟩, it can be proven
that 𝑐 is the rounding of 𝑎𝑏, that is by proving that ⟨𝑐⟩ − ⟨𝑎⟩⟨𝑏⟩ +
⟨1/2⟩ ∈ [0, 2𝜓 ). For s ∈ {0, 1}𝜓 the bitmap of ⟨𝑐⟩ − ⟨𝑎⟩⟨𝑏⟩ + ⟨1/2⟩
our circuit is

𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝑎⟩, ⟨𝑏⟩, ⟨𝑐⟩, s) (cid:66) 𝐶𝑅𝑎 (𝜓 ; ⟨𝑐⟩ − ⟨𝑎⟩⟨𝑏⟩ + ⟨1/2⟩, s).

Approximate division. For private 𝑎, 𝑏, 𝑐 ∈ Q⟨𝑝,𝜓 ⟩, we prove that 𝑐
is approximately 𝑎/𝑏 with error 2−𝜓 . We also require that 𝑏 ∈ [𝐴, 𝐵]
for public 𝐴, 𝐵 ∈ Q⟨𝑝,𝜓 ⟩. We prove that ⟨𝑏⟩⟨𝑐⟩ − 2𝜓 ⟨𝑎⟩ + ⟨𝑏⟩ ∈
[0, 2⟨𝑏⟩). Our range proofs require that the bounds are public, so
we prove that ⟨𝑏⟩⟨𝑐⟩ − 2𝜓 ⟨𝑎⟩ + ⟨𝑏⟩ ∈ [0, 2𝑠𝑏 +1) and 2𝜓 ⟨𝑎⟩ − ⟨𝑏⟩⟨𝑐⟩ ∈
[0, 2𝑠𝑏 +1) where 𝑠𝑏 = ⌊log2 (⟨𝐵⟩ − ⟨𝐴⟩)⌋ + 1. For s1, s2 ∈ Z𝑠𝑏 +1

𝑝

auxiliary bit vectors, the circuit is

𝐶𝐷𝑖𝑣 (𝜓, 𝑠𝑏 ; ⟨𝑎⟩, ⟨𝑏⟩, ⟨𝑐⟩, s1, s2)

(cid:66)

(cid:20)𝐶𝑅𝑎 (𝑠𝑏 ; ⟨𝑏⟩⟨𝑐⟩ − 2𝜓 ⟨𝑎⟩ + ⟨𝑏⟩, s1)
𝐶𝑅𝑎 (𝑠𝑏 ; 2𝜓 ⟨𝑎⟩ − ⟨𝑏⟩⟨𝑐⟩, s2)

(cid:21)

.

Exponentiation in Z𝑝 . Let 𝑦, 𝑥 ∈ Z𝑝 be private values with 𝑥 ∈
[0, 2𝑘 ) and 𝐸 ∈ Z𝑝 a public integer such that 𝐸𝑥 < 𝑝/2. We prove
that 𝑦 = 𝐸𝑥 . Let x ∈ {0, 1}𝑘 the vector of bits of 𝑥, we prove that
𝑦=1 𝑦𝑖 where for 𝑖 ∈ {1, . . . , 𝑘 }, 𝑦𝑖 is equal to 𝐸2𝑖−1 if x𝑖 = 1,
𝑦 = (cid:206)𝑘
or to 1 if x𝑖 = 0. The circuit is

𝐶𝐼 𝐸𝑥 (𝑘, 𝐸; 𝑥, 𝑦, x) (cid:66)

(cid:20)
𝑦 − (cid:206)𝑘

𝐶𝑅𝑎 (𝑘; 𝑥, x)
𝑖=1 1 + x𝑖 (𝐸2𝑖−1

(cid:21)

.

− 1)

Modular sum. We prove, for private 𝑥, 𝑧 ∈ Z𝑝 and public 𝑦 ∈ Z𝑝
such that all belong to [0, 𝑀), that 𝑧 = 𝑥 + 𝑦 mod 𝑀. Let x1, x2, z1
and z2 vectors of intermediate values for 𝐶𝐺𝑅𝑎, and let 𝑏 ∈ {0, 1},
our circuit is

𝐶𝑀𝑜𝑑 (𝑀, 𝑦; 𝑥, 𝑧, x1, x2, z1, z2, 𝑏) (cid:66)

𝐶𝐺𝑅𝑎 (0, 𝑀 − 1; 𝑥, x1, x2)


𝐶𝐺𝑅𝑎 (0, 𝑀 − 1; 𝑧, z1, z2)


𝑏 (1 − 𝑏)


𝑧 − (𝑥 + 𝑦 − 𝑏𝑀)












.

Ideas for 𝐶𝐼 𝐸𝑥 and 𝐶𝑀𝑜𝑑 are taken from pages 112-115 of [16].

Private magnitude shift. Here, we prove that 𝑦 = 𝑥 >> 𝑘 for
public 𝐾 and private 𝑘 ≤ 𝐾. Let k, k′, k′′ ∈ {0, 1}𝐾 and ℎ ∈ Z𝑝 be
intermediate values for range proofs and integer exponentiations
and I>> = (ℎ, k, k′, k′′), our circuit is

𝐶𝑃 >> (𝐾; 𝑥, 𝑘, 𝑦, I>>) (cid:66)

𝐶𝐼 𝐸𝑥 (𝐾, 2; 𝑘, ℎ, k)


𝐶𝑅𝑎 (𝐾; 𝑥 − ℎ𝑦, k′)


𝐶𝑅𝑎 (𝐾; ℎ − 𝑥 + ℎ𝑦 − 1, k′′)










.

6.2 Cordic Algorithm
We use the Cordic algorithm [52] for approximations, which has
long been state of the art for computations of elementary functions
from simple operations [44]. Essentially, it uses the same core it-
eration algorithm, which only uses additions and bit-shifts, for all
elementary function approximations. We will use Cordic parame-
terized for two settings described below, the first is used for sine
and cosine and the second for square root and logarithm. In what
follows, we only provide an algorithmic description of the Cordic
algorithm as is needed in order to understand our extension to the
zero knowledge setting in Section 6.3.

Setting 1 (Sine and Cosine). Let 𝜃0 = 0. From input values 𝑋0, 𝑌0, 𝜃 ∈

Q⟨𝑝,𝜓 ⟩, the following iterations are performed:

𝑋𝑖 = 𝑋𝑖−1 − 𝜉𝑖 (𝑌𝑖−1 >> 𝑖)
𝑌𝑖 = 𝑌𝑖−1 + 𝜉𝑖 (𝑋𝑖−1 >> 𝑖)
𝜃𝑖 = 𝜉𝑖 tan−1 (1 >> 𝑖) + 𝜃𝑖−1

where 𝜉𝑖 ∈ {−1, 1} is equal to sign(𝜃 − 𝜃𝑖−1) and tan−1 (1 >> 𝑖)
is taken from a precomputed table. Let 𝜈 be the total number of
(cid:112)1 + (1 >> 2𝑗) and 𝐾1 =
iterations, and let constants 𝐾1,𝜈 = (cid:206)𝜈

𝑗=0

7

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

lim𝜈→∞ 𝐾1,𝜈 ≈ 1.6. We have that

.















= 𝐾1

lim
𝜈→∞

𝑋𝜈


𝑌𝜈


𝜃𝜈 − 𝜃



𝑋0 cos 𝜃 − 𝑌0 sin 𝜃


𝑋0 sin 𝜃 + 𝑌0 cos 𝜃


0


Recall the representation parameter 𝜓 of Q⟨𝑝,𝜓 ⟩ defined at the
beginning of the section. By the convergence rate of Cordic, if
𝜓 ≥ 𝜈 + ⌈log2 (𝜈)⌉ + 1, with input 𝑋0 = 1/𝐾1,𝜈 , 𝑌0 = 0, and
𝜃 ∈ [−𝜋/2, 𝜋/2], then 𝑋𝜈 and 𝑌𝜈 are approximations of sin(𝜃 )
and cos(𝜃 ) respectively with error at most 21−𝜈 .
√

𝑥). In this setting Cordic only takes two
inputs 𝑋0, 𝑌0 ∈ Q⟨𝑝,𝜓 ⟩ and, with 𝜃0 = 0, it performs the iterations

Setting 2 (ln(𝑥) and

𝑋𝑖 = 𝑋𝑖−1 + 𝜉𝑖 (𝑌𝑖−1 >> 𝐹𝑖 )
𝑌𝑖 = 𝑌𝑖−1 + 𝜉𝑖 (𝑋𝑖−1 >> 𝐹𝑖 )
𝜃𝑖 = 𝜉𝑖 tanh−1 (1 >> 𝐹𝑖 ) + 𝜃𝑖−1
with 𝜉𝑖 = sign(−𝑌𝑖−1) and shift magnitude 𝐹𝑖 = 𝑖 + 1 − 𝑘 where
the small value 𝑘 is equal to the biggest integer such that 3𝑘+1 +
(cid:112)1 + (1 >> 2𝐹 𝑗−1) and
2𝑘 − 1 ≤ 2(𝑖 + 1). Now let 𝐾2,𝜈 = (cid:206)𝜈
𝐾2 = lim𝜈→∞ 𝐾2,𝜈 ≈ 0.8. In Setting 2, we have that

𝑗=1

(cid:113)

.

=








lim
𝜈→∞

𝑋𝜈


𝑌𝜈


𝜃𝜈



0 − 𝑌 2
𝑋 2
0
0
tanh−1 (cid:16) 𝑌0
𝑋0


𝐾2







With 𝜓 as in Setting 1, 𝑥 ∈ [ 1
4 , 1) and fixing 𝑋0 = 𝑥 + 1, 𝑌0 =
𝑥 − 1 we get by the identity ln(𝑥) = 2 tanh−1 ( 𝑥−1
𝑥+1 ) that 𝜃𝜈 is
an approximation of 1
2 ln(𝑥) with error at most 21−𝐹𝜈 . Similarly,
for the same 𝜓 and domain of 𝑥,
𝑥 can be obtained by setting
(cid:19)










√

(cid:17)

with error at most 21−𝐹𝜈 .

(𝑋0, 𝑌0) =

(cid:18)
𝑥 +

1
𝐾 2

2,𝑛+1

, 𝑥 − 1
𝐾 2

2,𝑛+1

6.3 Cordic in Zero Knowledge
We first specify a set of statements that together are equivalent to
a correctly performed Cordic computation. Note that the iterations
in Settings 1 and 2 are very similar. Except for the correctness of
the 𝜉𝑖 values, they can be described by equations

𝜉𝑖 = −1 ∨ 𝜉𝑖 = 1 ∀𝑖 ∈ {1, . . . , 𝜈 },
𝑌𝑖 = 𝑌𝑖−1 + 𝜉𝑖 (𝑋𝑖−1 >> 𝐹𝑖 ) ∀𝑖 ∈ {1, . . . , 𝜈 },
𝑋𝑖 = 𝑋𝑖−1 − 𝑚𝜉𝑖 (𝑌𝑖−1 >> 𝐹𝑖 ) ∀𝑖 ∈ {1, . . . , 𝜈 },

𝜃𝜈 =

𝜈
(cid:213)

𝑖=1

𝜉𝑖𝛼𝑖,

(2)

(3)

(4)

(5)

where the constants in Setting 1 are 𝑚 = 1, 𝐹𝑖 = 𝑖 and 𝛼𝑖 =
tan−1 (1 >> 𝑖) and in Setting 2, 𝐹𝑖 is already defined, 𝑚 = −1
and 𝛼𝑖 = tanh−1 (1 >> 𝐹𝑖 ). To prove the correct value of the 𝜉𝑖 ’s,
we avoid wide range checks at each iteration (on 𝜃 − 𝜃𝑖 or 𝑌𝑖−1),
but instead we use properties of the convergence of Cordic: all of
𝜉1, . . . , 𝜉𝜈 ∈ {−1, 1} have been chosen correctly if

𝜃𝜈 − 𝜃 ∈ [−𝛼𝜈, 𝛼𝜈 ]

𝑌𝜈 ∈ [−2−𝐹𝜈−1, 2−𝐹𝜈−1 ]

in Setting 1, and

in Setting 2.

(6)

(7)

8

We outline below the circuits that imply the above statements.
Let 𝑆 ∈ {1, 2} be the Cordic setting that defines the involved con-
stants. Let 𝜉 ∗ = (𝜉1, . . . , 𝜉𝜈 ) and let
𝑖=1 , (s𝑖, s′
be the vector of all intermediate values. The nullity of circuit

I = (⟨𝑋𝑖 ⟩, ⟨𝑌𝑖 ⟩)𝜈−1

𝑖=0 , 𝜉 ∗)

𝑖 ⟩)𝜈−1

𝑖 ⟩, ⟨𝑌 ′

𝑖, ⟨𝑋 ′

𝐶𝐶𝑟𝑑 (𝜈, 𝑆; ⟨𝑋0⟩, ⟨𝑌0⟩, ⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I)
𝐶>> (𝐹𝑖 ; ⟨𝑋𝑖−1⟩, ⟨𝑋 ′


𝐶>> (𝐹𝑖 ; ⟨𝑌𝑖−1⟩, ⟨𝑌 ′











⟨𝑌𝑖 ⟩ − ⟨𝑌𝑖−1⟩ − 𝜉𝑖 ⟨𝑋 ′
⟨𝑋𝑖 ⟩ − ⟨𝑋𝑖−1⟩ + 𝑚𝜉𝑖 ⟨𝑌 ′

(1 + 𝜉 ∗) ∗ (1 − 𝜉 ∗)

⟨𝜃𝜈 ⟩ − (cid:205)𝜈

𝑖=1 𝜉𝑖 ⟨𝛼𝑖 ⟩

(cid:66)

𝑖−1⟩, s𝑖−1) ∀𝑖 ∈ [𝜈]
𝑖−1⟩, s′
𝑖−1) ∀𝑖 ∈ [𝜈]

𝑖−1⟩ ∀𝑖 ∈ [𝜈]
𝑖−1⟩ ∀𝑖 ∈ [𝜈]














is a proof of the core of the execution in eqs. (2) to (5). Here, for
𝑖 ∈ {0, 1}𝐹𝑖 are auxiliary bit vectors to prove bit
𝑖 ∈ {1, . . . , 𝜈 }, s𝑖, s′
shifts of 𝑋𝑖 and 𝑌𝑖 with result 𝑋 ′

𝑖−1 respectively.
We complete the above core circuit for Setting 1. Let

𝑖−1 and 𝑌 ′

𝛾 = ⌊log2 (2⟨𝛼𝜈 ⟩)⌋ + 1,
and let s𝛼 ∈ {0, 1}𝛾 be the bit decomposition of ⟨𝜃 ⟩ − ⟨𝜃𝜈 ⟩. The
circuit

𝐶𝐶𝑟𝑑1 (𝜈; ⟨𝜃 ⟩, ⟨𝑋0⟩, ⟨𝑌0⟩, ⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I, s𝛼 )

(cid:66)

(cid:20)𝐶𝐶𝑟𝑑 (𝜈, 1; ⟨𝑋0⟩, ⟨𝑌0⟩, ⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I)
𝐶𝑅𝑎 (𝛾; ⟨𝜃 ⟩ − ⟨𝜃𝜈 ⟩ + ⟨𝛼𝜈 ⟩, s𝛼 )

(cid:21)

.

proves eqs. (2) to (6). Similarly, we extend the core circuit to a
complete one for setting 2: for s𝑌 equal to the bit decomposition of
𝑌𝜈 ,

𝐶𝐶𝑟𝑑2 (𝜓, 𝜈; ⟨𝑋0⟩, ⟨𝑌0⟩, ⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I, s𝑌 )

(cid:66)

(cid:20)𝐶𝐶𝑟𝑑 (𝜈, 2; ⟨𝑋0⟩, ⟨𝑌0⟩, ⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I)
𝐶𝑅𝑎 (𝜓 − 𝐹𝜈 ; ⟨𝑌𝜈 ⟩, s𝑌 )

(cid:21)

.

proves eqs. (2) to (5) and (7).

The instantiation of 𝐶𝐶𝑟𝑑1 and 𝐶𝐶𝑟𝑑2 for elementary functions
is straightforward. Inputs that are intermediate values are defined
as above. For trigonometric functions, we set I𝑇 = (⟨𝜃𝜈 ⟩, I, s𝛼 ) and
use

𝐶𝑇 𝑟 (𝜈; ⟨𝜃 ⟩, ⟨𝑐⟩, ⟨𝑠⟩, I𝑇 ) (cid:66) 𝐶𝐶𝑟𝑑1 (𝜈; ⟨𝜃 ⟩, ⟨1/𝐾1,𝜈 ⟩, 0, ⟨𝑠⟩, ⟨𝑐⟩, I𝑇 )

to compute 𝑠 = sin(𝜃 ) and 𝑐 = cos(𝜃 ). For the logarithm, let I𝐿 =
(⟨𝑋𝜈 ⟩, ⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I, s𝑌 ). Then,

𝐶𝐿𝑜𝑔 (𝜓, 𝜈; ⟨𝑥⟩, ⟨𝑙⟩, I𝐿) (cid:66)

(cid:20)𝐶𝐶𝑟𝑑2 (𝜓, 𝜈; ⟨𝑥⟩ + ⟨1⟩, ⟨𝑥⟩ − ⟨1⟩, I𝐿)
⟨𝑙⟩ − 2⟨𝜃𝜈 ⟩

(cid:21)

proves 𝑙 = ln(𝑥). For the square root let I𝑆 = (⟨𝑌𝜈 ⟩, ⟨𝜃𝜈 ⟩, I, s𝑌 ), then

𝐶𝑆𝑞𝑟𝑡 (𝜓, 𝜈; ⟨𝑥⟩, ⟨𝑠⟩, I𝑆 ) (cid:66)
𝐶𝐶𝑟𝑑2 (𝜓, 𝜈; ⟨𝑥⟩ + ⟨1/4𝐾 2

2,𝜈+1⟩, ⟨𝑥⟩ − ⟨1/4𝐾 2

2,𝜈+1⟩, ⟨𝑠⟩, I𝑆 )

proves 𝑠 =

√

𝑥.

Finally, we point out that, with minor adjustments to the above
approximations, proofs of hyperbolic trigonometric functions and
𝑒𝑥 can be obtained.

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

6.4 Extending the Domain
Here we extend the domain of approximations, which is necessary
for our sampling applications. We sometimes do not define inputs
such as bit vectors for range proofs and other intermediate values
that are clear from the context or that are already defined in previous
circuits.

Sine and cosine. As shown, sine and cosine can be approximated

in (cid:2)− 𝜋

2 , 𝜋
2

(cid:3). For 𝑄 ∈ {1, 2, 3, 4} we use the identity

sin (cid:16)
𝑄

𝜋
2

+ 𝜃 ′(cid:17)

=

cos(𝜃 ′)
− sin(𝜃 ′)
− cos(𝜃 ′)
sin(𝜃 ′)






if 𝑄 = 1
if 𝑄 = 2
if 𝑄 = 3
if 𝑄 = 4

extend the domain to [0, 2𝜋]. Let s𝜋 , s′
𝐶𝐺𝑅𝑎, and I𝑇𝑔 = (⟨𝜃 ′⟩, ⟨𝑠 ′⟩, ⟨𝑐 ′⟩, 𝑄, s𝜋 , s′

𝜋 , I𝑇 ). Let

𝜋 be bit vectors as needed for

([ 𝑗1], [ 𝑗2], [ 𝑗3], [ 𝑗4]) = (⟨𝑐 ′⟩, −⟨𝑠 ′⟩, −⟨𝑐 ′⟩, ⟨𝑠 ′⟩)

and

([𝑘1], [𝑘2], [𝑘3], [𝑘4]) = ([ 𝑗2], [ 𝑗3], [ 𝑗4], [ 𝑗1])

for 𝑖 ∈ {1, 2, 3, 4} be literal variable replacements. Circuit

𝐶𝑇 𝑟𝐺 (𝜈; ⟨𝜃 ⟩, ⟨𝑠⟩, ⟨𝑐⟩, I𝑇𝑔)

(cid:66)










𝐶𝐺𝑅𝑎 (⟨− 𝜋

𝐶𝑇 𝑟 (𝜈; ⟨𝜃 ′⟩, ⟨𝑠 ′⟩, ⟨𝑐 ′⟩, I𝑇 )
2 ⟩; ⟨𝜃 ′⟩, s𝜋 , s′
𝜋 )
2 ⟩ − ⟨𝜃 ′⟩

2 ⟩, ⟨ 𝜋
⟨𝜃 ⟩ − 𝑄 ⟨ 𝜋

(cid:206)4

𝑖=1 (𝑄 − 𝑖)2 + ([ 𝑗𝑖 ] − ⟨𝑠⟩)2 + ([𝑘𝑖 ] − ⟨𝑐⟩)2










proves 𝑠 = 𝑠𝑖𝑛(𝜃 ) and 𝑐 = cos(𝜃 ) in the extended domain.

Natural logarithm. We extend the domain of ln(𝑥) to (0, 1). For
𝑥 ′ ∈ [ 1
2 , 1) and non-negative integer 𝑒 such that 𝑥 = 2−𝑒𝑥 ′ ∈
(0, 1). We prove that 𝑙 = ln(𝑥 ′) − 𝑒 ln(2) = ln(𝑥). Let I𝐿𝑔 =
(𝑒, ℎ, e, s𝑥 ′, ⟨𝑥 ′⟩, ⟨𝑙 ′⟩, I𝐿), then

𝐶𝐿𝑜𝑔𝐺 (𝜓, 𝜈; ⟨𝑥⟩, ⟨𝑙⟩, I𝐿𝑔) (cid:66)

proves our approximation.

𝐶𝐿𝑜𝑔 (𝜓, 𝜈; ⟨𝑥 ′⟩, ⟨𝑙 ′⟩, I𝐿)


𝐶𝑅𝑎 (𝜓 − 1; ⟨𝑥 ′⟩ − ⟨0.5⟩, s𝑥 ′)


𝐶𝐼 𝐸𝑥 (𝜓 − 1, 2; 𝑒, ℎ, e)


ℎ⟨𝑥⟩ − ⟨𝑥 ′⟩


⟨𝑙⟩ − ⟨𝑙 ′⟩ + 𝑒 ⟨ln(2)⟩














Square root. Now, for a public bound 𝐵 > 0 and a private 𝑥 ∈
𝑥. Let 𝛾 = ⌊log2 (𝐵)⌋ + 1. We choose
2 , 1) and an integer 𝑒 ∈ [−𝜓, 𝛾] such that 𝑥 = 2𝑒𝑥 ′, and we

[0, 𝐵], we prove that 𝑠 =
𝑥 ′ ∈ [ 1
have that

√

√

𝑥 =

(cid:40)2𝑒/2√
𝑥 ′
2(𝑒+1)/2(cid:112)𝑥 ′/2

if 𝑒 is even
if 𝑒 is odd.

We break the proof in several circuits to handle different cases. For
that we use bit variables as flags to decide which computation will
be proven. Let 𝑛𝑒 ∈ {0, 1} be the “negativity flag” of 𝑒 and 𝑒 ′ ≥ 0
such that 𝑒 = (1 − 𝑛𝑒 )𝑒 ′. Let 𝑖𝑒 ∈ {0, 1} be the “parity flag” of
𝑒, such that 𝑒 = 2𝑓 − 𝑖𝑒 for an integer 𝑓 . We also define 𝑓 ′ ≥ 0
such that 𝑓 = (1 − 𝑛𝑒 )𝑓 ′. We first handle the relations between

9

√
𝑥 and 𝑠 ′ = (cid:112)𝑥 ′/(1 + 𝑖𝑒 ) when 𝑒 is non-negative, or
𝑥, 𝑥 ′, 𝑠 =
equivalently, when 𝑛𝑒 = 0. Let I𝐷1 = (𝑙, f, I>>), then our circuit is

Similarly, for I𝐷2 = (ℎ, e, I′
scribed by

>>) the case when 𝑒 is negative is de-

𝐶𝑆𝐷𝑜𝑚1 (𝐵; ⟨𝑥⟩, ⟨𝑠⟩, ⟨𝑥 ′⟩, ⟨𝑠 ′⟩, 𝑖𝑒, 𝑒 ′, 𝑓 ′, I𝐷1)
𝐶𝑃 >> (𝛾; ⟨𝑥⟩, 𝑒 ′ + 𝑖𝑒, ⟨𝑥 ′⟩, I>>)


𝑒 ′ − 2𝑓 ′ + 𝑖𝑒


𝐶𝐼 𝐸𝑥 (𝛾, 2; 𝑓 ′, 𝑙, f)


⟨𝑠⟩ − ⟨𝑠 ′⟩𝑙



(cid:66)










𝐶𝑆𝐷𝑜𝑚2 (𝜓 ; ⟨𝑥⟩, ⟨𝑠⟩, ⟨𝑥 ′⟩, ⟨𝑠 ′⟩, 𝑖𝑒, 𝑒 ′, 𝑓 ′, I𝐷2)
𝐶𝐼 𝐸𝑥 (𝜓 − 1, 2; 𝑒 ′ − 𝑖𝑒, ℎ, e)


⟨𝑥 ′⟩ − ℎ⟨𝑥⟩


𝑒 ′ − 2𝑓 ′ − 𝑖𝑒


𝐶𝑃 >> (𝜓 − 1; ⟨𝑠⟩, 𝑓 ′, ⟨𝑠 ′⟩, I′



(cid:66)

>>)










.

.

Now we describe the main circuit. For I𝐷 = (⟨𝑥 ′⟩, ⟨𝑠 ′⟩, 𝑖𝑒, 𝑒 ′, 𝑓 ′)
and I𝑆𝑔 = (𝑛𝑒, s𝑥 ′, I𝑆, I𝐷, I𝐷1, I𝐷2) vectors of intermediate values,
we prove 𝑠 =

𝑥 with

√

𝐶𝑆𝑞𝑟𝑡𝐺 (𝜓, 𝜈, 𝐵; ⟨𝑥⟩, ⟨𝑠⟩, I𝑆𝑔)

(cid:66)
















𝐶𝑆𝑞𝑟𝑡 (𝜓, 𝜈; ⟨𝑥 ′⟩, ⟨𝑠 ′⟩, I𝑆 )
𝑖𝑒 (1 − 𝑖𝑒 )
𝑛𝑒 (1 − 𝑛𝑒 )
𝑖𝑒 ∗ 𝐶𝑅𝑎 (𝜓 − 2; ⟨𝑥 ′⟩ − ⟨0.25⟩, s𝑥 ′)
(1 − 𝑖𝑒 ) ∗ 𝐶𝑅𝑎 (𝜓 − 1; ⟨𝑥 ′⟩ − ⟨0.5⟩, s𝑥 ′)
(1 − 𝑛𝑒 ) ∗ 𝐶𝑆𝐷𝑜𝑚1 (𝐵; ⟨𝑥⟩, ⟨𝑠⟩, I𝐷, I𝐷1)
𝑛𝑒 ∗ 𝐶𝑆𝐷𝑜𝑚2 (𝜓, ⟨𝑥⟩, ⟨𝑠⟩, I𝐷, I𝐷2)

.
















While the circuit above is easier to read, the practical implemen-
tation contains a number of further optimizations to reduce the
number of multiplications. In particular, additional variables are
introduced to avoid multiplying flags such as 𝑖𝑒 with larger vec-
tors such as the output of a 𝐶𝑅𝑎 circuit. This introduces additional
variables, e.g., 𝑖𝑒 ∗ 𝐶𝑅𝑎 (𝜓 − 2; ⟨𝑥 ′⟩ − ⟨0.25⟩, s𝑥 ′) would become
𝑖𝑒 (𝑥 ′ − 𝑥 ′

𝑎𝑢𝑥 ) and 𝐶𝑅𝑎 (𝜓 − 2; ⟨𝑥 ′

𝑎𝑢𝑥 ⟩ − ⟨0.25⟩, s𝑥 ′

𝑎𝑢𝑥 ).

7 THE LAPLACE DISTRIBUTION
7.1 Private Laplace Sampling

Protocol 6 (private drawing from Laplace). First, party 𝑃1
privately draws 𝑠0 and 𝑎′ uniformly at random in [0, 𝐿) with 𝐿 suf-
ficiently large (Protocol 2). Then, 𝑃1 computes 𝑎 = −𝑏 log(1 − 𝑎′/𝐿),
𝑠 = 2(𝑠0 mod 2) − 1 and 𝑟 = 𝑠𝑎, and provides a ZKP for these relations
(in Section 6.3 we showed a ZKP for the logarithm function, in Section
6.1 for approximate division).

As Protocol 2 verifiably draws random numbers uniformly and
for the other computations in Protocol 6 a ZKP is provided, Protocol
6 verifiably draws random numbers from the 𝐿𝑎𝑝 (𝑏) distribution.
An alternative method could be based on work by [26] (see also
[19] for related ideas). In particular, [26] proposes a technique to
sample directly from the exponential distribution using a range of
independent biased coin flips. The main advantage of our method
is that we only need one uniformly sampled public random number,
which strongly reduces the communication cost.

This remark also holds for the protocol of Laplace hidden draws

which we will present in Section 7.2 below.

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

7.2 Hidden Laplace Sampling
We can also make hidden draws from the Laplace distribution, i.e.,
drawing a Laplace-distributed random number 𝑟 as a secret share
⟦𝑟 ⟧. For this, we build on the basic operations discussed in Section
2.5.

(cid:19)

First, we observe that one can sample a sign 𝑠 uniformly from
{−1, 1} as follows: the parties apply Protocol 3 to draw a secret
shared random number uniformly distributed in Z𝑝 , obtaining the
(cid:19)
(cid:18)
𝑡 2
sharing ⟦𝑡⟧, next they multiply the sharing with itself to obtain
to reveal 𝑡 2, and finally they multiply ⟦𝑡⟧ with the
and open
(cid:20)
public constant 1/
∈ {−1, 1}. Drawing
𝑡/
a secret shared random bit 𝑏 ∈ {0, 1} is then just drawing a sign
⟦𝑠⟧ and computing ⟦𝑏⟧ = (⟦𝑠⟧ + 1) /2 (this is protocol 𝑅𝐴𝑁2 in
[23]).

𝑡 2 to obtain ⟦𝑠⟧ =

(cid:18)
𝑡 2

𝑡 2

√

√

(cid:21)

The Cordic algorithm for logarithm computation described in
Section 6.2 requires only additions, bit shifts and comparisons (when
setting 𝜉𝑖 = sign (−𝑌𝑖−1)). While it does not directly use multipli-
cations, implementations of bit operations and comparisons, e.g.,
as in [23], often are using multiplications so the use of multiplica-
tions cannot be fully avoided. Alternative strategies to compute the
logarithm suffer from similar challenges.

As in Section 7.1, we want to draw a number 𝑎′ uniformly from
[0, 𝐿), compute 𝑎 = −𝑏 log(1 − 𝑎′/𝐿) and multiply it with a random
sign 𝑠 to get the random number 𝑎𝑠 distributed according to 𝐿𝑎𝑝 (𝑏).
To compute log(𝑥), Cordic expects 𝑥 ∈ [1/4, 1), so before applying
Cordic we may need to scale its input to fit this interval.

We set 𝐿 = 2𝑙 for some sufficiently large integer 𝑙 and generate 𝑎′
(cid:21)
(cid:20)
2𝑖 where 𝑎 (𝑖) are random
𝑎 (𝑖)

as an 𝑙-bit number, i.e., ⟦𝑎′⟧ = (cid:205)𝑙−1
𝑖=0
bits.

(cid:19)

(cid:19)

(cid:19)(cid:20)

(cid:18)
ℎ′
𝑖

(cid:18)
ℎ′
𝑖

We can find the highest zero bit of 𝑎′ as follows: set ℎ𝑙 = 0, ℎ′

𝑙 = 1
and 𝑎 (−1) = 0, and for 𝑖 = 𝑙 − 1 . . . − 1, set
⟦1 − ℎ𝑖+1⟧
=
(cid:21)
1 − 𝑎 (𝑖)
. The meaning of ℎ𝑖 then is ’bit 𝑖 is the
and ⟦ℎ𝑖 ⟧ =
highest 0-bit’, and the meaning of ℎ′
𝑖 is ’the bits higher than bit 𝑖
are all ones’. Exactly one ℎ𝑖 equals 1 and all others are 0 among
𝑖 = −1 . . . 𝑙 − 1. We then can write log(1 − 𝑎′/𝐿) = 𝑎h + log(𝑥) with
(cid:18)
𝑎h

𝑖=0 ⟦ℎ𝑖 ⟧ log(2𝑖+1−𝑙 ) and 𝐵𝐼𝑇 𝑆 (𝑥, (𝑥 (𝑖) )𝑙

𝑖=0) where

(cid:18)
ℎ′
𝑖+1

= (cid:205)𝑙−1

(cid:19)

(⟦𝑥 (𝑖) ⟧)𝑙

𝑖=0 = Bit-add(2𝑙 , (⟦𝑥 (𝑖)

− ⟧)𝑙−1
𝑖=0 )

and ⟦𝑥 (𝑖)

− ⟧ = (cid:205)𝑙−1

𝑗=0 ⟦ℎ 𝑗 ⟧⟦𝑎 (𝑖+𝑗+1−𝑙) ⟧ (with 𝑎 (𝑖) = 0 for 𝑖 < 0).

Now we can apply Cordic on 𝑥. Cordic needs additions (using
the Bit-add protocol), bit shifts (moving bits to the right and dupli-
cating the highest bit), the sign(·) function (check the highest bit)
and negation (invert all bits and add 1).

Protocol 7 (hidden drawing from Laplace). One can verifi-
ably draw a hidden Laplace-distributed random number by following
the steps explained above, and by providing ZKP for all computations.
The ZKP are similar to those for private sampling, where parts of
secret shares are transfered between parties, the parties can agree on
the commitment which will represent the shared number.

8 THE GAUSSIAN DISTRIBUTION
In this section we elaborate several strategies to sample from the
Gaussian distribution.

10

In particular, we are interested in protocols such that upon termi-
nation one party has a private number 𝑦 ∈ Q⟨𝑝,𝜓 ⟩ and has provided
a zero knowledge argument that 𝑦 ∼ N (𝜇, 𝜎2) for some public 𝜇
and 𝜎.

All methods require as a subprotocol sampling uniformly dis-
tributed numbers. Therefore all our protocols for private drawing
numbers from the Gaussian distribution follow the same high-level
structure:

(1) use Protocol 2 to verifiably draw uniformly distributed num-

ber(s),

(2) transform the uniformly distributed number(s) into Gaussian

distributed number(s), and

(3) use an arithmetic circuit matching this transformation to-
gether with compressed Σ-protocols (see Section 2.4) to prove
the transformation.

We implement ZKPs of the correct execution of Gaussian draws.
The sampling methods we implement are (1) the central limit theo-
rem approach (averaging over uniform samples), (2) the Box Müller
method [12], (3) the Polar Method [39], (4) the inversion method
using a series expansion for erf −1 [18], and (5) the inversion method
using a fractional polynomial to approximate erf −1 [28].

8.1 The Central Limit Theorem Method
The uniform distribution over the interval [0, 𝐿) has variance 𝐿2/12.
Let a party privately draw 𝑁 random numbers {𝑥𝑖 }𝑁
𝑖=1 uniformly
(cid:17).
(cid:16)
distributed over [0, 𝐿), and compute 𝑥 = 𝜇 + 𝜎
𝑥𝑖 − 𝐿
(cid:205)𝑁
𝑖=1
2
𝐿
Then, 𝑥 is N (𝜇, 𝜎2) distributed. For a ZKP for this relation between
𝑥 and the 𝑥𝑖 we only need the homomorphic property of the Ped-
ersen commitment (for the additions and the multiplication with
a constant) and a range proof (for the rounding). This method
is essentially the technique of [26] to sample from the Gaussian
distribution.

12
𝑁

√
√

8.2 The Box Müller Method
The Box Müller method [12] consists of drawing two uniform sam-
ples 𝑈1 and 𝑈2 in the interval (0, 1) and to compute

𝜌 = (cid:112)−2 ln(𝑈1), 𝑋1 = 𝜌 cos(2𝜋𝑈2)

𝑎𝑛𝑑 𝑋2 = 𝜌 sin(2𝜋𝑈2).

Then, 𝑋1 and 𝑋2 are distributed according to N (0, 1). Now we use
circuits of elementary functions defined in Section 6 to construct
our proof. Recall parameters 𝜓 and the number of Cordic iterations
𝜈 defined therein. Let

I𝐵𝑀 = (s1, s2, s3, ⟨𝑠⟩, ⟨𝑐⟩, I𝑇𝑔, ⟨𝑎𝜋 ⟩, ⟨𝑋 ′
1, U′

I𝑆𝑔, ⟨𝜌⟩, I𝐿𝑔, ⟨𝑙⟩, a′

1⟩, ⟨𝑋 ′
2⟩
2 , U′′
1 , a′′
2, a′′

2, U′

1, a′

1 , U′′
2 )

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

be a vector containing all intermediate values of the computation.
Then the approximation circuit is

extra samples is negligible. To obtain a distribution with different
mean and variance, we scale 𝑉1 and 𝑉2 with addition and product.

(cid:66)

1, U′
2)
1 , U′′
2 )

𝐶𝐵𝑀 (𝜓, 𝜈, 𝑧1, 𝑧2; ⟨𝑈1⟩, ⟨𝑈2⟩, ⟨𝑋1⟩, ⟨𝑋2⟩, I𝐵𝑀 )
𝐶𝑀𝑜𝑑 (2𝜓 − 1, 𝑧1; 𝑎1, ⟨𝑈1⟩ − 1, a′
2, U′


𝐶𝑀𝑜𝑑 (2𝜓 − 1, 𝑧2; 𝑎2, ⟨𝑈2⟩ − 1, a′′
2 , U′′















1, a′
1 , a′′
𝐶𝐿𝑜𝑔𝐺 (𝜓, 𝜈; ⟨𝑈1⟩, ⟨𝑙⟩, I𝐿𝑔)
𝐶𝑆𝑞𝑟𝑡𝐺 (𝜓, 𝜈, 2𝜓 ln(2); −2⟨𝑙⟩, ⟨𝜌⟩, I𝑆𝑔)
𝐶𝑃𝑟𝑜𝑑 (𝜓 ; 2⟨𝜋⟩, ⟨𝑈2⟩, ⟨𝑎𝜋 ⟩, s1)
𝐶𝑇 𝑟𝐺 (𝜈; ⟨𝑎𝜋 ⟩, ⟨𝑠⟩, ⟨𝑐⟩, I𝑇𝑔)
𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝜌⟩, ⟨𝑐⟩, ⟨𝑋 ′
1⟩, s2)
𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝜌⟩, ⟨𝑠⟩, ⟨𝑋 ′
2⟩, s3)
Private values 𝑎1 and 𝑎2 and public challenges 𝑧1 and 𝑧2 are used
in the modular proofs of circuit 𝐶𝑀𝑜𝑑 to generate 𝑈1 and 𝑈2 with
Protocol 2. To obtain a sample with standard deviation different
than 1, the resulting samples can be scaled with an extra 𝐶𝑃𝑟𝑜𝑑
circuit. Different mean requires an extra addition gate.


















.

8.3 The Polar Box-Müller Method
The polar method [36] is an optimization of Box-Müller that avoids
the computation of sine and cosine by the use of rejection sampling.
It samples two uniform values 𝑉1 and 𝑉2 in the (−1, 1) interval, and
keeps the result only if 0 < 𝑉 2
1 + 𝑉 2
2 ≤ 1. Otherwise 𝑉1 and 𝑉2 are
re-sampled. For non rejected 𝑉1 and 𝑉2 it computes
𝛼 = 𝑉 2

(cid:112)−2 ln(𝛼)/𝛼 .

(cid:112)−2 ln(𝛼)/𝛼,

𝑎𝑛𝑑 𝑌2 = 𝑉2

𝑌1 = 𝑉1

1 + 𝑉 2
2 ,

𝑌1 and 𝑌2 have distribution N (0, 1).

In the private sampling, if 𝑉1 and 𝑉2 are rejected, the prover can
just reveal them and start new uniform draws until acceptance,
when it proves the correctness of accepting pairs. As in Box Müller,
parameters 𝜈 and 𝜓 define our elementary function approximations,
and 𝑎1, 𝑎2, 𝑧1, 𝑧2 are used to generate 𝑉1 and 𝑉2 in Protocol 2. Let

I𝑃𝑜𝑙 = (⟨𝑠⟩, I𝑆𝑔, ⟨𝑑⟩, ⟨𝛼⟩, ⟨𝑙⟩, I𝐿𝑔, s6, s5, s4, s3, s2, s1, ⟨𝛼⟩,
1, a′
1 , V′′
2 )
be a vector of intermediate computation values, then the imple-
mented circuit is

1 ⟩, v′, v, a′

2 ⟩, ⟨𝑉 ′

2 , V′′

1 , a′′

2, a′′

1, V′

2, V′

⟨𝑉 ′

(cid:66)

a′
1, a′

1, V′
2)

a′′
1 , a′′

1 , V′′
2 )

𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝑉1⟩, ⟨𝑉1⟩, ⟨𝑉 ′
1 ⟩, v)
𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝑉2⟩, ⟨𝑉2⟩, ⟨𝑉 ′
2 ⟩, v′)
⟨𝛼⟩ − ⟨𝑉 ′
1 ⟩ − ⟨𝑉 ′
2 ⟩

𝐶𝑃𝑜𝑙 (𝜓, 𝜈, 𝑧1, 𝑧2; ⟨𝑉1⟩, ⟨𝑉2⟩, ⟨𝑌1⟩, ⟨𝑌2⟩, I𝑃𝑜𝑙 )
𝐶𝑀𝑜𝑑 (22𝜓 − 2, 𝑧1; 𝑎1, ⟨𝑉1⟩ + ⟨1⟩ − 1,
2, V′
𝐶𝑀𝑜𝑑 (22𝜓 − 2, 𝑧2; 𝑎2, ⟨𝑉2⟩ + ⟨1⟩ − 1,
2 , V′′















𝐶𝐺𝑅𝑎 (1, ⟨1⟩ − 1; ⟨𝛼⟩, s1, s2)


𝐶𝐿𝑜𝑔𝐺 (𝜓, 𝜈; ⟨𝛼⟩, ⟨𝑙⟩, I𝐿𝑔)


𝐶𝐷𝑖𝑣 (𝜓 ; −2⟨𝑙⟩, ⟨𝛼⟩, ⟨𝑑⟩, s3, s4)


𝐶𝑆𝑞𝑟𝑡𝐺 (𝜓, 𝜈, 2𝜓 +1𝜓 ln(2); ⟨𝑑⟩, ⟨𝑠⟩, I𝑆𝑔)


𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝑠⟩, ⟨𝑉1⟩, ⟨𝑌1⟩, s5)


𝐶𝑃𝑟𝑜𝑑 (𝜓 ; ⟨𝑠⟩, ⟨𝑉2⟩, ⟨𝑌2⟩, s6)


To avoid multiple interactions due to rejection, Protocol 2 is set
to draw a sufficiently large number of uniform samples such that at
least one pair is not rejected with high probability. The cost of the




























.

8.4 The Inversion Method
Inverting eq. (1) we get

𝐹 −1
N (𝑥) =

√

2erf−1 (2𝑥 − 1).

There are many numerical strategies to approximate either erf or
erf−1, of which we implemented two.

A first strategy due to [18] is to use the series

erf(𝑥) =

2
√
𝜋

∞
(cid:213)

(−1)𝑙 𝑥 2𝑙+1
𝑙!(2𝑙 + 1)

.

𝑙=0
However, its approximation error gets larger as 𝑥 gets bigger. There-
fore, when 𝑥 is large, it is better approximate erfc(𝑥) = 1 − erf(𝑥)
using the series

erfc(𝑥) =

𝑒−𝑥 2
√
𝜋
𝑥

(cid:32)𝐿−1
(cid:213)

𝑙=0

(cid:33)

(−1)𝑙 (2𝑙 − 1)!!
(2𝑥 2)𝑙

+ 𝑅𝐿 (𝑥),

where

𝑅𝐿 (𝑥) ≤

𝑒−𝑥 2
√
𝜋
𝑥

(2𝐿 − 1)!!
(2𝑥 2)𝐿

is the remainder, 𝑙!! = 1 for 𝑙 < 1 and (2𝑙 − 1)!! = (cid:206)𝑙
𝑖=1 (2𝑖 − 1). The
number of terms 𝐿 of the series is tuned for minimal error. If we
set 𝐵 to be the maximum error of our approximation, we use erf if

(cid:113) ln(1/𝐵)
2

+ 0.788 and erfc otherwise. The ZKP of this method
𝑥 <
proves that 𝑦 = erf(𝑥) or 1 − 𝑦 = erfc(𝑥) depending on the domain
of 𝑥.

A second strategy is proposed in [28] and uses a rational approx-

imation. Therein, erf −1 is computed by

erfinvSP (𝑥) =

(cid:40)𝑥𝑝1 (𝑤)
𝑥𝑝2 (𝑠)
√
where 𝑤 = − log(1−𝑥 2), 𝑠 =
𝑤 and 𝑝1 and 𝑝2 are two polynomials
of degree 8. We use Cordic, product and range ZKPs to prove its
computation.

if 𝑤 ≤ 5 (central region)
if 𝑤 > 5 (tail region)

8.5 Hidden Drawing
For the several strategies for sampling the Gaussian distribution
described above, one can construct a protocol based on secret shar-
ing for hidden sampling. Similar considerations apply as for the
discussion in Section 7.2. As an example, we show a protocol using
the Central Limit Theorem approach.

Protocol 8. Let 𝑁 /12 be a power of 4. For 𝑖 = 0 . . . 𝑙 − 1 and
𝑗 ⟧. This yields 𝑁 random
𝑗=1 in the interval [0, 2𝑙 ). For 𝑗 ∈ [𝑁 ] and 𝑖 = 𝑙 . . . 𝑙 +
𝑗 = 0. Let (⟦𝑦 (𝑖)
and for

𝑗 = 1 . . . 𝑁 , draw a random bit sharing ⟦𝑥 (𝑖)
numbers {𝑥 𝑗 }𝑁
log2 𝑁 , set 𝑥 (𝑖)
𝑗 = 2 . . . 𝑁 let
(⟦𝑦 (𝑖)
Finally let ⟦𝑟 ⟧ = (cid:205)𝑙+log2 𝑁
proximates N (2𝑙 √

2𝑖−log2 (𝑁 /12)/2. Then, 𝑟 ap-
3𝑁 , 2𝑙 ). The computations can be made verifiable

= Bit-add((⟦𝑦 (𝑖)

𝑗−1⟧)
𝑦 (𝑖)
𝑁

𝑖=log2 (𝑁 /12)/2

𝑙+log2 𝑁
𝑖=0

𝑙+log2 𝑁
𝑖=0

𝑙+log2 𝑁
𝑖=0

𝑙+log2 𝑁
𝑖=0

𝑙+log2 𝑁
𝑖=0

= (⟦𝑥1⟧)

, (⟦𝑥 (𝑖)

1 ⟧)

𝑗 ⟧)

𝑗 ⟧)

).

11

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

using a ZKP where parties send a number to each other can agree on
using the same commitment.

9 EVALUATION
In this section, we present an empirical comparison of several
methods to privately sample from the Gaussian distribution. We
will publish code to reproduce all experiments together with the
final version of this paper.

9.1 Setup
We evaluate the costs of the methods presented in Section 8. Namely,
the Central Limit Theorem approach (CLT), the Box Müller (BM),
the Polar Method (PolM) and the inversion method. In the latter,
we evaluate the two described strategies: using series (InvM-S) and
rational approximations (InvM-R). Samples are generated for the
N (0, 1) distribution.

We evaluate the cost of each method instantiated for several
parameters against the statistical quality of the generated samples.
For the computational cost we measure the exponentiations in G
(GEX), which dominate the computation. The total communication
cost is the number of elements of G and Z𝑝 sent (see Section 2.4).
To measure the statistical quality, we generate 107 samples and
measure the Mean Squared Error (MSE) from the ideal Gaussian
CDF.

The varying parameter for BM and PolM is the number of itera-
tions 𝜈 of their Cordic approximations, which is chosen between 2
and 14. For CLT we vary the number of averaged uniform terms
between 2 and 400. For InvM-R, the number of terms of the approxi-
mation series is changed in order to obtain different approximations
with errors between 0.5 and 2−20. The rational approach InvM-R
has no varying parameter. The representation parameter 𝜓 which
defines Q⟨𝑝,𝜓 ⟩ is chosen to be the smallest as allowed by BM, PolM,
InvM-S due to approximation constraints, and for CLT is set to
optimize the quality/cost tradeoff .

9.2 Results
Figure 1 shows the communication costs, i.e., the number of el-
ements of G required to prove one Gaussian draw. Note that, as
described in Section 2.4, 6 elements of Z𝑝 must be added to ob-
tain the final cost. If high precision isn’t important, CLT performs
well, but in general PolM, BM and Inv-R give the best precision
for a given computational investment. The Inv-R method is much
simpler but can’t be tuned to other precisions.

Figure 2 shows the number of GEX to prove (by the party who
draws the number) or to verify (by another party) one Gaussian
draw. Here too, BM and PolM are the most efficient methods as
soon as a good statistical quality is required. We note that, as the
communication cost is logarithmic in the number of inputs and
multiplication gates, several parameter settings give different points
in Figure 2 but may have the same communication cost, so in Figure
1 we just show the proof with best statistical quality.

For illustration, if we implement Pedersen commitments using
the secp256k1 1 elliptic curve, we obtain 128 bit security and an
element of G can be represented with 257 bits. One GEX using this

1See https://www.secg.org/SEC2-Ver-1.0.pdf and https://github.com/bitcoin-core/
secp256k1

Figure 1: (Comm. costs) Required Group Elements for one
sample against the MSE for BM, PolM, InvM and CLT ap-
proaches.

(a) Proving cost.

(b) Verification cost.

Figure 2: (Comp. costs) Required group exponentiations for
one sample against the MSE for BM, PolM, InvM and CLT
approaches. Costs in the left side plots are in logarithmic
scale. The right side plots are zooms of their left plots, in
linear scale and with a detailed view on the most efficient
methods.

curve takes no more than 30 microseconds on an Intel Core i7-6600U
at 2.60 GHz CPU. With BM, PolM and InvM-R, a sample with MSE
< 2−20 requires less than 900 Bytes of communication. With PolM,
such sample takes less than 360 milliseconds (ms) to prove and 75
ms for its verification. While CLT quickly gets very expensive, if
quality is less important and an MSE > 2−13 is satisfactory, it is
the most efficient approach. A proof of a sample using CLT with
MSE 0.01 can be generated in less than 10 ms, verified in 3 ms and
has a size of 482 Bytes. We also note that it is possible to further
optimize our implementation using special-purpose algorithms [46]
to compute multiple exponentiations in the form gb.

Finally, in Figure 3 we show the gap in the communication cost
between our PolM and CLT sampling techniques implemented
with classic (non-compressed) Σ-protocols [21, 22] to the presented
compressed techniques.

12

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

Even if the corrupted parties would collect all noise they have
𝜂𝑖 and subtracts it from ˆ𝜃 to obtain
contributed 𝜂𝑐𝑜𝑙𝑙 = (cid:205)𝑖 ∈P𝑐𝑜𝑟
𝜃𝑐𝑜𝑙𝑙 = ˆ𝜃 − 𝜂𝑐𝑜𝑙𝑙 /𝑛, then there is still Gaussian noise with variance
1−𝜌 − 𝜌 𝜎 2
𝜎 2
1−𝜌 = 𝜎2 left on their best estimation of 𝜃 . This strategy,
which adopts some ideas from [26], works best for Gaussian noise,
as the sum of Gaussian distributions is again a Gaussian distribution.

Protocol 10 (DP learning using hidden sampling). Let all
parties 𝑃𝑖 (with 𝑖 ∈ [𝑛]) represent their private number 𝑥𝑖 as a shared
secret. Let the parties next together verifiably drawn a hidden random
number 𝜂, i.e., a random number they obtain only as a shared secret.
Finally, let them sum the secret shares and reveal ˆ𝜃 = (cid:205)𝑛

𝑖=1 𝑥𝑖 + 𝜂

The advantage of this protocol is that no parties see 𝜂 or parts of
it, so it is impossible to get back towards the sensitive statistic 𝜃 . On
the other hand, the full computation needs to be performed through
multi-party computations, e.g., using shared secrets, which is clearly
more expensive than the ZKPs which are needed in Protocol 9,
especially as compressed Σ-protocols allow for ZKPs of size only
logarithmic in the circuit size while calculations on secret shares
have a linear communication cost.

As such drawing of random noise is a basic building block and
needs to be performed repeatedly by secure federated differentially
private machine learning algorithms, being able to draw from these
probability distributions with low communication cost is essential
to make algorithms more efficient.

Issues of finite precision. The work of [42] shows the impact that
finite precision approximation of continuous distributions can have
on DP guarantees. As explained in [42, Sec. 5.2], these vulnerabili-
ties can be overcome by appropriately adjusting the precision and
truncating the outcome after the noise is added to private values.
This can be achieved in our protocols by using the correct precision
parameters and range proofs.

To overcome vulnerabilities of finite precision approximations,
other lines of work have explored the use of discrete distributions
[17, 34]. These methods require in expectation comparable compu-
tational effort as our protocols. However, sampling from a discrete
distribution requires in the worst case many iterations which results
in longer zero-knowledge proofs.

11 CONCLUSION
We have presented novel methods for drawing random numbers in
a verifiable way in a public, private and hidden setting. We applied
the ideas to the Laplace and Gaussian distribution, and evaluated
several alternatives to sample from the Gaussian distribution.

We see several interesting directions for future work. First, we
hope to develop novel strategies to let our methods scale better
when in the course of an algorithm many random numbers are
needed. Second, we would like to develop new methods which
allow for more efficient sampling in the hidden setting where the
random numbers are output as shared secrets. In particular, our
current methods based on generic secret sharing techniques require
multiple rounds of computation and communication, it may be
possible to develop more efficient special-purpose strategies.

Figure 3: (Comparison w. classic Σ-protocols) Required Group El-
ements for one sample against the MSE using compressed
and classic Σ-protocols for PolM (left) and CLT (right).

10 APPLICATION: DIFFERENTIALLY

PRIVATE MACHINE LEARNING

(cid:205)𝑛

𝑖=1 𝑥𝑖 .

An important application of verifiable sampling can be found in
the field of federated machine learning under differential privacy.
Consider parties P = {𝑃𝑖 }𝑛
𝑖=1 where each party 𝑃𝑖 has some sensitive
private data 𝑥𝑖 . The parties P want to keep their data 𝑥𝑖 private but
want to collaborate to obtain statistical information 𝜃 of common
interest. For example, assume that 𝑥𝑖 ∈ R and the parties in P would
like to compute 𝜃 = 1
𝑛

Even if no inputs nor intermediate results are revealed, com-
puting and sharing the exact statistic 𝜃 may impact privacy. For
example, suppose thet 𝑥𝑖 = 1 if 𝑃𝑖 likes a particular idea or 𝑥𝑖 = 0
if 𝑃𝑖 doesn’t like it. It may turn out that no party likes the idea of
interest, in which case we would get 𝜃 = 0. If we publish that 𝜃 = 0
no party can claim anymore that it liked the idea, so its privacy is
lost. Statistical notions of privacy, such as differential privacy [27],
add noise to guarantee the privacy of the individuals independently
of the output. In particular, let 𝜃 be a function mapping datasets on
values in X. We say datasets are adjacent if they differ in the data
of only one party. Then, we say a randomized algorithm 𝐴 is (𝜖, 𝛿)-
differentially private (DP) if for any two adjacent datasets 𝐷1 and
𝐷2 and for any subset 𝑋 ∈ X, 𝑃 (𝐴(𝐷1) ∈ 𝑋 ) ≤ 𝑒𝜖 𝑃 (𝐴(𝐷2) ∈ 𝑋 ) +𝛿.
𝐴 is 𝜖-DP if it is (𝜖, 0)-DP.

The most common strategy to make information DP before pub-
lication is to add noise from appropriately scaled Laplace or Gauss-
ian distributions. For example, consider again the above example
where the parties in P want to average their private 𝑥𝑖 . Assume
that ∀𝑖 ∈ [𝑛] : 0 ≤ 𝑥𝑖 ≤ 1. Then, for any 𝜖 > 0, if we set ˆ𝜃 = 𝜃 + 𝜂
with 𝜂 ∼ Lap(1/𝜖) there holds that ˆ𝜃 is 𝜖-DP. Alternatively, for any
𝜖 > 0 and 𝛿 > 0, if we set ˆ𝜃 = 𝜃 + 𝜂 with 𝜂 ∼ N (0, 2ln(1.25/𝛿)/𝜖2)
there holds that ˆ𝜃 is (𝜖, 𝛿)-DP.

It is important that no party knows the added noise 𝜂, because
knowing both ˆ𝜃 and 𝜂 would allow to reconstruct 𝜃 = ˆ𝜃 − 𝜂. We
present two protocols, one privately drawing random numbers,
which produces a less accurate result, and one based on the more
expensive hidden drawing which has optimal precision.

Protocol 9 (DP learning using private sampling). Let P𝑐𝑜𝑟 ⊂
P be the set of corrupted parties of size at most 𝜌𝑛 (with 0 ≤ 𝜌 < 1). As
described in Section 8, let all parties 𝑃𝑖 (𝑖 ∈ [𝑛]) privately verifiably
draw a Gaussian random number 𝜂 ∼ N (0, 𝜎2/𝑛(1 − 𝜌)), where
noise with variance 𝜎2 on 𝜃 would be sufficient to achieve the desired
𝑖=1 (𝑥𝑖 + 𝜂𝑖 ) and publish ˆ𝜃 .
privacy level. Then, securely sum ˆ𝜃 = 1
(cid:205)𝑛
𝑛

13

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

ACKNOWLEDGMENTS
We thank Christian Weinert for fruitful discussions. This project
was partially supported by ANR project ANR-20-CE23-0013 ’PMR’,
the ’Chair TIP’ project funded by ANR and MEL, and the Horizon
Europe TRUMPET project grant no. 101070038.

REFERENCES
[1] Abdelrahaman Aly and Nigel P. Smart. 2019. Benchmarking Privacy Preserving
Scientific Operations. In Applied Cryptography and Network Security (Lecture
Notes in Computer Science), Robert H. Deng, Valérie Gauthier-Umaña, Martín
Ochoa, and Moti Yung (Eds.). Springer International Publishing, Cham, 509–529.
[2] Thomas Attema and Ronald Cramer. 2020. Compressed Σ-Protocol Theory
and Practical Application to Plug & Play Secure Algorithmics. In Advances in
Cryptology – CRYPTO 2020 (Lecture Notes in Computer Science), Daniele Mic-
ciancio and Thomas Ristenpart (Eds.). Springer International Publishing, Cham,
513–543. https://doi.org/10.1007/978-3-030-56877-1_18

[3] Yonatan Aumann and Yehuda Lindell. 2010. Security against covert adversaries:
Efficient protocols for realistic adversaries. Journal of Cryptology 23, 2 (2010),
281–343.

[4] Fattaneh Bayatbabolghani, Marina Blanton, Mehrdad Aliasgari, and Michael

Goodrich. 2017. Secure fingerprint alignment and matching protocols.

[5] Amos Beimel, Eran Omri, and Ilan Orlov. 2010. Protocols for Multiparty Coin
Toss with Dishonest Majority. In Advances in Cryptology – CRYPTO 2010, Tal
Rabin (Ed.). Springer Berlin Heidelberg, Berlin, Heidelberg, 538–557.

[6] Mihir Bellare and Phillip Rogaway. 1993. Random oracles are practical: a paradigm
for designing efficient protocols. In Proceedings of the 1st ACM conference on
Computer and communications security (CCS ’93). Association for Computing
Machinery, New York, NY, USA, 62–73. https://doi.org/10.1145/168588.168596
[7] Danial Benarroch, Matteo Campanelli, Dario Fiore, Kobi Gurkan, and Dimitris
Kolonelos. 2019. Zero-Knowledge Proofs for Set Membership: Efficient, Succinct,
Modular. Cryptology ePrint Archive, Report 2019/1255. https://ia.cr/2019/1255.
[8] David Bernhard, Olivier Pereira, and Bogdan Warinschi. 2012. How Not to Prove
Yourself: Pitfalls of the Fiat-Shamir Heuristic and Applications to Helios. In
Advances in Cryptology – ASIACRYPT 2012 (Lecture Notes in Computer Science),
Xiaoyun Wang and Kazue Sako (Eds.). Springer, Berlin, Heidelberg, 626–643.
https://doi.org/10.1007/978-3-642-34961-4_38

[9] Ari Biswas and Graham Cormode. 2022. Verifiable Differential Privacy For When
The Curious Become Dishonest. https://doi.org/10.48550/ARXIV.2208.09011

[10] Manuel Blum. 1983. Coin flipping by telephone a protocol for solving impossible
problems. ACM SIGACT News 15, 1 (Jan. 1983), 23–27. https://doi.org/10.1145/
1008908.1008911

[11] Jonathan Bootle, Andrea Cerulli, Pyrros Chaidos, Jens Groth, and Christophe
Petit. 2016. Efficient Zero-Knowledge Arguments for Arithmetic Circuits in the
Discrete Log Setting. In Advances in Cryptology – EUROCRYPT 2016 (Lecture Notes
in Computer Science), Marc Fischlin and Jean-Sébastien Coron (Eds.). Springer,
Berlin, Heidelberg, 327–357. https://doi.org/10.1007/978-3-662-49896-5_12
[12] G. E. P. Box and Mervin E. Muller. 1958. A Note on the Generation of Random
Normal Deviates. Annals of Mathematical Statistics 29, 2 (June 1958), 610–611.
https://doi.org/10.1214/aoms/1177706645 Publisher: Institute of Mathematical
Statistics.

[13] A.Z. Broder and D. Dolev. 1984. Flipping Coins In Many Pockets (Byzan-
tine Agreement On Uniformly Random Values). In 25th Annual Symposium on
Foundations of Computer Science, 1984. IEEE, Singer Island, FL, USA, 157–170.
https://doi.org/10.1109/SFCS.1984.715912

[14] Benedikt Bunz, Jonathan Bootle, Dan Boneh, Andrew Poelstra, Pieter Wuille, and
Greg Maxwell. 2018. Bulletproofs: Short Proofs for Confidential Transactions and
More. In 2018 IEEE Symposium on Security and Privacy (SP). IEEE, San Francisco,
CA, 315–334. https://doi.org/10.1109/SP.2018.00020

[15] Jan Camenisch, Rafik Chaabouni, and abhi shelat. 2008. Efficient Protocols for
Set Membership and Range Proofs. In Advances in Cryptology - ASIACRYPT
2008 (Lecture Notes in Computer Science), Josef Pieprzyk (Ed.). Springer, Berlin,
Heidelberg, 234–252. https://doi.org/10.1007/978-3-540-89255-7_15

[16] Jan Camenisch and Markus Michels. 1999. Proving in Zero-Knowledge that a
Number is the Product of Two Safe Primes. In Advances in Cryptology — EU-
ROCRYPT ’99 (Lecture Notes in Computer Science), Jacques Stern (Ed.). Springer,
Berlin, Heidelberg, 107–122. https://doi.org/10.1007/3-540-48910-X_8

[17] Clément L Canonne, Gautam Kamath, and Thomas Steinke. 2020. The Discrete
Gaussian for Differential Privacy. In Advances in Neural Information Processing
Systems, H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (Eds.),
Vol. 33. Curran Associates, Inc., Virtual, 15676–15688.
https://proceedings.
neurips.cc/paper/2020/file/b53b3a3d6ab90ce0268229151c9bde11-Paper.pdf
[18] S. Chevillard. 2012. The functions erf and erfc computed with arbitrary precision
and explicit error bounds. Information and Computation 216 (July 2012), 72–95.
https://doi.org/10.1016/j.ic.2011.09.001

14

[19] Seung Geol Choi, Dana Dachman-Soled, Mukul Kulkarni, and Arkady Yerukhi-
movich. 2020. Differentially-Private Multi-Party Sketching for Large-Scale Statis-
tics. Cryptology ePrint Archive, Paper 2020/029. https://eprint.iacr.org/2020/029
https://eprint.iacr.org/2020/029.

[20] R Cleve. 1986. Limits on the Security of Coin Flips When Half the Processors
Are Faulty. In Proceedings of the Eighteenth Annual ACM Symposium on Theory
of Computing (Berkeley, California, USA) (STOC ’86). Association for Computing
Machinery, New York, NY, USA, 364–369. https://doi.org/10.1145/12130.12168
[21] Ronald Cramer. 1997. Modular Design of Secure yet Practical Cryptographic
Protocols. Ph. D. Dissertation. University of Amsterdam. https://ir.cwi.nl/pub/
21438

[22] Ronald Cramer and Ivan Damgård. 1998. Zero-knowledge proofs for finite field
arithmetic, or: Can zero-knowledge be for free?. In Advances in Cryptology —
CRYPTO ’98 (Lecture Notes in Computer Science), Hugo Krawczyk (Ed.). Springer,
Berlin, Heidelberg, 424–441. https://doi.org/10.1007/BFb0055745

[23] I. Damgard, M. Fitzi, E. Kiltz, J.B. Nielsen, and T. Toft. 2006. Unconditionally
secure constant rounds multi-party computation for equality, comparison, bits
and exponentiation. In TCC 2006 (LNCS, Vol. 3876). Springer, New York, NY USA,
285–304.

[24] Ivan Damgard, Marcel Keller, Enrique Larraia, Valerio Pastro, Peter Scholl, and
Nigel P. Smart. 2013. Practical Covertly Secure MPC for Dishonest Majority –
Or: Breaking the SPDZ Limits. In ESORICS (LNCS, Vol. 8134). Springer, Egham,
UK, 1–18.

[25] Vassil Dimitrov, Liisi Kerik, Toomas Krips, Jaak Randmets, and Jan Willemson.
2016. Alternative Implementations of Secure Real Numbers. In Proceedings of
the 2016 ACM SIGSAC Conference on Computer and Communications Security
(CCS ’16). Association for Computing Machinery, New York, NY, USA, 553–564.
https://doi.org/10.1145/2976749.2978348

[26] Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, and
Moni Naor. 2006. Our Data, Ourselves: Privacy Via Distributed Noise Generation.
In Advances in Cryptology - EUROCRYPT 2006, Serge Vaudenay (Ed.). Springer
Berlin Heidelberg, Berlin, Heidelberg, 486–503.

[27] Cynthia Dwork and Aaron Roth. 2014. The algorithmic foundations of differential
privacy. Foundations and Trends in Theoretical Computer Science 9, 3-4 (2014),
211–407.

[28] Mike Giles. 2012. Approximating the erfinv function. In GPU Computing Gems

Jade Edition. Elsevier, Amsterdam, Netherlands, 109–116.

[29] Oded Goldreich. 2009. Foundations of cryptography: volume 2, basic applications.

Cambridge university press, Cambridge, England.

[30] O. Goldreich, S. Micali, and A. Wigderson. 1987. How to Play ANY Mental Game.
In Proceedings of the Nineteenth Annual ACM Symposium on Theory of Computing
(New York, New York, USA) (STOC ’87). Association for Computing Machinery,
New York, NY, USA, 218–229. https://doi.org/10.1145/28395.28420

[31] Shafi Goldwasser, Silvio Micali, and Charles Rackoff. 1989. The Knowledge
Complexity of Interactive Proof Systems. SIAM J. Comput. 18, 1 (Feb. 1989),
186–208. https://doi.org/10.1137/0218012 Publisher: Society for Industrial and
Applied Mathematics.

[32] Kanav Gupta, Deepak Kumaraswamy, Nishanth Chandran, and Divya Gupta.
2022. LLAMA: A Low Latency Math Library for Secure Inference. Cryptology
ePrint Archive, Paper 2022/793. https://eprint.iacr.org/2022/793 https://eprint.
iacr.org/2022/793.

[33] Yuval Ishai, Rafail Ostrovsky, and Vassilis Zikas. 2014. Secure Multi-Party Compu-
tation with Identifiable Abort. In Advances in Cryptology – CRYPTO 2014, Juan A.
Garay and Rosario Gennaro (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
369–386. The full version can be found at https://eprint.iacr.org/2015/325.pdf..
[34] Peter Kairouz, Ziyu Liu, and Thomas Steinke. 2021. The Distributed Discrete
Gaussian Mechanism for Federated Learning with Secure Aggregation. In Pro-
ceedings of the 38th International Conference on Machine Learning (Proceedings
of Machine Learning Research, Vol. 139), Marina Meila and Tong Zhang (Eds.).
PMLR, Virtual, 5201–5212. https://proceedings.mlr.press/v139/kairouz21a.html
[35] Fumiyuki Kato, Yang Cao, and Masatoshi Yoshikawa. 2021. Preventing Ma-
nipulation Attack in Local Differential Privacy Using Verifiable Randomization
Mechanism. In Data and Applications Security and Privacy XXXV, Ken Barker
and Kambiz Ghazinour (Eds.). Springer International Publishing, Cham, 43–60.
[36] R. Knop. 1969. Remark on algorithm 334 [G5]: normal random deviates. Commun.

ACM 12, 5 (1969), 281. Publisher: ACM New York, NY, USA.

[37] Manuel Liedel. 2012. Secure Distributed Computation of the Square Root and
Applications. In Information Security Practice and Experience, Mark D. Ryan, Ben
Smyth, and Guilin Wang (Eds.). Springer Berlin Heidelberg, Berlin, Heidelberg,
277–288.

[38] Lindell. 2003. Parallel Coin-Tossing and Constant-Round Secure Two-Party
Computation. Journal of Cryptology 16, 3 (June 2003), 143–184. https://doi.org/
10.1007/s00145-002-0143-7

[39] G. Marsaglia and T. A. Bray. 1964. A Convenient Method for Generating Normal
Variables. SIAM Rev. 6, 3 (July 1964), 260–264. https://doi.org/10.1137/1006063
Publisher: Society for Industrial and Applied Mathematics.

[40] George Marsaglia and Wai Wan Tsang. 2000. The ziggurat method for generating

random variables. Journal of statistical software 5, 8 (2000), 1–7.

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

[41] Sahar Mazloom and S. Dov Gordon. 2018. Secure Computation with Differentially
Private Access Patterns. In Proceedings of the 2018 ACM SIGSAC Conference on
Computer and Communications Security (Toronto, Canada) (CCS ’18). Association
for Computing Machinery, New York, NY, USA, 490–507. https://doi.org/10.
1145/3243734.3243851

[42] Ilya Mironov. 2012. On Significance of the Least Significant Bits for Differential
Privacy. In Proceedings of the 2012 ACM Conference on Computer and Commu-
nications Security (Raleigh, North Carolina, USA) (CCS ’12). Association for
Computing Machinery, New York, NY, USA, 650–661. https://doi.org/10.1145/
2382196.2382264

[43] Tal Moran, Moni Naor, and Gil Segev. 2009. An Optimally Fair Coin Toss. In
Theory of Cryptography, Omer Reingold (Ed.). Springer Berlin Heidelberg, Berlin,
Heidelberg, 1–18.

[44] Jean-Michel Muller. 2016. Elementary Functions: Algorithms and Implementation
(3 ed.). Birkhäuser Basel, Basel, Switzerland. https://doi.org/10.1007/978-1-4899-
7983-4

[45] Gonzalo Munilla Garrido, Johannes Sedlmeir, and Matthias Babel. 2022. Towards
Verifiable Differentially-Private Polling. In Proceedings of the 17th International
Conference on Availability, Reliability and Security (Vienna, Austria) (ARES ’22).
Association for Computing Machinery, New York, NY, USA, Article 6, 11 pages.
https://doi.org/10.1145/3538969.3538992

[46] Bodo Möller. 2001. Algorithms for Multi-exponentiation. In Selected Areas in
Cryptography (Lecture Notes in Computer Science), Serge Vaudenay and Amr M.
Youssef (Eds.). Springer, Berlin, Heidelberg, 165–180. https://doi.org/10.1007/3-
540-45537-X_13

[47] Torben Pryds Pedersen. 1992. Non-Interactive and Information-Theoretic Secure
Verifiable Secret Sharing. In Advances in Cryptology — CRYPTO ’91 (Lecture
Notes in Computer Science), Joan Feigenbaum (Ed.). Springer, Berlin, Heidelberg,
129–140. https://doi.org/10.1007/3-540-46766-1_9

[48] David Pointcheval and Jacques Stern. 1996. Security Proofs for Signature Schemes.
In Advances in Cryptology — EUROCRYPT ’96, Ueli Maurer (Ed.). Springer Berlin
Heidelberg, Berlin, Heidelberg, 387–398.

[49] Meital Ben Sinai, Nimrod Partush, Shir Yadid, and Eran Yahav. 2014. Exploiting

Social Navigation. https://doi.org/10.48550/ARXIV.1410.0151

[50] Georgia Tsaloli and Aikaterini Mitrokotsa. 2019. Differential Privacy meets
Verifiable Computation: Achieving Strong Privacy and Integrity Guarantees. In
Proceedings of the 16th International Joint Conference on e-Business and Telecom-
munications, ICETE 2019 - Volume 2: SECRYPT, Prague, Czech Republic, July 26-28,
2019. SciTePress, Prague, Czech Republic, 425–430. https://doi.org/10.5220/
0007919404250430

[51] C. S. Wallace. 1996. Fast pseudorandom generators for normal and exponential
variates. ACM Trans. Math. Software 22, 1 (March 1996), 119–127. https://doi.
org/10.1145/225545.225554

[52] J. S. Walther. 1971. A unified algorithm for elementary functions. In Proceedings
of the May 18-20, 1971, spring joint computer conference (AFIPS ’71 (Spring)).
Association for Computing Machinery, New York, NY, USA, 379–385. https:
//doi.org/10.1145/1478786.1478840

[53] Simon Weckert. 2020. Google Maps hacks. Retrieved Dec 6, 2022 from http:

//www.simonweckert.com/googlemapshacks.html

[54] Lingchen Zhao, Qian Wang, Cong Wang, Qi Li, Chao Shen, and Bo Feng. 2021.
VeriML: Enabling Integrity Assurances and Fair Payments for Machine Learning
as a Service. IEEE Transactions on Parallel and Distributed Systems 32, 10 (2021),
2524–2540. https://doi.org/10.1109/TPDS.2021.3068195

A COMPRESSED Σ-PROTOCOLS
In this appendix, we explain all necessary notions to understand
compressed Σ-protocols [2]. In Appendix A.1, we explain the basic
concepts of ZKP. Classic approaches to construct ZKP of linear
relations are shown in Appendix A.2 and techniques to compress
the communication cost in Appendix A.3. In Appendix A.4 we
explain how linear proofs can be used to construct ZKP involving
circuit computations. Finally, Appendix A.5 has an application for
range proofs and Appendix A.6 discusses the costs of the techniques.

A.1 Zero Knowledge Proofs and Arguments
An interactive proof of knowledge (PoK) for an NP relation R is
a protocol between a prover P and a verifier V in which P tries
to prove to V that they know a witness 𝑤 such that (𝑎, 𝑤) ∈ R for
a public statement 𝑎. At the end of the protocol, V either accepts
or rejects the proof. We denote by (𝑎; 𝑤) a member of a relation

15

or an input of a protocol, using a semicolon to separate the public
statement 𝑎 from the private witness 𝑤. The tuple of all messages
in a proof is called the conversation or transcript. Proofs may satisfy
the following properties:

• Completeness: a proof is complete if V always accepts the

proof when (𝑎; 𝑤) ∈ R and P knows 𝑤.

• Soundness: a proof is sound if any prover whose proof for
statement 𝑎 is accepted by the verifier knows a valid wit-
ness 𝑤 such that (𝑎; 𝑤) ∈ R with overwhelming probability.
The notion of soundness we use is called witness extended
emulation [38]. Proofs that are sound only if the prover is
computationally bounded are also called arguments.

• Zero Knowledge: a proof is zero knowledge if its transcript
reveals no or negligible information about the witness other
than its validity.

A.2 Σ-protocols for Linear Relations
We now show how to prove linear relations over secret committed
values. Recall the definition of Pedersen vector commitments pre-
sented in Section 2.2, which defines the commitment domain Z𝑝 ,
our underlying cryptographic group G and vector of elements g.
As explained in Section 2.2, we reserve one of the components of g
for randomness so that commitments are hiding. For 𝐿 : Z𝑘
𝑝 → Z𝑝
a linear function in Z𝑝 , that is 𝐿(𝑥1, . . . , 𝑥𝑘 ) = 𝑎1𝑥1 + · · · + 𝑎𝑘𝑥𝑘
for coefficiens 𝑎1, . . . , 𝑎𝑘 ∈ Z𝑝 , a vector commitment 𝑃 ∈ G and a
value 𝑦 ∈ Z𝑝 , a prover P proves to know an opening x ∈ Z𝑘
𝑝 of 𝑃
such that 𝐿(x) = 𝑦. We formally describe our linear relation by

R𝐿 = {(𝑃 ∈ G, 𝑦 ∈ Z𝑝 ; x ∈ Z𝑘

𝑝 ) : 𝑃 = gx ∧ 𝑦 = 𝐿(x)}.

Note that in our case x has a coordinate reserved for randomness,
so in valid relations the correspondent coefficient of 𝐿 must be
0. However, in later auxiliary protocols we will not impose such
restriction. To provide a zero knowledge proof for R𝐿 we use a
family of zero knowledge proofs called Σ-protocols [21] and its
compressed version proposed in [2]. They provide soundness un-
der the Discrete Logarithm Assumption (DLA). Protocol Π0 below
describes a classic proof of R𝐿 originally stated for more general
types of commitments defined in [21, 22] and which we instantiate
for the Pedersen scheme. Π0 takes as input (𝑃, 𝑦; x):
Protocol Π0 (𝑃, 𝑦, x):

𝑝 , 𝐴 = gr, 𝑡 = 𝐿(r)

(1) P computes: r ←𝑅 Z𝑘
(2) P sends to V: 𝐴, 𝑡
(3) V sends to P: 𝑐 ←𝑅 Z𝑝
(4) P sends to V: z = 𝑐x + r
(5) V: if gz = 𝐴𝑃𝑐 and 𝐿(z) = 𝑐𝑦 + 𝑡 then accept, else reject.

Theorem 2. Π0 is a complete, sound and zero knowledge proof of

R𝐿.

We provide an intuition of how these properties are obtained.
Completeness follows directly from the homomorphic property. For
soundness, consider a prover P∗ that by following Π0 can produce
an accepting transcript ((𝐴, 𝑡), 𝑐1, z1) with significant probability.
Then it is shown that also with non-negligible probability, by using
P∗’s strategy many times, another accepting transcript of the form
((𝐴, 𝑡), 𝑐2, z2) can be produced, where the first message is equal

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

in both transcripts and such that 𝑐1 ≠ 𝑐2. Now, since both tran-
scripts are accepting, we have gz1 = 𝐴𝑃𝑐1 and gz2 = 𝐴𝑃𝑐2 so P∗
can efficiently compute the witness x = z1−z2
such that gx = 𝑃.
𝑐1−𝑐2
Acceptance also implies that 𝐿(z1) = 𝑐1𝑦 + 𝑡 and 𝐿(z2) = 𝑐2𝑦 + 𝑡
and it follows that 𝐿(x) = 𝑦. Therefore is x a valid witness. Either
P∗ already knew it or they can efficiently compute the discrete
logarithms between components of g, which is a contradiction due
to the DLA.

Zero knowledge is obtained by showing that all information
seen in the proof is random that does not depend on the secrets.
By only knowing the statement (𝑃, 𝑦) one can compute z′ ←𝑅 Z𝑝 ,
𝑐 ′ ←𝑅 Z𝑝 , 𝐴′ = 𝑃 −𝑐′
gz′ and 𝑡 ′ = 𝐿(z′) − 𝑐 ′𝑦, and the transcript
((𝐴′, 𝑡 ′), 𝑐 ′, z′) has the same distribution as a conversation between
an honest prover and a honest verifier. Note that, as it is computed
in reverse, ((𝐴′, 𝑡 ′), 𝑐 ′, z′) cannot be efficiently produced in the
actual protocol by a dishonest prover. Note that this reasoning
only holds if the verifier is honest and generates its messages uni-
formly at random. To circumvent this, we implement our proofs
transforming them into non-interactive proofs using the Strong
Fiat-Shamir heuristic [8], where the verifier is replaced by a hash
function and therefore without the need of involving a trusted party.
The construction is secure under the Random Oracle Model [6].

A.3 Compression Mechanism
Now we reduce the communication cost of Π0 using ideas of com-
pressed Σ-protocols [2] and also present in [11, 14]. The transfer in
Π0 is dominated by the third message of the protocols in Step 4, with
size of 𝑘 elements of Z𝑝 . It can be reduced if instead of sending z, P
proves that (𝐴𝑃𝑐, 𝑐𝑦 + 𝑡; z) ∈ R𝐿 which would imply the condition
tested in Step 5. Note that this proof does not need to be zero knowl-
edge as z is originally revealed in Π0. We first present Π1, a proof
of R that halves communication cost by “folding” z before sending
it. Next, we show how to use this protocol to reduce cost of Π0. By
assuming that 𝑘 is even, we define g𝐿 = (𝑔1, . . . , 𝑔𝑘/2) ∈ G𝑘/2 and
g𝑅 = (𝑔(𝑘/2)+1, . . . , 𝑔𝑘 ) ∈ G𝑘/2 and analogously for x𝐿 ∈ Z𝑘/2
and
x𝑅 ∈ Z𝑘/2
𝑝 → Z𝑝
such that 𝐿𝐿 (a) = 𝐿(a, 0) and 𝐿𝑅 (a) = 𝐿(0, a). We use, an additional
group element ˆ𝑔 ∈ G generated in the same way as the components
of g.

𝑝
𝑝 → Z𝑝 and 𝐿𝑅 : Z𝑘/2

𝑝 . We also define 𝐿𝐿 : Z𝑘/2

Protocol Π1 (𝑃, 𝑦; x):

ˆ𝑔𝐿𝑅 (x𝐿) , 𝐵 = gx𝑅
𝐿

ˆ𝑔𝐿𝐿 (x𝑅 )

(1) P computes: 𝐴 = gx𝐿
𝑅
(2) P sends to V: 𝐴, 𝐵
(3) V sends to P: 𝑐 ←𝑅 Z𝑝
(4) P sends to V: z = x𝐿 + 𝑐x𝑅
(5) V: if (g𝑐

else reject

𝐿 ∗ g𝑅)z ˆ𝑔𝑐𝐿𝐿 (z)+𝐿𝑅 (z) = 𝐴(𝑃 ˆ𝑔𝐿 (x) )𝑐 𝐵𝑐2 then accept,

Π1 is a complete and sound proof of R𝐿 with half the communica-
tion of Π0. The communication of Step 4, can be further reduced
by applying Π1 recursively until the size of z is sufficiently small.
Let Π𝐵 ⋄ Π𝐴 be the interactive proof obtained executing Π𝐴 except
for the last message and then executing Π𝐵. Now we can define to
Π𝑐 = Π1 ⋄ . . . ⋄ Π1 ⋄ Π0 where the ⋄ is applied log2 (𝑘) − 2 times.
Note that 𝑘 requires to be a power of 2, but padding vectors with
0’s is sufficient to fix this. Presented with more detail, it is proven

16

in Theorem 3 of [2], that Π𝑐 is a complete, sound and zero knowl-
edge protocol for R𝐿. Completeness is straightforward, and for zero
knowledge it is sufficient to see that Π0 is already zero knowledge,
and the rest of the protocol only reveals as much as Π0. Soundness
follows from similar ideas than those shown for Theorem 2.

Amortization techniques can be applied to prove many nul-
lity checks, where the prover claims for linear relations 𝐿1, . . . , 𝐿𝑟
that 𝐿𝑖 (x) = 0 for all 𝑖 ∈ {1, . . . , 𝑟 }. For that, V sends a ran-
dom value 𝜌 ← Z𝑝 and then P and V execute Π𝑐 on input
(𝑃, (cid:205)𝑟
𝑖=1 𝜌𝑖−1𝐿𝑖, 0; x). If 𝐿(x) = 0 then 𝐿𝑖 (x) = 0 for all 𝑖 with
overwhelming probability 1 − (𝑟 − 1)/𝑝. Amortized nullity checks
also hold when replacing linear forms by affine forms Φ1, . . . , Φ𝑟
where each one is the application of a linear form plus a constant.
We denote this protocol by Π𝑁 and its input by (𝑃, (Φ1, . . . , Φ𝑟 ); x).
A prover can prove the opening of an affine map Φ : Z𝑘
𝑝 to
y = (𝑦1, . . . , 𝑦𝑟 ) ∈ Z𝑟
𝑝 by running Π𝑁 on input (𝑃, (Φ1 −𝑦1, . . . , Φ𝑟 −
𝑦𝑟 ); x) where Φ1, . . . , Φ𝑟 : Z𝑘
𝑝 → Z𝑝 are the affine forms that com-
pose Φ. The communication cost of these protocols sends 𝑟 − 1
elements of Z𝑝 more than Π𝑐 , which account for the size of y.

𝑝 → Z𝑟

A.4 Proving Multiplications and Circuits
Now, we show the idea of [2] to prove multiplicative relations only
with black-box access to Π𝑁 . For a set committed triplets

(𝛼1, 𝛽1, 𝛾1), . . . , (𝛼𝑚, 𝛽𝑚, 𝛾𝑚),

P proves to V that 𝛼𝑖 𝛽𝑖 = 𝛾𝑖 for all 𝑖 ∈ {1, . . . , 𝑚}. Let 𝛼 =
(𝛼1, . . . , 𝛼𝑚), 𝛽 = (𝛽1, . . . , 𝛽𝑚) and 𝛾 = (𝛾1, . . . , 𝛾𝑚).

Protocol Π𝑀 :
(1) P: samples random polynomials 𝑓 (𝑋 ), 𝑔(𝑋 ) in Z𝑝 of degree
at most 𝑚 that define a secret sharing over 𝛼 and 𝛽 by fixing
𝑓 (𝑖) = 𝛼𝑖 and 𝑔(𝑖) = 𝛽𝑖 for all 𝑖 ∈ {1, . . . , 𝑚} and sampling
𝑓 (0), 𝑔(0) ←𝑅 Z𝑝 .

(2) P: computes the product polynomial ℎ(𝑋 ) = 𝑓 (𝑋 )𝑔(𝑋 )

which has degree at most 2𝑚.

(3) P sends to V: a vector commitment of

x = (𝛼, 𝛽, 𝑓 (0), 𝑔(0), ℎ(0), . . . , ℎ(2𝑚)).

Note that 𝛾 = (ℎ(1), . . . , ℎ(𝑛)).
(4) V sends to P: 𝑐 ←𝑅 Z𝑝 \ {0, . . . , 𝑚}
(5) P and V run Π𝑁 to prove that 𝑓 (𝑐), 𝑔(𝑐), ℎ(𝑐) open to some
points 𝑢, 𝑣 and 𝑤 respectively. This is possible by Lagrange
interpolation, where by having sufficient points of 𝑓 ,𝑔 and
ℎ, which are in the commitment of x, they can be evaluated
its domain by applying an affine form to x

(6) V: if 𝑢𝑣 = 𝑤 then accept else reject
As before, completeness is straightforward. Zero knowledge fol-
lows from fact that 𝑓 , 𝑔 and ℎ are random polynomials and their
evaluations do not reveal information and that Π𝑁 is zero knowl-
edge. If the multiplicative relations does not hold in all triplets, the
probability that 𝑢𝑣 = 𝑤 is negligible. From that and the soundness
of Π𝑁 , soundness is obtained.

𝑝 → Z𝑠

Now, let 𝐶 : Z𝑘

𝑝 be a circuit, i.e. a function that only
contains addition and multiplication gates in Z𝑝 . For a vector com-
mitment 𝑃, we adapt ideas from Π𝑀 to construct a proof that P
knows a opening x ∈ Z𝑘
𝑝 of 𝑃 such that 𝐶 (x) = 0. Suppose that 𝐶
has 𝑚 multiplication gates. We enumerate the multiplication gates

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

from 1 to 𝑚. For 𝑖 ∈ {1, . . . , 𝑚}, let 𝛼𝑖 and 𝛽𝑖 be inputs of the 𝑖th
multiplication gate, and 𝛾𝑖 its output. Let 𝛼,𝛽 and 𝛾 as defined in
the multiplication protocol. It is not necessary to commit to 𝛼 and
𝛽 as a commitment of them can be obtained from affine forms on
inputs (x, 𝛾) which are only dependent on 𝐶. Similarly, the output
of 𝐶 can be computed from an affine map 𝜔 : Z𝑘+2𝑚
𝑝 that
takes as input (x, 𝛾). When committing to x and 𝛾, the prover only
needs to prove that multiplication gates hold and that 𝜔 opens to 0.
This can be done with amortized nullity checks. Let [a] be a hiding
vector commitment of a i.e., [a] = g(a,𝑟 ) where 𝑟 ∈ Z𝑝 is chosen at
random.

𝑝 → Z𝑠

Protocol Π𝑐𝑠 (𝐶):
(1) P: Computes 𝑓 , 𝑔 and ℎ from 𝛼, 𝛽 as in Steps 1 and 2 of Π𝑀 .
(2) P sends to V: [y], where

y = (x, 𝑓 (0), 𝑔(0), ℎ(0), ℎ(1), . . . , ℎ(2𝑚)) ∈ Z𝑘+2𝑚+3

𝑝

.

(3) V sends to P: 𝑐 ←𝑅 Z𝑝 \ {1, . . . , 𝑚}.
(4) P sends to V: 𝑧1 = 𝑓 (𝑐), 𝑧2 = 𝑓 (𝑐), 𝑧3 = 𝑓 (𝑐).
(5) P and V run Π𝑁 with input

([y], (𝜔, 𝑓 (𝑐) − 𝑧1, 𝑔(𝑐) − 𝑧2, ℎ(𝑐) − 𝑧3); y) ,

where linear forms are obtained by Lagrange interpolation
as in Step 5 of Π𝑀 .

(6) V: if 𝑧1𝑧2 = 𝑧3 then accept else reject

Note that [y], additionally to 𝛼 and 𝛽, is an implicit commitment to
𝛾 = (ℎ(1), . . . , ℎ(𝑚)). Properties of completeness, zero knowledge
and soundness, which can be found in Theorem 4 of [2], follow
from the same arguments as the multiplication protocol.

A.5 Range Proofs
A straightforward application of circuit proofs are range proofs.
Namely, for a secret 𝑥 ∈ Z𝑝 and an integer 𝑘 < log2 (𝑝), that
𝑥 ∈ [0, 2𝑘 ). For that you commit to the first 𝑘 bits 𝑏1, . . . , 𝑏𝑘 of 𝑥.
Then, for b = (𝑏1, . . . , 𝑏𝑘 ), a circuit proof for circuit

𝐶𝑅𝑎 (𝑥, b) (cid:66)

b ∗ (1 − b)

(cid:20)
𝑥 − (cid:205)𝑘

𝑖=1 2𝑖−1𝑏𝑖

(cid:21)

implies the range constraint. Note that in 𝐶𝑅𝑎 the output of the
multiplication gates is 0. Therefore, in protocol Π𝑐𝑠 , it is not neces-
sary to include in y the elements ℎ(1), . . . , ℎ(𝑘), which reduces the
proof cost.

A.6 Cost of Proofs
We now briefly summarize communication and computational cost
of the proofs. As previously stated in the Appendix, 𝑘 is the number
of inputs and 𝑚 of multiplication gates in circuits.

Theorems 3 and 4 of [2] give the communication costs for Π𝑐 and
Π𝑐𝑠 respectively. As we use versions of the protocols transformed
by the Fiat-Shamir heuristic, the verifier does not send any message.
Therefore, the proof sizes are 2⌈log(𝑘 + 1)⌉ elements of G and 3
elements of Z𝑝 for Π𝑐 , and 2⌈log(𝑘 + 2𝑚 + 4)⌉ − 1 elements of G
and 6 elements of Z𝑝 for Π𝑐𝑠 .

For the computational cost, we count the amount of group ex-
ponentiations in G (GEX) as they dominate the work. In protocol
Π0, P performs 𝑘 GEX to compute 𝐴, and V performs 𝑘 + 1 GEX,
which corresponds to the verification of Step 5. In Π1, P performs

17

𝑘 + 2 GEX to compute 𝐴 and 𝐵, and V does 𝑘/2 + 4 GEX in the
verification of Step 4. Π𝑐 is a composition of one instance of Π0 and
𝜇 = ⌈log2 (𝑘)⌉ − 2 instances of Π1. After the first Π1 proof, 𝑘 halves
at each instance of Π1. Additionally, P and V have to compute
g′ = g𝑐
𝐿 + g𝑅 after the first Π1 to update parameters for each of
following sub-protocols. V avoids each of the verification checks
except for the last one, which requires a constant amount of GEX.
Therefore, P performs 𝑘 + 2 + (cid:205)𝜇
2𝑖 = 4𝑘 + 2𝜇 − 10 GEX
𝑖=1
and V does 3 + (cid:205)𝜇
𝑘
2𝑖 + 2 = 𝑘 + 2𝜇 − 1 GEX. Protocol Π𝑁 requires
𝑖=1
the same amount of GEX than Π𝑐 .

2𝑖−1 + 𝑘

𝑘

𝑝

In Π𝑐𝑠 , P is required to compute a (hiding) commitment of y ∈
Z𝑘+2𝑚+3
, which costs 𝑙 = 𝑘 + 2𝑚 + 4 GEX. Then P and V engage
in Π𝑁 for an affine form of 𝑙 inputs. The final costs for Π𝑐𝑠 are
then 5𝑘 + 8𝑚 + 2⌈log2 (𝑘 + 2𝑚 + 4)⌉ + 6 GEX for P and 𝑘 + 2𝑚 +
2⌈log2 (𝑘 + 2𝑚 + 4)⌉ − 1 GEX for V. For a proof of membership to
the range [0, 2𝑘 ), as discussed in Appendix A.5, ℎ(1), . . . , ℎ(𝑘) are
not included in y which then has 2𝑘 + 4 elements. The costs are of
9𝑘 + 2⌈log2 (2𝑘 + 5)⌉ + 11 GEX for P, and 2𝑘 + 2⌈log2 (2𝑘 + 5)⌉ GEX
for V.

We apply the same optimization done for range proofs to all
of our circuits. That is, multiplication gates that are expected to
be equal to 0 are not included in y. Therefore, for circuits with 𝑘
inputs, 𝑚 multiplication gates, and 𝑚0 multiplication gates that will
be equal to 0,

• P performs 5𝑘 + 8𝑚 − 4𝑚0 + 2⌈log2 (𝑘 + 2𝑚 − 𝑚0 + 4)⌉ + 6

GEX

• V performs 𝑘 + 2𝑚 −𝑚0 + 2⌈log2 (𝑘 + 2𝑚 −𝑚0 + 4)⌉ − 1 GEX.

B SECURITY OF OUR PROTOCOLS
In this section, we prove the security of the protocols presented in
the main paper. In the sequel, we will often restate in more detail
and more formally the protocols. We consider a set of 𝑛 parties
P = {𝑃1 . . . 𝑃𝑛 }. We will denote by 𝑃−𝑖 the set of all parties except
𝑖, i.e., 𝑃−𝑖 = P \ {𝑃𝑖 }. We assume that a subset of parties P𝑐𝑜𝑟 ⊂ P
is corrupted and controlled by an adversary A. The set P𝑐𝑜𝑟 of
corrupted parties is static, i.e. does not change after the beginning
of the execution.

For the description of our protocols, we will denote the fact that
a party 𝐴 sends a message 𝑀 to a party 𝐵 by “𝐴 → 𝐵: 𝑀”. Recall
that we use a bulletin board for communication. Among others, this
means that when a protocol contains a broadcast instruction a single
message is sent from one party to all others, in practice by sending
it from that party to the bulletin board, which forwards it to all
other agents. We will also use hiding vector Pedersen commitments
defined in Section 2.2. Recall the finite groups Z𝑝 and G defined
therein. For any integer 𝑘 > 0, we will denote by 𝐶𝑜𝑚(x; 𝑟 ) ∈ G the
commitment of the 𝑘-dimension vector x ∈ Z𝑘
𝑝 with randomness
𝑟 ∈ Z𝑝 .

We describe our security framework in Appendix B.1. In Appen-
dix B.2, we describe our model of compressed Σ-protocols in our
security analysis. In appendices B.3 and B.4 we prove the security
of Protocols 1 and 2 respectively. We conclude by discussing the
security of our protocols for public and private draws from some
other distributions in Appendix B.5.

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

B.1 Security Definitions
We prove security in the simulation paradigm, using the model of
malicious security with identifiable abort [33] in the stand-alone
setting [29]. Therefore, we assume parties are able to detect mali-
cious actions and can in such cases abort the protocol. Deterrence
measures may be in place to discourage parties from being detected
as malicious. In fact, unless parties stop participating our protocols
either complete successfully or abort while detecting that a specific
party is a cheater.

We start by introducing the key concepts of multiparty compu-
tation under the model of security with identifiable abort in the
stand-alone setting (see [33, App. B of the full version]). A multi-
party computation between our 𝑛 parties in P is a protocol that
computes a stochastic process F : ({0, 1}∗)𝑛 → ({0, 1}∗)𝑛, which
is also called an ideal functionality, where for all 𝑖 ∈ {1, . . . , 𝑛}, the
𝑖th component of the input and output of F maps respectively to
the private input and output of party 𝑃𝑖 .

In the simulation paradigm, a multiparty protocol securely com-
putes an ideal functionality in the presence of malicious adversaries
if any possible malicious behavior in the protocol caused by col-
luding malicious parties is not more harmful than what such party
can cause in the ideal model as defined below.

Ideal model. In this model, it is assumed that there exists a trusted
party that computes F. A malicious adversary S controls a set of
corrupted parties P𝑐𝑜𝑟 . The ideal execution comprises 7 phases and
goes as follows:

(1) Inputs: Each party 𝑃𝑖 receives a private input 𝑢𝑖 . Addition-
ally, S has an auxiliary input 𝑢∗ which represents the extra
knowledge other than its regular input.

(2) Send inputs to the trusted party: All honest parties send
their input to the trusted party, while parties controlled by
S might deviate and send what S wishes.

(3) Early abort or corrupted input: S can send abort𝑖 in-
stead of a valid input, which means that some corrupted
party 𝑃𝑖 performed an early abortion or sent a corrupted
input. In that case, the trusted party sends abort𝑖 (choosing
the index 𝑖 deterministically if many parties aborted or sent
a corrupted input) to all honest parties and halts.

(4) Detect cheating parties: During the execution, S can send
abort𝑖 to the trusted party, which means that a corrupted
party 𝑃𝑖 attempted to cheat. In that case, the trusted party
sends abort𝑖 to all parties (i.e. the attempt of cheating is
detected).

(5) Trusted party answers the adversary: If no abort𝑖 is
sent, then the trusted party sends to S the outputs of F
of the corrupted parties. After receiving them, S can send
abort𝑖 to the trusted party or instruct it to continue.
(6) Trusted party answers the honest parties: If S instructed
the trusted party to continue, then the latter sends their out-
puts of F to the honest parties.

(7) Output: The honest parties always output what the trusted
party sent to them. S outputs any arbitrary computable
function of the inputs {𝑢𝑖 }𝑖 ∈P𝑐𝑜𝑟 , the auxiliary input 𝑢∗ and
the messages obtained from the trusted party.

18

Let ¯𝑢 = (𝑢1 . . . 𝑢𝑛) be the vector of inputs of all parties and 𝑢∗
the auxiliary input of S. Recall that 𝜆 is the security parameter. We
denote by idealF,S (𝑢∗),P𝑐𝑜𝑟 ( ¯𝑢, 𝜆) to the vector of outputs of parties
in the above execution.

The real model. The real model of an 𝑛-party protocol Π describes
its execution in the presence of non-uniform probabilistic polyno-
mial time advesary A that corrupts a set of parties P𝑐𝑜𝑟 . Parties in
P \ P𝑐𝑜𝑟 behave as described by Π. We denote by realΠ,A (𝑢∗) ( ¯𝑢, 𝜆)
the vector of outputs of parties in the real execution of Π with input
¯𝑢 and where A has auxiliary input 𝑢∗.

We formalize the notion of security with identifiable abort [33,

Def. 16 of the full version] below.

Definition 3 (Security with identifiable abort in the stand-alone
setting). Let 𝜆 be the security parameter and F : ({0, 1}∗)𝑛 →
({0, 1}∗)𝑛 be an 𝑛-party ideal functionality. A protocol Π securely
computes F with identifiable abort if for every non-uniform proba-
bilistic polynomial time (PPT) adversary A in the real model, there
exist a non-uniform PPT adversary S in the ideal model such that
the distributions of

{idealF,S (𝑢∗),P𝑐𝑜𝑟 ( ¯𝑢, 𝜆)} ¯𝑢,𝑢∗ ∈ ( {0,1}∗)𝑛+1,𝜆 ∈N

and

{realΠ,A (𝑢∗),P𝑐𝑜𝑟 ( ¯𝑢, 𝜆)} ¯𝑢,𝑢∗ ∈ ( {0,1}∗)𝑛+1,𝜆 ∈N

are computationally indistinguishable.

Hybrid model. In addition to the security definition, the simula-
tion paradigm facilitates tools to prove security of protocols which
use sub-protocols already known to be secure. Given functionalities
F1, . . . , F𝑘 , where 𝑘 is polynomial in 𝜆, it allows to define a protocol
in which both parties can send messages to each other and place
“ideal calls” to a trusted party that computes F𝑖 for 𝑖 ∈ {1, . . . , 𝑘 }.
In these ideal calls, parties can send their input to the trusted party
and wait for the output of F𝑖 . However, (1) they cannot send any
messages between each other after invoking an ideal functional-
ity and before its response is returned by the trusted party and
(2) functionalities cannot be called concurrently. In other words,
functionalities can only be sequentially composed with all other in-
teractions. We denote such model as the (F1, . . . , F𝑘 )-hybrid model.
When we describe a protocol in the (F1, . . . , F𝑘 )-hybrid model, we
say that F1, . . . , F𝑘 are hybrid functionalities.

Sequential composition. Consider the protocol Π and functionali-
ties F1, . . . , F𝑘 as defined above and let 𝜌1, . . . , 𝜌𝑘 be protocols. We
define the protocol Π𝜌1,...,𝜌𝑘 to be the protocol in the ideal model
that behaves exactly as Π in real messages, but for all 𝑖 ∈ {1, . . . , 𝑘 }
each ideal call to F𝑖 is replaced by the execution of protocol 𝜌𝑖 .
We now state conditions such in which sequential composition is
secure.

Theorem 4 (Seqential composition [29]). Let F1, . . . , F𝑘 be
secure multiparty functionalities and let 𝜌1, . . . , 𝜌𝑘 be protocols that
securely compute F1, . . . , F𝑘 respectively with identifiable abort. Let
G be a multiparty functionality and let Π be a multiparty protocol
that securely computes G in the (F1, . . . , F𝑘 )-hybrid model with
identifiable abort. Then Π𝜌1,...,𝜌𝑘 securely computes G in the real
model with identifiable abort.

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

We note that the model of [33] is defined for more general types
of composition. Nevertheless, it is compatible with the definition
described above.

Assumptions on adversaries. We can see A as a deterministic
algorithm with a special input which is a random tape of uniformly
distributed bits. In the ideal model, we can also rewind A to a
previous state in execution, where the random tape also rewinds.

B.2 Compressed Σ-protocols as Ideal

Functionalities

We will use compressed Σ-protocols implemented with the Fiat-
Shamir heuristic which are proven secure in the random oracle
model [48]. They have been proven secure against (by definition)
malicious provers and there is no interaction with malicious veri-
fiers. Therefore we can consider them as secure and abstract them
as hybrid functionalities. In particular, when we write 𝑃 → F 𝑅
:
Σ
(𝑥; 𝑤); F 𝑅
gets as input from
party 𝑃 the public data 𝑥 and secret witness 𝑤, gets from all other
relevant parties as input the empty string, and returns to all parties
in O the same pair [𝑏, 𝑥 ′] where 𝑥 ′ is the data provided as input by
𝑃 and 𝑏 is 1 if (𝑥; 𝑤) ∈ 𝑅 (the proof succeeds) and 0 otherwise.

Σ → O : [𝑏, 𝑥 ′], we mean that F 𝑅
Σ

B.3 Proof of Protocol 1
Let 𝑈 be the random variable uniformly distributed over the interval
[0, 𝐿) for 𝐿 ≤ 𝑝. We consider the ideal functionality

F𝑝1 ({} . . . {}) = (𝑈 . . . 𝑈 ),

i.e., F𝑝1 takes as input from each of the 𝑛 parties an empty string
and outputs to every party the same uniformly distributed 𝑈 .

Protocol. The protocol Π𝑝1 is explained below.

Protocol Π𝑝1:
Security Parameter: 𝜆
𝑅1
Hybrid Functionality sub-protocols: Functionalities F
Σ
F

are zero knowledge proofs of respectively

𝑅2
Σ

and

• 𝑅1 = {(𝐶; 𝑥, 𝑟 ) : 𝐶 = 𝐶𝑜𝑚(𝑥, 𝑟 )}
• 𝑅2 = {(𝐶, 𝑥; 𝑟 ) : 𝐶 = 𝐶𝑜𝑚(𝑥, 𝑟 )} (only 𝑟 is secret),

Protocol:

(1) For 𝑖 = 1 . . . 𝑛 :

• 𝑃𝑖 : choose 𝑥𝑖 ∈ [0, 𝐿), 𝑟𝑖 ∈ Z𝑝 at random
• 𝑃𝑖 : compute the commitment 𝐶𝑖 = 𝐶𝑜𝑚(𝑥𝑖, 𝑟𝑖 )
• 𝑃𝑖 : broadcast 𝐶𝑖
𝑅1
• 𝑃𝑖 → F
Σ
𝑅1
Σ

: (𝐶𝑖 ; 𝑥𝑖, 𝑟𝑖 )
: broadcast [𝑏𝑖, 𝐶 ′
𝑖 ]

• F
• 𝑃−𝑖 : if 𝑏𝑖 ≠ 1 or 𝐶 ′

𝑖 ≠ 𝐶𝑖 , detect 𝑃𝑖 as a cheater and abort

(2) For 𝑖 = 1 . . . 𝑛:
𝑅2
• 𝑃𝑖 → F
Σ
𝑅2
Σ

: broadcast [𝑏 ′
• F
• 𝑃−𝑖 : if 𝑥𝑖 ∉ [0, 𝐿), 𝑏 ′

: (𝐶𝑖, 𝑥𝑖 ; 𝑟𝑖 )
𝑖 , 𝐶 ′′
𝑖 , 𝑥 ′
𝑖 ]
𝑖 ≠ 1 or 𝐶 ′′

and abort

𝑖 ≠ 𝐶𝑖 , detect 𝑃𝑖 as a cheater

(3) For 𝑖 = 1 . . . 𝑛:
• output (cid:205)𝑛

𝑖=1 𝑥 ′

𝑖 mod 𝐿.

We state the security of protocol Π𝑝1 in the theorem below.

19

𝑅2
Σ

Theorem 5 (Security of Π𝑝1). Let 𝐶𝑜𝑚 be a computationally
and

𝑅1
binding and perfectly hiding commitment scheme and let F
Σ

be secure multiparty functionalities of computationally sound
F
zero-knowledge proofs of relations 𝑅1 and 𝑅2 respectively. Then, Pro-
𝑅2
tocol Π𝑝1 securely computes F𝑝1 in the (F
Σ )-hybrid model
with identifiable abort if at least one party is honest.

𝑅1
Σ , F

Proof. It is clear that Π𝑝1 securely computes F𝑝1 in the honest-

but-curious setting.

Below, we will use A to denote a non-uniform probabilistic

polynomial-time (PPT) adversary that controls covert parties.

In Figure 4, we define four very similar algorithms S𝑣, 𝑣 ∈
{0, 1, 2, 3} where S0 is a simulator and for which we will prove that
their ideal execution output is indistinguishable from the hybrid
execution output. Each simulator S𝑣 will internally run a copy of
A which we will denote by A𝑣. Without loss of generality, we
can assume that at the points where all parties send messages,
the messages of the honest parties arrive first, as everything an
adversary can infer from the messages of a subset of honest parties
it can also infer from the messages of all honest parties.

To see that the simulation of S0 is indistinguishable from the
𝑅1
𝑅2
Σ )-hybrid model with adversary A, we define our simula-
Σ , F
(F
tors such that

• The outputs of S0 and S1 are identically distributed, because
their only difference is the moment on which 𝑧 is chosen
uniformly at random (and hence independently from other
variables).

• The outputs of S1 and S2 are identically distributed, the only
difference is that S1 first draws 𝑧 in line 28 and then com-
putes 𝑥𝑖′ from it, while S2 first draws 𝑥𝑖′ and then computes
𝑧 from it.

• The outputs of S2 and S3 are indistinguishable. All inputs to
A are the same, except for a commitment 𝐶𝑜𝑚(0, 𝑟𝑖′) versus
a commitment 𝐶𝑜𝑚(𝑥𝑖′, 𝑟𝑖′). As the commitment scheme is
hiding and 𝑟𝑖′ is chosen independetly, the distributions of
these commitments are indistinguishable and for any A3
getting input 𝐶𝑜𝑚(𝑥𝑖′, 𝑟𝑖′) there is an A2 producing a com-
putationally indistinguishable output.

• The output of S3 is identically distributed as the output of

Π𝑝1 in the hybrid model.

□

Vectorized version. We can now consider the ideal functionality

F (𝑘)
𝑝1 ({} . . . {}) = ((𝑈1 . . . 𝑈𝑘 ) . . . (𝑈1 . . . 𝑈𝑘 )),

i.e., F (𝑘)
𝑝1 takes as input from each of the 𝑛 parties an empty string
and outputs to every party the same vector (𝑈1 . . . 𝑈𝑘 ) where every
𝑈𝑖 is uniformly distributed in [0, 𝐿) independently for 𝑖 = 1 . . . 𝑘.
We can then similarly construct a protocol Π (𝑘)
𝑝1 that draws a vector
𝑧 uniformly distributed in [0, 𝐿)𝑘 .

In this protocol we will use a pseudo-random number generator
as we defined in 2.6. We use a similar but equivalent definition which
is more convenient in our proof, in particular, for some polynomial
𝑝, this is a function 𝐺 : {0, 1}𝑞 → [0, 𝐿)𝑝 (𝑞) such that for any

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

F𝑝1 → S0 : 𝑧 (S0 invokes trusted party delivering ideal functionality)

1: Phase 1: choosing 𝑧 (see also phase 4)
2:

if 𝑣 = 0 then

end if

4:
5: Phase 2: S𝑣 simulates honest parties:
6:

S𝑣 : 𝑖 ′ = max{𝑖 | 𝑃𝑖 ∈ P \ P𝑐𝑜𝑟 }
for 𝑃𝑖 ∈ (P \ P𝑐𝑜𝑟 ) \ {𝑃𝑖′ } do

S𝑣: choose 𝑥𝑖 randomly in [0, 𝐿) and 𝑟𝑖 randomly in Z𝑝
S𝑣: 𝐶𝑖 = 𝐶𝑜𝑚(𝑥𝑖, 𝑟𝑖 ); [𝑏𝑖, 𝐶 ′
S𝑣 → A𝑣 : [𝑏𝑖, 𝐶 ′

𝑖 ] = F
𝑖 ] (as if it is sent by 𝑃𝑖 )

𝑅1
Σ (𝐶𝑖 ; 𝑥𝑖, 𝑟𝑖 )

end for
if 𝑣 ∈ {0, 1, 2} then

draw 𝑟𝑖′ randomly; 𝐶𝑖′ = 𝐶𝑜𝑚(0, 𝑟𝑖′); [𝑏𝑖′, 𝐶 ′

𝑖′] = [1, 𝐶𝑖′]

else

draw 𝑥𝑖′ and 𝑟𝑖′ randomly; 𝐶𝑖′ = 𝐶𝑜𝑚(𝑥𝑖′; 𝑟𝑖′); [𝑏𝑖′, 𝐶 ′

𝑖′] = F

𝑅1
Σ (𝐶𝑖′; 𝑥𝑖′, 𝑟𝑖′)

16:

end if
S𝑣 → A𝑣 : [1, 𝐶 ′
17:
18: Phase 3: S𝑣 simulates A𝑣:
for 𝑖 ∈ P𝑐𝑜𝑟 do
19:

𝑖′] (as if it is the answer of F

𝑅1
Σ (𝐶𝑖′; 𝑥𝑖′, 𝑟𝑖′))

: (𝐶𝑖 ; 𝑥𝑖, 𝑟𝑖 ); S𝑣 records 𝐶𝑖 , 𝑥𝑖 and 𝑟𝑖 .

A𝑣 → S𝑣 : 𝐶𝑖
𝑅1
A𝑣 → F
Σ
𝑅1
Σ → S𝑣 : [𝑏𝑖, 𝐶 ′
F
If 𝐶 ′
𝑖 ≠ 𝐶𝑖 or 𝐶𝑖 ≠ 𝐶𝑜𝑚(𝑥𝑖, 𝑟𝑖 ) detect 𝑃𝑖 as cheater
end for

𝑖 ] (as if sent to members of P \ P𝑐𝑜𝑟 )

24:
25: Phase 4: choosing 𝑧 and 𝑥𝑖′
if 𝑣 ∈ {0, 1} then
26:
if 𝑣 = 1 then

27:

S1 chooses 𝑧 uniformly at random

end if
𝑥𝑖′ = 𝑧 − (cid:205)𝑖≠𝑖′ 𝑥𝑖 mod 𝐿

else (i.e., if 𝑣 ∈ {2, 3})

draw 𝑥𝑖′ uniformly at random and set 𝑧 = (cid:205)𝑖 ∈P 𝑥𝑖 mod 𝐿

end if

33:
34: Phase 5:
35:

for 𝑃𝑖 ∈ P \ P𝑐𝑜𝑟 do
S𝑣: set 𝑥 ′
S𝑣 → A𝑣: [𝑏 ′

𝑖 = 𝑥𝑖 ; 𝐶 ′′
𝑖 , 𝐶 ′′

𝑖 = 𝐶𝑖 ; 𝑏 ′
𝑖 , 𝑥 ′

𝑖 = 1

end for

38:
39: Phase 6: S𝑣 continues simulation of A𝑣
40:

for 𝑃𝑖 ∈ P𝑐𝑜𝑟 do
A𝑣 → F 𝑅2
: (𝐶 ′′
Σ
F 𝑅2
Σ → S𝑣 : [𝑏 ′
If 𝑥 ′
𝑖 ≠ 𝑥𝑖 or 𝐶 ′′
end for

𝑖 ); S𝑣 records 𝐶 ′′
𝑖 , 𝑥 ′
𝑖 ; 𝑟 ′
𝑖 , 𝐶 ′′
𝑖 , 𝑥 ′
𝑖 ]
𝑖 ≠ 𝐶𝑖 or 𝑏 ′

𝑖 = 0 detect 𝑃𝑖 as cheater

𝑖 , 𝑥 ′

𝑖 and 𝑟 ′
𝑖

44:
45: Phase 7: Output
46:

A𝑣 → S𝑣 : 𝑧 ′ (the output of A𝑣)
output 𝑧 ′

𝑅2
𝑖 ] (as if it is sent by F
Σ

in answer to (𝑥𝑖, 𝐶𝑖 ; 𝑟𝑖 ))

3:

7:

8:

9:

10:

11:

12:

13:

14:

15:

20:

21:

22:

23:

28:

29:

30:

31:

32:

36:

37:

41:

42:

43:

47:

Figure 4: Simulators S𝑣, for 𝑣 ∈ {0, 1, 2, 3}.

randomized polynomial time algorithm 𝐴 : [0, 𝐿)𝑝 (𝑞) → {0, 1}
there holds that |𝑃𝑥←𝑅 {0,1}𝑞 (𝐴(𝐺 (𝑥)) = 1) −𝑃𝑥←𝑅 [0,𝐿)𝑝 (𝑞) (𝐴(𝑥) =
1)| ≤ 𝜇 (𝑞) with 𝜇 a negligible function. We choose 𝑞 sufficiently
large such that 𝑝 (𝑞) ≥ 𝑘 ⌈log(𝐿)⌉ and 𝜇 (𝑞) is sufficiently small.

20

We describe this protocol in the hybrid model using the ideal
, which is a variant on the F𝑝1 functionality

functionality F𝑝1[0, 2𝑞)

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

we introduced above where 𝐿 is set to 2𝑞. The protocol Π (𝑘)
described below:
1: Protocol Π (𝑘)
𝑝1
2: Security parameter: 𝜆
3: Hybrid functionality sub-protocols:

𝑝1 is

: draws a single public random number in [0, 2𝑞).

• F𝑝1[0, 2𝑞)

4: Protocol:
5: All parties collaboratively perform:
𝑧 ′ = F𝑝1[0, 2𝑞) ({} . . . {})
6:
7: For 𝑃𝑖 ∈ P:
8:

𝑃𝑖 : Output 𝑧 = (𝑧1 . . . 𝑧𝑘 ) with 𝑧 𝑗 containing bits

( 𝑗 − 1) ⌈log(𝐿)⌉ + 1 . . . 𝑗 ⌈log(𝐿)⌉

of 𝐺 (𝑧 ′) for 𝑗 = 1 . . . 𝑘

Theorem 6 (Security of Π (𝑘)

𝑝1 ). Let F𝑝1[0, 2𝑞)

be a secure mul-

tiparty functionality and G be a PRG as defined above. Then, Protocol
𝑝1 securely computes F (𝑘)
Π (𝑘)
-hybrid model with
𝑝1 in the F𝑝1[0, 2𝑞)
identifiable abort if at least one party is honest.

Proof. It follows from the definition of random number gener-
ator that the output of the protocol is indistinguishable from the
output of the ideal functionality when all parties are honest-but-
curious.

The protocol consists of first a call to a secure sub-protocol and
then a public computation which each agent can do for himself
without any interaction. It is hence easy to see that the protocol is
□
secure.

B.4 Proof of Protocol 2
Now we prove the security of Protocol 2, which performs a pri-
vate uniform draw. Without loss of generality, we assume that
the drawn sample should be private to 𝑃1. The ideal functionality
F𝑝2 : ({0, 1}∗)𝑛 → ({0, 1}∗)𝑛 is defined as

F𝑝2 ({} . . . {}) = ((𝑧, 𝑟𝑧), 𝐶𝑧, . . . , 𝐶𝑧)

where 𝐶𝑧 = 𝐶𝑜𝑚(𝑧, 𝑟𝑧), 𝑧 is uniformly randomly distributed in
[0, 𝐿)𝑘 and 𝑟𝑧 is uniformly randomly distributed in Z𝑝 (as a conse-
quence of the distributions of 𝑧 and 𝑟𝑧, 𝐶𝑧 is uniformly distributed
over G). The pair (𝑧, 𝑟𝑧) is private to 𝑃1 while 𝐶𝑧 is known by all
parties. We will describe a detailed version of Protocol 2 in the hy-
brid model. Our hybrid functionalities will be F𝑝1 and F (𝑘)
𝑝1 , which
𝑅𝑚
correspond to Protocol 1, and F
, which, for some modulus 𝐿 ≤ 𝑝
Σ
is the ideal functionality of a zero knowledge proof for relation

𝑅𝑚 = {(𝑦 ∈ [0, 𝐿)𝑘, 𝑟𝑦 ∈ Z𝑝, 𝐶𝑥 ∈ G, 𝐶𝑧 ∈ G;

𝑥 ∈ [0, 𝐿)𝑘, 𝑟𝑥 ∈ Z𝑝, 𝑧 ∈ [0, 𝐿)𝑘, 𝑟𝑧 ∈ Z𝑝 ) :
𝐶𝑥 = 𝐶𝑜𝑚(𝑥, 𝑟𝑥 ) ∧ 𝐶𝑧 = 𝐶𝑜𝑚(𝑧, 𝑟𝑧) ∧ 𝑥 ∈ [0, 𝐿)
∧ 𝑧 = 𝑥 + 𝑦 mod 𝐿 ∧ 𝑟𝑧 = 𝑟𝑥 + 𝑟𝑦 mod Z𝑝 }.

Such proof can be performed by applying the techiques decribed in
Section 6.1. In Figure 5, we define the protocol Π𝑝2 which describes
Protocol 2 in more detail.

21

Theorem 7. Let 𝐶𝑜𝑚 be a computationally binding and perfectly
𝑅𝑚
hiding commitment scheme and let F
be a secure multiparty func-
Σ
tionality of a computationally sound zero-knowledge proof of relation
𝑅𝑚. Let F (𝑘)
be secure multiparty functionalities
as defined above. Then, protocol Π𝑝2 securely computes F𝑝2 in the
(F (𝑘)
𝑅𝑚
Σ )-hybrid model with identifiable abort if at least
𝑝1 , F𝑝1Z𝑝
one party is honest.

𝑝1 and F𝑝1[0, 2𝑞)

, F

Proof. First note that, except for 𝑃1, the other parties are only
supposed to perform ideal calls and do not interact with each other.
We will consider first the most difficult case in which 𝑃1 is among
the corrupted parties controlled by A. In Figure 6, we define our
adversary S that simulates the output of A in the ideal model.

We show that the ideal and hybrid execution outputs are indis-
tinguishable. We first start by analyzing the view of A in the hybrid
protocol and when interacting with S.

• Since A has not seen any other message, the first commit-
ment 𝐶𝑥 of A is the same in both hybrid and ideal executions
• 𝑦 and 𝑟𝑦 have the same distribution in the hybrid and ideal
model as they are part of an ideal call. Therefore, also the
𝐶𝑧 broadcasted by A follows the same distribution in the
hybrid and ideal model.

• if A cheats in 𝐶𝑧 (i.e., 𝐶𝑧 is not a commitment according
to relation 𝑅𝑚), it gets caught both in the hybrid and ideal
executions

• before rewinding A, S recovers 𝑥 and 𝑟𝑥 such that 𝐶𝑥 =
𝐶𝑜𝑚(𝑥, 𝑟𝑥 ) with overwhelming probability (this is because
𝑅𝑚
A cannot fake the zero knowledge proof in F
except with
Σ
negligible probability)

• in the ideal world, S sets 𝑦 and 𝑟𝑦 such that 𝑧 = 𝑥 + 𝑦 mod 𝐿
and 𝑟𝑧 = 𝑟𝑥 + 𝑟𝑦 mod 𝑝, where 𝑥 and 𝑟𝑥 are chosen by A, 𝑧
and 𝑦 are uniformly randomly distributed in [0, 𝐿)𝑘 and 𝑟
and 𝑟𝑦 are uniformly randomly distributed in Z𝑝 . This is the
same distribution as in the hybrid world.

• now A broadcast 𝐶 ′′

𝑧 and either is detected as cheater or
𝐶 ′′
𝑧 = 𝐶𝑜𝑚(𝑧, 𝑟𝑧) with overwhelming probability both in the
hybrid or ideal executions

Up to this point, from the view of A the transcripts simulated by
S in the ideal execution and the transcript in the hybrid execution
are indistinguishable. Since A runs in polynomial time, his output
must be indistinguishable in both executions.

Now we analyze the case where 𝑃1 is among then honest parties.
Particularly, consider the worst case where all other parties are
malicious and 𝑃1 is the only honest party. This case is still easy
since the only interaction of malicious users is to perform ideal calls
to F (𝑘)
. The only role of S is to send inputs that
might be consistent according to the behavior of A. Even if all the
verifiers are malicious, the honest party can still detect them. □

𝑝1 , F𝑝1Z𝑝

𝑅𝑚
and F
Σ

B.5 Non-uniform Public and Private Draws
Public and Private draws from many distributions such as Gaus-
sians or Laplace distributions can be performed by first drawing uni-
formly distributed samples with either Protocol 1 for public draws
or Protocol 2 for private draws, then applying a non-interactive

Proceedings on Privacy Enhancing Technologies YYYY(X)

César Sabater, Florian Hahn, Andreas Peter, and Jan Ramon

1: Protocol Π𝑝2 (to generate single private sample):
2: Security Parameter: 𝜆
3: Hybrid Functionalitiy sub-protocols:

𝑝1 draws publicly a random number from [0, 𝐿)𝑘 .

is a variant of F𝑝1 that draws a random number from Z𝑝 rather than from [0, 𝐿).

performs a zero-knowledge proof for the relation 𝑅𝑚 defined above

• F (𝑘)
• F𝑝1Z𝑝
𝑅𝑚
• F
Σ
4: Protocol:
5: 𝑃1:
6:

7:

11:
12: 𝑃1:
13:

14:

draw 𝑥 ∈ [0, 𝐿)𝑘 and 𝑟𝑥 ∈ Z𝑝 uniformly at random
compute 𝐶𝑥 = 𝐶𝑜𝑚(𝑥, 𝑟𝑥 )
broadcast 𝐶𝑥

8:
9: All parties in P collaboratively:
10:

call F (𝑘)
call F𝑝1Z𝑝

𝑝1 to obtain a public 𝑦 uniformly distributed over [0, 𝐿)𝑘
to obtain a public 𝑟𝑦 uniformly distributed over Z𝑝

Compute 𝑧 = 𝑥 + 𝑦 mod 𝐿 and 𝑟𝑧 = 𝑟𝑥 + 𝑟𝑦 mod 𝑝
Compute 𝐶𝑧 = 𝐶𝑜𝑚(𝑧, 𝑟𝑧)
broadcast 𝐶𝑧

17:

15:
𝑅𝑚
16: Parties perform an ideal call to F
Σ
𝑅𝑚
𝑃1 → F
Σ
𝑅𝑚
F
Σ
𝑃−1: if 𝑏 = 0 ∨ 𝑟𝑢 ≠ 𝑟 ′

: (𝑦, 𝑟𝑦, 𝐶𝑥 , 𝐶𝑧; 𝑥, 𝑟𝑥 , 𝑧, 𝑟𝑧)
𝑦, 𝐶 ′

: broadcast [𝑏, 𝑦 ′, 𝑟 ′

𝑥 , 𝐶 ′
𝑧]
𝑦 ∨ 𝑦 ≠ 𝑦 ′ ∨ 𝐶𝑥 ≠ 𝐶 ′

18:

:

19:
20: 𝑃1: output (𝑧, 𝑟𝑧)
21: 𝑃−1: output 𝐶𝑧

𝑥 ∨ 𝐶𝑍 ≠ 𝐶 ′

𝑧, detect 𝑃1 as a cheater and abort, otherwise continue the execution

Figure 5: Protocol Π𝑝2, a detailed description of Protocol 2.

transformation. For private draws, this transformation is a non-
interactive compressed Σ-protocol as described in Appendix B.2.
For each technique, we explain the appropriate transformation in
Sections 7.1, 8.1, 8.2, 8.3 and 8.4. This procedure is secure as it is
essentially a secure drawing of a uniformly distributed random
number as discussed in the previous sections followed by a private
but verifiable single-party post-processing.

22

Private Sampling with Identifiable Cheaters

Proceedings on Privacy Enhancing Technologies YYYY(X)

1: S: internally run A until broadcast 𝐶𝑥 (line 8 in Π𝑝2)
2: A → S : 𝐶𝑥
3: S: continue the run of A until after the ideal call to F (𝑘)
4: S: draw a random value 𝑦 ∈ [0, 𝐿)𝑘
5: S → A : 𝑦 (as if it came from F (𝑘)
𝑝1 )
6: S: continue the run of A until after the ideal call to F𝑝1Z𝑝
7: S: draw a random value 𝑟𝑦 ∈ Z𝑝
8: S → A : 𝑟𝑦 (as if it came from F𝑝1Z𝑝
9: A → S : 𝐶𝑧
𝑅𝑚
10: S: continue run of A: 𝑃1 → F
Σ
𝑥 , 𝐶 ′
: broadcast [𝑏, 𝑦 ′, 𝑟 ′
𝑦, 𝐶 ′
𝑧]
𝑥 ≠ 𝐶𝑥 ∨ 𝐶 ′
𝑦 ≠ 𝑟𝑦 ∨ 𝐶 ′

𝑅𝑚
Σ
if 𝑏 = 0 ∨ 𝑦 ′ ≠ 𝑦 ∨ 𝑟 ′

𝑧, 𝑥 ′, 𝑟 ′

: (𝑦 ′, 𝑟 ′

𝑥 , 𝐶 ′

𝑦, 𝐶 ′

)

𝑥 , 𝑧 ′, 𝑟 ′
𝑧)

𝑝1 (line 10 in Π𝑝2)

(line 11 in Π𝑝2)

𝑧 ≠ 𝐶𝑧, detect 𝑃1 as a cheater

11: F
12:
13: S: invoke trusted party computing F𝑝2
14: F𝑝2 returns ((𝑧, 𝑟𝑧) ∈ [0, 𝐿)𝑘 × Z𝑝, (𝐶𝑧, . . . , 𝐶𝑧) ∈ G|P𝑐𝑜𝑟 |−1) to S and (𝐶𝑧, . . . , 𝐶𝑧) ∈ G|P\P𝑐𝑜𝑟 | to the honest parties
15: S sets 𝑦 = 𝑧 − 𝑥 mod 𝐿 and 𝑟𝑦 = 𝑟𝑧 − 𝑟𝑥 mod 𝑝
16: S rewinds A to before the invocation of F (𝑘)
𝑝1
17: S continues the internal run of A, which performs ideal calls to F (𝑘)
18: S → A : 𝑦, 𝑟𝑦 (as if they were sent by F (𝑘)
19: A → S : 𝐶 ′′
𝑧 ; if 𝐶 ′′
𝑧 ≠ 𝐶𝑧, detect 𝑃1 as a cheater
𝑅𝑚
𝑦 , 𝐶 ′′
20: S continues to run A: 𝑃1 → F
Σ
𝑦 , 𝐶 ′′
𝑥 , 𝐶 ′′
𝑧 ]
𝑦 ≠ 𝑟𝑦 ∨ 𝐶 ′′
𝑥 ≠ 𝐶𝑥 ∨ 𝐶 ′′

𝑧 ≠ 𝐶𝑧, detect 𝑃1 as a cheater

: broadcast [𝑏 ′, 𝑦 ′′, 𝑟 ′′

𝑝1 and F𝑝1Z𝑝

𝑝1 and F𝑝1Z𝑝

𝑥 , 𝑧 ′′, 𝑟 ′′
𝑧 )

𝑧 , 𝑥 ′′, 𝑟 ′′

: (𝑦 ′′, 𝑟 ′′

𝑥 , 𝐶 ′′

)

.

𝑅𝑚
21: F
Σ
if 𝑏 ′ = 0 ∨ 𝑦 ′′ ≠ 𝑦 ∨ 𝑟 ′′
22:
23: output whatever A outputs

Figure 6: Simulator of advesary A in Protocol Π𝑝2, for the case when 𝑃1 is corrupted.

23

