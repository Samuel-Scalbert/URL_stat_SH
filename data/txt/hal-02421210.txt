Vers un désenchevêtrement de l’ambiguïté de la tâche et
de l’incertitude du modèle pour la classification avec
option de rejet à l’aide de réseaux neuronaux
Titouan Lorieul, Alexis Joly

To cite this version:

Titouan Lorieul, Alexis Joly. Vers un désenchevêtrement de l’ambiguïté de la tâche et de l’incertitude
du modèle pour la classification avec option de rejet à l’aide de réseaux neuronaux. CAP 2019 - 21e
PFIA Conférence sur l’Apprentissage Automatique, Jul 2019, Toulouse, France. ￿hal-02421210￿

HAL Id: hal-02421210

https://hal.science/hal-02421210

Submitted on 20 Dec 2019

HAL is a multi-disciplinary open access
archive for the deposit and dissemination of sci-
entific research documents, whether they are pub-
lished or not. The documents may come from
teaching and research institutions in France or
abroad, or from public or private research centers.

L’archive ouverte pluridisciplinaire HAL, est
destinée au dépôt et à la diffusion de documents
scientifiques de niveau recherche, publiés ou non,
émanant des établissements d’enseignement et de
recherche français ou étrangers, des laboratoires
publics ou privés.

Vers un désenchevêtrement de l’ambiguïté de la tâche et de l’incertitude du
modèle pour la classiﬁcation avec option de rejet à l’aide de réseaux neuronaux

T. Lorieul1

A. Joly1

1 Zenith, LIRMM, Université de Montpellier, Inria, France

titouan.lorieul@gmail.com

Résumé

La classiﬁcation avec option de rejet est un moyen d’abor-
der le problème de l’estimation de l’incertitude d’un classi-
ﬁeur. Les approches récentes s’attaquant à ce problème uti-
lisent des critères basés sur une mesure, soit, de conﬁance,
soit, de dispersion. Cependant, aucune d’entre elles ne
combine explicitement les deux principales sources d’in-
certitude : l’ambiguïté de la tâche, intrinsèque à celle-
ci, et l’incertitude du modèle, découlant de l’échantillon-
nage des données et de la stochasticité de l’apprentissage.
Dans cet article, nous explorons comment ces deux quan-
tités peuvent être fusionnées aﬁn d’établir des critères de
rejet plus efﬁcaces. En particulier, nous proposons une sé-
rie de méthodes combinant des mesures de désaccord et
des estimations de l’ambiguïté en utilisant un ensemble de
modèles. Des expériences sur des jeux de données synthé-
tiques construits pour modéliser différents types d’incer-
titudes indiquent que ces nouveaux critères ont des per-
formances similaires aux méthodes de référence. Néan-
moins, des analyses plus approfondies montrent des in-
dices empiriques qui mettent en avant l’existence d’infor-
mation supplémentaire dans la distribution des résultats de
l’ensemble. Dans les faits, le réjecteur idéal peut être une
fonction plus complexe que les critères précédents, et peut
même parfois être contre-intuitif.

Mots Clef

Classiﬁcation avec option de rejet, estimation d’incerti-
tude, réseaux neuronaux, ensemble de modèles.

Abstract

Classiﬁcation with reject option is a way to address the
problem of estimating the uncertainty of a classiﬁer. Recent
approaches to this problem use criteria based on either a
conﬁdence or a dispersion measure. However, they do not
explicitly combine the two main sources of uncertainty : the
ambiguity of the task, inherent to it, and the uncertainty of
the model, resulting from data sampling and stochasticity
of learning process. In this article, we explore how these
two quantities can be merged to build more effective rejec-
tion criteria. In particular, we propose methods for combi-
ning disagreement measures and ambiguity estimates using

an ensemble of models. Experiments on synthetic data sets
constructed to model different types of uncertainties indi-
cate that these new criteria have similar performance to
the baselines. Nevertheless, more in-depth analyses show
empirical evidence that highlights the existence of additio-
nal information in the distribution of the overall results. In
practice, the ideal rejector may be a more complex func-
tion than the previous criteria, and may even be counter-
intuitive at times.

Keywords

Classiﬁcation with reject option, uncertainty estimation,
neural networks, ensembles.

Introduction

1
Il est important de disposer de mesures précises de l’in-
certitude des prévisions d’un modèle dans de nombreux
scénarios pratiques où l’on ne peut pas se permettre de
commettre des erreurs. Cela est en particulier vrai dans des
applications médicales, de conduite autonome, etc. Cepen-
dant, quantiﬁer précisément cette information d’incertitude
est un problème difﬁcile, surtout lorsque le processus d’ap-
prentissage n’est pas entièrement compris comme cela est
le cas pour les réseaux neuronaux. Une façon d’assouplir
cet objectif ambitieux, tout en progressant dans cette direc-
tion, est de permettre aux classiﬁeurs de refuser de donner
une réponse pour une entrée donnée. Ceci est connu sous
le nom de classiﬁcation avec une option de rejet [5, 14].
Cette décision de rejeter peut tirer parti de l’incertitude
prédictive sans avoir à la modéliser complètement et ainsi
permettre de mieux comprendre ce qui est nécessaire pour
construire des modèles fournissant des informations d’in-
certitude plus complètes.
La classiﬁcation avec option de rejet consiste à fournir
deux fonctions : un prédicteur h : X → Y et un réjecteur
r : X → {0, 1}, où X et Y sont, respectivement, les es-
paces d’entrée et de sortie de la tâche. La fonction apprise
est alors

(h, r)(x) =

(cid:40)

h(x)
(cid:114)

si r(x) = 0,
sinon (r(x) = 1),

où (cid:114) désigne le refus de répondre.

Parmi les approches classiques du rejet, on peut distinguer
deux grandes familles de méthodes. La première considère
que h ne donne pas seulement une prédiction en Y mais
fournit également une forme d’information de conﬁance,
par exemple dans R, qui peut être utilisée pour effectuer un
rejet en seuillant sur sa valeur [1]. C’est le cas, par exemple,
de la régression logistique et des réseaux de neurones qui
donnent une distribution de probabilité catégorielle en sor-
tie, ou des SVMs qui fournissent une distance à la frontière
de décision. Nous les qualiﬁerons de méthodes basées sur
la conﬁance. L’autre catégorie tente de mesurer les ﬂuc-
tuations du classiﬁeur et favorise le rejet dans les zones de
l’espace d’entrée où sa variabilité est la plus élevée. L’hy-
pothèse avancée par ces méthodes est que le prédicteur est
plus susceptible d’être incertain dans sa décision dans ces
zones-là. Ces approches ont été particulièrement explorées
dans le contexte de l’apprentissage actif [21] et dans les
réseaux neuronaux bayésiens [9]. Nous les qualiﬁerons de
méthodes basées sur la dispersion.

Nous afﬁrmons que, en fait, ces deux approches sont in-
complètes dans le sens où elles ne saisissent que partiel-
lement l’information sur l’incertitude. En effet, cette der-
nière peut être divisée en deux catégories : l’ambiguïté de
la tâche et l’incertitude du modèle. La première est intrin-
sèque à la tâche que nous voulons accomplir. Par exemple,
une image de la ﬂeur d’une plante ne contient qu’une infor-
mation partielle qui peut ne pas être sufﬁsante pour distin-
guer deux espèces similaires. Cette incertitude provient du
bruit de la mesure (prendre une photo dans notre exemple)
ainsi que du bruit dans le processus d’annotation. Elle est,
en fait, directement liée à la fonction de régression

ηk(x) = Pr [Y = k | X = x]

de l’apprentissage avec un superviseur imparfait.

Cependant, ce n’est pas la seule incertitude qui apparaît
quand on essaie d’apprendre un prédicteur. En effet, lors-
qu’on nous donne un ensemble de données, nous devons
faire face à l’incertitude du processus d’échantillonnage :
nous n’avons accès qu’à une vue partielle de la distribu-
tion latente des données. Un échantillonnage différent des
données nous induira à choisir un autre prédicteur. De plus,
l’algorithme d’apprentissage peut être intrinsèquement sto-
chastique. Ainsi, lors de l’apprentissage de réseaux neuro-
naux, en raison de la non-convexité de l’objectif d’appren-
tissage, la ré-exécution de la descente de gradient stochas-
tique en utilisant une initialisation différente et un brassage
différent des données d’apprentissage nous donnera une so-
lution différente qui est souvent comparable en termes de
précision tout en apportant de la diversité. Cette incertitude
n’est pas intrinsèque à la tâche et survient lors de l’appren-
tissage du modèle, nous l’appellerons donc incertitude du
modèle.

Ces deux types d’incertitude, l’ambiguïté des tâches et l’in-
certitude du modèle, saisissent des informations différentes
et complémentaires. Nous proposons de les utiliser expli-
citement pour construire de nouveaux critères de rejet en

essayant de les démêler avant de les fusionner de nouveau
de manière adaptée.
Dans cet article, nous nous concentrerons principalement
sur la classiﬁcation binaire à l’aide de réseaux neuronaux.
Nous présentons deux contributions principales. Premiè-
rement, dans la Section 3, nous proposons de nouveaux
critères de classiﬁcation avec option de rejet en utilisant
des mesures de l’ambiguïté des tâches et de l’incertitude
du modèle. Deuxièmement, comme ces critères semblent
avoir des performances similaires à celles des méthodes
de référence dans nos expériences, dans la Section 4, nous
montrons qu’il existe effectivement des informations sup-
plémentaires à exploiter en démêlant les deux types d’in-
certitude présentés précédemment mais qu’elles peuvent
être difﬁcile à saisir sans apprendre un critère ad hoc sur
un ensemble de validation.

2 Formulation du problème et état

de l’art

La classiﬁcation avec option de rejet a d’abord été intro-
duite et étudiée dans [4, 5] en utilisant des modèles pro-
babilistes. Des travaux plus récents ont étudié ce problème
dans le cadre de la théorie de l’apprentissage statistique en
déﬁnissant une fonction de risque adaptée. Il est habituel-
lement exprimé pour un coût de rejet donné de λ [14, 6]
par

Rλ(h, r) = EX,Y

(cid:2)δh(X)(cid:54)=Y (1 − r(X)) + λr(X)(cid:3)

(1)
et est minimisé pour le classiﬁer de Bayes optimal (h∗, r∗)
suivant :

h∗(x) = δη(x)≥ 1

2

et

r∗(x) = δ|η(x)− 1

2 |< 1

2 −λ.

(2)

Il s’agit donc d’un compromis entre le taux d’erreur et le
taux de rejet pour ce coût λ et favorise le rejet dans les
zones où l’ambiguïté de la tâche est plus grande.
Beaucoup de travaux théoriques partent de cette formula-
tion et se concentrent principalement sur le cas binaire. Par
exemple, [14] a étudié le taux de convergence des estima-
teurs plug-in et des minimiseurs du risque empirique. [1]
a proposé une hinge loss pour les réjecteurs basés sur la
conﬁance qui peut être mise en œuvre dans la pratique et
en propose l’étude théorique. [25] étudie d’autres fonctions
objectives convexes tandis que [6] étend cela à des réjec-
teurs d’une classe de fonctions différente de celle du pré-
dicteur. Une autre approche consiste à apprendre séquen-
tiellement des classiﬁeurs qui peuvent rejeter avec un coût,
une tâche appelée apprentissage séquentiel, comme étudié
dans [22].
Parallèlement, [8] a utilisé une stratégie basée sur les
désaccords pour apprendre un prédicteur parfait dans le cas
réalisable, c’est-à-dire en l’absence de bruit et lorsque le
classiﬁeur parfait est dans la classe des hypothèses. [23, 24]
ont ensuite étudié de telles approches pour le cas agnos-
tique aﬁn d’apprendre ce qu’ils appellent des classiﬁeurs
sélectifs point par point, c’est-à-dire que les prédicteurs ont
le même taux d’erreur que celui optimal tout en essayant de

maintenir le taux de rejet le plus bas possible. De plus, ils
proposent de mesurer la performance de ces modèles, non
seulement pour un coût de rejet λ donné, qui pourrait ne
pas être quantiﬁable en pratique, mais sur l’ensemble de la
courbe de risque/couverture, ce qui revient à comparer la
performance pour tous les choix de λ en même temps [8].
Cependant, ces travaux sont, soit purement théoriques, soit
reposent sur une optimisation convexe. Cela peut être un
problème pour les réseaux de neurones parce que leur pro-
cessus d’apprentissage n’est pas encore entièrement com-
pris. Ainsi, de nombreuses études empiriques et heuris-
tiques ont été réalisées autour des critères de rejet et de
l’estimation de l’incertitude pour ces modèles. Pour les
réseaux neuronaux, les approches basées sur la conﬁance
ont été étudiées depuis longtemps et continuent de l’être
jusqu’à récemment dans [17, 16] par exemple. En ce qui
concerne les méthodes fondées sur la dispersion, [9] in-
terprète le dropout comme une approximation de l’infé-
rence bayésienne et propose d’utiliser la variance du résul-
tat comme mesure d’incertitude. Cependant, [10] montre
que ces différentes mesures, basées sur la conﬁance ou sur
la dispersion, peuvent être améliorées en choisissant, pen-
dant la phase d’apprentissage, des modèles mieux adaptés
à chaque zone de l’espace d’entrée. Plus largement, dans
le contexte de l’apprentissage actif, des mesures basées sur
la conﬁance et sur la dispersion ont été étudiées, [21] en
propose une vue d’ensemble.
Les mesures de dispersions que nous introduisons dans
ce papier sont basées sur le désaccord entre les modèles
d’un ensemble. Cette notion de désaccord est importante
dans l’apprentissage et a été exploitée à multiples reprises.
En effet, elle a d’abord été utilisée pour obtenir un mo-
dèle plus performant que chacun des modèles individuels
à travers le bagging [3] et le boosting [20]. Certains tra-
vaux tels que [11] fournissent une étude théorique de ces
approaches. La notion de désaccord est également impor-
tante dans d’autres paradigmes d’apprentissage tels que
l’apprentissage actif [13] ou bien, comme développé pré-
cedémment, la classiﬁcation avec rejet [24].
Enﬁn, les différentes sources d’incertitudes sont générale-
ment séparées en incertitudes aléatoriques et épistémiques
[7, 15]. La première est déﬁnie comme la partie irréduc-
tible de l’incertitude, par opposition à la seconde qui peut
être réduite en collectant plus de données ou en afﬁnant le
modèle. Cependant, comme cela est expliqué en détail dans
[7], la distinction précédente a un sens dans un modèle pour
lequel il est explicite quelle incertitude peut être réduite.
Nous préférons la terminologie de l’ambiguïté de la tâche
et l’incertitude du modèle parce que nous ne considérons
pas ici quelle incertitude peut être réduite et comment mais
plutôt si elle est intrinsèque à la tâche ou si elle provient du
processus d’apprentissage.

3 Deux types d’incertitude

Dans cette section, nous étudions comment, à la fois, l’am-
biguïté des tâches et l’incertitude du modèle peuvent être

utilisées pour obtenir de nouveaux critères de classiﬁcation
avec option de rejet.

3.1

Incertitude dans le choix du prédicteur

En raison de la stochasticité de l’apprentissage et des pro-
cessus d’échantillonnage des données, il y a une incertitude
dans le choix de l’hypothèse h. Nous pouvons construire
un critère basé sur la variabilité de la prédiction due à cette
stochasticité.
Comme nous utilisons des classes d’hypothèses paramé-
trées, l’incertitude dans le choix de h = hθ provient
en fait d’une incertitude dans le choix des paramètres
θ étant donné les données d’apprentissage Dtrain, c’est-
à-dire Pr [θ = θ(cid:48) | Dtrain]. Ainsi, une première approche
consiste à modéliser complètement cette distribution de
probabilité sur les paramètres et une façon de le faire est
d’utiliser des approches bayésiennes [18]. Dans ce cas, une
distribution a priori sur tous les paramètres, Pr [θ = θ(cid:48)], est
déﬁnie et sa la distribution a posteriori Pr [θ = θ(cid:48) | Dtrain]
est calculée en appliquant la règle de Bayes.
Cependant, selon le modèle utilisé, il peut être difﬁcile
d’établir une distribution a priori adaptée, de plus, le cal-
cul de la distribution a posteriori peut s’avérer difﬁcile. Il
est possible d’utiliser des méthodes d’approximation mais,
dans certaines situations, cela peut ne pas être sufﬁsant.
Cela est en particulier le cas pour les réseaux de neurones
où l’application des méthodes bayésiennes est un domaine
de recherche actif [18, 19, 2, 9].
Néanmoins, comme dans le présent article, nous nous in-
téressons uniquement à la classiﬁcation avec option de
rejet, il n’est pas nécessaire de modéliser cette distribu-
tion complexe. Nous pouvons utiliser une approche plus
directe pour estimer nos critères en supposant que nous
pouvons échantillonner les modèles de notre distribution
Pr [θ = θ(cid:48) | Dtrain]. On peut y parvenir en simulant les dif-
férentes sources d’incertitude du modèle, c’est-à-dire :

• la stochasticité de l’algorithme d’apprentissage en exé-
cutant plusieurs fois l’apprentissage sur les mêmes
données

• l’échantillonnage des données d’entraînement en uti-
techniques de bootstrap et de sous-
lisant des
échantillonage pour simuler la stochasticité du proces-
sus de génération des données.

Une fois qu’il est supposé que nous pouvons échantillon-
ner à partir de Pr [θ = θ(cid:48) | Dtrain], nous pouvons alors
construire des critères basés sur la dispersion. En particu-
lier, nous étudions dans la section suivante un critère basé
sur le désaccord entre les prédicteurs de cette distribution.

3.2 Un critère pratique de désaccord

Les critères de désaccord ont été théoriquement étudiés
dans le contexte de la classiﬁcation avec option de rejet
pour trouver un prédicteur ayant le même taux d’erreur que
le classiﬁeur parfait tout en ayant un taux de rejet faible
[8, 23, 24], ainsi que dans le cadre de l’apprentissage actif
[13]. Les statégies proposés restent cependant théoriques et

ne sont pas implémentables en pratique. Dans cette sous-
section, nous proposons un moyen de les rendre pratiques
et de les généraliser.

L’idée générale est de quantiﬁer le désaccord entre les mo-
dèles (hθ)θ d’un ensemble de modèles en regardant uni-
quement leurs prédictions ˆy = hθ(x) ∈ Y. Pour cela, nous
déﬁnissons la mesure de désaccord ζ(x) comme
(cid:104) ˆY = 1 | X = x

ζ(x) = Pr

(cid:2)δhθ(x)=1

= Eθ

(cid:3) ,

(cid:105)

étant donné une mesure de probabilité sur l’ensemble des
paramètres θ. Notez que cette quantité est différente de
la fonction de régression η(x) qui mesure l’ambiguïté de
la tâche elle-même, Pr [Y = 1 | X = x], indépendamment
des modèles. De plus, cette quantité n’est pas à proprement
parler une probabilité de désaccord, mais elle capture cette
information. En effet, le désaccord est maximal quand ζ(x)
vaut 0.5 et minimal quand il vaut 0 ou 1.

Si nous modélisons complètement l’incertitude dans les pa-
ramètres Pr [θ = θ(cid:48) | Dtrain], il est alors possible de calcu-
ler le désaccord entre ces hypothèses en utilisant

ˆζ(x) =

(cid:90)

θ(cid:48)

δhθ(cid:48) (x)=1 Pr [θ = θ(cid:48) | Dtrain] dθ(cid:48).

(3)

Cependant, si nous ne nous intéressons qu’à ζ(x), nous
n’avons, en général, pas besoin de modéliser complètement
la distribution sur les paramètres, ce qui peut être une tâche
complexe comme le montre la sous-section précédente.

Au lieu de cela, parce que ˆy ∈ Y est discret, si on dispose
de C échantillons, θ1, . . . , θC, nous pouvons estimer di-
rectement la distribution Pr
avec une ap-
proche fréquentiste :

(cid:104) ˆY = 1|X = x

(cid:105)

ˆζfreq(x) =

1
C

C
(cid:88)

i=1

δhθi (x)=1.

(4)

Néanmoins, bien que cet estimateur soit non biaisé, il pour-
rait nécessiter beaucoup d’échantillons, soit un grand C,
pour réduire sa variance.

En général, la plupart des modèles hθ peuvent être décom-
posés en utilisant une fonction paramétrée fθ : X → R sur
lequel est appliquée une fonction de décision δZ : R →
{0, 1}. Typiquement, δZ(z) = δz≥0. Lors de l’utilisation
d’une fonction de coût logistique, z est appelé logit et nous
pouvons même décomposer h un peu plus en appliquant,
par-dessus fθ, la fonction sigmoid σ : R → [0, 1] pour
transformer z en probabilité avant de prendre la décision
qui devient δP (p) = δp≥ 1
. Ces décompositions peuvent
2
être résumées comme suit :

hθ−→ ˆy ⇔ x

fθ−→ z

δZ−→ ˆy ⇔ x

fθ−→ z

x

σ−→ p

δP−→ ˆy

Sur la base de la décomposition précédente, nous pouvons
en fait utiliser une approche intermédiaire entre les deux
extrêmes que sont les Équations (3) et (4). En effet, parce
que ˆy est une fonction (non paramétrique) de z et p, il sufﬁt
de modéliser l’incertitude dans l’espace des logits ou de
la probabilité. A partir de ces distributions, nous pouvons

ensuite dériver la mesure de désaccord en utilisant
ˆζ(x) =

δz≥0 Pr [Z = z | X = x] dz = 1 − F Z

(cid:90)

x (0) (5)

z

(cid:90)

et

ˆζ(x) =

δp≥ 1

2

Pr [P = p | X = x] dp = 1 − F P
x (

1
2

)

p

x et F P

(6)
où F Z
x sont respectivement la fonction de répartition
de la probabilité conditionnelle dans l’espace des logits et
des probabilités.
Cette méthode permet d’introduire des hypothèses et des
connaissances à priori qui sont plus faciles à tester dans
la pratique que la modélisation complète de la distribution
des paramètres. En même temps, si ces hypothèses sont vé-
riﬁées, l’estimateur résultant convergerait plus rapidement
que ˆζfreq(x), ce qui signiﬁe que nous pourrions choisir un
C plus petit, rendant cette approche plus pratique. Fina-
lement, cette formalisation nous permet de mieux com-
prendre comment fusionner les différentes statistiques et
moments, comme le montre la section suivante.

3.3 Choix de la distribution

Nous étudions maintenant quels sont les choix de distribu-
tions appropriées dans les espaces des logits et des proba-
bilités.
logits,
En supposant qu’on nous donne plusieurs
z1, . . . , zC, pour une entrée x, un choix courant est
d’utiliser une loi normale pour modéliser leur distribu-
tion. Dans ce cas, nous pouvons ajuster les paramètres
de la distribution en utilisant les estimateurs de maxi-
mum de vraisemblance habituels ˆµz = 1
i=1 zi et
C
z = 1
ˆσ2
i=1(zi − ˆµz)2. L’estimateur de l’Équation (5)
C
devient alors

(cid:80)C

(cid:80)C

ˆζnorm(x) = 1 − φ

(cid:18)

−

ˆµz
ˆσz

(cid:19)

,

.

où φ est la fonction de répartition de la distribution nor-
male standard. Fait intéressant, ce critère est une fonction
bijective de ˆµz
ˆσz
Alternativement, si nous considérons l’espace des distri-
butions binaires p, un choix naturel est la loi bêta. Dans
ce cas, il n’existe pas de forme close pour les estimateurs
du maximum de vraisemblance de ses paramètres α et β.
Il faut soit s’appuyer sur un algorithme itératif, soit uti-
liser la méthode des moments. Dans ce dernier cas, les
estimateurs de la méthode des estimateurs sont égaux à
(cid:17)
ˆα = ˆµp
avec ˆµp = 1
C
mateur de l’Équation (6) est alors égal à

(cid:16) ˆµp(1−ˆµp)
− 1
ˆvp
i=1(pi − ˆµp)2. L’esti-

(cid:16) ˆµp(1−ˆµp)
ˆvp
(cid:80)C

i=1 pi et ˆvp = 1
C

et ˆβ = (1 − ˆµp)

(cid:80)C

− 1

(cid:17)

(ˆα, ˆβ),

ˆζbeta(x) = 1 − I 1
où Ix est la fonction bêta incomplète régularisée.
Maintenant que nous disposons d’une mesure pratique de
désaccord, nous pouvons établir un critère de classiﬁcation
avec une option de rejet telle que

2

cdisagree(x) = max(ˆζ(x), 1 − ˆζ(x)).

(7)

Cependant, il ne s’agit là que d’une mesure de la disper-
sion des prédictions de l’ensemble, l’incorporation d’une
mesure de l’ambiguïté de la tâche pourrait conduire à de
meilleurs critères.

3.4 Critère de fusion

Si l’on examine la fonction de risque de la classiﬁcation
avec option de rejet de l’Équation (1), cette quantité est
minimisée par le réjecteur optimal de Bayes de l’Équation
(2). En estimant la fonction de régression η(x), nous pou-
vons construire une règle plug-in qui nous permettrait d’ef-
fectuer un rejet basé sur notre estimateur ˆη(x). Le taux de
convergence théorique de cet estimateur plug-in a été étu-
dié dans [14] où il a été démontré qu’il dépend de la qua-
lité de l’estimateur ˆη(x) et de la structure et du niveau de
l’ambiguité η(x). La construction d’un tel estimateur peut
se faire en optimisant une fonction de coût strictly proper
[12]. Il s’avère que la fonction de coût logistique est en fait
strictly proper, un telle approche a par ailleurs été appli-
quée aux réseaux neuronaux dans [16].
Cependant, cette méthode ne tient pas compte de la va-
riabilité de l’estimateur qui change en fonction des zones
de l’espace d’entrée. Cette variabilité pourrait donner lieu
à une prédiction différente ˆy. En utilisant le critère de
désaccord de la sous-section précédente, nous pouvons
construire un nouveau critère en marginalisant notre incer-
titude dans le choix de la prédiction :

cfusion(x) = Pr

(cid:104) ˆY = 0 | X = x

(cid:105)

(1 − ˆη(x))

+ Pr

(cid:104) ˆY = 1 | X = x

(cid:105)

ˆη(x).

S’il n’y a pas de désaccord, c’est-à-dire si ζ(x) ∈ {0, 1},
ce critère est simplement l’ambiguïté estimée de la prévi-
sion : max(ˆη(x), 1 − ˆη(x)). De plus, pour une valeur égale
de ˆη(x), ce critère rejettera d’abord les zones de l’espace
d’entrée où le désaccord est le plus fort. Cette quantité a
donc des propriétés intéressantes.
En injectant notre estimateur de ζ(x) dans l’équation pré-
cédente, le critère devient

cfusion(x) = (1 − ˆζ(x))(1 − ˆη(x)) + ˆζ(x)ˆη(x).

(8)

3.5 Expériences synthétiques

Aﬁn de comparer les différents critères de rejet, nous utili-
sons des jeux de données synthétiques où nous pouvons
contrôler la quantité d’ambiguïté η(x) et la densité des
données p(x). Nous utilisons trois jeux de données diffé-
rents illustrés dans la Figure 1 :

• Fig.1a : absence d’ambiguïté, i.e. η(x) ∈ {0, 1}, mais
il existe deux zones de densités uniformes différentes ;

• Fig.1b : x est distribué uniformément mais il y a des

zones d’ambiguïté de quantité différente ;

• Fig.1c : mélange des deux scénarios précédents.

Ces jeux de données permettent de comprendre ﬁnement
comment les prédictions du modèle et les critères de rejet
se comportent sous différentes contraintes d’incertitude.

La mesure de performance que nous utilisons est la courbe
RC [8] et, en particulier, l’aire sous cette courbe telle que
déﬁnie dans [10] que nous désignons RC-AUC. La courbe
de risque/couverture (RC) est déﬁnie comme suit
(cid:21)

R(h, r) = EX,Y

(cid:20)
δh(X)(cid:54)=Y

1 − r(X)
φ(h, r)

,

φ(h, r) = 1 − EX [r(X)] .

Le risque R quantiﬁe le taux d’erreur des échantillons qui
ne sont pas rejetés. La couverture φ mesure le taux d’accep-
tation. Plus cette quantité est faible, meilleur est le compro-
mis entre précision et taux de rejet.
Toutes les fonctions de rejet que nous considérons effec-
tuent un seuillage se basant sur un critère c :

r(x) = δc(x)≥τ .

(9)

Nous utilisons comme références les critères suivants :

• pour les approches basées sur la conﬁance : moyenne
de |µp − 1
2 | dans l’espace de probabilité, notée “prob.
mean”, et moyenne de |µz| dans l’espace logit, notée
“logit mean” 1

• pour les approches basées sur la dispersion : la va-
riance de |µp − 1
2 | notée “var. prob.” et de |µz| notée
“var. logit” et la moyenne de la divergence de Kullback-
Leibler (KL) des prévisions des modèles individuels de
l’ensemble comparé à la prévision moyenne telle que
déﬁnie dans [21]

Notez que pour les critères basés sur la dispersion, c’est
leur opposé qui est seuillé. Nous intégrons en outre le clas-
siﬁeur optimal de Bayes de l’Équation (2) pour fournir la
plus faible valeur de la RC-AUC réalisable.
Nous comparons d’abord les différents critères basés sur
les mesures de désaccord des Équations (7) et (8) dans la
colonne de gauche de la Figure 2. Avec sufﬁsamment de
données, les critères de désaccord convergent vers le cri-
tère optimal en l’absence d’ambiguïté alors qu’en présence
d’ambiguïté, ce n’est pas le cas. Cela est attendu car ces
critères ne prennent pas en compte cette partie de l’incer-
titude, mais seulement le désaccord entre les modèles de
l’ensemble. L’utilisation du critère de fusion pour incorpo-
rer l’ambiguïté à ces critères les améliore et les fait conver-
ger vers la performance du critère optimal. Parce que nous
utilisons un ensemble de taille 1000, les approches fré-
quentistes peuvent être considérées comme les meilleurs
estimateurs des critères de désaccord et de fusion. Les cri-
tères basés sur la loi bêta sont toujours assez proches et, par
conséquent, cette dernière peut être considérée comme un
bon choix pour modéliser la distribution des probabilités
produites par l’ensemble. A contrario, les critères basés sur
la loi normale ont une performance médiocre en l’absence
d’ambiguïté tout en étant au même niveau ou légèrement
meilleurs autrement. Cette loi ne semble donc pas adaptée
pour modéliser la distribution dans l’espace des logits.

1. ici, parce que nous considérons des tâches de classiﬁcation binaire,
les autres critères basés sur ces moyennes, par exemple, l’entropie etc,
sont équivalents aux critères que nous utilisons

(a)

(b)

(c)

FIGURE 1 – Jeux de données synthétiques avec un degré variable d’ambiguïté et de densité des données. La distribution de
densité de probabilité de x est indiquée en pointiés bleus tandis que la fonction de régression η(x) est indiquée en vert.

FIGURE 2 – Aire sous la courbe des courbes risk/couverture (RC-AUC) pour comparer les différents critères en fonction
de la taille du jeu d’apprentissage. Les colonnes correspondent aux trois jeux de données synthétiques de la Figure 1. La
première ligne compare les critères de désaccord et les critères de fusion entre eux. La seconde ligne les compare aux critères
de base.

Lorsque ces critères sont comparés à ceux de référence,
les critères de fusion donnent des résultats proches de la
moyenne de la probabilité et se situent toujours à l’intérieur
des ﬂuctuations statistiques comme le montre la colonne de
droite de la Figure 2. De plus, il est surprenant de constater
que les autres critères basés sur la dispersion peuvent avoir
de mauvais résultats et, dans certains cas, ils peuvent même
ne pas apparaître sur le graphique.

Deux conclusions principales se dégagent de ces expé-
riences. Premièrement, le bon comportement du critère
fondé sur la moyenne de probabilité indique qu’il semble
saisir une partie de l’incertitude du modèle, ce qui implique
qu’il s’agit d’un estimateur biaisé en ce sens de η(x). Par
exemple, en l’absence d’ambiguïté, il est toujours perfor-
mant alors que l’ambiguïté satisfait η(x) ∈ {0, 1} et n’ap-
porte donc aucune information sur l’incertitude dans ce

cas. Deuxièmement, le critère de fusion proposé ne semble
pas tenir compte de l’incertitude supplémentaire, du moins
dans le cadre de ces expériences synthétiques. Toutefois,
dans la section suivante, nous analysons plus en détail ces
jeux de données contrôlés aﬁn de comprendre s’il existe ef-
fectivement des informations supplémentaires qui peuvent
être exploitées et comment y parvenir.

4 Étude approfondie des rejeteurs

4.1 Visualisation des frontières de décision

Les critères précédemment étudiés peuvent être considé-
rés comme une simple décision prise par seuillage comme
explicité dans l’Équation (9). La plupart d’entre eux dé-
ﬁnissent des frontières de décision, soit sur la moyenne
et la variance dans l’espace de probabilité, (µp, vp), soit

−4−202400.51x00.10.2η(x)p(x)−4−202400.51x00.10.2η(x)p(x)−4−202400.51x00.10.2η(x)p(x)102102.500.51·10−310210324·10−210210300.10.20.30.4disagree.(freq.)disagree.(beta)disagree.(norm.)fusion(freq.)fusion(beta)fusion(norm)Bayesoptimal102102.500.51·10−310210324·10−210210300.10.20.30.4prob.meanprob.var.logitmeanlogitvar.KL-divergencedisagree.(freq.)fusion(freq.)Bayesoptimal(a) # samples = 25

(b) # samples = 100

(c) # samples = 400

(d) # samples = 25

(e) # samples = 100

(f) # samples = 400

FIGURE 3 – La moyenne et la variance des prédictions dans l’espace de probabilité, (µp, vp), pour chaque point de l’espace
d’entrée, c’est-à-dire −4 < x < 4. La couleur de la courbe indique le taux d’erreur pour ces valeurs, le jaune correspondant
à un taux d’erreur élevé et le mauve à un taux faible, le blue étant une valeur intermédiaire. Les première et deuxième lignes
correspondent respectivement au premier et au deuxième jeu de données synthétique.

sur la moyenne et l’écart-type dans l’espace logit, (µz, σz).
Aﬁn de visualiser la complexité de la frontière de décision
idéale, la Figure 3 montre les valeurs de (µp, vp) pour x
variant sur l’espace d’entrée, de −4 à 4, pour les deux pre-
miers jeux de données synthétiques. À chacun de ces points
est associé la probabilité d’erreur en couleur.
Ces ﬁgures montrent que cette frontière de décision idéale
peut en fait être assez complexe et varie en fonction de la
taille du jeu d’apprentissage. De plus, la variance de la zone
avec moins d’incertitude, c’est-à-dire pour x autour de −2,
augmente avec le nombre d’échantillons d’apprentissage et
cette zone ﬁnit par être celle avec la variance la plus élevée.
Au premier abord, cela semble plutôt contre-intuitif. En ef-
fet, si l’on s’attend à ce que la variance donne directement
l’information de l’incertitude du modèle, cette quantité de-
vrait toujours diminuer au fur et à mesure que la taille des
données d’entrainement augmente. De plus, il devrait être
plus faible dans la zone de non-ambiguïté parce que le mo-
dèle devrait la capturer plus rapidement.
Si l’on examine de près la distribution des fonctions de pré-
diction des modèles dans l’ensemble de la Figure 4, cela est
en fait logique. Dans les zones où l’ambiguïté est faible,
lorsqu’on dispose de sufﬁsamment de données d’appren-
tissage, l’incertitude de la fonction de prévision est faible
et nous savons presque exactement où se produit le pas-
sage d’une classe à une autre. Cependant, comme tous les
modèles de l’ensemble ont compris qu’il n’y a pas d’ambi-
guïté, chacun d’entre eux prédit ou bien 0, ou bien 1, avec
une “conﬁance” élevée, ce qui entraîne une variance éle-
vée de cette valeur de conﬁance à ce point précis tout en
ayant un faible risque d’erreur. A contrario, dans les zones
ambigües, la variance est plus faible car chaque modèle a
connaissance de cette ambiguité mais est incertain sur l’en-

droit exact où la transition de la classe 0 à la classe 1 a lieu.
La fonction de décision ﬁnale semble plus incertaine mais
la variance calculée en un point reste relativement faible
comparé à la zone non-ambigüe.
Les Figure 5 et Figure 6 montrent les frontières de dé-
cision des critères de rejet utilisés dans la section précé-
dente, respectivement, dans l’espace de probabilité et l’es-
pace logit. Les critères de désaccord et de fusion que nous
proposons tiennent compte à la fois de la moyenne et de
la variance dans ces espaces et sont donc plus suscep-
tibles de rejeter des zones de forte variance même pour
une moyenne constante ou le contraire. Cependant, ces gra-
phiques mettent en lumière les limites des différents cri-
tères de base et des critères que nous proposons. En ef-
fet, aucun d’entre eux n’a une forme adaptée pour effec-
tuer un rejet efﬁcace sur les jeux de données synthétiques.
Cela est attendu, car plus la variance est élevée, plus il est
probable que nous rejettions. Mais cette hypothèse n’est
pas la bonne ici, ce qui souligne la complexité de l’élabo-
ration d’un critère théorique. Cependant, comme on peut
le remarquer dans la Figure 3, les zones de taux d’erreur
différents peuvent toujours être séparées dans l’espace de
(µp, vp). Nous pouvons donc essayer d’apprendre de ma-
nière supervisée à mieux rejeter.

4.2 Apprentissage supervisé du réjecteur

Étant donnée que la frontière de décision du réjecteur est
une fonction complexe, comme nous l’avons vu dans la
sous-section précédente, nous proposons d’essayer de l’ap-
prendre à partir des données en utilisant un jeu de données
de calibration. Pour ce faire, nous devons revenir à la fonc-
tion de risque de la classiﬁcation avec option de rejet de
l’Équation (1). Dans notre cas, h est déjà appris et il suf-

0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp(a) # samples = 25

(b) # samples = 100

(c) # samples = 400

FIGURE 4 – Diagrammes en centiles des distributions binaires prédites par les modèles de l’ensemble pour plusieurs tailles
du jeu d’apprentissage. Les centiles représentés en pointillés sont : 5%, 10%, 25%, 50%, 75%, 90% et 95%. La moyenne de
ces prédictions est indiquée en vert.

(a) moyenne des probabilités

(b) variance des probabilités

(c) désaccord (bêta)

(d) fusion (bêta)

FIGURE 5 – Frontières de décision des différents critères dans l’espace (µp, vp) de l’espace de probabilité.

ﬁt donc d’optimiser le risque précédent par rapport à r. Ce
scénario a été étudié dans le contexte de l’apprentissage
séquentiel [22]. Cela revient simplement à apprendre une
tâche de classiﬁcation binaire pondérée

Rrej

λ (h, r) = EX,E

(cid:2)wEδr(X)(cid:54)=E

(cid:3) ,

(10)

où E est la variable aléatoire correspondant à une erreur de
prédiction, E = δh(X)(cid:54)=Y , et les poids sont égaux à w0 = λ
et w1 = 1 − λ.
Le réjecteur de Bayes optimal est dans ce cas égal à

(11)

r∗(x) = δηE (x)>λ
où ηE(x) est la fonction de régression de l’Équation (10),
c’est-à-dire ηE(x) = Pr [Y (cid:54)= h(X) | X = x].
Nous pouvons alors apprendre n’importe quel modèle de
classiﬁcation habituel pour effectuer cette tâche. En faisant
varier la valeur de λ, on peut alors reconstituer la courbe
RC en réapprenant le réjecteur adapté à chaque fois.
Notre but ici n’est pas de construire le meilleur modèle de
rejet mais plutôt de montrer qu’en changeant notre espace
d’entrée pour le rejet de x ∈ X à (µp, vp) ∈ R2, nous
conservons encore sufﬁsamment d’informations discrimi-
nantes pour effectuer le rejet. Nous ne prétendons pas qu’il
s’agit du meilleur espace pour accomplir cette tâche mais
qu’il est sufﬁsant pour apprendre de meilleurs critères de
rejet que les critères précédents.
Nous utilisons des classiﬁeurs polynomiaux de degré 3 en-
trainés avec une fonction de coût logistique. Nous utilisons
beaucoup de données d’étalonnage, soit 1000 échantillons,
pour apprendre le réjecteur. Ce chiffre n’est pas réaliste
dans un scénario réel où nous préférerions utiliser ces don-

nées pour améliorer notre prédicteur. Cependant, notre but
ici est de comprendre à quel point un dispositif de rejet peut
devenir meilleur si nous lui permettons d’être plus com-
plexe et d’être dépendant de la tâche. La Figure 7 montre la
courbe RC-AUC du rejecteur par rapport aux critères pré-
cedents et aux réjecteurs de Bayes des Équations (11) et (2)
sur le deuxième jeu de données synthétique. La fonction de
rejet apprise est en effet bien meilleure que les critères pré-
cédents. Cela montre la richesse de l’information contenue
dans le plan (µp, vp).

5 Conclusion et travaux futurs

Les critères classiques, tels que la valeur maximale de la
probabilité prédite par un réseau neuronal, fonctionnent
bien dans la pratique, cependant ils n’utilisent pas toute
l’information d’incertitude disponible. L’analyse des pré-
dictions d’un ensemble met en lumière certains comporte-
ments contre-intuitifs qui soulignent notre mauvaise com-
préhension de l’information d’incertitude capturée par ces
modèles. Trouver un bon critère de rejet qui tire parti de
toute cette information et qui généralise à différentes tâches
est un problème difﬁcile.
Une suite naturelle de ces travaux est d’effectuer des ana-
lyses sur des données réelles aﬁn de vériﬁer que les com-
portements présentés ici se produisent également dans des
jeux de données usuels. De plus, ce travail ouvre la voie
à l’élaboration d’un meilleur critère de rejet. Une piste de
recherche en ce sens consiste à trouver un espace de re-
présentation plus adapté pour l’apprentissage supervisé des
réjeteurs aﬁn de permettre à ces derniers d’être calibrés en

−4−202400.51−4−202400.51−4−202400.510.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp0.00.20.40.60.81.0p0.000.020.040.060.080.10vp(a) moyenne des logits

(b) écart-type des logits

(c) désaccord (normale)

(d) fusion (normale)

FIGURE 6 – Frontières de décision des différents critères dans l’espace (µz, σz) de l’espace des logits.

[11] P. Germain, A. Lacasse, F. Laviolette, M. Marchand, and
J.-F. Roy. Risk bounds for the majority vote : from a PAC-
Bayesian analysis to a learning algorithm. J. Mach. Learn.
Res., 2015.

[12] T. Gneiting and A. E. Raftery. Strictly proper scoring rules,
prediction, and estimation. J. Am. Stat. Assoc., 2007.

[13] S. Hanneke et al. Theory of disagreement-based active lear-

ning. Found. and Trends R(cid:13) in Mach. Learn., 2014.

[14] R. Herbei and M. H. Wegkamp. Classiﬁcation with reject

option. Can. J. Stat., 2006.

[15] A. Kendall and Y. Gal. What uncertainties do we need in
Bayesian Deep Learning for Computer Vision ? In NeurIPS,
2017.

[16] B. Lakshminarayanan, A. Pritzel, and C. Blundell. Simple
and scalable predictive uncertainty estimation using deep
ensembles. In NeurIPS, 2017.

[17] A. Mandelbaum and D. Weinshall. Distance-based conﬁ-
dence score for neural network classiﬁers. arXiv preprint
arXiv :1709.09844, 2017.

[18] R. M. Neal. Bayesian learning for neural networks, volume

118. Springer Science & Business Media, 2012.

[19] D. J. Rezende, S. Mohamed, and D. Wierstra. Stochastic
backpropagation and approximate inference in deep gene-
rative models. In ICML, 2014.

[20] R. E. Schapire and Y. Singer. Improved boosting algorithms
using conﬁdence-rated predictions. Mach. Learn., 1999.

[21] B. Settles. Active learning. Synthesis Lectures on Artiﬁcial

Intelligence and Machine Learning, 2012.

[22] K. Trapeznikov and V. Saligrama. Supervised sequential
classiﬁcation under budget constraints. In AISTATS, 2013.

[23] Y. Wiener and R. El-Yaniv. Agnostic selective classiﬁcation.

FIGURE 7 – Aire sous la courbe des courbes RC (RC-
AUC) comparant
le réjecteur supervisé aux différents
autres critères avec une taille du jeu d’apprentissage va-
riable sur le deuxième jeu de données synthétique.

utilisant beaucoup moins de données.

Remerciements
Ce travail a été partiellement ﬁnancé par le projet ANR
WeedElec.

Références
[1] P. L. Bartlett and M. H. Wegkamp. Classiﬁcation with a
reject option using a hinge loss. J. Mach. Learn. Res., 2008.

[2] C. Blundell, J. Cornebise, K. Kavukcuoglu, and D. Wierstra.
Weight uncertainty in neural network. In ICML, 2015.

[3] L. Breiman. Bagging predictors. Mach. Learn., 1996.

[4] C. K. Chow. An optimum character recognition system

using decision functions. IRE T. Elec. Comp., 1957.

[5] C. K. Chow. On optimum recognition error and reject tra-

In NeurIPS, 2011.

deoff. IEEE Trans. Inf. Theory, 1970.

[24] Y. Wiener and R. El-Yaniv. Agnostic pointwise-competitive

[6] C. Cortes, G. DeSalvo, and M. Mohri. Learning with rejec-

selective classiﬁcation. J. Artif. Intell. Res., 2015.

tion. In ALT, 2016.

[7] A. Der Kiureghian and O. Ditlevsen. Aleatory or epistemic ?

Does it matter ? Struct. Saf., 2009.

[8] R. El-Yaniv and Y. Wiener. On the foundations of noise-free

selective classiﬁcation. J. Mach. Learn. Res., 2010.

[9] Y. Gal and Z. Ghahramani. Dropout as a Bayesian approxi-
mation : representing model uncertainty in Deep Learning.
In ICML, 2016.

[10] Y. Geifman, G. Uziel, and R. El-Yaniv. Bias-reduced uncer-
tainty estimation for deep neural classiﬁers. In ICLR, 2019.

[25] M. Yuan and M. Wegkamp. Classiﬁcation methods with
reject option based on convex risk minimization. J. Mach.
Learn. Res., 2010.

6420246z100101z6420246z100101z6420246z100101z6420246z100101z102103123·10−2prob.meanlogitmeanfusion(freq.)supervisedBayesrejectorBayesoptimal